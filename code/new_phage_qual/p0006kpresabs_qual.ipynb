{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0006kpresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0006kpresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "248    1\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>GAGTCCTGTTT</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>CAGAAAAGCGT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  \\\n",
       "0     107            1              1              1               1   \n",
       "1     109            1              1              1               1   \n",
       "2     115            1              1              1               1   \n",
       "3  120335            1              1              1               1   \n",
       "4  120337            1              1              1               1   \n",
       "\n",
       "   TATTATGTTAATG  TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  \\\n",
       "0              1            1             1               1            1   \n",
       "1              1            1             1               1            1   \n",
       "2              1            1             1               1            1   \n",
       "3              1            1             1               1            1   \n",
       "4              1            1             1               1            1   \n",
       "\n",
       "   GAGTCCTGTT  GAGTCCTGTTT  \\\n",
       "0           1            1   \n",
       "1           1            1   \n",
       "2           1            1   \n",
       "3           1            1   \n",
       "4           1            1   \n",
       "\n",
       "   GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                  0                                                     \n",
       "1                                                  0                                                     \n",
       "2                                                  0                                                     \n",
       "3                                                  0                                                     \n",
       "4                                                  0                                                     \n",
       "\n",
       "   CTTTTTCACCTGT  CTTGTGAATTTAG  \\\n",
       "0              1              1   \n",
       "1              1              1   \n",
       "2              1              1   \n",
       "3              1              1   \n",
       "4              1              1   \n",
       "\n",
       "   CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG  CGCCATTATGTT  \\\n",
       "0                                                  1              0   \n",
       "1                                                  1              0   \n",
       "2                                                  1              1   \n",
       "3                                                  1              0   \n",
       "4                                                  1              0   \n",
       "\n",
       "   CAGAAAAGCGT  ACAATTACTATATTT  pheno  \n",
       "0            1                1      1  \n",
       "1            1                1      0  \n",
       "2            1                1      1  \n",
       "3            1                1      1  \n",
       "4            1                1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>GAGTCCTGTTT</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>CAGAAAAGCGT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  TATTATGTTAATG  \\\n",
       "0            1              1              1               1              1   \n",
       "1            1              1              1               1              1   \n",
       "2            1              1              1               1              1   \n",
       "3            1              1              1               1              1   \n",
       "4            1              1              1               1              1   \n",
       "\n",
       "   TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  GAGTCCTGTT  \\\n",
       "0            1             1               1            1           1   \n",
       "1            1             1               1            1           1   \n",
       "2            1             1               1            1           1   \n",
       "3            1             1               1            1           1   \n",
       "4            1             1               1            1           1   \n",
       "\n",
       "   GAGTCCTGTTT  \\\n",
       "0            1   \n",
       "1            1   \n",
       "2            1   \n",
       "3            1   \n",
       "4            1   \n",
       "\n",
       "   GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                  0                                                     \n",
       "1                                                  0                                                     \n",
       "2                                                  0                                                     \n",
       "3                                                  0                                                     \n",
       "4                                                  0                                                     \n",
       "\n",
       "   CTTTTTCACCTGT  CTTGTGAATTTAG  \\\n",
       "0              1              1   \n",
       "1              1              1   \n",
       "2              1              1   \n",
       "3              1              1   \n",
       "4              1              1   \n",
       "\n",
       "   CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG  CGCCATTATGTT  \\\n",
       "0                                                  1              0   \n",
       "1                                                  1              0   \n",
       "2                                                  1              1   \n",
       "3                                                  1              0   \n",
       "4                                                  1              0   \n",
       "\n",
       "   CAGAAAAGCGT  ACAATTACTATATTT  pheno  \n",
       "0            1                1      1  \n",
       "1            1                1      0  \n",
       "2            1                1      1  \n",
       "3            1                1      1  \n",
       "4            1                1      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 19) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS383     1\n",
       "1       NRS254     1\n",
       "2       NRS218     1\n",
       "3       NRS215     0\n",
       "4    BCH-SA-14     2\n",
       "..         ...   ...\n",
       "112     NRS227     1\n",
       "113     NRS272     1\n",
       "114   CFBRSa24     0\n",
       "115   CFBRSa74     0\n",
       "116     NRS271     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 1.1545 - accuracy: 0.2519 - val_loss: 1.1221 - val_accuracy: 0.2735\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.1250 - accuracy: 0.2593 - val_loss: 1.1014 - val_accuracy: 0.2991\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 1.1092 - accuracy: 0.3111 - val_loss: 1.0872 - val_accuracy: 0.3761\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 1.0985 - accuracy: 0.3296 - val_loss: 1.0775 - val_accuracy: 0.3675\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 1.0883 - accuracy: 0.3889 - val_loss: 1.0634 - val_accuracy: 0.4444\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.0786 - accuracy: 0.4296 - val_loss: 1.0493 - val_accuracy: 0.4701\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0686 - accuracy: 0.4593 - val_loss: 1.0386 - val_accuracy: 0.4957\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.0611 - accuracy: 0.4667 - val_loss: 1.0303 - val_accuracy: 0.4957\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.31 - 0s 104us/step - loss: 1.0521 - accuracy: 0.4630 - val_loss: 1.0260 - val_accuracy: 0.5128\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.0477 - accuracy: 0.4926 - val_loss: 1.0205 - val_accuracy: 0.5128\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.0200 - accuracy: 0.56 - 0s 112us/step - loss: 1.0404 - accuracy: 0.4852 - val_loss: 1.0147 - val_accuracy: 0.5128\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0346 - accuracy: 0.4852 - val_loss: 1.0105 - val_accuracy: 0.5128\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0325 - accuracy: 0.4630 - val_loss: 1.0044 - val_accuracy: 0.5299\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.0245 - accuracy: 0.5074 - val_loss: 1.0023 - val_accuracy: 0.5299\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.0211 - accuracy: 0.5074 - val_loss: 0.9977 - val_accuracy: 0.5299\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 1.0172 - accuracy: 0.5148 - val_loss: 0.9952 - val_accuracy: 0.5299\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0129 - accuracy: 0.5148 - val_loss: 0.9899 - val_accuracy: 0.5299\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9947 - accuracy: 0.50 - 0s 110us/step - loss: 1.0088 - accuracy: 0.5185 - val_loss: 0.9859 - val_accuracy: 0.5299\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0045 - accuracy: 0.5185 - val_loss: 0.9805 - val_accuracy: 0.5299\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0003 - accuracy: 0.5185 - val_loss: 0.9786 - val_accuracy: 0.5299\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9976 - accuracy: 0.5222 - val_loss: 0.9762 - val_accuracy: 0.5299\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9985 - accuracy: 0.5259 - val_loss: 0.9792 - val_accuracy: 0.5299\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9930 - accuracy: 0.5222 - val_loss: 0.9737 - val_accuracy: 0.5299\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9903 - accuracy: 0.4926 - val_loss: 0.9688 - val_accuracy: 0.5299\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9891 - accuracy: 0.4963 - val_loss: 0.9685 - val_accuracy: 0.5128\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9861 - accuracy: 0.4852 - val_loss: 0.9681 - val_accuracy: 0.5299\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9823 - accuracy: 0.5222 - val_loss: 0.9685 - val_accuracy: 0.5299\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9825 - accuracy: 0.5222 - val_loss: 0.9695 - val_accuracy: 0.5299\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9797 - accuracy: 0.5222 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9783 - accuracy: 0.5074 - val_loss: 0.9633 - val_accuracy: 0.5128\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9757 - accuracy: 0.5074 - val_loss: 0.9615 - val_accuracy: 0.5299\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9760 - accuracy: 0.5222 - val_loss: 0.9599 - val_accuracy: 0.5299\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9726 - accuracy: 0.5222 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9727 - accuracy: 0.5259 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.9697 - accuracy: 0.5111 - val_loss: 0.9585 - val_accuracy: 0.5299\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.9697 - accuracy: 0.5222 - val_loss: 0.9553 - val_accuracy: 0.5299\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9680 - accuracy: 0.5259 - val_loss: 0.9578 - val_accuracy: 0.5299\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9663 - accuracy: 0.5259 - val_loss: 0.9573 - val_accuracy: 0.5299\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9653 - accuracy: 0.5259 - val_loss: 0.9556 - val_accuracy: 0.5299\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9643 - accuracy: 0.5259 - val_loss: 0.9563 - val_accuracy: 0.5299\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9658 - accuracy: 0.5259 - val_loss: 0.9596 - val_accuracy: 0.5299\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9648 - accuracy: 0.4852 - val_loss: 0.9540 - val_accuracy: 0.5299\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9623 - accuracy: 0.5259 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9608 - accuracy: 0.5259 - val_loss: 0.9528 - val_accuracy: 0.5299\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9596 - accuracy: 0.5074 - val_loss: 0.9535 - val_accuracy: 0.5128\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9587 - accuracy: 0.5148 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9586 - accuracy: 0.5259 - val_loss: 0.9563 - val_accuracy: 0.5299\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9602 - accuracy: 0.5259 - val_loss: 0.9541 - val_accuracy: 0.5299\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9563 - accuracy: 0.5222 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9579 - accuracy: 0.5074 - val_loss: 0.9541 - val_accuracy: 0.5128\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9545 - accuracy: 0.5185 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9546 - accuracy: 0.5259 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9552 - accuracy: 0.5185 - val_loss: 0.9527 - val_accuracy: 0.5299\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9522 - accuracy: 0.5222 - val_loss: 0.9556 - val_accuracy: 0.5299\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9539 - accuracy: 0.5259 - val_loss: 0.9554 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9533 - accuracy: 0.5037 - val_loss: 0.9514 - val_accuracy: 0.5128\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9517 - accuracy: 0.5111 - val_loss: 0.9519 - val_accuracy: 0.5299\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9531 - accuracy: 0.5296 - val_loss: 0.9554 - val_accuracy: 0.5299\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9531 - accuracy: 0.4963 - val_loss: 0.9540 - val_accuracy: 0.5128\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9512 - accuracy: 0.5259 - val_loss: 0.9556 - val_accuracy: 0.5299\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9507 - accuracy: 0.5222 - val_loss: 0.9486 - val_accuracy: 0.5299\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9492 - accuracy: 0.4963 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9502 - accuracy: 0.5296 - val_loss: 0.9566 - val_accuracy: 0.5299\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9464 - accuracy: 0.5296 - val_loss: 0.9496 - val_accuracy: 0.5299\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9464 - accuracy: 0.5111 - val_loss: 0.9494 - val_accuracy: 0.5128\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9446 - accuracy: 0.5407 - val_loss: 0.9513 - val_accuracy: 0.5299\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9460 - accuracy: 0.5296 - val_loss: 0.9563 - val_accuracy: 0.5299\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9442 - accuracy: 0.5370 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9449 - accuracy: 0.5370 - val_loss: 0.9505 - val_accuracy: 0.5299\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9441 - accuracy: 0.5185 - val_loss: 0.9505 - val_accuracy: 0.5128\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9475 - accuracy: 0.4889 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9403 - accuracy: 0.5370 - val_loss: 0.9509 - val_accuracy: 0.5128\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.9494 - accuracy: 0.5222 - val_loss: 0.9516 - val_accuracy: 0.5128\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9494 - accuracy: 0.50 - 0s 125us/step - loss: 0.9440 - accuracy: 0.5259 - val_loss: 0.9492 - val_accuracy: 0.5299\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9408 - accuracy: 0.5333 - val_loss: 0.9530 - val_accuracy: 0.5299\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9416 - accuracy: 0.5407 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.9388 - accuracy: 0.5407 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9404 - accuracy: 0.5444 - val_loss: 0.9521 - val_accuracy: 0.5128\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9394 - accuracy: 0.4926 - val_loss: 0.9477 - val_accuracy: 0.5299\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.9404 - accuracy: 0.5000 - val_loss: 0.9490 - val_accuracy: 0.5128\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9380 - accuracy: 0.5370 - val_loss: 0.9511 - val_accuracy: 0.5299\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9372 - accuracy: 0.5407 - val_loss: 0.9484 - val_accuracy: 0.5299\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9395 - accuracy: 0.5370 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9345 - accuracy: 0.5407 - val_loss: 0.9493 - val_accuracy: 0.5128\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9354 - accuracy: 0.5296 - val_loss: 0.9493 - val_accuracy: 0.5128\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9361 - accuracy: 0.5296 - val_loss: 0.9502 - val_accuracy: 0.5299\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9335 - accuracy: 0.5407 - val_loss: 0.9524 - val_accuracy: 0.5299\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9347 - accuracy: 0.5444 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9354 - accuracy: 0.5444 - val_loss: 0.9509 - val_accuracy: 0.5299\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9357 - accuracy: 0.5074 - val_loss: 0.9478 - val_accuracy: 0.5128\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9335 - accuracy: 0.5296 - val_loss: 0.9502 - val_accuracy: 0.5299\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9333 - accuracy: 0.5407 - val_loss: 0.9534 - val_accuracy: 0.5299\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9321 - accuracy: 0.5444 - val_loss: 0.9511 - val_accuracy: 0.5299\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9307 - accuracy: 0.5370 - val_loss: 0.9476 - val_accuracy: 0.5128\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9325 - accuracy: 0.5222 - val_loss: 0.9482 - val_accuracy: 0.5299\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9322 - accuracy: 0.5407 - val_loss: 0.9481 - val_accuracy: 0.5299\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9303 - accuracy: 0.5407 - val_loss: 0.9483 - val_accuracy: 0.5299\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9384 - accuracy: 0.5074 - val_loss: 0.9482 - val_accuracy: 0.5128\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9370 - accuracy: 0.5000 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9287 - accuracy: 0.5444 - val_loss: 0.9481 - val_accuracy: 0.5299\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9304 - accuracy: 0.5259 - val_loss: 0.9487 - val_accuracy: 0.5128\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9313 - accuracy: 0.5148 - val_loss: 0.9471 - val_accuracy: 0.5299\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9298 - accuracy: 0.5407 - val_loss: 0.9507 - val_accuracy: 0.5299\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9280 - accuracy: 0.5444 - val_loss: 0.9492 - val_accuracy: 0.5299\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.9299 - accuracy: 0.5259 - val_loss: 0.9483 - val_accuracy: 0.5128\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9267 - accuracy: 0.5148 - val_loss: 0.9495 - val_accuracy: 0.5299\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9274 - accuracy: 0.5407 - val_loss: 0.9492 - val_accuracy: 0.5299\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9265 - accuracy: 0.5407 - val_loss: 0.9503 - val_accuracy: 0.5299\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9262 - accuracy: 0.5407 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9285 - accuracy: 0.5407 - val_loss: 0.9534 - val_accuracy: 0.5299\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9269 - accuracy: 0.5370 - val_loss: 0.9491 - val_accuracy: 0.5128\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9251 - accuracy: 0.5074 - val_loss: 0.9529 - val_accuracy: 0.5299\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.9259 - accuracy: 0.5111 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9254 - accuracy: 0.5444 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9277 - accuracy: 0.5407 - val_loss: 0.9499 - val_accuracy: 0.5299\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9226 - accuracy: 0.5185 - val_loss: 0.9480 - val_accuracy: 0.5128\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9252 - accuracy: 0.5296 - val_loss: 0.9484 - val_accuracy: 0.5299\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9278 - accuracy: 0.5444 - val_loss: 0.9562 - val_accuracy: 0.5299\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9229 - accuracy: 0.5407 - val_loss: 0.9509 - val_accuracy: 0.5299\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.9225 - accuracy: 0.5407 - val_loss: 0.9492 - val_accuracy: 0.5299\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9220 - accuracy: 0.5407 - val_loss: 0.9510 - val_accuracy: 0.5299\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9223 - accuracy: 0.5407 - val_loss: 0.9477 - val_accuracy: 0.5299\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9205 - accuracy: 0.5407 - val_loss: 0.9493 - val_accuracy: 0.5299\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9206 - accuracy: 0.5407 - val_loss: 0.9517 - val_accuracy: 0.5299\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9201 - accuracy: 0.5407 - val_loss: 0.9480 - val_accuracy: 0.5299\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9205 - accuracy: 0.5444 - val_loss: 0.9480 - val_accuracy: 0.5299\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9185 - accuracy: 0.5407 - val_loss: 0.9454 - val_accuracy: 0.5299\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9201 - accuracy: 0.5000 - val_loss: 0.9442 - val_accuracy: 0.5299\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9197 - accuracy: 0.5444 - val_loss: 0.9478 - val_accuracy: 0.5299\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9176 - accuracy: 0.5407 - val_loss: 0.9476 - val_accuracy: 0.5299\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9190 - accuracy: 0.5333 - val_loss: 0.9473 - val_accuracy: 0.5128\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9175 - accuracy: 0.5407 - val_loss: 0.9467 - val_accuracy: 0.5299\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9203 - accuracy: 0.5444 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9172 - accuracy: 0.5444 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9166 - accuracy: 0.5444 - val_loss: 0.9475 - val_accuracy: 0.5299\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9174 - accuracy: 0.5185 - val_loss: 0.9451 - val_accuracy: 0.5299\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9179 - accuracy: 0.5407 - val_loss: 0.9443 - val_accuracy: 0.5299\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9152 - accuracy: 0.5407 - val_loss: 0.9458 - val_accuracy: 0.5299\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9156 - accuracy: 0.5407 - val_loss: 0.9453 - val_accuracy: 0.5299\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9142 - accuracy: 0.5407 - val_loss: 0.9478 - val_accuracy: 0.5299\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9151 - accuracy: 0.5259 - val_loss: 0.9486 - val_accuracy: 0.5128\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9165 - accuracy: 0.5074 - val_loss: 0.9511 - val_accuracy: 0.5299\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9151 - accuracy: 0.5333 - val_loss: 0.9497 - val_accuracy: 0.5128\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9141 - accuracy: 0.5222 - val_loss: 0.9500 - val_accuracy: 0.5299\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9148 - accuracy: 0.5407 - val_loss: 0.9534 - val_accuracy: 0.5299\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9147 - accuracy: 0.5444 - val_loss: 0.9491 - val_accuracy: 0.5299\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9128 - accuracy: 0.5407 - val_loss: 0.9486 - val_accuracy: 0.5299\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9155 - accuracy: 0.4889 - val_loss: 0.9460 - val_accuracy: 0.5299\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9129 - accuracy: 0.5444 - val_loss: 0.9501 - val_accuracy: 0.5299\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9119 - accuracy: 0.5444 - val_loss: 0.9489 - val_accuracy: 0.5299\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.71 - 0s 134us/step - loss: 0.9113 - accuracy: 0.5407 - val_loss: 0.9486 - val_accuracy: 0.5299\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.9102 - accuracy: 0.5444 - val_loss: 0.9494 - val_accuracy: 0.5299\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9108 - accuracy: 0.5444 - val_loss: 0.9478 - val_accuracy: 0.5299\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9113 - accuracy: 0.5444 - val_loss: 0.9483 - val_accuracy: 0.5299\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9097 - accuracy: 0.5444 - val_loss: 0.9500 - val_accuracy: 0.5299\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9097 - accuracy: 0.5481 - val_loss: 0.9493 - val_accuracy: 0.5299\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9088 - accuracy: 0.5481 - val_loss: 0.9463 - val_accuracy: 0.5299\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9092 - accuracy: 0.5444 - val_loss: 0.9489 - val_accuracy: 0.5299\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9087 - accuracy: 0.5481 - val_loss: 0.9464 - val_accuracy: 0.5299\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9133 - accuracy: 0.5148 - val_loss: 0.9489 - val_accuracy: 0.5128\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9115 - accuracy: 0.5185 - val_loss: 0.9505 - val_accuracy: 0.5299\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9099 - accuracy: 0.5444 - val_loss: 0.9488 - val_accuracy: 0.5299\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9074 - accuracy: 0.5481 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9076 - accuracy: 0.5111 - val_loss: 0.9466 - val_accuracy: 0.5299\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9072 - accuracy: 0.5481 - val_loss: 0.9514 - val_accuracy: 0.5299\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 86us/step - loss: 0.9128 - accuracy: 0.5370 - val_loss: 0.9487 - val_accuracy: 0.5299\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9053 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9068 - accuracy: 0.5444 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9067 - accuracy: 0.5222 - val_loss: 0.9483 - val_accuracy: 0.5299\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9065 - accuracy: 0.5148 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9051 - accuracy: 0.5481 - val_loss: 0.9477 - val_accuracy: 0.5299\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9038 - accuracy: 0.5481 - val_loss: 0.9457 - val_accuracy: 0.5299\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9042 - accuracy: 0.5259 - val_loss: 0.9473 - val_accuracy: 0.5128\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9479 - accuracy: 0.43 - 0s 110us/step - loss: 0.9097 - accuracy: 0.5333 - val_loss: 0.9541 - val_accuracy: 0.5299\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9043 - accuracy: 0.5407 - val_loss: 0.9514 - val_accuracy: 0.5128\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9048 - accuracy: 0.5481 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9051 - accuracy: 0.5519 - val_loss: 0.9489 - val_accuracy: 0.5128\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9023 - accuracy: 0.5333 - val_loss: 0.9527 - val_accuracy: 0.5385\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9027 - accuracy: 0.5519 - val_loss: 0.9490 - val_accuracy: 0.5299\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9019 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9013 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5299\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9063 - accuracy: 0.5259 - val_loss: 0.9464 - val_accuracy: 0.5128\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9032 - accuracy: 0.5556 - val_loss: 0.9510 - val_accuracy: 0.5385\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9014 - accuracy: 0.5481 - val_loss: 0.9457 - val_accuracy: 0.5299\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9020 - accuracy: 0.5481 - val_loss: 0.9461 - val_accuracy: 0.5299\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9019 - accuracy: 0.5222 - val_loss: 0.9436 - val_accuracy: 0.5128\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9007 - accuracy: 0.5519 - val_loss: 0.9459 - val_accuracy: 0.5385\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8992 - accuracy: 0.5519 - val_loss: 0.9467 - val_accuracy: 0.5385\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8990 - accuracy: 0.5481 - val_loss: 0.9444 - val_accuracy: 0.5299\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8992 - accuracy: 0.5370 - val_loss: 0.9435 - val_accuracy: 0.5128\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9000 - accuracy: 0.5333 - val_loss: 0.9480 - val_accuracy: 0.5385\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8991 - accuracy: 0.5481 - val_loss: 0.9484 - val_accuracy: 0.5385\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8979 - accuracy: 0.5481 - val_loss: 0.9450 - val_accuracy: 0.5299\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8976 - accuracy: 0.5259 - val_loss: 0.9486 - val_accuracy: 0.5299\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9006 - accuracy: 0.5074 - val_loss: 0.9479 - val_accuracy: 0.5299\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8975 - accuracy: 0.5481 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8973 - accuracy: 0.5444 - val_loss: 0.9475 - val_accuracy: 0.5299\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8972 - accuracy: 0.5481 - val_loss: 0.9464 - val_accuracy: 0.5299\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8976 - accuracy: 0.5481 - val_loss: 0.9453 - val_accuracy: 0.5299\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8971 - accuracy: 0.5370 - val_loss: 0.9477 - val_accuracy: 0.5128\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8960 - accuracy: 0.5407 - val_loss: 0.9470 - val_accuracy: 0.5299\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8950 - accuracy: 0.5519 - val_loss: 0.9485 - val_accuracy: 0.5385\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8961 - accuracy: 0.5519 - val_loss: 0.9469 - val_accuracy: 0.5385\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8936 - accuracy: 0.5519 - val_loss: 0.9451 - val_accuracy: 0.5128\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8957 - accuracy: 0.5296 - val_loss: 0.9433 - val_accuracy: 0.5299\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8960 - accuracy: 0.5148 - val_loss: 0.9442 - val_accuracy: 0.5299\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8967 - accuracy: 0.5519 - val_loss: 0.9487 - val_accuracy: 0.5385\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8962 - accuracy: 0.5519 - val_loss: 0.9488 - val_accuracy: 0.5385\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8959 - accuracy: 0.5222 - val_loss: 0.9461 - val_accuracy: 0.5128\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8919 - accuracy: 0.5704 - val_loss: 0.9484 - val_accuracy: 0.5385\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9008 - accuracy: 0.5481 - val_loss: 0.9537 - val_accuracy: 0.5385\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8981 - accuracy: 0.5148 - val_loss: 0.9476 - val_accuracy: 0.5214\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8943 - accuracy: 0.5222 - val_loss: 0.9496 - val_accuracy: 0.5385\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8943 - accuracy: 0.5519 - val_loss: 0.9523 - val_accuracy: 0.5385\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8923 - accuracy: 0.5481 - val_loss: 0.9470 - val_accuracy: 0.5385\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8921 - accuracy: 0.5519 - val_loss: 0.9463 - val_accuracy: 0.5385\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8923 - accuracy: 0.5481 - val_loss: 0.9464 - val_accuracy: 0.5385\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8935 - accuracy: 0.5481 - val_loss: 0.9494 - val_accuracy: 0.5385\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8902 - accuracy: 0.5444 - val_loss: 0.9501 - val_accuracy: 0.5128\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8927 - accuracy: 0.5370 - val_loss: 0.9476 - val_accuracy: 0.5299\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8940 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5385\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8906 - accuracy: 0.5519 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8919 - accuracy: 0.5370 - val_loss: 0.9460 - val_accuracy: 0.5214\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8912 - accuracy: 0.5444 - val_loss: 0.9466 - val_accuracy: 0.5385\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9001 - accuracy: 0.5481 - val_loss: 0.9470 - val_accuracy: 0.5385\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8946 - accuracy: 0.5296 - val_loss: 0.9463 - val_accuracy: 0.5128\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8929 - accuracy: 0.5370 - val_loss: 0.9465 - val_accuracy: 0.5385\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8893 - accuracy: 0.5519 - val_loss: 0.9469 - val_accuracy: 0.5385\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8893 - accuracy: 0.5519 - val_loss: 0.9471 - val_accuracy: 0.5299\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8896 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8897 - accuracy: 0.5481 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8878 - accuracy: 0.5519 - val_loss: 0.9476 - val_accuracy: 0.5214\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8898 - accuracy: 0.5407 - val_loss: 0.9472 - val_accuracy: 0.5214\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8928 - accuracy: 0.5185 - val_loss: 0.9469 - val_accuracy: 0.5385\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8868 - accuracy: 0.5481 - val_loss: 0.9466 - val_accuracy: 0.5385\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8884 - accuracy: 0.5593 - val_loss: 0.9501 - val_accuracy: 0.5214\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8935 - accuracy: 0.5111 - val_loss: 0.9462 - val_accuracy: 0.5299\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8859 - accuracy: 0.5481 - val_loss: 0.9485 - val_accuracy: 0.5385\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8871 - accuracy: 0.5481 - val_loss: 0.9500 - val_accuracy: 0.5385\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8879 - accuracy: 0.5519 - val_loss: 0.9520 - val_accuracy: 0.5385\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8871 - accuracy: 0.5148 - val_loss: 0.9460 - val_accuracy: 0.5128\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8864 - accuracy: 0.5630 - val_loss: 0.9486 - val_accuracy: 0.5385\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8903 - accuracy: 0.5481 - val_loss: 0.9505 - val_accuracy: 0.5385\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8879 - accuracy: 0.5593 - val_loss: 0.9514 - val_accuracy: 0.5128\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8924 - accuracy: 0.5407 - val_loss: 0.9472 - val_accuracy: 0.5385\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8847 - accuracy: 0.5519 - val_loss: 0.9455 - val_accuracy: 0.5385\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8848 - accuracy: 0.5481 - val_loss: 0.9494 - val_accuracy: 0.5385\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8856 - accuracy: 0.5481 - val_loss: 0.9445 - val_accuracy: 0.5385\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8863 - accuracy: 0.5407 - val_loss: 0.9466 - val_accuracy: 0.5214\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8848 - accuracy: 0.5519 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8841 - accuracy: 0.5519 - val_loss: 0.9476 - val_accuracy: 0.5385\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8879 - accuracy: 0.5296 - val_loss: 0.9477 - val_accuracy: 0.5128\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8843 - accuracy: 0.5296 - val_loss: 0.9449 - val_accuracy: 0.5385\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8854 - accuracy: 0.5481 - val_loss: 0.9453 - val_accuracy: 0.5385\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8868 - accuracy: 0.5111 - val_loss: 0.9439 - val_accuracy: 0.5214\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8824 - accuracy: 0.5630 - val_loss: 0.9498 - val_accuracy: 0.5385\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8852 - accuracy: 0.5481 - val_loss: 0.9482 - val_accuracy: 0.5385\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8833 - accuracy: 0.5519 - val_loss: 0.9457 - val_accuracy: 0.5385\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8836 - accuracy: 0.5519 - val_loss: 0.9457 - val_accuracy: 0.5385\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8866 - accuracy: 0.5037 - val_loss: 0.9434 - val_accuracy: 0.5385\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8831 - accuracy: 0.5185 - val_loss: 0.9445 - val_accuracy: 0.5385\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8870 - accuracy: 0.5519 - val_loss: 0.9459 - val_accuracy: 0.5385\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8856 - accuracy: 0.5481 - val_loss: 0.9478 - val_accuracy: 0.5214\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8859 - accuracy: 0.5370 - val_loss: 0.9433 - val_accuracy: 0.5214\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8832 - accuracy: 0.5259 - val_loss: 0.9483 - val_accuracy: 0.5385\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8846 - accuracy: 0.5556 - val_loss: 0.9515 - val_accuracy: 0.5299\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8817 - accuracy: 0.5519 - val_loss: 0.9470 - val_accuracy: 0.5214\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8847 - accuracy: 0.5148 - val_loss: 0.9454 - val_accuracy: 0.5385\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8823 - accuracy: 0.5407 - val_loss: 0.9467 - val_accuracy: 0.5214\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8828 - accuracy: 0.5148 - val_loss: 0.9437 - val_accuracy: 0.5385\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8878 - accuracy: 0.4963 - val_loss: 0.9452 - val_accuracy: 0.5214\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8802 - accuracy: 0.5333 - val_loss: 0.9536 - val_accuracy: 0.5385\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8842 - accuracy: 0.5519 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8819 - accuracy: 0.5074 - val_loss: 0.9469 - val_accuracy: 0.5385\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8808 - accuracy: 0.5556 - val_loss: 0.9508 - val_accuracy: 0.5299\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8783 - accuracy: 0.5481 - val_loss: 0.9471 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8870 - accuracy: 0.5481 - val_loss: 0.9461 - val_accuracy: 0.5385\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8830 - accuracy: 0.5519 - val_loss: 0.9525 - val_accuracy: 0.5385\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8788 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5128\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8832 - accuracy: 0.5407 - val_loss: 0.9457 - val_accuracy: 0.5214\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8795 - accuracy: 0.5407 - val_loss: 0.9463 - val_accuracy: 0.5385\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8811 - accuracy: 0.5519 - val_loss: 0.9514 - val_accuracy: 0.5385\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8802 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5214\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8821 - accuracy: 0.5370 - val_loss: 0.9462 - val_accuracy: 0.5385\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8793 - accuracy: 0.5481 - val_loss: 0.9488 - val_accuracy: 0.5385\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8760 - accuracy: 0.5519 - val_loss: 0.9444 - val_accuracy: 0.5385\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8767 - accuracy: 0.5519 - val_loss: 0.9447 - val_accuracy: 0.5385\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8769 - accuracy: 0.5519 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8780 - accuracy: 0.5519 - val_loss: 0.9476 - val_accuracy: 0.5385\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8770 - accuracy: 0.5519 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8779 - accuracy: 0.5370 - val_loss: 0.9502 - val_accuracy: 0.5214\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8786 - accuracy: 0.5444 - val_loss: 0.9511 - val_accuracy: 0.5385\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8768 - accuracy: 0.5519 - val_loss: 0.9485 - val_accuracy: 0.5385\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8789 - accuracy: 0.5185 - val_loss: 0.9460 - val_accuracy: 0.5214\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8763 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5385\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8787 - accuracy: 0.5519 - val_loss: 0.9484 - val_accuracy: 0.5128\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8764 - accuracy: 0.5407 - val_loss: 0.9455 - val_accuracy: 0.5214\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8746 - accuracy: 0.5407 - val_loss: 0.9443 - val_accuracy: 0.5385\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8775 - accuracy: 0.5519 - val_loss: 0.9443 - val_accuracy: 0.5385\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8793 - accuracy: 0.5259 - val_loss: 0.9447 - val_accuracy: 0.5214\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8779 - accuracy: 0.5370 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8781 - accuracy: 0.5519 - val_loss: 0.9423 - val_accuracy: 0.5385\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8767 - accuracy: 0.5296 - val_loss: 0.9434 - val_accuracy: 0.5214\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8785 - accuracy: 0.5519 - val_loss: 0.9471 - val_accuracy: 0.5385\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8761 - accuracy: 0.5519 - val_loss: 0.9414 - val_accuracy: 0.5385\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8788 - accuracy: 0.5296 - val_loss: 0.9472 - val_accuracy: 0.5214\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8750 - accuracy: 0.5444 - val_loss: 0.9460 - val_accuracy: 0.5385\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8776 - accuracy: 0.5519 - val_loss: 0.9470 - val_accuracy: 0.5385\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8743 - accuracy: 0.5296 - val_loss: 0.9455 - val_accuracy: 0.5214\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8793 - accuracy: 0.5407 - val_loss: 0.9426 - val_accuracy: 0.5214\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8743 - accuracy: 0.5593 - val_loss: 0.9473 - val_accuracy: 0.5385\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8743 - accuracy: 0.5519 - val_loss: 0.9420 - val_accuracy: 0.5385\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8729 - accuracy: 0.5296 - val_loss: 0.9418 - val_accuracy: 0.5214\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8753 - accuracy: 0.5222 - val_loss: 0.9411 - val_accuracy: 0.5385\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8730 - accuracy: 0.5519 - val_loss: 0.9427 - val_accuracy: 0.5385\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8726 - accuracy: 0.5519 - val_loss: 0.9443 - val_accuracy: 0.5385\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8748 - accuracy: 0.5259 - val_loss: 0.9464 - val_accuracy: 0.5214\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8740 - accuracy: 0.5444 - val_loss: 0.9538 - val_accuracy: 0.5385\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8735 - accuracy: 0.5519 - val_loss: 0.9479 - val_accuracy: 0.5385\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8732 - accuracy: 0.5519 - val_loss: 0.9480 - val_accuracy: 0.5385\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8715 - accuracy: 0.5333 - val_loss: 0.9466 - val_accuracy: 0.5214\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8752 - accuracy: 0.5407 - val_loss: 0.9455 - val_accuracy: 0.5214\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8736 - accuracy: 0.5370 - val_loss: 0.9537 - val_accuracy: 0.5385\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8728 - accuracy: 0.5593 - val_loss: 0.9479 - val_accuracy: 0.5299\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8711 - accuracy: 0.5444 - val_loss: 0.9447 - val_accuracy: 0.5214\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8720 - accuracy: 0.5407 - val_loss: 0.9453 - val_accuracy: 0.5385\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8725 - accuracy: 0.5556 - val_loss: 0.9484 - val_accuracy: 0.5385\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8721 - accuracy: 0.5556 - val_loss: 0.9489 - val_accuracy: 0.5385\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8706 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8730 - accuracy: 0.5444 - val_loss: 0.9469 - val_accuracy: 0.5214\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8714 - accuracy: 0.5519 - val_loss: 0.9502 - val_accuracy: 0.5385\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8738 - accuracy: 0.5444 - val_loss: 0.9527 - val_accuracy: 0.5299\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8701 - accuracy: 0.5556 - val_loss: 0.9489 - val_accuracy: 0.5470\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8708 - accuracy: 0.5556 - val_loss: 0.9457 - val_accuracy: 0.5385\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8748 - accuracy: 0.5185 - val_loss: 0.9460 - val_accuracy: 0.5299\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8709 - accuracy: 0.5370 - val_loss: 0.9460 - val_accuracy: 0.5470\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8712 - accuracy: 0.5037 - val_loss: 0.9475 - val_accuracy: 0.5470\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8715 - accuracy: 0.5593 - val_loss: 0.9475 - val_accuracy: 0.5470\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8713 - accuracy: 0.5333 - val_loss: 0.9495 - val_accuracy: 0.5299\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8701 - accuracy: 0.5407 - val_loss: 0.9477 - val_accuracy: 0.5470\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8692 - accuracy: 0.5593 - val_loss: 0.9480 - val_accuracy: 0.5470\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8702 - accuracy: 0.5296 - val_loss: 0.9448 - val_accuracy: 0.5299\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8691 - accuracy: 0.5444 - val_loss: 0.9463 - val_accuracy: 0.5470\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8706 - accuracy: 0.5333 - val_loss: 0.9428 - val_accuracy: 0.5299\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8701 - accuracy: 0.5444 - val_loss: 0.9449 - val_accuracy: 0.5470\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8686 - accuracy: 0.5593 - val_loss: 0.9452 - val_accuracy: 0.5470\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8688 - accuracy: 0.5556 - val_loss: 0.9460 - val_accuracy: 0.5470\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8678 - accuracy: 0.5593 - val_loss: 0.9476 - val_accuracy: 0.5470\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8673 - accuracy: 0.5593 - val_loss: 0.9468 - val_accuracy: 0.5470\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8677 - accuracy: 0.5593 - val_loss: 0.9447 - val_accuracy: 0.5470\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8694 - accuracy: 0.5444 - val_loss: 0.9457 - val_accuracy: 0.5299\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8809 - accuracy: 0.5074 - val_loss: 0.9478 - val_accuracy: 0.5470\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8716 - accuracy: 0.5407 - val_loss: 0.9487 - val_accuracy: 0.5214\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 0.9463 - val_accuracy: 0.5470\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8672 - accuracy: 0.5593 - val_loss: 0.9470 - val_accuracy: 0.5470\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8685 - accuracy: 0.5593 - val_loss: 0.9424 - val_accuracy: 0.5470\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8673 - accuracy: 0.5259 - val_loss: 0.9437 - val_accuracy: 0.5470\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8687 - accuracy: 0.5556 - val_loss: 0.9447 - val_accuracy: 0.5470\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8685 - accuracy: 0.5259 - val_loss: 0.9463 - val_accuracy: 0.5470\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8683 - accuracy: 0.5593 - val_loss: 0.9451 - val_accuracy: 0.5470\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8681 - accuracy: 0.5444 - val_loss: 0.9493 - val_accuracy: 0.5299\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8679 - accuracy: 0.5444 - val_loss: 0.9469 - val_accuracy: 0.5299\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8690 - accuracy: 0.5519 - val_loss: 0.9476 - val_accuracy: 0.5470\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8671 - accuracy: 0.5593 - val_loss: 0.9478 - val_accuracy: 0.5470\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8794 - accuracy: 0.5148 - val_loss: 0.9480 - val_accuracy: 0.5299\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8724 - accuracy: 0.5296 - val_loss: 0.9472 - val_accuracy: 0.5470\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8705 - accuracy: 0.5370 - val_loss: 0.9446 - val_accuracy: 0.5299\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8670 - accuracy: 0.5296 - val_loss: 0.9483 - val_accuracy: 0.5470\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8669 - accuracy: 0.5593 - val_loss: 0.9470 - val_accuracy: 0.5470\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8744 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5299\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8659 - accuracy: 0.5556 - val_loss: 0.9465 - val_accuracy: 0.5470\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8682 - accuracy: 0.5593 - val_loss: 0.9485 - val_accuracy: 0.5470\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8655 - accuracy: 0.5593 - val_loss: 0.9445 - val_accuracy: 0.5470\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8712 - accuracy: 0.5593 - val_loss: 0.9422 - val_accuracy: 0.5299\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8658 - accuracy: 0.5407 - val_loss: 0.9469 - val_accuracy: 0.5470\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8662 - accuracy: 0.5593 - val_loss: 0.9473 - val_accuracy: 0.5470\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8644 - accuracy: 0.5593 - val_loss: 0.9461 - val_accuracy: 0.5470\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8666 - accuracy: 0.5185 - val_loss: 0.9484 - val_accuracy: 0.5299\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8634 - accuracy: 0.5630 - val_loss: 0.9471 - val_accuracy: 0.5470\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8650 - accuracy: 0.5593 - val_loss: 0.9439 - val_accuracy: 0.5470\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8664 - accuracy: 0.5593 - val_loss: 0.9455 - val_accuracy: 0.5470\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8643 - accuracy: 0.5593 - val_loss: 0.9457 - val_accuracy: 0.5470\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8647 - accuracy: 0.5593 - val_loss: 0.9421 - val_accuracy: 0.5470\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8664 - accuracy: 0.5593 - val_loss: 0.9477 - val_accuracy: 0.5470\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8640 - accuracy: 0.5593 - val_loss: 0.9455 - val_accuracy: 0.5470\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8642 - accuracy: 0.5333 - val_loss: 0.9466 - val_accuracy: 0.5470\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8650 - accuracy: 0.5444 - val_loss: 0.9501 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8640 - accuracy: 0.5481 - val_loss: 0.9467 - val_accuracy: 0.5470\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8632 - accuracy: 0.5481 - val_loss: 0.9433 - val_accuracy: 0.5470\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8632 - accuracy: 0.5593 - val_loss: 0.9457 - val_accuracy: 0.5470\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8639 - accuracy: 0.5593 - val_loss: 0.9492 - val_accuracy: 0.5470\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8628 - accuracy: 0.5704 - val_loss: 0.9485 - val_accuracy: 0.5299\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8659 - accuracy: 0.5481 - val_loss: 0.9492 - val_accuracy: 0.5299\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8634 - accuracy: 0.5407 - val_loss: 0.9489 - val_accuracy: 0.5470\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8618 - accuracy: 0.5593 - val_loss: 0.9448 - val_accuracy: 0.5470\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8629 - accuracy: 0.5481 - val_loss: 0.9436 - val_accuracy: 0.5470\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 0.9437 - val_accuracy: 0.5470\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8621 - accuracy: 0.5593 - val_loss: 0.9493 - val_accuracy: 0.5470\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8670 - accuracy: 0.5556 - val_loss: 0.9508 - val_accuracy: 0.5470\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8661 - accuracy: 0.5185 - val_loss: 0.9459 - val_accuracy: 0.5299\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8621 - accuracy: 0.5667 - val_loss: 0.9442 - val_accuracy: 0.5470\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8640 - accuracy: 0.5593 - val_loss: 0.9483 - val_accuracy: 0.5470\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8638 - accuracy: 0.5593 - val_loss: 0.9472 - val_accuracy: 0.5470\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8647 - accuracy: 0.5296 - val_loss: 0.9486 - val_accuracy: 0.5470\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8608 - accuracy: 0.5593 - val_loss: 0.9492 - val_accuracy: 0.5470\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8609 - accuracy: 0.5593 - val_loss: 0.9488 - val_accuracy: 0.5470\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8609 - accuracy: 0.5593 - val_loss: 0.9462 - val_accuracy: 0.5470\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8630 - accuracy: 0.5593 - val_loss: 0.9444 - val_accuracy: 0.5299\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8611 - accuracy: 0.5481 - val_loss: 0.9470 - val_accuracy: 0.5299\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8601 - accuracy: 0.5667 - val_loss: 0.9512 - val_accuracy: 0.5470\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8669 - accuracy: 0.5593 - val_loss: 0.9496 - val_accuracy: 0.5470\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8612 - accuracy: 0.5407 - val_loss: 0.9499 - val_accuracy: 0.5299\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8619 - accuracy: 0.5481 - val_loss: 0.9492 - val_accuracy: 0.5470\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8613 - accuracy: 0.5593 - val_loss: 0.9530 - val_accuracy: 0.5470\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8601 - accuracy: 0.5593 - val_loss: 0.9482 - val_accuracy: 0.5470\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 0.9460 - val_accuracy: 0.5299\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8623 - accuracy: 0.5037 - val_loss: 0.9466 - val_accuracy: 0.5470\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8607 - accuracy: 0.5593 - val_loss: 0.9502 - val_accuracy: 0.5470\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8600 - accuracy: 0.5556 - val_loss: 0.9487 - val_accuracy: 0.5299\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8655 - accuracy: 0.5074 - val_loss: 0.9526 - val_accuracy: 0.5470\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8610 - accuracy: 0.5593 - val_loss: 0.9524 - val_accuracy: 0.5299\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8599 - accuracy: 0.5407 - val_loss: 0.9534 - val_accuracy: 0.5470\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8609 - accuracy: 0.5222 - val_loss: 0.9503 - val_accuracy: 0.5299\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8593 - accuracy: 0.5593 - val_loss: 0.9488 - val_accuracy: 0.5470\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8636 - accuracy: 0.5593 - val_loss: 0.9480 - val_accuracy: 0.5470\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8579 - accuracy: 0.5630 - val_loss: 0.9490 - val_accuracy: 0.5299\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8618 - accuracy: 0.5481 - val_loss: 0.9529 - val_accuracy: 0.5299\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8620 - accuracy: 0.5370 - val_loss: 0.9494 - val_accuracy: 0.5470\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8608 - accuracy: 0.5593 - val_loss: 0.9442 - val_accuracy: 0.5470\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8592 - accuracy: 0.5259 - val_loss: 0.9459 - val_accuracy: 0.5470\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8603 - accuracy: 0.5370 - val_loss: 0.9448 - val_accuracy: 0.5299\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8621 - accuracy: 0.5444 - val_loss: 0.9480 - val_accuracy: 0.5470\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8587 - accuracy: 0.5593 - val_loss: 0.9466 - val_accuracy: 0.5299\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8603 - accuracy: 0.5481 - val_loss: 0.9491 - val_accuracy: 0.5299\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8601 - accuracy: 0.5667 - val_loss: 0.9562 - val_accuracy: 0.5470\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8606 - accuracy: 0.5593 - val_loss: 0.9517 - val_accuracy: 0.5470\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8614 - accuracy: 0.5259 - val_loss: 0.9515 - val_accuracy: 0.5299\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8564 - accuracy: 0.5778 - val_loss: 0.9517 - val_accuracy: 0.5470\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8612 - accuracy: 0.5593 - val_loss: 0.9513 - val_accuracy: 0.5470\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8541 - accuracy: 0.5593 - val_loss: 0.9487 - val_accuracy: 0.5299\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8656 - accuracy: 0.5481 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8677 - accuracy: 0.5185 - val_loss: 0.9547 - val_accuracy: 0.5470\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8601 - accuracy: 0.5593 - val_loss: 0.9501 - val_accuracy: 0.5470\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8594 - accuracy: 0.5593 - val_loss: 0.9530 - val_accuracy: 0.5470\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8588 - accuracy: 0.5593 - val_loss: 0.9504 - val_accuracy: 0.5470\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8589 - accuracy: 0.5630 - val_loss: 0.9473 - val_accuracy: 0.5299\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8576 - accuracy: 0.5481 - val_loss: 0.9471 - val_accuracy: 0.5299\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8567 - accuracy: 0.5630 - val_loss: 0.9494 - val_accuracy: 0.5470\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8577 - accuracy: 0.5593 - val_loss: 0.9453 - val_accuracy: 0.5470\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8580 - accuracy: 0.5593 - val_loss: 0.9467 - val_accuracy: 0.5470\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8591 - accuracy: 0.5593 - val_loss: 0.9490 - val_accuracy: 0.5470\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8564 - accuracy: 0.5630 - val_loss: 0.9472 - val_accuracy: 0.5299\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8580 - accuracy: 0.5444 - val_loss: 0.9493 - val_accuracy: 0.5470\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8571 - accuracy: 0.5593 - val_loss: 0.9485 - val_accuracy: 0.5470\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8561 - accuracy: 0.5556 - val_loss: 0.9473 - val_accuracy: 0.5299\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8574 - accuracy: 0.5481 - val_loss: 0.9474 - val_accuracy: 0.5470\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8574 - accuracy: 0.5222 - val_loss: 0.9497 - val_accuracy: 0.5470\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8632 - accuracy: 0.5593 - val_loss: 0.9519 - val_accuracy: 0.5470\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8560 - accuracy: 0.5630 - val_loss: 0.9466 - val_accuracy: 0.5299\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8617 - accuracy: 0.5481 - val_loss: 0.9479 - val_accuracy: 0.5299\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8561 - accuracy: 0.5556 - val_loss: 0.9502 - val_accuracy: 0.5470\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8565 - accuracy: 0.5593 - val_loss: 0.9467 - val_accuracy: 0.5470\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8593 - accuracy: 0.5185 - val_loss: 0.9473 - val_accuracy: 0.5299\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8554 - accuracy: 0.5630 - val_loss: 0.9464 - val_accuracy: 0.5470\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8586 - accuracy: 0.5593 - val_loss: 0.9465 - val_accuracy: 0.5470\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8551 - accuracy: 0.5481 - val_loss: 0.9463 - val_accuracy: 0.5299\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8567 - accuracy: 0.5481 - val_loss: 0.9452 - val_accuracy: 0.5470\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8553 - accuracy: 0.5593 - val_loss: 0.9499 - val_accuracy: 0.5470\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8599 - accuracy: 0.5593 - val_loss: 0.9524 - val_accuracy: 0.5470\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8584 - accuracy: 0.5667 - val_loss: 0.9489 - val_accuracy: 0.5299\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8548 - accuracy: 0.5519 - val_loss: 0.9538 - val_accuracy: 0.5470\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8595 - accuracy: 0.5593 - val_loss: 0.9588 - val_accuracy: 0.5470\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8562 - accuracy: 0.5481 - val_loss: 0.9499 - val_accuracy: 0.5299\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8564 - accuracy: 0.5519 - val_loss: 0.9501 - val_accuracy: 0.5470\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8565 - accuracy: 0.5556 - val_loss: 0.9489 - val_accuracy: 0.5470\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8575 - accuracy: 0.5593 - val_loss: 0.9497 - val_accuracy: 0.5470\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8567 - accuracy: 0.5444 - val_loss: 0.9488 - val_accuracy: 0.5299\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8580 - accuracy: 0.5444 - val_loss: 0.9561 - val_accuracy: 0.5470\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8568 - accuracy: 0.5593 - val_loss: 0.9489 - val_accuracy: 0.5470\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8548 - accuracy: 0.5593 - val_loss: 0.9494 - val_accuracy: 0.5299\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8547 - accuracy: 0.5333 - val_loss: 0.9488 - val_accuracy: 0.5470\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8546 - accuracy: 0.5593 - val_loss: 0.9503 - val_accuracy: 0.5470\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8552 - accuracy: 0.5593 - val_loss: 0.9512 - val_accuracy: 0.5470\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8617 - accuracy: 0.5222 - val_loss: 0.9509 - val_accuracy: 0.5299\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8540 - accuracy: 0.5630 - val_loss: 0.9582 - val_accuracy: 0.5470\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8586 - accuracy: 0.5593 - val_loss: 0.9501 - val_accuracy: 0.5470\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8554 - accuracy: 0.5481 - val_loss: 0.9481 - val_accuracy: 0.5299\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8547 - accuracy: 0.5556 - val_loss: 0.9499 - val_accuracy: 0.5470\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8598 - accuracy: 0.5630 - val_loss: 0.9541 - val_accuracy: 0.5385\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8619 - accuracy: 0.5259 - val_loss: 0.9435 - val_accuracy: 0.5299\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8550 - accuracy: 0.5593 - val_loss: 0.9445 - val_accuracy: 0.5470\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8554 - accuracy: 0.5593 - val_loss: 0.9477 - val_accuracy: 0.5470\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8538 - accuracy: 0.5593 - val_loss: 0.9485 - val_accuracy: 0.5470\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8555 - accuracy: 0.5333 - val_loss: 0.9490 - val_accuracy: 0.5299\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8584 - accuracy: 0.5148 - val_loss: 0.9468 - val_accuracy: 0.5470\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8536 - accuracy: 0.5593 - val_loss: 0.9467 - val_accuracy: 0.5470\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8551 - accuracy: 0.5593 - val_loss: 0.9503 - val_accuracy: 0.5470\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8537 - accuracy: 0.5333 - val_loss: 0.9495 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8554 - accuracy: 0.5148 - val_loss: 0.9476 - val_accuracy: 0.5470\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8547 - accuracy: 0.5593 - val_loss: 0.9499 - val_accuracy: 0.5470\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8535 - accuracy: 0.5593 - val_loss: 0.9498 - val_accuracy: 0.5470\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8680 - accuracy: 0.5556 - val_loss: 0.9562 - val_accuracy: 0.5385\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 0.9539 - val_accuracy: 0.5299\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8594 - accuracy: 0.5481 - val_loss: 0.9500 - val_accuracy: 0.5299\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8606 - accuracy: 0.5259 - val_loss: 0.9605 - val_accuracy: 0.5470\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8586 - accuracy: 0.5259 - val_loss: 0.9523 - val_accuracy: 0.5299\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8532 - accuracy: 0.5630 - val_loss: 0.9512 - val_accuracy: 0.5470\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8541 - accuracy: 0.5593 - val_loss: 0.9524 - val_accuracy: 0.5470\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 0.9505 - val_accuracy: 0.5299\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8541 - accuracy: 0.5593 - val_loss: 0.9499 - val_accuracy: 0.5470\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8520 - accuracy: 0.5593 - val_loss: 0.9528 - val_accuracy: 0.5470\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8546 - accuracy: 0.5222 - val_loss: 0.9543 - val_accuracy: 0.5470\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8526 - accuracy: 0.5519 - val_loss: 0.9535 - val_accuracy: 0.5299\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8526 - accuracy: 0.5741 - val_loss: 0.9527 - val_accuracy: 0.5470\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8534 - accuracy: 0.5407 - val_loss: 0.9519 - val_accuracy: 0.5470\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8533 - accuracy: 0.5593 - val_loss: 0.9541 - val_accuracy: 0.5470\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8514 - accuracy: 0.5593 - val_loss: 0.9496 - val_accuracy: 0.5470\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8561 - accuracy: 0.5296 - val_loss: 0.9493 - val_accuracy: 0.5299\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8639 - accuracy: 0.5444 - val_loss: 0.9574 - val_accuracy: 0.5470\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8502 - accuracy: 0.5630 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8565 - accuracy: 0.5481 - val_loss: 0.9511 - val_accuracy: 0.5299\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8545 - accuracy: 0.5481 - val_loss: 0.9619 - val_accuracy: 0.5470\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8552 - accuracy: 0.5444 - val_loss: 0.9550 - val_accuracy: 0.5299\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8552 - accuracy: 0.5481 - val_loss: 0.9536 - val_accuracy: 0.5470\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8554 - accuracy: 0.5370 - val_loss: 0.9519 - val_accuracy: 0.5299\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8510 - accuracy: 0.5519 - val_loss: 0.9524 - val_accuracy: 0.5470\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8513 - accuracy: 0.5593 - val_loss: 0.9547 - val_accuracy: 0.5470\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8550 - accuracy: 0.5593 - val_loss: 0.9522 - val_accuracy: 0.5470\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8512 - accuracy: 0.5593 - val_loss: 0.9528 - val_accuracy: 0.5299\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8525 - accuracy: 0.5481 - val_loss: 0.9509 - val_accuracy: 0.5299\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8552 - accuracy: 0.5185 - val_loss: 0.9505 - val_accuracy: 0.5470\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8508 - accuracy: 0.5593 - val_loss: 0.9488 - val_accuracy: 0.5470\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8530 - accuracy: 0.5593 - val_loss: 0.9508 - val_accuracy: 0.5470\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8523 - accuracy: 0.5370 - val_loss: 0.9513 - val_accuracy: 0.5299\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8504 - accuracy: 0.5519 - val_loss: 0.9527 - val_accuracy: 0.5470\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8521 - accuracy: 0.5593 - val_loss: 0.9544 - val_accuracy: 0.5470\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8500 - accuracy: 0.5593 - val_loss: 0.9525 - val_accuracy: 0.5470\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8524 - accuracy: 0.5407 - val_loss: 0.9532 - val_accuracy: 0.5299\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8535 - accuracy: 0.5333 - val_loss: 0.9563 - val_accuracy: 0.5470\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8511 - accuracy: 0.5593 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8532 - accuracy: 0.5444 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8563 - accuracy: 0.5481 - val_loss: 0.9506 - val_accuracy: 0.5470\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8608 - accuracy: 0.5593 - val_loss: 0.9646 - val_accuracy: 0.5470\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8582 - accuracy: 0.5444 - val_loss: 0.9523 - val_accuracy: 0.5299\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8532 - accuracy: 0.5481 - val_loss: 0.9526 - val_accuracy: 0.5470\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8499 - accuracy: 0.5593 - val_loss: 0.9574 - val_accuracy: 0.5470\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8499 - accuracy: 0.5593 - val_loss: 0.9519 - val_accuracy: 0.5470\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8490 - accuracy: 0.5593 - val_loss: 0.9508 - val_accuracy: 0.5299\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8530 - accuracy: 0.5481 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8483 - accuracy: 0.5370 - val_loss: 0.9529 - val_accuracy: 0.5470\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8530 - accuracy: 0.5593 - val_loss: 0.9543 - val_accuracy: 0.5470\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8504 - accuracy: 0.5593 - val_loss: 0.9492 - val_accuracy: 0.5470\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8498 - accuracy: 0.5593 - val_loss: 0.9540 - val_accuracy: 0.5470\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8539 - accuracy: 0.5296 - val_loss: 0.9567 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8521 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5470\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8520 - accuracy: 0.5148 - val_loss: 0.9538 - val_accuracy: 0.5470\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8492 - accuracy: 0.5593 - val_loss: 0.9562 - val_accuracy: 0.5470\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8551 - accuracy: 0.5593 - val_loss: 0.9595 - val_accuracy: 0.5470\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8509 - accuracy: 0.5593 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8509 - accuracy: 0.5296 - val_loss: 0.9519 - val_accuracy: 0.5470\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8505 - accuracy: 0.5259 - val_loss: 0.9540 - val_accuracy: 0.5470\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8499 - accuracy: 0.5593 - val_loss: 0.9518 - val_accuracy: 0.5470\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8505 - accuracy: 0.5593 - val_loss: 0.9528 - val_accuracy: 0.5470\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8480 - accuracy: 0.5593 - val_loss: 0.9519 - val_accuracy: 0.5470\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8493 - accuracy: 0.5593 - val_loss: 0.9526 - val_accuracy: 0.5470\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8490 - accuracy: 0.5593 - val_loss: 0.9537 - val_accuracy: 0.5470\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8523 - accuracy: 0.5444 - val_loss: 0.9527 - val_accuracy: 0.5214\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8508 - accuracy: 0.5630 - val_loss: 0.9529 - val_accuracy: 0.5470\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8498 - accuracy: 0.5593 - val_loss: 0.9537 - val_accuracy: 0.5470\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8512 - accuracy: 0.5630 - val_loss: 0.9569 - val_accuracy: 0.5214\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8481 - accuracy: 0.5481 - val_loss: 0.9531 - val_accuracy: 0.5299\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8504 - accuracy: 0.5333 - val_loss: 0.9521 - val_accuracy: 0.5470\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8507 - accuracy: 0.5593 - val_loss: 0.9531 - val_accuracy: 0.5470\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8527 - accuracy: 0.5333 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8617 - accuracy: 0.5407 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8521 - accuracy: 0.5444 - val_loss: 0.9617 - val_accuracy: 0.5299\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8498 - accuracy: 0.5481 - val_loss: 0.9602 - val_accuracy: 0.5470\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8528 - accuracy: 0.5593 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8491 - accuracy: 0.5593 - val_loss: 0.9550 - val_accuracy: 0.5470\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8507 - accuracy: 0.5444 - val_loss: 0.9585 - val_accuracy: 0.5299\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8487 - accuracy: 0.5444 - val_loss: 0.9594 - val_accuracy: 0.5470\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8488 - accuracy: 0.5593 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8492 - accuracy: 0.5593 - val_loss: 0.9595 - val_accuracy: 0.5470\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8476 - accuracy: 0.5407 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8497 - accuracy: 0.5407 - val_loss: 0.9554 - val_accuracy: 0.5299\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8493 - accuracy: 0.5481 - val_loss: 0.9540 - val_accuracy: 0.5299\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8474 - accuracy: 0.5630 - val_loss: 0.9558 - val_accuracy: 0.5470\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8485 - accuracy: 0.5593 - val_loss: 0.9549 - val_accuracy: 0.5470\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8470 - accuracy: 0.5593 - val_loss: 0.9535 - val_accuracy: 0.5470\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8468 - accuracy: 0.5593 - val_loss: 0.9549 - val_accuracy: 0.5470\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8467 - accuracy: 0.5593 - val_loss: 0.9534 - val_accuracy: 0.5299\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 0.9534 - val_accuracy: 0.5470\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8509 - accuracy: 0.5111 - val_loss: 0.9547 - val_accuracy: 0.5470\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8474 - accuracy: 0.5333 - val_loss: 0.9528 - val_accuracy: 0.5470\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8481 - accuracy: 0.5481 - val_loss: 0.9541 - val_accuracy: 0.5299\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8466 - accuracy: 0.5481 - val_loss: 0.9548 - val_accuracy: 0.5470\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8527 - accuracy: 0.5593 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 0.9548 - val_accuracy: 0.5299\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8489 - accuracy: 0.5481 - val_loss: 0.9529 - val_accuracy: 0.5299\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8537 - accuracy: 0.5407 - val_loss: 0.9567 - val_accuracy: 0.5470\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8470 - accuracy: 0.5593 - val_loss: 0.9528 - val_accuracy: 0.5299\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8475 - accuracy: 0.5481 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8489 - accuracy: 0.5185 - val_loss: 0.9541 - val_accuracy: 0.5470\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8506 - accuracy: 0.5074 - val_loss: 0.9551 - val_accuracy: 0.5470\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8542 - accuracy: 0.5593 - val_loss: 0.9583 - val_accuracy: 0.5470\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8480 - accuracy: 0.5593 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8484 - accuracy: 0.5259 - val_loss: 0.9596 - val_accuracy: 0.5299\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8478 - accuracy: 0.5481 - val_loss: 0.9606 - val_accuracy: 0.5299\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8478 - accuracy: 0.5370 - val_loss: 0.9526 - val_accuracy: 0.5470\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8475 - accuracy: 0.5593 - val_loss: 0.9528 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8465 - accuracy: 0.5593 - val_loss: 0.9512 - val_accuracy: 0.5470\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8498 - accuracy: 0.5593 - val_loss: 0.9481 - val_accuracy: 0.5470\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8575 - accuracy: 0.5222 - val_loss: 0.9477 - val_accuracy: 0.5299\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8468 - accuracy: 0.5741 - val_loss: 0.9508 - val_accuracy: 0.5470\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8482 - accuracy: 0.5593 - val_loss: 0.9542 - val_accuracy: 0.5470\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8472 - accuracy: 0.5593 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8464 - accuracy: 0.5111 - val_loss: 0.9547 - val_accuracy: 0.5470\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8468 - accuracy: 0.5593 - val_loss: 0.9574 - val_accuracy: 0.5470\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8461 - accuracy: 0.5593 - val_loss: 0.9551 - val_accuracy: 0.5470\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8473 - accuracy: 0.5444 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8473 - accuracy: 0.5481 - val_loss: 0.9522 - val_accuracy: 0.5299\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 0.9526 - val_accuracy: 0.5470\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8569 - accuracy: 0.5593 - val_loss: 0.9596 - val_accuracy: 0.5470\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8504 - accuracy: 0.5333 - val_loss: 0.9577 - val_accuracy: 0.5470\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8448 - accuracy: 0.5593 - val_loss: 0.9579 - val_accuracy: 0.5470\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8466 - accuracy: 0.5593 - val_loss: 0.9585 - val_accuracy: 0.5470\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 0.9569 - val_accuracy: 0.5299\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8462 - accuracy: 0.5333 - val_loss: 0.9557 - val_accuracy: 0.5470\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8455 - accuracy: 0.5593 - val_loss: 0.9581 - val_accuracy: 0.5470\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8495 - accuracy: 0.5222 - val_loss: 0.9578 - val_accuracy: 0.5470\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8453 - accuracy: 0.5593 - val_loss: 0.9587 - val_accuracy: 0.5470\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8462 - accuracy: 0.5370 - val_loss: 0.9603 - val_accuracy: 0.5470\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8489 - accuracy: 0.5593 - val_loss: 0.9617 - val_accuracy: 0.5470\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8462 - accuracy: 0.5296 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8439 - accuracy: 0.5593 - val_loss: 0.9536 - val_accuracy: 0.5470\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8474 - accuracy: 0.5593 - val_loss: 0.9571 - val_accuracy: 0.5470\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8491 - accuracy: 0.5593 - val_loss: 0.9556 - val_accuracy: 0.5470\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8486 - accuracy: 0.5704 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8510 - accuracy: 0.5185 - val_loss: 0.9602 - val_accuracy: 0.5470\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8506 - accuracy: 0.5593 - val_loss: 0.9562 - val_accuracy: 0.5470\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8487 - accuracy: 0.5593 - val_loss: 0.9587 - val_accuracy: 0.5470\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8458 - accuracy: 0.5185 - val_loss: 0.9546 - val_accuracy: 0.5299\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8455 - accuracy: 0.5481 - val_loss: 0.9543 - val_accuracy: 0.5299\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8463 - accuracy: 0.5481 - val_loss: 0.9552 - val_accuracy: 0.5470\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8471 - accuracy: 0.5593 - val_loss: 0.9579 - val_accuracy: 0.5470\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8458 - accuracy: 0.5593 - val_loss: 0.9567 - val_accuracy: 0.5470\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8437 - accuracy: 0.5370 - val_loss: 0.9591 - val_accuracy: 0.5470\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8440 - accuracy: 0.5593 - val_loss: 0.9590 - val_accuracy: 0.5470\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8452 - accuracy: 0.5593 - val_loss: 0.9585 - val_accuracy: 0.5470\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8453 - accuracy: 0.5481 - val_loss: 0.9587 - val_accuracy: 0.5470\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8442 - accuracy: 0.5370 - val_loss: 0.9590 - val_accuracy: 0.5470\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8450 - accuracy: 0.5148 - val_loss: 0.9602 - val_accuracy: 0.5470\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8450 - accuracy: 0.5593 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8450 - accuracy: 0.5593 - val_loss: 0.9600 - val_accuracy: 0.5470\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 0.9579 - val_accuracy: 0.5299\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 0.9569 - val_accuracy: 0.5470\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8452 - accuracy: 0.5593 - val_loss: 0.9628 - val_accuracy: 0.5470\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8468 - accuracy: 0.5630 - val_loss: 0.9592 - val_accuracy: 0.5385\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 0.9550 - val_accuracy: 0.5470\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8484 - accuracy: 0.5593 - val_loss: 0.9542 - val_accuracy: 0.5470\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8463 - accuracy: 0.5444 - val_loss: 0.9583 - val_accuracy: 0.5214\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8460 - accuracy: 0.5148 - val_loss: 0.9618 - val_accuracy: 0.5214\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8444 - accuracy: 0.5481 - val_loss: 0.9598 - val_accuracy: 0.5470\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8487 - accuracy: 0.5222 - val_loss: 0.9549 - val_accuracy: 0.5299\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8440 - accuracy: 0.5593 - val_loss: 0.9609 - val_accuracy: 0.5385\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8458 - accuracy: 0.5222 - val_loss: 0.9573 - val_accuracy: 0.5214\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 0.9573 - val_accuracy: 0.5385\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8478 - accuracy: 0.5148 - val_loss: 0.9568 - val_accuracy: 0.5299\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 0.9559 - val_accuracy: 0.5470\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8428 - accuracy: 0.5593 - val_loss: 0.9575 - val_accuracy: 0.5470\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8464 - accuracy: 0.5593 - val_loss: 0.9604 - val_accuracy: 0.5385\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 0.9578 - val_accuracy: 0.5470\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.8446 - accuracy: 0.5259 - val_loss: 0.9600 - val_accuracy: 0.5385\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8438 - accuracy: 0.5630 - val_loss: 0.9588 - val_accuracy: 0.5470\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8461 - accuracy: 0.5593 - val_loss: 0.9614 - val_accuracy: 0.5470\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8510 - accuracy: 0.5593 - val_loss: 0.9652 - val_accuracy: 0.5470\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8442 - accuracy: 0.5481 - val_loss: 0.9580 - val_accuracy: 0.5470\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8422 - accuracy: 0.5593 - val_loss: 0.9605 - val_accuracy: 0.5470\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8457 - accuracy: 0.5593 - val_loss: 0.9557 - val_accuracy: 0.5470\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8442 - accuracy: 0.5296 - val_loss: 0.9565 - val_accuracy: 0.5470\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 0.9581 - val_accuracy: 0.5470\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8421 - accuracy: 0.5593 - val_loss: 0.9581 - val_accuracy: 0.5470\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.8452 - accuracy: 0.5333 - val_loss: 0.9591 - val_accuracy: 0.5299\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 0.9556 - val_accuracy: 0.5470\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8430 - accuracy: 0.5593 - val_loss: 0.9557 - val_accuracy: 0.5470\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8435 - accuracy: 0.5593 - val_loss: 0.9554 - val_accuracy: 0.5470\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8429 - accuracy: 0.5444 - val_loss: 0.9567 - val_accuracy: 0.5299\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 0.9606 - val_accuracy: 0.5470\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 0.9598 - val_accuracy: 0.5470\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8436 - accuracy: 0.5222 - val_loss: 0.9612 - val_accuracy: 0.5299\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 0.9606 - val_accuracy: 0.5470\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8431 - accuracy: 0.5593 - val_loss: 0.9607 - val_accuracy: 0.5470\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8473 - accuracy: 0.5593 - val_loss: 0.9617 - val_accuracy: 0.5470\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8470 - accuracy: 0.5481 - val_loss: 0.9672 - val_accuracy: 0.5214\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8579 - accuracy: 0.5148 - val_loss: 0.9664 - val_accuracy: 0.5470\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 0.9590 - val_accuracy: 0.5470\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8425 - accuracy: 0.5593 - val_loss: 0.9569 - val_accuracy: 0.5470\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 0.9591 - val_accuracy: 0.5470\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8435 - accuracy: 0.5370 - val_loss: 0.9546 - val_accuracy: 0.5470\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 0.9546 - val_accuracy: 0.5470\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 0.9573 - val_accuracy: 0.5470\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8454 - accuracy: 0.5593 - val_loss: 0.9532 - val_accuracy: 0.5470\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8423 - accuracy: 0.5593 - val_loss: 0.9550 - val_accuracy: 0.5470\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8436 - accuracy: 0.5444 - val_loss: 0.9577 - val_accuracy: 0.5470\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8453 - accuracy: 0.5593 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 0.9586 - val_accuracy: 0.5470\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8463 - accuracy: 0.5593 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8451 - accuracy: 0.5630 - val_loss: 0.9590 - val_accuracy: 0.5214\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8473 - accuracy: 0.5481 - val_loss: 0.9587 - val_accuracy: 0.5299\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8408 - accuracy: 0.5667 - val_loss: 0.9621 - val_accuracy: 0.5470\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8496 - accuracy: 0.5630 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8456 - accuracy: 0.5333 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 0.9617 - val_accuracy: 0.5470\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8438 - accuracy: 0.5593 - val_loss: 0.9628 - val_accuracy: 0.5385\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 0.9553 - val_accuracy: 0.5470\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8424 - accuracy: 0.5407 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 78us/step - loss: 0.8418 - accuracy: 0.5481 - val_loss: 0.9591 - val_accuracy: 0.5470\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8435 - accuracy: 0.5593 - val_loss: 0.9677 - val_accuracy: 0.5470\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8444 - accuracy: 0.5519 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8424 - accuracy: 0.5407 - val_loss: 0.9609 - val_accuracy: 0.5470\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8418 - accuracy: 0.5556 - val_loss: 0.9590 - val_accuracy: 0.5470\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8408 - accuracy: 0.5593 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8431 - accuracy: 0.5593 - val_loss: 0.9596 - val_accuracy: 0.5470\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8415 - accuracy: 0.5593 - val_loss: 0.9626 - val_accuracy: 0.5470\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8424 - accuracy: 0.5444 - val_loss: 0.9613 - val_accuracy: 0.5299\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8430 - accuracy: 0.5630 - val_loss: 0.9608 - val_accuracy: 0.5470\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8409 - accuracy: 0.5593 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8441 - accuracy: 0.5593 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8421 - accuracy: 0.5444 - val_loss: 0.9619 - val_accuracy: 0.5299\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8417 - accuracy: 0.5630 - val_loss: 0.9631 - val_accuracy: 0.5470\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8410 - accuracy: 0.5593 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8431 - accuracy: 0.5593 - val_loss: 0.9637 - val_accuracy: 0.5470\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8410 - accuracy: 0.5593 - val_loss: 0.9598 - val_accuracy: 0.5470\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8425 - accuracy: 0.5333 - val_loss: 0.9588 - val_accuracy: 0.5470\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8429 - accuracy: 0.5259 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8456 - accuracy: 0.5630 - val_loss: 0.9662 - val_accuracy: 0.5470\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8486 - accuracy: 0.5037 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8413 - accuracy: 0.5630 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8407 - accuracy: 0.5370 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8451 - accuracy: 0.5593 - val_loss: 0.9624 - val_accuracy: 0.5470\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8392 - accuracy: 0.5667 - val_loss: 0.9614 - val_accuracy: 0.5299\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8417 - accuracy: 0.5481 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8404 - accuracy: 0.5667 - val_loss: 0.9622 - val_accuracy: 0.5470\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8400 - accuracy: 0.5630 - val_loss: 0.9646 - val_accuracy: 0.5470\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8424 - accuracy: 0.5593 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8387 - accuracy: 0.5593 - val_loss: 0.9630 - val_accuracy: 0.5470\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8431 - accuracy: 0.5333 - val_loss: 0.9663 - val_accuracy: 0.5385\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8436 - accuracy: 0.5259 - val_loss: 0.9630 - val_accuracy: 0.5470\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8434 - accuracy: 0.5593 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8401 - accuracy: 0.5444 - val_loss: 0.9614 - val_accuracy: 0.5299\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8416 - accuracy: 0.5481 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8424 - accuracy: 0.5630 - val_loss: 0.9643 - val_accuracy: 0.5470\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8409 - accuracy: 0.5593 - val_loss: 0.9602 - val_accuracy: 0.5299\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8431 - accuracy: 0.5481 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8413 - accuracy: 0.5667 - val_loss: 0.9694 - val_accuracy: 0.5470\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8397 - accuracy: 0.5630 - val_loss: 0.9646 - val_accuracy: 0.5470\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8475 - accuracy: 0.5333 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8488 - accuracy: 0.5222 - val_loss: 0.9648 - val_accuracy: 0.5299\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8422 - accuracy: 0.5370 - val_loss: 0.9656 - val_accuracy: 0.5470\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 0.9611 - val_accuracy: 0.5470\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8409 - accuracy: 0.5593 - val_loss: 0.9630 - val_accuracy: 0.5470\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8398 - accuracy: 0.5593 - val_loss: 0.9630 - val_accuracy: 0.5470\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8416 - accuracy: 0.5444 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8409 - accuracy: 0.5407 - val_loss: 0.9602 - val_accuracy: 0.5470\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8424 - accuracy: 0.5630 - val_loss: 0.9588 - val_accuracy: 0.5470\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8397 - accuracy: 0.5556 - val_loss: 0.9587 - val_accuracy: 0.5299\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8440 - accuracy: 0.5370 - val_loss: 0.9599 - val_accuracy: 0.5470\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8415 - accuracy: 0.5630 - val_loss: 0.9609 - val_accuracy: 0.5470\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8441 - accuracy: 0.5407 - val_loss: 0.9640 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8400 - accuracy: 0.5556 - val_loss: 0.9657 - val_accuracy: 0.5470\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8408 - accuracy: 0.5333 - val_loss: 0.9641 - val_accuracy: 0.5299\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8398 - accuracy: 0.5222 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8394 - accuracy: 0.5593 - val_loss: 0.9619 - val_accuracy: 0.5470\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8389 - accuracy: 0.5630 - val_loss: 0.9663 - val_accuracy: 0.5470\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8399 - accuracy: 0.5630 - val_loss: 0.9634 - val_accuracy: 0.5470\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8448 - accuracy: 0.5593 - val_loss: 0.9618 - val_accuracy: 0.5470\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8438 - accuracy: 0.5407 - val_loss: 0.9700 - val_accuracy: 0.5214\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8433 - accuracy: 0.5593 - val_loss: 0.9715 - val_accuracy: 0.5470\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8416 - accuracy: 0.5630 - val_loss: 0.9621 - val_accuracy: 0.5299\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8428 - accuracy: 0.5370 - val_loss: 0.9639 - val_accuracy: 0.5299\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8442 - accuracy: 0.5481 - val_loss: 0.9617 - val_accuracy: 0.5299\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8392 - accuracy: 0.5481 - val_loss: 0.9628 - val_accuracy: 0.5470\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8415 - accuracy: 0.5630 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8401 - accuracy: 0.5630 - val_loss: 0.9626 - val_accuracy: 0.5470\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8449 - accuracy: 0.5444 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 0.9587 - val_accuracy: 0.5470\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 0.9624 - val_accuracy: 0.5299\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8397 - accuracy: 0.5593 - val_loss: 0.9660 - val_accuracy: 0.5470\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8395 - accuracy: 0.5630 - val_loss: 0.9673 - val_accuracy: 0.5470\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8390 - accuracy: 0.5630 - val_loss: 0.9610 - val_accuracy: 0.5470\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8386 - accuracy: 0.5630 - val_loss: 0.9632 - val_accuracy: 0.5470\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8390 - accuracy: 0.5630 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8422 - accuracy: 0.5148 - val_loss: 0.9664 - val_accuracy: 0.5470\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8411 - accuracy: 0.5593 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8386 - accuracy: 0.5630 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8405 - accuracy: 0.5630 - val_loss: 0.9675 - val_accuracy: 0.5470\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8411 - accuracy: 0.5630 - val_loss: 0.9660 - val_accuracy: 0.5470\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8397 - accuracy: 0.5630 - val_loss: 0.9654 - val_accuracy: 0.5470\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8401 - accuracy: 0.5593 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8411 - accuracy: 0.5556 - val_loss: 0.9660 - val_accuracy: 0.5385\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8393 - accuracy: 0.5630 - val_loss: 0.9616 - val_accuracy: 0.5385\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8402 - accuracy: 0.5667 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8396 - accuracy: 0.5593 - val_loss: 0.9683 - val_accuracy: 0.5214\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8381 - accuracy: 0.5407 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8382 - accuracy: 0.5630 - val_loss: 0.9681 - val_accuracy: 0.5470\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8419 - accuracy: 0.5630 - val_loss: 0.9668 - val_accuracy: 0.5470\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8427 - accuracy: 0.5333 - val_loss: 0.9640 - val_accuracy: 0.5214\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 0.9661 - val_accuracy: 0.5470\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 0.9661 - val_accuracy: 0.5470\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8431 - accuracy: 0.5481 - val_loss: 0.9687 - val_accuracy: 0.5214\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8396 - accuracy: 0.5556 - val_loss: 0.9661 - val_accuracy: 0.5470\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8390 - accuracy: 0.5630 - val_loss: 0.9646 - val_accuracy: 0.5470\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8422 - accuracy: 0.5259 - val_loss: 0.9649 - val_accuracy: 0.5299\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8367 - accuracy: 0.5556 - val_loss: 0.9663 - val_accuracy: 0.5470\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 0.9650 - val_accuracy: 0.5470\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8393 - accuracy: 0.5630 - val_loss: 0.9661 - val_accuracy: 0.5470\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8389 - accuracy: 0.5667 - val_loss: 0.9633 - val_accuracy: 0.5470\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8436 - accuracy: 0.5630 - val_loss: 0.9624 - val_accuracy: 0.5470\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8448 - accuracy: 0.5296 - val_loss: 0.9604 - val_accuracy: 0.5299\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 0.9653 - val_accuracy: 0.5385\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8430 - accuracy: 0.5444 - val_loss: 0.9608 - val_accuracy: 0.5214\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8373 - accuracy: 0.5593 - val_loss: 0.9610 - val_accuracy: 0.5470\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8384 - accuracy: 0.5630 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8408 - accuracy: 0.5630 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8534 - accuracy: 0.5185 - val_loss: 0.9630 - val_accuracy: 0.5214\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8396 - accuracy: 0.5741 - val_loss: 0.9711 - val_accuracy: 0.5470\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8434 - accuracy: 0.5630 - val_loss: 0.9618 - val_accuracy: 0.5470\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8399 - accuracy: 0.5333 - val_loss: 0.9598 - val_accuracy: 0.5299\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8400 - accuracy: 0.5407 - val_loss: 0.9610 - val_accuracy: 0.5470\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 0.9649 - val_accuracy: 0.5470\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8372 - accuracy: 0.5630 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8399 - accuracy: 0.5444 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8402 - accuracy: 0.5593 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8396 - accuracy: 0.5630 - val_loss: 0.9669 - val_accuracy: 0.5470\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8378 - accuracy: 0.5630 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8375 - accuracy: 0.5593 - val_loss: 0.9654 - val_accuracy: 0.5385\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 0.9628 - val_accuracy: 0.5470\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8378 - accuracy: 0.5556 - val_loss: 0.9706 - val_accuracy: 0.5470\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 0.9670 - val_accuracy: 0.5470\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8384 - accuracy: 0.5481 - val_loss: 0.9653 - val_accuracy: 0.5299\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 0.9621 - val_accuracy: 0.5299\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8379 - accuracy: 0.5519 - val_loss: 0.9625 - val_accuracy: 0.5470\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8401 - accuracy: 0.5630 - val_loss: 0.9642 - val_accuracy: 0.5470\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 0.9633 - val_accuracy: 0.5470\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8418 - accuracy: 0.5111 - val_loss: 0.9660 - val_accuracy: 0.5299\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8424 - accuracy: 0.5481 - val_loss: 0.9596 - val_accuracy: 0.5470\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8395 - accuracy: 0.5630 - val_loss: 0.9614 - val_accuracy: 0.5470\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 0.9634 - val_accuracy: 0.5385\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8386 - accuracy: 0.5593 - val_loss: 0.9637 - val_accuracy: 0.5214\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8472 - accuracy: 0.5481 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 0.9683 - val_accuracy: 0.5470\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8417 - accuracy: 0.5630 - val_loss: 0.9659 - val_accuracy: 0.5470\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8400 - accuracy: 0.5296 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8357 - accuracy: 0.5815 - val_loss: 0.9688 - val_accuracy: 0.5385\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 0.9734 - val_accuracy: 0.5385\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8354 - accuracy: 0.5630 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8425 - accuracy: 0.5333 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8412 - accuracy: 0.5259 - val_loss: 0.9647 - val_accuracy: 0.5385\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8367 - accuracy: 0.5667 - val_loss: 0.9649 - val_accuracy: 0.5214\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8381 - accuracy: 0.5519 - val_loss: 0.9649 - val_accuracy: 0.5385\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8393 - accuracy: 0.5593 - val_loss: 0.9692 - val_accuracy: 0.5470\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 0.9682 - val_accuracy: 0.5214\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8399 - accuracy: 0.5519 - val_loss: 0.9681 - val_accuracy: 0.5214\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8392 - accuracy: 0.5333 - val_loss: 0.9713 - val_accuracy: 0.5470\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 0.9660 - val_accuracy: 0.5470\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8381 - accuracy: 0.5630 - val_loss: 0.9637 - val_accuracy: 0.5214\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8383 - accuracy: 0.5519 - val_loss: 0.9625 - val_accuracy: 0.5470\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8415 - accuracy: 0.4963 - val_loss: 0.9628 - val_accuracy: 0.5470\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8400 - accuracy: 0.5630 - val_loss: 0.9589 - val_accuracy: 0.5470\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 0.9666 - val_accuracy: 0.5385\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8369 - accuracy: 0.5481 - val_loss: 0.9667 - val_accuracy: 0.5214\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8397 - accuracy: 0.5444 - val_loss: 0.9635 - val_accuracy: 0.5470\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8363 - accuracy: 0.5630 - val_loss: 0.9666 - val_accuracy: 0.5470\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 0.9683 - val_accuracy: 0.5470\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8405 - accuracy: 0.5593 - val_loss: 0.9659 - val_accuracy: 0.5385\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8399 - accuracy: 0.5630 - val_loss: 0.9605 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8377 - accuracy: 0.5481 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8394 - accuracy: 0.5593 - val_loss: 0.9711 - val_accuracy: 0.5470\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8384 - accuracy: 0.5630 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 0.9664 - val_accuracy: 0.5299\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8391 - accuracy: 0.5481 - val_loss: 0.9717 - val_accuracy: 0.5470\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 0.9635 - val_accuracy: 0.5470\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8384 - accuracy: 0.5556 - val_loss: 0.9599 - val_accuracy: 0.5299\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8370 - accuracy: 0.5370 - val_loss: 0.9636 - val_accuracy: 0.5385\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8380 - accuracy: 0.5630 - val_loss: 0.9698 - val_accuracy: 0.5385\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 0.9678 - val_accuracy: 0.5470\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8365 - accuracy: 0.5630 - val_loss: 0.9645 - val_accuracy: 0.5470\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8364 - accuracy: 0.5630 - val_loss: 0.9629 - val_accuracy: 0.5470\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8391 - accuracy: 0.5630 - val_loss: 0.9587 - val_accuracy: 0.5470\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8397 - accuracy: 0.5296 - val_loss: 0.9616 - val_accuracy: 0.5214\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8392 - accuracy: 0.5481 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8385 - accuracy: 0.5630 - val_loss: 0.9665 - val_accuracy: 0.5470\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8372 - accuracy: 0.5630 - val_loss: 0.9659 - val_accuracy: 0.5385\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8362 - accuracy: 0.5481 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8367 - accuracy: 0.5481 - val_loss: 0.9609 - val_accuracy: 0.5470\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8373 - accuracy: 0.5630 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8423 - accuracy: 0.5185 - val_loss: 0.9620 - val_accuracy: 0.5299\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8366 - accuracy: 0.5444 - val_loss: 0.9671 - val_accuracy: 0.5470\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8391 - accuracy: 0.5630 - val_loss: 0.9671 - val_accuracy: 0.5470\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8362 - accuracy: 0.5630 - val_loss: 0.9690 - val_accuracy: 0.5470\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 0.9674 - val_accuracy: 0.5470\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8384 - accuracy: 0.5407 - val_loss: 0.9698 - val_accuracy: 0.5214\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8394 - accuracy: 0.5370 - val_loss: 0.9689 - val_accuracy: 0.5470\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8368 - accuracy: 0.5556 - val_loss: 0.9659 - val_accuracy: 0.5299\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8374 - accuracy: 0.5259 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 0.9650 - val_accuracy: 0.5214\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8393 - accuracy: 0.5407 - val_loss: 0.9695 - val_accuracy: 0.5470\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8364 - accuracy: 0.5630 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8404 - accuracy: 0.5333 - val_loss: 0.9658 - val_accuracy: 0.5214\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8380 - accuracy: 0.5667 - val_loss: 0.9690 - val_accuracy: 0.5470\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8385 - accuracy: 0.5630 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8416 - accuracy: 0.5481 - val_loss: 0.9705 - val_accuracy: 0.5214\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8380 - accuracy: 0.5481 - val_loss: 0.9683 - val_accuracy: 0.5470\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8368 - accuracy: 0.5630 - val_loss: 0.9677 - val_accuracy: 0.5470\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8360 - accuracy: 0.5630 - val_loss: 0.9649 - val_accuracy: 0.5470\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8380 - accuracy: 0.5630 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8369 - accuracy: 0.5556 - val_loss: 0.9679 - val_accuracy: 0.5214\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 0.9683 - val_accuracy: 0.5299\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8370 - accuracy: 0.5481 - val_loss: 0.9723 - val_accuracy: 0.5470\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8365 - accuracy: 0.5593 - val_loss: 0.9699 - val_accuracy: 0.5385\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8363 - accuracy: 0.5630 - val_loss: 0.9653 - val_accuracy: 0.5385\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8417 - accuracy: 0.5148 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8402 - accuracy: 0.5630 - val_loss: 0.9679 - val_accuracy: 0.5470\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8391 - accuracy: 0.5630 - val_loss: 0.9662 - val_accuracy: 0.5470\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8376 - accuracy: 0.5556 - val_loss: 0.9706 - val_accuracy: 0.5214\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 0.9716 - val_accuracy: 0.5385\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8409 - accuracy: 0.5593 - val_loss: 0.9667 - val_accuracy: 0.5470\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8362 - accuracy: 0.5630 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8377 - accuracy: 0.5556 - val_loss: 0.9693 - val_accuracy: 0.5214\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8376 - accuracy: 0.5407 - val_loss: 0.9672 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8366 - accuracy: 0.5370 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8413 - accuracy: 0.5630 - val_loss: 0.9694 - val_accuracy: 0.5470\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8353 - accuracy: 0.5630 - val_loss: 0.9613 - val_accuracy: 0.5299\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8387 - accuracy: 0.5519 - val_loss: 0.9631 - val_accuracy: 0.5214\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8414 - accuracy: 0.5370 - val_loss: 0.9668 - val_accuracy: 0.5470\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8354 - accuracy: 0.5630 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8370 - accuracy: 0.5519 - val_loss: 0.9610 - val_accuracy: 0.5299\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8368 - accuracy: 0.5593 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8356 - accuracy: 0.5481 - val_loss: 0.9674 - val_accuracy: 0.5299\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8364 - accuracy: 0.5593 - val_loss: 0.9654 - val_accuracy: 0.5470\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8386 - accuracy: 0.5333 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8366 - accuracy: 0.5556 - val_loss: 0.9722 - val_accuracy: 0.5470\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8366 - accuracy: 0.5667 - val_loss: 0.9691 - val_accuracy: 0.5470\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8362 - accuracy: 0.5667 - val_loss: 0.9681 - val_accuracy: 0.5299\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8361 - accuracy: 0.5519 - val_loss: 0.9645 - val_accuracy: 0.5299\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8418 - accuracy: 0.5593 - val_loss: 0.9716 - val_accuracy: 0.5470\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8381 - accuracy: 0.5630 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8376 - accuracy: 0.5778 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8421 - accuracy: 0.5407 - val_loss: 0.9726 - val_accuracy: 0.5470\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 0.9666 - val_accuracy: 0.5299\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 0.9626 - val_accuracy: 0.5299\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8377 - accuracy: 0.5296 - val_loss: 0.9645 - val_accuracy: 0.5470\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8372 - accuracy: 0.5333 - val_loss: 0.9637 - val_accuracy: 0.5299\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8360 - accuracy: 0.5593 - val_loss: 0.9667 - val_accuracy: 0.5470\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9670 - val_accuracy: 0.5470\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8367 - accuracy: 0.5556 - val_loss: 0.9662 - val_accuracy: 0.5299\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8378 - accuracy: 0.5333 - val_loss: 0.9667 - val_accuracy: 0.5470\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9699 - val_accuracy: 0.5470\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8366 - accuracy: 0.5630 - val_loss: 0.9674 - val_accuracy: 0.5470\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8427 - accuracy: 0.5259 - val_loss: 0.9712 - val_accuracy: 0.5299\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8417 - accuracy: 0.5481 - val_loss: 0.9717 - val_accuracy: 0.5470\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 0.9625 - val_accuracy: 0.5470\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8338 - accuracy: 0.5852 - val_loss: 0.9629 - val_accuracy: 0.5214\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 0.9641 - val_accuracy: 0.5214\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8375 - accuracy: 0.5407 - val_loss: 0.9672 - val_accuracy: 0.5470\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8371 - accuracy: 0.5630 - val_loss: 0.9645 - val_accuracy: 0.5470\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8343 - accuracy: 0.5852 - val_loss: 0.9667 - val_accuracy: 0.5299\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8376 - accuracy: 0.5333 - val_loss: 0.9692 - val_accuracy: 0.5470\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8353 - accuracy: 0.5630 - val_loss: 0.9665 - val_accuracy: 0.5470\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 0.9642 - val_accuracy: 0.5470\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8382 - accuracy: 0.5630 - val_loss: 0.9695 - val_accuracy: 0.5470\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8367 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8358 - accuracy: 0.5704 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8353 - accuracy: 0.5519 - val_loss: 0.9691 - val_accuracy: 0.5470\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8371 - accuracy: 0.5630 - val_loss: 0.9716 - val_accuracy: 0.5470\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 0.9673 - val_accuracy: 0.5299\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8357 - accuracy: 0.5296 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 0.9691 - val_accuracy: 0.5470\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 0.9674 - val_accuracy: 0.5470\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8345 - accuracy: 0.5630 - val_loss: 0.9674 - val_accuracy: 0.5470\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8345 - accuracy: 0.5630 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8353 - accuracy: 0.5630 - val_loss: 0.9695 - val_accuracy: 0.5470\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8376 - accuracy: 0.5630 - val_loss: 0.9684 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8364 - accuracy: 0.5630 - val_loss: 0.9742 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38125198>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 89us/step\n",
      "over-sampling test accuracy: 53.85%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, 0, 2, 1, 0, 2,\n",
       "       0, 0, 1, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS383     1     0\n",
       "1       NRS254     1     1\n",
       "2       NRS218     1     1\n",
       "3       NRS215     0     0\n",
       "4    BCH-SA-14     2     0\n",
       "..         ...   ...   ...\n",
       "112     NRS227     1     1\n",
       "113     NRS272     1     2\n",
       "114   CFBRSa24     0     0\n",
       "115   CFBRSa74     0     0\n",
       "116     NRS271     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510052</td>\n",
       "      <td>0.256485</td>\n",
       "      <td>0.233462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.273881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.273881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994780</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.003063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444397</td>\n",
       "      <td>0.374179</td>\n",
       "      <td>0.181424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.273881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.993949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.444397</td>\n",
       "      <td>0.374179</td>\n",
       "      <td>0.181424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.444397</td>\n",
       "      <td>0.374179</td>\n",
       "      <td>0.181424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.272272</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.273881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.510052  0.256485  0.233462\n",
       "1    0.272272  0.453846  0.273881\n",
       "2    0.272272  0.453846  0.273881\n",
       "3    0.994780  0.002158  0.003063\n",
       "4    0.444397  0.374179  0.181424\n",
       "..        ...       ...       ...\n",
       "112  0.272272  0.453846  0.273881\n",
       "113  0.000551  0.005500  0.993949\n",
       "114  0.444397  0.374179  0.181424\n",
       "115  0.444397  0.374179  0.181424\n",
       "116  0.272272  0.453846  0.273881\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8447 - accuracy: 0.5111 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8335 - accuracy: 0.5481 - val_loss: 0.9670 - val_accuracy: 0.5470\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8465 - accuracy: 0.5630 - val_loss: 0.9734 - val_accuracy: 0.5470\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8336 - accuracy: 0.5667 - val_loss: 0.9692 - val_accuracy: 0.5299\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 0.9705 - val_accuracy: 0.5470\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 0.9737 - val_accuracy: 0.5470\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 0.9768 - val_accuracy: 0.5470\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 0.9684 - val_accuracy: 0.5299\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8356 - accuracy: 0.5370 - val_loss: 0.9685 - val_accuracy: 0.5299\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8357 - accuracy: 0.5519 - val_loss: 0.9722 - val_accuracy: 0.5299\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8373 - accuracy: 0.5444 - val_loss: 0.9717 - val_accuracy: 0.5470\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8347 - accuracy: 0.5630 - val_loss: 0.9670 - val_accuracy: 0.5470\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8837 - accuracy: 0.53 - 0s 108us/step - loss: 0.8345 - accuracy: 0.5667 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8354 - accuracy: 0.5519 - val_loss: 0.9682 - val_accuracy: 0.5470\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8029 - accuracy: 0.62 - 0s 114us/step - loss: 0.8345 - accuracy: 0.5630 - val_loss: 0.9689 - val_accuracy: 0.5470\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 0.9654 - val_accuracy: 0.5470\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8376 - accuracy: 0.5111 - val_loss: 0.9693 - val_accuracy: 0.5214\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8339 - accuracy: 0.5556 - val_loss: 0.9722 - val_accuracy: 0.5470\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9700 - val_accuracy: 0.5470\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 0.9674 - val_accuracy: 0.5470\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8333 - accuracy: 0.5667 - val_loss: 0.9683 - val_accuracy: 0.5385\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 0.9701 - val_accuracy: 0.5385\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8340 - accuracy: 0.5556 - val_loss: 0.9706 - val_accuracy: 0.5214\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8332 - accuracy: 0.5444 - val_loss: 0.9685 - val_accuracy: 0.5385\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8370 - accuracy: 0.5630 - val_loss: 0.9701 - val_accuracy: 0.5385\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8355 - accuracy: 0.5481 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8361 - accuracy: 0.5444 - val_loss: 0.9697 - val_accuracy: 0.5470\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 0.9703 - val_accuracy: 0.5385\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 0.9705 - val_accuracy: 0.5214\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8383 - accuracy: 0.5407 - val_loss: 0.9754 - val_accuracy: 0.5214\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 291us/step - loss: 0.8371 - accuracy: 0.5519 - val_loss: 0.9775 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 0.9745 - val_accuracy: 0.5385\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8347 - accuracy: 0.5630 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8379 - accuracy: 0.5630 - val_loss: 0.9755 - val_accuracy: 0.5385\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8407 - accuracy: 0.5296 - val_loss: 0.9756 - val_accuracy: 0.5214\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8350 - accuracy: 0.5333 - val_loss: 0.9710 - val_accuracy: 0.5385\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8390 - accuracy: 0.5148 - val_loss: 0.9692 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8337 - accuracy: 0.5556 - val_loss: 0.9742 - val_accuracy: 0.5385\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8374 - accuracy: 0.5407 - val_loss: 0.9692 - val_accuracy: 0.5385\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9737 - val_accuracy: 0.5470\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8359 - accuracy: 0.5630 - val_loss: 0.9709 - val_accuracy: 0.5470\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 0.9732 - val_accuracy: 0.5470\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8341 - accuracy: 0.5444 - val_loss: 0.9713 - val_accuracy: 0.5470\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8368 - accuracy: 0.5296 - val_loss: 0.9733 - val_accuracy: 0.5385\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9685 - val_accuracy: 0.5470\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8358 - accuracy: 0.5630 - val_loss: 0.9709 - val_accuracy: 0.5470\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8319 - accuracy: 0.5815 - val_loss: 0.9684 - val_accuracy: 0.5214\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8358 - accuracy: 0.5519 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 0.9777 - val_accuracy: 0.5470\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8329 - accuracy: 0.5593 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8351 - accuracy: 0.5519 - val_loss: 0.9685 - val_accuracy: 0.5299\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8341 - accuracy: 0.5593 - val_loss: 0.9652 - val_accuracy: 0.5470\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8333 - accuracy: 0.5593 - val_loss: 0.9658 - val_accuracy: 0.5385\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 0.9667 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8344 - accuracy: 0.5333 - val_loss: 0.9634 - val_accuracy: 0.5214\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8342 - accuracy: 0.5407 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 0.9686 - val_accuracy: 0.5470\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8322 - accuracy: 0.5593 - val_loss: 0.9704 - val_accuracy: 0.5299\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8361 - accuracy: 0.5519 - val_loss: 0.9706 - val_accuracy: 0.5299\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 0.9746 - val_accuracy: 0.5470\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8385 - accuracy: 0.5630 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8372 - accuracy: 0.5370 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8337 - accuracy: 0.5519 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8363 - accuracy: 0.5630 - val_loss: 0.9712 - val_accuracy: 0.5470\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8346 - accuracy: 0.5630 - val_loss: 0.9713 - val_accuracy: 0.5470\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8334 - accuracy: 0.5444 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 622us/step - loss: 0.8350 - accuracy: 0.5519 - val_loss: 0.9660 - val_accuracy: 0.5299\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8396 - accuracy: 0.5556 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8331 - accuracy: 0.5481 - val_loss: 0.9669 - val_accuracy: 0.5299\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8346 - accuracy: 0.5519 - val_loss: 0.9679 - val_accuracy: 0.5385\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 0.9705 - val_accuracy: 0.5385\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8328 - accuracy: 0.5630 - val_loss: 0.9689 - val_accuracy: 0.5470\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 0.9676 - val_accuracy: 0.5299\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8339 - accuracy: 0.5333 - val_loss: 0.9689 - val_accuracy: 0.5299\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8330 - accuracy: 0.5370 - val_loss: 0.9697 - val_accuracy: 0.5214\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8336 - accuracy: 0.5556 - val_loss: 0.9732 - val_accuracy: 0.5385\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 0.9701 - val_accuracy: 0.5385\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 0.9687 - val_accuracy: 0.5385\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8342 - accuracy: 0.5778 - val_loss: 0.9662 - val_accuracy: 0.5214\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8366 - accuracy: 0.5259 - val_loss: 0.9677 - val_accuracy: 0.5385\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8384 - accuracy: 0.5481 - val_loss: 0.9698 - val_accuracy: 0.5299\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8345 - accuracy: 0.5519 - val_loss: 0.9739 - val_accuracy: 0.5385\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8410 - accuracy: 0.5667 - val_loss: 0.9761 - val_accuracy: 0.5470\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 0.9731 - val_accuracy: 0.5299\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8381 - accuracy: 0.5519 - val_loss: 0.9737 - val_accuracy: 0.5214\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8341 - accuracy: 0.5593 - val_loss: 0.9695 - val_accuracy: 0.5470\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8333 - accuracy: 0.5630 - val_loss: 0.9675 - val_accuracy: 0.5470\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8341 - accuracy: 0.5630 - val_loss: 0.9678 - val_accuracy: 0.5470\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8339 - accuracy: 0.5222 - val_loss: 0.9676 - val_accuracy: 0.5385\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8373 - accuracy: 0.5444 - val_loss: 0.9702 - val_accuracy: 0.5214\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8347 - accuracy: 0.5556 - val_loss: 0.9681 - val_accuracy: 0.5385\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8367 - accuracy: 0.5296 - val_loss: 0.9657 - val_accuracy: 0.5385\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8386 - accuracy: 0.5222 - val_loss: 0.9697 - val_accuracy: 0.5470\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8348 - accuracy: 0.5630 - val_loss: 0.9745 - val_accuracy: 0.5385\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8347 - accuracy: 0.5630 - val_loss: 0.9794 - val_accuracy: 0.5385\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8323 - accuracy: 0.5593 - val_loss: 0.9693 - val_accuracy: 0.5214\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8360 - accuracy: 0.5444 - val_loss: 0.9672 - val_accuracy: 0.5470\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8318 - accuracy: 0.5481 - val_loss: 0.9687 - val_accuracy: 0.5385\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 0.9724 - val_accuracy: 0.5385\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8353 - accuracy: 0.5630 - val_loss: 0.9697 - val_accuracy: 0.5214\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8348 - accuracy: 0.5259 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8333 - accuracy: 0.5333 - val_loss: 0.9690 - val_accuracy: 0.5385\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9746 - val_accuracy: 0.5385\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8333 - accuracy: 0.5630 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8333 - accuracy: 0.5593 - val_loss: 0.9723 - val_accuracy: 0.5470\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8335 - accuracy: 0.5148 - val_loss: 0.9727 - val_accuracy: 0.5385\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8334 - accuracy: 0.5593 - val_loss: 0.9698 - val_accuracy: 0.5385\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8338 - accuracy: 0.5407 - val_loss: 0.9710 - val_accuracy: 0.5299\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8361 - accuracy: 0.5407 - val_loss: 0.9770 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8365 - accuracy: 0.5630 - val_loss: 0.9657 - val_accuracy: 0.5470\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8335 - accuracy: 0.5444 - val_loss: 0.9648 - val_accuracy: 0.5385\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8336 - accuracy: 0.5444 - val_loss: 0.9650 - val_accuracy: 0.5556\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8345 - accuracy: 0.5630 - val_loss: 0.9721 - val_accuracy: 0.5470\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8348 - accuracy: 0.5593 - val_loss: 0.9684 - val_accuracy: 0.5470\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 0.9699 - val_accuracy: 0.5470\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8336 - accuracy: 0.5444 - val_loss: 0.9666 - val_accuracy: 0.5299\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8372 - accuracy: 0.5259 - val_loss: 0.9660 - val_accuracy: 0.5470\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8321 - accuracy: 0.5407 - val_loss: 0.9685 - val_accuracy: 0.5214\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8329 - accuracy: 0.5407 - val_loss: 0.9689 - val_accuracy: 0.5470\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8358 - accuracy: 0.5222 - val_loss: 0.9705 - val_accuracy: 0.5299\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 0.9697 - val_accuracy: 0.5470\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 0.9713 - val_accuracy: 0.5470\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 436us/step - loss: 0.8347 - accuracy: 0.5407 - val_loss: 0.9670 - val_accuracy: 0.5470\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8337 - accuracy: 0.5407 - val_loss: 0.9709 - val_accuracy: 0.5299\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8346 - accuracy: 0.5481 - val_loss: 0.9723 - val_accuracy: 0.5470\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8362 - accuracy: 0.5630 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8415 - accuracy: 0.5259 - val_loss: 0.9742 - val_accuracy: 0.5299\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8317 - accuracy: 0.5556 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 0.9757 - val_accuracy: 0.5470\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8325 - accuracy: 0.5444 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8347 - accuracy: 0.5556 - val_loss: 0.9681 - val_accuracy: 0.5385\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8342 - accuracy: 0.5630 - val_loss: 0.9702 - val_accuracy: 0.5470\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8337 - accuracy: 0.5593 - val_loss: 0.9753 - val_accuracy: 0.5470\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8344 - accuracy: 0.5259 - val_loss: 0.9797 - val_accuracy: 0.5470\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8327 - accuracy: 0.5630 - val_loss: 0.9767 - val_accuracy: 0.5470\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8337 - accuracy: 0.5407 - val_loss: 0.9762 - val_accuracy: 0.5299\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8348 - accuracy: 0.5481 - val_loss: 0.9728 - val_accuracy: 0.5470\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8332 - accuracy: 0.5519 - val_loss: 0.9736 - val_accuracy: 0.5214\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8347 - accuracy: 0.5296 - val_loss: 0.9727 - val_accuracy: 0.5385\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9710 - val_accuracy: 0.5385\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8369 - accuracy: 0.5370 - val_loss: 0.9719 - val_accuracy: 0.5214\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8328 - accuracy: 0.5556 - val_loss: 0.9728 - val_accuracy: 0.5385\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 0.9762 - val_accuracy: 0.5385\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 0.9728 - val_accuracy: 0.5385\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8365 - accuracy: 0.5111 - val_loss: 0.9715 - val_accuracy: 0.5470\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8331 - accuracy: 0.5259 - val_loss: 0.9705 - val_accuracy: 0.5470\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8344 - accuracy: 0.5481 - val_loss: 0.9723 - val_accuracy: 0.5299\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 0.9760 - val_accuracy: 0.5470\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8372 - accuracy: 0.5630 - val_loss: 0.9743 - val_accuracy: 0.5470\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8330 - accuracy: 0.5407 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8355 - accuracy: 0.5519 - val_loss: 0.9718 - val_accuracy: 0.5299\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8348 - accuracy: 0.5741 - val_loss: 0.9759 - val_accuracy: 0.5470\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 0.9739 - val_accuracy: 0.5214\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8376 - accuracy: 0.5519 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8338 - accuracy: 0.5407 - val_loss: 0.9750 - val_accuracy: 0.5385\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8321 - accuracy: 0.5556 - val_loss: 0.9737 - val_accuracy: 0.5470\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8327 - accuracy: 0.5630 - val_loss: 0.9734 - val_accuracy: 0.5470\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 0.9751 - val_accuracy: 0.5470\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8387 - accuracy: 0.5148 - val_loss: 0.9727 - val_accuracy: 0.5299\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8356 - accuracy: 0.5370 - val_loss: 0.9705 - val_accuracy: 0.5470\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 0.9707 - val_accuracy: 0.5470\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8344 - accuracy: 0.5667 - val_loss: 0.9761 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8372 - accuracy: 0.5370 - val_loss: 0.9710 - val_accuracy: 0.5299\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8337 - accuracy: 0.5407 - val_loss: 0.9713 - val_accuracy: 0.5470\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8323 - accuracy: 0.5593 - val_loss: 0.9708 - val_accuracy: 0.5385\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8311 - accuracy: 0.5593 - val_loss: 0.9726 - val_accuracy: 0.5299\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8331 - accuracy: 0.5519 - val_loss: 0.9743 - val_accuracy: 0.5470\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 0.9783 - val_accuracy: 0.5470\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9731 - val_accuracy: 0.5470\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 0.9729 - val_accuracy: 0.5470\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8321 - accuracy: 0.5667 - val_loss: 0.9734 - val_accuracy: 0.5299\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8337 - accuracy: 0.5444 - val_loss: 0.9728 - val_accuracy: 0.5470\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8458 - accuracy: 0.5148 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 0.9816 - val_accuracy: 0.5385\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8333 - accuracy: 0.5593 - val_loss: 0.9755 - val_accuracy: 0.5299\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8324 - accuracy: 0.5519 - val_loss: 0.9764 - val_accuracy: 0.5470\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9751 - val_accuracy: 0.5470\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 494us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 0.9755 - val_accuracy: 0.5470\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 394us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9727 - val_accuracy: 0.5470\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8330 - accuracy: 0.5370 - val_loss: 0.9744 - val_accuracy: 0.5214\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8324 - accuracy: 0.5519 - val_loss: 0.9725 - val_accuracy: 0.5470\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8351 - accuracy: 0.5630 - val_loss: 0.9746 - val_accuracy: 0.5470\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8328 - accuracy: 0.5630 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8297 - accuracy: 0.5667 - val_loss: 0.9710 - val_accuracy: 0.5385\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8358 - accuracy: 0.5444 - val_loss: 0.9759 - val_accuracy: 0.5214\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8332 - accuracy: 0.5593 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8341 - accuracy: 0.5630 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8325 - accuracy: 0.5556 - val_loss: 0.9715 - val_accuracy: 0.5299\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8323 - accuracy: 0.5407 - val_loss: 0.9730 - val_accuracy: 0.5385\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9730 - val_accuracy: 0.5385\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 0.9745 - val_accuracy: 0.5385\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8338 - accuracy: 0.5593 - val_loss: 0.9790 - val_accuracy: 0.5470\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8331 - accuracy: 0.5481 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8334 - accuracy: 0.5519 - val_loss: 0.9730 - val_accuracy: 0.5470\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9764 - val_accuracy: 0.5470\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8338 - accuracy: 0.5074 - val_loss: 0.9748 - val_accuracy: 0.5470\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 0.9760 - val_accuracy: 0.5470\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8327 - accuracy: 0.5519 - val_loss: 0.9734 - val_accuracy: 0.5214\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8339 - accuracy: 0.5778 - val_loss: 0.9770 - val_accuracy: 0.5470\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8358 - accuracy: 0.5481 - val_loss: 0.9695 - val_accuracy: 0.5214\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 0.9716 - val_accuracy: 0.5385\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8422 - accuracy: 0.5593 - val_loss: 0.9732 - val_accuracy: 0.5470\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8352 - accuracy: 0.5667 - val_loss: 0.9711 - val_accuracy: 0.5299\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8351 - accuracy: 0.5481 - val_loss: 0.9709 - val_accuracy: 0.5214\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8307 - accuracy: 0.5481 - val_loss: 0.9771 - val_accuracy: 0.5385\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8335 - accuracy: 0.5407 - val_loss: 0.9782 - val_accuracy: 0.5214\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8321 - accuracy: 0.5407 - val_loss: 0.9741 - val_accuracy: 0.5299\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8312 - accuracy: 0.5556 - val_loss: 0.9748 - val_accuracy: 0.5470\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8320 - accuracy: 0.5444 - val_loss: 0.9747 - val_accuracy: 0.5299\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8353 - accuracy: 0.5407 - val_loss: 0.9810 - val_accuracy: 0.5385\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 0.9742 - val_accuracy: 0.5385\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8354 - accuracy: 0.5407 - val_loss: 0.9765 - val_accuracy: 0.5214\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8359 - accuracy: 0.5333 - val_loss: 0.9796 - val_accuracy: 0.5470\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8336 - accuracy: 0.5481 - val_loss: 0.9739 - val_accuracy: 0.5299\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8380 - accuracy: 0.5296 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9754 - val_accuracy: 0.5470\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8350 - accuracy: 0.5444 - val_loss: 0.9708 - val_accuracy: 0.5299\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8348 - accuracy: 0.5370 - val_loss: 0.9729 - val_accuracy: 0.5470\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9729 - val_accuracy: 0.5470\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 0.9746 - val_accuracy: 0.5470\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8335 - accuracy: 0.5481 - val_loss: 0.9753 - val_accuracy: 0.5299\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8323 - accuracy: 0.5519 - val_loss: 0.9766 - val_accuracy: 0.5470\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8380 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8360 - accuracy: 0.5407 - val_loss: 0.9807 - val_accuracy: 0.5214\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8347 - accuracy: 0.5333 - val_loss: 0.9763 - val_accuracy: 0.5385\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8428 - accuracy: 0.4889 - val_loss: 0.9776 - val_accuracy: 0.5299\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8363 - accuracy: 0.5333 - val_loss: 0.9752 - val_accuracy: 0.5385\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8310 - accuracy: 0.5667 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8318 - accuracy: 0.5519 - val_loss: 0.9709 - val_accuracy: 0.5299\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8356 - accuracy: 0.5519 - val_loss: 0.9703 - val_accuracy: 0.5470\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9812 - val_accuracy: 0.5470\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8412 - accuracy: 0.5630 - val_loss: 0.9774 - val_accuracy: 0.5470\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8328 - accuracy: 0.5667 - val_loss: 0.9761 - val_accuracy: 0.5299\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8352 - accuracy: 0.5481 - val_loss: 0.9707 - val_accuracy: 0.5299\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 0.9763 - val_accuracy: 0.5470\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9723 - val_accuracy: 0.5470\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8314 - accuracy: 0.5778 - val_loss: 0.9739 - val_accuracy: 0.5299\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8315 - accuracy: 0.5519 - val_loss: 0.9756 - val_accuracy: 0.5470\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9791 - val_accuracy: 0.5470\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8370 - accuracy: 0.5630 - val_loss: 0.9742 - val_accuracy: 0.5385\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8381 - accuracy: 0.5704 - val_loss: 0.9722 - val_accuracy: 0.5470\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8359 - accuracy: 0.5444 - val_loss: 0.9740 - val_accuracy: 0.5214\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8350 - accuracy: 0.5519 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 0.9754 - val_accuracy: 0.5385\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 0.9776 - val_accuracy: 0.5470\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8362 - accuracy: 0.5407 - val_loss: 0.9740 - val_accuracy: 0.5299\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8309 - accuracy: 0.5667 - val_loss: 0.9759 - val_accuracy: 0.5470\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 0.9761 - val_accuracy: 0.5470\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 0.9728 - val_accuracy: 0.5470\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 0.9756 - val_accuracy: 0.5470\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9751 - val_accuracy: 0.5470\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8305 - accuracy: 0.5704 - val_loss: 0.9769 - val_accuracy: 0.5299\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8347 - accuracy: 0.5481 - val_loss: 0.9724 - val_accuracy: 0.5214\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8340 - accuracy: 0.5519 - val_loss: 0.9751 - val_accuracy: 0.5470\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8317 - accuracy: 0.5556 - val_loss: 0.9733 - val_accuracy: 0.5299\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8318 - accuracy: 0.5333 - val_loss: 0.9749 - val_accuracy: 0.5470\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9772 - val_accuracy: 0.5470\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8325 - accuracy: 0.5667 - val_loss: 0.9740 - val_accuracy: 0.5385\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8304 - accuracy: 0.5593 - val_loss: 0.9729 - val_accuracy: 0.5299\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8310 - accuracy: 0.5407 - val_loss: 0.9732 - val_accuracy: 0.5385\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 0.9721 - val_accuracy: 0.5385\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8333 - accuracy: 0.5593 - val_loss: 0.9714 - val_accuracy: 0.5385\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 0.9755 - val_accuracy: 0.5385\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8368 - accuracy: 0.5370 - val_loss: 0.9725 - val_accuracy: 0.5214\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 0.9717 - val_accuracy: 0.5470\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8343 - accuracy: 0.5556 - val_loss: 0.9751 - val_accuracy: 0.5385\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 0.9751 - val_accuracy: 0.5214\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8320 - accuracy: 0.5519 - val_loss: 0.9787 - val_accuracy: 0.5214\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8303 - accuracy: 0.5593 - val_loss: 0.9802 - val_accuracy: 0.5470\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8344 - accuracy: 0.5667 - val_loss: 0.9801 - val_accuracy: 0.5385\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9750 - val_accuracy: 0.5214\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 109us/step - loss: 0.8321 - accuracy: 0.5667 - val_loss: 0.9721 - val_accuracy: 0.5470\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8333 - accuracy: 0.5630 - val_loss: 0.9768 - val_accuracy: 0.5470\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 0.9756 - val_accuracy: 0.5470\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8332 - accuracy: 0.5222 - val_loss: 0.9753 - val_accuracy: 0.5385\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 0.9787 - val_accuracy: 0.5385\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8316 - accuracy: 0.5519 - val_loss: 0.9791 - val_accuracy: 0.5214\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8327 - accuracy: 0.5333 - val_loss: 0.9750 - val_accuracy: 0.5385\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 0.9766 - val_accuracy: 0.5385\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8331 - accuracy: 0.5407 - val_loss: 0.9748 - val_accuracy: 0.5299\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8364 - accuracy: 0.5333 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8310 - accuracy: 0.5444 - val_loss: 0.9756 - val_accuracy: 0.5214\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8332 - accuracy: 0.5407 - val_loss: 0.9785 - val_accuracy: 0.5385\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8317 - accuracy: 0.5444 - val_loss: 0.9761 - val_accuracy: 0.5385\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8340 - accuracy: 0.5630 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8297 - accuracy: 0.5667 - val_loss: 0.9745 - val_accuracy: 0.5299\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8321 - accuracy: 0.5481 - val_loss: 0.9746 - val_accuracy: 0.5214\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8314 - accuracy: 0.5519 - val_loss: 0.9795 - val_accuracy: 0.5385\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9778 - val_accuracy: 0.5470\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 0.9789 - val_accuracy: 0.5470\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8306 - accuracy: 0.5593 - val_loss: 0.9796 - val_accuracy: 0.5470\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8317 - accuracy: 0.5370 - val_loss: 0.9778 - val_accuracy: 0.5214\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8312 - accuracy: 0.5481 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 0.9742 - val_accuracy: 0.5470\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8327 - accuracy: 0.5370 - val_loss: 0.9740 - val_accuracy: 0.5214\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8301 - accuracy: 0.5556 - val_loss: 0.9722 - val_accuracy: 0.5470\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9725 - val_accuracy: 0.5470\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 0.9747 - val_accuracy: 0.5470\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8314 - accuracy: 0.5519 - val_loss: 0.9754 - val_accuracy: 0.5470\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 0.9779 - val_accuracy: 0.5470\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8304 - accuracy: 0.5519 - val_loss: 0.9794 - val_accuracy: 0.5299\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8314 - accuracy: 0.5519 - val_loss: 0.9778 - val_accuracy: 0.5299\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8294 - accuracy: 0.5556 - val_loss: 0.9795 - val_accuracy: 0.5470\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9744 - val_accuracy: 0.5470\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8323 - accuracy: 0.5444 - val_loss: 0.9749 - val_accuracy: 0.5299\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8295 - accuracy: 0.5667 - val_loss: 0.9766 - val_accuracy: 0.5470\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 0.9767 - val_accuracy: 0.5470\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9782 - val_accuracy: 0.5470\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9838 - val_accuracy: 0.5470\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8340 - accuracy: 0.5259 - val_loss: 0.9815 - val_accuracy: 0.5214\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8300 - accuracy: 0.5593 - val_loss: 0.9772 - val_accuracy: 0.5385\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8315 - accuracy: 0.5667 - val_loss: 0.9767 - val_accuracy: 0.5385\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9717 - val_accuracy: 0.5470\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8367 - accuracy: 0.5296 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8318 - accuracy: 0.5593 - val_loss: 0.9725 - val_accuracy: 0.5470\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 0.9737 - val_accuracy: 0.5470\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8310 - accuracy: 0.5444 - val_loss: 0.9757 - val_accuracy: 0.5299\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8313 - accuracy: 0.5519 - val_loss: 0.9762 - val_accuracy: 0.5299\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8332 - accuracy: 0.5593 - val_loss: 0.9734 - val_accuracy: 0.5470\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 0.9763 - val_accuracy: 0.5470\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8286 - accuracy: 0.5704 - val_loss: 0.9787 - val_accuracy: 0.5299\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8353 - accuracy: 0.5444 - val_loss: 0.9767 - val_accuracy: 0.5470\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 0.9772 - val_accuracy: 0.5470\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8319 - accuracy: 0.5630 - val_loss: 0.9751 - val_accuracy: 0.5470\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8329 - accuracy: 0.5333 - val_loss: 0.9799 - val_accuracy: 0.5214\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8312 - accuracy: 0.5481 - val_loss: 0.9802 - val_accuracy: 0.5470\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8369 - accuracy: 0.5074 - val_loss: 0.9778 - val_accuracy: 0.5299\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8360 - accuracy: 0.5519 - val_loss: 0.9808 - val_accuracy: 0.5470\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8309 - accuracy: 0.5519 - val_loss: 0.9753 - val_accuracy: 0.5299\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8314 - accuracy: 0.5333 - val_loss: 0.9741 - val_accuracy: 0.5470\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9744 - val_accuracy: 0.5470\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 0.9786 - val_accuracy: 0.5470\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8358 - accuracy: 0.5259 - val_loss: 0.9792 - val_accuracy: 0.5214\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8324 - accuracy: 0.5444 - val_loss: 0.9819 - val_accuracy: 0.5385\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8305 - accuracy: 0.5556 - val_loss: 0.9780 - val_accuracy: 0.5470\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8324 - accuracy: 0.5593 - val_loss: 0.9775 - val_accuracy: 0.5470\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8292 - accuracy: 0.5519 - val_loss: 0.9737 - val_accuracy: 0.5214\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8299 - accuracy: 0.5407 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9753 - val_accuracy: 0.5385\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8337 - accuracy: 0.5444 - val_loss: 0.9748 - val_accuracy: 0.5299\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8341 - accuracy: 0.5407 - val_loss: 0.9770 - val_accuracy: 0.5470\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9752 - val_accuracy: 0.5470\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8329 - accuracy: 0.5333 - val_loss: 0.9787 - val_accuracy: 0.5214\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8351 - accuracy: 0.5519 - val_loss: 0.9806 - val_accuracy: 0.5214\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.8310 - accuracy: 0.5481 - val_loss: 0.9798 - val_accuracy: 0.5470\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 0.9747 - val_accuracy: 0.5470\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9786 - val_accuracy: 0.5470\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8343 - accuracy: 0.5296 - val_loss: 0.9810 - val_accuracy: 0.5214\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 0.9803 - val_accuracy: 0.5385\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9805 - val_accuracy: 0.5470\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9822 - val_accuracy: 0.5470\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9786 - val_accuracy: 0.5470\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.8307 - accuracy: 0.5296 - val_loss: 0.9799 - val_accuracy: 0.5385\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9820 - val_accuracy: 0.5385\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8303 - accuracy: 0.5630 - val_loss: 0.9791 - val_accuracy: 0.5385\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9785 - val_accuracy: 0.5470\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8301 - accuracy: 0.5593 - val_loss: 0.9760 - val_accuracy: 0.5299\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8314 - accuracy: 0.5333 - val_loss: 0.9750 - val_accuracy: 0.5385\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8321 - accuracy: 0.5407 - val_loss: 0.9762 - val_accuracy: 0.5214\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8336 - accuracy: 0.5667 - val_loss: 0.9749 - val_accuracy: 0.5385\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8312 - accuracy: 0.5519 - val_loss: 0.9750 - val_accuracy: 0.5214\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.8311 - accuracy: 0.5519 - val_loss: 0.9755 - val_accuracy: 0.5470\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 0.9750 - val_accuracy: 0.5470\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8328 - accuracy: 0.5222 - val_loss: 0.9781 - val_accuracy: 0.5299\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8361 - accuracy: 0.5444 - val_loss: 0.9798 - val_accuracy: 0.5470\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 0.9793 - val_accuracy: 0.5385\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8331 - accuracy: 0.5593 - val_loss: 0.9769 - val_accuracy: 0.5385\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8358 - accuracy: 0.5296 - val_loss: 0.9747 - val_accuracy: 0.5214\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8319 - accuracy: 0.5407 - val_loss: 0.9738 - val_accuracy: 0.5470\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9715 - val_accuracy: 0.5470\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8347 - accuracy: 0.5259 - val_loss: 0.9736 - val_accuracy: 0.5299\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8439 - accuracy: 0.5407 - val_loss: 0.9854 - val_accuracy: 0.5470\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8291 - accuracy: 0.5815 - val_loss: 0.9734 - val_accuracy: 0.5299\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8365 - accuracy: 0.5519 - val_loss: 0.9735 - val_accuracy: 0.5299\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8330 - accuracy: 0.5296 - val_loss: 0.9758 - val_accuracy: 0.5470\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9743 - val_accuracy: 0.5470\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 99us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9732 - val_accuracy: 0.5299\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8325 - accuracy: 0.5519 - val_loss: 0.9765 - val_accuracy: 0.5299\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8334 - accuracy: 0.5296 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8337 - accuracy: 0.5333 - val_loss: 0.9758 - val_accuracy: 0.5299\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8301 - accuracy: 0.5519 - val_loss: 0.9784 - val_accuracy: 0.5470\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 0.9804 - val_accuracy: 0.5470\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9779 - val_accuracy: 0.5470\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8323 - accuracy: 0.5667 - val_loss: 0.9788 - val_accuracy: 0.5299\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8298 - accuracy: 0.5519 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8330 - accuracy: 0.5630 - val_loss: 0.9809 - val_accuracy: 0.5470\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8345 - accuracy: 0.5407 - val_loss: 0.9755 - val_accuracy: 0.5299\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9748 - val_accuracy: 0.5470\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9758 - val_accuracy: 0.5470\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 0.9774 - val_accuracy: 0.5470\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8334 - accuracy: 0.5444 - val_loss: 0.9787 - val_accuracy: 0.5299\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8309 - accuracy: 0.5333 - val_loss: 0.9796 - val_accuracy: 0.5470\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9798 - val_accuracy: 0.5470\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8309 - accuracy: 0.5630 - val_loss: 0.9807 - val_accuracy: 0.5470\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8342 - accuracy: 0.5370 - val_loss: 0.9795 - val_accuracy: 0.5470\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8364 - accuracy: 0.5630 - val_loss: 0.9805 - val_accuracy: 0.5470\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9820 - val_accuracy: 0.5214\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8332 - accuracy: 0.5519 - val_loss: 0.9821 - val_accuracy: 0.5214\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8311 - accuracy: 0.5370 - val_loss: 0.9811 - val_accuracy: 0.5385\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8314 - accuracy: 0.5333 - val_loss: 0.9790 - val_accuracy: 0.5385\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8339 - accuracy: 0.5593 - val_loss: 0.9871 - val_accuracy: 0.5470\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 0.9821 - val_accuracy: 0.5299\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8362 - accuracy: 0.5519 - val_loss: 0.9824 - val_accuracy: 0.5299\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8313 - accuracy: 0.5704 - val_loss: 0.9784 - val_accuracy: 0.5385\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9780 - val_accuracy: 0.5385\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9801 - val_accuracy: 0.5385\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8334 - accuracy: 0.5296 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8308 - accuracy: 0.5370 - val_loss: 0.9774 - val_accuracy: 0.5299\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8364 - accuracy: 0.5519 - val_loss: 0.9759 - val_accuracy: 0.5470\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8342 - accuracy: 0.5444 - val_loss: 0.9794 - val_accuracy: 0.5299\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8298 - accuracy: 0.5593 - val_loss: 0.9808 - val_accuracy: 0.5470\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8322 - accuracy: 0.5630 - val_loss: 0.9835 - val_accuracy: 0.5470\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 0.9875 - val_accuracy: 0.5470\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8321 - accuracy: 0.5556 - val_loss: 0.9857 - val_accuracy: 0.5214\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8307 - accuracy: 0.5519 - val_loss: 0.9816 - val_accuracy: 0.5299\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8305 - accuracy: 0.5407 - val_loss: 0.9809 - val_accuracy: 0.5470\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8333 - accuracy: 0.5630 - val_loss: 0.9804 - val_accuracy: 0.5470\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 0.9802 - val_accuracy: 0.5470\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8304 - accuracy: 0.5556 - val_loss: 0.9789 - val_accuracy: 0.5299\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8318 - accuracy: 0.5407 - val_loss: 0.9807 - val_accuracy: 0.5470\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8310 - accuracy: 0.5519 - val_loss: 0.9805 - val_accuracy: 0.5470\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 0.9893 - val_accuracy: 0.5470\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8345 - accuracy: 0.5407 - val_loss: 0.9816 - val_accuracy: 0.5214\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8304 - accuracy: 0.5519 - val_loss: 0.9783 - val_accuracy: 0.5470\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9778 - val_accuracy: 0.5470\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 0.9737 - val_accuracy: 0.5470\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8318 - accuracy: 0.5259 - val_loss: 0.9749 - val_accuracy: 0.5299\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8344 - accuracy: 0.5704 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8323 - accuracy: 0.5667 - val_loss: 0.9735 - val_accuracy: 0.5299\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8330 - accuracy: 0.5444 - val_loss: 0.9773 - val_accuracy: 0.5214\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8315 - accuracy: 0.5481 - val_loss: 0.9833 - val_accuracy: 0.5385\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8328 - accuracy: 0.5593 - val_loss: 0.9808 - val_accuracy: 0.5470\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8380 - accuracy: 0.5222 - val_loss: 0.9843 - val_accuracy: 0.5299\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8316 - accuracy: 0.5593 - val_loss: 0.9887 - val_accuracy: 0.5470\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 0.9817 - val_accuracy: 0.5385\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8295 - accuracy: 0.5519 - val_loss: 0.9801 - val_accuracy: 0.5299\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8349 - accuracy: 0.5481 - val_loss: 0.9820 - val_accuracy: 0.5470\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8299 - accuracy: 0.5593 - val_loss: 0.9821 - val_accuracy: 0.5299\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8332 - accuracy: 0.5481 - val_loss: 0.9810 - val_accuracy: 0.5470\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8342 - accuracy: 0.5593 - val_loss: 0.9789 - val_accuracy: 0.5299\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8318 - accuracy: 0.5259 - val_loss: 0.9808 - val_accuracy: 0.5470\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9829 - val_accuracy: 0.5470\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8317 - accuracy: 0.5444 - val_loss: 0.9823 - val_accuracy: 0.5214\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8333 - accuracy: 0.5370 - val_loss: 0.9822 - val_accuracy: 0.5470\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8299 - accuracy: 0.5407 - val_loss: 0.9782 - val_accuracy: 0.5299\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8296 - accuracy: 0.5444 - val_loss: 0.9811 - val_accuracy: 0.5470\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8360 - accuracy: 0.5630 - val_loss: 0.9841 - val_accuracy: 0.5470\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8301 - accuracy: 0.5556 - val_loss: 0.9771 - val_accuracy: 0.5214\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8341 - accuracy: 0.5296 - val_loss: 0.9792 - val_accuracy: 0.5470\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8352 - accuracy: 0.5407 - val_loss: 0.9778 - val_accuracy: 0.5470\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8284 - accuracy: 0.5593 - val_loss: 0.9803 - val_accuracy: 0.5385\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9811 - val_accuracy: 0.5385\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8294 - accuracy: 0.5593 - val_loss: 0.9796 - val_accuracy: 0.5299\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8305 - accuracy: 0.5407 - val_loss: 0.9779 - val_accuracy: 0.5299\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8302 - accuracy: 0.5519 - val_loss: 0.9753 - val_accuracy: 0.5385\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8302 - accuracy: 0.5370 - val_loss: 0.9757 - val_accuracy: 0.5214\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8320 - accuracy: 0.5519 - val_loss: 0.9806 - val_accuracy: 0.5385\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8296 - accuracy: 0.5593 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9738 - val_accuracy: 0.5470\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 0.9757 - val_accuracy: 0.5470\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8289 - accuracy: 0.5593 - val_loss: 0.9810 - val_accuracy: 0.5385\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8329 - accuracy: 0.5481 - val_loss: 0.9911 - val_accuracy: 0.5299\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8336 - accuracy: 0.5185 - val_loss: 0.9849 - val_accuracy: 0.5470\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8305 - accuracy: 0.5519 - val_loss: 0.9744 - val_accuracy: 0.5299\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8327 - accuracy: 0.5333 - val_loss: 0.9753 - val_accuracy: 0.5385\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8296 - accuracy: 0.5593 - val_loss: 0.9724 - val_accuracy: 0.5385\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9764 - val_accuracy: 0.5470\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9768 - val_accuracy: 0.5470\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 0.9756 - val_accuracy: 0.5385\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9724 - val_accuracy: 0.5385\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9733 - val_accuracy: 0.5385\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8316 - accuracy: 0.5444 - val_loss: 0.9752 - val_accuracy: 0.5214\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8364 - accuracy: 0.5185 - val_loss: 0.9776 - val_accuracy: 0.5470\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 0.9835 - val_accuracy: 0.5470\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8296 - accuracy: 0.5444 - val_loss: 0.9815 - val_accuracy: 0.5299\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8301 - accuracy: 0.5444 - val_loss: 0.9787 - val_accuracy: 0.5470\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9780 - val_accuracy: 0.5470\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8311 - accuracy: 0.5444 - val_loss: 0.9787 - val_accuracy: 0.5299\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8314 - accuracy: 0.5296 - val_loss: 0.9783 - val_accuracy: 0.5470\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8293 - accuracy: 0.5593 - val_loss: 0.9788 - val_accuracy: 0.5470\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8317 - accuracy: 0.5593 - val_loss: 0.9758 - val_accuracy: 0.5556\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8326 - accuracy: 0.5370 - val_loss: 0.9748 - val_accuracy: 0.5299\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 112us/step - loss: 0.8317 - accuracy: 0.5593 - val_loss: 0.9746 - val_accuracy: 0.5470\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9741 - val_accuracy: 0.5470\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9752 - val_accuracy: 0.5385\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8307 - accuracy: 0.5259 - val_loss: 0.9732 - val_accuracy: 0.5470\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9749 - val_accuracy: 0.5470\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 0.9770 - val_accuracy: 0.5470\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8308 - accuracy: 0.5519 - val_loss: 0.9779 - val_accuracy: 0.5299\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8317 - accuracy: 0.5556 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 0.9760 - val_accuracy: 0.5299\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8292 - accuracy: 0.5556 - val_loss: 0.9754 - val_accuracy: 0.5470\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8313 - accuracy: 0.5481 - val_loss: 0.9756 - val_accuracy: 0.5470\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8290 - accuracy: 0.5333 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8304 - accuracy: 0.5593 - val_loss: 0.9814 - val_accuracy: 0.5385\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8298 - accuracy: 0.5481 - val_loss: 0.9825 - val_accuracy: 0.5214\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8336 - accuracy: 0.5519 - val_loss: 0.9863 - val_accuracy: 0.5385\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9773 - val_accuracy: 0.5470\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 0.9765 - val_accuracy: 0.5470\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9781 - val_accuracy: 0.5214\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8308 - accuracy: 0.5519 - val_loss: 0.9857 - val_accuracy: 0.5214\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8323 - accuracy: 0.5481 - val_loss: 0.9844 - val_accuracy: 0.5385\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 0.9807 - val_accuracy: 0.5385\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8328 - accuracy: 0.5519 - val_loss: 0.9829 - val_accuracy: 0.5214\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8309 - accuracy: 0.5259 - val_loss: 0.9868 - val_accuracy: 0.5385\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8348 - accuracy: 0.5259 - val_loss: 0.9858 - val_accuracy: 0.5214\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8352 - accuracy: 0.5704 - val_loss: 0.9864 - val_accuracy: 0.5470\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 0.9802 - val_accuracy: 0.5470\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8290 - accuracy: 0.5481 - val_loss: 0.9801 - val_accuracy: 0.5214\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8310 - accuracy: 0.5519 - val_loss: 0.9800 - val_accuracy: 0.5385\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8508 - accuracy: 0.5593 - val_loss: 0.9813 - val_accuracy: 0.5385\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8329 - accuracy: 0.5519 - val_loss: 0.9805 - val_accuracy: 0.5299\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8333 - accuracy: 0.5481 - val_loss: 0.9792 - val_accuracy: 0.5385\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9782 - val_accuracy: 0.5385\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8296 - accuracy: 0.5370 - val_loss: 0.9783 - val_accuracy: 0.5214\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8313 - accuracy: 0.5667 - val_loss: 0.9841 - val_accuracy: 0.5385\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9851 - val_accuracy: 0.5385\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9816 - val_accuracy: 0.5385\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8285 - accuracy: 0.5704 - val_loss: 0.9791 - val_accuracy: 0.5299\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8296 - accuracy: 0.5444 - val_loss: 0.9792 - val_accuracy: 0.5470\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8298 - accuracy: 0.5593 - val_loss: 0.9784 - val_accuracy: 0.5470\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8284 - accuracy: 0.5593 - val_loss: 0.9766 - val_accuracy: 0.5385\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8383 - accuracy: 0.5296 - val_loss: 0.9768 - val_accuracy: 0.5299\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8292 - accuracy: 0.5741 - val_loss: 0.9820 - val_accuracy: 0.5385\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.8315 - accuracy: 0.5556 - val_loss: 0.9764 - val_accuracy: 0.5470\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 339us/step - loss: 0.8385 - accuracy: 0.5111 - val_loss: 0.9772 - val_accuracy: 0.5214\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8289 - accuracy: 0.5778 - val_loss: 0.9804 - val_accuracy: 0.5470\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9780 - val_accuracy: 0.5385\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8314 - accuracy: 0.5407 - val_loss: 0.9769 - val_accuracy: 0.5214\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8323 - accuracy: 0.5444 - val_loss: 0.9790 - val_accuracy: 0.5385\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 0.9812 - val_accuracy: 0.5385\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8344 - accuracy: 0.5333 - val_loss: 0.9770 - val_accuracy: 0.5470\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8301 - accuracy: 0.5259 - val_loss: 0.9753 - val_accuracy: 0.5470\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 0.9793 - val_accuracy: 0.5470\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8296 - accuracy: 0.5519 - val_loss: 0.9748 - val_accuracy: 0.5214\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8303 - accuracy: 0.5481 - val_loss: 0.9743 - val_accuracy: 0.5299\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8285 - accuracy: 0.5667 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 0.9785 - val_accuracy: 0.5470\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 365us/step - loss: 0.8300 - accuracy: 0.5593 - val_loss: 0.9729 - val_accuracy: 0.5470\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.8291 - accuracy: 0.5593 - val_loss: 0.9747 - val_accuracy: 0.5385\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8306 - accuracy: 0.5407 - val_loss: 0.9724 - val_accuracy: 0.5470\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 0.9746 - val_accuracy: 0.5470\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8368 - accuracy: 0.5370 - val_loss: 0.9857 - val_accuracy: 0.5214\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8304 - accuracy: 0.5333 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9809 - val_accuracy: 0.5470\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8322 - accuracy: 0.5259 - val_loss: 0.9777 - val_accuracy: 0.5385\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8299 - accuracy: 0.5444 - val_loss: 0.9767 - val_accuracy: 0.5470\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 0.9785 - val_accuracy: 0.5470\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8367 - accuracy: 0.5630 - val_loss: 0.9872 - val_accuracy: 0.5385\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9790 - val_accuracy: 0.5470\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8334 - accuracy: 0.5333 - val_loss: 0.9815 - val_accuracy: 0.5299\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8290 - accuracy: 0.5593 - val_loss: 0.9842 - val_accuracy: 0.5470\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8319 - accuracy: 0.5296 - val_loss: 0.9842 - val_accuracy: 0.5385\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8332 - accuracy: 0.5593 - val_loss: 0.9813 - val_accuracy: 0.5470\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9792 - val_accuracy: 0.5470\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8332 - accuracy: 0.5593 - val_loss: 0.9793 - val_accuracy: 0.5299\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8287 - accuracy: 0.5519 - val_loss: 0.9792 - val_accuracy: 0.5470\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8328 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8322 - accuracy: 0.5370 - val_loss: 0.9793 - val_accuracy: 0.5214\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8318 - accuracy: 0.5556 - val_loss: 0.9796 - val_accuracy: 0.5299\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8289 - accuracy: 0.5259 - val_loss: 0.9813 - val_accuracy: 0.5470\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8323 - accuracy: 0.5222 - val_loss: 0.9825 - val_accuracy: 0.5299\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8332 - accuracy: 0.5444 - val_loss: 0.9888 - val_accuracy: 0.5470\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8310 - accuracy: 0.5593 - val_loss: 0.9818 - val_accuracy: 0.5385\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8296 - accuracy: 0.5593 - val_loss: 0.9783 - val_accuracy: 0.5214\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8291 - accuracy: 0.5556 - val_loss: 0.9752 - val_accuracy: 0.5385\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8300 - accuracy: 0.5593 - val_loss: 0.9753 - val_accuracy: 0.5470\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 0.9783 - val_accuracy: 0.5385\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8290 - accuracy: 0.5556 - val_loss: 0.9793 - val_accuracy: 0.5214\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8313 - accuracy: 0.5519 - val_loss: 0.9778 - val_accuracy: 0.5214\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8313 - accuracy: 0.5593 - val_loss: 0.9820 - val_accuracy: 0.5385\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 0.9795 - val_accuracy: 0.5470\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8323 - accuracy: 0.5370 - val_loss: 0.9822 - val_accuracy: 0.5299\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8286 - accuracy: 0.5704 - val_loss: 0.9888 - val_accuracy: 0.5385\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8303 - accuracy: 0.5593 - val_loss: 0.9825 - val_accuracy: 0.5214\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8288 - accuracy: 0.5444 - val_loss: 0.9800 - val_accuracy: 0.5385\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8307 - accuracy: 0.5333 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8302 - accuracy: 0.5519 - val_loss: 0.9772 - val_accuracy: 0.5214\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8351 - accuracy: 0.5593 - val_loss: 0.9818 - val_accuracy: 0.5385\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 0.9788 - val_accuracy: 0.5214\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8319 - accuracy: 0.5370 - val_loss: 0.9844 - val_accuracy: 0.5214\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8309 - accuracy: 0.5519 - val_loss: 0.9760 - val_accuracy: 0.5214\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8317 - accuracy: 0.5370 - val_loss: 0.9747 - val_accuracy: 0.5470\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8304 - accuracy: 0.5630 - val_loss: 0.9741 - val_accuracy: 0.5470\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8298 - accuracy: 0.5593 - val_loss: 0.9773 - val_accuracy: 0.5385\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9811 - val_accuracy: 0.5470\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8320 - accuracy: 0.5630 - val_loss: 0.9803 - val_accuracy: 0.5385\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 324us/step - loss: 0.8333 - accuracy: 0.5481 - val_loss: 0.9794 - val_accuracy: 0.5299\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8357 - accuracy: 0.5407 - val_loss: 0.9850 - val_accuracy: 0.5470\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8291 - accuracy: 0.5667 - val_loss: 0.9833 - val_accuracy: 0.5214\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8291 - accuracy: 0.5519 - val_loss: 0.9839 - val_accuracy: 0.5214\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 103us/step - loss: 0.8303 - accuracy: 0.5444 - val_loss: 0.9801 - val_accuracy: 0.5385\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 0.9810 - val_accuracy: 0.5385\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5385\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9800 - val_accuracy: 0.5470\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8282 - accuracy: 0.5519 - val_loss: 0.9799 - val_accuracy: 0.5470\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5470\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8283 - accuracy: 0.5556 - val_loss: 0.9828 - val_accuracy: 0.5299\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8296 - accuracy: 0.5259 - val_loss: 0.9790 - val_accuracy: 0.5470\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8293 - accuracy: 0.5556 - val_loss: 0.9783 - val_accuracy: 0.5556\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8321 - accuracy: 0.5593 - val_loss: 0.9801 - val_accuracy: 0.5470\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8279 - accuracy: 0.5519 - val_loss: 0.9804 - val_accuracy: 0.5299\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8318 - accuracy: 0.5519 - val_loss: 0.9799 - val_accuracy: 0.5299\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8322 - accuracy: 0.5556 - val_loss: 0.9814 - val_accuracy: 0.5470\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 0.9792 - val_accuracy: 0.5470\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8298 - accuracy: 0.5519 - val_loss: 0.9750 - val_accuracy: 0.5299\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8305 - accuracy: 0.5185 - val_loss: 0.9776 - val_accuracy: 0.5470\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8296 - accuracy: 0.5370 - val_loss: 0.9801 - val_accuracy: 0.5214\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8285 - accuracy: 0.5519 - val_loss: 0.9833 - val_accuracy: 0.5385\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8285 - accuracy: 0.5593 - val_loss: 0.9856 - val_accuracy: 0.5470\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9849 - val_accuracy: 0.5385\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8294 - accuracy: 0.5444 - val_loss: 0.9812 - val_accuracy: 0.5299\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8294 - accuracy: 0.5556 - val_loss: 0.9798 - val_accuracy: 0.5385\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9834 - val_accuracy: 0.5385\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.8345 - accuracy: 0.5296 - val_loss: 0.9767 - val_accuracy: 0.5214\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.8297 - accuracy: 0.5556 - val_loss: 0.9746 - val_accuracy: 0.5385\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9760 - val_accuracy: 0.5385\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8310 - accuracy: 0.5259 - val_loss: 0.9789 - val_accuracy: 0.5214\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8296 - accuracy: 0.5444 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8296 - accuracy: 0.5444 - val_loss: 0.9814 - val_accuracy: 0.5214\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8347 - accuracy: 0.5481 - val_loss: 0.9820 - val_accuracy: 0.5385\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 0.9862 - val_accuracy: 0.5214\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8352 - accuracy: 0.5519 - val_loss: 0.9842 - val_accuracy: 0.5214\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8302 - accuracy: 0.5667 - val_loss: 0.9843 - val_accuracy: 0.5470\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8296 - accuracy: 0.5556 - val_loss: 0.9836 - val_accuracy: 0.5299\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8292 - accuracy: 0.5444 - val_loss: 0.9836 - val_accuracy: 0.5385\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8305 - accuracy: 0.5370 - val_loss: 0.9840 - val_accuracy: 0.5385\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 0.9803 - val_accuracy: 0.5385\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 0.9785 - val_accuracy: 0.5385\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 0.9828 - val_accuracy: 0.5385\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9854 - val_accuracy: 0.5385\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 0.9830 - val_accuracy: 0.5385\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 282us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 0.9860 - val_accuracy: 0.5385\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9864 - val_accuracy: 0.5385\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8287 - accuracy: 0.5593 - val_loss: 0.9836 - val_accuracy: 0.5214\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8338 - accuracy: 0.5407 - val_loss: 0.9853 - val_accuracy: 0.5385\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8289 - accuracy: 0.5444 - val_loss: 0.9812 - val_accuracy: 0.5299\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8305 - accuracy: 0.5593 - val_loss: 0.9839 - val_accuracy: 0.5470\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9778 - val_accuracy: 0.5470\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8290 - accuracy: 0.5667 - val_loss: 0.9782 - val_accuracy: 0.5385\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 427us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 0.9808 - val_accuracy: 0.5214\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8298 - accuracy: 0.5333 - val_loss: 0.9778 - val_accuracy: 0.5214\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.8296 - accuracy: 0.5556 - val_loss: 0.9766 - val_accuracy: 0.5385\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9780 - val_accuracy: 0.5385\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8308 - accuracy: 0.5222 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8321 - accuracy: 0.5444 - val_loss: 0.9806 - val_accuracy: 0.5299\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8270 - accuracy: 0.5815 - val_loss: 0.9850 - val_accuracy: 0.5385\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8343 - accuracy: 0.5556 - val_loss: 0.9880 - val_accuracy: 0.5470\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8367 - accuracy: 0.5370 - val_loss: 0.9866 - val_accuracy: 0.5214\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8319 - accuracy: 0.5519 - val_loss: 0.9845 - val_accuracy: 0.5385\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9837 - val_accuracy: 0.5385\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8289 - accuracy: 0.5481 - val_loss: 0.9830 - val_accuracy: 0.5214\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8323 - accuracy: 0.5296 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8282 - accuracy: 0.5556 - val_loss: 0.9784 - val_accuracy: 0.5214\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8286 - accuracy: 0.5481 - val_loss: 0.9797 - val_accuracy: 0.5385\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8292 - accuracy: 0.5333 - val_loss: 0.9785 - val_accuracy: 0.5385\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8296 - accuracy: 0.5593 - val_loss: 0.9820 - val_accuracy: 0.5470\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8285 - accuracy: 0.5481 - val_loss: 0.9790 - val_accuracy: 0.5299\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8297 - accuracy: 0.5519 - val_loss: 0.9816 - val_accuracy: 0.5299\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8278 - accuracy: 0.5556 - val_loss: 0.9826 - val_accuracy: 0.5470\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9905 - val_accuracy: 0.5470\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 0.9863 - val_accuracy: 0.5470\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8303 - accuracy: 0.5222 - val_loss: 0.9802 - val_accuracy: 0.5556\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9804 - val_accuracy: 0.5470\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8298 - accuracy: 0.5593 - val_loss: 0.9819 - val_accuracy: 0.5470\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9857 - val_accuracy: 0.5470\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 0.9846 - val_accuracy: 0.5470\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8274 - accuracy: 0.5704 - val_loss: 0.9813 - val_accuracy: 0.5299\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8316 - accuracy: 0.5481 - val_loss: 0.9840 - val_accuracy: 0.5214\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8353 - accuracy: 0.5222 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8282 - accuracy: 0.5630 - val_loss: 0.9810 - val_accuracy: 0.5385\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8286 - accuracy: 0.5370 - val_loss: 0.9821 - val_accuracy: 0.5214\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8285 - accuracy: 0.5370 - val_loss: 0.9800 - val_accuracy: 0.5470\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8282 - accuracy: 0.5630 - val_loss: 0.9790 - val_accuracy: 0.5470\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 0.9818 - val_accuracy: 0.5470\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8269 - accuracy: 0.5741 - val_loss: 0.9819 - val_accuracy: 0.5214\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8286 - accuracy: 0.5519 - val_loss: 0.9840 - val_accuracy: 0.5385\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8339 - accuracy: 0.5593 - val_loss: 0.9873 - val_accuracy: 0.5470\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8263 - accuracy: 0.5667 - val_loss: 0.9806 - val_accuracy: 0.5214\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8310 - accuracy: 0.5481 - val_loss: 0.9803 - val_accuracy: 0.5214\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8274 - accuracy: 0.5519 - val_loss: 0.9774 - val_accuracy: 0.5385\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8355 - accuracy: 0.5593 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8508 - accuracy: 0.5630 - val_loss: 0.9831 - val_accuracy: 0.5299\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 0.9928 - val_accuracy: 0.5299\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8309 - accuracy: 0.5481 - val_loss: 0.9879 - val_accuracy: 0.5385\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9929 - val_accuracy: 0.5385\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8296 - accuracy: 0.5593 - val_loss: 0.9934 - val_accuracy: 0.5214\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8319 - accuracy: 0.5519 - val_loss: 0.9893 - val_accuracy: 0.5214\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8287 - accuracy: 0.5667 - val_loss: 0.9905 - val_accuracy: 0.5385\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9916 - val_accuracy: 0.5385\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8299 - accuracy: 0.5556 - val_loss: 0.9888 - val_accuracy: 0.5470\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8317 - accuracy: 0.5296 - val_loss: 0.9856 - val_accuracy: 0.5299\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8307 - accuracy: 0.5407 - val_loss: 0.9831 - val_accuracy: 0.5385\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9784 - val_accuracy: 0.5385\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9807 - val_accuracy: 0.5385\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8291 - accuracy: 0.5519 - val_loss: 0.9826 - val_accuracy: 0.5214\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8347 - accuracy: 0.5481 - val_loss: 0.9860 - val_accuracy: 0.5385\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 0.9783 - val_accuracy: 0.5470\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8317 - accuracy: 0.5444 - val_loss: 0.9814 - val_accuracy: 0.5299\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 104us/step - loss: 0.8326 - accuracy: 0.5444 - val_loss: 0.9838 - val_accuracy: 0.5470\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8294 - accuracy: 0.5519 - val_loss: 0.9831 - val_accuracy: 0.5470\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 0.9829 - val_accuracy: 0.5470\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8320 - accuracy: 0.5444 - val_loss: 0.9799 - val_accuracy: 0.5385\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8284 - accuracy: 0.5444 - val_loss: 0.9815 - val_accuracy: 0.5385\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8282 - accuracy: 0.5630 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 0.9781 - val_accuracy: 0.5470\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8292 - accuracy: 0.5704 - val_loss: 0.9818 - val_accuracy: 0.5385\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8301 - accuracy: 0.5481 - val_loss: 0.9833 - val_accuracy: 0.5385\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9867 - val_accuracy: 0.5385\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 0.9810 - val_accuracy: 0.5470\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8316 - accuracy: 0.5407 - val_loss: 0.9838 - val_accuracy: 0.5299\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8293 - accuracy: 0.5333 - val_loss: 0.9878 - val_accuracy: 0.5470\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9888 - val_accuracy: 0.5470\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8284 - accuracy: 0.5407 - val_loss: 0.9839 - val_accuracy: 0.5214\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.75 - 0s 109us/step - loss: 0.8317 - accuracy: 0.5519 - val_loss: 0.9858 - val_accuracy: 0.5214\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 0.9843 - val_accuracy: 0.5470\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8293 - accuracy: 0.5407 - val_loss: 0.9830 - val_accuracy: 0.5299\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8308 - accuracy: 0.5407 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8284 - accuracy: 0.5519 - val_loss: 0.9863 - val_accuracy: 0.5214\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8293 - accuracy: 0.5481 - val_loss: 0.9869 - val_accuracy: 0.5385\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8316 - accuracy: 0.5593 - val_loss: 0.9882 - val_accuracy: 0.5470\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8294 - accuracy: 0.5593 - val_loss: 0.9882 - val_accuracy: 0.5385\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8328 - accuracy: 0.5556 - val_loss: 0.9893 - val_accuracy: 0.5214\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8314 - accuracy: 0.5481 - val_loss: 0.9902 - val_accuracy: 0.5299\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8302 - accuracy: 0.5667 - val_loss: 0.9853 - val_accuracy: 0.5470\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9784 - val_accuracy: 0.5470\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 0.9791 - val_accuracy: 0.5470\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 0.9768 - val_accuracy: 0.5470\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8288 - accuracy: 0.5222 - val_loss: 0.9771 - val_accuracy: 0.5470\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 0.9822 - val_accuracy: 0.5470\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8306 - accuracy: 0.5593 - val_loss: 0.9821 - val_accuracy: 0.5556\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9868 - val_accuracy: 0.5470\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8289 - accuracy: 0.5556 - val_loss: 0.9864 - val_accuracy: 0.5470\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8308 - accuracy: 0.5630 - val_loss: 0.9889 - val_accuracy: 0.5470\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8288 - accuracy: 0.5444 - val_loss: 0.9860 - val_accuracy: 0.5299\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8300 - accuracy: 0.5481 - val_loss: 0.9874 - val_accuracy: 0.5299\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8299 - accuracy: 0.5556 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 0.9824 - val_accuracy: 0.5470\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 0.9836 - val_accuracy: 0.5470\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 0.9876 - val_accuracy: 0.5470\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9849 - val_accuracy: 0.5470\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 0.9837 - val_accuracy: 0.5470\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8290 - accuracy: 0.5667 - val_loss: 0.9886 - val_accuracy: 0.5385\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9871 - val_accuracy: 0.5470\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9882 - val_accuracy: 0.5470\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8289 - accuracy: 0.5444 - val_loss: 0.9877 - val_accuracy: 0.5299\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8287 - accuracy: 0.5333 - val_loss: 0.9881 - val_accuracy: 0.5299\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8297 - accuracy: 0.5593 - val_loss: 0.9878 - val_accuracy: 0.5470\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 0.9845 - val_accuracy: 0.5470\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8323 - accuracy: 0.5519 - val_loss: 0.9893 - val_accuracy: 0.5385\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 0.9850 - val_accuracy: 0.5470\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 0.9887 - val_accuracy: 0.5470\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8268 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5299\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8303 - accuracy: 0.5481 - val_loss: 0.9826 - val_accuracy: 0.5214\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8328 - accuracy: 0.5333 - val_loss: 0.9831 - val_accuracy: 0.5385\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9811 - val_accuracy: 0.5385\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8277 - accuracy: 0.5519 - val_loss: 0.9855 - val_accuracy: 0.5214\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8285 - accuracy: 0.5444 - val_loss: 0.9834 - val_accuracy: 0.5385\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9814 - val_accuracy: 0.5470\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8284 - accuracy: 0.5556 - val_loss: 0.9813 - val_accuracy: 0.5470\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8287 - accuracy: 0.5148 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 0.9870 - val_accuracy: 0.5470\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 0.9866 - val_accuracy: 0.5470\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8320 - accuracy: 0.5111 - val_loss: 0.9844 - val_accuracy: 0.5299\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8276 - accuracy: 0.5481 - val_loss: 0.9817 - val_accuracy: 0.5556\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 0.9797 - val_accuracy: 0.5556\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8287 - accuracy: 0.5370 - val_loss: 0.9812 - val_accuracy: 0.5556\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8299 - accuracy: 0.5444 - val_loss: 0.9839 - val_accuracy: 0.5556\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8279 - accuracy: 0.5630 - val_loss: 0.9821 - val_accuracy: 0.5556\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8291 - accuracy: 0.5593 - val_loss: 0.9846 - val_accuracy: 0.5470\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8293 - accuracy: 0.5333 - val_loss: 0.9842 - val_accuracy: 0.5470\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9863 - val_accuracy: 0.5470\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8313 - accuracy: 0.5519 - val_loss: 0.9841 - val_accuracy: 0.5470\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8289 - accuracy: 0.5222 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8276 - accuracy: 0.5630 - val_loss: 0.9881 - val_accuracy: 0.5470\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9855 - val_accuracy: 0.5470\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8390 - accuracy: 0.5296 - val_loss: 0.9804 - val_accuracy: 0.5385\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8354 - accuracy: 0.5333 - val_loss: 0.9865 - val_accuracy: 0.5470\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8272 - accuracy: 0.5630 - val_loss: 0.9850 - val_accuracy: 0.5470\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9856 - val_accuracy: 0.5470\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9838 - val_accuracy: 0.5470\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8274 - accuracy: 0.5630 - val_loss: 0.9854 - val_accuracy: 0.5299\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8291 - accuracy: 0.5444 - val_loss: 0.9887 - val_accuracy: 0.5470\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8284 - accuracy: 0.5556 - val_loss: 0.9893 - val_accuracy: 0.5470\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 0.9918 - val_accuracy: 0.5470\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9872 - val_accuracy: 0.5470\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9866 - val_accuracy: 0.5470\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 0.9884 - val_accuracy: 0.5470\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8273 - accuracy: 0.5630 - val_loss: 0.9857 - val_accuracy: 0.5470\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8320 - accuracy: 0.5259 - val_loss: 0.9850 - val_accuracy: 0.5470\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 0.9904 - val_accuracy: 0.5385\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 0.9869 - val_accuracy: 0.5385\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8302 - accuracy: 0.5407 - val_loss: 0.9864 - val_accuracy: 0.5299\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8285 - accuracy: 0.5407 - val_loss: 0.9842 - val_accuracy: 0.5470\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 0.9855 - val_accuracy: 0.5470\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 0.9835 - val_accuracy: 0.5470\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8311 - accuracy: 0.5481 - val_loss: 0.9890 - val_accuracy: 0.5214\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8285 - accuracy: 0.5333 - val_loss: 0.9900 - val_accuracy: 0.5470\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9896 - val_accuracy: 0.5470\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8275 - accuracy: 0.5519 - val_loss: 0.9885 - val_accuracy: 0.5299\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8310 - accuracy: 0.5519 - val_loss: 0.9845 - val_accuracy: 0.5299\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8285 - accuracy: 0.5704 - val_loss: 0.9900 - val_accuracy: 0.5470\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8319 - accuracy: 0.5593 - val_loss: 0.9886 - val_accuracy: 0.5385\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8335 - accuracy: 0.5111 - val_loss: 0.9849 - val_accuracy: 0.5299\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 391us/step - loss: 0.8297 - accuracy: 0.5407 - val_loss: 0.9878 - val_accuracy: 0.5470\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 532us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9831 - val_accuracy: 0.5470\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8299 - accuracy: 0.5481 - val_loss: 0.9811 - val_accuracy: 0.5214\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 93us/step - loss: 0.8287 - accuracy: 0.5444 - val_loss: 0.9813 - val_accuracy: 0.5385\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9821 - val_accuracy: 0.5470\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8281 - accuracy: 0.5593 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8293 - accuracy: 0.5593 - val_loss: 0.9845 - val_accuracy: 0.5470\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8288 - accuracy: 0.5481 - val_loss: 0.9852 - val_accuracy: 0.5299\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8301 - accuracy: 0.5481 - val_loss: 0.9820 - val_accuracy: 0.5470\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8276 - accuracy: 0.5630 - val_loss: 0.9876 - val_accuracy: 0.5385\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8299 - accuracy: 0.5519 - val_loss: 0.9834 - val_accuracy: 0.5299\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8291 - accuracy: 0.5667 - val_loss: 0.9844 - val_accuracy: 0.5470\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8295 - accuracy: 0.5593 - val_loss: 0.9859 - val_accuracy: 0.5385\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8266 - accuracy: 0.5630 - val_loss: 0.9868 - val_accuracy: 0.5385\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8280 - accuracy: 0.5630 - val_loss: 0.9826 - val_accuracy: 0.5385\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8270 - accuracy: 0.5630 - val_loss: 0.9833 - val_accuracy: 0.5385\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8270 - accuracy: 0.5630 - val_loss: 0.9842 - val_accuracy: 0.5385\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8297 - accuracy: 0.5185 - val_loss: 0.9865 - val_accuracy: 0.5385\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8319 - accuracy: 0.5630 - val_loss: 0.9889 - val_accuracy: 0.5470\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8415 - accuracy: 0.5630 - val_loss: 0.9880 - val_accuracy: 0.5299\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8301 - accuracy: 0.5296 - val_loss: 0.9813 - val_accuracy: 0.5385\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8299 - accuracy: 0.5481 - val_loss: 0.9792 - val_accuracy: 0.5214\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8280 - accuracy: 0.5519 - val_loss: 0.9819 - val_accuracy: 0.5385\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8276 - accuracy: 0.5630 - val_loss: 0.9847 - val_accuracy: 0.5385\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 0.9840 - val_accuracy: 0.5214\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8321 - accuracy: 0.5519 - val_loss: 0.9859 - val_accuracy: 0.5214\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8348 - accuracy: 0.5296 - val_loss: 0.9875 - val_accuracy: 0.5385\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8376 - accuracy: 0.5074 - val_loss: 0.9830 - val_accuracy: 0.5299\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8337 - accuracy: 0.5037 - val_loss: 0.9828 - val_accuracy: 0.5470\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8293 - accuracy: 0.5148 - val_loss: 0.9847 - val_accuracy: 0.5470\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 0.9849 - val_accuracy: 0.5470\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8281 - accuracy: 0.5370 - val_loss: 0.9852 - val_accuracy: 0.5299\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8289 - accuracy: 0.5407 - val_loss: 0.9849 - val_accuracy: 0.5470\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8311 - accuracy: 0.5370 - val_loss: 0.9833 - val_accuracy: 0.5299\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8280 - accuracy: 0.5630 - val_loss: 0.9860 - val_accuracy: 0.5470\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8277 - accuracy: 0.5630 - val_loss: 0.9901 - val_accuracy: 0.5470\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8286 - accuracy: 0.5444 - val_loss: 0.9873 - val_accuracy: 0.5470\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8274 - accuracy: 0.5407 - val_loss: 0.9870 - val_accuracy: 0.5470\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9891 - val_accuracy: 0.5470\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 0.9902 - val_accuracy: 0.5470\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8309 - accuracy: 0.5630 - val_loss: 0.9880 - val_accuracy: 0.5385\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8294 - accuracy: 0.5593 - val_loss: 0.9827 - val_accuracy: 0.5470\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8339 - accuracy: 0.5333 - val_loss: 0.9815 - val_accuracy: 0.5299\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8291 - accuracy: 0.5333 - val_loss: 0.9800 - val_accuracy: 0.5385\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 0.9829 - val_accuracy: 0.5470\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8277 - accuracy: 0.5593 - val_loss: 0.9818 - val_accuracy: 0.5556\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8320 - accuracy: 0.5630 - val_loss: 0.9820 - val_accuracy: 0.5470\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8288 - accuracy: 0.5481 - val_loss: 0.9797 - val_accuracy: 0.5385\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8296 - accuracy: 0.5481 - val_loss: 0.9826 - val_accuracy: 0.5385\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8300 - accuracy: 0.5593 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8318 - accuracy: 0.5407 - val_loss: 0.9818 - val_accuracy: 0.5299\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 0.9859 - val_accuracy: 0.5470\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8315 - accuracy: 0.5370 - val_loss: 0.9877 - val_accuracy: 0.5214\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8376 - accuracy: 0.5407 - val_loss: 0.9936 - val_accuracy: 0.5470\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8313 - accuracy: 0.5296 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8293 - accuracy: 0.5259 - val_loss: 0.9876 - val_accuracy: 0.5470\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8273 - accuracy: 0.5630 - val_loss: 0.9863 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9857 - val_accuracy: 0.5299\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8295 - accuracy: 0.5519 - val_loss: 0.9855 - val_accuracy: 0.5299\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8280 - accuracy: 0.5667 - val_loss: 0.9860 - val_accuracy: 0.5470\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 0.9840 - val_accuracy: 0.5470\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9876 - val_accuracy: 0.5470\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8269 - accuracy: 0.5630 - val_loss: 0.9856 - val_accuracy: 0.5299\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8282 - accuracy: 0.5519 - val_loss: 0.9862 - val_accuracy: 0.5470\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 0.9851 - val_accuracy: 0.5470\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8274 - accuracy: 0.5593 - val_loss: 0.9836 - val_accuracy: 0.5385\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8308 - accuracy: 0.5296 - val_loss: 0.9827 - val_accuracy: 0.5214\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9827 - val_accuracy: 0.5470\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8359 - accuracy: 0.5630 - val_loss: 0.9905 - val_accuracy: 0.5470\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8285 - accuracy: 0.5519 - val_loss: 0.9875 - val_accuracy: 0.5299\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8283 - accuracy: 0.5481 - val_loss: 0.9911 - val_accuracy: 0.5470\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9887 - val_accuracy: 0.5470\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8271 - accuracy: 0.5704 - val_loss: 0.9891 - val_accuracy: 0.5299\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8294 - accuracy: 0.5556 - val_loss: 0.9861 - val_accuracy: 0.5470\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 0.9827 - val_accuracy: 0.5556\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8295 - accuracy: 0.5593 - val_loss: 0.9868 - val_accuracy: 0.5470\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 0.9854 - val_accuracy: 0.5556\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8303 - accuracy: 0.5630 - val_loss: 0.9871 - val_accuracy: 0.5556\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8293 - accuracy: 0.5370 - val_loss: 0.9889 - val_accuracy: 0.5299\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8299 - accuracy: 0.5519 - val_loss: 0.9879 - val_accuracy: 0.5385\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8358 - accuracy: 0.5630 - val_loss: 0.9893 - val_accuracy: 0.5385\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8279 - accuracy: 0.5667 - val_loss: 0.9855 - val_accuracy: 0.5214\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8326 - accuracy: 0.5519 - val_loss: 0.9845 - val_accuracy: 0.5385\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9881 - val_accuracy: 0.5385\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 0.9845 - val_accuracy: 0.5385\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 0.9841 - val_accuracy: 0.5385\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8312 - accuracy: 0.5370 - val_loss: 0.9900 - val_accuracy: 0.5214\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8274 - accuracy: 0.5556 - val_loss: 0.9865 - val_accuracy: 0.5385\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 0.9857 - val_accuracy: 0.5470\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 0.9826 - val_accuracy: 0.5470\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8296 - accuracy: 0.5407 - val_loss: 0.9830 - val_accuracy: 0.5385\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8309 - accuracy: 0.5185 - val_loss: 0.9851 - val_accuracy: 0.5470\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 0.9825 - val_accuracy: 0.5385\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8281 - accuracy: 0.5593 - val_loss: 0.9849 - val_accuracy: 0.5470\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8299 - accuracy: 0.5593 - val_loss: 0.9866 - val_accuracy: 0.5385\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8285 - accuracy: 0.5593 - val_loss: 0.9857 - val_accuracy: 0.5470\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8270 - accuracy: 0.5630 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8268 - accuracy: 0.5630 - val_loss: 0.9795 - val_accuracy: 0.5556\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8277 - accuracy: 0.5519 - val_loss: 0.9804 - val_accuracy: 0.5299\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8285 - accuracy: 0.5556 - val_loss: 0.9848 - val_accuracy: 0.5470\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 0.9872 - val_accuracy: 0.5385\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 0.9882 - val_accuracy: 0.5385\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8291 - accuracy: 0.5407 - val_loss: 0.9896 - val_accuracy: 0.5385\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8268 - accuracy: 0.5630 - val_loss: 0.9882 - val_accuracy: 0.5470\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8304 - accuracy: 0.5556 - val_loss: 0.9867 - val_accuracy: 0.5299\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8287 - accuracy: 0.5370 - val_loss: 0.9866 - val_accuracy: 0.5385\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8346 - accuracy: 0.5593 - val_loss: 0.9889 - val_accuracy: 0.5470\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8282 - accuracy: 0.5444 - val_loss: 0.9856 - val_accuracy: 0.5299\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8297 - accuracy: 0.5407 - val_loss: 0.9848 - val_accuracy: 0.5470\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 0.9872 - val_accuracy: 0.5470\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9871 - val_accuracy: 0.5470\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8271 - accuracy: 0.5370 - val_loss: 0.9840 - val_accuracy: 0.5470\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8274 - accuracy: 0.5630 - val_loss: 0.9831 - val_accuracy: 0.5470\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8272 - accuracy: 0.5593 - val_loss: 0.9829 - val_accuracy: 0.5470\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8295 - accuracy: 0.5630 - val_loss: 0.9859 - val_accuracy: 0.5470\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 0.9905 - val_accuracy: 0.5470\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8327 - accuracy: 0.5185 - val_loss: 0.9879 - val_accuracy: 0.5299\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8278 - accuracy: 0.5481 - val_loss: 0.9868 - val_accuracy: 0.5470\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8277 - accuracy: 0.5630 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8307 - accuracy: 0.5259 - val_loss: 0.9842 - val_accuracy: 0.5299\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 0.9840 - val_accuracy: 0.5470\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 0.9878 - val_accuracy: 0.5385\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 0.9859 - val_accuracy: 0.5214\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8307 - accuracy: 0.5519 - val_loss: 0.9841 - val_accuracy: 0.5299\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8268 - accuracy: 0.5704 - val_loss: 0.9869 - val_accuracy: 0.5470\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 0.9852 - val_accuracy: 0.5470\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8290 - accuracy: 0.5407 - val_loss: 0.9830 - val_accuracy: 0.5299\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8298 - accuracy: 0.5593 - val_loss: 0.9823 - val_accuracy: 0.5470\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8309 - accuracy: 0.5333 - val_loss: 0.9800 - val_accuracy: 0.5385\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8289 - accuracy: 0.5407 - val_loss: 0.9817 - val_accuracy: 0.5470\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8289 - accuracy: 0.5519 - val_loss: 0.9821 - val_accuracy: 0.5299\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8285 - accuracy: 0.5593 - val_loss: 0.9808 - val_accuracy: 0.5470\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8273 - accuracy: 0.5593 - val_loss: 0.9806 - val_accuracy: 0.5214\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8279 - accuracy: 0.5370 - val_loss: 0.9822 - val_accuracy: 0.5470\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 0.9860 - val_accuracy: 0.5470\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8292 - accuracy: 0.5481 - val_loss: 0.9831 - val_accuracy: 0.5385\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8289 - accuracy: 0.5296 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8280 - accuracy: 0.5407 - val_loss: 0.9797 - val_accuracy: 0.5214\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8286 - accuracy: 0.5481 - val_loss: 0.9806 - val_accuracy: 0.5385\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 0.9832 - val_accuracy: 0.5385\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 0.9820 - val_accuracy: 0.5385\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8303 - accuracy: 0.5630 - val_loss: 0.9847 - val_accuracy: 0.5385\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 0.9828 - val_accuracy: 0.5385\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8282 - accuracy: 0.5407 - val_loss: 0.9838 - val_accuracy: 0.5385\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 0.9864 - val_accuracy: 0.5385\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8315 - accuracy: 0.5185 - val_loss: 0.9832 - val_accuracy: 0.5470\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8310 - accuracy: 0.5370 - val_loss: 0.9851 - val_accuracy: 0.5214\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8261 - accuracy: 0.5593 - val_loss: 0.9836 - val_accuracy: 0.5470\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8288 - accuracy: 0.5593 - val_loss: 0.9821 - val_accuracy: 0.5470\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9850 - val_accuracy: 0.5470\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8274 - accuracy: 0.5444 - val_loss: 0.9841 - val_accuracy: 0.5470\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8278 - accuracy: 0.5593 - val_loss: 0.9892 - val_accuracy: 0.5470\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 0.9834 - val_accuracy: 0.5470\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9837 - val_accuracy: 0.5470\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8294 - accuracy: 0.5148 - val_loss: 0.9838 - val_accuracy: 0.5470\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8283 - accuracy: 0.5556 - val_loss: 0.9854 - val_accuracy: 0.5299\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8270 - accuracy: 0.5667 - val_loss: 0.9866 - val_accuracy: 0.5470\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9843 - val_accuracy: 0.5470\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 0.9788 - val_accuracy: 0.5385\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8303 - accuracy: 0.5333 - val_loss: 0.9812 - val_accuracy: 0.5299\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8296 - accuracy: 0.5481 - val_loss: 0.9887 - val_accuracy: 0.5470\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 0.9867 - val_accuracy: 0.5470\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8279 - accuracy: 0.5370 - val_loss: 0.9833 - val_accuracy: 0.5470\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8292 - accuracy: 0.5259 - val_loss: 0.9870 - val_accuracy: 0.5470\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8331 - accuracy: 0.5185 - val_loss: 0.9864 - val_accuracy: 0.5299\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8262 - accuracy: 0.5778 - val_loss: 0.9896 - val_accuracy: 0.5470\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 0.9867 - val_accuracy: 0.5470\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 231us/step - loss: 0.8295 - accuracy: 0.5630 - val_loss: 0.9930 - val_accuracy: 0.5470\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 0.9830 - val_accuracy: 0.5470\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8279 - accuracy: 0.5444 - val_loss: 0.9838 - val_accuracy: 0.5556\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 0.9819 - val_accuracy: 0.5556\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8283 - accuracy: 0.5667 - val_loss: 0.9826 - val_accuracy: 0.5470\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8309 - accuracy: 0.5370 - val_loss: 0.9829 - val_accuracy: 0.5299\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8267 - accuracy: 0.5667 - val_loss: 0.9849 - val_accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 55.28%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [9.9477980e-01, 2.1576720e-03, 3.0625204e-03],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [3.2683715e-04, 1.2991672e-08, 9.9967310e-01],\n",
       "       [5.1640872e-02, 6.7280570e-04, 9.4768640e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.2761596e-02, 2.1610180e-01, 7.7113660e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.5892214e-03, 4.9088103e-01, 5.0752980e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.7754565e-03, 1.5023647e-07, 9.9822444e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [9.3084670e-01, 2.2198789e-02, 4.6954475e-02],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1640872e-02, 6.7280570e-04, 9.4768640e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.3677110e-01, 1.0307487e-01, 6.6015400e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [9.6168160e-01, 2.0798804e-02, 1.7519578e-02],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.0640832e-02, 3.0074632e-02, 9.5928460e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7775237e-01, 2.6900962e-01, 4.5323795e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.2761596e-02, 2.1610180e-01, 7.7113660e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [5.5092200e-04, 5.5000360e-03, 9.9394906e-01],\n",
       "       [1.2761596e-02, 2.1610180e-01, 7.7113660e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [3.4691475e-02, 1.2496646e-02, 9.5281184e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.3677110e-01, 1.0307487e-01, 6.6015400e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [7.3658820e-01, 1.9648278e-03, 2.6144698e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1640872e-02, 6.7280570e-04, 9.4768640e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.6796376e-01, 3.1456800e-01, 2.1746820e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [9.9477980e-01, 2.1576720e-03, 3.0625204e-03],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.5892214e-03, 4.9088103e-01, 5.0752980e-01],\n",
       "       [1.7754565e-03, 1.5023647e-07, 9.9822444e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [1.2761596e-02, 2.1610180e-01, 7.7113660e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [7.8333520e-05, 9.6158653e-01, 3.8335178e-02],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [5.1005230e-01, 2.5648522e-01, 2.3346250e-01],\n",
       "       [2.4236040e-04, 4.2877486e-04, 9.9932885e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [3.2683715e-04, 1.2991672e-08, 9.9967310e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.2761596e-02, 2.1610180e-01, 7.7113660e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [1.5892214e-03, 4.9088103e-01, 5.0752980e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [7.1653030e-01, 5.6085910e-02, 2.2738387e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01],\n",
       "       [5.5092200e-04, 5.5000360e-03, 9.9394906e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [4.4439682e-01, 3.7417945e-01, 1.8142363e-01],\n",
       "       [2.7227250e-01, 4.5384616e-01, 2.7388138e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7098400175323253"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7098400175323253"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0    BCH-SA-11     2\n",
       "1       NRS161     1\n",
       "2    BCH-SA-14     2\n",
       "3    BCH-SA-11     2\n",
       "4     CFBRSa49     1\n",
       "..         ...   ...\n",
       "112     NRS064     2\n",
       "113     NRS266     2\n",
       "114     NRS222     0\n",
       "115       GA27     2\n",
       "116      GA984     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 392us/step - loss: 1.4445 - accuracy: 0.3370 - val_loss: 1.3060 - val_accuracy: 0.3248\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.2325 - accuracy: 0.3111 - val_loss: 1.1691 - val_accuracy: 0.2821\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.1538 - accuracy: 0.3296 - val_loss: 1.1367 - val_accuracy: 0.3248\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.1366 - accuracy: 0.3074 - val_loss: 1.1217 - val_accuracy: 0.2906\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.1248 - accuracy: 0.2667 - val_loss: 1.1093 - val_accuracy: 0.2821\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.1139 - accuracy: 0.2778 - val_loss: 1.0952 - val_accuracy: 0.2906\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.1041 - accuracy: 0.3185 - val_loss: 1.0822 - val_accuracy: 0.3333\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0939 - accuracy: 0.3778 - val_loss: 1.0687 - val_accuracy: 0.3846\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0849 - accuracy: 0.4111 - val_loss: 1.0589 - val_accuracy: 0.4274\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0788 - accuracy: 0.4037 - val_loss: 1.0477 - val_accuracy: 0.4701\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 1.0705 - accuracy: 0.4185 - val_loss: 1.0373 - val_accuracy: 0.4701\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0660 - accuracy: 0.4259 - val_loss: 1.0299 - val_accuracy: 0.4701\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 1.0605 - accuracy: 0.4185 - val_loss: 1.0225 - val_accuracy: 0.4701\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.0562 - accuracy: 0.4185 - val_loss: 1.0161 - val_accuracy: 0.4701\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.0527 - accuracy: 0.4185 - val_loss: 1.0093 - val_accuracy: 0.4701\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0453 - accuracy: 0.4333 - val_loss: 1.0038 - val_accuracy: 0.4957\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0428 - accuracy: 0.4333 - val_loss: 0.9940 - val_accuracy: 0.4957\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0363 - accuracy: 0.4148 - val_loss: 0.9887 - val_accuracy: 0.4786\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 1.0355 - accuracy: 0.4259 - val_loss: 0.9852 - val_accuracy: 0.4786\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 1.0309 - accuracy: 0.4259 - val_loss: 0.9793 - val_accuracy: 0.4786\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 1.0283 - accuracy: 0.4037 - val_loss: 0.9769 - val_accuracy: 0.4872\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 1.0253 - accuracy: 0.4630 - val_loss: 0.9751 - val_accuracy: 0.4957\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 1.0254 - accuracy: 0.4704 - val_loss: 0.9718 - val_accuracy: 0.4957\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0207 - accuracy: 0.4852 - val_loss: 0.9644 - val_accuracy: 0.5726\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.0192 - accuracy: 0.4556 - val_loss: 0.9601 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0169 - accuracy: 0.4444 - val_loss: 0.9576 - val_accuracy: 0.4957\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0152 - accuracy: 0.4741 - val_loss: 0.9565 - val_accuracy: 0.5726\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0148 - accuracy: 0.4704 - val_loss: 0.9519 - val_accuracy: 0.5726\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0101 - accuracy: 0.4926 - val_loss: 0.9517 - val_accuracy: 0.4957\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 1.0099 - accuracy: 0.4667 - val_loss: 0.9506 - val_accuracy: 0.4957\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 1.0087 - accuracy: 0.4667 - val_loss: 0.9495 - val_accuracy: 0.4957\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 1.0065 - accuracy: 0.4889 - val_loss: 0.9471 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 1.0052 - accuracy: 0.4778 - val_loss: 0.9440 - val_accuracy: 0.5726\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0029 - accuracy: 0.4926 - val_loss: 0.9422 - val_accuracy: 0.5726\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 1.0042 - accuracy: 0.4630 - val_loss: 0.9429 - val_accuracy: 0.4957\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.0022 - accuracy: 0.4741 - val_loss: 0.9389 - val_accuracy: 0.5726\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9993 - accuracy: 0.4926 - val_loss: 0.9360 - val_accuracy: 0.5726\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9998 - accuracy: 0.4333 - val_loss: 0.9357 - val_accuracy: 0.5726\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9974 - accuracy: 0.4926 - val_loss: 0.9366 - val_accuracy: 0.5726\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.9974 - accuracy: 0.4926 - val_loss: 0.9361 - val_accuracy: 0.5726\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9972 - accuracy: 0.4926 - val_loss: 0.9319 - val_accuracy: 0.5726\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.9959 - accuracy: 0.4889 - val_loss: 0.9328 - val_accuracy: 0.5726\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9932 - accuracy: 0.4926 - val_loss: 0.9304 - val_accuracy: 0.5726\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9979 - accuracy: 0.4370 - val_loss: 0.9308 - val_accuracy: 0.5726\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9932 - accuracy: 0.4926 - val_loss: 0.9299 - val_accuracy: 0.5726\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.9929 - accuracy: 0.4815 - val_loss: 0.9310 - val_accuracy: 0.5726\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9914 - accuracy: 0.4926 - val_loss: 0.9284 - val_accuracy: 0.5726\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9926 - accuracy: 0.5037 - val_loss: 0.9278 - val_accuracy: 0.5726\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9946 - accuracy: 0.5000 - val_loss: 0.9314 - val_accuracy: 0.5726\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9907 - accuracy: 0.5037 - val_loss: 0.9268 - val_accuracy: 0.5726\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9888 - accuracy: 0.4704 - val_loss: 0.9260 - val_accuracy: 0.5897\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9880 - accuracy: 0.4889 - val_loss: 0.9260 - val_accuracy: 0.5726\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9859 - accuracy: 0.4926 - val_loss: 0.9293 - val_accuracy: 0.5726\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9910 - accuracy: 0.4704 - val_loss: 0.9306 - val_accuracy: 0.5726\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9853 - accuracy: 0.5037 - val_loss: 0.9243 - val_accuracy: 0.5726\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9875 - accuracy: 0.4926 - val_loss: 0.9226 - val_accuracy: 0.5897\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9855 - accuracy: 0.4889 - val_loss: 0.9217 - val_accuracy: 0.5726\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9831 - accuracy: 0.5000 - val_loss: 0.9222 - val_accuracy: 0.5726\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9822 - accuracy: 0.5000 - val_loss: 0.9244 - val_accuracy: 0.5726\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9828 - accuracy: 0.5000 - val_loss: 0.9227 - val_accuracy: 0.5726\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9818 - accuracy: 0.5037 - val_loss: 0.9230 - val_accuracy: 0.5726\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9803 - accuracy: 0.5074 - val_loss: 0.9210 - val_accuracy: 0.5726\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9818 - accuracy: 0.5074 - val_loss: 0.9219 - val_accuracy: 0.5726\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9806 - accuracy: 0.5074 - val_loss: 0.9233 - val_accuracy: 0.5726\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9783 - accuracy: 0.5074 - val_loss: 0.9217 - val_accuracy: 0.5726\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9782 - accuracy: 0.5037 - val_loss: 0.9199 - val_accuracy: 0.5726\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9777 - accuracy: 0.5111 - val_loss: 0.9197 - val_accuracy: 0.5726\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.9794 - accuracy: 0.5037 - val_loss: 0.9177 - val_accuracy: 0.5726\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.9743 - accuracy: 0.5111 - val_loss: 0.9187 - val_accuracy: 0.5726\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.9752 - accuracy: 0.5037 - val_loss: 0.9208 - val_accuracy: 0.5726\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9751 - accuracy: 0.5037 - val_loss: 0.9189 - val_accuracy: 0.5726\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.9755 - accuracy: 0.5111 - val_loss: 0.9178 - val_accuracy: 0.5726\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.9746 - accuracy: 0.5111 - val_loss: 0.9201 - val_accuracy: 0.5726\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.9744 - accuracy: 0.5037 - val_loss: 0.9193 - val_accuracy: 0.5726\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9715 - accuracy: 0.5111 - val_loss: 0.9175 - val_accuracy: 0.5726\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9726 - accuracy: 0.5111 - val_loss: 0.9168 - val_accuracy: 0.5726\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9739 - accuracy: 0.5074 - val_loss: 0.9162 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9721 - accuracy: 0.5148 - val_loss: 0.9146 - val_accuracy: 0.5726\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9701 - accuracy: 0.5148 - val_loss: 0.9143 - val_accuracy: 0.5726\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.9692 - accuracy: 0.5074 - val_loss: 0.9163 - val_accuracy: 0.5726\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.9682 - accuracy: 0.5074 - val_loss: 0.9137 - val_accuracy: 0.5726\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.9708 - accuracy: 0.5148 - val_loss: 0.9147 - val_accuracy: 0.5726\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9706 - accuracy: 0.5111 - val_loss: 0.9149 - val_accuracy: 0.5726\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9685 - accuracy: 0.5148 - val_loss: 0.9156 - val_accuracy: 0.5726\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9705 - accuracy: 0.4963 - val_loss: 0.9145 - val_accuracy: 0.5726\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9662 - accuracy: 0.5148 - val_loss: 0.9142 - val_accuracy: 0.5726\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9719 - accuracy: 0.5111 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9682 - accuracy: 0.5074 - val_loss: 0.9135 - val_accuracy: 0.5726\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9659 - accuracy: 0.5148 - val_loss: 0.9138 - val_accuracy: 0.5726\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9637 - accuracy: 0.5111 - val_loss: 0.9127 - val_accuracy: 0.5726\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9663 - accuracy: 0.4556 - val_loss: 0.9127 - val_accuracy: 0.5726\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9624 - accuracy: 0.5111 - val_loss: 0.9144 - val_accuracy: 0.5726\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9632 - accuracy: 0.5111 - val_loss: 0.9160 - val_accuracy: 0.5726\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9607 - accuracy: 0.5111 - val_loss: 0.9131 - val_accuracy: 0.5726\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9628 - accuracy: 0.5148 - val_loss: 0.9139 - val_accuracy: 0.5726\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9627 - accuracy: 0.5148 - val_loss: 0.9144 - val_accuracy: 0.5726\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9604 - accuracy: 0.5111 - val_loss: 0.9148 - val_accuracy: 0.5726\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9609 - accuracy: 0.5111 - val_loss: 0.9124 - val_accuracy: 0.5726\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9616 - accuracy: 0.5148 - val_loss: 0.9131 - val_accuracy: 0.5726\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9593 - accuracy: 0.5148 - val_loss: 0.9124 - val_accuracy: 0.5726\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9621 - accuracy: 0.5111 - val_loss: 0.9163 - val_accuracy: 0.5726\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9603 - accuracy: 0.5111 - val_loss: 0.9116 - val_accuracy: 0.5726\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9570 - accuracy: 0.5148 - val_loss: 0.9117 - val_accuracy: 0.5726\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9574 - accuracy: 0.5148 - val_loss: 0.9091 - val_accuracy: 0.5726\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9581 - accuracy: 0.5111 - val_loss: 0.9102 - val_accuracy: 0.5726\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9560 - accuracy: 0.5111 - val_loss: 0.9088 - val_accuracy: 0.5726\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.9565 - accuracy: 0.5185 - val_loss: 0.9091 - val_accuracy: 0.5726\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9589 - accuracy: 0.5148 - val_loss: 0.9123 - val_accuracy: 0.5726\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9559 - accuracy: 0.5111 - val_loss: 0.9097 - val_accuracy: 0.5726\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9583 - accuracy: 0.5111 - val_loss: 0.9093 - val_accuracy: 0.5726\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9560 - accuracy: 0.5111 - val_loss: 0.9121 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9546 - accuracy: 0.5111 - val_loss: 0.9095 - val_accuracy: 0.5726\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9536 - accuracy: 0.5111 - val_loss: 0.9083 - val_accuracy: 0.5726\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9556 - accuracy: 0.4889 - val_loss: 0.9104 - val_accuracy: 0.5726\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9593 - accuracy: 0.5111 - val_loss: 0.9150 - val_accuracy: 0.5726\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9537 - accuracy: 0.5111 - val_loss: 0.9076 - val_accuracy: 0.5726\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9531 - accuracy: 0.5148 - val_loss: 0.9078 - val_accuracy: 0.5726\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9508 - accuracy: 0.5111 - val_loss: 0.9080 - val_accuracy: 0.5726\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9504 - accuracy: 0.5148 - val_loss: 0.9088 - val_accuracy: 0.5726\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9521 - accuracy: 0.5185 - val_loss: 0.9087 - val_accuracy: 0.5726\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9512 - accuracy: 0.5148 - val_loss: 0.9095 - val_accuracy: 0.5726\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9503 - accuracy: 0.5111 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9484 - accuracy: 0.5111 - val_loss: 0.9084 - val_accuracy: 0.5726\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9494 - accuracy: 0.5148 - val_loss: 0.9092 - val_accuracy: 0.5726\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9508 - accuracy: 0.5111 - val_loss: 0.9094 - val_accuracy: 0.5726\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9493 - accuracy: 0.5185 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9484 - accuracy: 0.5148 - val_loss: 0.9086 - val_accuracy: 0.5726\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9482 - accuracy: 0.5111 - val_loss: 0.9087 - val_accuracy: 0.5726\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9473 - accuracy: 0.5111 - val_loss: 0.9077 - val_accuracy: 0.5726\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9479 - accuracy: 0.5111 - val_loss: 0.9053 - val_accuracy: 0.5726\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9543 - accuracy: 0.5185 - val_loss: 0.9068 - val_accuracy: 0.5726\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9508 - accuracy: 0.5111 - val_loss: 0.9108 - val_accuracy: 0.5726\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9478 - accuracy: 0.5111 - val_loss: 0.9077 - val_accuracy: 0.5726\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.9456 - accuracy: 0.5111 - val_loss: 0.9067 - val_accuracy: 0.5726\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9446 - accuracy: 0.5111 - val_loss: 0.9074 - val_accuracy: 0.5726\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9444 - accuracy: 0.5111 - val_loss: 0.9071 - val_accuracy: 0.5726\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9447 - accuracy: 0.5111 - val_loss: 0.9079 - val_accuracy: 0.5726\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9444 - accuracy: 0.5111 - val_loss: 0.9080 - val_accuracy: 0.5726\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9429 - accuracy: 0.5111 - val_loss: 0.9062 - val_accuracy: 0.5726\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9419 - accuracy: 0.5185 - val_loss: 0.9060 - val_accuracy: 0.5726\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9414 - accuracy: 0.5111 - val_loss: 0.9067 - val_accuracy: 0.5726\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9407 - accuracy: 0.5111 - val_loss: 0.9040 - val_accuracy: 0.5726\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9464 - accuracy: 0.4593 - val_loss: 0.9078 - val_accuracy: 0.5897\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9419 - accuracy: 0.4963 - val_loss: 0.9053 - val_accuracy: 0.5726\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9394 - accuracy: 0.5111 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9410 - accuracy: 0.5111 - val_loss: 0.9087 - val_accuracy: 0.5726\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9424 - accuracy: 0.5111 - val_loss: 0.9077 - val_accuracy: 0.5726\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9454 - accuracy: 0.5000 - val_loss: 0.9065 - val_accuracy: 0.5897\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9416 - accuracy: 0.5222 - val_loss: 0.9020 - val_accuracy: 0.5726\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9470 - accuracy: 0.5111 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9394 - accuracy: 0.5185 - val_loss: 0.9065 - val_accuracy: 0.5726\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9430 - accuracy: 0.5000 - val_loss: 0.9083 - val_accuracy: 0.5897\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9389 - accuracy: 0.5037 - val_loss: 0.9089 - val_accuracy: 0.5726\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9437 - accuracy: 0.5111 - val_loss: 0.9124 - val_accuracy: 0.5726\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9393 - accuracy: 0.5111 - val_loss: 0.9066 - val_accuracy: 0.5726\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9376 - accuracy: 0.5111 - val_loss: 0.9057 - val_accuracy: 0.5726\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9389 - accuracy: 0.5148 - val_loss: 0.9053 - val_accuracy: 0.5726\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9391 - accuracy: 0.5185 - val_loss: 0.9073 - val_accuracy: 0.5726\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9357 - accuracy: 0.5185 - val_loss: 0.9035 - val_accuracy: 0.5726\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9392 - accuracy: 0.5111 - val_loss: 0.9060 - val_accuracy: 0.5726\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9324 - accuracy: 0.5148 - val_loss: 0.9099 - val_accuracy: 0.5726\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9397 - accuracy: 0.5111 - val_loss: 0.9147 - val_accuracy: 0.5726\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9363 - accuracy: 0.5148 - val_loss: 0.9082 - val_accuracy: 0.5726\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9342 - accuracy: 0.5185 - val_loss: 0.9069 - val_accuracy: 0.5726\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9338 - accuracy: 0.5185 - val_loss: 0.9056 - val_accuracy: 0.5726\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9337 - accuracy: 0.5185 - val_loss: 0.9052 - val_accuracy: 0.5726\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9339 - accuracy: 0.5185 - val_loss: 0.9069 - val_accuracy: 0.5726\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9346 - accuracy: 0.4926 - val_loss: 0.9081 - val_accuracy: 0.5726\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9330 - accuracy: 0.5185 - val_loss: 0.9082 - val_accuracy: 0.5726\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.9325 - accuracy: 0.5148 - val_loss: 0.9078 - val_accuracy: 0.5726\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9322 - accuracy: 0.5185 - val_loss: 0.9090 - val_accuracy: 0.5726\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9305 - accuracy: 0.5111 - val_loss: 0.9088 - val_accuracy: 0.5726\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9338 - accuracy: 0.5148 - val_loss: 0.9076 - val_accuracy: 0.5726\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9327 - accuracy: 0.5185 - val_loss: 0.9054 - val_accuracy: 0.5726\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.9320 - accuracy: 0.5185 - val_loss: 0.9062 - val_accuracy: 0.5726\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9289 - accuracy: 0.5148 - val_loss: 0.9070 - val_accuracy: 0.5726\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9290 - accuracy: 0.5185 - val_loss: 0.9064 - val_accuracy: 0.5726\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9290 - accuracy: 0.5185 - val_loss: 0.9035 - val_accuracy: 0.5726\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9326 - accuracy: 0.5222 - val_loss: 0.9032 - val_accuracy: 0.5726\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9308 - accuracy: 0.5185 - val_loss: 0.9077 - val_accuracy: 0.5726\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9292 - accuracy: 0.5148 - val_loss: 0.9047 - val_accuracy: 0.5726\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9328 - accuracy: 0.4815 - val_loss: 0.9064 - val_accuracy: 0.5726\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9290 - accuracy: 0.5185 - val_loss: 0.9015 - val_accuracy: 0.5726\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9289 - accuracy: 0.5222 - val_loss: 0.9028 - val_accuracy: 0.5726\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9269 - accuracy: 0.5185 - val_loss: 0.9058 - val_accuracy: 0.5726\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9267 - accuracy: 0.5185 - val_loss: 0.9051 - val_accuracy: 0.5726\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9269 - accuracy: 0.5222 - val_loss: 0.9061 - val_accuracy: 0.5726\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9270 - accuracy: 0.5222 - val_loss: 0.9057 - val_accuracy: 0.5726\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9329 - accuracy: 0.5111 - val_loss: 0.9107 - val_accuracy: 0.5726\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9250 - accuracy: 0.5222 - val_loss: 0.9057 - val_accuracy: 0.5726\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9265 - accuracy: 0.5296 - val_loss: 0.9042 - val_accuracy: 0.5726\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9251 - accuracy: 0.5259 - val_loss: 0.9061 - val_accuracy: 0.5726\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9259 - accuracy: 0.5222 - val_loss: 0.9081 - val_accuracy: 0.5726\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9253 - accuracy: 0.5148 - val_loss: 0.9082 - val_accuracy: 0.5726\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9235 - accuracy: 0.5259 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9259 - accuracy: 0.4815 - val_loss: 0.9062 - val_accuracy: 0.5726\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9249 - accuracy: 0.5259 - val_loss: 0.9077 - val_accuracy: 0.5726\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9243 - accuracy: 0.5148 - val_loss: 0.9060 - val_accuracy: 0.5726\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9240 - accuracy: 0.5185 - val_loss: 0.9082 - val_accuracy: 0.5726\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9226 - accuracy: 0.5259 - val_loss: 0.9058 - val_accuracy: 0.5726\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9215 - accuracy: 0.5296 - val_loss: 0.9052 - val_accuracy: 0.5726\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.9225 - accuracy: 0.5296 - val_loss: 0.9054 - val_accuracy: 0.5726\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9214 - accuracy: 0.5296 - val_loss: 0.9055 - val_accuracy: 0.5726\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9227 - accuracy: 0.5148 - val_loss: 0.9074 - val_accuracy: 0.5726\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9207 - accuracy: 0.5296 - val_loss: 0.9055 - val_accuracy: 0.5726\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9224 - accuracy: 0.5296 - val_loss: 0.9065 - val_accuracy: 0.5726\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9226 - accuracy: 0.5296 - val_loss: 0.9052 - val_accuracy: 0.5726\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9203 - accuracy: 0.5296 - val_loss: 0.9050 - val_accuracy: 0.5726\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9207 - accuracy: 0.5148 - val_loss: 0.9074 - val_accuracy: 0.5726\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9215 - accuracy: 0.5185 - val_loss: 0.9086 - val_accuracy: 0.5726\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9199 - accuracy: 0.5185 - val_loss: 0.9058 - val_accuracy: 0.5726\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9224 - accuracy: 0.5037 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9203 - accuracy: 0.5296 - val_loss: 0.9062 - val_accuracy: 0.5726\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9224 - accuracy: 0.5259 - val_loss: 0.9090 - val_accuracy: 0.5726\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9197 - accuracy: 0.5222 - val_loss: 0.9071 - val_accuracy: 0.5726\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9184 - accuracy: 0.5296 - val_loss: 0.9064 - val_accuracy: 0.5726\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9180 - accuracy: 0.5296 - val_loss: 0.9078 - val_accuracy: 0.5726\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9191 - accuracy: 0.5222 - val_loss: 0.9123 - val_accuracy: 0.5726\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9219 - accuracy: 0.5111 - val_loss: 0.9064 - val_accuracy: 0.5726\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9180 - accuracy: 0.5296 - val_loss: 0.9066 - val_accuracy: 0.5726\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9188 - accuracy: 0.5259 - val_loss: 0.9090 - val_accuracy: 0.5726\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9175 - accuracy: 0.5259 - val_loss: 0.9065 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9153 - accuracy: 0.5296 - val_loss: 0.9068 - val_accuracy: 0.5726\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9160 - accuracy: 0.5296 - val_loss: 0.9065 - val_accuracy: 0.5726\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9154 - accuracy: 0.5296 - val_loss: 0.9086 - val_accuracy: 0.5726\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9165 - accuracy: 0.5296 - val_loss: 0.9080 - val_accuracy: 0.5726\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9201 - accuracy: 0.5296 - val_loss: 0.9078 - val_accuracy: 0.5726\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9156 - accuracy: 0.5296 - val_loss: 0.9069 - val_accuracy: 0.5726\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9185 - accuracy: 0.5296 - val_loss: 0.9105 - val_accuracy: 0.5726\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9177 - accuracy: 0.5222 - val_loss: 0.9098 - val_accuracy: 0.5726\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9170 - accuracy: 0.5259 - val_loss: 0.9054 - val_accuracy: 0.5812\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9167 - accuracy: 0.4963 - val_loss: 0.9075 - val_accuracy: 0.5641\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9153 - accuracy: 0.5296 - val_loss: 0.9094 - val_accuracy: 0.5726\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9143 - accuracy: 0.5296 - val_loss: 0.9067 - val_accuracy: 0.5726\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9196 - accuracy: 0.5074 - val_loss: 0.9087 - val_accuracy: 0.5726\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9152 - accuracy: 0.5296 - val_loss: 0.9112 - val_accuracy: 0.5726\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9179 - accuracy: 0.5296 - val_loss: 0.9091 - val_accuracy: 0.5726\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9150 - accuracy: 0.5296 - val_loss: 0.9074 - val_accuracy: 0.5726\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9128 - accuracy: 0.5296 - val_loss: 0.9065 - val_accuracy: 0.5726\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9129 - accuracy: 0.5296 - val_loss: 0.9076 - val_accuracy: 0.5726\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9115 - accuracy: 0.5296 - val_loss: 0.9104 - val_accuracy: 0.5726\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9144 - accuracy: 0.5259 - val_loss: 0.9092 - val_accuracy: 0.5726\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9116 - accuracy: 0.5296 - val_loss: 0.9090 - val_accuracy: 0.5726\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9110 - accuracy: 0.5296 - val_loss: 0.9083 - val_accuracy: 0.5726\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9112 - accuracy: 0.5296 - val_loss: 0.9080 - val_accuracy: 0.5641\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9120 - accuracy: 0.5296 - val_loss: 0.9108 - val_accuracy: 0.5641\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9121 - accuracy: 0.5259 - val_loss: 0.9121 - val_accuracy: 0.5726\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9106 - accuracy: 0.5296 - val_loss: 0.9097 - val_accuracy: 0.5726\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9154 - accuracy: 0.5296 - val_loss: 0.9102 - val_accuracy: 0.5726\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9105 - accuracy: 0.5296 - val_loss: 0.9093 - val_accuracy: 0.5726\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9102 - accuracy: 0.5296 - val_loss: 0.9117 - val_accuracy: 0.5726\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9147 - accuracy: 0.5296 - val_loss: 0.9129 - val_accuracy: 0.5726\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9093 - accuracy: 0.5296 - val_loss: 0.9120 - val_accuracy: 0.5726\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9128 - accuracy: 0.4926 - val_loss: 0.9078 - val_accuracy: 0.5812\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9101 - accuracy: 0.5185 - val_loss: 0.9081 - val_accuracy: 0.5641\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9102 - accuracy: 0.5296 - val_loss: 0.9092 - val_accuracy: 0.5726\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9125 - accuracy: 0.5296 - val_loss: 0.9087 - val_accuracy: 0.5726\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9122 - accuracy: 0.5296 - val_loss: 0.9098 - val_accuracy: 0.5726\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9107 - accuracy: 0.5296 - val_loss: 0.9119 - val_accuracy: 0.5726\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9085 - accuracy: 0.5296 - val_loss: 0.9121 - val_accuracy: 0.5726\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9069 - accuracy: 0.5296 - val_loss: 0.9121 - val_accuracy: 0.5726\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9086 - accuracy: 0.5296 - val_loss: 0.9086 - val_accuracy: 0.5726\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9078 - accuracy: 0.5296 - val_loss: 0.9092 - val_accuracy: 0.5726\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9089 - accuracy: 0.5296 - val_loss: 0.9149 - val_accuracy: 0.5726\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9111 - accuracy: 0.5296 - val_loss: 0.9133 - val_accuracy: 0.5726\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9072 - accuracy: 0.5296 - val_loss: 0.9129 - val_accuracy: 0.5726\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9075 - accuracy: 0.5296 - val_loss: 0.9100 - val_accuracy: 0.5726\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9043 - accuracy: 0.5296 - val_loss: 0.9111 - val_accuracy: 0.5726\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9091 - accuracy: 0.5296 - val_loss: 0.9100 - val_accuracy: 0.5726\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9087 - accuracy: 0.5296 - val_loss: 0.9075 - val_accuracy: 0.5726\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9049 - accuracy: 0.5296 - val_loss: 0.9118 - val_accuracy: 0.5726\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9066 - accuracy: 0.5296 - val_loss: 0.9136 - val_accuracy: 0.5726\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9081 - accuracy: 0.5296 - val_loss: 0.9138 - val_accuracy: 0.5726\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9036 - accuracy: 0.5296 - val_loss: 0.9103 - val_accuracy: 0.5726\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9074 - accuracy: 0.5259 - val_loss: 0.9108 - val_accuracy: 0.5726\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9037 - accuracy: 0.5259 - val_loss: 0.9119 - val_accuracy: 0.5726\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9088 - accuracy: 0.5296 - val_loss: 0.9114 - val_accuracy: 0.5641\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9038 - accuracy: 0.5296 - val_loss: 0.9088 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9047 - accuracy: 0.5296 - val_loss: 0.9118 - val_accuracy: 0.5641\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9034 - accuracy: 0.5259 - val_loss: 0.9154 - val_accuracy: 0.5726\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9040 - accuracy: 0.5296 - val_loss: 0.9130 - val_accuracy: 0.5726\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9063 - accuracy: 0.5296 - val_loss: 0.9141 - val_accuracy: 0.5641\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9088 - accuracy: 0.5296 - val_loss: 0.9132 - val_accuracy: 0.5641\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9057 - accuracy: 0.5296 - val_loss: 0.9173 - val_accuracy: 0.5726\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9054 - accuracy: 0.5296 - val_loss: 0.9114 - val_accuracy: 0.5641\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9022 - accuracy: 0.5296 - val_loss: 0.9152 - val_accuracy: 0.5641\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9034 - accuracy: 0.5259 - val_loss: 0.9150 - val_accuracy: 0.5641\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9014 - accuracy: 0.5296 - val_loss: 0.9128 - val_accuracy: 0.5641\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9033 - accuracy: 0.5259 - val_loss: 0.9100 - val_accuracy: 0.5641\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9008 - accuracy: 0.5296 - val_loss: 0.9122 - val_accuracy: 0.5726\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9004 - accuracy: 0.5296 - val_loss: 0.9116 - val_accuracy: 0.5726\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9017 - accuracy: 0.5296 - val_loss: 0.9106 - val_accuracy: 0.5726\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9060 - accuracy: 0.5259 - val_loss: 0.9095 - val_accuracy: 0.5641\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9041 - accuracy: 0.5185 - val_loss: 0.9104 - val_accuracy: 0.5726\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9033 - accuracy: 0.5333 - val_loss: 0.9102 - val_accuracy: 0.5726\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9015 - accuracy: 0.5333 - val_loss: 0.9133 - val_accuracy: 0.5726\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9006 - accuracy: 0.5333 - val_loss: 0.9131 - val_accuracy: 0.5726\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9024 - accuracy: 0.5296 - val_loss: 0.9154 - val_accuracy: 0.5726\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9018 - accuracy: 0.5296 - val_loss: 0.9108 - val_accuracy: 0.5726\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9028 - accuracy: 0.4926 - val_loss: 0.9117 - val_accuracy: 0.5897\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9009 - accuracy: 0.4852 - val_loss: 0.9080 - val_accuracy: 0.5726\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9084 - accuracy: 0.5333 - val_loss: 0.9161 - val_accuracy: 0.5726\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8989 - accuracy: 0.5333 - val_loss: 0.9134 - val_accuracy: 0.5897\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9048 - accuracy: 0.5037 - val_loss: 0.9175 - val_accuracy: 0.5726\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9050 - accuracy: 0.5370 - val_loss: 0.9153 - val_accuracy: 0.5726\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9012 - accuracy: 0.5333 - val_loss: 0.9132 - val_accuracy: 0.5726\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8983 - accuracy: 0.5296 - val_loss: 0.9130 - val_accuracy: 0.5726\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8991 - accuracy: 0.5296 - val_loss: 0.9109 - val_accuracy: 0.5726\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9017 - accuracy: 0.5222 - val_loss: 0.9116 - val_accuracy: 0.5726\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8959 - accuracy: 0.5370 - val_loss: 0.9103 - val_accuracy: 0.5726\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9013 - accuracy: 0.5407 - val_loss: 0.9134 - val_accuracy: 0.5726\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8973 - accuracy: 0.5370 - val_loss: 0.9124 - val_accuracy: 0.5726\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9010 - accuracy: 0.5000 - val_loss: 0.9154 - val_accuracy: 0.5897\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8988 - accuracy: 0.5333 - val_loss: 0.9161 - val_accuracy: 0.5726\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8987 - accuracy: 0.5370 - val_loss: 0.9151 - val_accuracy: 0.5726\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8963 - accuracy: 0.5370 - val_loss: 0.9158 - val_accuracy: 0.5726\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8971 - accuracy: 0.5370 - val_loss: 0.9118 - val_accuracy: 0.5726\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8979 - accuracy: 0.5407 - val_loss: 0.9107 - val_accuracy: 0.5726\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8949 - accuracy: 0.5370 - val_loss: 0.9123 - val_accuracy: 0.5726\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8972 - accuracy: 0.5370 - val_loss: 0.9153 - val_accuracy: 0.5726\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9009 - accuracy: 0.5407 - val_loss: 0.9142 - val_accuracy: 0.5726\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8969 - accuracy: 0.5444 - val_loss: 0.9165 - val_accuracy: 0.5726\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8977 - accuracy: 0.5370 - val_loss: 0.9228 - val_accuracy: 0.5726\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8996 - accuracy: 0.5296 - val_loss: 0.9211 - val_accuracy: 0.5726\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8948 - accuracy: 0.5333 - val_loss: 0.9128 - val_accuracy: 0.5726\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8958 - accuracy: 0.5407 - val_loss: 0.9124 - val_accuracy: 0.5641\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8962 - accuracy: 0.5444 - val_loss: 0.9096 - val_accuracy: 0.5726\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8946 - accuracy: 0.5370 - val_loss: 0.9153 - val_accuracy: 0.5726\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9018 - accuracy: 0.5333 - val_loss: 0.9123 - val_accuracy: 0.5641\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8964 - accuracy: 0.5370 - val_loss: 0.9135 - val_accuracy: 0.5641\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8953 - accuracy: 0.5259 - val_loss: 0.9189 - val_accuracy: 0.5726\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8967 - accuracy: 0.5333 - val_loss: 0.9162 - val_accuracy: 0.5726\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8937 - accuracy: 0.5370 - val_loss: 0.9115 - val_accuracy: 0.5726\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8973 - accuracy: 0.5444 - val_loss: 0.9116 - val_accuracy: 0.5726\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8951 - accuracy: 0.5185 - val_loss: 0.9168 - val_accuracy: 0.5897\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8987 - accuracy: 0.5519 - val_loss: 0.9150 - val_accuracy: 0.5726\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8937 - accuracy: 0.5407 - val_loss: 0.9159 - val_accuracy: 0.5726\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8931 - accuracy: 0.5407 - val_loss: 0.9135 - val_accuracy: 0.5726\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8950 - accuracy: 0.5370 - val_loss: 0.9173 - val_accuracy: 0.5726\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8936 - accuracy: 0.5370 - val_loss: 0.9164 - val_accuracy: 0.5726\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8945 - accuracy: 0.5370 - val_loss: 0.9178 - val_accuracy: 0.5726\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8912 - accuracy: 0.5370 - val_loss: 0.9155 - val_accuracy: 0.5726\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8955 - accuracy: 0.5407 - val_loss: 0.9180 - val_accuracy: 0.5641\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8973 - accuracy: 0.5074 - val_loss: 0.9165 - val_accuracy: 0.5897\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8941 - accuracy: 0.5444 - val_loss: 0.9151 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8944 - accuracy: 0.5407 - val_loss: 0.9193 - val_accuracy: 0.5726\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8906 - accuracy: 0.5444 - val_loss: 0.9195 - val_accuracy: 0.5726\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8930 - accuracy: 0.5370 - val_loss: 0.9194 - val_accuracy: 0.5726\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8919 - accuracy: 0.5370 - val_loss: 0.9230 - val_accuracy: 0.5641\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8924 - accuracy: 0.5444 - val_loss: 0.9195 - val_accuracy: 0.5641\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8948 - accuracy: 0.5407 - val_loss: 0.9201 - val_accuracy: 0.5641\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8907 - accuracy: 0.5370 - val_loss: 0.9165 - val_accuracy: 0.5641\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8931 - accuracy: 0.5407 - val_loss: 0.9175 - val_accuracy: 0.5726\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8911 - accuracy: 0.5407 - val_loss: 0.9164 - val_accuracy: 0.5726\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8921 - accuracy: 0.5407 - val_loss: 0.9202 - val_accuracy: 0.5726\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8962 - accuracy: 0.5370 - val_loss: 0.9259 - val_accuracy: 0.5726\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8937 - accuracy: 0.5333 - val_loss: 0.9182 - val_accuracy: 0.5641\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8912 - accuracy: 0.5444 - val_loss: 0.9164 - val_accuracy: 0.5726\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8950 - accuracy: 0.5370 - val_loss: 0.9242 - val_accuracy: 0.5726\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8898 - accuracy: 0.5407 - val_loss: 0.9171 - val_accuracy: 0.5726\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8896 - accuracy: 0.5444 - val_loss: 0.9160 - val_accuracy: 0.5726\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.8906 - accuracy: 0.5444 - val_loss: 0.9181 - val_accuracy: 0.5726\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8938 - accuracy: 0.5444 - val_loss: 0.9168 - val_accuracy: 0.5726\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8894 - accuracy: 0.5481 - val_loss: 0.9201 - val_accuracy: 0.5726\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8896 - accuracy: 0.5444 - val_loss: 0.9156 - val_accuracy: 0.5726\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8880 - accuracy: 0.5444 - val_loss: 0.9180 - val_accuracy: 0.5726\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8893 - accuracy: 0.5444 - val_loss: 0.9197 - val_accuracy: 0.5726\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8885 - accuracy: 0.5481 - val_loss: 0.9219 - val_accuracy: 0.5726\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8904 - accuracy: 0.5407 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8888 - accuracy: 0.5444 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8929 - accuracy: 0.5444 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8903 - accuracy: 0.5481 - val_loss: 0.9178 - val_accuracy: 0.5726\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8901 - accuracy: 0.5481 - val_loss: 0.9171 - val_accuracy: 0.5726\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8875 - accuracy: 0.5481 - val_loss: 0.9175 - val_accuracy: 0.5726\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8896 - accuracy: 0.5481 - val_loss: 0.9171 - val_accuracy: 0.5726\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8874 - accuracy: 0.5481 - val_loss: 0.9196 - val_accuracy: 0.5726\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8906 - accuracy: 0.5037 - val_loss: 0.9174 - val_accuracy: 0.5726\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8900 - accuracy: 0.5481 - val_loss: 0.9197 - val_accuracy: 0.5726\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8867 - accuracy: 0.5481 - val_loss: 0.9221 - val_accuracy: 0.5726\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8895 - accuracy: 0.5444 - val_loss: 0.9248 - val_accuracy: 0.5726\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8875 - accuracy: 0.5444 - val_loss: 0.9230 - val_accuracy: 0.5726\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8883 - accuracy: 0.5370 - val_loss: 0.9187 - val_accuracy: 0.5641\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8873 - accuracy: 0.5407 - val_loss: 0.9179 - val_accuracy: 0.5726\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8862 - accuracy: 0.5444 - val_loss: 0.9208 - val_accuracy: 0.5726\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8855 - accuracy: 0.5481 - val_loss: 0.9176 - val_accuracy: 0.5726\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8878 - accuracy: 0.5481 - val_loss: 0.9185 - val_accuracy: 0.5726\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8857 - accuracy: 0.5444 - val_loss: 0.9186 - val_accuracy: 0.5641\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8843 - accuracy: 0.5444 - val_loss: 0.9211 - val_accuracy: 0.5726\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 135us/step - loss: 0.8854 - accuracy: 0.5444 - val_loss: 0.9222 - val_accuracy: 0.5726\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8880 - accuracy: 0.5444 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8881 - accuracy: 0.5407 - val_loss: 0.9194 - val_accuracy: 0.5641\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8897 - accuracy: 0.5481 - val_loss: 0.9209 - val_accuracy: 0.5726\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8868 - accuracy: 0.5481 - val_loss: 0.9191 - val_accuracy: 0.5726\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8870 - accuracy: 0.5444 - val_loss: 0.9199 - val_accuracy: 0.5726\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8891 - accuracy: 0.5333 - val_loss: 0.9260 - val_accuracy: 0.5726\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8855 - accuracy: 0.5481 - val_loss: 0.9224 - val_accuracy: 0.5726\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8877 - accuracy: 0.5481 - val_loss: 0.9182 - val_accuracy: 0.5726\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8845 - accuracy: 0.5481 - val_loss: 0.9193 - val_accuracy: 0.5726\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8835 - accuracy: 0.5481 - val_loss: 0.9194 - val_accuracy: 0.5641\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8839 - accuracy: 0.5519 - val_loss: 0.9223 - val_accuracy: 0.5726\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8922 - accuracy: 0.5222 - val_loss: 0.9248 - val_accuracy: 0.5726\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8855 - accuracy: 0.5481 - val_loss: 0.9203 - val_accuracy: 0.5726\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8873 - accuracy: 0.5519 - val_loss: 0.9239 - val_accuracy: 0.5726\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8875 - accuracy: 0.5481 - val_loss: 0.9225 - val_accuracy: 0.5726\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8860 - accuracy: 0.5481 - val_loss: 0.9211 - val_accuracy: 0.5726\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8888 - accuracy: 0.5296 - val_loss: 0.9225 - val_accuracy: 0.5726\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8919 - accuracy: 0.5481 - val_loss: 0.9291 - val_accuracy: 0.5726\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8804 - accuracy: 0.5444 - val_loss: 0.9156 - val_accuracy: 0.5812\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8869 - accuracy: 0.5222 - val_loss: 0.9143 - val_accuracy: 0.5641\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8846 - accuracy: 0.5519 - val_loss: 0.9171 - val_accuracy: 0.5726\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8844 - accuracy: 0.5481 - val_loss: 0.9170 - val_accuracy: 0.5726\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8846 - accuracy: 0.5481 - val_loss: 0.9151 - val_accuracy: 0.5726\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8858 - accuracy: 0.5148 - val_loss: 0.9196 - val_accuracy: 0.5726\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8995 - accuracy: 0.5481 - val_loss: 0.9256 - val_accuracy: 0.5726\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8800 - accuracy: 0.5481 - val_loss: 0.9295 - val_accuracy: 0.5726\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8858 - accuracy: 0.5444 - val_loss: 0.9305 - val_accuracy: 0.5726\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8861 - accuracy: 0.5370 - val_loss: 0.9274 - val_accuracy: 0.5726\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8841 - accuracy: 0.5444 - val_loss: 0.9280 - val_accuracy: 0.5726\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8822 - accuracy: 0.5444 - val_loss: 0.9277 - val_accuracy: 0.5726\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8853 - accuracy: 0.5481 - val_loss: 0.9256 - val_accuracy: 0.5726\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8864 - accuracy: 0.5444 - val_loss: 0.9234 - val_accuracy: 0.5726\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8818 - accuracy: 0.5481 - val_loss: 0.9210 - val_accuracy: 0.5641\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8835 - accuracy: 0.5481 - val_loss: 0.9290 - val_accuracy: 0.5726\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8836 - accuracy: 0.5481 - val_loss: 0.9271 - val_accuracy: 0.5726\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8824 - accuracy: 0.5481 - val_loss: 0.9215 - val_accuracy: 0.5726\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8803 - accuracy: 0.5481 - val_loss: 0.9225 - val_accuracy: 0.5726\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8915 - accuracy: 0.5481 - val_loss: 0.9261 - val_accuracy: 0.5726\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8843 - accuracy: 0.5481 - val_loss: 0.9258 - val_accuracy: 0.5726\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8816 - accuracy: 0.5481 - val_loss: 0.9216 - val_accuracy: 0.5726\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8811 - accuracy: 0.5481 - val_loss: 0.9220 - val_accuracy: 0.5726\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8819 - accuracy: 0.5444 - val_loss: 0.9212 - val_accuracy: 0.5726\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8793 - accuracy: 0.5481 - val_loss: 0.9219 - val_accuracy: 0.5726\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8802 - accuracy: 0.5481 - val_loss: 0.9214 - val_accuracy: 0.5641\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8793 - accuracy: 0.5481 - val_loss: 0.9215 - val_accuracy: 0.5641\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8834 - accuracy: 0.5444 - val_loss: 0.9254 - val_accuracy: 0.5726\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8797 - accuracy: 0.5481 - val_loss: 0.9213 - val_accuracy: 0.5641\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8832 - accuracy: 0.5519 - val_loss: 0.9201 - val_accuracy: 0.5641\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8811 - accuracy: 0.5111 - val_loss: 0.9244 - val_accuracy: 0.5726\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 265us/step - loss: 0.8836 - accuracy: 0.5481 - val_loss: 0.9255 - val_accuracy: 0.5726\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8804 - accuracy: 0.5481 - val_loss: 0.9249 - val_accuracy: 0.5726\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8802 - accuracy: 0.5481 - val_loss: 0.9279 - val_accuracy: 0.5726\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8819 - accuracy: 0.5481 - val_loss: 0.9279 - val_accuracy: 0.5726\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8835 - accuracy: 0.5037 - val_loss: 0.9222 - val_accuracy: 0.5812\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8859 - accuracy: 0.5296 - val_loss: 0.9213 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8799 - accuracy: 0.5519 - val_loss: 0.9240 - val_accuracy: 0.5726\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8839 - accuracy: 0.5481 - val_loss: 0.9246 - val_accuracy: 0.5726\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8862 - accuracy: 0.5222 - val_loss: 0.9298 - val_accuracy: 0.5812\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8779 - accuracy: 0.5630 - val_loss: 0.9260 - val_accuracy: 0.5726\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8869 - accuracy: 0.5481 - val_loss: 0.9284 - val_accuracy: 0.5726\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8766 - accuracy: 0.5481 - val_loss: 0.9279 - val_accuracy: 0.5726\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8809 - accuracy: 0.5444 - val_loss: 0.9260 - val_accuracy: 0.5726\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8806 - accuracy: 0.5481 - val_loss: 0.9285 - val_accuracy: 0.5726\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8767 - accuracy: 0.5481 - val_loss: 0.9261 - val_accuracy: 0.5726\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8776 - accuracy: 0.5481 - val_loss: 0.9236 - val_accuracy: 0.5726\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8770 - accuracy: 0.5481 - val_loss: 0.9230 - val_accuracy: 0.5726\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8807 - accuracy: 0.5481 - val_loss: 0.9258 - val_accuracy: 0.5726\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8798 - accuracy: 0.5481 - val_loss: 0.9227 - val_accuracy: 0.5726\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8786 - accuracy: 0.5407 - val_loss: 0.9220 - val_accuracy: 0.5641\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8803 - accuracy: 0.5481 - val_loss: 0.9244 - val_accuracy: 0.5726\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8786 - accuracy: 0.5481 - val_loss: 0.9222 - val_accuracy: 0.5726\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8841 - accuracy: 0.5222 - val_loss: 0.9246 - val_accuracy: 0.5897\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8757 - accuracy: 0.5556 - val_loss: 0.9252 - val_accuracy: 0.5726\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8764 - accuracy: 0.5481 - val_loss: 0.9294 - val_accuracy: 0.5726\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8762 - accuracy: 0.5481 - val_loss: 0.9281 - val_accuracy: 0.5726\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8757 - accuracy: 0.5481 - val_loss: 0.9237 - val_accuracy: 0.5726\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8765 - accuracy: 0.5519 - val_loss: 0.9264 - val_accuracy: 0.5641\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8777 - accuracy: 0.5519 - val_loss: 0.9288 - val_accuracy: 0.5726\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8795 - accuracy: 0.5481 - val_loss: 0.9267 - val_accuracy: 0.5641\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8790 - accuracy: 0.5519 - val_loss: 0.9222 - val_accuracy: 0.5641\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8769 - accuracy: 0.5519 - val_loss: 0.9220 - val_accuracy: 0.5641\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8754 - accuracy: 0.5481 - val_loss: 0.9258 - val_accuracy: 0.5641\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8763 - accuracy: 0.5444 - val_loss: 0.9295 - val_accuracy: 0.5726\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8855 - accuracy: 0.5519 - val_loss: 0.9275 - val_accuracy: 0.5641\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8768 - accuracy: 0.5519 - val_loss: 0.9268 - val_accuracy: 0.5641\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8756 - accuracy: 0.5519 - val_loss: 0.9311 - val_accuracy: 0.5726\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8799 - accuracy: 0.5481 - val_loss: 0.9272 - val_accuracy: 0.5726\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8756 - accuracy: 0.5481 - val_loss: 0.9233 - val_accuracy: 0.5726\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8748 - accuracy: 0.5519 - val_loss: 0.9249 - val_accuracy: 0.5726\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8752 - accuracy: 0.5519 - val_loss: 0.9277 - val_accuracy: 0.5641\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8765 - accuracy: 0.5519 - val_loss: 0.9285 - val_accuracy: 0.5641\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8799 - accuracy: 0.5481 - val_loss: 0.9326 - val_accuracy: 0.5726\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8778 - accuracy: 0.5407 - val_loss: 0.9289 - val_accuracy: 0.5641\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8748 - accuracy: 0.5481 - val_loss: 0.9279 - val_accuracy: 0.5726\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8739 - accuracy: 0.5481 - val_loss: 0.9291 - val_accuracy: 0.5726\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8743 - accuracy: 0.5481 - val_loss: 0.9263 - val_accuracy: 0.5726\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8776 - accuracy: 0.5481 - val_loss: 0.9289 - val_accuracy: 0.5726\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8828 - accuracy: 0.5519 - val_loss: 0.9285 - val_accuracy: 0.5726\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8786 - accuracy: 0.5481 - val_loss: 0.9264 - val_accuracy: 0.5726\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8738 - accuracy: 0.5519 - val_loss: 0.9273 - val_accuracy: 0.5726\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8757 - accuracy: 0.5519 - val_loss: 0.9288 - val_accuracy: 0.5726\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8767 - accuracy: 0.5519 - val_loss: 0.9290 - val_accuracy: 0.5726\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8751 - accuracy: 0.5519 - val_loss: 0.9262 - val_accuracy: 0.5726\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8749 - accuracy: 0.5481 - val_loss: 0.9285 - val_accuracy: 0.5726\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8745 - accuracy: 0.5519 - val_loss: 0.9252 - val_accuracy: 0.5726\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8751 - accuracy: 0.5519 - val_loss: 0.9237 - val_accuracy: 0.5726\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8761 - accuracy: 0.5519 - val_loss: 0.9318 - val_accuracy: 0.5726\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8754 - accuracy: 0.5519 - val_loss: 0.9291 - val_accuracy: 0.5641\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8743 - accuracy: 0.5519 - val_loss: 0.9293 - val_accuracy: 0.5726\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8729 - accuracy: 0.5519 - val_loss: 0.9275 - val_accuracy: 0.5726\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8735 - accuracy: 0.5481 - val_loss: 0.9263 - val_accuracy: 0.5726\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8734 - accuracy: 0.5519 - val_loss: 0.9255 - val_accuracy: 0.5726\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8719 - accuracy: 0.5519 - val_loss: 0.9269 - val_accuracy: 0.5726\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8740 - accuracy: 0.5519 - val_loss: 0.9315 - val_accuracy: 0.5726\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9288 - val_accuracy: 0.5726\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8773 - accuracy: 0.5519 - val_loss: 0.9321 - val_accuracy: 0.5726\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8723 - accuracy: 0.5519 - val_loss: 0.9301 - val_accuracy: 0.5726\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8774 - accuracy: 0.5037 - val_loss: 0.9265 - val_accuracy: 0.5641\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8739 - accuracy: 0.5519 - val_loss: 0.9345 - val_accuracy: 0.5726\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8755 - accuracy: 0.5519 - val_loss: 0.9300 - val_accuracy: 0.5726\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8720 - accuracy: 0.5519 - val_loss: 0.9289 - val_accuracy: 0.5726\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8729 - accuracy: 0.5481 - val_loss: 0.9277 - val_accuracy: 0.5726\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8767 - accuracy: 0.5519 - val_loss: 0.9272 - val_accuracy: 0.5726\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8755 - accuracy: 0.5185 - val_loss: 0.9373 - val_accuracy: 0.5726\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8788 - accuracy: 0.5519 - val_loss: 0.9343 - val_accuracy: 0.5726\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8759 - accuracy: 0.5519 - val_loss: 0.9284 - val_accuracy: 0.5726\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8783 - accuracy: 0.5185 - val_loss: 0.9274 - val_accuracy: 0.5641\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9332 - val_accuracy: 0.5726\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8726 - accuracy: 0.5519 - val_loss: 0.9330 - val_accuracy: 0.5726\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8725 - accuracy: 0.5259 - val_loss: 0.9276 - val_accuracy: 0.5812\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8730 - accuracy: 0.5519 - val_loss: 0.9289 - val_accuracy: 0.5726\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8779 - accuracy: 0.5519 - val_loss: 0.9297 - val_accuracy: 0.5726\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8759 - accuracy: 0.5185 - val_loss: 0.9348 - val_accuracy: 0.5897\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8789 - accuracy: 0.5037 - val_loss: 0.9331 - val_accuracy: 0.5726\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8708 - accuracy: 0.5481 - val_loss: 0.9308 - val_accuracy: 0.5641\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8713 - accuracy: 0.5481 - val_loss: 0.9291 - val_accuracy: 0.5726\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8737 - accuracy: 0.5148 - val_loss: 0.9284 - val_accuracy: 0.5726\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8709 - accuracy: 0.5519 - val_loss: 0.9298 - val_accuracy: 0.5726\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8709 - accuracy: 0.5519 - val_loss: 0.9318 - val_accuracy: 0.5726\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8734 - accuracy: 0.5444 - val_loss: 0.9308 - val_accuracy: 0.5641\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8729 - accuracy: 0.5593 - val_loss: 0.9328 - val_accuracy: 0.5726\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8711 - accuracy: 0.5519 - val_loss: 0.9293 - val_accuracy: 0.5726\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8725 - accuracy: 0.5519 - val_loss: 0.9265 - val_accuracy: 0.5726\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8768 - accuracy: 0.5333 - val_loss: 0.9305 - val_accuracy: 0.5897\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8696 - accuracy: 0.5444 - val_loss: 0.9355 - val_accuracy: 0.5726\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9332 - val_accuracy: 0.5726\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8694 - accuracy: 0.5444 - val_loss: 0.9293 - val_accuracy: 0.5812\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8760 - accuracy: 0.5259 - val_loss: 0.9263 - val_accuracy: 0.5812\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8695 - accuracy: 0.5667 - val_loss: 0.9286 - val_accuracy: 0.5641\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8710 - accuracy: 0.5481 - val_loss: 0.9324 - val_accuracy: 0.5726\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8717 - accuracy: 0.5519 - val_loss: 0.9336 - val_accuracy: 0.5726\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8730 - accuracy: 0.5519 - val_loss: 0.9355 - val_accuracy: 0.5726\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8712 - accuracy: 0.5519 - val_loss: 0.9327 - val_accuracy: 0.5641\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8697 - accuracy: 0.5481 - val_loss: 0.9313 - val_accuracy: 0.5726\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8702 - accuracy: 0.5519 - val_loss: 0.9313 - val_accuracy: 0.5726\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8712 - accuracy: 0.5519 - val_loss: 0.9302 - val_accuracy: 0.5726\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8713 - accuracy: 0.5519 - val_loss: 0.9374 - val_accuracy: 0.5726\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8682 - accuracy: 0.5519 - val_loss: 0.9329 - val_accuracy: 0.5726\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8744 - accuracy: 0.5519 - val_loss: 0.9324 - val_accuracy: 0.5641\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8770 - accuracy: 0.5481 - val_loss: 0.9347 - val_accuracy: 0.5726\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8690 - accuracy: 0.5519 - val_loss: 0.9300 - val_accuracy: 0.5726\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8695 - accuracy: 0.5519 - val_loss: 0.9303 - val_accuracy: 0.5726\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8738 - accuracy: 0.5519 - val_loss: 0.9339 - val_accuracy: 0.5726\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8721 - accuracy: 0.5444 - val_loss: 0.9312 - val_accuracy: 0.5812\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8701 - accuracy: 0.5593 - val_loss: 0.9337 - val_accuracy: 0.5641\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8709 - accuracy: 0.5556 - val_loss: 0.9371 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8696 - accuracy: 0.5444 - val_loss: 0.9331 - val_accuracy: 0.5641\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8718 - accuracy: 0.5481 - val_loss: 0.9341 - val_accuracy: 0.5641\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8685 - accuracy: 0.5519 - val_loss: 0.9301 - val_accuracy: 0.5641\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 0.9321 - val_accuracy: 0.5726\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8681 - accuracy: 0.5519 - val_loss: 0.9301 - val_accuracy: 0.5726\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8702 - accuracy: 0.5519 - val_loss: 0.9333 - val_accuracy: 0.5641\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8709 - accuracy: 0.5519 - val_loss: 0.9309 - val_accuracy: 0.5641\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 0.9314 - val_accuracy: 0.5641\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8696 - accuracy: 0.5519 - val_loss: 0.9358 - val_accuracy: 0.5726\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8708 - accuracy: 0.5481 - val_loss: 0.9320 - val_accuracy: 0.5726\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8676 - accuracy: 0.5519 - val_loss: 0.9328 - val_accuracy: 0.5726\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8730 - accuracy: 0.5519 - val_loss: 0.9329 - val_accuracy: 0.5726\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8728 - accuracy: 0.5222 - val_loss: 0.9355 - val_accuracy: 0.5726\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8701 - accuracy: 0.5481 - val_loss: 0.9347 - val_accuracy: 0.5641\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8681 - accuracy: 0.5519 - val_loss: 0.9346 - val_accuracy: 0.5726\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8684 - accuracy: 0.5519 - val_loss: 0.9354 - val_accuracy: 0.5726\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8670 - accuracy: 0.5519 - val_loss: 0.9328 - val_accuracy: 0.5726\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8723 - accuracy: 0.5111 - val_loss: 0.9333 - val_accuracy: 0.5897\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8755 - accuracy: 0.5222 - val_loss: 0.9339 - val_accuracy: 0.5641\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8664 - accuracy: 0.5481 - val_loss: 0.9350 - val_accuracy: 0.5726\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8747 - accuracy: 0.5407 - val_loss: 0.9394 - val_accuracy: 0.5726\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8671 - accuracy: 0.5519 - val_loss: 0.9343 - val_accuracy: 0.5726\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8687 - accuracy: 0.5519 - val_loss: 0.9344 - val_accuracy: 0.5641\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8688 - accuracy: 0.5519 - val_loss: 0.9340 - val_accuracy: 0.5726\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8671 - accuracy: 0.5519 - val_loss: 0.9326 - val_accuracy: 0.5726\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8674 - accuracy: 0.5519 - val_loss: 0.9343 - val_accuracy: 0.5641\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8672 - accuracy: 0.5519 - val_loss: 0.9374 - val_accuracy: 0.5726\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8666 - accuracy: 0.5519 - val_loss: 0.9410 - val_accuracy: 0.5726\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8688 - accuracy: 0.5185 - val_loss: 0.9340 - val_accuracy: 0.5897\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8694 - accuracy: 0.5407 - val_loss: 0.9363 - val_accuracy: 0.5726\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8702 - accuracy: 0.5519 - val_loss: 0.9413 - val_accuracy: 0.5726\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8674 - accuracy: 0.5519 - val_loss: 0.9361 - val_accuracy: 0.5726\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8671 - accuracy: 0.5519 - val_loss: 0.9347 - val_accuracy: 0.5726\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8704 - accuracy: 0.5185 - val_loss: 0.9370 - val_accuracy: 0.5726\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8694 - accuracy: 0.5519 - val_loss: 0.9407 - val_accuracy: 0.5726\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8727 - accuracy: 0.5259 - val_loss: 0.9393 - val_accuracy: 0.5726\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8663 - accuracy: 0.5519 - val_loss: 0.9373 - val_accuracy: 0.5726\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8707 - accuracy: 0.5519 - val_loss: 0.9390 - val_accuracy: 0.5726\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8670 - accuracy: 0.5519 - val_loss: 0.9366 - val_accuracy: 0.5726\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8694 - accuracy: 0.4852 - val_loss: 0.9356 - val_accuracy: 0.5726\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8664 - accuracy: 0.5519 - val_loss: 0.9438 - val_accuracy: 0.5726\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8684 - accuracy: 0.5185 - val_loss: 0.9320 - val_accuracy: 0.5812\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8683 - accuracy: 0.5333 - val_loss: 0.9301 - val_accuracy: 0.5641\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8689 - accuracy: 0.5519 - val_loss: 0.9355 - val_accuracy: 0.5641\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8685 - accuracy: 0.5519 - val_loss: 0.9415 - val_accuracy: 0.5641\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8667 - accuracy: 0.5481 - val_loss: 0.9362 - val_accuracy: 0.5726\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8680 - accuracy: 0.5519 - val_loss: 0.9361 - val_accuracy: 0.5726\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8672 - accuracy: 0.5519 - val_loss: 0.9341 - val_accuracy: 0.5641\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8656 - accuracy: 0.5333 - val_loss: 0.9353 - val_accuracy: 0.5726\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8668 - accuracy: 0.5519 - val_loss: 0.9390 - val_accuracy: 0.5726\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8742 - accuracy: 0.5519 - val_loss: 0.9367 - val_accuracy: 0.5641\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8686 - accuracy: 0.5556 - val_loss: 0.9390 - val_accuracy: 0.5726\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8632 - accuracy: 0.5481 - val_loss: 0.9357 - val_accuracy: 0.5726\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8660 - accuracy: 0.5407 - val_loss: 0.9363 - val_accuracy: 0.5897\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8645 - accuracy: 0.5185 - val_loss: 0.9332 - val_accuracy: 0.5726\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8656 - accuracy: 0.5519 - val_loss: 0.9365 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8667 - accuracy: 0.5519 - val_loss: 0.9362 - val_accuracy: 0.5726\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8660 - accuracy: 0.5519 - val_loss: 0.9365 - val_accuracy: 0.5726\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8643 - accuracy: 0.5519 - val_loss: 0.9376 - val_accuracy: 0.5726\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8661 - accuracy: 0.5519 - val_loss: 0.9402 - val_accuracy: 0.5726\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8657 - accuracy: 0.5519 - val_loss: 0.9349 - val_accuracy: 0.5726\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8635 - accuracy: 0.5519 - val_loss: 0.9403 - val_accuracy: 0.5726\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8665 - accuracy: 0.5519 - val_loss: 0.9441 - val_accuracy: 0.5726\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8647 - accuracy: 0.5481 - val_loss: 0.9373 - val_accuracy: 0.5812\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8665 - accuracy: 0.5222 - val_loss: 0.9359 - val_accuracy: 0.5726\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8671 - accuracy: 0.5444 - val_loss: 0.9381 - val_accuracy: 0.5641\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8675 - accuracy: 0.5519 - val_loss: 0.9353 - val_accuracy: 0.5641\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8691 - accuracy: 0.5259 - val_loss: 0.9360 - val_accuracy: 0.5726\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8641 - accuracy: 0.5519 - val_loss: 0.9372 - val_accuracy: 0.5726\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8678 - accuracy: 0.5519 - val_loss: 0.9382 - val_accuracy: 0.5726\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8712 - accuracy: 0.5519 - val_loss: 0.9335 - val_accuracy: 0.5641\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8657 - accuracy: 0.5519 - val_loss: 0.9353 - val_accuracy: 0.5726\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8655 - accuracy: 0.5519 - val_loss: 0.9389 - val_accuracy: 0.5726\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8625 - accuracy: 0.5519 - val_loss: 0.9393 - val_accuracy: 0.5726\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8656 - accuracy: 0.5519 - val_loss: 0.9414 - val_accuracy: 0.5726\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8661 - accuracy: 0.5519 - val_loss: 0.9393 - val_accuracy: 0.5726\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8668 - accuracy: 0.5481 - val_loss: 0.9372 - val_accuracy: 0.5641\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8673 - accuracy: 0.5481 - val_loss: 0.9373 - val_accuracy: 0.5726\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8678 - accuracy: 0.5519 - val_loss: 0.9360 - val_accuracy: 0.5726\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8653 - accuracy: 0.5519 - val_loss: 0.9440 - val_accuracy: 0.5726\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8665 - accuracy: 0.5519 - val_loss: 0.9435 - val_accuracy: 0.5726\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8656 - accuracy: 0.5519 - val_loss: 0.9382 - val_accuracy: 0.5726\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8636 - accuracy: 0.5519 - val_loss: 0.9395 - val_accuracy: 0.5726\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8657 - accuracy: 0.5519 - val_loss: 0.9439 - val_accuracy: 0.5726\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8665 - accuracy: 0.5519 - val_loss: 0.9434 - val_accuracy: 0.5726\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8625 - accuracy: 0.5519 - val_loss: 0.9426 - val_accuracy: 0.5726\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8624 - accuracy: 0.5519 - val_loss: 0.9372 - val_accuracy: 0.5641\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8633 - accuracy: 0.5519 - val_loss: 0.9380 - val_accuracy: 0.5641\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8665 - accuracy: 0.5222 - val_loss: 0.9447 - val_accuracy: 0.5726\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8626 - accuracy: 0.5481 - val_loss: 0.9398 - val_accuracy: 0.5641\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8633 - accuracy: 0.5519 - val_loss: 0.9409 - val_accuracy: 0.5641\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8637 - accuracy: 0.5481 - val_loss: 0.9415 - val_accuracy: 0.5726\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8628 - accuracy: 0.5481 - val_loss: 0.9424 - val_accuracy: 0.5641\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8654 - accuracy: 0.5481 - val_loss: 0.9420 - val_accuracy: 0.5726\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8664 - accuracy: 0.5037 - val_loss: 0.9388 - val_accuracy: 0.5812\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8686 - accuracy: 0.5370 - val_loss: 0.9354 - val_accuracy: 0.5641\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8697 - accuracy: 0.5407 - val_loss: 0.9411 - val_accuracy: 0.5726\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8635 - accuracy: 0.5185 - val_loss: 0.9380 - val_accuracy: 0.5641\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8701 - accuracy: 0.5519 - val_loss: 0.9419 - val_accuracy: 0.5641\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8664 - accuracy: 0.5370 - val_loss: 0.9403 - val_accuracy: 0.5812\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8631 - accuracy: 0.5407 - val_loss: 0.9515 - val_accuracy: 0.5726\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8677 - accuracy: 0.5519 - val_loss: 0.9457 - val_accuracy: 0.5726\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8623 - accuracy: 0.5481 - val_loss: 0.9420 - val_accuracy: 0.5812\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8664 - accuracy: 0.5296 - val_loss: 0.9375 - val_accuracy: 0.5641\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8668 - accuracy: 0.5444 - val_loss: 0.9406 - val_accuracy: 0.5726\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8616 - accuracy: 0.5519 - val_loss: 0.9399 - val_accuracy: 0.5726\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8676 - accuracy: 0.5296 - val_loss: 0.9419 - val_accuracy: 0.5726\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8615 - accuracy: 0.5519 - val_loss: 0.9388 - val_accuracy: 0.5726\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8647 - accuracy: 0.5185 - val_loss: 0.9395 - val_accuracy: 0.5812\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8647 - accuracy: 0.5333 - val_loss: 0.9398 - val_accuracy: 0.5641\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8624 - accuracy: 0.5519 - val_loss: 0.9441 - val_accuracy: 0.5726\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 0.9404 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8624 - accuracy: 0.5519 - val_loss: 0.9385 - val_accuracy: 0.5726\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8628 - accuracy: 0.5519 - val_loss: 0.9428 - val_accuracy: 0.5726\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8615 - accuracy: 0.5519 - val_loss: 0.9391 - val_accuracy: 0.5726\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8617 - accuracy: 0.5519 - val_loss: 0.9415 - val_accuracy: 0.5726\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8648 - accuracy: 0.5519 - val_loss: 0.9384 - val_accuracy: 0.5726\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8629 - accuracy: 0.5519 - val_loss: 0.9423 - val_accuracy: 0.5726\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8639 - accuracy: 0.5519 - val_loss: 0.9443 - val_accuracy: 0.5726\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8626 - accuracy: 0.5519 - val_loss: 0.9376 - val_accuracy: 0.5726\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8657 - accuracy: 0.5556 - val_loss: 0.9410 - val_accuracy: 0.5726\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8630 - accuracy: 0.5481 - val_loss: 0.9524 - val_accuracy: 0.4957\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8639 - accuracy: 0.5444 - val_loss: 0.9392 - val_accuracy: 0.5726\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8601 - accuracy: 0.5481 - val_loss: 0.9388 - val_accuracy: 0.5641\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8649 - accuracy: 0.5519 - val_loss: 0.9409 - val_accuracy: 0.5726\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.56 - 0s 110us/step - loss: 0.8685 - accuracy: 0.5148 - val_loss: 0.9513 - val_accuracy: 0.5726\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8635 - accuracy: 0.5519 - val_loss: 0.9415 - val_accuracy: 0.5726\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8676 - accuracy: 0.5519 - val_loss: 0.9431 - val_accuracy: 0.5726\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8653 - accuracy: 0.5519 - val_loss: 0.9399 - val_accuracy: 0.5726\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8627 - accuracy: 0.5519 - val_loss: 0.9422 - val_accuracy: 0.5726\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8636 - accuracy: 0.5444 - val_loss: 0.9424 - val_accuracy: 0.5726\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 0.9436 - val_accuracy: 0.5726\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8616 - accuracy: 0.5519 - val_loss: 0.9373 - val_accuracy: 0.5726\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8608 - accuracy: 0.5519 - val_loss: 0.9373 - val_accuracy: 0.5726\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8608 - accuracy: 0.5519 - val_loss: 0.9411 - val_accuracy: 0.5726\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8598 - accuracy: 0.5519 - val_loss: 0.9405 - val_accuracy: 0.5726\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8605 - accuracy: 0.5519 - val_loss: 0.9416 - val_accuracy: 0.5726\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8630 - accuracy: 0.5519 - val_loss: 0.9357 - val_accuracy: 0.5726\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8658 - accuracy: 0.5519 - val_loss: 0.9392 - val_accuracy: 0.5726\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 0.9404 - val_accuracy: 0.5726\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 0.9378 - val_accuracy: 0.5726\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8709 - accuracy: 0.5185 - val_loss: 0.9409 - val_accuracy: 0.5812\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8645 - accuracy: 0.5296 - val_loss: 0.9465 - val_accuracy: 0.5641\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8650 - accuracy: 0.5481 - val_loss: 0.9425 - val_accuracy: 0.5726\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 0.9420 - val_accuracy: 0.5726\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8595 - accuracy: 0.5519 - val_loss: 0.9409 - val_accuracy: 0.5726\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8612 - accuracy: 0.5519 - val_loss: 0.9395 - val_accuracy: 0.5726\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8595 - accuracy: 0.5519 - val_loss: 0.9442 - val_accuracy: 0.5726\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 0.9416 - val_accuracy: 0.5726\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8606 - accuracy: 0.5519 - val_loss: 0.9425 - val_accuracy: 0.5726\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8611 - accuracy: 0.5519 - val_loss: 0.9400 - val_accuracy: 0.5726\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8619 - accuracy: 0.5519 - val_loss: 0.9420 - val_accuracy: 0.5726\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8630 - accuracy: 0.5519 - val_loss: 0.9493 - val_accuracy: 0.5726\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8619 - accuracy: 0.5519 - val_loss: 0.9417 - val_accuracy: 0.5726\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8605 - accuracy: 0.5519 - val_loss: 0.9427 - val_accuracy: 0.5726\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 0.9424 - val_accuracy: 0.5726\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8619 - accuracy: 0.5222 - val_loss: 0.9486 - val_accuracy: 0.5726\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8620 - accuracy: 0.5519 - val_loss: 0.9458 - val_accuracy: 0.5726\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 0.9413 - val_accuracy: 0.5726\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8611 - accuracy: 0.5519 - val_loss: 0.9425 - val_accuracy: 0.5726\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8598 - accuracy: 0.5519 - val_loss: 0.9478 - val_accuracy: 0.5726\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8601 - accuracy: 0.5519 - val_loss: 0.9474 - val_accuracy: 0.5726\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8597 - accuracy: 0.5481 - val_loss: 0.9421 - val_accuracy: 0.5641\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8595 - accuracy: 0.5519 - val_loss: 0.9419 - val_accuracy: 0.5641\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8639 - accuracy: 0.5519 - val_loss: 0.9504 - val_accuracy: 0.5726\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8595 - accuracy: 0.5519 - val_loss: 0.9446 - val_accuracy: 0.5641\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8590 - accuracy: 0.5519 - val_loss: 0.9458 - val_accuracy: 0.5641\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8626 - accuracy: 0.5481 - val_loss: 0.9484 - val_accuracy: 0.5726\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 0.9439 - val_accuracy: 0.5641\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8599 - accuracy: 0.5519 - val_loss: 0.9453 - val_accuracy: 0.5726\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8576 - accuracy: 0.5519 - val_loss: 0.9443 - val_accuracy: 0.5726\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8594 - accuracy: 0.5519 - val_loss: 0.9473 - val_accuracy: 0.5726\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8611 - accuracy: 0.5519 - val_loss: 0.9480 - val_accuracy: 0.5726\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8602 - accuracy: 0.5481 - val_loss: 0.9459 - val_accuracy: 0.5641\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8582 - accuracy: 0.5481 - val_loss: 0.9462 - val_accuracy: 0.5726\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8594 - accuracy: 0.5519 - val_loss: 0.9432 - val_accuracy: 0.5726\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8601 - accuracy: 0.5556 - val_loss: 0.9408 - val_accuracy: 0.5641\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8607 - accuracy: 0.5259 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8602 - accuracy: 0.5259 - val_loss: 0.9445 - val_accuracy: 0.5726\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8601 - accuracy: 0.5556 - val_loss: 0.9467 - val_accuracy: 0.5726\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8617 - accuracy: 0.5519 - val_loss: 0.9487 - val_accuracy: 0.5726\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8681 - accuracy: 0.5185 - val_loss: 0.9481 - val_accuracy: 0.5897\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8614 - accuracy: 0.5481 - val_loss: 0.9463 - val_accuracy: 0.5726\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8634 - accuracy: 0.5519 - val_loss: 0.9494 - val_accuracy: 0.5726\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8659 - accuracy: 0.5111 - val_loss: 0.9506 - val_accuracy: 0.5726\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8597 - accuracy: 0.5519 - val_loss: 0.9487 - val_accuracy: 0.5726\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8638 - accuracy: 0.5519 - val_loss: 0.9494 - val_accuracy: 0.5726\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8578 - accuracy: 0.5519 - val_loss: 0.9419 - val_accuracy: 0.5726\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8600 - accuracy: 0.5185 - val_loss: 0.9451 - val_accuracy: 0.5726\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8592 - accuracy: 0.5519 - val_loss: 0.9430 - val_accuracy: 0.5726\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8689 - accuracy: 0.5259 - val_loss: 0.9456 - val_accuracy: 0.5726\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8636 - accuracy: 0.5444 - val_loss: 0.9544 - val_accuracy: 0.5897\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8603 - accuracy: 0.5630 - val_loss: 0.9531 - val_accuracy: 0.5726\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8596 - accuracy: 0.5481 - val_loss: 0.9498 - val_accuracy: 0.5641\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8611 - accuracy: 0.5556 - val_loss: 0.9466 - val_accuracy: 0.5726\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8604 - accuracy: 0.5481 - val_loss: 0.9465 - val_accuracy: 0.5641\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8716 - accuracy: 0.5296 - val_loss: 0.9522 - val_accuracy: 0.5726\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8620 - accuracy: 0.5481 - val_loss: 0.9470 - val_accuracy: 0.5556\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8600 - accuracy: 0.5519 - val_loss: 0.9482 - val_accuracy: 0.5726\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8586 - accuracy: 0.5519 - val_loss: 0.9452 - val_accuracy: 0.5726\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8584 - accuracy: 0.5519 - val_loss: 0.9529 - val_accuracy: 0.5726\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8575 - accuracy: 0.5519 - val_loss: 0.9475 - val_accuracy: 0.5726\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8585 - accuracy: 0.5444 - val_loss: 0.9467 - val_accuracy: 0.5726\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8645 - accuracy: 0.5000 - val_loss: 0.9434 - val_accuracy: 0.5812\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8573 - accuracy: 0.5444 - val_loss: 0.9445 - val_accuracy: 0.5726\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8613 - accuracy: 0.5370 - val_loss: 0.9534 - val_accuracy: 0.4957\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8569 - accuracy: 0.5630 - val_loss: 0.9459 - val_accuracy: 0.5641\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8655 - accuracy: 0.4926 - val_loss: 0.9468 - val_accuracy: 0.5641\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8614 - accuracy: 0.5481 - val_loss: 0.9504 - val_accuracy: 0.5726\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 0.9463 - val_accuracy: 0.5641\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8645 - accuracy: 0.5111 - val_loss: 0.9536 - val_accuracy: 0.5897\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8588 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5641\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8601 - accuracy: 0.5519 - val_loss: 0.9458 - val_accuracy: 0.5641\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8643 - accuracy: 0.5519 - val_loss: 0.9519 - val_accuracy: 0.5641\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8603 - accuracy: 0.5000 - val_loss: 0.9442 - val_accuracy: 0.5641\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8602 - accuracy: 0.5519 - val_loss: 0.9488 - val_accuracy: 0.5641\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8625 - accuracy: 0.5519 - val_loss: 0.9553 - val_accuracy: 0.5726\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8574 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5641\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8589 - accuracy: 0.5148 - val_loss: 0.9454 - val_accuracy: 0.5641\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8626 - accuracy: 0.5481 - val_loss: 0.9485 - val_accuracy: 0.5641\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8571 - accuracy: 0.5519 - val_loss: 0.9450 - val_accuracy: 0.5641\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8579 - accuracy: 0.5222 - val_loss: 0.9479 - val_accuracy: 0.5641\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8571 - accuracy: 0.5556 - val_loss: 0.9545 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8588 - accuracy: 0.5444 - val_loss: 0.9518 - val_accuracy: 0.5641\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8571 - accuracy: 0.5556 - val_loss: 0.9523 - val_accuracy: 0.5641\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8570 - accuracy: 0.5519 - val_loss: 0.9451 - val_accuracy: 0.5641\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8604 - accuracy: 0.5222 - val_loss: 0.9495 - val_accuracy: 0.5812\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8581 - accuracy: 0.5370 - val_loss: 0.9509 - val_accuracy: 0.5641\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8594 - accuracy: 0.5481 - val_loss: 0.9570 - val_accuracy: 0.5726\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8588 - accuracy: 0.5519 - val_loss: 0.9471 - val_accuracy: 0.5726\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8570 - accuracy: 0.5185 - val_loss: 0.9464 - val_accuracy: 0.5812\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8626 - accuracy: 0.5222 - val_loss: 0.9507 - val_accuracy: 0.5641\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8561 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5726\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8649 - accuracy: 0.5481 - val_loss: 0.9492 - val_accuracy: 0.5641\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8567 - accuracy: 0.5481 - val_loss: 0.9501 - val_accuracy: 0.5726\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8584 - accuracy: 0.5481 - val_loss: 0.9468 - val_accuracy: 0.5641\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8576 - accuracy: 0.5519 - val_loss: 0.9532 - val_accuracy: 0.5726\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8612 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5641\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8599 - accuracy: 0.5519 - val_loss: 0.9555 - val_accuracy: 0.5726\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8582 - accuracy: 0.5556 - val_loss: 0.9490 - val_accuracy: 0.5641\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8567 - accuracy: 0.5519 - val_loss: 0.9472 - val_accuracy: 0.5641\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8552 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5641\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8599 - accuracy: 0.5481 - val_loss: 0.9490 - val_accuracy: 0.5641\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8564 - accuracy: 0.5481 - val_loss: 0.9466 - val_accuracy: 0.5812\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8589 - accuracy: 0.5259 - val_loss: 0.9477 - val_accuracy: 0.5641\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8583 - accuracy: 0.5481 - val_loss: 0.9506 - val_accuracy: 0.5726\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 0.9474 - val_accuracy: 0.5641\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8577 - accuracy: 0.5444 - val_loss: 0.9515 - val_accuracy: 0.5726\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8575 - accuracy: 0.5296 - val_loss: 0.9508 - val_accuracy: 0.5726\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8581 - accuracy: 0.5519 - val_loss: 0.9529 - val_accuracy: 0.5726\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8572 - accuracy: 0.5481 - val_loss: 0.9526 - val_accuracy: 0.5641\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8562 - accuracy: 0.5519 - val_loss: 0.9482 - val_accuracy: 0.5641\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8550 - accuracy: 0.5519 - val_loss: 0.9504 - val_accuracy: 0.5641\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8565 - accuracy: 0.5481 - val_loss: 0.9506 - val_accuracy: 0.5641\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8574 - accuracy: 0.5481 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8643 - accuracy: 0.5556 - val_loss: 0.9461 - val_accuracy: 0.5641\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8557 - accuracy: 0.5481 - val_loss: 0.9485 - val_accuracy: 0.5726\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8607 - accuracy: 0.5222 - val_loss: 0.9449 - val_accuracy: 0.5641\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8620 - accuracy: 0.5519 - val_loss: 0.9464 - val_accuracy: 0.5641\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8591 - accuracy: 0.5519 - val_loss: 0.9489 - val_accuracy: 0.5726\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8608 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5726\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8569 - accuracy: 0.5519 - val_loss: 0.9534 - val_accuracy: 0.5726\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8601 - accuracy: 0.5111 - val_loss: 0.9444 - val_accuracy: 0.5812\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8586 - accuracy: 0.5407 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8598 - accuracy: 0.5481 - val_loss: 0.9472 - val_accuracy: 0.5641\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8572 - accuracy: 0.5444 - val_loss: 0.9472 - val_accuracy: 0.5726\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8597 - accuracy: 0.5593 - val_loss: 0.9569 - val_accuracy: 0.4957\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 0.9475 - val_accuracy: 0.5897\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8589 - accuracy: 0.5222 - val_loss: 0.9569 - val_accuracy: 0.5726\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8611 - accuracy: 0.5519 - val_loss: 0.9552 - val_accuracy: 0.5726\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8577 - accuracy: 0.5185 - val_loss: 0.9530 - val_accuracy: 0.5897\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8575 - accuracy: 0.5296 - val_loss: 0.9521 - val_accuracy: 0.5726\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8550 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8579 - accuracy: 0.5519 - val_loss: 0.9440 - val_accuracy: 0.5726\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8532 - accuracy: 0.5519 - val_loss: 0.9493 - val_accuracy: 0.5726\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8608 - accuracy: 0.5444 - val_loss: 0.9550 - val_accuracy: 0.5726\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8545 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5641\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8561 - accuracy: 0.5481 - val_loss: 0.9502 - val_accuracy: 0.5726\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8555 - accuracy: 0.5481 - val_loss: 0.9490 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8556 - accuracy: 0.5444 - val_loss: 0.9520 - val_accuracy: 0.5726\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8560 - accuracy: 0.5481 - val_loss: 0.9506 - val_accuracy: 0.5641\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8545 - accuracy: 0.5519 - val_loss: 0.9478 - val_accuracy: 0.5726\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8561 - accuracy: 0.5519 - val_loss: 0.9487 - val_accuracy: 0.5726\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8550 - accuracy: 0.5519 - val_loss: 0.9468 - val_accuracy: 0.5726\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8555 - accuracy: 0.5185 - val_loss: 0.9483 - val_accuracy: 0.5897\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8558 - accuracy: 0.5444 - val_loss: 0.9508 - val_accuracy: 0.5726\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8552 - accuracy: 0.5519 - val_loss: 0.9534 - val_accuracy: 0.5726\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8564 - accuracy: 0.5519 - val_loss: 0.9497 - val_accuracy: 0.5726\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8541 - accuracy: 0.5519 - val_loss: 0.9520 - val_accuracy: 0.5726\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8545 - accuracy: 0.5519 - val_loss: 0.9507 - val_accuracy: 0.5726\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8561 - accuracy: 0.5519 - val_loss: 0.9518 - val_accuracy: 0.5726\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8594 - accuracy: 0.5519 - val_loss: 0.9479 - val_accuracy: 0.5726\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8628 - accuracy: 0.5444 - val_loss: 0.9520 - val_accuracy: 0.5641\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8578 - accuracy: 0.5481 - val_loss: 0.9561 - val_accuracy: 0.5726\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8566 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5726\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8550 - accuracy: 0.5519 - val_loss: 0.9549 - val_accuracy: 0.5726\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 0.9495 - val_accuracy: 0.5726\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8551 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8570 - accuracy: 0.5111 - val_loss: 0.9514 - val_accuracy: 0.5641\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8596 - accuracy: 0.5519 - val_loss: 0.9564 - val_accuracy: 0.5726\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8561 - accuracy: 0.5519 - val_loss: 0.9509 - val_accuracy: 0.5726\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8563 - accuracy: 0.5037 - val_loss: 0.9516 - val_accuracy: 0.5726\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8548 - accuracy: 0.5370 - val_loss: 0.9519 - val_accuracy: 0.5812\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8543 - accuracy: 0.5370 - val_loss: 0.9524 - val_accuracy: 0.5726\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8551 - accuracy: 0.5481 - val_loss: 0.9493 - val_accuracy: 0.5641\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8557 - accuracy: 0.5519 - val_loss: 0.9505 - val_accuracy: 0.5641\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8557 - accuracy: 0.5519 - val_loss: 0.9501 - val_accuracy: 0.5641\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8546 - accuracy: 0.5519 - val_loss: 0.9530 - val_accuracy: 0.5726\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8552 - accuracy: 0.5519 - val_loss: 0.9480 - val_accuracy: 0.5726\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8547 - accuracy: 0.5519 - val_loss: 0.9502 - val_accuracy: 0.5726\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8537 - accuracy: 0.5519 - val_loss: 0.9496 - val_accuracy: 0.5726\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8555 - accuracy: 0.5519 - val_loss: 0.9497 - val_accuracy: 0.5726\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8541 - accuracy: 0.5519 - val_loss: 0.9501 - val_accuracy: 0.5726\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8589 - accuracy: 0.5519 - val_loss: 0.9518 - val_accuracy: 0.5726\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8577 - accuracy: 0.5519 - val_loss: 0.9498 - val_accuracy: 0.5726\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5726\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8560 - accuracy: 0.5519 - val_loss: 0.9481 - val_accuracy: 0.5726\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8569 - accuracy: 0.5556 - val_loss: 0.9471 - val_accuracy: 0.5641\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8545 - accuracy: 0.5481 - val_loss: 0.9525 - val_accuracy: 0.5726\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 0.9515 - val_accuracy: 0.5726\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8540 - accuracy: 0.5481 - val_loss: 0.9517 - val_accuracy: 0.5641\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8545 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5726\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8543 - accuracy: 0.5370 - val_loss: 0.9512 - val_accuracy: 0.5641\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8565 - accuracy: 0.5519 - val_loss: 0.9579 - val_accuracy: 0.5726\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8553 - accuracy: 0.5481 - val_loss: 0.9511 - val_accuracy: 0.5641\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8547 - accuracy: 0.5519 - val_loss: 0.9486 - val_accuracy: 0.5641\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8562 - accuracy: 0.5185 - val_loss: 0.9503 - val_accuracy: 0.5726\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8559 - accuracy: 0.5185 - val_loss: 0.9484 - val_accuracy: 0.5726\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8534 - accuracy: 0.5519 - val_loss: 0.9538 - val_accuracy: 0.5726\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8570 - accuracy: 0.5519 - val_loss: 0.9540 - val_accuracy: 0.5726\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8549 - accuracy: 0.5370 - val_loss: 0.9508 - val_accuracy: 0.5726\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8533 - accuracy: 0.5519 - val_loss: 0.9550 - val_accuracy: 0.5726\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8569 - accuracy: 0.5519 - val_loss: 0.9559 - val_accuracy: 0.5726\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8585 - accuracy: 0.5519 - val_loss: 0.9508 - val_accuracy: 0.5726\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8534 - accuracy: 0.5519 - val_loss: 0.9528 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8582 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5726\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8542 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5726\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8601 - accuracy: 0.5519 - val_loss: 0.9617 - val_accuracy: 0.5726\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8540 - accuracy: 0.5519 - val_loss: 0.9579 - val_accuracy: 0.5726\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8539 - accuracy: 0.5519 - val_loss: 0.9588 - val_accuracy: 0.5726\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8559 - accuracy: 0.5519 - val_loss: 0.9594 - val_accuracy: 0.5726\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8522 - accuracy: 0.5519 - val_loss: 0.9528 - val_accuracy: 0.5726\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8666 - accuracy: 0.5037 - val_loss: 0.9515 - val_accuracy: 0.5726\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8589 - accuracy: 0.5370 - val_loss: 0.9604 - val_accuracy: 0.5726\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8548 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5726\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8529 - accuracy: 0.5593 - val_loss: 0.9531 - val_accuracy: 0.5641\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8529 - accuracy: 0.5519 - val_loss: 0.9569 - val_accuracy: 0.5641\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8561 - accuracy: 0.5519 - val_loss: 0.9551 - val_accuracy: 0.5641\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8616 - accuracy: 0.5444 - val_loss: 0.9604 - val_accuracy: 0.5641\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8528 - accuracy: 0.5519 - val_loss: 0.9503 - val_accuracy: 0.5812\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8561 - accuracy: 0.5000 - val_loss: 0.9566 - val_accuracy: 0.5641\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8531 - accuracy: 0.5519 - val_loss: 0.9552 - val_accuracy: 0.5641\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8516 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5641\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8573 - accuracy: 0.5481 - val_loss: 0.9546 - val_accuracy: 0.5641\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8529 - accuracy: 0.5519 - val_loss: 0.9548 - val_accuracy: 0.5726\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8554 - accuracy: 0.5519 - val_loss: 0.9600 - val_accuracy: 0.5726\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 0.9566 - val_accuracy: 0.5641\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8544 - accuracy: 0.5481 - val_loss: 0.9578 - val_accuracy: 0.5726\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8527 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5726\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8539 - accuracy: 0.5519 - val_loss: 0.9543 - val_accuracy: 0.5726\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 0.9516 - val_accuracy: 0.5641\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8537 - accuracy: 0.5519 - val_loss: 0.9510 - val_accuracy: 0.5641\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 0.9514 - val_accuracy: 0.5641\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8551 - accuracy: 0.5519 - val_loss: 0.9491 - val_accuracy: 0.5641\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8539 - accuracy: 0.5148 - val_loss: 0.9505 - val_accuracy: 0.5641\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8551 - accuracy: 0.5259 - val_loss: 0.9538 - val_accuracy: 0.5726\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8525 - accuracy: 0.5481 - val_loss: 0.9515 - val_accuracy: 0.5641\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8680 - accuracy: 0.5519 - val_loss: 0.9521 - val_accuracy: 0.5556\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8502 - accuracy: 0.5519 - val_loss: 0.9618 - val_accuracy: 0.5726\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8552 - accuracy: 0.5519 - val_loss: 0.9606 - val_accuracy: 0.5726\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8588 - accuracy: 0.5556 - val_loss: 0.9528 - val_accuracy: 0.5641\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8528 - accuracy: 0.5519 - val_loss: 0.9529 - val_accuracy: 0.5726\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8510 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5726\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8513 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5726\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8522 - accuracy: 0.5519 - val_loss: 0.9508 - val_accuracy: 0.5641\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8543 - accuracy: 0.5519 - val_loss: 0.9540 - val_accuracy: 0.5812\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8528 - accuracy: 0.5259 - val_loss: 0.9533 - val_accuracy: 0.5812\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8525 - accuracy: 0.5481 - val_loss: 0.9520 - val_accuracy: 0.5726\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8531 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5726\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8527 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5726\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8517 - accuracy: 0.5519 - val_loss: 0.9563 - val_accuracy: 0.5726\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8515 - accuracy: 0.5519 - val_loss: 0.9567 - val_accuracy: 0.5726\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8532 - accuracy: 0.5519 - val_loss: 0.9564 - val_accuracy: 0.5726\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8524 - accuracy: 0.5519 - val_loss: 0.9555 - val_accuracy: 0.5726\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8564 - accuracy: 0.5519 - val_loss: 0.9587 - val_accuracy: 0.5726\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8552 - accuracy: 0.5519 - val_loss: 0.9526 - val_accuracy: 0.5641\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8536 - accuracy: 0.5519 - val_loss: 0.9574 - val_accuracy: 0.5726\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8562 - accuracy: 0.5519 - val_loss: 0.9625 - val_accuracy: 0.5726\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8565 - accuracy: 0.5519 - val_loss: 0.9562 - val_accuracy: 0.5726\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8542 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5726\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8533 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8568 - accuracy: 0.5519 - val_loss: 0.9554 - val_accuracy: 0.5726\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8544 - accuracy: 0.5111 - val_loss: 0.9538 - val_accuracy: 0.5641\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8555 - accuracy: 0.5519 - val_loss: 0.9564 - val_accuracy: 0.5641\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8535 - accuracy: 0.5519 - val_loss: 0.9517 - val_accuracy: 0.5641\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8541 - accuracy: 0.5074 - val_loss: 0.9492 - val_accuracy: 0.5726\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 0.9479 - val_accuracy: 0.5726\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8526 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5726\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 0.9503 - val_accuracy: 0.5726\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8538 - accuracy: 0.5519 - val_loss: 0.9530 - val_accuracy: 0.5726\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8521 - accuracy: 0.5519 - val_loss: 0.9496 - val_accuracy: 0.5726\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8511 - accuracy: 0.5519 - val_loss: 0.9495 - val_accuracy: 0.5641\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8512 - accuracy: 0.5519 - val_loss: 0.9509 - val_accuracy: 0.5641\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8541 - accuracy: 0.5519 - val_loss: 0.9556 - val_accuracy: 0.5726\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8512 - accuracy: 0.5519 - val_loss: 0.9529 - val_accuracy: 0.5641\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8522 - accuracy: 0.5519 - val_loss: 0.9542 - val_accuracy: 0.5641\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8518 - accuracy: 0.5519 - val_loss: 0.9530 - val_accuracy: 0.5641\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8560 - accuracy: 0.5296 - val_loss: 0.9560 - val_accuracy: 0.5897\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8572 - accuracy: 0.5444 - val_loss: 0.9554 - val_accuracy: 0.5726\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8508 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5726\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8516 - accuracy: 0.5519 - val_loss: 0.9552 - val_accuracy: 0.5726\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8509 - accuracy: 0.5519 - val_loss: 0.9556 - val_accuracy: 0.5726\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8539 - accuracy: 0.5556 - val_loss: 0.9545 - val_accuracy: 0.5641\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8552 - accuracy: 0.5370 - val_loss: 0.9581 - val_accuracy: 0.5897\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8531 - accuracy: 0.5556 - val_loss: 0.9533 - val_accuracy: 0.5726\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8513 - accuracy: 0.5519 - val_loss: 0.9598 - val_accuracy: 0.5726\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8528 - accuracy: 0.5519 - val_loss: 0.9643 - val_accuracy: 0.5726\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8514 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5641\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8516 - accuracy: 0.5519 - val_loss: 0.9554 - val_accuracy: 0.5641\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8537 - accuracy: 0.5519 - val_loss: 0.9540 - val_accuracy: 0.5641\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8561 - accuracy: 0.5481 - val_loss: 0.9606 - val_accuracy: 0.5726\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8574 - accuracy: 0.5185 - val_loss: 0.9604 - val_accuracy: 0.5812\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8545 - accuracy: 0.5556 - val_loss: 0.9663 - val_accuracy: 0.5726\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8523 - accuracy: 0.5481 - val_loss: 0.9587 - val_accuracy: 0.5641\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8518 - accuracy: 0.5259 - val_loss: 0.9562 - val_accuracy: 0.5641\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8509 - accuracy: 0.5259 - val_loss: 0.9562 - val_accuracy: 0.5641\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8570 - accuracy: 0.5481 - val_loss: 0.9578 - val_accuracy: 0.5641\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8504 - accuracy: 0.5481 - val_loss: 0.9599 - val_accuracy: 0.5641\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8534 - accuracy: 0.5519 - val_loss: 0.9613 - val_accuracy: 0.5641\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8524 - accuracy: 0.5519 - val_loss: 0.9595 - val_accuracy: 0.5641\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 0.9645 - val_accuracy: 0.5726\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8523 - accuracy: 0.5481 - val_loss: 0.9550 - val_accuracy: 0.5641\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8508 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5641\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8530 - accuracy: 0.5519 - val_loss: 0.9546 - val_accuracy: 0.5641\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8496 - accuracy: 0.5519 - val_loss: 0.9560 - val_accuracy: 0.5726\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8541 - accuracy: 0.5000 - val_loss: 0.9580 - val_accuracy: 0.5726\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8531 - accuracy: 0.5519 - val_loss: 0.9622 - val_accuracy: 0.5726\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8522 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5641\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8573 - accuracy: 0.5148 - val_loss: 0.9544 - val_accuracy: 0.5812\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8551 - accuracy: 0.5333 - val_loss: 0.9656 - val_accuracy: 0.5726\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8515 - accuracy: 0.5444 - val_loss: 0.9563 - val_accuracy: 0.5641\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8499 - accuracy: 0.5519 - val_loss: 0.9563 - val_accuracy: 0.5641\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8530 - accuracy: 0.5519 - val_loss: 0.9554 - val_accuracy: 0.5641\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8519 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5641\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8492 - accuracy: 0.5519 - val_loss: 0.9549 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38683048>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 100us/step\n",
      "over-sampling test accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 0, 1, 0,\n",
       "       0, 0, 2, 1, 1, 1, 0, 0, 2, 2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0,\n",
       "       0, 1, 2, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0    BCH-SA-11     2     0\n",
       "1       NRS161     1     1\n",
       "2    BCH-SA-14     2     0\n",
       "3    BCH-SA-11     2     0\n",
       "4     CFBRSa49     1     0\n",
       "..         ...   ...   ...\n",
       "112     NRS064     2     2\n",
       "113     NRS266     2     2\n",
       "114     NRS222     0     0\n",
       "115       GA27     2     0\n",
       "116      GA984     1     0\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191576</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.343363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.988827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.219150</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.776542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.533972</td>\n",
       "      <td>0.280422</td>\n",
       "      <td>0.185605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.230959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.388714  0.380327  0.230959\n",
       "1    0.191576  0.465061  0.343363\n",
       "2    0.388714  0.380327  0.230959\n",
       "3    0.388714  0.380327  0.230959\n",
       "4    0.388714  0.380327  0.230959\n",
       "..        ...       ...       ...\n",
       "112  0.000037  0.011136  0.988827\n",
       "113  0.219150  0.004308  0.776542\n",
       "114  0.533972  0.280422  0.185605\n",
       "115  0.388714  0.380327  0.230959\n",
       "116  0.388714  0.380327  0.230959\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8440 - accuracy: 0.5593 - val_loss: 1.0299 - val_accuracy: 0.5726\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.0241 - val_accuracy: 0.5726\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0193 - val_accuracy: 0.5641\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8455 - accuracy: 0.5519 - val_loss: 1.0195 - val_accuracy: 0.5641\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0251 - val_accuracy: 0.5726\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.0229 - val_accuracy: 0.5726\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.0202 - val_accuracy: 0.5641\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8498 - accuracy: 0.5481 - val_loss: 1.0179 - val_accuracy: 0.5556\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8515 - accuracy: 0.5259 - val_loss: 1.0312 - val_accuracy: 0.4957\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8486 - accuracy: 0.5407 - val_loss: 1.0231 - val_accuracy: 0.5726\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8478 - accuracy: 0.5481 - val_loss: 1.0191 - val_accuracy: 0.5556\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8457 - accuracy: 0.5519 - val_loss: 1.0206 - val_accuracy: 0.5641\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8455 - accuracy: 0.5519 - val_loss: 1.0197 - val_accuracy: 0.5641\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0249 - val_accuracy: 0.5726\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0186 - val_accuracy: 0.5726\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8447 - accuracy: 0.5481 - val_loss: 1.0181 - val_accuracy: 0.5641\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8480 - accuracy: 0.5519 - val_loss: 1.0256 - val_accuracy: 0.5726\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0266 - val_accuracy: 0.5726\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8512 - accuracy: 0.4889 - val_loss: 1.0216 - val_accuracy: 0.5897\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8457 - accuracy: 0.5667 - val_loss: 1.0215 - val_accuracy: 0.5641\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.0270 - val_accuracy: 0.5726\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8482 - accuracy: 0.5519 - val_loss: 1.0274 - val_accuracy: 0.5726\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8485 - accuracy: 0.5519 - val_loss: 1.0194 - val_accuracy: 0.5641\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.0233 - val_accuracy: 0.5726\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8456 - accuracy: 0.5370 - val_loss: 1.0227 - val_accuracy: 0.5726\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8442 - accuracy: 0.5481 - val_loss: 1.0249 - val_accuracy: 0.5641\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0300 - val_accuracy: 0.5726\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5641\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8469 - accuracy: 0.5296 - val_loss: 1.0233 - val_accuracy: 0.5641\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8473 - accuracy: 0.5519 - val_loss: 1.0329 - val_accuracy: 0.5726\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0228 - val_accuracy: 0.5641\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8435 - accuracy: 0.5519 - val_loss: 1.0207 - val_accuracy: 0.5641\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8462 - accuracy: 0.5074 - val_loss: 1.0244 - val_accuracy: 0.5641\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0253 - val_accuracy: 0.5726\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.0189 - val_accuracy: 0.5641\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8487 - accuracy: 0.5519 - val_loss: 1.0236 - val_accuracy: 0.5726\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 343us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0213 - val_accuracy: 0.5726\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0222 - val_accuracy: 0.5726\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0195 - val_accuracy: 0.5726\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0233 - val_accuracy: 0.5726\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8473 - accuracy: 0.5222 - val_loss: 1.0231 - val_accuracy: 0.5897\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8490 - accuracy: 0.5593 - val_loss: 1.0241 - val_accuracy: 0.5726\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0226 - val_accuracy: 0.5726\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8444 - accuracy: 0.5519 - val_loss: 1.0248 - val_accuracy: 0.5726\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0233 - val_accuracy: 0.5726\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 1.0198 - val_accuracy: 0.5726\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0230 - val_accuracy: 0.5726\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0235 - val_accuracy: 0.5726\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.0234 - val_accuracy: 0.5726\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8450 - accuracy: 0.5481 - val_loss: 1.0211 - val_accuracy: 0.5641\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.0215 - val_accuracy: 0.5641\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0222 - val_accuracy: 0.5726\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0287 - val_accuracy: 0.5726\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0277 - val_accuracy: 0.5726\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8485 - accuracy: 0.5519 - val_loss: 1.0220 - val_accuracy: 0.5641\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0262 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0268 - val_accuracy: 0.5726\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8492 - accuracy: 0.5519 - val_loss: 1.0216 - val_accuracy: 0.5726\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8449 - accuracy: 0.5481 - val_loss: 1.0223 - val_accuracy: 0.5726\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8455 - accuracy: 0.5519 - val_loss: 1.0247 - val_accuracy: 0.5726\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0232 - val_accuracy: 0.5726\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.0182 - val_accuracy: 0.5641\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0214 - val_accuracy: 0.5641\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0233 - val_accuracy: 0.5726\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0258 - val_accuracy: 0.5726\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0206 - val_accuracy: 0.5641\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.0286 - val_accuracy: 0.5726\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8444 - accuracy: 0.5519 - val_loss: 1.0257 - val_accuracy: 0.5726\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.0231 - val_accuracy: 0.5726\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0236 - val_accuracy: 0.5726\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0284 - val_accuracy: 0.5726\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8506 - accuracy: 0.5259 - val_loss: 1.0314 - val_accuracy: 0.5726\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.0239 - val_accuracy: 0.5641\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0238 - val_accuracy: 0.5726\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0244 - val_accuracy: 0.5726\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.0243 - val_accuracy: 0.5726\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0292 - val_accuracy: 0.5726\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 589us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.0263 - val_accuracy: 0.5726\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8470 - accuracy: 0.5407 - val_loss: 1.0257 - val_accuracy: 0.5726\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8439 - accuracy: 0.5296 - val_loss: 1.0260 - val_accuracy: 0.5726\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0315 - val_accuracy: 0.5726\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.5641\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.0289 - val_accuracy: 0.5726\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0294 - val_accuracy: 0.5726\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8436 - accuracy: 0.5481 - val_loss: 1.0254 - val_accuracy: 0.5641\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8445 - accuracy: 0.5222 - val_loss: 1.0244 - val_accuracy: 0.5726\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8504 - accuracy: 0.5519 - val_loss: 1.0273 - val_accuracy: 0.5726\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0252 - val_accuracy: 0.5726\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0286 - val_accuracy: 0.5726\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0268 - val_accuracy: 0.5726\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0331 - val_accuracy: 0.5726\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0301 - val_accuracy: 0.5726\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8479 - accuracy: 0.5519 - val_loss: 1.0249 - val_accuracy: 0.5641\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0277 - val_accuracy: 0.5726\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0330 - val_accuracy: 0.5726\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8481 - accuracy: 0.5519 - val_loss: 1.0322 - val_accuracy: 0.5726\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8447 - accuracy: 0.5481 - val_loss: 1.0241 - val_accuracy: 0.5641\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8469 - accuracy: 0.5481 - val_loss: 1.0285 - val_accuracy: 0.5726\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8469 - accuracy: 0.5333 - val_loss: 1.0395 - val_accuracy: 0.4957\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 445us/step - loss: 0.8433 - accuracy: 0.5148 - val_loss: 1.0293 - val_accuracy: 0.5641\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8450 - accuracy: 0.5481 - val_loss: 1.0282 - val_accuracy: 0.5641\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.0285 - val_accuracy: 0.5641\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8441 - accuracy: 0.5481 - val_loss: 1.0324 - val_accuracy: 0.5726\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0308 - val_accuracy: 0.5641\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.0310 - val_accuracy: 0.5641\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8481 - accuracy: 0.5519 - val_loss: 1.0333 - val_accuracy: 0.5641\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0313 - val_accuracy: 0.5641\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.0316 - val_accuracy: 0.5641\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0333 - val_accuracy: 0.5641\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.0355 - val_accuracy: 0.5726\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8455 - accuracy: 0.5519 - val_loss: 1.0293 - val_accuracy: 0.5641\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0322 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0340 - val_accuracy: 0.5726\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0285 - val_accuracy: 0.5726\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8450 - accuracy: 0.5222 - val_loss: 1.0331 - val_accuracy: 0.5641\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8456 - accuracy: 0.5444 - val_loss: 1.0318 - val_accuracy: 0.5641\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8424 - accuracy: 0.5519 - val_loss: 1.0361 - val_accuracy: 0.5726\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8506 - accuracy: 0.5074 - val_loss: 1.0385 - val_accuracy: 0.5897\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8525 - accuracy: 0.5222 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0384 - val_accuracy: 0.4957\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.0352 - val_accuracy: 0.5726\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8455 - accuracy: 0.5074 - val_loss: 1.0309 - val_accuracy: 0.5641\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0327 - val_accuracy: 0.5641\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8498 - accuracy: 0.5000 - val_loss: 1.0384 - val_accuracy: 0.5726\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.0303 - val_accuracy: 0.5641\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0297 - val_accuracy: 0.5641\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0340 - val_accuracy: 0.5726\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0335 - val_accuracy: 0.5726\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8453 - accuracy: 0.5222 - val_loss: 1.0308 - val_accuracy: 0.5641\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8421 - accuracy: 0.5481 - val_loss: 1.0311 - val_accuracy: 0.5726\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0318 - val_accuracy: 0.5726\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0343 - val_accuracy: 0.5726\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8469 - accuracy: 0.5481 - val_loss: 1.0321 - val_accuracy: 0.5556\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0336 - val_accuracy: 0.5726\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8436 - accuracy: 0.5444 - val_loss: 1.0336 - val_accuracy: 0.5726\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0378 - val_accuracy: 0.5726\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.0349 - val_accuracy: 0.5726\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.0309 - val_accuracy: 0.5556\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0320 - val_accuracy: 0.5556\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.8432 - accuracy: 0.5481 - val_loss: 1.0340 - val_accuracy: 0.5726\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0311 - val_accuracy: 0.5641\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 374us/step - loss: 0.8491 - accuracy: 0.5000 - val_loss: 1.0289 - val_accuracy: 0.5726\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0320 - val_accuracy: 0.5726\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 538us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8432 - accuracy: 0.5333 - val_loss: 1.0285 - val_accuracy: 0.5812\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8449 - accuracy: 0.5259 - val_loss: 1.0276 - val_accuracy: 0.5812\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8476 - accuracy: 0.5630 - val_loss: 1.0400 - val_accuracy: 0.5726\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0316 - val_accuracy: 0.5556\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8457 - accuracy: 0.5519 - val_loss: 1.0324 - val_accuracy: 0.5556\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8424 - accuracy: 0.5519 - val_loss: 1.0373 - val_accuracy: 0.5726\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0387 - val_accuracy: 0.5726\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0325 - val_accuracy: 0.5726\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8435 - accuracy: 0.5444 - val_loss: 1.0328 - val_accuracy: 0.5897\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8443 - accuracy: 0.5296 - val_loss: 1.0373 - val_accuracy: 0.5726\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0364 - val_accuracy: 0.5726\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8469 - accuracy: 0.5296 - val_loss: 1.0376 - val_accuracy: 0.5812\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8462 - accuracy: 0.5111 - val_loss: 1.0409 - val_accuracy: 0.5726\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0386 - val_accuracy: 0.5726\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8434 - accuracy: 0.5407 - val_loss: 1.0361 - val_accuracy: 0.5641\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0358 - val_accuracy: 0.5726\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.0457 - val_accuracy: 0.4957\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0355 - val_accuracy: 0.5641\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0329 - val_accuracy: 0.5641\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0369 - val_accuracy: 0.5641\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8436 - accuracy: 0.5481 - val_loss: 1.0363 - val_accuracy: 0.5641\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.0340 - val_accuracy: 0.5726\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8448 - accuracy: 0.5370 - val_loss: 1.0349 - val_accuracy: 0.5726\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0375 - val_accuracy: 0.5726\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0303 - val_accuracy: 0.5726\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0311 - val_accuracy: 0.5726\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0403 - val_accuracy: 0.5726\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8484 - accuracy: 0.5185 - val_loss: 1.0487 - val_accuracy: 0.4957\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8440 - accuracy: 0.5407 - val_loss: 1.0335 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0377 - val_accuracy: 0.5641\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0355 - val_accuracy: 0.5641\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.0381 - val_accuracy: 0.5726\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0331 - val_accuracy: 0.5641\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0321 - val_accuracy: 0.5641\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8420 - accuracy: 0.5556 - val_loss: 1.0390 - val_accuracy: 0.5726\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.0404 - val_accuracy: 0.5726\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 1.0323 - val_accuracy: 0.5641\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.0328 - val_accuracy: 0.5726\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0358 - val_accuracy: 0.5726\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8427 - accuracy: 0.5481 - val_loss: 1.0341 - val_accuracy: 0.5556\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8464 - accuracy: 0.5037 - val_loss: 1.0373 - val_accuracy: 0.5897\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8460 - accuracy: 0.5444 - val_loss: 1.0324 - val_accuracy: 0.5641\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.5726\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0351 - val_accuracy: 0.5641\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0342 - val_accuracy: 0.5641\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0382 - val_accuracy: 0.5726\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8446 - accuracy: 0.5481 - val_loss: 1.0328 - val_accuracy: 0.5556\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8437 - accuracy: 0.5481 - val_loss: 1.0365 - val_accuracy: 0.5641\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8430 - accuracy: 0.5370 - val_loss: 1.0336 - val_accuracy: 0.5556\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0370 - val_accuracy: 0.5726\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8439 - accuracy: 0.5333 - val_loss: 1.0370 - val_accuracy: 0.5726\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8411 - accuracy: 0.5481 - val_loss: 1.0365 - val_accuracy: 0.5641\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0409 - val_accuracy: 0.5726\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8435 - accuracy: 0.5519 - val_loss: 1.0393 - val_accuracy: 0.5726\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.0392 - val_accuracy: 0.5641\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8496 - accuracy: 0.5481 - val_loss: 1.0454 - val_accuracy: 0.5726\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 314us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0369 - val_accuracy: 0.5556\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0379 - val_accuracy: 0.5641\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8424 - accuracy: 0.5481 - val_loss: 1.0435 - val_accuracy: 0.5726\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8481 - accuracy: 0.5000 - val_loss: 1.0373 - val_accuracy: 0.5726\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8447 - accuracy: 0.5630 - val_loss: 1.0390 - val_accuracy: 0.5556\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.0430 - val_accuracy: 0.5641\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8420 - accuracy: 0.5519 - val_loss: 1.0426 - val_accuracy: 0.5641\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8420 - accuracy: 0.5519 - val_loss: 1.0396 - val_accuracy: 0.5641\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8431 - accuracy: 0.5333 - val_loss: 1.0392 - val_accuracy: 0.5641\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8520 - accuracy: 0.5519 - val_loss: 1.0418 - val_accuracy: 0.5726\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0424 - val_accuracy: 0.5726\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.0369 - val_accuracy: 0.5556\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.0417 - val_accuracy: 0.5556\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0410 - val_accuracy: 0.5556\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.0425 - val_accuracy: 0.5726\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0387 - val_accuracy: 0.5641\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0396 - val_accuracy: 0.5641\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.0389 - val_accuracy: 0.5641\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0359 - val_accuracy: 0.5641\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0359 - val_accuracy: 0.5556\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.0448 - val_accuracy: 0.5726\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0429 - val_accuracy: 0.5726\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 122us/step - loss: 0.8485 - accuracy: 0.5481 - val_loss: 1.0371 - val_accuracy: 0.5641\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8423 - accuracy: 0.5481 - val_loss: 1.0448 - val_accuracy: 0.5726\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.0432 - val_accuracy: 0.5641\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8475 - accuracy: 0.5111 - val_loss: 1.0418 - val_accuracy: 0.5812\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8453 - accuracy: 0.5259 - val_loss: 1.0402 - val_accuracy: 0.5556\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0444 - val_accuracy: 0.5641\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0467 - val_accuracy: 0.5726\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0412 - val_accuracy: 0.5726\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.0393 - val_accuracy: 0.5641\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0428 - val_accuracy: 0.5641\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0489 - val_accuracy: 0.5726\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8424 - accuracy: 0.5519 - val_loss: 1.0416 - val_accuracy: 0.5726\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0435 - val_accuracy: 0.5726\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8520 - accuracy: 0.5444 - val_loss: 1.0388 - val_accuracy: 0.5641\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8434 - accuracy: 0.5370 - val_loss: 1.0542 - val_accuracy: 0.4957\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8452 - accuracy: 0.5370 - val_loss: 1.0433 - val_accuracy: 0.5726\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8417 - accuracy: 0.5481 - val_loss: 1.0409 - val_accuracy: 0.5641\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8432 - accuracy: 0.5296 - val_loss: 1.0424 - val_accuracy: 0.5641\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0465 - val_accuracy: 0.5726\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0468 - val_accuracy: 0.5726\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0413 - val_accuracy: 0.5726\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0389 - val_accuracy: 0.5641\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8442 - accuracy: 0.5296 - val_loss: 1.0400 - val_accuracy: 0.5641\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0471 - val_accuracy: 0.5726\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0470 - val_accuracy: 0.5726\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.0429 - val_accuracy: 0.5556\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.0422 - val_accuracy: 0.5556\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8410 - accuracy: 0.5556 - val_loss: 1.0500 - val_accuracy: 0.5726\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0500 - val_accuracy: 0.5726\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 1.0468 - val_accuracy: 0.5641\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0429 - val_accuracy: 0.5556\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8445 - accuracy: 0.5481 - val_loss: 1.0451 - val_accuracy: 0.5641\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8523 - accuracy: 0.5519 - val_loss: 1.0490 - val_accuracy: 0.5641\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8480 - accuracy: 0.5407 - val_loss: 1.0484 - val_accuracy: 0.5897\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8418 - accuracy: 0.5185 - val_loss: 1.0413 - val_accuracy: 0.5641\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0398 - val_accuracy: 0.5641\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0469 - val_accuracy: 0.5726\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0441 - val_accuracy: 0.5726\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0467 - val_accuracy: 0.5726\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0454 - val_accuracy: 0.5726\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0459 - val_accuracy: 0.5726\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0440 - val_accuracy: 0.5726\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0415 - val_accuracy: 0.5726\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8418 - accuracy: 0.5481 - val_loss: 1.0421 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0519 - val_accuracy: 0.5726\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8479 - accuracy: 0.5074 - val_loss: 1.0444 - val_accuracy: 0.5726\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8481 - accuracy: 0.5296 - val_loss: 1.0486 - val_accuracy: 0.5726\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8408 - accuracy: 0.5444 - val_loss: 1.0440 - val_accuracy: 0.5556\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0465 - val_accuracy: 0.5641\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8414 - accuracy: 0.5481 - val_loss: 1.0438 - val_accuracy: 0.5726\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0434 - val_accuracy: 0.5726\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0438 - val_accuracy: 0.5726\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0417 - val_accuracy: 0.5726\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.0469 - val_accuracy: 0.5726\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8427 - accuracy: 0.5481 - val_loss: 1.0383 - val_accuracy: 0.5641\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8427 - accuracy: 0.5444 - val_loss: 1.0401 - val_accuracy: 0.5726\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0463 - val_accuracy: 0.5726\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0456 - val_accuracy: 0.5641\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8495 - accuracy: 0.5296 - val_loss: 1.0450 - val_accuracy: 0.5726\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8448 - accuracy: 0.5333 - val_loss: 1.0570 - val_accuracy: 0.5726\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8463 - accuracy: 0.5333 - val_loss: 1.0494 - val_accuracy: 0.5726\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8417 - accuracy: 0.5556 - val_loss: 1.0433 - val_accuracy: 0.5556\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8444 - accuracy: 0.5333 - val_loss: 1.0462 - val_accuracy: 0.5726\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8452 - accuracy: 0.5222 - val_loss: 1.0481 - val_accuracy: 0.5726\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.0492 - val_accuracy: 0.5726\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0446 - val_accuracy: 0.5641\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8426 - accuracy: 0.5444 - val_loss: 1.0449 - val_accuracy: 0.5812\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8423 - accuracy: 0.5333 - val_loss: 1.0444 - val_accuracy: 0.5641\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.0460 - val_accuracy: 0.5726\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8429 - accuracy: 0.5481 - val_loss: 1.0442 - val_accuracy: 0.5641\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0447 - val_accuracy: 0.5726\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 1.0519 - val_accuracy: 0.5726\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8394 - accuracy: 0.5481 - val_loss: 1.0465 - val_accuracy: 0.5556\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.0469 - val_accuracy: 0.5641\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8427 - accuracy: 0.5481 - val_loss: 1.0459 - val_accuracy: 0.5556\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8414 - accuracy: 0.5481 - val_loss: 1.0493 - val_accuracy: 0.5726\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0463 - val_accuracy: 0.5726\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8424 - accuracy: 0.5481 - val_loss: 1.0511 - val_accuracy: 0.5726\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0496 - val_accuracy: 0.5726\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8420 - accuracy: 0.5519 - val_loss: 1.0456 - val_accuracy: 0.5726\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 1.0430 - val_accuracy: 0.5726\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0464 - val_accuracy: 0.5726\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8413 - accuracy: 0.5519 - val_loss: 1.0491 - val_accuracy: 0.5726\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0514 - val_accuracy: 0.5726\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0468 - val_accuracy: 0.5726\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0491 - val_accuracy: 0.5726\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0488 - val_accuracy: 0.5726\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0467 - val_accuracy: 0.5556\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8472 - accuracy: 0.5593 - val_loss: 1.0502 - val_accuracy: 0.5726\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0454 - val_accuracy: 0.5726\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0492 - val_accuracy: 0.5726\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0529 - val_accuracy: 0.5726\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0444 - val_accuracy: 0.5726\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8455 - accuracy: 0.5481 - val_loss: 1.0469 - val_accuracy: 0.5726\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0561 - val_accuracy: 0.5726\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0540 - val_accuracy: 0.5726\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 1.0521 - val_accuracy: 0.5641\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0510 - val_accuracy: 0.5641\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.0549 - val_accuracy: 0.5726\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0538 - val_accuracy: 0.5726\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0518 - val_accuracy: 0.5726\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0478 - val_accuracy: 0.5726\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0458 - val_accuracy: 0.5726\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0457 - val_accuracy: 0.5726\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0521 - val_accuracy: 0.5726\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0460 - val_accuracy: 0.5726\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8519 - accuracy: 0.5519 - val_loss: 1.0484 - val_accuracy: 0.5726\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8422 - accuracy: 0.5148 - val_loss: 1.0471 - val_accuracy: 0.5897\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 96us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0444 - val_accuracy: 0.5726\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0471 - val_accuracy: 0.5726\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.0472 - val_accuracy: 0.5726\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8424 - accuracy: 0.5519 - val_loss: 1.0471 - val_accuracy: 0.5726\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.37 - 0s 109us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0515 - val_accuracy: 0.5726\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0452 - val_accuracy: 0.5726\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8486 - accuracy: 0.5444 - val_loss: 1.0443 - val_accuracy: 0.5556\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8494 - accuracy: 0.5519 - val_loss: 1.0553 - val_accuracy: 0.5726\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8452 - accuracy: 0.5481 - val_loss: 1.0452 - val_accuracy: 0.5641\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8420 - accuracy: 0.5407 - val_loss: 1.0461 - val_accuracy: 0.5556\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8412 - accuracy: 0.5556 - val_loss: 1.0455 - val_accuracy: 0.5641\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0525 - val_accuracy: 0.5726\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0483 - val_accuracy: 0.5726\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0490 - val_accuracy: 0.5726\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0501 - val_accuracy: 0.5726\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8420 - accuracy: 0.5519 - val_loss: 1.0489 - val_accuracy: 0.5726\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0484 - val_accuracy: 0.5726\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0486 - val_accuracy: 0.5726\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.0503 - val_accuracy: 0.5726\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8430 - accuracy: 0.5259 - val_loss: 1.0493 - val_accuracy: 0.5812\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8415 - accuracy: 0.5185 - val_loss: 1.0496 - val_accuracy: 0.5726\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0529 - val_accuracy: 0.5726\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0462 - val_accuracy: 0.5556\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.0482 - val_accuracy: 0.5641\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8426 - accuracy: 0.5481 - val_loss: 1.0493 - val_accuracy: 0.5726\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0492 - val_accuracy: 0.5726\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0479 - val_accuracy: 0.5726\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8481 - accuracy: 0.5444 - val_loss: 1.0623 - val_accuracy: 0.5897\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8409 - accuracy: 0.5407 - val_loss: 1.0516 - val_accuracy: 0.5641\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0516 - val_accuracy: 0.5726\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8513 - accuracy: 0.5370 - val_loss: 1.0633 - val_accuracy: 0.4957\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8435 - accuracy: 0.5296 - val_loss: 1.0538 - val_accuracy: 0.5812\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8450 - accuracy: 0.5037 - val_loss: 1.0505 - val_accuracy: 0.5641\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8414 - accuracy: 0.5481 - val_loss: 1.0493 - val_accuracy: 0.5641\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8444 - accuracy: 0.5481 - val_loss: 1.0496 - val_accuracy: 0.5641\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8428 - accuracy: 0.5444 - val_loss: 1.0551 - val_accuracy: 0.5726\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0543 - val_accuracy: 0.5726\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0525 - val_accuracy: 0.5641\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0475 - val_accuracy: 0.5641\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8418 - accuracy: 0.5481 - val_loss: 1.0503 - val_accuracy: 0.5641\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0580 - val_accuracy: 0.5726\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0520 - val_accuracy: 0.5726\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8476 - accuracy: 0.5519 - val_loss: 1.0536 - val_accuracy: 0.5726\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0484 - val_accuracy: 0.5641\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0500 - val_accuracy: 0.5641\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8447 - accuracy: 0.5481 - val_loss: 1.0553 - val_accuracy: 0.5726\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0510 - val_accuracy: 0.5726\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0492 - val_accuracy: 0.5726\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8421 - accuracy: 0.5333 - val_loss: 1.0543 - val_accuracy: 0.5726\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8426 - accuracy: 0.5296 - val_loss: 1.0587 - val_accuracy: 0.4957\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8406 - accuracy: 0.5556 - val_loss: 1.0509 - val_accuracy: 0.5726\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0507 - val_accuracy: 0.5641\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0538 - val_accuracy: 0.5726\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.0640 - val_accuracy: 0.5726\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0541 - val_accuracy: 0.5641\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8415 - accuracy: 0.5444 - val_loss: 1.0541 - val_accuracy: 0.5812\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8416 - accuracy: 0.5185 - val_loss: 1.0537 - val_accuracy: 0.5641\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8433 - accuracy: 0.5481 - val_loss: 1.0518 - val_accuracy: 0.5726\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0603 - val_accuracy: 0.5726\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0535 - val_accuracy: 0.5641\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8413 - accuracy: 0.5519 - val_loss: 1.0522 - val_accuracy: 0.5641\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8443 - accuracy: 0.4778 - val_loss: 1.0547 - val_accuracy: 0.5641\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8405 - accuracy: 0.5556 - val_loss: 1.0556 - val_accuracy: 0.5726\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0632 - val_accuracy: 0.5641\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.0545 - val_accuracy: 0.5641\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.0513 - val_accuracy: 0.5556\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8436 - accuracy: 0.5481 - val_loss: 1.0561 - val_accuracy: 0.5726\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0564 - val_accuracy: 0.5556\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8416 - accuracy: 0.5185 - val_loss: 1.0564 - val_accuracy: 0.5726\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8416 - accuracy: 0.5370 - val_loss: 1.0553 - val_accuracy: 0.5726\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8409 - accuracy: 0.5444 - val_loss: 1.0561 - val_accuracy: 0.5641\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8410 - accuracy: 0.5481 - val_loss: 1.0557 - val_accuracy: 0.5556\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8424 - accuracy: 0.5259 - val_loss: 1.0538 - val_accuracy: 0.5726\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8421 - accuracy: 0.5296 - val_loss: 1.0560 - val_accuracy: 0.5556\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8414 - accuracy: 0.5407 - val_loss: 1.0603 - val_accuracy: 0.5726\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0573 - val_accuracy: 0.5726\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8389 - accuracy: 0.5370 - val_loss: 1.0677 - val_accuracy: 0.4957\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8456 - accuracy: 0.4926 - val_loss: 1.0559 - val_accuracy: 0.5726\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8409 - accuracy: 0.5444 - val_loss: 1.0530 - val_accuracy: 0.5726\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0547 - val_accuracy: 0.5726\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0620 - val_accuracy: 0.5726\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8440 - accuracy: 0.5481 - val_loss: 1.0552 - val_accuracy: 0.5641\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0568 - val_accuracy: 0.5641\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8420 - accuracy: 0.5481 - val_loss: 1.0542 - val_accuracy: 0.5641\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8435 - accuracy: 0.5037 - val_loss: 1.0586 - val_accuracy: 0.5641\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8394 - accuracy: 0.5519 - val_loss: 1.0579 - val_accuracy: 0.5726\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.0632 - val_accuracy: 0.5726\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8427 - accuracy: 0.5481 - val_loss: 1.0583 - val_accuracy: 0.5897\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8431 - accuracy: 0.5222 - val_loss: 1.0551 - val_accuracy: 0.5641\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0647 - val_accuracy: 0.5726\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0584 - val_accuracy: 0.5726\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0574 - val_accuracy: 0.5641\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0579 - val_accuracy: 0.5641\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0586 - val_accuracy: 0.5641\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0645 - val_accuracy: 0.5641\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8432 - accuracy: 0.5481 - val_loss: 1.0626 - val_accuracy: 0.5726\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8423 - accuracy: 0.5333 - val_loss: 1.0599 - val_accuracy: 0.5641\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0619 - val_accuracy: 0.5641\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8425 - accuracy: 0.5444 - val_loss: 1.0601 - val_accuracy: 0.5641\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8498 - accuracy: 0.5481 - val_loss: 1.0615 - val_accuracy: 0.5641\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8400 - accuracy: 0.5481 - val_loss: 1.0578 - val_accuracy: 0.5812\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8452 - accuracy: 0.5333 - val_loss: 1.0605 - val_accuracy: 0.5726\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0535 - val_accuracy: 0.5641\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0599 - val_accuracy: 0.5726\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8446 - accuracy: 0.5481 - val_loss: 1.0548 - val_accuracy: 0.5556\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0611 - val_accuracy: 0.5726\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0591 - val_accuracy: 0.5726\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0606 - val_accuracy: 0.5726\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0590 - val_accuracy: 0.5556\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 69us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0576 - val_accuracy: 0.5556\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0606 - val_accuracy: 0.5556\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8389 - accuracy: 0.5481 - val_loss: 1.0650 - val_accuracy: 0.5726\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8427 - accuracy: 0.5444 - val_loss: 1.0691 - val_accuracy: 0.5726\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8424 - accuracy: 0.5556 - val_loss: 1.0581 - val_accuracy: 0.5556\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8446 - accuracy: 0.5296 - val_loss: 1.0584 - val_accuracy: 0.5556\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8401 - accuracy: 0.5481 - val_loss: 1.0679 - val_accuracy: 0.5726\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0640 - val_accuracy: 0.5726\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0589 - val_accuracy: 0.5897\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8414 - accuracy: 0.5074 - val_loss: 1.0557 - val_accuracy: 0.5641\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8469 - accuracy: 0.5000 - val_loss: 1.0551 - val_accuracy: 0.5812\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.0609 - val_accuracy: 0.5641\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8408 - accuracy: 0.5481 - val_loss: 1.0651 - val_accuracy: 0.5726\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 1.0604 - val_accuracy: 0.5641\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8413 - accuracy: 0.5481 - val_loss: 1.0600 - val_accuracy: 0.5641\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0630 - val_accuracy: 0.5726\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0626 - val_accuracy: 0.5726\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.0578 - val_accuracy: 0.5556\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8377 - accuracy: 0.5519 - val_loss: 1.0655 - val_accuracy: 0.5726\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8449 - accuracy: 0.5222 - val_loss: 1.0692 - val_accuracy: 0.5726\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.0583 - val_accuracy: 0.5641\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0640 - val_accuracy: 0.5641\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8416 - accuracy: 0.5556 - val_loss: 1.0600 - val_accuracy: 0.5641\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0603 - val_accuracy: 0.5641\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0662 - val_accuracy: 0.5726\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0626 - val_accuracy: 0.5726\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0598 - val_accuracy: 0.5641\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0615 - val_accuracy: 0.5726\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0670 - val_accuracy: 0.5726\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0584 - val_accuracy: 0.5726\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8425 - accuracy: 0.5444 - val_loss: 1.0606 - val_accuracy: 0.5641\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8414 - accuracy: 0.5556 - val_loss: 1.0655 - val_accuracy: 0.5726\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0653 - val_accuracy: 0.5641\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8424 - accuracy: 0.5519 - val_loss: 1.0583 - val_accuracy: 0.5641\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0625 - val_accuracy: 0.5641\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8393 - accuracy: 0.5481 - val_loss: 1.0649 - val_accuracy: 0.5641\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0631 - val_accuracy: 0.5641\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0628 - val_accuracy: 0.5641\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8416 - accuracy: 0.5481 - val_loss: 1.0570 - val_accuracy: 0.5726\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0622 - val_accuracy: 0.5726\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0587 - val_accuracy: 0.5726\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8405 - accuracy: 0.5481 - val_loss: 1.0586 - val_accuracy: 0.5726\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0621 - val_accuracy: 0.5726\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8413 - accuracy: 0.5481 - val_loss: 1.0641 - val_accuracy: 0.5641\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0612 - val_accuracy: 0.5641\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8409 - accuracy: 0.5481 - val_loss: 1.0666 - val_accuracy: 0.5726\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.0672 - val_accuracy: 0.5726\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0639 - val_accuracy: 0.5726\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0597 - val_accuracy: 0.5641\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0617 - val_accuracy: 0.5641\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0624 - val_accuracy: 0.5726\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0657 - val_accuracy: 0.5726\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0605 - val_accuracy: 0.5726\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 1.0601 - val_accuracy: 0.5726\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0688 - val_accuracy: 0.5726\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0687 - val_accuracy: 0.5726\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8441 - accuracy: 0.5185 - val_loss: 1.0746 - val_accuracy: 0.5726\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0701 - val_accuracy: 0.5726\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8396 - accuracy: 0.5296 - val_loss: 1.0669 - val_accuracy: 0.5812\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8445 - accuracy: 0.5074 - val_loss: 1.0620 - val_accuracy: 0.5641\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.0694 - val_accuracy: 0.4957\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8415 - accuracy: 0.5481 - val_loss: 1.0667 - val_accuracy: 0.5726\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0673 - val_accuracy: 0.5726\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8404 - accuracy: 0.5481 - val_loss: 1.0657 - val_accuracy: 0.5641\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 1.0672 - val_accuracy: 0.5726\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8464 - accuracy: 0.5519 - val_loss: 1.0636 - val_accuracy: 0.5641\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0715 - val_accuracy: 0.5641\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8437 - accuracy: 0.5185 - val_loss: 1.0689 - val_accuracy: 0.5812\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8436 - accuracy: 0.5259 - val_loss: 1.0627 - val_accuracy: 0.5641\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0702 - val_accuracy: 0.5641\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0645 - val_accuracy: 0.5641\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.0698 - val_accuracy: 0.5726\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8468 - accuracy: 0.5148 - val_loss: 1.0679 - val_accuracy: 0.5556\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0662 - val_accuracy: 0.5556\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8409 - accuracy: 0.5444 - val_loss: 1.0752 - val_accuracy: 0.5726\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 295us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0670 - val_accuracy: 0.5726\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8462 - accuracy: 0.5481 - val_loss: 1.0629 - val_accuracy: 0.5556\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8420 - accuracy: 0.5481 - val_loss: 1.0709 - val_accuracy: 0.5726\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0726 - val_accuracy: 0.5726\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0644 - val_accuracy: 0.5641\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0599 - val_accuracy: 0.5641\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8408 - accuracy: 0.5444 - val_loss: 1.0694 - val_accuracy: 0.5726\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0676 - val_accuracy: 0.5641\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0633 - val_accuracy: 0.5641\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 379us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0666 - val_accuracy: 0.5641\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8404 - accuracy: 0.5519 - val_loss: 1.0737 - val_accuracy: 0.5726\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0695 - val_accuracy: 0.5726\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8447 - accuracy: 0.5185 - val_loss: 1.0640 - val_accuracy: 0.5726\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8455 - accuracy: 0.5259 - val_loss: 1.0644 - val_accuracy: 0.5641\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8403 - accuracy: 0.5481 - val_loss: 1.0687 - val_accuracy: 0.5726\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0706 - val_accuracy: 0.5726\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8459 - accuracy: 0.5000 - val_loss: 1.0635 - val_accuracy: 0.5897\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.0716 - val_accuracy: 0.5726\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.0670 - val_accuracy: 0.5726\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8391 - accuracy: 0.5481 - val_loss: 1.0654 - val_accuracy: 0.5641\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0701 - val_accuracy: 0.5641\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0722 - val_accuracy: 0.5641\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0682 - val_accuracy: 0.5641\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8397 - accuracy: 0.5556 - val_loss: 1.0715 - val_accuracy: 0.5726\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0730 - val_accuracy: 0.5726\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8401 - accuracy: 0.5259 - val_loss: 1.0665 - val_accuracy: 0.5812\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0662 - val_accuracy: 0.5641\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0743 - val_accuracy: 0.5726\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0685 - val_accuracy: 0.5726\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8404 - accuracy: 0.5519 - val_loss: 1.0699 - val_accuracy: 0.5726\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8448 - accuracy: 0.5370 - val_loss: 1.0789 - val_accuracy: 0.5726\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8397 - accuracy: 0.5481 - val_loss: 1.0657 - val_accuracy: 0.5641\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8421 - accuracy: 0.5444 - val_loss: 1.0669 - val_accuracy: 0.5641\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8436 - accuracy: 0.5481 - val_loss: 1.0714 - val_accuracy: 0.5726\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0675 - val_accuracy: 0.5726\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 102us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0666 - val_accuracy: 0.5726\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0609 - val_accuracy: 0.5726\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0622 - val_accuracy: 0.5556\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0690 - val_accuracy: 0.5726\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0701 - val_accuracy: 0.5641\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0665 - val_accuracy: 0.5641\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0660 - val_accuracy: 0.5556\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8485 - accuracy: 0.5074 - val_loss: 1.0709 - val_accuracy: 0.5726\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8450 - accuracy: 0.5148 - val_loss: 1.0669 - val_accuracy: 0.5641\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0666 - val_accuracy: 0.5641\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.0714 - val_accuracy: 0.5726\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0652 - val_accuracy: 0.5726\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0691 - val_accuracy: 0.5726\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0689 - val_accuracy: 0.5556\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0689 - val_accuracy: 0.5556\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0695 - val_accuracy: 0.5726\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8425 - accuracy: 0.5444 - val_loss: 1.0653 - val_accuracy: 0.5556\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0684 - val_accuracy: 0.5726\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0760 - val_accuracy: 0.5726\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0688 - val_accuracy: 0.5641\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0705 - val_accuracy: 0.5556\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0725 - val_accuracy: 0.5641\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0778 - val_accuracy: 0.5641\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0761 - val_accuracy: 0.5641\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8408 - accuracy: 0.5556 - val_loss: 1.0686 - val_accuracy: 0.5726\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8422 - accuracy: 0.5111 - val_loss: 1.0642 - val_accuracy: 0.5726\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8456 - accuracy: 0.5370 - val_loss: 1.0725 - val_accuracy: 0.5726\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8392 - accuracy: 0.5481 - val_loss: 1.0658 - val_accuracy: 0.5641\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8414 - accuracy: 0.5222 - val_loss: 1.0674 - val_accuracy: 0.5812\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8398 - accuracy: 0.5444 - val_loss: 1.0760 - val_accuracy: 0.5726\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.0700 - val_accuracy: 0.5726\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8404 - accuracy: 0.5519 - val_loss: 1.0710 - val_accuracy: 0.5726\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8399 - accuracy: 0.5481 - val_loss: 1.0697 - val_accuracy: 0.5641\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8420 - accuracy: 0.5556 - val_loss: 1.0736 - val_accuracy: 0.5726\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8437 - accuracy: 0.5444 - val_loss: 1.0661 - val_accuracy: 0.5726\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8440 - accuracy: 0.5185 - val_loss: 1.0660 - val_accuracy: 0.5726\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8415 - accuracy: 0.5481 - val_loss: 1.0707 - val_accuracy: 0.5726\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8429 - accuracy: 0.5444 - val_loss: 1.0687 - val_accuracy: 0.5641\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 1.0691 - val_accuracy: 0.5556\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0683 - val_accuracy: 0.5556\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8430 - accuracy: 0.5296 - val_loss: 1.0697 - val_accuracy: 0.5812\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8439 - accuracy: 0.5333 - val_loss: 1.0739 - val_accuracy: 0.5726\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.0695 - val_accuracy: 0.5641\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0672 - val_accuracy: 0.5556\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8420 - accuracy: 0.5519 - val_loss: 1.0710 - val_accuracy: 0.5726\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8394 - accuracy: 0.5407 - val_loss: 1.0713 - val_accuracy: 0.5897\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8428 - accuracy: 0.5111 - val_loss: 1.0754 - val_accuracy: 0.5726\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.0671 - val_accuracy: 0.5641\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0698 - val_accuracy: 0.5641\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0770 - val_accuracy: 0.5726\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0703 - val_accuracy: 0.5641\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 434us/step - loss: 0.8424 - accuracy: 0.5074 - val_loss: 1.0692 - val_accuracy: 0.5726\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8438 - accuracy: 0.5259 - val_loss: 1.0672 - val_accuracy: 0.5641\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8405 - accuracy: 0.5556 - val_loss: 1.0722 - val_accuracy: 0.5726\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.0764 - val_accuracy: 0.5726\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0730 - val_accuracy: 0.5726\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8644 - accuracy: 0.53 - 0s 195us/step - loss: 0.8421 - accuracy: 0.5037 - val_loss: 1.0682 - val_accuracy: 0.5726\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8435 - accuracy: 0.5370 - val_loss: 1.0715 - val_accuracy: 0.5726\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8385 - accuracy: 0.5519 - val_loss: 1.0768 - val_accuracy: 0.5726\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8432 - accuracy: 0.5185 - val_loss: 1.0800 - val_accuracy: 0.5726\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.0695 - val_accuracy: 0.5556\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0715 - val_accuracy: 0.5726\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0766 - val_accuracy: 0.5726\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0748 - val_accuracy: 0.5726\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0769 - val_accuracy: 0.5726\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0680 - val_accuracy: 0.5726\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0740 - val_accuracy: 0.5726\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8430 - accuracy: 0.5111 - val_loss: 1.0702 - val_accuracy: 0.5812\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8450 - accuracy: 0.5407 - val_loss: 1.0713 - val_accuracy: 0.5641\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8438 - accuracy: 0.5407 - val_loss: 1.0787 - val_accuracy: 0.5726\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8440 - accuracy: 0.5296 - val_loss: 1.0735 - val_accuracy: 0.5812\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8432 - accuracy: 0.5333 - val_loss: 1.0688 - val_accuracy: 0.5641\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0768 - val_accuracy: 0.5726\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0792 - val_accuracy: 0.5726\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.0728 - val_accuracy: 0.5641\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8404 - accuracy: 0.5333 - val_loss: 1.0729 - val_accuracy: 0.5812\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8427 - accuracy: 0.5185 - val_loss: 1.0700 - val_accuracy: 0.5897\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8363 - accuracy: 0.5593 - val_loss: 1.0728 - val_accuracy: 0.5726\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0737 - val_accuracy: 0.5726\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0780 - val_accuracy: 0.5726\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0697 - val_accuracy: 0.5726\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.0720 - val_accuracy: 0.5726\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8406 - accuracy: 0.5296 - val_loss: 1.0722 - val_accuracy: 0.5812\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8402 - accuracy: 0.5481 - val_loss: 1.0744 - val_accuracy: 0.5641\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0737 - val_accuracy: 0.5726\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8428 - accuracy: 0.5481 - val_loss: 1.0761 - val_accuracy: 0.5726\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0807 - val_accuracy: 0.5726\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8402 - accuracy: 0.5185 - val_loss: 1.0737 - val_accuracy: 0.5556\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8393 - accuracy: 0.5481 - val_loss: 1.0751 - val_accuracy: 0.5556\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8403 - accuracy: 0.5481 - val_loss: 1.0735 - val_accuracy: 0.5556\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8394 - accuracy: 0.5481 - val_loss: 1.0791 - val_accuracy: 0.5641\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.0802 - val_accuracy: 0.5726\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8391 - accuracy: 0.5556 - val_loss: 1.0748 - val_accuracy: 0.5641\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8418 - accuracy: 0.5481 - val_loss: 1.0767 - val_accuracy: 0.5641\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0737 - val_accuracy: 0.5641\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8399 - accuracy: 0.5519 - val_loss: 1.0750 - val_accuracy: 0.5641\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.0734 - val_accuracy: 0.5641\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8412 - accuracy: 0.5222 - val_loss: 1.0703 - val_accuracy: 0.5726\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8421 - accuracy: 0.5259 - val_loss: 1.0739 - val_accuracy: 0.5641\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8423 - accuracy: 0.5481 - val_loss: 1.0764 - val_accuracy: 0.5726\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0767 - val_accuracy: 0.5726\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.0750 - val_accuracy: 0.5641\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8413 - accuracy: 0.5519 - val_loss: 1.0767 - val_accuracy: 0.5641\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0743 - val_accuracy: 0.5556\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0751 - val_accuracy: 0.5556\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8396 - accuracy: 0.5444 - val_loss: 1.0896 - val_accuracy: 0.5726\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8429 - accuracy: 0.5185 - val_loss: 1.0823 - val_accuracy: 0.5556\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.0824 - val_accuracy: 0.5556\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.0869 - val_accuracy: 0.5726\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8487 - accuracy: 0.4741 - val_loss: 1.0836 - val_accuracy: 0.5726\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 147us/step - loss: 0.8420 - accuracy: 0.5556 - val_loss: 1.0843 - val_accuracy: 0.5726\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8448 - accuracy: 0.5481 - val_loss: 1.0787 - val_accuracy: 0.5556\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8403 - accuracy: 0.5481 - val_loss: 1.0829 - val_accuracy: 0.5726\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.0848 - val_accuracy: 0.5726\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0830 - val_accuracy: 0.5726\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8386 - accuracy: 0.5556 - val_loss: 1.0759 - val_accuracy: 0.5641\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0774 - val_accuracy: 0.5641\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0809 - val_accuracy: 0.5641\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0861 - val_accuracy: 0.5726\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0778 - val_accuracy: 0.5641\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0823 - val_accuracy: 0.5726\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.0833 - val_accuracy: 0.5726\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8397 - accuracy: 0.5481 - val_loss: 1.0800 - val_accuracy: 0.5641\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8426 - accuracy: 0.5481 - val_loss: 1.0815 - val_accuracy: 0.5556\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8384 - accuracy: 0.5519 - val_loss: 1.0760 - val_accuracy: 0.5556\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8503 - accuracy: 0.5556 - val_loss: 1.0782 - val_accuracy: 0.5641\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8452 - accuracy: 0.5296 - val_loss: 1.0873 - val_accuracy: 0.5897\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8413 - accuracy: 0.5296 - val_loss: 1.0780 - val_accuracy: 0.5641\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.0783 - val_accuracy: 0.5641\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0814 - val_accuracy: 0.5641\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0803 - val_accuracy: 0.5641\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0823 - val_accuracy: 0.5641\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0840 - val_accuracy: 0.5641\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0774 - val_accuracy: 0.5641\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8412 - accuracy: 0.5148 - val_loss: 1.0780 - val_accuracy: 0.5556\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8380 - accuracy: 0.5519 - val_loss: 1.0853 - val_accuracy: 0.5641\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0832 - val_accuracy: 0.5641\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8445 - accuracy: 0.5222 - val_loss: 1.0811 - val_accuracy: 0.5726\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8404 - accuracy: 0.5074 - val_loss: 1.0798 - val_accuracy: 0.5641\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0838 - val_accuracy: 0.5641\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8399 - accuracy: 0.5519 - val_loss: 1.0803 - val_accuracy: 0.5641\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0787 - val_accuracy: 0.5641\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8425 - accuracy: 0.5259 - val_loss: 1.0831 - val_accuracy: 0.5641\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.0839 - val_accuracy: 0.5641\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8402 - accuracy: 0.5481 - val_loss: 1.0832 - val_accuracy: 0.5726\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8408 - accuracy: 0.5444 - val_loss: 1.0804 - val_accuracy: 0.5812\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8400 - accuracy: 0.5259 - val_loss: 1.0820 - val_accuracy: 0.5641\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8451 - accuracy: 0.5370 - val_loss: 1.0916 - val_accuracy: 0.5726\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8391 - accuracy: 0.5519 - val_loss: 1.0829 - val_accuracy: 0.5641\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8399 - accuracy: 0.5519 - val_loss: 1.0794 - val_accuracy: 0.5556\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0819 - val_accuracy: 0.5641\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0847 - val_accuracy: 0.5726\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0870 - val_accuracy: 0.5726\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0874 - val_accuracy: 0.5726\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8431 - accuracy: 0.5407 - val_loss: 1.0781 - val_accuracy: 0.5556\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0820 - val_accuracy: 0.5726\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8416 - accuracy: 0.5296 - val_loss: 1.0901 - val_accuracy: 0.5726\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8399 - accuracy: 0.5481 - val_loss: 1.0829 - val_accuracy: 0.5556\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0866 - val_accuracy: 0.5641\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0846 - val_accuracy: 0.5641\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8407 - accuracy: 0.5481 - val_loss: 1.0809 - val_accuracy: 0.5641\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0829 - val_accuracy: 0.5726\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0831 - val_accuracy: 0.5726\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8386 - accuracy: 0.5556 - val_loss: 1.0816 - val_accuracy: 0.5556\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0844 - val_accuracy: 0.5556\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8415 - accuracy: 0.5481 - val_loss: 1.0889 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8408 - accuracy: 0.5481 - val_loss: 1.0840 - val_accuracy: 0.5556\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0833 - val_accuracy: 0.5556\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0823 - val_accuracy: 0.5556\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8411 - accuracy: 0.5556 - val_loss: 1.0867 - val_accuracy: 0.5726\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0820 - val_accuracy: 0.5726\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8398 - accuracy: 0.5444 - val_loss: 1.0823 - val_accuracy: 0.5556\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8411 - accuracy: 0.5444 - val_loss: 1.0820 - val_accuracy: 0.5556\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8420 - accuracy: 0.5333 - val_loss: 1.0840 - val_accuracy: 0.5897\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0811 - val_accuracy: 0.5726\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0820 - val_accuracy: 0.5726\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8415 - accuracy: 0.5481 - val_loss: 1.0855 - val_accuracy: 0.5726\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.0822 - val_accuracy: 0.5726\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0809 - val_accuracy: 0.5726\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8457 - accuracy: 0.5296 - val_loss: 1.0918 - val_accuracy: 0.4957\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.0820 - val_accuracy: 0.5726\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0793 - val_accuracy: 0.5641\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8420 - accuracy: 0.5222 - val_loss: 1.0879 - val_accuracy: 0.5726\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8488 - accuracy: 0.5222 - val_loss: 1.0907 - val_accuracy: 0.5726\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8479 - accuracy: 0.5444 - val_loss: 1.0785 - val_accuracy: 0.5726\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8413 - accuracy: 0.5259 - val_loss: 1.0827 - val_accuracy: 0.5812\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8399 - accuracy: 0.5333 - val_loss: 1.0851 - val_accuracy: 0.5726\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0920 - val_accuracy: 0.5726\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.0839 - val_accuracy: 0.5641\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0868 - val_accuracy: 0.5726\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8423 - accuracy: 0.5519 - val_loss: 1.0865 - val_accuracy: 0.5726\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.0854 - val_accuracy: 0.5726\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.0843 - val_accuracy: 0.5641\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.0869 - val_accuracy: 0.5726\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.0930 - val_accuracy: 0.5726\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8455 - accuracy: 0.5519 - val_loss: 1.0852 - val_accuracy: 0.5641\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.0846 - val_accuracy: 0.5641\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8385 - accuracy: 0.5481 - val_loss: 1.0871 - val_accuracy: 0.5726\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0920 - val_accuracy: 0.5726\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8413 - accuracy: 0.5519 - val_loss: 1.0876 - val_accuracy: 0.5726\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8379 - accuracy: 0.5519 - val_loss: 1.0832 - val_accuracy: 0.5556\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8413 - accuracy: 0.5556 - val_loss: 1.0864 - val_accuracy: 0.5641\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0824 - val_accuracy: 0.5641\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8425 - accuracy: 0.5074 - val_loss: 1.0902 - val_accuracy: 0.4872\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8405 - accuracy: 0.5296 - val_loss: 1.0808 - val_accuracy: 0.5641\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0783 - val_accuracy: 0.5641\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8393 - accuracy: 0.5481 - val_loss: 1.0825 - val_accuracy: 0.5726\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0835 - val_accuracy: 0.5726\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8384 - accuracy: 0.5519 - val_loss: 1.0822 - val_accuracy: 0.5641\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.0832 - val_accuracy: 0.5556\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8400 - accuracy: 0.5296 - val_loss: 1.0870 - val_accuracy: 0.5812\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8404 - accuracy: 0.5519 - val_loss: 1.0867 - val_accuracy: 0.5726\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8395 - accuracy: 0.5556 - val_loss: 1.0884 - val_accuracy: 0.5556\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0860 - val_accuracy: 0.5556\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0827 - val_accuracy: 0.5556\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0879 - val_accuracy: 0.5641\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0853 - val_accuracy: 0.5641\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8384 - accuracy: 0.5519 - val_loss: 1.0829 - val_accuracy: 0.5556\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8408 - accuracy: 0.5222 - val_loss: 1.0834 - val_accuracy: 0.5556\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0856 - val_accuracy: 0.5641\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8395 - accuracy: 0.5481 - val_loss: 1.0848 - val_accuracy: 0.5726\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0818 - val_accuracy: 0.5556\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0803 - val_accuracy: 0.5556\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0824 - val_accuracy: 0.5641\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 1.0885 - val_accuracy: 0.5641\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0875 - val_accuracy: 0.5726\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8375 - accuracy: 0.5556 - val_loss: 1.0814 - val_accuracy: 0.5556\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0814 - val_accuracy: 0.5556\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8391 - accuracy: 0.5519 - val_loss: 1.0850 - val_accuracy: 0.5641\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8381 - accuracy: 0.5519 - val_loss: 1.0878 - val_accuracy: 0.5726\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8383 - accuracy: 0.5519 - val_loss: 1.0876 - val_accuracy: 0.5726\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8405 - accuracy: 0.5481 - val_loss: 1.0839 - val_accuracy: 0.5641\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8408 - accuracy: 0.5185 - val_loss: 1.0840 - val_accuracy: 0.5726\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8415 - accuracy: 0.5519 - val_loss: 1.0868 - val_accuracy: 0.5726\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.0851 - val_accuracy: 0.5641\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8426 - accuracy: 0.5259 - val_loss: 1.0944 - val_accuracy: 0.5812\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8408 - accuracy: 0.5481 - val_loss: 1.0843 - val_accuracy: 0.5641\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.0876 - val_accuracy: 0.5641\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.0915 - val_accuracy: 0.5726\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8438 - accuracy: 0.5259 - val_loss: 1.0849 - val_accuracy: 0.5812\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8418 - accuracy: 0.5222 - val_loss: 1.0864 - val_accuracy: 0.5726\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.0891 - val_accuracy: 0.5726\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8426 - accuracy: 0.5481 - val_loss: 1.0852 - val_accuracy: 0.5641\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8395 - accuracy: 0.5481 - val_loss: 1.0935 - val_accuracy: 0.5726\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0882 - val_accuracy: 0.5726\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8427 - accuracy: 0.5481 - val_loss: 1.0840 - val_accuracy: 0.5641\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8383 - accuracy: 0.5519 - val_loss: 1.0880 - val_accuracy: 0.5726\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8458 - accuracy: 0.5370 - val_loss: 1.0973 - val_accuracy: 0.4957\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8410 - accuracy: 0.5481 - val_loss: 1.0866 - val_accuracy: 0.5726\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0855 - val_accuracy: 0.5726\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0879 - val_accuracy: 0.5726\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0870 - val_accuracy: 0.5726\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0915 - val_accuracy: 0.5726\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.0911 - val_accuracy: 0.5726\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8385 - accuracy: 0.5519 - val_loss: 1.0868 - val_accuracy: 0.5726\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0804 - val_accuracy: 0.5726\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0863 - val_accuracy: 0.5726\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0911 - val_accuracy: 0.5641\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8397 - accuracy: 0.5481 - val_loss: 1.0885 - val_accuracy: 0.5556\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8391 - accuracy: 0.5481 - val_loss: 1.0974 - val_accuracy: 0.5726\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.0927 - val_accuracy: 0.5641\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8390 - accuracy: 0.5481 - val_loss: 1.0917 - val_accuracy: 0.5556\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8389 - accuracy: 0.5519 - val_loss: 1.0938 - val_accuracy: 0.5641\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8412 - accuracy: 0.5481 - val_loss: 1.0908 - val_accuracy: 0.5641\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8397 - accuracy: 0.5481 - val_loss: 1.0932 - val_accuracy: 0.5726\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0892 - val_accuracy: 0.5641\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8389 - accuracy: 0.5519 - val_loss: 1.0938 - val_accuracy: 0.5641\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8392 - accuracy: 0.5444 - val_loss: 1.0953 - val_accuracy: 0.5556\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8371 - accuracy: 0.5519 - val_loss: 1.0914 - val_accuracy: 0.5556\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8393 - accuracy: 0.5519 - val_loss: 1.0894 - val_accuracy: 0.5556\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0906 - val_accuracy: 0.5556\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8386 - accuracy: 0.5519 - val_loss: 1.0988 - val_accuracy: 0.5726\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8420 - accuracy: 0.5444 - val_loss: 1.0951 - val_accuracy: 0.5556\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0934 - val_accuracy: 0.5556\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8415 - accuracy: 0.5407 - val_loss: 1.0980 - val_accuracy: 0.5641\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8422 - accuracy: 0.5444 - val_loss: 1.0931 - val_accuracy: 0.5556\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 97us/step - loss: 0.8381 - accuracy: 0.5519 - val_loss: 1.0948 - val_accuracy: 0.5556\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0955 - val_accuracy: 0.5556\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0943 - val_accuracy: 0.5641\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0965 - val_accuracy: 0.5726\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8444 - accuracy: 0.5185 - val_loss: 1.0905 - val_accuracy: 0.5556\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 431us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0936 - val_accuracy: 0.5641\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 660us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.1000 - val_accuracy: 0.5726\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0945 - val_accuracy: 0.5726\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0870 - val_accuracy: 0.5726\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.0868 - val_accuracy: 0.5556\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0912 - val_accuracy: 0.5641\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8410 - accuracy: 0.5481 - val_loss: 1.0989 - val_accuracy: 0.5726\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.0965 - val_accuracy: 0.5641\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8383 - accuracy: 0.5519 - val_loss: 1.0923 - val_accuracy: 0.5556\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8411 - accuracy: 0.5519 - val_loss: 1.0922 - val_accuracy: 0.5556\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8412 - accuracy: 0.5519 - val_loss: 1.0924 - val_accuracy: 0.5556\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0922 - val_accuracy: 0.5556\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8412 - accuracy: 0.5481 - val_loss: 1.0932 - val_accuracy: 0.5641\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8412 - accuracy: 0.5444 - val_loss: 1.0905 - val_accuracy: 0.5556\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.0937 - val_accuracy: 0.5556\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8401 - accuracy: 0.5519 - val_loss: 1.0969 - val_accuracy: 0.5641\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.1001 - val_accuracy: 0.5726\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8400 - accuracy: 0.5519 - val_loss: 1.0999 - val_accuracy: 0.5726\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0953 - val_accuracy: 0.5726\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0951 - val_accuracy: 0.5726\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8424 - accuracy: 0.5444 - val_loss: 1.0966 - val_accuracy: 0.5641\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8363 - accuracy: 0.5556 - val_loss: 1.0978 - val_accuracy: 0.5812\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8406 - accuracy: 0.5185 - val_loss: 1.0936 - val_accuracy: 0.5812\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8396 - accuracy: 0.5444 - val_loss: 1.0919 - val_accuracy: 0.5641\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.0960 - val_accuracy: 0.5726\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.0877 - val_accuracy: 0.5726\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8407 - accuracy: 0.5444 - val_loss: 1.0911 - val_accuracy: 0.5641\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0931 - val_accuracy: 0.5726\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8419 - accuracy: 0.5481 - val_loss: 1.0937 - val_accuracy: 0.5641\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.8402 - accuracy: 0.5481 - val_loss: 1.0952 - val_accuracy: 0.5641\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8431 - accuracy: 0.5259 - val_loss: 1.0964 - val_accuracy: 0.5897\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8418 - accuracy: 0.5407 - val_loss: 1.0918 - val_accuracy: 0.5726\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.0944 - val_accuracy: 0.5726\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.0892 - val_accuracy: 0.5556\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0963 - val_accuracy: 0.5726\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8409 - accuracy: 0.5259 - val_loss: 1.0935 - val_accuracy: 0.5556\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.0969 - val_accuracy: 0.5641\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8398 - accuracy: 0.5556 - val_loss: 1.0996 - val_accuracy: 0.5726\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8385 - accuracy: 0.5519 - val_loss: 1.0973 - val_accuracy: 0.5726\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.0946 - val_accuracy: 0.5726\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8387 - accuracy: 0.5519 - val_loss: 1.0898 - val_accuracy: 0.5641\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8435 - accuracy: 0.5519 - val_loss: 1.0969 - val_accuracy: 0.5726\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8385 - accuracy: 0.5481 - val_loss: 1.0886 - val_accuracy: 0.5641\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8413 - accuracy: 0.5556 - val_loss: 1.0900 - val_accuracy: 0.5726\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8405 - accuracy: 0.5407 - val_loss: 1.0900 - val_accuracy: 0.5726\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8409 - accuracy: 0.5148 - val_loss: 1.0942 - val_accuracy: 0.5641\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0944 - val_accuracy: 0.5641\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8411 - accuracy: 0.5444 - val_loss: 1.0933 - val_accuracy: 0.5641\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8397 - accuracy: 0.5556 - val_loss: 1.0973 - val_accuracy: 0.5726\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.1026 - val_accuracy: 0.5726\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0958 - val_accuracy: 0.5726\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8414 - accuracy: 0.5481 - val_loss: 1.0949 - val_accuracy: 0.5556\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8413 - accuracy: 0.5593 - val_loss: 1.1027 - val_accuracy: 0.5641\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0984 - val_accuracy: 0.5641\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.0969 - val_accuracy: 0.5556\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8433 - accuracy: 0.5444 - val_loss: 1.1013 - val_accuracy: 0.5726\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.1001 - val_accuracy: 0.5641\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.0936 - val_accuracy: 0.5641\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8385 - accuracy: 0.5519 - val_loss: 1.0959 - val_accuracy: 0.5641\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8429 - accuracy: 0.5222 - val_loss: 1.1024 - val_accuracy: 0.5726\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8441 - accuracy: 0.5000 - val_loss: 1.0929 - val_accuracy: 0.5556\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8410 - accuracy: 0.5519 - val_loss: 1.1026 - val_accuracy: 0.5641\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8414 - accuracy: 0.5519 - val_loss: 1.1007 - val_accuracy: 0.5556\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.1007 - val_accuracy: 0.5556\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8379 - accuracy: 0.5519 - val_loss: 1.1057 - val_accuracy: 0.5641\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8419 - accuracy: 0.5259 - val_loss: 1.1060 - val_accuracy: 0.5726\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 1.0969 - val_accuracy: 0.5556\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8391 - accuracy: 0.5444 - val_loss: 1.0986 - val_accuracy: 0.5641\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8409 - accuracy: 0.5481 - val_loss: 1.0988 - val_accuracy: 0.5641\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8480 - accuracy: 0.5185 - val_loss: 1.1104 - val_accuracy: 0.4957\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8390 - accuracy: 0.5593 - val_loss: 1.0988 - val_accuracy: 0.5812\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8484 - accuracy: 0.5259 - val_loss: 1.0994 - val_accuracy: 0.5726\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.1067 - val_accuracy: 0.5726\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8394 - accuracy: 0.5481 - val_loss: 1.1033 - val_accuracy: 0.5641\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8429 - accuracy: 0.5185 - val_loss: 1.1050 - val_accuracy: 0.5897\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8418 - accuracy: 0.5222 - val_loss: 1.1031 - val_accuracy: 0.5726\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8403 - accuracy: 0.5593 - val_loss: 1.0979 - val_accuracy: 0.5556\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8411 - accuracy: 0.5481 - val_loss: 1.1024 - val_accuracy: 0.5726\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.1021 - val_accuracy: 0.5641\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8387 - accuracy: 0.5519 - val_loss: 1.0998 - val_accuracy: 0.5641\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8399 - accuracy: 0.5519 - val_loss: 1.1014 - val_accuracy: 0.5641\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8379 - accuracy: 0.5519 - val_loss: 1.0980 - val_accuracy: 0.5641\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8403 - accuracy: 0.5481 - val_loss: 1.0976 - val_accuracy: 0.5556\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.1022 - val_accuracy: 0.5641\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8406 - accuracy: 0.5556 - val_loss: 1.1011 - val_accuracy: 0.5641\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8373 - accuracy: 0.5519 - val_loss: 1.0959 - val_accuracy: 0.5556\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9165 - accuracy: 0.50 - 0s 75us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.0968 - val_accuracy: 0.5556\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8375 - accuracy: 0.5519 - val_loss: 1.1037 - val_accuracy: 0.5556\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8416 - accuracy: 0.5407 - val_loss: 1.1038 - val_accuracy: 0.5726\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8389 - accuracy: 0.5519 - val_loss: 1.0991 - val_accuracy: 0.5556\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.1017 - val_accuracy: 0.5641\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8432 - accuracy: 0.5481 - val_loss: 1.0990 - val_accuracy: 0.5641\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8400 - accuracy: 0.5556 - val_loss: 1.0977 - val_accuracy: 0.5556\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8386 - accuracy: 0.5481 - val_loss: 1.1026 - val_accuracy: 0.5726\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.1069 - val_accuracy: 0.5726\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8382 - accuracy: 0.5556 - val_loss: 1.0964 - val_accuracy: 0.5641\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.1012 - val_accuracy: 0.5641\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8396 - accuracy: 0.5519 - val_loss: 1.0993 - val_accuracy: 0.5641\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8402 - accuracy: 0.5519 - val_loss: 1.1048 - val_accuracy: 0.5726\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.1066 - val_accuracy: 0.5726\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.0982 - val_accuracy: 0.5641\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8422 - accuracy: 0.5222 - val_loss: 1.0948 - val_accuracy: 0.5812\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8396 - accuracy: 0.5407 - val_loss: 1.0993 - val_accuracy: 0.5726\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8434 - accuracy: 0.5296 - val_loss: 1.1109 - val_accuracy: 0.4957\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8442 - accuracy: 0.5407 - val_loss: 1.0958 - val_accuracy: 0.5641\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 109us/step - loss: 0.8410 - accuracy: 0.5556 - val_loss: 1.0978 - val_accuracy: 0.5641\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8397 - accuracy: 0.5519 - val_loss: 1.1061 - val_accuracy: 0.5641\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.1017 - val_accuracy: 0.5641\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.0995 - val_accuracy: 0.5641\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8390 - accuracy: 0.5519 - val_loss: 1.0997 - val_accuracy: 0.5641\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8406 - accuracy: 0.5519 - val_loss: 1.0974 - val_accuracy: 0.5641\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 626us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.1015 - val_accuracy: 0.5641\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.1049 - val_accuracy: 0.5641\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8384 - accuracy: 0.5519 - val_loss: 1.1026 - val_accuracy: 0.5641\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8385 - accuracy: 0.5519 - val_loss: 1.1056 - val_accuracy: 0.5641\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8435 - accuracy: 0.5333 - val_loss: 1.1106 - val_accuracy: 0.5726\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.8386 - accuracy: 0.5481 - val_loss: 1.0993 - val_accuracy: 0.5641\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8376 - accuracy: 0.5481 - val_loss: 1.0967 - val_accuracy: 0.5726\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8413 - accuracy: 0.5519 - val_loss: 1.1016 - val_accuracy: 0.5726\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 1.0993 - val_accuracy: 0.5726\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8398 - accuracy: 0.5556 - val_loss: 1.0975 - val_accuracy: 0.5556\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8384 - accuracy: 0.5481 - val_loss: 1.0999 - val_accuracy: 0.5641\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8383 - accuracy: 0.5519 - val_loss: 1.1082 - val_accuracy: 0.5726\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8424 - accuracy: 0.5185 - val_loss: 1.1033 - val_accuracy: 0.5556\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8372 - accuracy: 0.5519 - val_loss: 1.1022 - val_accuracy: 0.5556\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8402 - accuracy: 0.5481 - val_loss: 1.1048 - val_accuracy: 0.5641\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8394 - accuracy: 0.5481 - val_loss: 1.1094 - val_accuracy: 0.5726\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.1039 - val_accuracy: 0.5726\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8411 - accuracy: 0.5481 - val_loss: 1.1013 - val_accuracy: 0.5556\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8389 - accuracy: 0.5444 - val_loss: 1.1026 - val_accuracy: 0.5726\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8391 - accuracy: 0.5519 - val_loss: 1.1081 - val_accuracy: 0.5726\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8392 - accuracy: 0.5556 - val_loss: 1.1021 - val_accuracy: 0.5556\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.1034 - val_accuracy: 0.5556\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8392 - accuracy: 0.5481 - val_loss: 1.1082 - val_accuracy: 0.5641\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8388 - accuracy: 0.5481 - val_loss: 1.1080 - val_accuracy: 0.5556\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8431 - accuracy: 0.5370 - val_loss: 1.1148 - val_accuracy: 0.5641\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8392 - accuracy: 0.5481 - val_loss: 1.1077 - val_accuracy: 0.5556\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8394 - accuracy: 0.5519 - val_loss: 1.1083 - val_accuracy: 0.5556\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8409 - accuracy: 0.5481 - val_loss: 1.1017 - val_accuracy: 0.5641\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.1049 - val_accuracy: 0.5726\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8394 - accuracy: 0.5519 - val_loss: 1.1137 - val_accuracy: 0.5726\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.1055 - val_accuracy: 0.5641\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8404 - accuracy: 0.5296 - val_loss: 1.1005 - val_accuracy: 0.5641\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7413 - accuracy: 0.59 - 0s 225us/step - loss: 0.8416 - accuracy: 0.5370 - val_loss: 1.1095 - val_accuracy: 0.4957\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8380 - accuracy: 0.5481 - val_loss: 1.1006 - val_accuracy: 0.5726\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8393 - accuracy: 0.5222 - val_loss: 1.0990 - val_accuracy: 0.5726\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8398 - accuracy: 0.5519 - val_loss: 1.1037 - val_accuracy: 0.5726\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.1116 - val_accuracy: 0.5726\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8382 - accuracy: 0.5519 - val_loss: 1.1032 - val_accuracy: 0.5641\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8394 - accuracy: 0.5519 - val_loss: 1.1020 - val_accuracy: 0.5556\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8416 - accuracy: 0.5481 - val_loss: 1.1082 - val_accuracy: 0.5726\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8405 - accuracy: 0.5519 - val_loss: 1.1042 - val_accuracy: 0.5641\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.1030 - val_accuracy: 0.5556\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8387 - accuracy: 0.5519 - val_loss: 1.1045 - val_accuracy: 0.5556\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8409 - accuracy: 0.5519 - val_loss: 1.1012 - val_accuracy: 0.5556\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8421 - accuracy: 0.5519 - val_loss: 1.1054 - val_accuracy: 0.5556\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8407 - accuracy: 0.5111 - val_loss: 1.1002 - val_accuracy: 0.5556\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.1044 - val_accuracy: 0.5641\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8406 - accuracy: 0.5481 - val_loss: 1.1090 - val_accuracy: 0.5897\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8424 - accuracy: 0.5259 - val_loss: 1.1045 - val_accuracy: 0.5641\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8408 - accuracy: 0.5519 - val_loss: 1.1075 - val_accuracy: 0.5641\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8403 - accuracy: 0.5519 - val_loss: 1.1061 - val_accuracy: 0.5641\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8395 - accuracy: 0.5519 - val_loss: 1.1085 - val_accuracy: 0.5641\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8418 - accuracy: 0.5519 - val_loss: 1.1107 - val_accuracy: 0.5641\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.1034 - val_accuracy: 0.5641\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8422 - accuracy: 0.5519 - val_loss: 1.1093 - val_accuracy: 0.5641\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8391 - accuracy: 0.5519 - val_loss: 1.1056 - val_accuracy: 0.5641\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 54.66%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [2.60268400e-03, 5.43314400e-03, 9.91964200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [8.44065370e-07, 8.08236250e-08, 9.99999050e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [7.32258330e-06, 1.04781775e-05, 9.99982240e-01],\n",
       "       [1.44944440e-02, 1.55937800e-02, 9.69911800e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [4.84708460e-04, 5.37492630e-01, 4.62022570e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [1.26332350e-02, 3.53688500e-04, 9.87013040e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [8.44065370e-07, 8.08236250e-08, 9.99999050e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [4.56441600e-02, 3.82001850e-01, 5.72354000e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [9.83125000e-01, 1.93313600e-04, 1.66818310e-02],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [4.84708460e-04, 5.37492630e-01, 4.62022570e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [4.90004660e-03, 6.96109900e-02, 9.25488950e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.78752090e-05, 2.37729770e-06, 9.99979730e-01],\n",
       "       [2.73316130e-05, 1.55798650e-06, 9.99971150e-01],\n",
       "       [4.56441600e-02, 3.82001850e-01, 5.72354000e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [9.89345970e-01, 5.36653960e-03, 5.28750750e-03],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [9.89345970e-01, 5.36653960e-03, 5.28750750e-03],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [2.13126220e-02, 4.43234700e-01, 5.35452660e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [4.56441600e-02, 3.82001850e-01, 5.72354000e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [2.78544250e-01, 2.87187220e-01, 4.34268560e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [2.78544250e-01, 2.87187220e-01, 4.34268560e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [4.90004660e-03, 6.96109900e-02, 9.25488950e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [4.84708460e-04, 5.37492630e-01, 4.62022570e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [9.59248200e-01, 1.33201400e-02, 2.74317020e-02],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.68740550e-05, 1.11357550e-02, 9.88827350e-01],\n",
       "       [4.56441600e-02, 3.82001850e-01, 5.72354000e-01],\n",
       "       [2.90622740e-01, 1.96601120e-01, 5.12776140e-01],\n",
       "       [4.56441600e-02, 3.82001850e-01, 5.72354000e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [1.26332350e-02, 3.53688500e-04, 9.87013040e-01],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [9.59248200e-01, 1.33201400e-02, 2.74317020e-02],\n",
       "       [1.91575570e-01, 4.65061280e-01, 3.43363200e-01],\n",
       "       [3.68740550e-05, 1.11357550e-02, 9.88827350e-01],\n",
       "       [2.19150110e-01, 4.30783020e-03, 7.76542070e-01],\n",
       "       [5.33972440e-01, 2.80422400e-01, 1.85605100e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01],\n",
       "       [3.88713870e-01, 3.80326800e-01, 2.30959280e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7341661187815034"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7341661187815034"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR4187     0\n",
       "1         NRS177     0\n",
       "2         NRS109     2\n",
       "3    CFBREBSa131     2\n",
       "4         SR4152     1\n",
       "..           ...   ...\n",
       "112       NRS110     2\n",
       "113     CFBRSa25     1\n",
       "114         834N     0\n",
       "115  CFBREBSa114     1\n",
       "116       NRS387     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 408us/step - loss: 1.2662 - accuracy: 0.3407 - val_loss: 1.2398 - val_accuracy: 0.3419\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 1.1721 - accuracy: 0.3481 - val_loss: 1.1671 - val_accuracy: 0.3675\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.1043 - accuracy: 0.3519 - val_loss: 1.1242 - val_accuracy: 0.4103\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.0678 - accuracy: 0.3852 - val_loss: 1.1041 - val_accuracy: 0.4359\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0500 - accuracy: 0.4222 - val_loss: 1.0983 - val_accuracy: 0.3761\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0474 - accuracy: 0.4407 - val_loss: 1.0992 - val_accuracy: 0.3761\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0451 - accuracy: 0.4370 - val_loss: 1.0997 - val_accuracy: 0.3761\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 1.0405 - accuracy: 0.4407 - val_loss: 1.0950 - val_accuracy: 0.3761\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 1.0354 - accuracy: 0.4407 - val_loss: 1.0885 - val_accuracy: 0.3761\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 1.0293 - accuracy: 0.4630 - val_loss: 1.0831 - val_accuracy: 0.3761\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0243 - accuracy: 0.4667 - val_loss: 1.0790 - val_accuracy: 0.3761\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.0215 - accuracy: 0.4704 - val_loss: 1.0778 - val_accuracy: 0.4274\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 1.0201 - accuracy: 0.4630 - val_loss: 1.0747 - val_accuracy: 0.4274\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 1.0165 - accuracy: 0.4630 - val_loss: 1.0701 - val_accuracy: 0.3675\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0136 - accuracy: 0.4704 - val_loss: 1.0674 - val_accuracy: 0.3761\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0098 - accuracy: 0.4704 - val_loss: 1.0678 - val_accuracy: 0.3761\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.0074 - accuracy: 0.4667 - val_loss: 1.0685 - val_accuracy: 0.3675\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0059 - accuracy: 0.4667 - val_loss: 1.0656 - val_accuracy: 0.3675\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0029 - accuracy: 0.4778 - val_loss: 1.0633 - val_accuracy: 0.3675\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 1.0002 - accuracy: 0.5000 - val_loss: 1.0608 - val_accuracy: 0.3675\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9989 - accuracy: 0.4963 - val_loss: 1.0594 - val_accuracy: 0.3675\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9955 - accuracy: 0.4926 - val_loss: 1.0575 - val_accuracy: 0.3675\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9939 - accuracy: 0.5037 - val_loss: 1.0560 - val_accuracy: 0.3846\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9917 - accuracy: 0.5000 - val_loss: 1.0539 - val_accuracy: 0.3932\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9904 - accuracy: 0.4926 - val_loss: 1.0530 - val_accuracy: 0.3932\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9894 - accuracy: 0.4926 - val_loss: 1.0509 - val_accuracy: 0.3932\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9857 - accuracy: 0.4926 - val_loss: 1.0483 - val_accuracy: 0.3846\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9827 - accuracy: 0.4926 - val_loss: 1.0469 - val_accuracy: 0.4444\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9826 - accuracy: 0.5259 - val_loss: 1.0481 - val_accuracy: 0.4274\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9805 - accuracy: 0.5259 - val_loss: 1.0452 - val_accuracy: 0.4359\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9778 - accuracy: 0.5259 - val_loss: 1.0421 - val_accuracy: 0.4359\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.9763 - accuracy: 0.4963 - val_loss: 1.0398 - val_accuracy: 0.3846\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9752 - accuracy: 0.4963 - val_loss: 1.0364 - val_accuracy: 0.3846\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9730 - accuracy: 0.4630 - val_loss: 1.0339 - val_accuracy: 0.4957\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.9709 - accuracy: 0.5407 - val_loss: 1.0333 - val_accuracy: 0.4359\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9698 - accuracy: 0.5296 - val_loss: 1.0347 - val_accuracy: 0.4274\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9687 - accuracy: 0.5259 - val_loss: 1.0344 - val_accuracy: 0.4359\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9669 - accuracy: 0.5222 - val_loss: 1.0324 - val_accuracy: 0.3846\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9666 - accuracy: 0.4556 - val_loss: 1.0298 - val_accuracy: 0.4957\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.9663 - accuracy: 0.5148 - val_loss: 1.0281 - val_accuracy: 0.4957\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9639 - accuracy: 0.5148 - val_loss: 1.0278 - val_accuracy: 0.4359\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9628 - accuracy: 0.5259 - val_loss: 1.0285 - val_accuracy: 0.4359\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.9617 - accuracy: 0.5296 - val_loss: 1.0313 - val_accuracy: 0.4274\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9615 - accuracy: 0.5259 - val_loss: 1.0320 - val_accuracy: 0.4359\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9607 - accuracy: 0.5296 - val_loss: 1.0330 - val_accuracy: 0.4359\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9593 - accuracy: 0.5296 - val_loss: 1.0296 - val_accuracy: 0.4359\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9546 - accuracy: 0.5296 - val_loss: 1.0263 - val_accuracy: 0.4957\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9600 - accuracy: 0.5222 - val_loss: 1.0270 - val_accuracy: 0.4957\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9614 - accuracy: 0.5259 - val_loss: 1.0270 - val_accuracy: 0.4359\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9570 - accuracy: 0.5296 - val_loss: 1.0216 - val_accuracy: 0.4957\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9537 - accuracy: 0.5222 - val_loss: 1.0223 - val_accuracy: 0.4957\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9523 - accuracy: 0.5222 - val_loss: 1.0221 - val_accuracy: 0.4957\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9506 - accuracy: 0.5222 - val_loss: 1.0197 - val_accuracy: 0.4957\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9506 - accuracy: 0.5222 - val_loss: 1.0191 - val_accuracy: 0.4957\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9508 - accuracy: 0.5148 - val_loss: 1.0194 - val_accuracy: 0.4957\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9498 - accuracy: 0.5148 - val_loss: 1.0197 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9469 - accuracy: 0.5185 - val_loss: 1.0221 - val_accuracy: 0.4359\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9467 - accuracy: 0.5296 - val_loss: 1.0242 - val_accuracy: 0.4274\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9475 - accuracy: 0.5296 - val_loss: 1.0246 - val_accuracy: 0.4274\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9441 - accuracy: 0.5296 - val_loss: 1.0198 - val_accuracy: 0.4359\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9475 - accuracy: 0.5148 - val_loss: 1.0205 - val_accuracy: 0.4957\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9471 - accuracy: 0.5407 - val_loss: 1.0201 - val_accuracy: 0.4359\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.9473 - accuracy: 0.5333 - val_loss: 1.0203 - val_accuracy: 0.4274\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.9448 - accuracy: 0.5296 - val_loss: 1.0178 - val_accuracy: 0.4359\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9438 - accuracy: 0.5111 - val_loss: 1.0165 - val_accuracy: 0.4957\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9434 - accuracy: 0.5222 - val_loss: 1.0170 - val_accuracy: 0.4957\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9412 - accuracy: 0.5148 - val_loss: 1.0178 - val_accuracy: 0.4274\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9407 - accuracy: 0.5296 - val_loss: 1.0184 - val_accuracy: 0.4274\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9410 - accuracy: 0.5296 - val_loss: 1.0207 - val_accuracy: 0.4274\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9398 - accuracy: 0.5296 - val_loss: 1.0207 - val_accuracy: 0.4274\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9389 - accuracy: 0.5296 - val_loss: 1.0201 - val_accuracy: 0.4274\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9382 - accuracy: 0.5296 - val_loss: 1.0203 - val_accuracy: 0.4274\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9389 - accuracy: 0.5296 - val_loss: 1.0194 - val_accuracy: 0.4274\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9378 - accuracy: 0.5296 - val_loss: 1.0188 - val_accuracy: 0.4274\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9377 - accuracy: 0.5296 - val_loss: 1.0195 - val_accuracy: 0.4274\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9376 - accuracy: 0.5296 - val_loss: 1.0182 - val_accuracy: 0.4274\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9370 - accuracy: 0.5296 - val_loss: 1.0155 - val_accuracy: 0.4274\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9352 - accuracy: 0.5296 - val_loss: 1.0151 - val_accuracy: 0.4274\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9339 - accuracy: 0.5296 - val_loss: 1.0163 - val_accuracy: 0.4274\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9341 - accuracy: 0.5296 - val_loss: 1.0178 - val_accuracy: 0.4274\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9343 - accuracy: 0.5296 - val_loss: 1.0195 - val_accuracy: 0.4274\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9351 - accuracy: 0.5296 - val_loss: 1.0193 - val_accuracy: 0.4274\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9345 - accuracy: 0.5296 - val_loss: 1.0165 - val_accuracy: 0.4274\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9321 - accuracy: 0.5296 - val_loss: 1.0153 - val_accuracy: 0.4274\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9330 - accuracy: 0.5296 - val_loss: 1.0140 - val_accuracy: 0.4274\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9326 - accuracy: 0.5000 - val_loss: 1.0144 - val_accuracy: 0.4872\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9314 - accuracy: 0.5222 - val_loss: 1.0142 - val_accuracy: 0.4872\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9317 - accuracy: 0.4963 - val_loss: 1.0159 - val_accuracy: 0.4274\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9308 - accuracy: 0.5185 - val_loss: 1.0159 - val_accuracy: 0.4872\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9310 - accuracy: 0.5037 - val_loss: 1.0158 - val_accuracy: 0.4872\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9295 - accuracy: 0.5222 - val_loss: 1.0130 - val_accuracy: 0.4872\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9299 - accuracy: 0.5259 - val_loss: 1.0111 - val_accuracy: 0.4872\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9303 - accuracy: 0.5259 - val_loss: 1.0115 - val_accuracy: 0.4274\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9299 - accuracy: 0.5333 - val_loss: 1.0114 - val_accuracy: 0.4188\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9284 - accuracy: 0.5296 - val_loss: 1.0116 - val_accuracy: 0.4274\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.9291 - accuracy: 0.5370 - val_loss: 1.0140 - val_accuracy: 0.5043\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9306 - accuracy: 0.5259 - val_loss: 1.0164 - val_accuracy: 0.5043\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9302 - accuracy: 0.5259 - val_loss: 1.0153 - val_accuracy: 0.4359\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9272 - accuracy: 0.5333 - val_loss: 1.0132 - val_accuracy: 0.4444\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9254 - accuracy: 0.5370 - val_loss: 1.0119 - val_accuracy: 0.4274\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9259 - accuracy: 0.5370 - val_loss: 1.0118 - val_accuracy: 0.4188\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9269 - accuracy: 0.5370 - val_loss: 1.0142 - val_accuracy: 0.4188\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9279 - accuracy: 0.5370 - val_loss: 1.0141 - val_accuracy: 0.4359\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9253 - accuracy: 0.5407 - val_loss: 1.0124 - val_accuracy: 0.4444\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9241 - accuracy: 0.5407 - val_loss: 1.0111 - val_accuracy: 0.4444\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 472us/step - loss: 0.9241 - accuracy: 0.5148 - val_loss: 1.0103 - val_accuracy: 0.5043\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9248 - accuracy: 0.5407 - val_loss: 1.0110 - val_accuracy: 0.4274\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9261 - accuracy: 0.5407 - val_loss: 1.0148 - val_accuracy: 0.4188\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9236 - accuracy: 0.5370 - val_loss: 1.0118 - val_accuracy: 0.4444\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9219 - accuracy: 0.5407 - val_loss: 1.0118 - val_accuracy: 0.5043\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9226 - accuracy: 0.5370 - val_loss: 1.0120 - val_accuracy: 0.5043\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9242 - accuracy: 0.5370 - val_loss: 1.0118 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9245 - accuracy: 0.5296 - val_loss: 1.0135 - val_accuracy: 0.5043\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9228 - accuracy: 0.5296 - val_loss: 1.0119 - val_accuracy: 0.5043\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9212 - accuracy: 0.5370 - val_loss: 1.0117 - val_accuracy: 0.5043\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9210 - accuracy: 0.5370 - val_loss: 1.0101 - val_accuracy: 0.5043\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9199 - accuracy: 0.5407 - val_loss: 1.0097 - val_accuracy: 0.4188\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9204 - accuracy: 0.5407 - val_loss: 1.0099 - val_accuracy: 0.4188\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9192 - accuracy: 0.5407 - val_loss: 1.0092 - val_accuracy: 0.5043\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9214 - accuracy: 0.5370 - val_loss: 1.0097 - val_accuracy: 0.5043\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9187 - accuracy: 0.5370 - val_loss: 1.0089 - val_accuracy: 0.4274\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9227 - accuracy: 0.5407 - val_loss: 1.0140 - val_accuracy: 0.4188\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9217 - accuracy: 0.5407 - val_loss: 1.0124 - val_accuracy: 0.4188\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9188 - accuracy: 0.5407 - val_loss: 1.0115 - val_accuracy: 0.4444\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9189 - accuracy: 0.5148 - val_loss: 1.0075 - val_accuracy: 0.5043\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9185 - accuracy: 0.5370 - val_loss: 1.0060 - val_accuracy: 0.4274\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9188 - accuracy: 0.5407 - val_loss: 1.0081 - val_accuracy: 0.4274\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9179 - accuracy: 0.5407 - val_loss: 1.0090 - val_accuracy: 0.4274\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9171 - accuracy: 0.5407 - val_loss: 1.0070 - val_accuracy: 0.4444\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9170 - accuracy: 0.5074 - val_loss: 1.0081 - val_accuracy: 0.5043\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9157 - accuracy: 0.5444 - val_loss: 1.0106 - val_accuracy: 0.4359\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9166 - accuracy: 0.5444 - val_loss: 1.0122 - val_accuracy: 0.4359\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9167 - accuracy: 0.5444 - val_loss: 1.0112 - val_accuracy: 0.4359\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9155 - accuracy: 0.5444 - val_loss: 1.0062 - val_accuracy: 0.4444\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9168 - accuracy: 0.5148 - val_loss: 1.0061 - val_accuracy: 0.5043\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9164 - accuracy: 0.5370 - val_loss: 1.0054 - val_accuracy: 0.5043\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9154 - accuracy: 0.5370 - val_loss: 1.0053 - val_accuracy: 0.5043\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9171 - accuracy: 0.5370 - val_loss: 1.0082 - val_accuracy: 0.5043\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9123 - accuracy: 0.5519 - val_loss: 1.0105 - val_accuracy: 0.4359\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9151 - accuracy: 0.5444 - val_loss: 1.0140 - val_accuracy: 0.4188\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.9182 - accuracy: 0.5370 - val_loss: 1.0108 - val_accuracy: 0.4188\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9141 - accuracy: 0.5444 - val_loss: 1.0030 - val_accuracy: 0.4444\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9143 - accuracy: 0.5370 - val_loss: 1.0028 - val_accuracy: 0.5043\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9150 - accuracy: 0.5370 - val_loss: 1.0027 - val_accuracy: 0.5043\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9119 - accuracy: 0.5370 - val_loss: 1.0043 - val_accuracy: 0.5043\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9109 - accuracy: 0.5519 - val_loss: 1.0067 - val_accuracy: 0.4701\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9117 - accuracy: 0.5481 - val_loss: 1.0078 - val_accuracy: 0.4701\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9129 - accuracy: 0.5407 - val_loss: 1.0051 - val_accuracy: 0.5043\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9111 - accuracy: 0.5370 - val_loss: 1.0039 - val_accuracy: 0.5043\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9133 - accuracy: 0.5370 - val_loss: 1.0032 - val_accuracy: 0.5043\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9134 - accuracy: 0.5111 - val_loss: 1.0074 - val_accuracy: 0.4701\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9108 - accuracy: 0.5481 - val_loss: 1.0072 - val_accuracy: 0.4701\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9103 - accuracy: 0.5481 - val_loss: 1.0066 - val_accuracy: 0.4701\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9102 - accuracy: 0.5481 - val_loss: 1.0040 - val_accuracy: 0.4701\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9110 - accuracy: 0.5407 - val_loss: 1.0034 - val_accuracy: 0.4444\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9093 - accuracy: 0.5444 - val_loss: 1.0044 - val_accuracy: 0.4359\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 1.0396 - accuracy: 0.45 - 0s 88us/step - loss: 0.9095 - accuracy: 0.5407 - val_loss: 1.0083 - val_accuracy: 0.4615\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9086 - accuracy: 0.5481 - val_loss: 1.0087 - val_accuracy: 0.4615\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9090 - accuracy: 0.5444 - val_loss: 1.0060 - val_accuracy: 0.5043\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9140 - accuracy: 0.5370 - val_loss: 1.0085 - val_accuracy: 0.5043\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9111 - accuracy: 0.5185 - val_loss: 1.0076 - val_accuracy: 0.4359\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9079 - accuracy: 0.5444 - val_loss: 1.0095 - val_accuracy: 0.4359\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9075 - accuracy: 0.5444 - val_loss: 1.0075 - val_accuracy: 0.4615\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9062 - accuracy: 0.5481 - val_loss: 1.0065 - val_accuracy: 0.4615\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9069 - accuracy: 0.5481 - val_loss: 1.0044 - val_accuracy: 0.4615\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9055 - accuracy: 0.5481 - val_loss: 1.0023 - val_accuracy: 0.4359\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9053 - accuracy: 0.5444 - val_loss: 1.0011 - val_accuracy: 0.4701\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9058 - accuracy: 0.5481 - val_loss: 1.0012 - val_accuracy: 0.4701\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9049 - accuracy: 0.5556 - val_loss: 1.0002 - val_accuracy: 0.5299\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9044 - accuracy: 0.5370 - val_loss: 1.0009 - val_accuracy: 0.4701\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9052 - accuracy: 0.5519 - val_loss: 1.0017 - val_accuracy: 0.4615\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9076 - accuracy: 0.5481 - val_loss: 1.0033 - val_accuracy: 0.4615\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9047 - accuracy: 0.5481 - val_loss: 1.0007 - val_accuracy: 0.4615\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9030 - accuracy: 0.5630 - val_loss: 0.9996 - val_accuracy: 0.5043\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.9046 - accuracy: 0.5370 - val_loss: 1.0013 - val_accuracy: 0.5043\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9079 - accuracy: 0.5370 - val_loss: 0.9999 - val_accuracy: 0.5043\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9053 - accuracy: 0.5333 - val_loss: 1.0028 - val_accuracy: 0.4615\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9031 - accuracy: 0.5519 - val_loss: 1.0036 - val_accuracy: 0.4615\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9041 - accuracy: 0.5519 - val_loss: 1.0032 - val_accuracy: 0.4615\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9035 - accuracy: 0.5519 - val_loss: 1.0029 - val_accuracy: 0.4615\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9016 - accuracy: 0.5407 - val_loss: 1.0020 - val_accuracy: 0.5214\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9019 - accuracy: 0.5407 - val_loss: 1.0014 - val_accuracy: 0.5214\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9016 - accuracy: 0.5556 - val_loss: 1.0063 - val_accuracy: 0.4615\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9020 - accuracy: 0.5519 - val_loss: 1.0098 - val_accuracy: 0.4615\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9047 - accuracy: 0.5519 - val_loss: 1.0112 - val_accuracy: 0.4615\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9030 - accuracy: 0.5519 - val_loss: 1.0049 - val_accuracy: 0.4615\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8997 - accuracy: 0.5519 - val_loss: 1.0029 - val_accuracy: 0.5299\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9032 - accuracy: 0.5407 - val_loss: 1.0034 - val_accuracy: 0.5299\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9024 - accuracy: 0.5407 - val_loss: 1.0020 - val_accuracy: 0.5043\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9022 - accuracy: 0.5407 - val_loss: 1.0013 - val_accuracy: 0.5299\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9000 - accuracy: 0.5407 - val_loss: 1.0016 - val_accuracy: 0.4701\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9002 - accuracy: 0.5481 - val_loss: 1.0041 - val_accuracy: 0.4615\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9010 - accuracy: 0.5519 - val_loss: 1.0043 - val_accuracy: 0.4615\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9011 - accuracy: 0.5519 - val_loss: 1.0043 - val_accuracy: 0.4615\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9006 - accuracy: 0.5519 - val_loss: 1.0073 - val_accuracy: 0.4615\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9026 - accuracy: 0.5519 - val_loss: 1.0047 - val_accuracy: 0.4615\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8996 - accuracy: 0.5519 - val_loss: 1.0033 - val_accuracy: 0.4615\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8980 - accuracy: 0.5852 - val_loss: 1.0006 - val_accuracy: 0.5299\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8991 - accuracy: 0.5407 - val_loss: 1.0005 - val_accuracy: 0.5299\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9056 - accuracy: 0.5407 - val_loss: 0.9992 - val_accuracy: 0.5299\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8988 - accuracy: 0.5444 - val_loss: 1.0000 - val_accuracy: 0.4701\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9001 - accuracy: 0.5519 - val_loss: 1.0071 - val_accuracy: 0.4615\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9026 - accuracy: 0.5519 - val_loss: 1.0035 - val_accuracy: 0.4615\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8980 - accuracy: 0.5519 - val_loss: 0.9975 - val_accuracy: 0.5299\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8979 - accuracy: 0.5407 - val_loss: 0.9983 - val_accuracy: 0.5299\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9017 - accuracy: 0.5407 - val_loss: 0.9989 - val_accuracy: 0.5299\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9002 - accuracy: 0.5444 - val_loss: 0.9973 - val_accuracy: 0.5299\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9015 - accuracy: 0.5148 - val_loss: 0.9996 - val_accuracy: 0.4701\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8977 - accuracy: 0.5519 - val_loss: 0.9995 - val_accuracy: 0.4701\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8988 - accuracy: 0.5444 - val_loss: 1.0021 - val_accuracy: 0.4701\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8967 - accuracy: 0.5519 - val_loss: 1.0026 - val_accuracy: 0.4615\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8966 - accuracy: 0.5407 - val_loss: 1.0012 - val_accuracy: 0.5214\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8948 - accuracy: 0.5481 - val_loss: 1.0008 - val_accuracy: 0.4615\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8947 - accuracy: 0.5481 - val_loss: 1.0008 - val_accuracy: 0.4615\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8945 - accuracy: 0.5481 - val_loss: 1.0005 - val_accuracy: 0.5214\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8944 - accuracy: 0.5407 - val_loss: 1.0001 - val_accuracy: 0.5214\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8944 - accuracy: 0.5407 - val_loss: 1.0022 - val_accuracy: 0.5214\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8944 - accuracy: 0.5481 - val_loss: 1.0029 - val_accuracy: 0.4615\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8934 - accuracy: 0.5407 - val_loss: 1.0029 - val_accuracy: 0.4615\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8943 - accuracy: 0.5519 - val_loss: 1.0033 - val_accuracy: 0.4615\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8936 - accuracy: 0.5519 - val_loss: 1.0045 - val_accuracy: 0.4615\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8942 - accuracy: 0.5556 - val_loss: 1.0050 - val_accuracy: 0.4615\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8935 - accuracy: 0.5481 - val_loss: 1.0014 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8948 - accuracy: 0.5556 - val_loss: 1.0006 - val_accuracy: 0.4615\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8951 - accuracy: 0.5444 - val_loss: 1.0015 - val_accuracy: 0.5214\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8935 - accuracy: 0.5444 - val_loss: 1.0014 - val_accuracy: 0.5299\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8937 - accuracy: 0.5444 - val_loss: 1.0012 - val_accuracy: 0.5299\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8938 - accuracy: 0.5481 - val_loss: 1.0023 - val_accuracy: 0.5214\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8913 - accuracy: 0.5444 - val_loss: 1.0074 - val_accuracy: 0.4615\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8926 - accuracy: 0.5519 - val_loss: 1.0130 - val_accuracy: 0.4615\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8950 - accuracy: 0.5556 - val_loss: 1.0113 - val_accuracy: 0.4615\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8903 - accuracy: 0.5556 - val_loss: 1.0050 - val_accuracy: 0.4615\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8915 - accuracy: 0.5556 - val_loss: 1.0041 - val_accuracy: 0.4615\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8918 - accuracy: 0.5370 - val_loss: 1.0019 - val_accuracy: 0.5299\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8918 - accuracy: 0.5444 - val_loss: 1.0040 - val_accuracy: 0.5299\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8965 - accuracy: 0.5444 - val_loss: 1.0076 - val_accuracy: 0.5299\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8938 - accuracy: 0.5444 - val_loss: 1.0043 - val_accuracy: 0.5299\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8892 - accuracy: 0.5630 - val_loss: 1.0085 - val_accuracy: 0.4615\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8953 - accuracy: 0.5593 - val_loss: 1.0167 - val_accuracy: 0.4615\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8965 - accuracy: 0.5593 - val_loss: 1.0152 - val_accuracy: 0.4615\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8928 - accuracy: 0.5556 - val_loss: 1.0129 - val_accuracy: 0.4615\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8908 - accuracy: 0.5556 - val_loss: 1.0112 - val_accuracy: 0.4701\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8876 - accuracy: 0.5481 - val_loss: 1.0046 - val_accuracy: 0.5043\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8895 - accuracy: 0.5407 - val_loss: 1.0048 - val_accuracy: 0.5043\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8949 - accuracy: 0.5259 - val_loss: 1.0070 - val_accuracy: 0.4615\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8904 - accuracy: 0.5556 - val_loss: 1.0047 - val_accuracy: 0.4701\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8877 - accuracy: 0.5556 - val_loss: 1.0031 - val_accuracy: 0.4701\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8891 - accuracy: 0.5667 - val_loss: 1.0053 - val_accuracy: 0.5299\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8917 - accuracy: 0.5444 - val_loss: 1.0044 - val_accuracy: 0.5299\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8899 - accuracy: 0.5444 - val_loss: 1.0042 - val_accuracy: 0.5299\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8877 - accuracy: 0.5296 - val_loss: 1.0078 - val_accuracy: 0.4615\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8885 - accuracy: 0.5593 - val_loss: 1.0072 - val_accuracy: 0.4615\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8868 - accuracy: 0.5593 - val_loss: 1.0052 - val_accuracy: 0.5214\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8872 - accuracy: 0.5519 - val_loss: 1.0054 - val_accuracy: 0.5214\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8880 - accuracy: 0.5519 - val_loss: 1.0069 - val_accuracy: 0.5214\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8889 - accuracy: 0.5519 - val_loss: 1.0080 - val_accuracy: 0.5214\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8882 - accuracy: 0.5519 - val_loss: 1.0081 - val_accuracy: 0.4615\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8862 - accuracy: 0.5593 - val_loss: 1.0068 - val_accuracy: 0.4615\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8894 - accuracy: 0.5556 - val_loss: 1.0044 - val_accuracy: 0.4359\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8877 - accuracy: 0.5370 - val_loss: 1.0012 - val_accuracy: 0.5214\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8854 - accuracy: 0.5519 - val_loss: 1.0047 - val_accuracy: 0.5299\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8879 - accuracy: 0.5519 - val_loss: 1.0040 - val_accuracy: 0.5299\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8856 - accuracy: 0.5481 - val_loss: 1.0057 - val_accuracy: 0.5299\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8854 - accuracy: 0.5519 - val_loss: 1.0085 - val_accuracy: 0.4615\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8848 - accuracy: 0.5593 - val_loss: 1.0108 - val_accuracy: 0.4615\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8873 - accuracy: 0.5593 - val_loss: 1.0156 - val_accuracy: 0.4615\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8917 - accuracy: 0.5593 - val_loss: 1.0155 - val_accuracy: 0.4615\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8882 - accuracy: 0.5593 - val_loss: 1.0087 - val_accuracy: 0.4615\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8859 - accuracy: 0.5556 - val_loss: 1.0079 - val_accuracy: 0.4701\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8855 - accuracy: 0.5556 - val_loss: 1.0066 - val_accuracy: 0.5299\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8850 - accuracy: 0.5481 - val_loss: 1.0064 - val_accuracy: 0.5299\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8848 - accuracy: 0.5407 - val_loss: 1.0066 - val_accuracy: 0.4615\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8831 - accuracy: 0.5593 - val_loss: 1.0103 - val_accuracy: 0.4615\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8843 - accuracy: 0.5593 - val_loss: 1.0117 - val_accuracy: 0.4615\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8853 - accuracy: 0.5593 - val_loss: 1.0116 - val_accuracy: 0.4615\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8850 - accuracy: 0.5593 - val_loss: 1.0094 - val_accuracy: 0.4615\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8859 - accuracy: 0.5593 - val_loss: 1.0125 - val_accuracy: 0.4615\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8848 - accuracy: 0.5185 - val_loss: 1.0061 - val_accuracy: 0.5214\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8835 - accuracy: 0.5444 - val_loss: 1.0056 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8840 - accuracy: 0.5593 - val_loss: 1.0066 - val_accuracy: 0.4615\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8889 - accuracy: 0.5444 - val_loss: 1.0078 - val_accuracy: 0.4615\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8863 - accuracy: 0.5593 - val_loss: 1.0087 - val_accuracy: 0.4615\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8851 - accuracy: 0.5593 - val_loss: 1.0084 - val_accuracy: 0.4615\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8815 - accuracy: 0.5593 - val_loss: 1.0092 - val_accuracy: 0.4615\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8832 - accuracy: 0.5333 - val_loss: 1.0041 - val_accuracy: 0.5299\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8814 - accuracy: 0.5111 - val_loss: 1.0031 - val_accuracy: 0.4615\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8817 - accuracy: 0.5593 - val_loss: 1.0032 - val_accuracy: 0.4615\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8825 - accuracy: 0.5593 - val_loss: 1.0065 - val_accuracy: 0.4615\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8824 - accuracy: 0.5593 - val_loss: 1.0042 - val_accuracy: 0.4615\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8819 - accuracy: 0.5481 - val_loss: 1.0020 - val_accuracy: 0.5299\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8855 - accuracy: 0.5481 - val_loss: 1.0017 - val_accuracy: 0.5299\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8808 - accuracy: 0.5481 - val_loss: 1.0065 - val_accuracy: 0.4615\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8807 - accuracy: 0.5593 - val_loss: 1.0145 - val_accuracy: 0.4615\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8847 - accuracy: 0.5593 - val_loss: 1.0155 - val_accuracy: 0.4615\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8834 - accuracy: 0.5593 - val_loss: 1.0092 - val_accuracy: 0.4615\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8834 - accuracy: 0.5556 - val_loss: 1.0033 - val_accuracy: 0.4615\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8825 - accuracy: 0.5111 - val_loss: 1.0035 - val_accuracy: 0.5214\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8789 - accuracy: 0.5481 - val_loss: 1.0047 - val_accuracy: 0.4615\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8792 - accuracy: 0.5593 - val_loss: 1.0046 - val_accuracy: 0.4615\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8785 - accuracy: 0.5593 - val_loss: 1.0072 - val_accuracy: 0.4615\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8787 - accuracy: 0.5593 - val_loss: 1.0109 - val_accuracy: 0.4615\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8817 - accuracy: 0.5593 - val_loss: 1.0134 - val_accuracy: 0.4615\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8812 - accuracy: 0.5593 - val_loss: 1.0087 - val_accuracy: 0.4615\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8781 - accuracy: 0.5593 - val_loss: 1.0025 - val_accuracy: 0.5214\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8788 - accuracy: 0.5519 - val_loss: 1.0032 - val_accuracy: 0.5299\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8821 - accuracy: 0.5519 - val_loss: 1.0025 - val_accuracy: 0.5214\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8789 - accuracy: 0.5519 - val_loss: 1.0039 - val_accuracy: 0.5214\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8780 - accuracy: 0.5593 - val_loss: 1.0054 - val_accuracy: 0.4615\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8775 - accuracy: 0.5593 - val_loss: 1.0040 - val_accuracy: 0.4615\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8774 - accuracy: 0.5481 - val_loss: 1.0025 - val_accuracy: 0.5299\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8795 - accuracy: 0.5222 - val_loss: 1.0010 - val_accuracy: 0.5299\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8771 - accuracy: 0.5481 - val_loss: 1.0026 - val_accuracy: 0.5299\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8782 - accuracy: 0.5481 - val_loss: 1.0029 - val_accuracy: 0.5299\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8793 - accuracy: 0.5370 - val_loss: 1.0037 - val_accuracy: 0.4701\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8783 - accuracy: 0.5593 - val_loss: 1.0083 - val_accuracy: 0.4701\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8793 - accuracy: 0.5593 - val_loss: 1.0066 - val_accuracy: 0.4701\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8789 - accuracy: 0.5593 - val_loss: 1.0068 - val_accuracy: 0.4615\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8843 - accuracy: 0.5556 - val_loss: 1.0077 - val_accuracy: 0.5299\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8840 - accuracy: 0.5481 - val_loss: 1.0001 - val_accuracy: 0.5299\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8751 - accuracy: 0.5519 - val_loss: 1.0008 - val_accuracy: 0.4701\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8750 - accuracy: 0.5593 - val_loss: 1.0083 - val_accuracy: 0.4615\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8800 - accuracy: 0.5593 - val_loss: 1.0092 - val_accuracy: 0.4615\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8788 - accuracy: 0.5593 - val_loss: 1.0000 - val_accuracy: 0.4615\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8762 - accuracy: 0.5556 - val_loss: 0.9989 - val_accuracy: 0.5299\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8762 - accuracy: 0.5519 - val_loss: 0.9994 - val_accuracy: 0.5299\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8763 - accuracy: 0.5519 - val_loss: 1.0003 - val_accuracy: 0.5299\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8772 - accuracy: 0.5519 - val_loss: 1.0026 - val_accuracy: 0.5299\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8751 - accuracy: 0.5556 - val_loss: 1.0015 - val_accuracy: 0.4701\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8753 - accuracy: 0.5593 - val_loss: 0.9998 - val_accuracy: 0.4701\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8752 - accuracy: 0.5556 - val_loss: 0.9970 - val_accuracy: 0.5299\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9996 - val_accuracy: 0.5299\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8762 - accuracy: 0.5519 - val_loss: 1.0026 - val_accuracy: 0.5299\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8762 - accuracy: 0.5519 - val_loss: 1.0006 - val_accuracy: 0.5299\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8754 - accuracy: 0.5519 - val_loss: 0.9987 - val_accuracy: 0.5299\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8751 - accuracy: 0.5296 - val_loss: 0.9985 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9973 - val_accuracy: 0.5299\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8773 - accuracy: 0.5519 - val_loss: 0.9980 - val_accuracy: 0.5299\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8771 - accuracy: 0.5519 - val_loss: 0.9995 - val_accuracy: 0.5299\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8745 - accuracy: 0.5519 - val_loss: 1.0039 - val_accuracy: 0.5299\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8726 - accuracy: 0.5519 - val_loss: 1.0069 - val_accuracy: 0.5214\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8738 - accuracy: 0.5519 - val_loss: 1.0067 - val_accuracy: 0.5299\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8742 - accuracy: 0.5519 - val_loss: 1.0053 - val_accuracy: 0.4701\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8742 - accuracy: 0.5593 - val_loss: 1.0085 - val_accuracy: 0.4615\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8760 - accuracy: 0.5593 - val_loss: 1.0117 - val_accuracy: 0.4615\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8746 - accuracy: 0.5593 - val_loss: 1.0096 - val_accuracy: 0.4701\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8738 - accuracy: 0.5630 - val_loss: 1.0096 - val_accuracy: 0.5299\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8727 - accuracy: 0.5259 - val_loss: 1.0125 - val_accuracy: 0.5299\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8753 - accuracy: 0.5519 - val_loss: 1.0171 - val_accuracy: 0.5299\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 1.0128 - val_accuracy: 0.5299\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8750 - accuracy: 0.5519 - val_loss: 1.0094 - val_accuracy: 0.4701\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8735 - accuracy: 0.5593 - val_loss: 1.0126 - val_accuracy: 0.4701\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8722 - accuracy: 0.5593 - val_loss: 1.0112 - val_accuracy: 0.4701\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8717 - accuracy: 0.5519 - val_loss: 1.0103 - val_accuracy: 0.5299\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8713 - accuracy: 0.5519 - val_loss: 1.0081 - val_accuracy: 0.5299\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.8707 - accuracy: 0.5519 - val_loss: 1.0076 - val_accuracy: 0.5299\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8704 - accuracy: 0.5519 - val_loss: 1.0094 - val_accuracy: 0.4701\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8713 - accuracy: 0.5593 - val_loss: 1.0108 - val_accuracy: 0.4615\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8704 - accuracy: 0.5593 - val_loss: 1.0124 - val_accuracy: 0.4615\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8705 - accuracy: 0.5593 - val_loss: 1.0094 - val_accuracy: 0.4701\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8718 - accuracy: 0.5407 - val_loss: 1.0091 - val_accuracy: 0.5299\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8700 - accuracy: 0.5333 - val_loss: 1.0119 - val_accuracy: 0.4615\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8708 - accuracy: 0.5593 - val_loss: 1.0130 - val_accuracy: 0.4615\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8724 - accuracy: 0.5593 - val_loss: 1.0177 - val_accuracy: 0.4615\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8710 - accuracy: 0.5593 - val_loss: 1.0190 - val_accuracy: 0.4615\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8696 - accuracy: 0.5593 - val_loss: 1.0158 - val_accuracy: 0.4701\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8694 - accuracy: 0.5593 - val_loss: 1.0144 - val_accuracy: 0.5299\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8700 - accuracy: 0.5519 - val_loss: 1.0166 - val_accuracy: 0.5299\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8691 - accuracy: 0.5519 - val_loss: 1.0135 - val_accuracy: 0.5299\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8693 - accuracy: 0.5519 - val_loss: 1.0127 - val_accuracy: 0.5299\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8677 - accuracy: 0.5852 - val_loss: 1.0151 - val_accuracy: 0.4701\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8707 - accuracy: 0.5556 - val_loss: 1.0134 - val_accuracy: 0.4444\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8709 - accuracy: 0.5556 - val_loss: 1.0133 - val_accuracy: 0.4444\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8695 - accuracy: 0.5556 - val_loss: 1.0131 - val_accuracy: 0.4701\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8678 - accuracy: 0.5593 - val_loss: 1.0149 - val_accuracy: 0.4701\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.8676 - accuracy: 0.5593 - val_loss: 1.0137 - val_accuracy: 0.5299\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8686 - accuracy: 0.5519 - val_loss: 1.0141 - val_accuracy: 0.5299\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.8684 - accuracy: 0.5519 - val_loss: 1.0119 - val_accuracy: 0.5299\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8671 - accuracy: 0.5519 - val_loss: 1.0121 - val_accuracy: 0.4701\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8686 - accuracy: 0.5593 - val_loss: 1.0124 - val_accuracy: 0.4701\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8675 - accuracy: 0.5593 - val_loss: 1.0159 - val_accuracy: 0.4701\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8677 - accuracy: 0.5593 - val_loss: 1.0179 - val_accuracy: 0.4701\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8674 - accuracy: 0.5630 - val_loss: 1.0159 - val_accuracy: 0.5299\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8669 - accuracy: 0.5444 - val_loss: 1.0129 - val_accuracy: 0.5299\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8678 - accuracy: 0.5519 - val_loss: 1.0120 - val_accuracy: 0.5043\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8684 - accuracy: 0.5519 - val_loss: 1.0136 - val_accuracy: 0.5299\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8683 - accuracy: 0.5630 - val_loss: 1.0195 - val_accuracy: 0.4615\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8696 - accuracy: 0.5593 - val_loss: 1.0221 - val_accuracy: 0.4615\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8704 - accuracy: 0.5593 - val_loss: 1.0209 - val_accuracy: 0.4615\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8694 - accuracy: 0.5593 - val_loss: 1.0232 - val_accuracy: 0.4615\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8693 - accuracy: 0.5519 - val_loss: 1.0124 - val_accuracy: 0.5299\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8667 - accuracy: 0.5519 - val_loss: 1.0108 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8667 - accuracy: 0.5519 - val_loss: 1.0115 - val_accuracy: 0.4701\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8662 - accuracy: 0.5593 - val_loss: 1.0168 - val_accuracy: 0.4615\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8674 - accuracy: 0.5593 - val_loss: 1.0168 - val_accuracy: 0.4615\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8663 - accuracy: 0.5593 - val_loss: 1.0131 - val_accuracy: 0.5299\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8691 - accuracy: 0.5481 - val_loss: 1.0145 - val_accuracy: 0.5043\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8714 - accuracy: 0.5481 - val_loss: 1.0124 - val_accuracy: 0.5299\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8636 - accuracy: 0.5741 - val_loss: 1.0182 - val_accuracy: 0.4615\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8687 - accuracy: 0.5593 - val_loss: 1.0276 - val_accuracy: 0.4615\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8677 - accuracy: 0.5593 - val_loss: 1.0204 - val_accuracy: 0.4615\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8651 - accuracy: 0.5593 - val_loss: 1.0157 - val_accuracy: 0.4701\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8672 - accuracy: 0.5593 - val_loss: 1.0170 - val_accuracy: 0.4701\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8651 - accuracy: 0.5593 - val_loss: 1.0205 - val_accuracy: 0.4701\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8693 - accuracy: 0.5593 - val_loss: 1.0377 - val_accuracy: 0.4615\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8734 - accuracy: 0.5444 - val_loss: 1.0371 - val_accuracy: 0.4701\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8682 - accuracy: 0.5444 - val_loss: 1.0218 - val_accuracy: 0.4701\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8658 - accuracy: 0.5593 - val_loss: 1.0177 - val_accuracy: 0.4701\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8662 - accuracy: 0.5593 - val_loss: 1.0145 - val_accuracy: 0.4701\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8660 - accuracy: 0.5593 - val_loss: 1.0176 - val_accuracy: 0.4701\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8653 - accuracy: 0.5593 - val_loss: 1.0157 - val_accuracy: 0.4701\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8646 - accuracy: 0.5185 - val_loss: 1.0126 - val_accuracy: 0.5299\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8624 - accuracy: 0.5741 - val_loss: 1.0137 - val_accuracy: 0.4701\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8642 - accuracy: 0.5593 - val_loss: 1.0174 - val_accuracy: 0.4701\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8648 - accuracy: 0.5593 - val_loss: 1.0214 - val_accuracy: 0.4615\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8643 - accuracy: 0.5593 - val_loss: 1.0143 - val_accuracy: 0.4701\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8650 - accuracy: 0.5407 - val_loss: 1.0101 - val_accuracy: 0.5299\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8661 - accuracy: 0.5519 - val_loss: 1.0105 - val_accuracy: 0.5299\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8659 - accuracy: 0.5519 - val_loss: 1.0103 - val_accuracy: 0.5299\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8663 - accuracy: 0.5519 - val_loss: 1.0160 - val_accuracy: 0.5299\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8646 - accuracy: 0.5519 - val_loss: 1.0155 - val_accuracy: 0.5299\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8638 - accuracy: 0.5444 - val_loss: 1.0166 - val_accuracy: 0.4701\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8622 - accuracy: 0.5593 - val_loss: 1.0164 - val_accuracy: 0.4701\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8619 - accuracy: 0.5481 - val_loss: 1.0141 - val_accuracy: 0.5299\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8638 - accuracy: 0.5519 - val_loss: 1.0137 - val_accuracy: 0.5299\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8622 - accuracy: 0.5333 - val_loss: 1.0177 - val_accuracy: 0.4701\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8617 - accuracy: 0.5593 - val_loss: 1.0200 - val_accuracy: 0.4615\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8632 - accuracy: 0.5593 - val_loss: 1.0150 - val_accuracy: 0.5299\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8607 - accuracy: 0.5519 - val_loss: 1.0175 - val_accuracy: 0.5299\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8636 - accuracy: 0.5519 - val_loss: 1.0205 - val_accuracy: 0.5299\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8634 - accuracy: 0.5519 - val_loss: 1.0174 - val_accuracy: 0.5299\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8611 - accuracy: 0.5444 - val_loss: 1.0180 - val_accuracy: 0.4701\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8608 - accuracy: 0.5593 - val_loss: 1.0177 - val_accuracy: 0.4701\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8614 - accuracy: 0.5593 - val_loss: 1.0165 - val_accuracy: 0.4701\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8595 - accuracy: 0.5481 - val_loss: 1.0195 - val_accuracy: 0.5299\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8632 - accuracy: 0.5519 - val_loss: 1.0278 - val_accuracy: 0.5299\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8628 - accuracy: 0.5519 - val_loss: 1.0214 - val_accuracy: 0.5299\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8625 - accuracy: 0.5296 - val_loss: 1.0210 - val_accuracy: 0.5299\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8666 - accuracy: 0.5519 - val_loss: 1.0219 - val_accuracy: 0.5299\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8629 - accuracy: 0.5481 - val_loss: 1.0286 - val_accuracy: 0.4701\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8629 - accuracy: 0.5593 - val_loss: 1.0342 - val_accuracy: 0.4701\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8644 - accuracy: 0.5593 - val_loss: 1.0251 - val_accuracy: 0.4701\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8596 - accuracy: 0.5593 - val_loss: 1.0215 - val_accuracy: 0.4701\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8609 - accuracy: 0.5481 - val_loss: 1.0208 - val_accuracy: 0.5299\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8676 - accuracy: 0.5519 - val_loss: 1.0216 - val_accuracy: 0.5299\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8626 - accuracy: 0.5519 - val_loss: 1.0201 - val_accuracy: 0.4701\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8595 - accuracy: 0.5593 - val_loss: 1.0246 - val_accuracy: 0.4701\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8620 - accuracy: 0.5593 - val_loss: 1.0355 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8645 - accuracy: 0.5593 - val_loss: 1.0299 - val_accuracy: 0.4615\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8609 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.5299\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8622 - accuracy: 0.5519 - val_loss: 1.0222 - val_accuracy: 0.5299\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8609 - accuracy: 0.5333 - val_loss: 1.0223 - val_accuracy: 0.4701\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8590 - accuracy: 0.5593 - val_loss: 1.0219 - val_accuracy: 0.4701\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8594 - accuracy: 0.5593 - val_loss: 1.0201 - val_accuracy: 0.4701\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8617 - accuracy: 0.5593 - val_loss: 1.0200 - val_accuracy: 0.4701\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8646 - accuracy: 0.5593 - val_loss: 1.0182 - val_accuracy: 0.4701\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8582 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.5299\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8607 - accuracy: 0.5519 - val_loss: 1.0168 - val_accuracy: 0.5299\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8591 - accuracy: 0.5519 - val_loss: 1.0193 - val_accuracy: 0.4701\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8582 - accuracy: 0.5593 - val_loss: 1.0251 - val_accuracy: 0.4701\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8588 - accuracy: 0.5593 - val_loss: 1.0291 - val_accuracy: 0.4701\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8592 - accuracy: 0.5593 - val_loss: 1.0297 - val_accuracy: 0.4701\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8579 - accuracy: 0.5593 - val_loss: 1.0283 - val_accuracy: 0.4701\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8582 - accuracy: 0.5444 - val_loss: 1.0285 - val_accuracy: 0.5299\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8600 - accuracy: 0.5519 - val_loss: 1.0270 - val_accuracy: 0.5299\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8594 - accuracy: 0.5333 - val_loss: 1.0318 - val_accuracy: 0.4701\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8581 - accuracy: 0.5593 - val_loss: 1.0263 - val_accuracy: 0.4701\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8589 - accuracy: 0.5370 - val_loss: 1.0241 - val_accuracy: 0.5299\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8592 - accuracy: 0.5519 - val_loss: 1.0256 - val_accuracy: 0.5299\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8586 - accuracy: 0.5778 - val_loss: 1.0335 - val_accuracy: 0.4701\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8591 - accuracy: 0.5593 - val_loss: 1.0343 - val_accuracy: 0.4701\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8590 - accuracy: 0.5593 - val_loss: 1.0275 - val_accuracy: 0.4701\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8590 - accuracy: 0.5444 - val_loss: 1.0282 - val_accuracy: 0.5299\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8635 - accuracy: 0.5519 - val_loss: 1.0274 - val_accuracy: 0.5299\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8589 - accuracy: 0.5519 - val_loss: 1.0266 - val_accuracy: 0.4701\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8565 - accuracy: 0.5593 - val_loss: 1.0327 - val_accuracy: 0.4615\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8608 - accuracy: 0.5593 - val_loss: 1.0375 - val_accuracy: 0.4615\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8619 - accuracy: 0.5593 - val_loss: 1.0283 - val_accuracy: 0.4615\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8591 - accuracy: 0.5593 - val_loss: 1.0345 - val_accuracy: 0.4615\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8601 - accuracy: 0.5407 - val_loss: 1.0323 - val_accuracy: 0.4615\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8568 - accuracy: 0.5593 - val_loss: 1.0280 - val_accuracy: 0.4701\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8576 - accuracy: 0.5593 - val_loss: 1.0252 - val_accuracy: 0.4701\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8567 - accuracy: 0.5593 - val_loss: 1.0262 - val_accuracy: 0.4701\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8566 - accuracy: 0.5593 - val_loss: 1.0276 - val_accuracy: 0.4701\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8548 - accuracy: 0.5481 - val_loss: 1.0316 - val_accuracy: 0.5299\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8563 - accuracy: 0.5519 - val_loss: 1.0361 - val_accuracy: 0.4701\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8560 - accuracy: 0.5593 - val_loss: 1.0358 - val_accuracy: 0.4701\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8554 - accuracy: 0.5593 - val_loss: 1.0335 - val_accuracy: 0.4701\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8553 - accuracy: 0.5593 - val_loss: 1.0345 - val_accuracy: 0.4701\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8552 - accuracy: 0.5593 - val_loss: 1.0297 - val_accuracy: 0.4701\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8565 - accuracy: 0.5556 - val_loss: 1.0280 - val_accuracy: 0.5299\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8553 - accuracy: 0.5519 - val_loss: 1.0275 - val_accuracy: 0.5299\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8540 - accuracy: 0.5778 - val_loss: 1.0314 - val_accuracy: 0.4701\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8554 - accuracy: 0.5593 - val_loss: 1.0360 - val_accuracy: 0.4701\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8558 - accuracy: 0.5593 - val_loss: 1.0319 - val_accuracy: 0.4701\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8561 - accuracy: 0.5593 - val_loss: 1.0305 - val_accuracy: 0.5299\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8571 - accuracy: 0.5519 - val_loss: 1.0367 - val_accuracy: 0.5299\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8566 - accuracy: 0.5519 - val_loss: 1.0375 - val_accuracy: 0.5299\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8525 - accuracy: 0.5778 - val_loss: 1.0370 - val_accuracy: 0.4701\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8551 - accuracy: 0.5593 - val_loss: 1.0354 - val_accuracy: 0.4701\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8070 - accuracy: 0.56 - 0s 38us/step - loss: 0.8585 - accuracy: 0.5741 - val_loss: 1.0340 - val_accuracy: 0.4701\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8538 - accuracy: 0.5593 - val_loss: 1.0445 - val_accuracy: 0.4701\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8561 - accuracy: 0.5593 - val_loss: 1.0463 - val_accuracy: 0.4701\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8555 - accuracy: 0.5407 - val_loss: 1.0363 - val_accuracy: 0.5299\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8547 - accuracy: 0.5444 - val_loss: 1.0363 - val_accuracy: 0.4701\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8538 - accuracy: 0.5593 - val_loss: 1.0358 - val_accuracy: 0.4701\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8546 - accuracy: 0.5593 - val_loss: 1.0404 - val_accuracy: 0.4701\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8538 - accuracy: 0.5593 - val_loss: 1.0383 - val_accuracy: 0.4701\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8534 - accuracy: 0.5259 - val_loss: 1.0342 - val_accuracy: 0.5299\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 1.0350 - val_accuracy: 0.4701\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8534 - accuracy: 0.5593 - val_loss: 1.0328 - val_accuracy: 0.4701\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8513 - accuracy: 0.5556 - val_loss: 1.0331 - val_accuracy: 0.5299\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8510 - accuracy: 0.5519 - val_loss: 1.0323 - val_accuracy: 0.5299\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8518 - accuracy: 0.5519 - val_loss: 1.0330 - val_accuracy: 0.4701\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8527 - accuracy: 0.5593 - val_loss: 1.0363 - val_accuracy: 0.4701\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8511 - accuracy: 0.5593 - val_loss: 1.0384 - val_accuracy: 0.4701\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8509 - accuracy: 0.5593 - val_loss: 1.0431 - val_accuracy: 0.4701\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8524 - accuracy: 0.5593 - val_loss: 1.0434 - val_accuracy: 0.4701\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8529 - accuracy: 0.5593 - val_loss: 1.0408 - val_accuracy: 0.5299\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8531 - accuracy: 0.5519 - val_loss: 1.0356 - val_accuracy: 0.5299\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8555 - accuracy: 0.5519 - val_loss: 1.0312 - val_accuracy: 0.5299\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8519 - accuracy: 0.5704 - val_loss: 1.0358 - val_accuracy: 0.4701\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8533 - accuracy: 0.5593 - val_loss: 1.0455 - val_accuracy: 0.4701\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8565 - accuracy: 0.5593 - val_loss: 1.0366 - val_accuracy: 0.4701\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8527 - accuracy: 0.5593 - val_loss: 1.0306 - val_accuracy: 0.5299\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8528 - accuracy: 0.5519 - val_loss: 1.0329 - val_accuracy: 0.5299\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8549 - accuracy: 0.5519 - val_loss: 1.0369 - val_accuracy: 0.5299\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8551 - accuracy: 0.5407 - val_loss: 1.0490 - val_accuracy: 0.4701\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8591 - accuracy: 0.5593 - val_loss: 1.0509 - val_accuracy: 0.4701\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8524 - accuracy: 0.5593 - val_loss: 1.0420 - val_accuracy: 0.4701\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8481 - accuracy: 0.5741 - val_loss: 1.0376 - val_accuracy: 0.5299\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8527 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.5299\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8527 - accuracy: 0.5407 - val_loss: 1.0402 - val_accuracy: 0.4701\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8493 - accuracy: 0.5593 - val_loss: 1.0471 - val_accuracy: 0.4701\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8534 - accuracy: 0.5593 - val_loss: 1.0512 - val_accuracy: 0.4701\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8514 - accuracy: 0.5667 - val_loss: 1.0413 - val_accuracy: 0.5299\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8514 - accuracy: 0.5519 - val_loss: 1.0455 - val_accuracy: 0.5299\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8559 - accuracy: 0.5519 - val_loss: 1.0437 - val_accuracy: 0.5299\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8542 - accuracy: 0.5519 - val_loss: 1.0406 - val_accuracy: 0.5299\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8509 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.4701\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8514 - accuracy: 0.5593 - val_loss: 1.0468 - val_accuracy: 0.4701\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8527 - accuracy: 0.5593 - val_loss: 1.0445 - val_accuracy: 0.4701\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8509 - accuracy: 0.5556 - val_loss: 1.0389 - val_accuracy: 0.5299\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8509 - accuracy: 0.5519 - val_loss: 1.0385 - val_accuracy: 0.5299\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8499 - accuracy: 0.5481 - val_loss: 1.0399 - val_accuracy: 0.4701\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8508 - accuracy: 0.5593 - val_loss: 1.0402 - val_accuracy: 0.4701\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8522 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4701\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8498 - accuracy: 0.5593 - val_loss: 1.0400 - val_accuracy: 0.4701\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8521 - accuracy: 0.5333 - val_loss: 1.0460 - val_accuracy: 0.5299\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8514 - accuracy: 0.5519 - val_loss: 1.0473 - val_accuracy: 0.5299\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8475 - accuracy: 0.5519 - val_loss: 1.0398 - val_accuracy: 0.5299\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8498 - accuracy: 0.5519 - val_loss: 1.0366 - val_accuracy: 0.4701\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8521 - accuracy: 0.5593 - val_loss: 1.0366 - val_accuracy: 0.4701\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8502 - accuracy: 0.5593 - val_loss: 1.0389 - val_accuracy: 0.4701\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8526 - accuracy: 0.5593 - val_loss: 1.0484 - val_accuracy: 0.4701\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8533 - accuracy: 0.5593 - val_loss: 1.0430 - val_accuracy: 0.5299\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8508 - accuracy: 0.5519 - val_loss: 1.0379 - val_accuracy: 0.5299\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8496 - accuracy: 0.5519 - val_loss: 1.0384 - val_accuracy: 0.5299\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8486 - accuracy: 0.5407 - val_loss: 1.0373 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8472 - accuracy: 0.5593 - val_loss: 1.0387 - val_accuracy: 0.4701\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8476 - accuracy: 0.5593 - val_loss: 1.0395 - val_accuracy: 0.4701\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8469 - accuracy: 0.5667 - val_loss: 1.0381 - val_accuracy: 0.5299\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8525 - accuracy: 0.5519 - val_loss: 1.0451 - val_accuracy: 0.5299\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8518 - accuracy: 0.5519 - val_loss: 1.0395 - val_accuracy: 0.5299\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8499 - accuracy: 0.5519 - val_loss: 1.0396 - val_accuracy: 0.5299\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8481 - accuracy: 0.5519 - val_loss: 1.0440 - val_accuracy: 0.5299\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8488 - accuracy: 0.5519 - val_loss: 1.0436 - val_accuracy: 0.5299\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8481 - accuracy: 0.5519 - val_loss: 1.0418 - val_accuracy: 0.5299\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8498 - accuracy: 0.5519 - val_loss: 1.0426 - val_accuracy: 0.4701\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8489 - accuracy: 0.5593 - val_loss: 1.0454 - val_accuracy: 0.4701\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8466 - accuracy: 0.5593 - val_loss: 1.0511 - val_accuracy: 0.4701\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8507 - accuracy: 0.5593 - val_loss: 1.0591 - val_accuracy: 0.4701\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8501 - accuracy: 0.5481 - val_loss: 1.0505 - val_accuracy: 0.4701\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8477 - accuracy: 0.5593 - val_loss: 1.0431 - val_accuracy: 0.4701\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8487 - accuracy: 0.5333 - val_loss: 1.0409 - val_accuracy: 0.5299\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8506 - accuracy: 0.5519 - val_loss: 1.0418 - val_accuracy: 0.5299\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8480 - accuracy: 0.5519 - val_loss: 1.0478 - val_accuracy: 0.5299\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8472 - accuracy: 0.5407 - val_loss: 1.0482 - val_accuracy: 0.4701\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8458 - accuracy: 0.5593 - val_loss: 1.0450 - val_accuracy: 0.4701\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8478 - accuracy: 0.5593 - val_loss: 1.0434 - val_accuracy: 0.4701\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8463 - accuracy: 0.5704 - val_loss: 1.0452 - val_accuracy: 0.5299\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8476 - accuracy: 0.5519 - val_loss: 1.0516 - val_accuracy: 0.5299\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8486 - accuracy: 0.5519 - val_loss: 1.0512 - val_accuracy: 0.5299\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8509 - accuracy: 0.5407 - val_loss: 1.0561 - val_accuracy: 0.4701\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8476 - accuracy: 0.5593 - val_loss: 1.0498 - val_accuracy: 0.4701\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8464 - accuracy: 0.5593 - val_loss: 1.0429 - val_accuracy: 0.4701\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8509 - accuracy: 0.5444 - val_loss: 1.0423 - val_accuracy: 0.5299\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8541 - accuracy: 0.5519 - val_loss: 1.0438 - val_accuracy: 0.5299\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8499 - accuracy: 0.5519 - val_loss: 1.0456 - val_accuracy: 0.5214\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8460 - accuracy: 0.5667 - val_loss: 1.0516 - val_accuracy: 0.4615\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8470 - accuracy: 0.5593 - val_loss: 1.0474 - val_accuracy: 0.4615\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8456 - accuracy: 0.5593 - val_loss: 1.0476 - val_accuracy: 0.4615\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8484 - accuracy: 0.5593 - val_loss: 1.0521 - val_accuracy: 0.4615\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8493 - accuracy: 0.5593 - val_loss: 1.0483 - val_accuracy: 0.4615\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8456 - accuracy: 0.5593 - val_loss: 1.0524 - val_accuracy: 0.4615\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8457 - accuracy: 0.5407 - val_loss: 1.0547 - val_accuracy: 0.5214\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8479 - accuracy: 0.5519 - val_loss: 1.0501 - val_accuracy: 0.5299\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8448 - accuracy: 0.5481 - val_loss: 1.0511 - val_accuracy: 0.4701\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8460 - accuracy: 0.5593 - val_loss: 1.0507 - val_accuracy: 0.4701\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8468 - accuracy: 0.5593 - val_loss: 1.0464 - val_accuracy: 0.4701\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8455 - accuracy: 0.5593 - val_loss: 1.0441 - val_accuracy: 0.4701\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8445 - accuracy: 0.5593 - val_loss: 1.0458 - val_accuracy: 0.4701\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8451 - accuracy: 0.5593 - val_loss: 1.0444 - val_accuracy: 0.4701\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8437 - accuracy: 0.5593 - val_loss: 1.0453 - val_accuracy: 0.4701\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8450 - accuracy: 0.5593 - val_loss: 1.0470 - val_accuracy: 0.4701\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8449 - accuracy: 0.5593 - val_loss: 1.0502 - val_accuracy: 0.4701\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8467 - accuracy: 0.5593 - val_loss: 1.0503 - val_accuracy: 0.4615\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8441 - accuracy: 0.5630 - val_loss: 1.0479 - val_accuracy: 0.5299\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.0475 - val_accuracy: 0.5299\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8420 - accuracy: 0.5704 - val_loss: 1.0475 - val_accuracy: 0.4701\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8440 - accuracy: 0.5593 - val_loss: 1.0519 - val_accuracy: 0.4701\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8473 - accuracy: 0.5593 - val_loss: 1.0509 - val_accuracy: 0.4701\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8497 - accuracy: 0.5630 - val_loss: 1.0457 - val_accuracy: 0.5299\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8512 - accuracy: 0.5519 - val_loss: 1.0447 - val_accuracy: 0.5299\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8482 - accuracy: 0.5519 - val_loss: 1.0440 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8436 - accuracy: 0.5593 - val_loss: 1.0480 - val_accuracy: 0.4615\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8437 - accuracy: 0.5593 - val_loss: 1.0458 - val_accuracy: 0.5299\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.0468 - val_accuracy: 0.5299\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0541 - val_accuracy: 0.5214\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0529 - val_accuracy: 0.4615\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 1.0526 - val_accuracy: 0.4615\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.48 - 0s 50us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 1.0510 - val_accuracy: 0.4701\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8449 - accuracy: 0.5593 - val_loss: 1.0503 - val_accuracy: 0.4701\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8437 - accuracy: 0.5630 - val_loss: 1.0506 - val_accuracy: 0.5299\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0537 - val_accuracy: 0.5299\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0623 - val_accuracy: 0.5299\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0551 - val_accuracy: 0.5299\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0496 - val_accuracy: 0.5299\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0493 - val_accuracy: 0.5299\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8439 - accuracy: 0.5481 - val_loss: 1.0486 - val_accuracy: 0.4701\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8420 - accuracy: 0.5593 - val_loss: 1.0493 - val_accuracy: 0.4701\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8446 - accuracy: 0.5593 - val_loss: 1.0470 - val_accuracy: 0.4701\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8445 - accuracy: 0.5593 - val_loss: 1.0465 - val_accuracy: 0.4701\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8439 - accuracy: 0.5407 - val_loss: 1.0459 - val_accuracy: 0.5299\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.0456 - val_accuracy: 0.5299\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8474 - accuracy: 0.5519 - val_loss: 1.0467 - val_accuracy: 0.5299\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8479 - accuracy: 0.5519 - val_loss: 1.0500 - val_accuracy: 0.4701\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8418 - accuracy: 0.5593 - val_loss: 1.0551 - val_accuracy: 0.4701\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8425 - accuracy: 0.5593 - val_loss: 1.0580 - val_accuracy: 0.4701\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8425 - accuracy: 0.5593 - val_loss: 1.0609 - val_accuracy: 0.4701\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8434 - accuracy: 0.5593 - val_loss: 1.0562 - val_accuracy: 0.4701\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8444 - accuracy: 0.5593 - val_loss: 1.0530 - val_accuracy: 0.4701\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8449 - accuracy: 0.5593 - val_loss: 1.0493 - val_accuracy: 0.4701\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8421 - accuracy: 0.5481 - val_loss: 1.0499 - val_accuracy: 0.5299\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0528 - val_accuracy: 0.5299\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8425 - accuracy: 0.5519 - val_loss: 1.0558 - val_accuracy: 0.4615\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8438 - accuracy: 0.5593 - val_loss: 1.0648 - val_accuracy: 0.4615\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8467 - accuracy: 0.5593 - val_loss: 1.0555 - val_accuracy: 0.4615\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8436 - accuracy: 0.5593 - val_loss: 1.0514 - val_accuracy: 0.4701\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8406 - accuracy: 0.5741 - val_loss: 1.0490 - val_accuracy: 0.5299\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0487 - val_accuracy: 0.5299\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8407 - accuracy: 0.5593 - val_loss: 1.0565 - val_accuracy: 0.4701\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8435 - accuracy: 0.5593 - val_loss: 1.0549 - val_accuracy: 0.4701\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 1.0525 - val_accuracy: 0.4701\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8410 - accuracy: 0.5741 - val_loss: 1.0439 - val_accuracy: 0.5299\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8464 - accuracy: 0.5519 - val_loss: 1.0462 - val_accuracy: 0.5214\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8503 - accuracy: 0.5519 - val_loss: 1.0477 - val_accuracy: 0.5299\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0567 - val_accuracy: 0.5299\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.0568 - val_accuracy: 0.5299\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8417 - accuracy: 0.5556 - val_loss: 1.0500 - val_accuracy: 0.4701\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 1.0506 - val_accuracy: 0.4701\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8414 - accuracy: 0.5593 - val_loss: 1.0574 - val_accuracy: 0.4701\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8415 - accuracy: 0.5593 - val_loss: 1.0602 - val_accuracy: 0.4615\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.0624 - val_accuracy: 0.4615\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8406 - accuracy: 0.5593 - val_loss: 1.0530 - val_accuracy: 0.4701\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8423 - accuracy: 0.5741 - val_loss: 1.0564 - val_accuracy: 0.5214\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 1.0564 - val_accuracy: 0.4615\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8441 - accuracy: 0.5630 - val_loss: 1.0605 - val_accuracy: 0.4701\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8468 - accuracy: 0.5593 - val_loss: 1.0638 - val_accuracy: 0.4615\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8416 - accuracy: 0.5593 - val_loss: 1.0620 - val_accuracy: 0.5214\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.0642 - val_accuracy: 0.5214\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0554 - val_accuracy: 0.5214\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8417 - accuracy: 0.5704 - val_loss: 1.0547 - val_accuracy: 0.4615\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8428 - accuracy: 0.5593 - val_loss: 1.0567 - val_accuracy: 0.4615\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8422 - accuracy: 0.5593 - val_loss: 1.0544 - val_accuracy: 0.4615\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8402 - accuracy: 0.5556 - val_loss: 1.0525 - val_accuracy: 0.5299\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.0546 - val_accuracy: 0.5299\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0524 - val_accuracy: 0.5299\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.0556 - val_accuracy: 0.4701\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8414 - accuracy: 0.5593 - val_loss: 1.0575 - val_accuracy: 0.4701\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8408 - accuracy: 0.5593 - val_loss: 1.0598 - val_accuracy: 0.4701\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8392 - accuracy: 0.5593 - val_loss: 1.0689 - val_accuracy: 0.4615\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8441 - accuracy: 0.5593 - val_loss: 1.0702 - val_accuracy: 0.4615\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 1.0620 - val_accuracy: 0.4615\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8386 - accuracy: 0.5630 - val_loss: 1.0608 - val_accuracy: 0.4701\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8446 - accuracy: 0.5259 - val_loss: 1.0580 - val_accuracy: 0.4615\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.0649 - val_accuracy: 0.4701\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8530 - accuracy: 0.5593 - val_loss: 1.0770 - val_accuracy: 0.4615\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8483 - accuracy: 0.5593 - val_loss: 1.0636 - val_accuracy: 0.4615\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8407 - accuracy: 0.5519 - val_loss: 1.0606 - val_accuracy: 0.5299\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8399 - accuracy: 0.5556 - val_loss: 1.0633 - val_accuracy: 0.4615\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8412 - accuracy: 0.5593 - val_loss: 1.0770 - val_accuracy: 0.4615\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8453 - accuracy: 0.5593 - val_loss: 1.0739 - val_accuracy: 0.4615\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8412 - accuracy: 0.5593 - val_loss: 1.0696 - val_accuracy: 0.4615\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8415 - accuracy: 0.5593 - val_loss: 1.0662 - val_accuracy: 0.5214\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8406 - accuracy: 0.5556 - val_loss: 1.0649 - val_accuracy: 0.5214\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8389 - accuracy: 0.5667 - val_loss: 1.0668 - val_accuracy: 0.4615\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8410 - accuracy: 0.5593 - val_loss: 1.0721 - val_accuracy: 0.4615\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8431 - accuracy: 0.5593 - val_loss: 1.0722 - val_accuracy: 0.4615\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8411 - accuracy: 0.5593 - val_loss: 1.0728 - val_accuracy: 0.4615\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8395 - accuracy: 0.5481 - val_loss: 1.0704 - val_accuracy: 0.5214\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8416 - accuracy: 0.5556 - val_loss: 1.0740 - val_accuracy: 0.5214\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8385 - accuracy: 0.5556 - val_loss: 1.0683 - val_accuracy: 0.5299\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8411 - accuracy: 0.5556 - val_loss: 1.0644 - val_accuracy: 0.5299\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8389 - accuracy: 0.5444 - val_loss: 1.0685 - val_accuracy: 0.4615\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8477 - accuracy: 0.5593 - val_loss: 1.0804 - val_accuracy: 0.4615\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 1.0751 - val_accuracy: 0.5214\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.0699 - val_accuracy: 0.5299\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0706 - val_accuracy: 0.5299\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.0691 - val_accuracy: 0.5299\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8418 - accuracy: 0.5556 - val_loss: 1.0666 - val_accuracy: 0.5299\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.0765 - val_accuracy: 0.4615\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8465 - accuracy: 0.5593 - val_loss: 1.0896 - val_accuracy: 0.4615\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8455 - accuracy: 0.5593 - val_loss: 1.0683 - val_accuracy: 0.4701\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8365 - accuracy: 0.5556 - val_loss: 1.0618 - val_accuracy: 0.5299\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8418 - accuracy: 0.5556 - val_loss: 1.0610 - val_accuracy: 0.5299\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8420 - accuracy: 0.5556 - val_loss: 1.0649 - val_accuracy: 0.5299\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8366 - accuracy: 0.5778 - val_loss: 1.0674 - val_accuracy: 0.4615\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8392 - accuracy: 0.5593 - val_loss: 1.0659 - val_accuracy: 0.4701\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8396 - accuracy: 0.5704 - val_loss: 1.0600 - val_accuracy: 0.5299\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8402 - accuracy: 0.5556 - val_loss: 1.0614 - val_accuracy: 0.5299\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8403 - accuracy: 0.5556 - val_loss: 1.0631 - val_accuracy: 0.5299\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8382 - accuracy: 0.5556 - val_loss: 1.0629 - val_accuracy: 0.5299\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8377 - accuracy: 0.5481 - val_loss: 1.0648 - val_accuracy: 0.4701\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8378 - accuracy: 0.5593 - val_loss: 1.0664 - val_accuracy: 0.5214\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8370 - accuracy: 0.5556 - val_loss: 1.0646 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8384 - accuracy: 0.5556 - val_loss: 1.0647 - val_accuracy: 0.5299\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8417 - accuracy: 0.5556 - val_loss: 1.0630 - val_accuracy: 0.5299\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8372 - accuracy: 0.5667 - val_loss: 1.0691 - val_accuracy: 0.4615\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8385 - accuracy: 0.5593 - val_loss: 1.0787 - val_accuracy: 0.4615\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8382 - accuracy: 0.5593 - val_loss: 1.0733 - val_accuracy: 0.4615\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8370 - accuracy: 0.5704 - val_loss: 1.0740 - val_accuracy: 0.5214\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.0729 - val_accuracy: 0.5299\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8421 - accuracy: 0.5556 - val_loss: 1.0699 - val_accuracy: 0.5299\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.0702 - val_accuracy: 0.4615\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8384 - accuracy: 0.5593 - val_loss: 1.0718 - val_accuracy: 0.4701\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8418 - accuracy: 0.5593 - val_loss: 1.0665 - val_accuracy: 0.4701\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8382 - accuracy: 0.5593 - val_loss: 1.0628 - val_accuracy: 0.4701\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8390 - accuracy: 0.5296 - val_loss: 1.0619 - val_accuracy: 0.5299\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8373 - accuracy: 0.5556 - val_loss: 1.0608 - val_accuracy: 0.5299\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8369 - accuracy: 0.5556 - val_loss: 1.0625 - val_accuracy: 0.4701\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8372 - accuracy: 0.5630 - val_loss: 1.0658 - val_accuracy: 0.4615\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8361 - accuracy: 0.5593 - val_loss: 1.0652 - val_accuracy: 0.5214\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8370 - accuracy: 0.5556 - val_loss: 1.0656 - val_accuracy: 0.5214\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8362 - accuracy: 0.5556 - val_loss: 1.0670 - val_accuracy: 0.5214\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8387 - accuracy: 0.5259 - val_loss: 1.0751 - val_accuracy: 0.4615\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8404 - accuracy: 0.5593 - val_loss: 1.0722 - val_accuracy: 0.4701\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 1.0673 - val_accuracy: 0.5299\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8372 - accuracy: 0.5556 - val_loss: 1.0715 - val_accuracy: 0.5299\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.0726 - val_accuracy: 0.5214\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8405 - accuracy: 0.5556 - val_loss: 1.0687 - val_accuracy: 0.5214\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8349 - accuracy: 0.5852 - val_loss: 1.0687 - val_accuracy: 0.4615\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8391 - accuracy: 0.5593 - val_loss: 1.0734 - val_accuracy: 0.4615\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8414 - accuracy: 0.5593 - val_loss: 1.0722 - val_accuracy: 0.4615\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8394 - accuracy: 0.5593 - val_loss: 1.0764 - val_accuracy: 0.4615\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8370 - accuracy: 0.5630 - val_loss: 1.0734 - val_accuracy: 0.5214\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8378 - accuracy: 0.5556 - val_loss: 1.0760 - val_accuracy: 0.5214\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8411 - accuracy: 0.5556 - val_loss: 1.0795 - val_accuracy: 0.5214\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8422 - accuracy: 0.5556 - val_loss: 1.0748 - val_accuracy: 0.5299\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8384 - accuracy: 0.5556 - val_loss: 1.0704 - val_accuracy: 0.4615\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 1.0764 - val_accuracy: 0.4615\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8426 - accuracy: 0.5593 - val_loss: 1.0793 - val_accuracy: 0.4615\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8411 - accuracy: 0.5593 - val_loss: 1.0764 - val_accuracy: 0.4615\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 1.0732 - val_accuracy: 0.4615\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8368 - accuracy: 0.5630 - val_loss: 1.0827 - val_accuracy: 0.4615\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8388 - accuracy: 0.5926 - val_loss: 1.0772 - val_accuracy: 0.5214\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.0727 - val_accuracy: 0.5214\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.0697 - val_accuracy: 0.4615\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8396 - accuracy: 0.5667 - val_loss: 1.0713 - val_accuracy: 0.4615\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8391 - accuracy: 0.5593 - val_loss: 1.0701 - val_accuracy: 0.4615\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8389 - accuracy: 0.5593 - val_loss: 1.0687 - val_accuracy: 0.4615\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8370 - accuracy: 0.5593 - val_loss: 1.0734 - val_accuracy: 0.4615\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8366 - accuracy: 0.5593 - val_loss: 1.0806 - val_accuracy: 0.4615\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8357 - accuracy: 0.5630 - val_loss: 1.0784 - val_accuracy: 0.5214\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8359 - accuracy: 0.5556 - val_loss: 1.0770 - val_accuracy: 0.5214\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8385 - accuracy: 0.5444 - val_loss: 1.0851 - val_accuracy: 0.4615\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 1.0826 - val_accuracy: 0.4615\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8351 - accuracy: 0.5630 - val_loss: 1.0809 - val_accuracy: 0.4615\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8355 - accuracy: 0.5481 - val_loss: 1.0763 - val_accuracy: 0.5214\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8341 - accuracy: 0.5519 - val_loss: 1.0765 - val_accuracy: 0.4615\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8366 - accuracy: 0.5630 - val_loss: 1.0771 - val_accuracy: 0.4701\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8351 - accuracy: 0.5444 - val_loss: 1.0839 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8367 - accuracy: 0.5519 - val_loss: 1.0942 - val_accuracy: 0.4615\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8399 - accuracy: 0.5630 - val_loss: 1.0919 - val_accuracy: 0.4615\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8353 - accuracy: 0.5111 - val_loss: 1.0815 - val_accuracy: 0.4615\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8342 - accuracy: 0.5630 - val_loss: 1.0818 - val_accuracy: 0.4701\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8369 - accuracy: 0.5667 - val_loss: 1.0806 - val_accuracy: 0.4701\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8348 - accuracy: 0.5630 - val_loss: 1.0825 - val_accuracy: 0.4615\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 1.0780 - val_accuracy: 0.4615\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8345 - accuracy: 0.5556 - val_loss: 1.0773 - val_accuracy: 0.5214\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8345 - accuracy: 0.5481 - val_loss: 1.0768 - val_accuracy: 0.5214\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8345 - accuracy: 0.5556 - val_loss: 1.0744 - val_accuracy: 0.5214\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8353 - accuracy: 0.5556 - val_loss: 1.0745 - val_accuracy: 0.5214\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8345 - accuracy: 0.5704 - val_loss: 1.0759 - val_accuracy: 0.4615\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 1.0808 - val_accuracy: 0.4615\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 1.0793 - val_accuracy: 0.5214\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8343 - accuracy: 0.5481 - val_loss: 1.0764 - val_accuracy: 0.4615\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8359 - accuracy: 0.5222 - val_loss: 1.0753 - val_accuracy: 0.5214\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8351 - accuracy: 0.5556 - val_loss: 1.0721 - val_accuracy: 0.5214\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8361 - accuracy: 0.5556 - val_loss: 1.0712 - val_accuracy: 0.5214\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8348 - accuracy: 0.5333 - val_loss: 1.0729 - val_accuracy: 0.4615\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 1.0753 - val_accuracy: 0.4615\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 1.0868 - val_accuracy: 0.4615\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8359 - accuracy: 0.5630 - val_loss: 1.0793 - val_accuracy: 0.4615\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8360 - accuracy: 0.5481 - val_loss: 1.0768 - val_accuracy: 0.5214\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8365 - accuracy: 0.5556 - val_loss: 1.0781 - val_accuracy: 0.5214\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8331 - accuracy: 0.5704 - val_loss: 1.0853 - val_accuracy: 0.4615\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8356 - accuracy: 0.5630 - val_loss: 1.0859 - val_accuracy: 0.4615\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8372 - accuracy: 0.5593 - val_loss: 1.0858 - val_accuracy: 0.4615\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8351 - accuracy: 0.5630 - val_loss: 1.0811 - val_accuracy: 0.4615\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8335 - accuracy: 0.5593 - val_loss: 1.0847 - val_accuracy: 0.5214\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8360 - accuracy: 0.5556 - val_loss: 1.0913 - val_accuracy: 0.5214\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.0881 - val_accuracy: 0.4615\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8342 - accuracy: 0.5630 - val_loss: 1.0895 - val_accuracy: 0.4615\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 1.0891 - val_accuracy: 0.4615\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8347 - accuracy: 0.5630 - val_loss: 1.0897 - val_accuracy: 0.4615\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8362 - accuracy: 0.5630 - val_loss: 1.0898 - val_accuracy: 0.4615\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8346 - accuracy: 0.5593 - val_loss: 1.0854 - val_accuracy: 0.5214\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8365 - accuracy: 0.5556 - val_loss: 1.0857 - val_accuracy: 0.5214\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8378 - accuracy: 0.5556 - val_loss: 1.0831 - val_accuracy: 0.5214\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8346 - accuracy: 0.5593 - val_loss: 1.0872 - val_accuracy: 0.4615\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8360 - accuracy: 0.5630 - val_loss: 1.0904 - val_accuracy: 0.4615\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8427 - accuracy: 0.5630 - val_loss: 1.0861 - val_accuracy: 0.4615\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 1.0771 - val_accuracy: 0.5128\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8391 - accuracy: 0.5556 - val_loss: 1.0847 - val_accuracy: 0.5214\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8371 - accuracy: 0.5556 - val_loss: 1.0871 - val_accuracy: 0.4615\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8352 - accuracy: 0.5630 - val_loss: 1.0869 - val_accuracy: 0.4615\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 1.0872 - val_accuracy: 0.4615\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8396 - accuracy: 0.5630 - val_loss: 1.0816 - val_accuracy: 0.4615\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8351 - accuracy: 0.5630 - val_loss: 1.0768 - val_accuracy: 0.5128\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.0797 - val_accuracy: 0.5128\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8346 - accuracy: 0.5556 - val_loss: 1.0853 - val_accuracy: 0.5214\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 1.0895 - val_accuracy: 0.4615\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.0904 - val_accuracy: 0.4615\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 1.0930 - val_accuracy: 0.4615\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8342 - accuracy: 0.5630 - val_loss: 1.0913 - val_accuracy: 0.4615\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8328 - accuracy: 0.5630 - val_loss: 1.0923 - val_accuracy: 0.4615\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 1.0917 - val_accuracy: 0.4615\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8320 - accuracy: 0.5630 - val_loss: 1.0904 - val_accuracy: 0.4615\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.0940 - val_accuracy: 0.4615\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8356 - accuracy: 0.5630 - val_loss: 1.1019 - val_accuracy: 0.4615\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8376 - accuracy: 0.5630 - val_loss: 1.0937 - val_accuracy: 0.4615\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 1.0913 - val_accuracy: 0.4615\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 1.0904 - val_accuracy: 0.4615\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8322 - accuracy: 0.5630 - val_loss: 1.0892 - val_accuracy: 0.4615\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8330 - accuracy: 0.5481 - val_loss: 1.0923 - val_accuracy: 0.5214\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8339 - accuracy: 0.5556 - val_loss: 1.0958 - val_accuracy: 0.5214\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8381 - accuracy: 0.5333 - val_loss: 1.1003 - val_accuracy: 0.5214\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8362 - accuracy: 0.5556 - val_loss: 1.0925 - val_accuracy: 0.5214\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8319 - accuracy: 0.5667 - val_loss: 1.0940 - val_accuracy: 0.4615\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 1.1019 - val_accuracy: 0.4615\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.0987 - val_accuracy: 0.4615\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8318 - accuracy: 0.5593 - val_loss: 1.0948 - val_accuracy: 0.5214\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8319 - accuracy: 0.5556 - val_loss: 1.0939 - val_accuracy: 0.4615\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 1.0966 - val_accuracy: 0.4615\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 1.0946 - val_accuracy: 0.4615\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8345 - accuracy: 0.5630 - val_loss: 1.0895 - val_accuracy: 0.4615\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 1.0979 - val_accuracy: 0.4615\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 1.0996 - val_accuracy: 0.4615\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8388 - accuracy: 0.5630 - val_loss: 1.0949 - val_accuracy: 0.4615\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8354 - accuracy: 0.5630 - val_loss: 1.0908 - val_accuracy: 0.4615\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8331 - accuracy: 0.5296 - val_loss: 1.0820 - val_accuracy: 0.5128\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8368 - accuracy: 0.5556 - val_loss: 1.0818 - val_accuracy: 0.5214\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.54 - 0s 79us/step - loss: 0.8354 - accuracy: 0.5667 - val_loss: 1.0836 - val_accuracy: 0.4615\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8347 - accuracy: 0.5630 - val_loss: 1.0915 - val_accuracy: 0.4615\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 1.0921 - val_accuracy: 0.4615\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 1.0878 - val_accuracy: 0.4615\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8332 - accuracy: 0.5370 - val_loss: 1.0841 - val_accuracy: 0.5214\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8388 - accuracy: 0.5519 - val_loss: 1.0869 - val_accuracy: 0.5128\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8382 - accuracy: 0.5556 - val_loss: 1.0863 - val_accuracy: 0.5214\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8332 - accuracy: 0.5667 - val_loss: 1.0924 - val_accuracy: 0.4615\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 1.0880 - val_accuracy: 0.4615\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8327 - accuracy: 0.5407 - val_loss: 1.0866 - val_accuracy: 0.5128\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8315 - accuracy: 0.5370 - val_loss: 1.0907 - val_accuracy: 0.4615\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 1.0903 - val_accuracy: 0.4615\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 1.0932 - val_accuracy: 0.4615\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8343 - accuracy: 0.5519 - val_loss: 1.0873 - val_accuracy: 0.5128\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8324 - accuracy: 0.5111 - val_loss: 1.0890 - val_accuracy: 0.4615\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 1.0980 - val_accuracy: 0.4615\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 1.0963 - val_accuracy: 0.4615\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8375 - accuracy: 0.5444 - val_loss: 1.0923 - val_accuracy: 0.5128\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8352 - accuracy: 0.5556 - val_loss: 1.0953 - val_accuracy: 0.5128\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8379 - accuracy: 0.5519 - val_loss: 1.1066 - val_accuracy: 0.5214\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8354 - accuracy: 0.5407 - val_loss: 1.1050 - val_accuracy: 0.4615\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 1.1021 - val_accuracy: 0.4615\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8320 - accuracy: 0.5630 - val_loss: 1.0927 - val_accuracy: 0.4530\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8309 - accuracy: 0.5630 - val_loss: 1.0907 - val_accuracy: 0.4530\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 1.0934 - val_accuracy: 0.4615\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8325 - accuracy: 0.5593 - val_loss: 1.0912 - val_accuracy: 0.4615\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 1.0941 - val_accuracy: 0.5214\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8304 - accuracy: 0.5333 - val_loss: 1.0990 - val_accuracy: 0.5214\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8340 - accuracy: 0.5556 - val_loss: 1.0998 - val_accuracy: 0.5214\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 62us/step - loss: 0.8349 - accuracy: 0.5556 - val_loss: 1.0993 - val_accuracy: 0.5214\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8327 - accuracy: 0.5556 - val_loss: 1.1010 - val_accuracy: 0.5214\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8309 - accuracy: 0.5704 - val_loss: 1.0967 - val_accuracy: 0.4615\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8315 - accuracy: 0.5593 - val_loss: 1.0960 - val_accuracy: 0.4615\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 1.0984 - val_accuracy: 0.4615\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 1.1039 - val_accuracy: 0.4615\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8320 - accuracy: 0.5630 - val_loss: 1.1133 - val_accuracy: 0.4615\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8370 - accuracy: 0.5630 - val_loss: 1.1103 - val_accuracy: 0.4615\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 1.1014 - val_accuracy: 0.4615\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8292 - accuracy: 0.5667 - val_loss: 1.0970 - val_accuracy: 0.5128\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8331 - accuracy: 0.5556 - val_loss: 1.0975 - val_accuracy: 0.5128\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8329 - accuracy: 0.5556 - val_loss: 1.0984 - val_accuracy: 0.4530\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 1.0954 - val_accuracy: 0.4615\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8354 - accuracy: 0.5630 - val_loss: 1.1009 - val_accuracy: 0.4615\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8311 - accuracy: 0.5704 - val_loss: 1.0969 - val_accuracy: 0.5214\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8327 - accuracy: 0.5556 - val_loss: 1.0974 - val_accuracy: 0.5214\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8308 - accuracy: 0.5519 - val_loss: 1.0925 - val_accuracy: 0.4530\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 1.0916 - val_accuracy: 0.4530\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 1.0927 - val_accuracy: 0.4530\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8340 - accuracy: 0.5630 - val_loss: 1.0954 - val_accuracy: 0.4615\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8327 - accuracy: 0.5333 - val_loss: 1.0955 - val_accuracy: 0.5128\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8344 - accuracy: 0.5556 - val_loss: 1.0969 - val_accuracy: 0.5128\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8309 - accuracy: 0.5556 - val_loss: 1.1032 - val_accuracy: 0.4615\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.1046 - val_accuracy: 0.4615\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 1.0998 - val_accuracy: 0.4615\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 1.0971 - val_accuracy: 0.5214\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8311 - accuracy: 0.5593 - val_loss: 1.0966 - val_accuracy: 0.5128\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8347 - accuracy: 0.5556 - val_loss: 1.0974 - val_accuracy: 0.5128\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8326 - accuracy: 0.5519 - val_loss: 1.1025 - val_accuracy: 0.4530\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 1.1145 - val_accuracy: 0.4615\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8348 - accuracy: 0.5630 - val_loss: 1.1150 - val_accuracy: 0.4615\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8319 - accuracy: 0.5630 - val_loss: 1.1103 - val_accuracy: 0.4530\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 1.1055 - val_accuracy: 0.4530\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8309 - accuracy: 0.5630 - val_loss: 1.1085 - val_accuracy: 0.4615\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 1.1115 - val_accuracy: 0.4615\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 1.1086 - val_accuracy: 0.5214\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8326 - accuracy: 0.5556 - val_loss: 1.1097 - val_accuracy: 0.5214\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8317 - accuracy: 0.5556 - val_loss: 1.1087 - val_accuracy: 0.5214\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8350 - accuracy: 0.5556 - val_loss: 1.1220 - val_accuracy: 0.4615\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 1.1092 - val_accuracy: 0.4615\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8398 - accuracy: 0.5333 - val_loss: 1.1099 - val_accuracy: 0.5128\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8416 - accuracy: 0.5556 - val_loss: 1.1044 - val_accuracy: 0.5128\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8347 - accuracy: 0.5556 - val_loss: 1.1040 - val_accuracy: 0.5214\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8307 - accuracy: 0.5407 - val_loss: 1.1030 - val_accuracy: 0.4615\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 1.1002 - val_accuracy: 0.4615\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8362 - accuracy: 0.5667 - val_loss: 1.0964 - val_accuracy: 0.4530\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8308 - accuracy: 0.5593 - val_loss: 1.0992 - val_accuracy: 0.4615\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 1.1069 - val_accuracy: 0.4615\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 1.1010 - val_accuracy: 0.5214\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8349 - accuracy: 0.5519 - val_loss: 1.0959 - val_accuracy: 0.5128\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8350 - accuracy: 0.5556 - val_loss: 1.0944 - val_accuracy: 0.5128\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 1.0976 - val_accuracy: 0.4615\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8350 - accuracy: 0.5630 - val_loss: 1.1116 - val_accuracy: 0.4615\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8340 - accuracy: 0.5630 - val_loss: 1.1090 - val_accuracy: 0.4615\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8319 - accuracy: 0.5630 - val_loss: 1.1036 - val_accuracy: 0.4615\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 1.1037 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8302 - accuracy: 0.5630 - val_loss: 1.1002 - val_accuracy: 0.4615\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8292 - accuracy: 0.5630 - val_loss: 1.0997 - val_accuracy: 0.5214\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8318 - accuracy: 0.5556 - val_loss: 1.0984 - val_accuracy: 0.5128\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8308 - accuracy: 0.5556 - val_loss: 1.0987 - val_accuracy: 0.5214\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8339 - accuracy: 0.5444 - val_loss: 1.1041 - val_accuracy: 0.4615\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8311 - accuracy: 0.5519 - val_loss: 1.0961 - val_accuracy: 0.5214\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8304 - accuracy: 0.5519 - val_loss: 1.0981 - val_accuracy: 0.4530\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8323 - accuracy: 0.5593 - val_loss: 1.0976 - val_accuracy: 0.4615\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8292 - accuracy: 0.5704 - val_loss: 1.0969 - val_accuracy: 0.5214\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8351 - accuracy: 0.5556 - val_loss: 1.1052 - val_accuracy: 0.5214\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7792 - accuracy: 0.59 - 0s 66us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.1020 - val_accuracy: 0.5214\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8311 - accuracy: 0.5519 - val_loss: 1.0953 - val_accuracy: 0.4530\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 1.0968 - val_accuracy: 0.4530\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 1.0998 - val_accuracy: 0.4615\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 1.1047 - val_accuracy: 0.4615\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8298 - accuracy: 0.5519 - val_loss: 1.1051 - val_accuracy: 0.5214\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8312 - accuracy: 0.5556 - val_loss: 1.1017 - val_accuracy: 0.5128\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8286 - accuracy: 0.5667 - val_loss: 1.1091 - val_accuracy: 0.4615\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8356 - accuracy: 0.5630 - val_loss: 1.1119 - val_accuracy: 0.4615\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8340 - accuracy: 0.5556 - val_loss: 1.1029 - val_accuracy: 0.5128\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8287 - accuracy: 0.5556 - val_loss: 1.1054 - val_accuracy: 0.4615\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.1097 - val_accuracy: 0.4615\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 1.1087 - val_accuracy: 0.4615\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 1.1092 - val_accuracy: 0.4615\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8296 - accuracy: 0.5667 - val_loss: 1.1099 - val_accuracy: 0.5214\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8301 - accuracy: 0.5296 - val_loss: 1.1119 - val_accuracy: 0.5214\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8294 - accuracy: 0.5519 - val_loss: 1.1127 - val_accuracy: 0.5128\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8329 - accuracy: 0.5556 - val_loss: 1.1126 - val_accuracy: 0.5128\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8298 - accuracy: 0.5481 - val_loss: 1.1148 - val_accuracy: 0.4530\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8295 - accuracy: 0.5593 - val_loss: 1.1146 - val_accuracy: 0.4615\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8287 - accuracy: 0.5630 - val_loss: 1.1174 - val_accuracy: 0.4615\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 1.1226 - val_accuracy: 0.5214\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8317 - accuracy: 0.5556 - val_loss: 1.1117 - val_accuracy: 0.5128\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8307 - accuracy: 0.5556 - val_loss: 1.1068 - val_accuracy: 0.5128\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.1016 - val_accuracy: 0.4530\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 1.1069 - val_accuracy: 0.4615\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 1.1125 - val_accuracy: 0.4615\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 1.1072 - val_accuracy: 0.4615\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8303 - accuracy: 0.5630 - val_loss: 1.1004 - val_accuracy: 0.4530\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8316 - accuracy: 0.5630 - val_loss: 1.0998 - val_accuracy: 0.4530\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.1024 - val_accuracy: 0.4615\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 1.1089 - val_accuracy: 0.4615\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 1.1060 - val_accuracy: 0.5214\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8329 - accuracy: 0.5556 - val_loss: 1.1083 - val_accuracy: 0.5214\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8336 - accuracy: 0.5556 - val_loss: 1.1074 - val_accuracy: 0.5214\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8301 - accuracy: 0.5593 - val_loss: 1.1066 - val_accuracy: 0.4615\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8295 - accuracy: 0.5667 - val_loss: 1.1048 - val_accuracy: 0.4530\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8330 - accuracy: 0.5370 - val_loss: 1.1058 - val_accuracy: 0.5128\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8360 - accuracy: 0.5111 - val_loss: 1.1150 - val_accuracy: 0.4615\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 1.1125 - val_accuracy: 0.4615\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 1.1133 - val_accuracy: 0.4615\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8301 - accuracy: 0.5593 - val_loss: 1.1148 - val_accuracy: 0.4615\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 1.1152 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38af0c50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step\n",
      "over-sampling test accuracy: 52.14%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2,\n",
       "       2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 2, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1,\n",
       "       1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR4187     0     1\n",
       "1         NRS177     0     0\n",
       "2         NRS109     2     2\n",
       "3    CFBREBSa131     2     1\n",
       "4         SR4152     1     1\n",
       "..           ...   ...   ...\n",
       "112       NRS110     2     1\n",
       "113     CFBRSa25     1     1\n",
       "114         834N     0     1\n",
       "115  CFBREBSa114     1     1\n",
       "116       NRS387     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511673</td>\n",
       "      <td>0.310775</td>\n",
       "      <td>0.177551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045383</td>\n",
       "      <td>0.189247</td>\n",
       "      <td>0.765370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.363948</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.208301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.363948  0.427751  0.208301\n",
       "1    0.511673  0.310775  0.177551\n",
       "2    0.045383  0.189247  0.765370\n",
       "3    0.363948  0.427751  0.208301\n",
       "4    0.363948  0.427751  0.208301\n",
       "..        ...       ...       ...\n",
       "112  0.363948  0.427751  0.208301\n",
       "113  0.363948  0.427751  0.208301\n",
       "114  0.363948  0.427751  0.208301\n",
       "115  0.363948  0.427751  0.208301\n",
       "116  0.363948  0.427751  0.208301\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8446 - accuracy: 0.5481 - val_loss: 1.0492 - val_accuracy: 0.4615\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8436 - accuracy: 0.5185 - val_loss: 1.0550 - val_accuracy: 0.5214\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8438 - accuracy: 0.5741 - val_loss: 1.0581 - val_accuracy: 0.4615\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8420 - accuracy: 0.5667 - val_loss: 1.0514 - val_accuracy: 0.5214\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.0533 - val_accuracy: 0.5214\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8457 - accuracy: 0.5667 - val_loss: 1.0607 - val_accuracy: 0.4615\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.0626 - val_accuracy: 0.5214\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8486 - accuracy: 0.5296 - val_loss: 1.0517 - val_accuracy: 0.4615\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8487 - accuracy: 0.5407 - val_loss: 1.0491 - val_accuracy: 0.5214\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8459 - accuracy: 0.5259 - val_loss: 1.0456 - val_accuracy: 0.4615\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8431 - accuracy: 0.5630 - val_loss: 1.0445 - val_accuracy: 0.4615\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8450 - accuracy: 0.5259 - val_loss: 1.0480 - val_accuracy: 0.5214\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8408 - accuracy: 0.5630 - val_loss: 1.0554 - val_accuracy: 0.4615\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8489 - accuracy: 0.5593 - val_loss: 1.0603 - val_accuracy: 0.4615\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8412 - accuracy: 0.5630 - val_loss: 1.0612 - val_accuracy: 0.4615\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8437 - accuracy: 0.5444 - val_loss: 1.0602 - val_accuracy: 0.4615\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8417 - accuracy: 0.5630 - val_loss: 1.0607 - val_accuracy: 0.4615\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8434 - accuracy: 0.5630 - val_loss: 1.0597 - val_accuracy: 0.4615\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8414 - accuracy: 0.5630 - val_loss: 1.0520 - val_accuracy: 0.4615\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8446 - accuracy: 0.5370 - val_loss: 1.0477 - val_accuracy: 0.4615\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8446 - accuracy: 0.5593 - val_loss: 1.0553 - val_accuracy: 0.4615\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8423 - accuracy: 0.5778 - val_loss: 1.0510 - val_accuracy: 0.5214\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8413 - accuracy: 0.5556 - val_loss: 1.0510 - val_accuracy: 0.4615\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8431 - accuracy: 0.5630 - val_loss: 1.0568 - val_accuracy: 0.4615\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8454 - accuracy: 0.5630 - val_loss: 1.0647 - val_accuracy: 0.4615\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8430 - accuracy: 0.5481 - val_loss: 1.0588 - val_accuracy: 0.5214\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.0550 - val_accuracy: 0.4615\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8447 - accuracy: 0.5630 - val_loss: 1.0509 - val_accuracy: 0.4615\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8464 - accuracy: 0.5630 - val_loss: 1.0592 - val_accuracy: 0.4615\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8473 - accuracy: 0.5481 - val_loss: 1.0600 - val_accuracy: 0.5214\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8437 - accuracy: 0.5593 - val_loss: 1.0516 - val_accuracy: 0.4615\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8444 - accuracy: 0.5630 - val_loss: 1.0547 - val_accuracy: 0.4615\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8526 - accuracy: 0.5259 - val_loss: 1.0619 - val_accuracy: 0.5214\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8382 - accuracy: 0.5667 - val_loss: 1.0568 - val_accuracy: 0.4615\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8483 - accuracy: 0.5630 - val_loss: 1.0567 - val_accuracy: 0.4615\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8451 - accuracy: 0.5630 - val_loss: 1.0536 - val_accuracy: 0.4615\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.0615 - val_accuracy: 0.5214\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.0568 - val_accuracy: 0.4615\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8435 - accuracy: 0.5593 - val_loss: 1.0598 - val_accuracy: 0.4615\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8437 - accuracy: 0.5593 - val_loss: 1.0549 - val_accuracy: 0.4615\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8430 - accuracy: 0.5370 - val_loss: 1.0546 - val_accuracy: 0.4615\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8454 - accuracy: 0.5074 - val_loss: 1.0503 - val_accuracy: 0.5214\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8399 - accuracy: 0.5444 - val_loss: 1.0525 - val_accuracy: 0.5214\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8416 - accuracy: 0.5407 - val_loss: 1.0530 - val_accuracy: 0.5214\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8468 - accuracy: 0.5407 - val_loss: 1.0691 - val_accuracy: 0.4615\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8411 - accuracy: 0.5593 - val_loss: 1.0564 - val_accuracy: 0.4615\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8408 - accuracy: 0.5444 - val_loss: 1.0499 - val_accuracy: 0.5214\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8419 - accuracy: 0.5556 - val_loss: 1.0521 - val_accuracy: 0.5214\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8407 - accuracy: 0.5481 - val_loss: 1.0579 - val_accuracy: 0.4615\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8416 - accuracy: 0.5593 - val_loss: 1.0591 - val_accuracy: 0.4615\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8407 - accuracy: 0.5630 - val_loss: 1.0546 - val_accuracy: 0.5214\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8398 - accuracy: 0.5407 - val_loss: 1.0565 - val_accuracy: 0.5214\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8400 - accuracy: 0.5407 - val_loss: 1.0607 - val_accuracy: 0.4615\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8402 - accuracy: 0.5556 - val_loss: 1.0584 - val_accuracy: 0.5214\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8416 - accuracy: 0.5519 - val_loss: 1.0648 - val_accuracy: 0.4615\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8423 - accuracy: 0.5481 - val_loss: 1.0607 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8413 - accuracy: 0.5556 - val_loss: 1.0579 - val_accuracy: 0.5214\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8392 - accuracy: 0.5741 - val_loss: 1.0648 - val_accuracy: 0.4615\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8414 - accuracy: 0.5630 - val_loss: 1.0648 - val_accuracy: 0.4615\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8397 - accuracy: 0.5630 - val_loss: 1.0626 - val_accuracy: 0.4615\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8396 - accuracy: 0.5630 - val_loss: 1.0599 - val_accuracy: 0.4615\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8398 - accuracy: 0.5630 - val_loss: 1.0542 - val_accuracy: 0.5214\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8398 - accuracy: 0.5444 - val_loss: 1.0539 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8434 - accuracy: 0.5444 - val_loss: 1.0599 - val_accuracy: 0.4615\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 610us/step - loss: 0.8405 - accuracy: 0.5370 - val_loss: 1.0584 - val_accuracy: 0.4615\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8414 - accuracy: 0.5593 - val_loss: 1.0563 - val_accuracy: 0.5214\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8387 - accuracy: 0.5556 - val_loss: 1.0599 - val_accuracy: 0.4615\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8389 - accuracy: 0.5630 - val_loss: 1.0619 - val_accuracy: 0.4615\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8402 - accuracy: 0.5630 - val_loss: 1.0549 - val_accuracy: 0.4615\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8404 - accuracy: 0.5556 - val_loss: 1.0550 - val_accuracy: 0.5214\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8423 - accuracy: 0.5074 - val_loss: 1.0558 - val_accuracy: 0.4615\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8384 - accuracy: 0.5630 - val_loss: 1.0591 - val_accuracy: 0.4615\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8388 - accuracy: 0.5630 - val_loss: 1.0598 - val_accuracy: 0.4615\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8422 - accuracy: 0.5630 - val_loss: 1.0622 - val_accuracy: 0.4615\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 1.0549 - val_accuracy: 0.4615\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 0.8417 - accuracy: 0.5519 - val_loss: 1.0552 - val_accuracy: 0.5214\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8399 - accuracy: 0.5407 - val_loss: 1.0613 - val_accuracy: 0.4615\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8439 - accuracy: 0.5630 - val_loss: 1.0627 - val_accuracy: 0.4615\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8459 - accuracy: 0.5630 - val_loss: 1.0656 - val_accuracy: 0.4615\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8404 - accuracy: 0.5407 - val_loss: 1.0583 - val_accuracy: 0.5214\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8380 - accuracy: 0.5741 - val_loss: 1.0582 - val_accuracy: 0.4615\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8404 - accuracy: 0.5630 - val_loss: 1.0578 - val_accuracy: 0.4615\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.8413 - accuracy: 0.5556 - val_loss: 1.0600 - val_accuracy: 0.5214\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8389 - accuracy: 0.5556 - val_loss: 1.0612 - val_accuracy: 0.4615\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8411 - accuracy: 0.5444 - val_loss: 1.0659 - val_accuracy: 0.4615\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8393 - accuracy: 0.5630 - val_loss: 1.0634 - val_accuracy: 0.4615\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8400 - accuracy: 0.5630 - val_loss: 1.0608 - val_accuracy: 0.4615\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8378 - accuracy: 0.5630 - val_loss: 1.0614 - val_accuracy: 0.4615\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8401 - accuracy: 0.5630 - val_loss: 1.0627 - val_accuracy: 0.4615\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8382 - accuracy: 0.5630 - val_loss: 1.0598 - val_accuracy: 0.4615\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8394 - accuracy: 0.5593 - val_loss: 1.0598 - val_accuracy: 0.4615\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 1.0647 - val_accuracy: 0.4615\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8486 - accuracy: 0.5259 - val_loss: 1.0726 - val_accuracy: 0.4615\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8385 - accuracy: 0.5370 - val_loss: 1.0579 - val_accuracy: 0.4615\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8435 - accuracy: 0.5630 - val_loss: 1.0639 - val_accuracy: 0.4615\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8391 - accuracy: 0.5630 - val_loss: 1.0602 - val_accuracy: 0.4615\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8393 - accuracy: 0.5630 - val_loss: 1.0650 - val_accuracy: 0.5214\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 358us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.0587 - val_accuracy: 0.5214\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8387 - accuracy: 0.5481 - val_loss: 1.0638 - val_accuracy: 0.4615\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8397 - accuracy: 0.5630 - val_loss: 1.0662 - val_accuracy: 0.4615\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8449 - accuracy: 0.5333 - val_loss: 1.0686 - val_accuracy: 0.5214\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8393 - accuracy: 0.5852 - val_loss: 1.0613 - val_accuracy: 0.4615\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8401 - accuracy: 0.5630 - val_loss: 1.0600 - val_accuracy: 0.4615\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8388 - accuracy: 0.5630 - val_loss: 1.0609 - val_accuracy: 0.4615\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8416 - accuracy: 0.5593 - val_loss: 1.0598 - val_accuracy: 0.5214\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8419 - accuracy: 0.5481 - val_loss: 1.0626 - val_accuracy: 0.4615\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8367 - accuracy: 0.5296 - val_loss: 1.0638 - val_accuracy: 0.5214\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8373 - accuracy: 0.5593 - val_loss: 1.0694 - val_accuracy: 0.4615\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8390 - accuracy: 0.5630 - val_loss: 1.0620 - val_accuracy: 0.4615\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8383 - accuracy: 0.5630 - val_loss: 1.0629 - val_accuracy: 0.4615\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8425 - accuracy: 0.5370 - val_loss: 1.0652 - val_accuracy: 0.5214\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8427 - accuracy: 0.5222 - val_loss: 1.0682 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8422 - accuracy: 0.5259 - val_loss: 1.0646 - val_accuracy: 0.5214\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8379 - accuracy: 0.5704 - val_loss: 1.0563 - val_accuracy: 0.4615\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8404 - accuracy: 0.5630 - val_loss: 1.0578 - val_accuracy: 0.4615\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8369 - accuracy: 0.5593 - val_loss: 1.0551 - val_accuracy: 0.5214\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8387 - accuracy: 0.5556 - val_loss: 1.0571 - val_accuracy: 0.5214\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8372 - accuracy: 0.5667 - val_loss: 1.0609 - val_accuracy: 0.4615\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8364 - accuracy: 0.5630 - val_loss: 1.0661 - val_accuracy: 0.4615\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8376 - accuracy: 0.5630 - val_loss: 1.0678 - val_accuracy: 0.4615\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8378 - accuracy: 0.5407 - val_loss: 1.0650 - val_accuracy: 0.5214\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8409 - accuracy: 0.5407 - val_loss: 1.0680 - val_accuracy: 0.4615\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8383 - accuracy: 0.5630 - val_loss: 1.0780 - val_accuracy: 0.4615\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8384 - accuracy: 0.5333 - val_loss: 1.0679 - val_accuracy: 0.4615\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8392 - accuracy: 0.5185 - val_loss: 1.0685 - val_accuracy: 0.4615\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8356 - accuracy: 0.5630 - val_loss: 1.0650 - val_accuracy: 0.4615\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8409 - accuracy: 0.5630 - val_loss: 1.0595 - val_accuracy: 0.4615\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8394 - accuracy: 0.5630 - val_loss: 1.0534 - val_accuracy: 0.4615\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8405 - accuracy: 0.5556 - val_loss: 1.0578 - val_accuracy: 0.5214\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8382 - accuracy: 0.5481 - val_loss: 1.0598 - val_accuracy: 0.4615\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8360 - accuracy: 0.5630 - val_loss: 1.0614 - val_accuracy: 0.4615\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8374 - accuracy: 0.5630 - val_loss: 1.0637 - val_accuracy: 0.4615\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8422 - accuracy: 0.5556 - val_loss: 1.0740 - val_accuracy: 0.5214\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8392 - accuracy: 0.5519 - val_loss: 1.0670 - val_accuracy: 0.4615\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8392 - accuracy: 0.5630 - val_loss: 1.0664 - val_accuracy: 0.4615\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 255us/step - loss: 0.8378 - accuracy: 0.5593 - val_loss: 1.0628 - val_accuracy: 0.5214\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8367 - accuracy: 0.5333 - val_loss: 1.0654 - val_accuracy: 0.4615\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8358 - accuracy: 0.5630 - val_loss: 1.0669 - val_accuracy: 0.4615\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8370 - accuracy: 0.5481 - val_loss: 1.0678 - val_accuracy: 0.5214\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8355 - accuracy: 0.5593 - val_loss: 1.0691 - val_accuracy: 0.4615\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 1.0713 - val_accuracy: 0.4615\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8389 - accuracy: 0.5630 - val_loss: 1.0662 - val_accuracy: 0.4615\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8399 - accuracy: 0.5444 - val_loss: 1.0714 - val_accuracy: 0.5214\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8412 - accuracy: 0.5407 - val_loss: 1.0735 - val_accuracy: 0.4615\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8397 - accuracy: 0.5630 - val_loss: 1.0711 - val_accuracy: 0.4615\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 1.0729 - val_accuracy: 0.4615\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8385 - accuracy: 0.5741 - val_loss: 1.0790 - val_accuracy: 0.5214\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8401 - accuracy: 0.5556 - val_loss: 1.0682 - val_accuracy: 0.4615\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8402 - accuracy: 0.5407 - val_loss: 1.0736 - val_accuracy: 0.5214\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8383 - accuracy: 0.5556 - val_loss: 1.0661 - val_accuracy: 0.4615\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8361 - accuracy: 0.5481 - val_loss: 1.0711 - val_accuracy: 0.4615\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8357 - accuracy: 0.5630 - val_loss: 1.0703 - val_accuracy: 0.4615\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8436 - accuracy: 0.5630 - val_loss: 1.0692 - val_accuracy: 0.4615\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8345 - accuracy: 0.5778 - val_loss: 1.0686 - val_accuracy: 0.5214\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8386 - accuracy: 0.5407 - val_loss: 1.0677 - val_accuracy: 0.4615\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8365 - accuracy: 0.5444 - val_loss: 1.0657 - val_accuracy: 0.5214\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8347 - accuracy: 0.5481 - val_loss: 1.0704 - val_accuracy: 0.4615\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8402 - accuracy: 0.5630 - val_loss: 1.0692 - val_accuracy: 0.4615\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8360 - accuracy: 0.5519 - val_loss: 1.0636 - val_accuracy: 0.5214\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8405 - accuracy: 0.5259 - val_loss: 1.0677 - val_accuracy: 0.4615\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.8362 - accuracy: 0.5630 - val_loss: 1.0646 - val_accuracy: 0.5214\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8373 - accuracy: 0.5556 - val_loss: 1.0671 - val_accuracy: 0.5214\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8388 - accuracy: 0.5333 - val_loss: 1.0674 - val_accuracy: 0.4615\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8433 - accuracy: 0.5556 - val_loss: 1.0637 - val_accuracy: 0.5214\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8390 - accuracy: 0.5556 - val_loss: 1.0680 - val_accuracy: 0.5214\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8386 - accuracy: 0.5407 - val_loss: 1.0727 - val_accuracy: 0.4615\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8370 - accuracy: 0.5481 - val_loss: 1.0691 - val_accuracy: 0.5214\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0691 - val_accuracy: 0.4615\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8377 - accuracy: 0.5630 - val_loss: 1.0639 - val_accuracy: 0.5214\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8354 - accuracy: 0.5556 - val_loss: 1.0626 - val_accuracy: 0.5214\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8348 - accuracy: 0.5556 - val_loss: 1.0655 - val_accuracy: 0.5214\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8416 - accuracy: 0.5407 - val_loss: 1.0754 - val_accuracy: 0.4615\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8330 - accuracy: 0.5630 - val_loss: 1.0693 - val_accuracy: 0.5214\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8376 - accuracy: 0.5556 - val_loss: 1.0691 - val_accuracy: 0.5214\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8408 - accuracy: 0.5444 - val_loss: 1.0702 - val_accuracy: 0.4615\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8375 - accuracy: 0.5630 - val_loss: 1.0765 - val_accuracy: 0.4615\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8343 - accuracy: 0.5593 - val_loss: 1.0689 - val_accuracy: 0.5214\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8367 - accuracy: 0.5333 - val_loss: 1.0676 - val_accuracy: 0.4615\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8357 - accuracy: 0.5704 - val_loss: 1.0668 - val_accuracy: 0.5214\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8349 - accuracy: 0.5333 - val_loss: 1.0700 - val_accuracy: 0.4615\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8381 - accuracy: 0.5593 - val_loss: 1.0734 - val_accuracy: 0.5214\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8361 - accuracy: 0.5556 - val_loss: 1.0682 - val_accuracy: 0.4615\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8383 - accuracy: 0.5630 - val_loss: 1.0707 - val_accuracy: 0.4615\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8376 - accuracy: 0.5519 - val_loss: 1.0675 - val_accuracy: 0.5214\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8389 - accuracy: 0.5519 - val_loss: 1.0760 - val_accuracy: 0.4615\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8361 - accuracy: 0.5630 - val_loss: 1.0708 - val_accuracy: 0.4615\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8363 - accuracy: 0.5630 - val_loss: 1.0737 - val_accuracy: 0.4615\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.46 - 0s 124us/step - loss: 0.8358 - accuracy: 0.5630 - val_loss: 1.0767 - val_accuracy: 0.4615\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8387 - accuracy: 0.5667 - val_loss: 1.0725 - val_accuracy: 0.5214\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8409 - accuracy: 0.5630 - val_loss: 1.0693 - val_accuracy: 0.4615\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8379 - accuracy: 0.5630 - val_loss: 1.0627 - val_accuracy: 0.4615\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8346 - accuracy: 0.5407 - val_loss: 1.0628 - val_accuracy: 0.5214\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8390 - accuracy: 0.5556 - val_loss: 1.0695 - val_accuracy: 0.5214\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8363 - accuracy: 0.5667 - val_loss: 1.0715 - val_accuracy: 0.4615\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8363 - accuracy: 0.5630 - val_loss: 1.0689 - val_accuracy: 0.4615\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8344 - accuracy: 0.5370 - val_loss: 1.0700 - val_accuracy: 0.4615\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8350 - accuracy: 0.5444 - val_loss: 1.0725 - val_accuracy: 0.5214\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8329 - accuracy: 0.5407 - val_loss: 1.0780 - val_accuracy: 0.4615\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8387 - accuracy: 0.5630 - val_loss: 1.0767 - val_accuracy: 0.4615\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8366 - accuracy: 0.5667 - val_loss: 1.0730 - val_accuracy: 0.5214\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8389 - accuracy: 0.5593 - val_loss: 1.0662 - val_accuracy: 0.4615\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8354 - accuracy: 0.5630 - val_loss: 1.0751 - val_accuracy: 0.4615\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8375 - accuracy: 0.5370 - val_loss: 1.0715 - val_accuracy: 0.4615\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8332 - accuracy: 0.5630 - val_loss: 1.0735 - val_accuracy: 0.4615\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8356 - accuracy: 0.5481 - val_loss: 1.0726 - val_accuracy: 0.4615\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 1.0736 - val_accuracy: 0.4615\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 1.0731 - val_accuracy: 0.4615\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 1.0764 - val_accuracy: 0.4615\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8365 - accuracy: 0.5407 - val_loss: 1.0782 - val_accuracy: 0.4615\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8341 - accuracy: 0.5630 - val_loss: 1.0755 - val_accuracy: 0.4615\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.0718 - val_accuracy: 0.4615\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8343 - accuracy: 0.5370 - val_loss: 1.0691 - val_accuracy: 0.5214\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8334 - accuracy: 0.5481 - val_loss: 1.0722 - val_accuracy: 0.4615\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8340 - accuracy: 0.5407 - val_loss: 1.0746 - val_accuracy: 0.5214\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8330 - accuracy: 0.5667 - val_loss: 1.0746 - val_accuracy: 0.4615\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 1.0765 - val_accuracy: 0.4615\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 1.0742 - val_accuracy: 0.4615\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 1.0742 - val_accuracy: 0.4615\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8338 - accuracy: 0.5593 - val_loss: 1.0737 - val_accuracy: 0.5214\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8380 - accuracy: 0.5333 - val_loss: 1.0797 - val_accuracy: 0.4615\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 1.0812 - val_accuracy: 0.5214\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8373 - accuracy: 0.5556 - val_loss: 1.0718 - val_accuracy: 0.5214\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 166us/step - loss: 0.8335 - accuracy: 0.5296 - val_loss: 1.0759 - val_accuracy: 0.4615\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8339 - accuracy: 0.5630 - val_loss: 1.0767 - val_accuracy: 0.4615\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8364 - accuracy: 0.5370 - val_loss: 1.0758 - val_accuracy: 0.5214\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8394 - accuracy: 0.5259 - val_loss: 1.0711 - val_accuracy: 0.4615\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 1.0707 - val_accuracy: 0.4615\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8361 - accuracy: 0.5333 - val_loss: 1.0712 - val_accuracy: 0.5214\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8373 - accuracy: 0.5593 - val_loss: 1.0778 - val_accuracy: 0.4615\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 1.0778 - val_accuracy: 0.4615\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8337 - accuracy: 0.5556 - val_loss: 1.0771 - val_accuracy: 0.4615\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 1.0747 - val_accuracy: 0.4615\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 1.0736 - val_accuracy: 0.5214\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8348 - accuracy: 0.5630 - val_loss: 1.0773 - val_accuracy: 0.4615\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8330 - accuracy: 0.5556 - val_loss: 1.0734 - val_accuracy: 0.5214\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8349 - accuracy: 0.5556 - val_loss: 1.0786 - val_accuracy: 0.4615\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8333 - accuracy: 0.5630 - val_loss: 1.0723 - val_accuracy: 0.4615\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8355 - accuracy: 0.5630 - val_loss: 1.0623 - val_accuracy: 0.4615\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8338 - accuracy: 0.5481 - val_loss: 1.0647 - val_accuracy: 0.5214\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8346 - accuracy: 0.5556 - val_loss: 1.0680 - val_accuracy: 0.5214\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8372 - accuracy: 0.5630 - val_loss: 1.0704 - val_accuracy: 0.4615\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8338 - accuracy: 0.5630 - val_loss: 1.0748 - val_accuracy: 0.4615\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8333 - accuracy: 0.5370 - val_loss: 1.0752 - val_accuracy: 0.4615\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8341 - accuracy: 0.5407 - val_loss: 1.0724 - val_accuracy: 0.5214\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8337 - accuracy: 0.5593 - val_loss: 1.0798 - val_accuracy: 0.4615\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8344 - accuracy: 0.5630 - val_loss: 1.0829 - val_accuracy: 0.5214\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8355 - accuracy: 0.5556 - val_loss: 1.0777 - val_accuracy: 0.5214\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8310 - accuracy: 0.5889 - val_loss: 1.0771 - val_accuracy: 0.4615\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 1.0830 - val_accuracy: 0.4615\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 1.0831 - val_accuracy: 0.4615\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8367 - accuracy: 0.5630 - val_loss: 1.0869 - val_accuracy: 0.4615\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 1.0781 - val_accuracy: 0.4615\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 1.0776 - val_accuracy: 0.4615\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8356 - accuracy: 0.5630 - val_loss: 1.0752 - val_accuracy: 0.4615\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8382 - accuracy: 0.5593 - val_loss: 1.0787 - val_accuracy: 0.5214\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8349 - accuracy: 0.5556 - val_loss: 1.0855 - val_accuracy: 0.5214\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8362 - accuracy: 0.5704 - val_loss: 1.0799 - val_accuracy: 0.4615\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8329 - accuracy: 0.5630 - val_loss: 1.0725 - val_accuracy: 0.5214\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8368 - accuracy: 0.5556 - val_loss: 1.0722 - val_accuracy: 0.5214\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8347 - accuracy: 0.5444 - val_loss: 1.0753 - val_accuracy: 0.4615\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 1.0795 - val_accuracy: 0.4615\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 1.0856 - val_accuracy: 0.4615\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8311 - accuracy: 0.5556 - val_loss: 1.0804 - val_accuracy: 0.5214\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8329 - accuracy: 0.5556 - val_loss: 1.0794 - val_accuracy: 0.5214\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8349 - accuracy: 0.5630 - val_loss: 1.0857 - val_accuracy: 0.4615\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 1.0835 - val_accuracy: 0.4615\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8374 - accuracy: 0.5519 - val_loss: 1.0859 - val_accuracy: 0.5214\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8324 - accuracy: 0.5481 - val_loss: 1.0797 - val_accuracy: 0.4615\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 1.0812 - val_accuracy: 0.4615\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 1.0791 - val_accuracy: 0.4615\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8311 - accuracy: 0.5630 - val_loss: 1.0833 - val_accuracy: 0.4615\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 1.0859 - val_accuracy: 0.4615\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8323 - accuracy: 0.5630 - val_loss: 1.0897 - val_accuracy: 0.4615\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 1.0884 - val_accuracy: 0.4615\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8336 - accuracy: 0.5556 - val_loss: 1.0792 - val_accuracy: 0.4615\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8341 - accuracy: 0.5630 - val_loss: 1.0772 - val_accuracy: 0.4615\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8308 - accuracy: 0.5704 - val_loss: 1.0782 - val_accuracy: 0.5214\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8325 - accuracy: 0.5556 - val_loss: 1.0813 - val_accuracy: 0.5214\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8309 - accuracy: 0.5519 - val_loss: 1.0827 - val_accuracy: 0.4615\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 1.0833 - val_accuracy: 0.4615\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 1.0863 - val_accuracy: 0.4615\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.8316 - accuracy: 0.5296 - val_loss: 1.0776 - val_accuracy: 0.4615\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8368 - accuracy: 0.5444 - val_loss: 1.0767 - val_accuracy: 0.5214\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8343 - accuracy: 0.5481 - val_loss: 1.0894 - val_accuracy: 0.4615\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 1.0868 - val_accuracy: 0.4615\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 1.0795 - val_accuracy: 0.4615\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8365 - accuracy: 0.5407 - val_loss: 1.0827 - val_accuracy: 0.4615\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8322 - accuracy: 0.5630 - val_loss: 1.0900 - val_accuracy: 0.4615\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 1.0905 - val_accuracy: 0.4615\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.0789 - val_accuracy: 0.4615\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8331 - accuracy: 0.5630 - val_loss: 1.0761 - val_accuracy: 0.4615\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8352 - accuracy: 0.5333 - val_loss: 1.0726 - val_accuracy: 0.5214\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8325 - accuracy: 0.5556 - val_loss: 1.0770 - val_accuracy: 0.4615\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8325 - accuracy: 0.5481 - val_loss: 1.0795 - val_accuracy: 0.4615\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8344 - accuracy: 0.5519 - val_loss: 1.0870 - val_accuracy: 0.5214\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8314 - accuracy: 0.5407 - val_loss: 1.0842 - val_accuracy: 0.4615\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8327 - accuracy: 0.5630 - val_loss: 1.0822 - val_accuracy: 0.4615\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 1.0807 - val_accuracy: 0.4615\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8304 - accuracy: 0.5444 - val_loss: 1.0813 - val_accuracy: 0.5214\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8317 - accuracy: 0.5333 - val_loss: 1.0836 - val_accuracy: 0.5214\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8312 - accuracy: 0.5481 - val_loss: 1.0861 - val_accuracy: 0.4615\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8315 - accuracy: 0.5370 - val_loss: 1.0854 - val_accuracy: 0.5214\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8299 - accuracy: 0.5630 - val_loss: 1.0868 - val_accuracy: 0.4615\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8322 - accuracy: 0.5630 - val_loss: 1.0859 - val_accuracy: 0.4615\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.0801 - val_accuracy: 0.4615\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 1.0821 - val_accuracy: 0.4615\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8313 - accuracy: 0.5667 - val_loss: 1.0823 - val_accuracy: 0.5214\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8307 - accuracy: 0.5556 - val_loss: 1.0858 - val_accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8300 - accuracy: 0.5704 - val_loss: 1.0875 - val_accuracy: 0.4615\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 1.0874 - val_accuracy: 0.4615\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8310 - accuracy: 0.5630 - val_loss: 1.0865 - val_accuracy: 0.4615\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8312 - accuracy: 0.5519 - val_loss: 1.0842 - val_accuracy: 0.5214\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8314 - accuracy: 0.5556 - val_loss: 1.0838 - val_accuracy: 0.4615\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8330 - accuracy: 0.5630 - val_loss: 1.0932 - val_accuracy: 0.4615\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8315 - accuracy: 0.5519 - val_loss: 1.0936 - val_accuracy: 0.5214\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8307 - accuracy: 0.5370 - val_loss: 1.0909 - val_accuracy: 0.4615\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8324 - accuracy: 0.5556 - val_loss: 1.0851 - val_accuracy: 0.5214\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8298 - accuracy: 0.5519 - val_loss: 1.0810 - val_accuracy: 0.4615\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8326 - accuracy: 0.5630 - val_loss: 1.0775 - val_accuracy: 0.5214\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8324 - accuracy: 0.5000 - val_loss: 1.0767 - val_accuracy: 0.5214\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8304 - accuracy: 0.5556 - val_loss: 1.0781 - val_accuracy: 0.5214\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8318 - accuracy: 0.5556 - val_loss: 1.0829 - val_accuracy: 0.5214\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8301 - accuracy: 0.5556 - val_loss: 1.0837 - val_accuracy: 0.4615\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8334 - accuracy: 0.5630 - val_loss: 1.0870 - val_accuracy: 0.4615\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 1.0842 - val_accuracy: 0.5214\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8311 - accuracy: 0.5556 - val_loss: 1.0885 - val_accuracy: 0.5214\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8363 - accuracy: 0.5259 - val_loss: 1.0879 - val_accuracy: 0.4615\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.8307 - accuracy: 0.5630 - val_loss: 1.0907 - val_accuracy: 0.5214\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8301 - accuracy: 0.5556 - val_loss: 1.0826 - val_accuracy: 0.5214\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.8316 - accuracy: 0.5667 - val_loss: 1.0840 - val_accuracy: 0.4615\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 1.0831 - val_accuracy: 0.4615\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8316 - accuracy: 0.5481 - val_loss: 1.0828 - val_accuracy: 0.5128\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 149us/step - loss: 0.8313 - accuracy: 0.5556 - val_loss: 1.0875 - val_accuracy: 0.5214\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.8341 - accuracy: 0.5444 - val_loss: 1.0919 - val_accuracy: 0.4615\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8320 - accuracy: 0.5407 - val_loss: 1.0875 - val_accuracy: 0.5214\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8316 - accuracy: 0.5556 - val_loss: 1.0839 - val_accuracy: 0.5214\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8297 - accuracy: 0.5667 - val_loss: 1.0824 - val_accuracy: 0.4615\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8313 - accuracy: 0.5630 - val_loss: 1.0892 - val_accuracy: 0.4615\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8305 - accuracy: 0.5630 - val_loss: 1.0863 - val_accuracy: 0.4615\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 1.0876 - val_accuracy: 0.5214\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8299 - accuracy: 0.5556 - val_loss: 1.0908 - val_accuracy: 0.5214\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8301 - accuracy: 0.5593 - val_loss: 1.0930 - val_accuracy: 0.4615\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8325 - accuracy: 0.5630 - val_loss: 1.0939 - val_accuracy: 0.4615\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8314 - accuracy: 0.5630 - val_loss: 1.0891 - val_accuracy: 0.4615\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8301 - accuracy: 0.5630 - val_loss: 1.0904 - val_accuracy: 0.4615\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.0913 - val_accuracy: 0.4615\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8313 - accuracy: 0.5407 - val_loss: 1.0937 - val_accuracy: 0.5214\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8300 - accuracy: 0.5407 - val_loss: 1.0847 - val_accuracy: 0.4615\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 1.0875 - val_accuracy: 0.4615\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.0916 - val_accuracy: 0.4615\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8298 - accuracy: 0.5630 - val_loss: 1.0916 - val_accuracy: 0.4615\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8301 - accuracy: 0.5407 - val_loss: 1.0894 - val_accuracy: 0.4615\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8284 - accuracy: 0.5481 - val_loss: 1.0907 - val_accuracy: 0.4615\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8367 - accuracy: 0.5630 - val_loss: 1.0992 - val_accuracy: 0.4615\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 1.0831 - val_accuracy: 0.4615\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8325 - accuracy: 0.5593 - val_loss: 1.0832 - val_accuracy: 0.5214\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8311 - accuracy: 0.5556 - val_loss: 1.0890 - val_accuracy: 0.4615\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.0882 - val_accuracy: 0.4615\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8319 - accuracy: 0.5296 - val_loss: 1.0920 - val_accuracy: 0.4615\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 1.0921 - val_accuracy: 0.4615\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8315 - accuracy: 0.5630 - val_loss: 1.0930 - val_accuracy: 0.4615\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 1.0880 - val_accuracy: 0.4615\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 1.0877 - val_accuracy: 0.4615\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8303 - accuracy: 0.5407 - val_loss: 1.0871 - val_accuracy: 0.4615\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.0925 - val_accuracy: 0.4615\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8327 - accuracy: 0.5519 - val_loss: 1.0888 - val_accuracy: 0.5214\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8287 - accuracy: 0.5704 - val_loss: 1.0945 - val_accuracy: 0.4615\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 1.0999 - val_accuracy: 0.4615\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.1006 - val_accuracy: 0.4615\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8335 - accuracy: 0.5630 - val_loss: 1.1042 - val_accuracy: 0.4615\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8280 - accuracy: 0.5630 - val_loss: 1.0957 - val_accuracy: 0.4615\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8312 - accuracy: 0.5296 - val_loss: 1.0847 - val_accuracy: 0.5214\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8293 - accuracy: 0.5519 - val_loss: 1.0858 - val_accuracy: 0.4615\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8373 - accuracy: 0.5444 - val_loss: 1.0898 - val_accuracy: 0.5214\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8317 - accuracy: 0.5481 - val_loss: 1.0887 - val_accuracy: 0.4615\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 1.0897 - val_accuracy: 0.4615\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 1.0920 - val_accuracy: 0.4615\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 1.0973 - val_accuracy: 0.4615\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 1.0979 - val_accuracy: 0.5214\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8314 - accuracy: 0.5556 - val_loss: 1.0882 - val_accuracy: 0.4615\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8321 - accuracy: 0.5630 - val_loss: 1.0881 - val_accuracy: 0.4615\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8295 - accuracy: 0.5444 - val_loss: 1.0860 - val_accuracy: 0.5214\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8287 - accuracy: 0.5667 - val_loss: 1.0890 - val_accuracy: 0.4615\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8295 - accuracy: 0.5630 - val_loss: 1.0908 - val_accuracy: 0.4615\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8280 - accuracy: 0.5630 - val_loss: 1.0953 - val_accuracy: 0.4615\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.0997 - val_accuracy: 0.4615\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8310 - accuracy: 0.5519 - val_loss: 1.0941 - val_accuracy: 0.5214\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8304 - accuracy: 0.5778 - val_loss: 1.0962 - val_accuracy: 0.4615\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 1.0973 - val_accuracy: 0.4615\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8284 - accuracy: 0.5519 - val_loss: 1.0916 - val_accuracy: 0.5214\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8321 - accuracy: 0.5519 - val_loss: 1.0945 - val_accuracy: 0.5214\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8298 - accuracy: 0.5481 - val_loss: 1.0986 - val_accuracy: 0.4615\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.0997 - val_accuracy: 0.4615\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8341 - accuracy: 0.5481 - val_loss: 1.0939 - val_accuracy: 0.5128\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8322 - accuracy: 0.5407 - val_loss: 1.1017 - val_accuracy: 0.4615\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8285 - accuracy: 0.5630 - val_loss: 1.0963 - val_accuracy: 0.4615\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8294 - accuracy: 0.5370 - val_loss: 1.0948 - val_accuracy: 0.5214\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8262 - accuracy: 0.5778 - val_loss: 1.0980 - val_accuracy: 0.4615\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 1.1011 - val_accuracy: 0.4615\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8280 - accuracy: 0.5630 - val_loss: 1.1019 - val_accuracy: 0.4615\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8336 - accuracy: 0.5630 - val_loss: 1.0954 - val_accuracy: 0.4615\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8327 - accuracy: 0.5444 - val_loss: 1.0956 - val_accuracy: 0.5214\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8307 - accuracy: 0.5667 - val_loss: 1.0933 - val_accuracy: 0.4615\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8337 - accuracy: 0.5630 - val_loss: 1.0935 - val_accuracy: 0.4615\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8267 - accuracy: 0.5593 - val_loss: 1.0927 - val_accuracy: 0.5214\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8311 - accuracy: 0.5556 - val_loss: 1.0973 - val_accuracy: 0.5214\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8287 - accuracy: 0.5444 - val_loss: 1.0990 - val_accuracy: 0.4615\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8290 - accuracy: 0.5630 - val_loss: 1.0957 - val_accuracy: 0.4615\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8268 - accuracy: 0.5370 - val_loss: 1.1012 - val_accuracy: 0.4615\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8315 - accuracy: 0.5593 - val_loss: 1.1114 - val_accuracy: 0.5214\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8279 - accuracy: 0.5630 - val_loss: 1.1064 - val_accuracy: 0.4615\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8297 - accuracy: 0.5630 - val_loss: 1.0920 - val_accuracy: 0.4615\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8293 - accuracy: 0.5370 - val_loss: 1.0889 - val_accuracy: 0.5214\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8299 - accuracy: 0.5556 - val_loss: 1.0948 - val_accuracy: 0.5214\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8272 - accuracy: 0.5593 - val_loss: 1.0974 - val_accuracy: 0.4615\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8284 - accuracy: 0.5630 - val_loss: 1.0991 - val_accuracy: 0.4615\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8304 - accuracy: 0.5481 - val_loss: 1.0971 - val_accuracy: 0.4615\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 1.0988 - val_accuracy: 0.4615\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8285 - accuracy: 0.5593 - val_loss: 1.0964 - val_accuracy: 0.5214\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8288 - accuracy: 0.5556 - val_loss: 1.0947 - val_accuracy: 0.5214\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8273 - accuracy: 0.5593 - val_loss: 1.0942 - val_accuracy: 0.4615\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8291 - accuracy: 0.5481 - val_loss: 1.0970 - val_accuracy: 0.5214\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8277 - accuracy: 0.5593 - val_loss: 1.0949 - val_accuracy: 0.4615\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8317 - accuracy: 0.5630 - val_loss: 1.0991 - val_accuracy: 0.4615\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8276 - accuracy: 0.5630 - val_loss: 1.0957 - val_accuracy: 0.4615\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8282 - accuracy: 0.5481 - val_loss: 1.0975 - val_accuracy: 0.5128\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8294 - accuracy: 0.5556 - val_loss: 1.0903 - val_accuracy: 0.5214\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8274 - accuracy: 0.5630 - val_loss: 1.0969 - val_accuracy: 0.4615\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8324 - accuracy: 0.5630 - val_loss: 1.0954 - val_accuracy: 0.4615\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8281 - accuracy: 0.5630 - val_loss: 1.0920 - val_accuracy: 0.4615\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 1.0908 - val_accuracy: 0.4615\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8280 - accuracy: 0.5519 - val_loss: 1.0917 - val_accuracy: 0.4615\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8276 - accuracy: 0.5630 - val_loss: 1.0947 - val_accuracy: 0.4615\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 1.0960 - val_accuracy: 0.4615\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8291 - accuracy: 0.5481 - val_loss: 1.1058 - val_accuracy: 0.5214\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8299 - accuracy: 0.5556 - val_loss: 1.0998 - val_accuracy: 0.5214\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8278 - accuracy: 0.5556 - val_loss: 1.0984 - val_accuracy: 0.4615\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.1019 - val_accuracy: 0.4615\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 1.0994 - val_accuracy: 0.5214\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8267 - accuracy: 0.5556 - val_loss: 1.1011 - val_accuracy: 0.5214\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8287 - accuracy: 0.5481 - val_loss: 1.1020 - val_accuracy: 0.4615\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1027 - val_accuracy: 0.4615\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 173us/step - loss: 0.8276 - accuracy: 0.5556 - val_loss: 1.1013 - val_accuracy: 0.5128\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8314 - accuracy: 0.5481 - val_loss: 1.1034 - val_accuracy: 0.4615\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8263 - accuracy: 0.5630 - val_loss: 1.1045 - val_accuracy: 0.4615\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8296 - accuracy: 0.5630 - val_loss: 1.1048 - val_accuracy: 0.4615\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8302 - accuracy: 0.5593 - val_loss: 1.0998 - val_accuracy: 0.5128\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8273 - accuracy: 0.5704 - val_loss: 1.0946 - val_accuracy: 0.4615\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8306 - accuracy: 0.5556 - val_loss: 1.0922 - val_accuracy: 0.4615\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 1.0932 - val_accuracy: 0.4615\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8264 - accuracy: 0.5556 - val_loss: 1.0994 - val_accuracy: 0.5214\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8278 - accuracy: 0.5481 - val_loss: 1.1054 - val_accuracy: 0.4615\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8270 - accuracy: 0.5296 - val_loss: 1.0999 - val_accuracy: 0.4615\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8312 - accuracy: 0.5630 - val_loss: 1.1045 - val_accuracy: 0.4615\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 1.1050 - val_accuracy: 0.4615\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8245 - accuracy: 0.5667 - val_loss: 1.1062 - val_accuracy: 0.5214\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8277 - accuracy: 0.5556 - val_loss: 1.1003 - val_accuracy: 0.5214\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8256 - accuracy: 0.5519 - val_loss: 1.1028 - val_accuracy: 0.4615\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8269 - accuracy: 0.5630 - val_loss: 1.1061 - val_accuracy: 0.4615\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8273 - accuracy: 0.5481 - val_loss: 1.1008 - val_accuracy: 0.5128\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8272 - accuracy: 0.5593 - val_loss: 1.1019 - val_accuracy: 0.4615\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8269 - accuracy: 0.5630 - val_loss: 1.1074 - val_accuracy: 0.4615\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.1092 - val_accuracy: 0.4615\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8274 - accuracy: 0.5630 - val_loss: 1.0986 - val_accuracy: 0.4615\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 1.1008 - val_accuracy: 0.4615\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8287 - accuracy: 0.5333 - val_loss: 1.1035 - val_accuracy: 0.5214\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8325 - accuracy: 0.5519 - val_loss: 1.1075 - val_accuracy: 0.4615\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.0990 - val_accuracy: 0.4615\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8291 - accuracy: 0.5444 - val_loss: 1.1001 - val_accuracy: 0.5128\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8300 - accuracy: 0.5519 - val_loss: 1.1048 - val_accuracy: 0.5214\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8261 - accuracy: 0.5704 - val_loss: 1.1052 - val_accuracy: 0.4615\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8291 - accuracy: 0.5630 - val_loss: 1.1077 - val_accuracy: 0.4615\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8323 - accuracy: 0.5407 - val_loss: 1.1071 - val_accuracy: 0.5214\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8332 - accuracy: 0.5556 - val_loss: 1.1019 - val_accuracy: 0.4530\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8278 - accuracy: 0.5593 - val_loss: 1.1066 - val_accuracy: 0.4615\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8260 - accuracy: 0.5630 - val_loss: 1.1093 - val_accuracy: 0.4615\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8272 - accuracy: 0.5630 - val_loss: 1.1080 - val_accuracy: 0.4615\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8270 - accuracy: 0.5630 - val_loss: 1.1110 - val_accuracy: 0.4530\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8270 - accuracy: 0.5519 - val_loss: 1.1135 - val_accuracy: 0.5214\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8282 - accuracy: 0.5444 - val_loss: 1.1094 - val_accuracy: 0.4615\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8296 - accuracy: 0.5222 - val_loss: 1.1035 - val_accuracy: 0.5214\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8275 - accuracy: 0.5667 - val_loss: 1.1048 - val_accuracy: 0.4615\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8256 - accuracy: 0.5556 - val_loss: 1.1016 - val_accuracy: 0.5214\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8284 - accuracy: 0.5556 - val_loss: 1.1078 - val_accuracy: 0.5214\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8266 - accuracy: 0.5667 - val_loss: 1.1057 - val_accuracy: 0.4615\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8264 - accuracy: 0.5630 - val_loss: 1.1061 - val_accuracy: 0.4615\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8263 - accuracy: 0.5630 - val_loss: 1.1049 - val_accuracy: 0.4615\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8328 - accuracy: 0.5148 - val_loss: 1.1036 - val_accuracy: 0.4530\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8264 - accuracy: 0.5296 - val_loss: 1.1109 - val_accuracy: 0.4615\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8268 - accuracy: 0.5630 - val_loss: 1.1095 - val_accuracy: 0.4615\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8345 - accuracy: 0.5667 - val_loss: 1.1037 - val_accuracy: 0.4530\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1070 - val_accuracy: 0.5214\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8292 - accuracy: 0.5519 - val_loss: 1.1077 - val_accuracy: 0.5214\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8304 - accuracy: 0.5556 - val_loss: 1.1089 - val_accuracy: 0.4615\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8266 - accuracy: 0.5630 - val_loss: 1.1070 - val_accuracy: 0.4615\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 1.1120 - val_accuracy: 0.5214\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8272 - accuracy: 0.5481 - val_loss: 1.1078 - val_accuracy: 0.4615\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8254 - accuracy: 0.5407 - val_loss: 1.1057 - val_accuracy: 0.5128\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8272 - accuracy: 0.5815 - val_loss: 1.1070 - val_accuracy: 0.4530\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8257 - accuracy: 0.5630 - val_loss: 1.1111 - val_accuracy: 0.4615\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8264 - accuracy: 0.5481 - val_loss: 1.1088 - val_accuracy: 0.4615\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8256 - accuracy: 0.5630 - val_loss: 1.1103 - val_accuracy: 0.4615\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8259 - accuracy: 0.5630 - val_loss: 1.1092 - val_accuracy: 0.4615\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8254 - accuracy: 0.5370 - val_loss: 1.1075 - val_accuracy: 0.4615\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8287 - accuracy: 0.5037 - val_loss: 1.1057 - val_accuracy: 0.4615\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8256 - accuracy: 0.5481 - val_loss: 1.1014 - val_accuracy: 0.4615\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 1.1047 - val_accuracy: 0.4615\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 1.1154 - val_accuracy: 0.4615\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 1.1086 - val_accuracy: 0.4615\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8263 - accuracy: 0.5630 - val_loss: 1.1095 - val_accuracy: 0.4615\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8300 - accuracy: 0.5630 - val_loss: 1.1071 - val_accuracy: 0.4530\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8268 - accuracy: 0.5519 - val_loss: 1.1123 - val_accuracy: 0.4615\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8286 - accuracy: 0.5630 - val_loss: 1.1202 - val_accuracy: 0.4615\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8278 - accuracy: 0.5630 - val_loss: 1.1191 - val_accuracy: 0.4530\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8272 - accuracy: 0.5630 - val_loss: 1.1117 - val_accuracy: 0.4530\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.1165 - val_accuracy: 0.4615\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8251 - accuracy: 0.5630 - val_loss: 1.1105 - val_accuracy: 0.5214\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8266 - accuracy: 0.5556 - val_loss: 1.1113 - val_accuracy: 0.5214\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8272 - accuracy: 0.5556 - val_loss: 1.1100 - val_accuracy: 0.4530\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8243 - accuracy: 0.5667 - val_loss: 1.1117 - val_accuracy: 0.4615\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 1.1134 - val_accuracy: 0.4615\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8266 - accuracy: 0.5630 - val_loss: 1.1109 - val_accuracy: 0.4530\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 1.1110 - val_accuracy: 0.5128\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8283 - accuracy: 0.5704 - val_loss: 1.1115 - val_accuracy: 0.4615\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8252 - accuracy: 0.5630 - val_loss: 1.1102 - val_accuracy: 0.4615\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8289 - accuracy: 0.5407 - val_loss: 1.1090 - val_accuracy: 0.5128\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8254 - accuracy: 0.5481 - val_loss: 1.1123 - val_accuracy: 0.5214\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8266 - accuracy: 0.5333 - val_loss: 1.1102 - val_accuracy: 0.4615\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8281 - accuracy: 0.5407 - val_loss: 1.1094 - val_accuracy: 0.5128\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8259 - accuracy: 0.5741 - val_loss: 1.1142 - val_accuracy: 0.4615\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8277 - accuracy: 0.5630 - val_loss: 1.1149 - val_accuracy: 0.4615\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8263 - accuracy: 0.5630 - val_loss: 1.1125 - val_accuracy: 0.4615\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1105 - val_accuracy: 0.4615\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8256 - accuracy: 0.5630 - val_loss: 1.1077 - val_accuracy: 0.4615\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8275 - accuracy: 0.5519 - val_loss: 1.1083 - val_accuracy: 0.5214\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8270 - accuracy: 0.5593 - val_loss: 1.1152 - val_accuracy: 0.4615\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8255 - accuracy: 0.5630 - val_loss: 1.1157 - val_accuracy: 0.4615\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8252 - accuracy: 0.5630 - val_loss: 1.1257 - val_accuracy: 0.4615\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 1.1212 - val_accuracy: 0.4615\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8267 - accuracy: 0.5556 - val_loss: 1.1254 - val_accuracy: 0.4530\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8288 - accuracy: 0.5630 - val_loss: 1.1159 - val_accuracy: 0.4615\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8242 - accuracy: 0.5778 - val_loss: 1.1094 - val_accuracy: 0.5214\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8259 - accuracy: 0.5556 - val_loss: 1.1112 - val_accuracy: 0.5214\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8247 - accuracy: 0.5667 - val_loss: 1.1156 - val_accuracy: 0.4615\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8286 - accuracy: 0.5370 - val_loss: 1.1116 - val_accuracy: 0.4615\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8239 - accuracy: 0.5630 - val_loss: 1.1179 - val_accuracy: 0.4615\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8264 - accuracy: 0.5630 - val_loss: 1.1199 - val_accuracy: 0.4615\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8255 - accuracy: 0.5630 - val_loss: 1.1179 - val_accuracy: 0.4530\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8256 - accuracy: 0.5630 - val_loss: 1.1141 - val_accuracy: 0.4615\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8247 - accuracy: 0.5630 - val_loss: 1.1129 - val_accuracy: 0.4615\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8255 - accuracy: 0.5630 - val_loss: 1.1138 - val_accuracy: 0.4615\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8268 - accuracy: 0.5556 - val_loss: 1.1121 - val_accuracy: 0.5214\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 122us/step - loss: 0.8275 - accuracy: 0.5630 - val_loss: 1.1123 - val_accuracy: 0.4615\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8248 - accuracy: 0.5630 - val_loss: 1.1151 - val_accuracy: 0.4615\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8265 - accuracy: 0.5259 - val_loss: 1.1119 - val_accuracy: 0.5128\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8262 - accuracy: 0.5407 - val_loss: 1.1143 - val_accuracy: 0.4615\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8249 - accuracy: 0.5630 - val_loss: 1.1192 - val_accuracy: 0.4615\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8240 - accuracy: 0.5556 - val_loss: 1.1250 - val_accuracy: 0.5214\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8286 - accuracy: 0.5519 - val_loss: 1.1174 - val_accuracy: 0.5214\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8252 - accuracy: 0.5444 - val_loss: 1.1083 - val_accuracy: 0.4615\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8294 - accuracy: 0.5630 - val_loss: 1.1084 - val_accuracy: 0.4615\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.8227 - accuracy: 0.5630 - val_loss: 1.1103 - val_accuracy: 0.5214\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8268 - accuracy: 0.5556 - val_loss: 1.1155 - val_accuracy: 0.5214\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.8280 - accuracy: 0.5556 - val_loss: 1.1092 - val_accuracy: 0.5128\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 331us/step - loss: 0.8268 - accuracy: 0.5481 - val_loss: 1.1139 - val_accuracy: 0.4615\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 330us/step - loss: 0.8292 - accuracy: 0.5519 - val_loss: 1.1116 - val_accuracy: 0.5214\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8239 - accuracy: 0.5556 - val_loss: 1.1157 - val_accuracy: 0.4615\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8259 - accuracy: 0.5259 - val_loss: 1.1164 - val_accuracy: 0.5214\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8254 - accuracy: 0.5519 - val_loss: 1.1198 - val_accuracy: 0.4530\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8258 - accuracy: 0.5259 - val_loss: 1.1201 - val_accuracy: 0.5214\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8251 - accuracy: 0.5741 - val_loss: 1.1141 - val_accuracy: 0.4615\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8293 - accuracy: 0.5630 - val_loss: 1.1167 - val_accuracy: 0.4615\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8253 - accuracy: 0.5815 - val_loss: 1.1157 - val_accuracy: 0.5128\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8262 - accuracy: 0.5407 - val_loss: 1.1142 - val_accuracy: 0.4530\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1151 - val_accuracy: 0.4615\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8248 - accuracy: 0.5630 - val_loss: 1.1152 - val_accuracy: 0.5214\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8236 - accuracy: 0.5556 - val_loss: 1.1130 - val_accuracy: 0.5128\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8285 - accuracy: 0.5593 - val_loss: 1.1206 - val_accuracy: 0.5214\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8255 - accuracy: 0.5519 - val_loss: 1.1216 - val_accuracy: 0.4615\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8234 - accuracy: 0.5741 - val_loss: 1.1195 - val_accuracy: 0.5128\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8249 - accuracy: 0.5519 - val_loss: 1.1205 - val_accuracy: 0.4530\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8260 - accuracy: 0.5630 - val_loss: 1.1244 - val_accuracy: 0.4615\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8248 - accuracy: 0.5630 - val_loss: 1.1259 - val_accuracy: 0.4615\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8250 - accuracy: 0.5630 - val_loss: 1.1254 - val_accuracy: 0.4615\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8243 - accuracy: 0.5630 - val_loss: 1.1210 - val_accuracy: 0.4615\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8242 - accuracy: 0.5630 - val_loss: 1.1193 - val_accuracy: 0.4615\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8247 - accuracy: 0.5815 - val_loss: 1.1223 - val_accuracy: 0.5214\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8247 - accuracy: 0.5519 - val_loss: 1.1183 - val_accuracy: 0.4615\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8243 - accuracy: 0.5630 - val_loss: 1.1212 - val_accuracy: 0.4615\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8248 - accuracy: 0.5519 - val_loss: 1.1247 - val_accuracy: 0.5214\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8244 - accuracy: 0.5556 - val_loss: 1.1152 - val_accuracy: 0.5214\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8245 - accuracy: 0.5556 - val_loss: 1.1165 - val_accuracy: 0.4615\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 1.1201 - val_accuracy: 0.4615\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8253 - accuracy: 0.5259 - val_loss: 1.1149 - val_accuracy: 0.5214\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8267 - accuracy: 0.5370 - val_loss: 1.1170 - val_accuracy: 0.4530\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8254 - accuracy: 0.5148 - val_loss: 1.1191 - val_accuracy: 0.4615\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8239 - accuracy: 0.5593 - val_loss: 1.1212 - val_accuracy: 0.5214\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8236 - accuracy: 0.5704 - val_loss: 1.1197 - val_accuracy: 0.4615\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8240 - accuracy: 0.5630 - val_loss: 1.1207 - val_accuracy: 0.4615\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8279 - accuracy: 0.5556 - val_loss: 1.1172 - val_accuracy: 0.5128\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8254 - accuracy: 0.5630 - val_loss: 1.1243 - val_accuracy: 0.4615\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1216 - val_accuracy: 0.4615\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8235 - accuracy: 0.5630 - val_loss: 1.1165 - val_accuracy: 0.5128\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8241 - accuracy: 0.5556 - val_loss: 1.1190 - val_accuracy: 0.4530\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8238 - accuracy: 0.5667 - val_loss: 1.1219 - val_accuracy: 0.4615\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8247 - accuracy: 0.5630 - val_loss: 1.1242 - val_accuracy: 0.4615\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8244 - accuracy: 0.5667 - val_loss: 1.1230 - val_accuracy: 0.4530\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8256 - accuracy: 0.5333 - val_loss: 1.1248 - val_accuracy: 0.4615\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8239 - accuracy: 0.5667 - val_loss: 1.1217 - val_accuracy: 0.4530\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8283 - accuracy: 0.5630 - val_loss: 1.1199 - val_accuracy: 0.4615\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8248 - accuracy: 0.5556 - val_loss: 1.1179 - val_accuracy: 0.4530\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8252 - accuracy: 0.5370 - val_loss: 1.1229 - val_accuracy: 0.4615\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8250 - accuracy: 0.5630 - val_loss: 1.1255 - val_accuracy: 0.4615\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8250 - accuracy: 0.5444 - val_loss: 1.1278 - val_accuracy: 0.5128\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8267 - accuracy: 0.5444 - val_loss: 1.1267 - val_accuracy: 0.4530\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8263 - accuracy: 0.5148 - val_loss: 1.1177 - val_accuracy: 0.5214\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8264 - accuracy: 0.5556 - val_loss: 1.1242 - val_accuracy: 0.4615\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8231 - accuracy: 0.5593 - val_loss: 1.1137 - val_accuracy: 0.5128\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8268 - accuracy: 0.5222 - val_loss: 1.1124 - val_accuracy: 0.5128\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8286 - accuracy: 0.5593 - val_loss: 1.1157 - val_accuracy: 0.5128\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8278 - accuracy: 0.5444 - val_loss: 1.1258 - val_accuracy: 0.4615\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8258 - accuracy: 0.5704 - val_loss: 1.1175 - val_accuracy: 0.5214\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8245 - accuracy: 0.5593 - val_loss: 1.1156 - val_accuracy: 0.5128\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8266 - accuracy: 0.5296 - val_loss: 1.1163 - val_accuracy: 0.5128\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8246 - accuracy: 0.5889 - val_loss: 1.1230 - val_accuracy: 0.4615\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8235 - accuracy: 0.5667 - val_loss: 1.1208 - val_accuracy: 0.5128\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8279 - accuracy: 0.5593 - val_loss: 1.1247 - val_accuracy: 0.5128\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8241 - accuracy: 0.5519 - val_loss: 1.1278 - val_accuracy: 0.4615\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8277 - accuracy: 0.5630 - val_loss: 1.1237 - val_accuracy: 0.4615\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8246 - accuracy: 0.5556 - val_loss: 1.1217 - val_accuracy: 0.5128\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8249 - accuracy: 0.5481 - val_loss: 1.1279 - val_accuracy: 0.4615\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8261 - accuracy: 0.5630 - val_loss: 1.1294 - val_accuracy: 0.4615\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8257 - accuracy: 0.5556 - val_loss: 1.1300 - val_accuracy: 0.5128\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8254 - accuracy: 0.5630 - val_loss: 1.1255 - val_accuracy: 0.4615\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8246 - accuracy: 0.5667 - val_loss: 1.1272 - val_accuracy: 0.4615\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8243 - accuracy: 0.5630 - val_loss: 1.1267 - val_accuracy: 0.5214\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8277 - accuracy: 0.5630 - val_loss: 1.1247 - val_accuracy: 0.5128\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8271 - accuracy: 0.5630 - val_loss: 1.1346 - val_accuracy: 0.4615\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8252 - accuracy: 0.5667 - val_loss: 1.1279 - val_accuracy: 0.5128\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8300 - accuracy: 0.5593 - val_loss: 1.1261 - val_accuracy: 0.5128\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.8311 - accuracy: 0.5519 - val_loss: 1.1368 - val_accuracy: 0.4615\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8275 - accuracy: 0.5259 - val_loss: 1.1259 - val_accuracy: 0.5128\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8229 - accuracy: 0.5519 - val_loss: 1.1285 - val_accuracy: 0.4530\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8266 - accuracy: 0.5630 - val_loss: 1.1325 - val_accuracy: 0.4615\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8244 - accuracy: 0.5481 - val_loss: 1.1214 - val_accuracy: 0.5128\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8262 - accuracy: 0.5593 - val_loss: 1.1227 - val_accuracy: 0.5128\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8253 - accuracy: 0.5370 - val_loss: 1.1265 - val_accuracy: 0.4615\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8234 - accuracy: 0.5667 - val_loss: 1.1261 - val_accuracy: 0.4615\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8247 - accuracy: 0.5667 - val_loss: 1.1318 - val_accuracy: 0.4530\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8243 - accuracy: 0.5667 - val_loss: 1.1402 - val_accuracy: 0.4530\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8246 - accuracy: 0.5778 - val_loss: 1.1379 - val_accuracy: 0.5128\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8264 - accuracy: 0.5407 - val_loss: 1.1268 - val_accuracy: 0.4615\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8237 - accuracy: 0.5667 - val_loss: 1.1265 - val_accuracy: 0.5214\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8280 - accuracy: 0.5593 - val_loss: 1.1247 - val_accuracy: 0.5128\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8264 - accuracy: 0.5407 - val_loss: 1.1367 - val_accuracy: 0.4615\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8239 - accuracy: 0.5630 - val_loss: 1.1276 - val_accuracy: 0.4530\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8226 - accuracy: 0.5704 - val_loss: 1.1288 - val_accuracy: 0.5128\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8274 - accuracy: 0.5593 - val_loss: 1.1311 - val_accuracy: 0.4615\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8265 - accuracy: 0.5407 - val_loss: 1.1285 - val_accuracy: 0.5128\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8238 - accuracy: 0.5556 - val_loss: 1.1287 - val_accuracy: 0.4615\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8237 - accuracy: 0.5667 - val_loss: 1.1297 - val_accuracy: 0.4615\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8262 - accuracy: 0.5667 - val_loss: 1.1257 - val_accuracy: 0.4530\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 132us/step - loss: 0.8328 - accuracy: 0.5296 - val_loss: 1.1316 - val_accuracy: 0.5128\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8257 - accuracy: 0.5593 - val_loss: 1.1416 - val_accuracy: 0.4615\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8286 - accuracy: 0.5704 - val_loss: 1.1317 - val_accuracy: 0.5128\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8245 - accuracy: 0.5296 - val_loss: 1.1249 - val_accuracy: 0.4530\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8214 - accuracy: 0.5704 - val_loss: 1.1296 - val_accuracy: 0.4615\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8285 - accuracy: 0.5259 - val_loss: 1.1301 - val_accuracy: 0.4615\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8267 - accuracy: 0.5667 - val_loss: 1.1346 - val_accuracy: 0.4615\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8234 - accuracy: 0.5667 - val_loss: 1.1353 - val_accuracy: 0.4530\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8289 - accuracy: 0.5481 - val_loss: 1.1320 - val_accuracy: 0.5128\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8278 - accuracy: 0.5148 - val_loss: 1.1320 - val_accuracy: 0.4530\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8253 - accuracy: 0.5667 - val_loss: 1.1301 - val_accuracy: 0.4530\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8242 - accuracy: 0.5667 - val_loss: 1.1361 - val_accuracy: 0.4615\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 385us/step - loss: 0.8244 - accuracy: 0.5296 - val_loss: 1.1346 - val_accuracy: 0.4530\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8241 - accuracy: 0.5667 - val_loss: 1.1303 - val_accuracy: 0.4530\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8243 - accuracy: 0.5556 - val_loss: 1.1312 - val_accuracy: 0.5128\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8235 - accuracy: 0.5741 - val_loss: 1.1348 - val_accuracy: 0.4615\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1368 - val_accuracy: 0.4615\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8228 - accuracy: 0.5704 - val_loss: 1.1322 - val_accuracy: 0.4530\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8236 - accuracy: 0.5667 - val_loss: 1.1315 - val_accuracy: 0.4530\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8250 - accuracy: 0.5667 - val_loss: 1.1361 - val_accuracy: 0.4615\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8271 - accuracy: 0.5667 - val_loss: 1.1339 - val_accuracy: 0.4615\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1319 - val_accuracy: 0.5128\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8239 - accuracy: 0.5593 - val_loss: 1.1354 - val_accuracy: 0.4615\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8234 - accuracy: 0.5667 - val_loss: 1.1388 - val_accuracy: 0.4615\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8245 - accuracy: 0.5630 - val_loss: 1.1291 - val_accuracy: 0.4530\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8276 - accuracy: 0.5444 - val_loss: 1.1277 - val_accuracy: 0.5214\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8338 - accuracy: 0.5481 - val_loss: 1.1449 - val_accuracy: 0.4615\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8242 - accuracy: 0.5667 - val_loss: 1.1314 - val_accuracy: 0.5128\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8243 - accuracy: 0.5593 - val_loss: 1.1344 - val_accuracy: 0.5128\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8271 - accuracy: 0.5519 - val_loss: 1.1317 - val_accuracy: 0.4530\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8230 - accuracy: 0.5667 - val_loss: 1.1326 - val_accuracy: 0.5128\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8268 - accuracy: 0.5593 - val_loss: 1.1412 - val_accuracy: 0.4615\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1327 - val_accuracy: 0.4530\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8254 - accuracy: 0.5444 - val_loss: 1.1319 - val_accuracy: 0.5128\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8262 - accuracy: 0.5593 - val_loss: 1.1293 - val_accuracy: 0.5128\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8268 - accuracy: 0.5407 - val_loss: 1.1388 - val_accuracy: 0.4615\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8249 - accuracy: 0.5667 - val_loss: 1.1379 - val_accuracy: 0.4615\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8245 - accuracy: 0.5667 - val_loss: 1.1332 - val_accuracy: 0.4530\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8221 - accuracy: 0.5667 - val_loss: 1.1346 - val_accuracy: 0.4530\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8231 - accuracy: 0.5556 - val_loss: 1.1340 - val_accuracy: 0.4530\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8258 - accuracy: 0.5667 - val_loss: 1.1423 - val_accuracy: 0.4615\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8268 - accuracy: 0.5667 - val_loss: 1.1432 - val_accuracy: 0.4615\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8263 - accuracy: 0.5556 - val_loss: 1.1492 - val_accuracy: 0.5128\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8282 - accuracy: 0.5519 - val_loss: 1.1283 - val_accuracy: 0.4615\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8220 - accuracy: 0.5667 - val_loss: 1.1220 - val_accuracy: 0.5214\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8288 - accuracy: 0.5407 - val_loss: 1.1286 - val_accuracy: 0.4615\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8222 - accuracy: 0.5704 - val_loss: 1.1254 - val_accuracy: 0.5128\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8251 - accuracy: 0.5593 - val_loss: 1.1241 - val_accuracy: 0.5128\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8248 - accuracy: 0.5148 - val_loss: 1.1300 - val_accuracy: 0.4615\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8210 - accuracy: 0.5556 - val_loss: 1.1326 - val_accuracy: 0.5214\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8223 - accuracy: 0.5778 - val_loss: 1.1362 - val_accuracy: 0.4615\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8263 - accuracy: 0.5333 - val_loss: 1.1306 - val_accuracy: 0.5214\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8254 - accuracy: 0.5667 - val_loss: 1.1350 - val_accuracy: 0.4615\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8277 - accuracy: 0.5593 - val_loss: 1.1347 - val_accuracy: 0.5128\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1377 - val_accuracy: 0.4615\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8220 - accuracy: 0.5630 - val_loss: 1.1340 - val_accuracy: 0.5214\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8219 - accuracy: 0.5593 - val_loss: 1.1315 - val_accuracy: 0.4530\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8225 - accuracy: 0.5593 - val_loss: 1.1338 - val_accuracy: 0.4615\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8221 - accuracy: 0.5481 - val_loss: 1.1388 - val_accuracy: 0.4615\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8226 - accuracy: 0.5667 - val_loss: 1.1412 - val_accuracy: 0.4615\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8267 - accuracy: 0.5630 - val_loss: 1.1373 - val_accuracy: 0.5128\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8239 - accuracy: 0.5704 - val_loss: 1.1425 - val_accuracy: 0.4615\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8219 - accuracy: 0.5667 - val_loss: 1.1409 - val_accuracy: 0.4615\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8256 - accuracy: 0.5630 - val_loss: 1.1380 - val_accuracy: 0.5128\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8222 - accuracy: 0.5481 - val_loss: 1.1430 - val_accuracy: 0.4615\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8221 - accuracy: 0.5704 - val_loss: 1.1405 - val_accuracy: 0.4530\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8220 - accuracy: 0.5556 - val_loss: 1.1380 - val_accuracy: 0.5128\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8222 - accuracy: 0.5593 - val_loss: 1.1375 - val_accuracy: 0.5128\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8231 - accuracy: 0.5667 - val_loss: 1.1432 - val_accuracy: 0.4615\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8222 - accuracy: 0.5667 - val_loss: 1.1439 - val_accuracy: 0.4615\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1361 - val_accuracy: 0.4530\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1379 - val_accuracy: 0.4530\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8227 - accuracy: 0.5667 - val_loss: 1.1463 - val_accuracy: 0.4530\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8280 - accuracy: 0.5333 - val_loss: 1.1486 - val_accuracy: 0.4530\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8225 - accuracy: 0.5704 - val_loss: 1.1486 - val_accuracy: 0.4615\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8226 - accuracy: 0.5667 - val_loss: 1.1436 - val_accuracy: 0.4615\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8320 - accuracy: 0.5444 - val_loss: 1.1446 - val_accuracy: 0.5128\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8232 - accuracy: 0.5593 - val_loss: 1.1425 - val_accuracy: 0.4530\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8242 - accuracy: 0.5630 - val_loss: 1.1332 - val_accuracy: 0.4615\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8223 - accuracy: 0.5519 - val_loss: 1.1319 - val_accuracy: 0.5128\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8225 - accuracy: 0.5630 - val_loss: 1.1372 - val_accuracy: 0.4615\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8334 - accuracy: 0.5667 - val_loss: 1.1454 - val_accuracy: 0.4615\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8226 - accuracy: 0.5852 - val_loss: 1.1400 - val_accuracy: 0.5128\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8236 - accuracy: 0.5593 - val_loss: 1.1438 - val_accuracy: 0.5128\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8238 - accuracy: 0.5556 - val_loss: 1.1387 - val_accuracy: 0.4615\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8243 - accuracy: 0.5593 - val_loss: 1.1318 - val_accuracy: 0.5214\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8233 - accuracy: 0.5630 - val_loss: 1.1387 - val_accuracy: 0.4615\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8244 - accuracy: 0.5593 - val_loss: 1.1386 - val_accuracy: 0.5128\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8228 - accuracy: 0.5593 - val_loss: 1.1367 - val_accuracy: 0.5128\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8260 - accuracy: 0.5519 - val_loss: 1.1413 - val_accuracy: 0.4615\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8267 - accuracy: 0.5667 - val_loss: 1.1324 - val_accuracy: 0.5128\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8223 - accuracy: 0.5481 - val_loss: 1.1358 - val_accuracy: 0.5214\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8270 - accuracy: 0.5481 - val_loss: 1.1415 - val_accuracy: 0.4615\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8265 - accuracy: 0.5519 - val_loss: 1.1324 - val_accuracy: 0.5128\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8227 - accuracy: 0.5407 - val_loss: 1.1355 - val_accuracy: 0.4615\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8266 - accuracy: 0.5333 - val_loss: 1.1369 - val_accuracy: 0.4530\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8212 - accuracy: 0.5667 - val_loss: 1.1430 - val_accuracy: 0.4615\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8270 - accuracy: 0.5667 - val_loss: 1.1451 - val_accuracy: 0.4615\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8240 - accuracy: 0.5519 - val_loss: 1.1416 - val_accuracy: 0.5128\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8262 - accuracy: 0.5296 - val_loss: 1.1392 - val_accuracy: 0.4530\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8287 - accuracy: 0.5667 - val_loss: 1.1399 - val_accuracy: 0.4615\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8206 - accuracy: 0.5519 - val_loss: 1.1370 - val_accuracy: 0.5128\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8244 - accuracy: 0.5519 - val_loss: 1.1402 - val_accuracy: 0.4530\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8236 - accuracy: 0.5630 - val_loss: 1.1433 - val_accuracy: 0.4615\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8226 - accuracy: 0.5704 - val_loss: 1.1435 - val_accuracy: 0.5128\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8278 - accuracy: 0.5556 - val_loss: 1.1398 - val_accuracy: 0.4615\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8237 - accuracy: 0.5333 - val_loss: 1.1379 - val_accuracy: 0.5214\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8230 - accuracy: 0.5556 - val_loss: 1.1390 - val_accuracy: 0.4530\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8217 - accuracy: 0.5370 - val_loss: 1.1381 - val_accuracy: 0.5128\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8228 - accuracy: 0.5519 - val_loss: 1.1425 - val_accuracy: 0.4530\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 122us/step - loss: 0.8221 - accuracy: 0.5630 - val_loss: 1.1435 - val_accuracy: 0.4530\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8231 - accuracy: 0.5667 - val_loss: 1.1417 - val_accuracy: 0.4615\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8214 - accuracy: 0.5667 - val_loss: 1.1429 - val_accuracy: 0.5128\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8216 - accuracy: 0.5407 - val_loss: 1.1444 - val_accuracy: 0.4530\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8226 - accuracy: 0.5630 - val_loss: 1.1378 - val_accuracy: 0.4530\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8262 - accuracy: 0.5667 - val_loss: 1.1407 - val_accuracy: 0.4615\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8222 - accuracy: 0.5407 - val_loss: 1.1342 - val_accuracy: 0.5214\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8250 - accuracy: 0.5593 - val_loss: 1.1335 - val_accuracy: 0.5128\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8297 - accuracy: 0.5593 - val_loss: 1.1460 - val_accuracy: 0.4615\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8256 - accuracy: 0.5667 - val_loss: 1.1484 - val_accuracy: 0.5214\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8226 - accuracy: 0.5593 - val_loss: 1.1426 - val_accuracy: 0.5128\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8216 - accuracy: 0.5333 - val_loss: 1.1453 - val_accuracy: 0.4530\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8237 - accuracy: 0.5667 - val_loss: 1.1479 - val_accuracy: 0.4530\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8228 - accuracy: 0.5667 - val_loss: 1.1460 - val_accuracy: 0.4615\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8234 - accuracy: 0.5704 - val_loss: 1.1406 - val_accuracy: 0.5128\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8221 - accuracy: 0.5593 - val_loss: 1.1453 - val_accuracy: 0.4615\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8213 - accuracy: 0.5667 - val_loss: 1.1428 - val_accuracy: 0.4615\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8242 - accuracy: 0.5667 - val_loss: 1.1446 - val_accuracy: 0.4615\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8213 - accuracy: 0.5630 - val_loss: 1.1437 - val_accuracy: 0.5128\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8265 - accuracy: 0.5593 - val_loss: 1.1511 - val_accuracy: 0.5128\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8215 - accuracy: 0.5519 - val_loss: 1.1503 - val_accuracy: 0.4615\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8283 - accuracy: 0.5667 - val_loss: 1.1465 - val_accuracy: 0.4615\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8276 - accuracy: 0.5556 - val_loss: 1.1456 - val_accuracy: 0.5128\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1469 - val_accuracy: 0.4615\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8258 - accuracy: 0.5667 - val_loss: 1.1481 - val_accuracy: 0.4615\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8238 - accuracy: 0.5407 - val_loss: 1.1426 - val_accuracy: 0.5128\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8246 - accuracy: 0.5333 - val_loss: 1.1462 - val_accuracy: 0.4615\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8295 - accuracy: 0.5333 - val_loss: 1.1458 - val_accuracy: 0.5128\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8205 - accuracy: 0.5741 - val_loss: 1.1470 - val_accuracy: 0.4615\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8231 - accuracy: 0.5296 - val_loss: 1.1464 - val_accuracy: 0.5128\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8210 - accuracy: 0.5407 - val_loss: 1.1468 - val_accuracy: 0.5128\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8222 - accuracy: 0.5222 - val_loss: 1.1509 - val_accuracy: 0.4530\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8248 - accuracy: 0.5667 - val_loss: 1.1559 - val_accuracy: 0.4615\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8250 - accuracy: 0.5630 - val_loss: 1.1551 - val_accuracy: 0.4530\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8258 - accuracy: 0.5630 - val_loss: 1.1467 - val_accuracy: 0.4530\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8276 - accuracy: 0.5667 - val_loss: 1.1514 - val_accuracy: 0.4615\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8221 - accuracy: 0.5667 - val_loss: 1.1340 - val_accuracy: 0.4615\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8281 - accuracy: 0.5370 - val_loss: 1.1282 - val_accuracy: 0.5128\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8276 - accuracy: 0.5519 - val_loss: 1.1358 - val_accuracy: 0.4615\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8253 - accuracy: 0.5148 - val_loss: 1.1367 - val_accuracy: 0.5214\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8192 - accuracy: 0.5667 - val_loss: 1.1423 - val_accuracy: 0.4615\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8227 - accuracy: 0.5667 - val_loss: 1.1497 - val_accuracy: 0.4615\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8213 - accuracy: 0.5667 - val_loss: 1.1458 - val_accuracy: 0.4615\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8219 - accuracy: 0.5556 - val_loss: 1.1483 - val_accuracy: 0.5128\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8226 - accuracy: 0.5444 - val_loss: 1.1488 - val_accuracy: 0.4530\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8230 - accuracy: 0.5667 - val_loss: 1.1479 - val_accuracy: 0.4530\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8218 - accuracy: 0.5667 - val_loss: 1.1466 - val_accuracy: 0.4530\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8244 - accuracy: 0.5667 - val_loss: 1.1485 - val_accuracy: 0.4615\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8216 - accuracy: 0.5370 - val_loss: 1.1492 - val_accuracy: 0.5128\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8208 - accuracy: 0.5593 - val_loss: 1.1509 - val_accuracy: 0.5128\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8209 - accuracy: 0.5741 - val_loss: 1.1479 - val_accuracy: 0.4615\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8219 - accuracy: 0.5593 - val_loss: 1.1463 - val_accuracy: 0.5214\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8205 - accuracy: 0.5741 - val_loss: 1.1495 - val_accuracy: 0.4615\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8230 - accuracy: 0.5667 - val_loss: 1.1524 - val_accuracy: 0.4615\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8231 - accuracy: 0.5444 - val_loss: 1.1461 - val_accuracy: 0.5128\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8203 - accuracy: 0.5333 - val_loss: 1.1443 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8225 - accuracy: 0.5667 - val_loss: 1.1457 - val_accuracy: 0.4530\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8219 - accuracy: 0.5630 - val_loss: 1.1506 - val_accuracy: 0.4615\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8222 - accuracy: 0.5667 - val_loss: 1.1500 - val_accuracy: 0.4615\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8217 - accuracy: 0.5630 - val_loss: 1.1492 - val_accuracy: 0.4530\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8214 - accuracy: 0.5704 - val_loss: 1.1534 - val_accuracy: 0.4615\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7981 - accuracy: 0.59 - 0s 78us/step - loss: 0.8226 - accuracy: 0.5630 - val_loss: 1.1479 - val_accuracy: 0.4530\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8208 - accuracy: 0.5259 - val_loss: 1.1503 - val_accuracy: 0.5128\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8226 - accuracy: 0.5444 - val_loss: 1.1530 - val_accuracy: 0.4615\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8204 - accuracy: 0.5704 - val_loss: 1.1463 - val_accuracy: 0.4530\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8204 - accuracy: 0.5667 - val_loss: 1.1489 - val_accuracy: 0.4530\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8246 - accuracy: 0.5630 - val_loss: 1.1528 - val_accuracy: 0.4615\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8226 - accuracy: 0.5444 - val_loss: 1.1481 - val_accuracy: 0.5128\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8226 - accuracy: 0.5593 - val_loss: 1.1464 - val_accuracy: 0.4530\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8220 - accuracy: 0.5630 - val_loss: 1.1534 - val_accuracy: 0.4615\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8226 - accuracy: 0.5667 - val_loss: 1.1445 - val_accuracy: 0.4615\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8211 - accuracy: 0.5407 - val_loss: 1.1436 - val_accuracy: 0.5128\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8225 - accuracy: 0.5593 - val_loss: 1.1452 - val_accuracy: 0.4530\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1526 - val_accuracy: 0.4615\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8232 - accuracy: 0.5704 - val_loss: 1.1513 - val_accuracy: 0.4530\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8214 - accuracy: 0.5333 - val_loss: 1.1593 - val_accuracy: 0.4530\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8263 - accuracy: 0.5593 - val_loss: 1.1547 - val_accuracy: 0.5128\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8199 - accuracy: 0.5593 - val_loss: 1.1547 - val_accuracy: 0.4615\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8222 - accuracy: 0.5667 - val_loss: 1.1495 - val_accuracy: 0.4615\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1467 - val_accuracy: 0.4615\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8271 - accuracy: 0.5259 - val_loss: 1.1474 - val_accuracy: 0.5128\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8206 - accuracy: 0.5593 - val_loss: 1.1485 - val_accuracy: 0.4530\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8222 - accuracy: 0.5667 - val_loss: 1.1500 - val_accuracy: 0.4615\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1534 - val_accuracy: 0.4530\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8238 - accuracy: 0.5667 - val_loss: 1.1506 - val_accuracy: 0.5128\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8217 - accuracy: 0.5593 - val_loss: 1.1537 - val_accuracy: 0.4530\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8219 - accuracy: 0.5667 - val_loss: 1.1586 - val_accuracy: 0.4615\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8213 - accuracy: 0.5481 - val_loss: 1.1509 - val_accuracy: 0.5128\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8206 - accuracy: 0.5593 - val_loss: 1.1519 - val_accuracy: 0.5128\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8238 - accuracy: 0.5593 - val_loss: 1.1526 - val_accuracy: 0.5128\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8263 - accuracy: 0.5815 - val_loss: 1.1621 - val_accuracy: 0.4615\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8231 - accuracy: 0.5222 - val_loss: 1.1556 - val_accuracy: 0.4530\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8228 - accuracy: 0.5111 - val_loss: 1.1498 - val_accuracy: 0.5128\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8221 - accuracy: 0.5556 - val_loss: 1.1514 - val_accuracy: 0.4530\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8279 - accuracy: 0.5444 - val_loss: 1.1599 - val_accuracy: 0.4615\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8234 - accuracy: 0.5667 - val_loss: 1.1565 - val_accuracy: 0.4530\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8205 - accuracy: 0.5556 - val_loss: 1.1515 - val_accuracy: 0.4530\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8211 - accuracy: 0.5333 - val_loss: 1.1492 - val_accuracy: 0.4615\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8193 - accuracy: 0.5667 - val_loss: 1.1471 - val_accuracy: 0.4615\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8217 - accuracy: 0.5630 - val_loss: 1.1456 - val_accuracy: 0.5128\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8217 - accuracy: 0.5593 - val_loss: 1.1488 - val_accuracy: 0.5128\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8233 - accuracy: 0.5481 - val_loss: 1.1607 - val_accuracy: 0.4615\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8274 - accuracy: 0.5593 - val_loss: 1.1617 - val_accuracy: 0.5214\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8197 - accuracy: 0.5593 - val_loss: 1.1549 - val_accuracy: 0.4530\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8199 - accuracy: 0.5222 - val_loss: 1.1544 - val_accuracy: 0.4530\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8212 - accuracy: 0.5667 - val_loss: 1.1532 - val_accuracy: 0.4530\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8200 - accuracy: 0.5667 - val_loss: 1.1496 - val_accuracy: 0.4615\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8245 - accuracy: 0.5667 - val_loss: 1.1475 - val_accuracy: 0.4615\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8265 - accuracy: 0.5519 - val_loss: 1.1514 - val_accuracy: 0.5128\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8263 - accuracy: 0.5630 - val_loss: 1.1524 - val_accuracy: 0.4615\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8272 - accuracy: 0.5333 - val_loss: 1.1520 - val_accuracy: 0.5214\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8214 - accuracy: 0.5556 - val_loss: 1.1519 - val_accuracy: 0.4615\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8225 - accuracy: 0.5407 - val_loss: 1.1496 - val_accuracy: 0.4615\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8271 - accuracy: 0.5667 - val_loss: 1.1577 - val_accuracy: 0.4615\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8310 - accuracy: 0.5556 - val_loss: 1.1621 - val_accuracy: 0.5128\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1579 - val_accuracy: 0.4615\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8210 - accuracy: 0.5630 - val_loss: 1.1580 - val_accuracy: 0.4615\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8236 - accuracy: 0.5667 - val_loss: 1.1604 - val_accuracy: 0.4615\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8229 - accuracy: 0.5556 - val_loss: 1.1604 - val_accuracy: 0.5214\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8208 - accuracy: 0.5593 - val_loss: 1.1514 - val_accuracy: 0.5128\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8218 - accuracy: 0.5556 - val_loss: 1.1514 - val_accuracy: 0.4615\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8212 - accuracy: 0.5667 - val_loss: 1.1502 - val_accuracy: 0.4615\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8210 - accuracy: 0.5667 - val_loss: 1.1520 - val_accuracy: 0.4615\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.8211 - accuracy: 0.5667 - val_loss: 1.1566 - val_accuracy: 0.5214\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8220 - accuracy: 0.5333 - val_loss: 1.1561 - val_accuracy: 0.5128\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8260 - accuracy: 0.5593 - val_loss: 1.1576 - val_accuracy: 0.5128\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8241 - accuracy: 0.5259 - val_loss: 1.1683 - val_accuracy: 0.4615\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.8222 - accuracy: 0.5667 - val_loss: 1.1628 - val_accuracy: 0.4530\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8194 - accuracy: 0.5556 - val_loss: 1.1586 - val_accuracy: 0.5128\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8225 - accuracy: 0.5296 - val_loss: 1.1568 - val_accuracy: 0.5128\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8233 - accuracy: 0.5593 - val_loss: 1.1604 - val_accuracy: 0.4530\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8203 - accuracy: 0.5741 - val_loss: 1.1620 - val_accuracy: 0.5128\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8257 - accuracy: 0.5519 - val_loss: 1.1673 - val_accuracy: 0.4615\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8233 - accuracy: 0.5667 - val_loss: 1.1573 - val_accuracy: 0.4530\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8219 - accuracy: 0.5259 - val_loss: 1.1581 - val_accuracy: 0.5128\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8227 - accuracy: 0.5481 - val_loss: 1.1633 - val_accuracy: 0.4530\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8205 - accuracy: 0.5556 - val_loss: 1.1641 - val_accuracy: 0.5128\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8225 - accuracy: 0.5556 - val_loss: 1.1586 - val_accuracy: 0.4530\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8211 - accuracy: 0.5667 - val_loss: 1.1554 - val_accuracy: 0.4615\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8213 - accuracy: 0.5519 - val_loss: 1.1530 - val_accuracy: 0.4615\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8215 - accuracy: 0.5667 - val_loss: 1.1532 - val_accuracy: 0.4615\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8199 - accuracy: 0.5667 - val_loss: 1.1540 - val_accuracy: 0.4615\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8200 - accuracy: 0.5667 - val_loss: 1.1552 - val_accuracy: 0.4615\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8205 - accuracy: 0.5667 - val_loss: 1.1529 - val_accuracy: 0.5128\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8212 - accuracy: 0.5630 - val_loss: 1.1590 - val_accuracy: 0.4530\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8255 - accuracy: 0.5630 - val_loss: 1.1680 - val_accuracy: 0.4615\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8219 - accuracy: 0.5667 - val_loss: 1.1605 - val_accuracy: 0.4530\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8272 - accuracy: 0.5593 - val_loss: 1.1580 - val_accuracy: 0.4530\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8199 - accuracy: 0.5519 - val_loss: 1.1666 - val_accuracy: 0.4530\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8207 - accuracy: 0.5667 - val_loss: 1.1593 - val_accuracy: 0.4615\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8228 - accuracy: 0.5333 - val_loss: 1.1535 - val_accuracy: 0.5214\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8201 - accuracy: 0.5519 - val_loss: 1.1555 - val_accuracy: 0.4615\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8229 - accuracy: 0.5519 - val_loss: 1.1523 - val_accuracy: 0.5128\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8240 - accuracy: 0.5556 - val_loss: 1.1601 - val_accuracy: 0.4615\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8241 - accuracy: 0.5667 - val_loss: 1.1586 - val_accuracy: 0.4615\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8193 - accuracy: 0.5667 - val_loss: 1.1564 - val_accuracy: 0.5128\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8207 - accuracy: 0.5630 - val_loss: 1.1601 - val_accuracy: 0.4530\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8236 - accuracy: 0.5407 - val_loss: 1.1643 - val_accuracy: 0.5128\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8219 - accuracy: 0.5444 - val_loss: 1.1668 - val_accuracy: 0.4530\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8211 - accuracy: 0.5667 - val_loss: 1.1641 - val_accuracy: 0.4530\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8208 - accuracy: 0.5667 - val_loss: 1.1663 - val_accuracy: 0.5128\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8244 - accuracy: 0.5593 - val_loss: 1.1612 - val_accuracy: 0.5128\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8201 - accuracy: 0.5444 - val_loss: 1.1632 - val_accuracy: 0.4615\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8203 - accuracy: 0.5667 - val_loss: 1.1574 - val_accuracy: 0.4615\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8229 - accuracy: 0.5667 - val_loss: 1.1544 - val_accuracy: 0.4530\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1578 - val_accuracy: 0.4530\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 111us/step - loss: 0.8205 - accuracy: 0.5370 - val_loss: 1.1591 - val_accuracy: 0.5214\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8210 - accuracy: 0.5593 - val_loss: 1.1588 - val_accuracy: 0.4615\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8218 - accuracy: 0.5667 - val_loss: 1.1608 - val_accuracy: 0.4615\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8209 - accuracy: 0.5481 - val_loss: 1.1606 - val_accuracy: 0.4530\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8204 - accuracy: 0.5667 - val_loss: 1.1630 - val_accuracy: 0.4530\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8190 - accuracy: 0.5667 - val_loss: 1.1628 - val_accuracy: 0.5128\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8317 - accuracy: 0.5593 - val_loss: 1.1604 - val_accuracy: 0.5128\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8203 - accuracy: 0.5741 - val_loss: 1.1687 - val_accuracy: 0.4615\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8237 - accuracy: 0.5704 - val_loss: 1.1643 - val_accuracy: 0.4530\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8255 - accuracy: 0.5741 - val_loss: 1.1703 - val_accuracy: 0.5214\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8230 - accuracy: 0.5222 - val_loss: 1.1635 - val_accuracy: 0.4530\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8225 - accuracy: 0.5407 - val_loss: 1.1668 - val_accuracy: 0.5128\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8223 - accuracy: 0.5593 - val_loss: 1.1717 - val_accuracy: 0.4530\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8199 - accuracy: 0.5667 - val_loss: 1.1656 - val_accuracy: 0.4615\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8229 - accuracy: 0.5630 - val_loss: 1.1602 - val_accuracy: 0.4530\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8276 - accuracy: 0.5556 - val_loss: 1.1575 - val_accuracy: 0.5128\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8242 - accuracy: 0.5667 - val_loss: 1.1711 - val_accuracy: 0.4615\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8223 - accuracy: 0.5667 - val_loss: 1.1613 - val_accuracy: 0.4530\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8204 - accuracy: 0.5556 - val_loss: 1.1593 - val_accuracy: 0.5128\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8195 - accuracy: 0.5593 - val_loss: 1.1602 - val_accuracy: 0.4530\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8196 - accuracy: 0.5704 - val_loss: 1.1658 - val_accuracy: 0.4615\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8207 - accuracy: 0.5667 - val_loss: 1.1652 - val_accuracy: 0.4530\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8280 - accuracy: 0.5556 - val_loss: 1.1670 - val_accuracy: 0.5128\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8188 - accuracy: 0.5667 - val_loss: 1.1692 - val_accuracy: 0.4530\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8237 - accuracy: 0.5667 - val_loss: 1.1720 - val_accuracy: 0.4530\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8221 - accuracy: 0.5778 - val_loss: 1.1668 - val_accuracy: 0.5128\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8209 - accuracy: 0.5370 - val_loss: 1.1493 - val_accuracy: 0.5128\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8253 - accuracy: 0.5593 - val_loss: 1.1448 - val_accuracy: 0.4615\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 321us/step - loss: 0.8224 - accuracy: 0.5667 - val_loss: 1.1527 - val_accuracy: 0.4615\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.8215 - accuracy: 0.5667 - val_loss: 1.1548 - val_accuracy: 0.4615\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8204 - accuracy: 0.5593 - val_loss: 1.1550 - val_accuracy: 0.5214\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8193 - accuracy: 0.5370 - val_loss: 1.1581 - val_accuracy: 0.4615\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8208 - accuracy: 0.5519 - val_loss: 1.1595 - val_accuracy: 0.4530\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8200 - accuracy: 0.5667 - val_loss: 1.1663 - val_accuracy: 0.4615\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8215 - accuracy: 0.5667 - val_loss: 1.1676 - val_accuracy: 0.4615\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8212 - accuracy: 0.5667 - val_loss: 1.1710 - val_accuracy: 0.4615\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8226 - accuracy: 0.5296 - val_loss: 1.1645 - val_accuracy: 0.4530\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8232 - accuracy: 0.5593 - val_loss: 1.1639 - val_accuracy: 0.5128\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8229 - accuracy: 0.5333 - val_loss: 1.1620 - val_accuracy: 0.4530\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8228 - accuracy: 0.5630 - val_loss: 1.1656 - val_accuracy: 0.4615\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8214 - accuracy: 0.5667 - val_loss: 1.1652 - val_accuracy: 0.4615\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8192 - accuracy: 0.5481 - val_loss: 1.1661 - val_accuracy: 0.5128\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8221 - accuracy: 0.5630 - val_loss: 1.1688 - val_accuracy: 0.4615\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8183 - accuracy: 0.5519 - val_loss: 1.1657 - val_accuracy: 0.4530\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8257 - accuracy: 0.5667 - val_loss: 1.1671 - val_accuracy: 0.4530\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8218 - accuracy: 0.5593 - val_loss: 1.1699 - val_accuracy: 0.5128\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8215 - accuracy: 0.5593 - val_loss: 1.1683 - val_accuracy: 0.5128\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8202 - accuracy: 0.5741 - val_loss: 1.1689 - val_accuracy: 0.4615\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8205 - accuracy: 0.5667 - val_loss: 1.1646 - val_accuracy: 0.5128\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8189 - accuracy: 0.5593 - val_loss: 1.1692 - val_accuracy: 0.5128\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8203 - accuracy: 0.5407 - val_loss: 1.1718 - val_accuracy: 0.4615\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 570us/step - loss: 0.8215 - accuracy: 0.5667 - val_loss: 1.1701 - val_accuracy: 0.4530\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.8246 - accuracy: 0.5667 - val_loss: 1.1707 - val_accuracy: 0.4530\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8195 - accuracy: 0.5222 - val_loss: 1.1716 - val_accuracy: 0.5128\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.8216 - accuracy: 0.5593 - val_loss: 1.1706 - val_accuracy: 0.5128\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8239 - accuracy: 0.5185 - val_loss: 1.1793 - val_accuracy: 0.4615\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8201 - accuracy: 0.5667 - val_loss: 1.1736 - val_accuracy: 0.4530\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8193 - accuracy: 0.5667 - val_loss: 1.1726 - val_accuracy: 0.4530\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8204 - accuracy: 0.5926 - val_loss: 1.1749 - val_accuracy: 0.5128\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 479us/step - loss: 0.8223 - accuracy: 0.5704 - val_loss: 1.1732 - val_accuracy: 0.4530\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8205 - accuracy: 0.5667 - val_loss: 1.1785 - val_accuracy: 0.4615\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8191 - accuracy: 0.5630 - val_loss: 1.1771 - val_accuracy: 0.5128\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 55.63%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [5.1167310e-01, 3.1077550e-01, 1.7755142e-01],\n",
       "       [4.5383340e-02, 1.8924704e-01, 7.6536953e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [7.8565580e-02, 5.2625774e-03, 9.1617185e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [9.7123253e-01, 2.2602128e-02, 6.1653630e-03],\n",
       "       [4.4029397e-03, 1.4818345e-04, 9.9544890e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [1.5497790e-01, 2.3580870e-02, 8.2144123e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.2764690e-01, 5.6651635e-03, 6.6668790e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [8.0043715e-01, 1.8084738e-01, 1.8715518e-02],\n",
       "       [3.6757340e-02, 3.5374236e-01, 6.0950035e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.2764690e-01, 5.6651635e-03, 6.6668790e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [1.4193304e-01, 8.7311990e-03, 8.4933573e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.8500038e-01, 3.4911046e-03, 7.1150850e-01],\n",
       "       [2.5070460e-01, 1.9279501e-01, 5.5650040e-01],\n",
       "       [2.5070460e-01, 1.9279501e-01, 5.5650040e-01],\n",
       "       [8.7283563e-04, 3.3428954e-05, 9.9909380e-01],\n",
       "       [5.1167310e-01, 3.1077550e-01, 1.7755142e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6757340e-02, 3.5374236e-01, 6.0950035e-01],\n",
       "       [7.8565580e-02, 5.2625774e-03, 9.1617185e-01],\n",
       "       [9.6535316e-04, 1.9988595e-04, 9.9883480e-01],\n",
       "       [2.6425496e-01, 2.6797947e-01, 4.6776554e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [1.5497790e-01, 2.3580870e-02, 8.2144123e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [5.1167310e-01, 3.1077550e-01, 1.7755142e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [2.8500038e-01, 3.4911046e-03, 7.1150850e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [4.5271020e-01, 7.0579246e-02, 4.7671062e-01],\n",
       "       [8.0043715e-01, 1.8084738e-01, 1.8715518e-02],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.2764690e-01, 5.6651635e-03, 6.6668790e-01],\n",
       "       [4.5383340e-02, 1.8924704e-01, 7.6536953e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.5070460e-01, 1.9279501e-01, 5.5650040e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.4224446e-05, 1.3956051e-05, 9.9995184e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [4.5383340e-02, 1.8924704e-01, 7.6536953e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [4.5383340e-02, 1.8924704e-01, 7.6536953e-01],\n",
       "       [4.5383340e-02, 1.8924704e-01, 7.6536953e-01],\n",
       "       [2.8112056e-02, 8.2524460e-01, 1.4664334e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [7.7989950e-02, 3.0978726e-02, 8.9103130e-01],\n",
       "       [5.1167310e-01, 3.1077550e-01, 1.7755142e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [7.7989950e-02, 3.0978726e-02, 8.9103130e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [5.1167310e-01, 3.1077550e-01, 1.7755142e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [4.1709578e-04, 2.9624325e-05, 9.9955326e-01],\n",
       "       [2.5070460e-01, 1.9279501e-01, 5.5650040e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [2.0531367e-01, 4.8763870e-01, 3.0704760e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01],\n",
       "       [3.6394837e-01, 4.2775100e-01, 2.0830064e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6669953977646285"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6669953977646285"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa25     1\n",
       "1       CFBRSa07     0\n",
       "2         NRS247     0\n",
       "3          NY439     2\n",
       "4    CFBREBSa110     1\n",
       "..           ...   ...\n",
       "112       SR1129     0\n",
       "113       NRS172     0\n",
       "114       NRS205     2\n",
       "115        NY439     2\n",
       "116       NRS249     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    \n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 660us/step - loss: 1.3464 - accuracy: 0.3296 - val_loss: 1.2446 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 1.2268 - accuracy: 0.3852 - val_loss: 1.1529 - val_accuracy: 0.3761\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 1.1447 - accuracy: 0.4333 - val_loss: 1.1073 - val_accuracy: 0.3590\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 1.1070 - accuracy: 0.3444 - val_loss: 1.0897 - val_accuracy: 0.3504\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 1.0908 - accuracy: 0.3185 - val_loss: 1.0887 - val_accuracy: 0.3504\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0852 - accuracy: 0.4185 - val_loss: 1.0895 - val_accuracy: 0.3675\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0828 - accuracy: 0.4111 - val_loss: 1.0870 - val_accuracy: 0.3590\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0758 - accuracy: 0.4074 - val_loss: 1.0813 - val_accuracy: 0.4017\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.0702 - accuracy: 0.4667 - val_loss: 1.0763 - val_accuracy: 0.3932\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0652 - accuracy: 0.4741 - val_loss: 1.0710 - val_accuracy: 0.4274\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 1.0585 - accuracy: 0.4667 - val_loss: 1.0683 - val_accuracy: 0.4274\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 1.0541 - accuracy: 0.4852 - val_loss: 1.0660 - val_accuracy: 0.4530\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.0508 - accuracy: 0.4815 - val_loss: 1.0636 - val_accuracy: 0.4530\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 1.0460 - accuracy: 0.4778 - val_loss: 1.0613 - val_accuracy: 0.4530\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.0414 - accuracy: 0.4815 - val_loss: 1.0599 - val_accuracy: 0.4530\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0365 - accuracy: 0.5000 - val_loss: 1.0581 - val_accuracy: 0.4530\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 1.0333 - accuracy: 0.4778 - val_loss: 1.0570 - val_accuracy: 0.4530\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 1.0304 - accuracy: 0.4815 - val_loss: 1.0562 - val_accuracy: 0.4530\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0274 - accuracy: 0.4815 - val_loss: 1.0547 - val_accuracy: 0.4530\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 1.0237 - accuracy: 0.4778 - val_loss: 1.0519 - val_accuracy: 0.4530\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 1.0193 - accuracy: 0.4778 - val_loss: 1.0507 - val_accuracy: 0.4530\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0170 - accuracy: 0.4815 - val_loss: 1.0499 - val_accuracy: 0.4530\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0134 - accuracy: 0.4778 - val_loss: 1.0475 - val_accuracy: 0.4615\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 1.0094 - accuracy: 0.4926 - val_loss: 1.0459 - val_accuracy: 0.4701\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 1.0072 - accuracy: 0.5333 - val_loss: 1.0458 - val_accuracy: 0.4701\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.0045 - accuracy: 0.5333 - val_loss: 1.0446 - val_accuracy: 0.4701\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 1.0015 - accuracy: 0.5333 - val_loss: 1.0432 - val_accuracy: 0.4701\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9980 - accuracy: 0.5333 - val_loss: 1.0416 - val_accuracy: 0.4701\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9948 - accuracy: 0.5333 - val_loss: 1.0407 - val_accuracy: 0.4701\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9918 - accuracy: 0.5111 - val_loss: 1.0400 - val_accuracy: 0.4701\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9895 - accuracy: 0.5037 - val_loss: 1.0389 - val_accuracy: 0.4701\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9861 - accuracy: 0.5333 - val_loss: 1.0386 - val_accuracy: 0.4701\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9844 - accuracy: 0.5333 - val_loss: 1.0386 - val_accuracy: 0.4701\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9834 - accuracy: 0.5333 - val_loss: 1.0385 - val_accuracy: 0.4701\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9818 - accuracy: 0.5333 - val_loss: 1.0375 - val_accuracy: 0.4701\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9787 - accuracy: 0.5333 - val_loss: 1.0367 - val_accuracy: 0.4701\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9762 - accuracy: 0.5333 - val_loss: 1.0359 - val_accuracy: 0.4701\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9738 - accuracy: 0.5333 - val_loss: 1.0347 - val_accuracy: 0.4701\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9709 - accuracy: 0.5296 - val_loss: 1.0349 - val_accuracy: 0.4701\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9710 - accuracy: 0.5185 - val_loss: 1.0357 - val_accuracy: 0.4701\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9691 - accuracy: 0.5074 - val_loss: 1.0332 - val_accuracy: 0.4701\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9649 - accuracy: 0.5074 - val_loss: 1.0340 - val_accuracy: 0.4615\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.9666 - accuracy: 0.5037 - val_loss: 1.0354 - val_accuracy: 0.4615\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9648 - accuracy: 0.5259 - val_loss: 1.0335 - val_accuracy: 0.4615\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9603 - accuracy: 0.5259 - val_loss: 1.0327 - val_accuracy: 0.4615\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.9624 - accuracy: 0.5296 - val_loss: 1.0339 - val_accuracy: 0.4701\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9596 - accuracy: 0.5296 - val_loss: 1.0328 - val_accuracy: 0.4701\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9571 - accuracy: 0.5259 - val_loss: 1.0328 - val_accuracy: 0.4701\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9554 - accuracy: 0.5259 - val_loss: 1.0326 - val_accuracy: 0.4615\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.9560 - accuracy: 0.4778 - val_loss: 1.0345 - val_accuracy: 0.4615\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9554 - accuracy: 0.5074 - val_loss: 1.0344 - val_accuracy: 0.4615\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9546 - accuracy: 0.5185 - val_loss: 1.0324 - val_accuracy: 0.4615\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9519 - accuracy: 0.5259 - val_loss: 1.0323 - val_accuracy: 0.4701\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9507 - accuracy: 0.4926 - val_loss: 1.0330 - val_accuracy: 0.4701\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9532 - accuracy: 0.5259 - val_loss: 1.0347 - val_accuracy: 0.4701\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9511 - accuracy: 0.5259 - val_loss: 1.0334 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9483 - accuracy: 0.5259 - val_loss: 1.0335 - val_accuracy: 0.4530\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9492 - accuracy: 0.5407 - val_loss: 1.0362 - val_accuracy: 0.4530\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9478 - accuracy: 0.5407 - val_loss: 1.0353 - val_accuracy: 0.4530\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9452 - accuracy: 0.5407 - val_loss: 1.0338 - val_accuracy: 0.4615\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9445 - accuracy: 0.5259 - val_loss: 1.0352 - val_accuracy: 0.4701\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9475 - accuracy: 0.5259 - val_loss: 1.0360 - val_accuracy: 0.4701\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9451 - accuracy: 0.5259 - val_loss: 1.0342 - val_accuracy: 0.4615\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9426 - accuracy: 0.5333 - val_loss: 1.0359 - val_accuracy: 0.4530\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9439 - accuracy: 0.5407 - val_loss: 1.0367 - val_accuracy: 0.4530\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9448 - accuracy: 0.5407 - val_loss: 1.0351 - val_accuracy: 0.4530\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9419 - accuracy: 0.5444 - val_loss: 1.0339 - val_accuracy: 0.4615\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9412 - accuracy: 0.5407 - val_loss: 1.0335 - val_accuracy: 0.4701\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9407 - accuracy: 0.5407 - val_loss: 1.0334 - val_accuracy: 0.4615\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9417 - accuracy: 0.5407 - val_loss: 1.0337 - val_accuracy: 0.4530\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9389 - accuracy: 0.5444 - val_loss: 1.0330 - val_accuracy: 0.4530\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9395 - accuracy: 0.5519 - val_loss: 1.0336 - val_accuracy: 0.4615\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9397 - accuracy: 0.5444 - val_loss: 1.0341 - val_accuracy: 0.4615\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9374 - accuracy: 0.5519 - val_loss: 1.0340 - val_accuracy: 0.4530\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9361 - accuracy: 0.5444 - val_loss: 1.0354 - val_accuracy: 0.4530\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9383 - accuracy: 0.5481 - val_loss: 1.0383 - val_accuracy: 0.4530\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9395 - accuracy: 0.5481 - val_loss: 1.0371 - val_accuracy: 0.4530\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9365 - accuracy: 0.5481 - val_loss: 1.0359 - val_accuracy: 0.4530\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9356 - accuracy: 0.5481 - val_loss: 1.0353 - val_accuracy: 0.4530\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9354 - accuracy: 0.5519 - val_loss: 1.0363 - val_accuracy: 0.4615\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9354 - accuracy: 0.5556 - val_loss: 1.0373 - val_accuracy: 0.4615\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 353us/step - loss: 0.9349 - accuracy: 0.5593 - val_loss: 1.0361 - val_accuracy: 0.4530\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9329 - accuracy: 0.5556 - val_loss: 1.0370 - val_accuracy: 0.4530\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.9329 - accuracy: 0.5296 - val_loss: 1.0390 - val_accuracy: 0.4530\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9333 - accuracy: 0.5333 - val_loss: 1.0370 - val_accuracy: 0.4530\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9315 - accuracy: 0.5519 - val_loss: 1.0361 - val_accuracy: 0.4530\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9318 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.4615\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9326 - accuracy: 0.5556 - val_loss: 1.0374 - val_accuracy: 0.4615\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9318 - accuracy: 0.5556 - val_loss: 1.0363 - val_accuracy: 0.4530\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9300 - accuracy: 0.5556 - val_loss: 1.0365 - val_accuracy: 0.4530\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9298 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.4530\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9289 - accuracy: 0.5519 - val_loss: 1.0381 - val_accuracy: 0.4530\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9286 - accuracy: 0.5519 - val_loss: 1.0382 - val_accuracy: 0.4530\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9289 - accuracy: 0.5519 - val_loss: 1.0392 - val_accuracy: 0.4530\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9280 - accuracy: 0.5519 - val_loss: 1.0386 - val_accuracy: 0.4530\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9277 - accuracy: 0.5556 - val_loss: 1.0400 - val_accuracy: 0.4615\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9289 - accuracy: 0.5556 - val_loss: 1.0415 - val_accuracy: 0.4615\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9282 - accuracy: 0.5556 - val_loss: 1.0407 - val_accuracy: 0.4530\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9270 - accuracy: 0.5556 - val_loss: 1.0412 - val_accuracy: 0.4530\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9274 - accuracy: 0.5519 - val_loss: 1.0431 - val_accuracy: 0.4530\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9274 - accuracy: 0.5519 - val_loss: 1.0429 - val_accuracy: 0.4530\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9265 - accuracy: 0.5519 - val_loss: 1.0426 - val_accuracy: 0.4530\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9247 - accuracy: 0.5519 - val_loss: 1.0412 - val_accuracy: 0.4530\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9241 - accuracy: 0.5556 - val_loss: 1.0413 - val_accuracy: 0.4615\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9259 - accuracy: 0.5556 - val_loss: 1.0421 - val_accuracy: 0.4615\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9241 - accuracy: 0.5556 - val_loss: 1.0416 - val_accuracy: 0.4444\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9235 - accuracy: 0.5519 - val_loss: 1.0432 - val_accuracy: 0.4444\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9236 - accuracy: 0.5519 - val_loss: 1.0433 - val_accuracy: 0.4444\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9234 - accuracy: 0.5519 - val_loss: 1.0439 - val_accuracy: 0.4444\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9238 - accuracy: 0.5296 - val_loss: 1.0450 - val_accuracy: 0.4530\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9242 - accuracy: 0.5333 - val_loss: 1.0445 - val_accuracy: 0.4530\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9234 - accuracy: 0.5519 - val_loss: 1.0437 - val_accuracy: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9246 - accuracy: 0.5556 - val_loss: 1.0435 - val_accuracy: 0.4530\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9215 - accuracy: 0.5556 - val_loss: 1.0446 - val_accuracy: 0.4444\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9206 - accuracy: 0.5556 - val_loss: 1.0446 - val_accuracy: 0.4444\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9195 - accuracy: 0.5519 - val_loss: 1.0454 - val_accuracy: 0.4444\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9204 - accuracy: 0.5519 - val_loss: 1.0460 - val_accuracy: 0.4530\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9213 - accuracy: 0.5519 - val_loss: 1.0466 - val_accuracy: 0.4530\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.9208 - accuracy: 0.5519 - val_loss: 1.0454 - val_accuracy: 0.4530\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.9204 - accuracy: 0.5556 - val_loss: 1.0430 - val_accuracy: 0.4615\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9186 - accuracy: 0.5556 - val_loss: 1.0424 - val_accuracy: 0.4615\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9203 - accuracy: 0.5556 - val_loss: 1.0443 - val_accuracy: 0.4615\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9210 - accuracy: 0.5556 - val_loss: 1.0445 - val_accuracy: 0.4615\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9192 - accuracy: 0.5556 - val_loss: 1.0444 - val_accuracy: 0.4530\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9187 - accuracy: 0.5519 - val_loss: 1.0456 - val_accuracy: 0.4530\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9174 - accuracy: 0.5519 - val_loss: 1.0450 - val_accuracy: 0.4530\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9171 - accuracy: 0.5556 - val_loss: 1.0449 - val_accuracy: 0.4530\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9171 - accuracy: 0.5556 - val_loss: 1.0456 - val_accuracy: 0.4530\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9171 - accuracy: 0.5556 - val_loss: 1.0475 - val_accuracy: 0.4444\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9189 - accuracy: 0.5556 - val_loss: 1.0498 - val_accuracy: 0.4444\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9193 - accuracy: 0.5556 - val_loss: 1.0482 - val_accuracy: 0.4444\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9174 - accuracy: 0.5556 - val_loss: 1.0452 - val_accuracy: 0.4444\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9172 - accuracy: 0.5556 - val_loss: 1.0443 - val_accuracy: 0.4530\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9174 - accuracy: 0.5556 - val_loss: 1.0438 - val_accuracy: 0.4530\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9147 - accuracy: 0.5556 - val_loss: 1.0418 - val_accuracy: 0.4530\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9167 - accuracy: 0.5556 - val_loss: 1.0450 - val_accuracy: 0.4444\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9165 - accuracy: 0.5519 - val_loss: 1.0452 - val_accuracy: 0.4444\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9162 - accuracy: 0.5519 - val_loss: 1.0445 - val_accuracy: 0.4530\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9146 - accuracy: 0.5259 - val_loss: 1.0452 - val_accuracy: 0.4530\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9172 - accuracy: 0.5333 - val_loss: 1.0445 - val_accuracy: 0.4530\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9133 - accuracy: 0.5481 - val_loss: 1.0435 - val_accuracy: 0.4530\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9135 - accuracy: 0.5556 - val_loss: 1.0465 - val_accuracy: 0.4530\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9163 - accuracy: 0.5593 - val_loss: 1.0499 - val_accuracy: 0.4530\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9169 - accuracy: 0.5593 - val_loss: 1.0466 - val_accuracy: 0.4530\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9146 - accuracy: 0.5556 - val_loss: 1.0437 - val_accuracy: 0.4530\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9123 - accuracy: 0.5556 - val_loss: 1.0432 - val_accuracy: 0.4530\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9106 - accuracy: 0.5556 - val_loss: 1.0433 - val_accuracy: 0.4530\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9128 - accuracy: 0.5222 - val_loss: 1.0446 - val_accuracy: 0.4530\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9114 - accuracy: 0.5333 - val_loss: 1.0441 - val_accuracy: 0.4530\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9115 - accuracy: 0.5556 - val_loss: 1.0445 - val_accuracy: 0.4530\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9106 - accuracy: 0.5556 - val_loss: 1.0445 - val_accuracy: 0.4530\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9119 - accuracy: 0.5556 - val_loss: 1.0444 - val_accuracy: 0.4530\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9102 - accuracy: 0.5556 - val_loss: 1.0441 - val_accuracy: 0.4530\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.9098 - accuracy: 0.5556 - val_loss: 1.0431 - val_accuracy: 0.4530\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9103 - accuracy: 0.5556 - val_loss: 1.0430 - val_accuracy: 0.4530\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9089 - accuracy: 0.5556 - val_loss: 1.0431 - val_accuracy: 0.4530\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9085 - accuracy: 0.5556 - val_loss: 1.0429 - val_accuracy: 0.4530\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9078 - accuracy: 0.5556 - val_loss: 1.0423 - val_accuracy: 0.4530\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9085 - accuracy: 0.5593 - val_loss: 1.0424 - val_accuracy: 0.4530\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9078 - accuracy: 0.5593 - val_loss: 1.0413 - val_accuracy: 0.4530\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9079 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4530\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9080 - accuracy: 0.5407 - val_loss: 1.0411 - val_accuracy: 0.4530\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9066 - accuracy: 0.5593 - val_loss: 1.0400 - val_accuracy: 0.4530\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9059 - accuracy: 0.5593 - val_loss: 1.0400 - val_accuracy: 0.4530\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9058 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4530\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9059 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4530\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9067 - accuracy: 0.5593 - val_loss: 1.0431 - val_accuracy: 0.4530\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9064 - accuracy: 0.5593 - val_loss: 1.0421 - val_accuracy: 0.4530\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9062 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4530\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9034 - accuracy: 0.5667 - val_loss: 1.0411 - val_accuracy: 0.4530\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9025 - accuracy: 0.5667 - val_loss: 1.0431 - val_accuracy: 0.4530\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9052 - accuracy: 0.5593 - val_loss: 1.0446 - val_accuracy: 0.4530\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9059 - accuracy: 0.5593 - val_loss: 1.0457 - val_accuracy: 0.4530\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9037 - accuracy: 0.5593 - val_loss: 1.0456 - val_accuracy: 0.4530\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9022 - accuracy: 0.5667 - val_loss: 1.0465 - val_accuracy: 0.4530\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9021 - accuracy: 0.5593 - val_loss: 1.0481 - val_accuracy: 0.4530\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9028 - accuracy: 0.5481 - val_loss: 1.0495 - val_accuracy: 0.4530\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9031 - accuracy: 0.5481 - val_loss: 1.0498 - val_accuracy: 0.4530\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9030 - accuracy: 0.5481 - val_loss: 1.0502 - val_accuracy: 0.4530\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9025 - accuracy: 0.5481 - val_loss: 1.0478 - val_accuracy: 0.4530\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9011 - accuracy: 0.5667 - val_loss: 1.0485 - val_accuracy: 0.4530\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.9005 - accuracy: 0.5667 - val_loss: 1.0504 - val_accuracy: 0.4444\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9036 - accuracy: 0.5667 - val_loss: 1.0476 - val_accuracy: 0.4530\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8999 - accuracy: 0.5667 - val_loss: 1.0457 - val_accuracy: 0.4530\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.9003 - accuracy: 0.5556 - val_loss: 1.0481 - val_accuracy: 0.4530\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9002 - accuracy: 0.5370 - val_loss: 1.0478 - val_accuracy: 0.4530\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9001 - accuracy: 0.5667 - val_loss: 1.0470 - val_accuracy: 0.4530\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8988 - accuracy: 0.5667 - val_loss: 1.0475 - val_accuracy: 0.4530\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8986 - accuracy: 0.5667 - val_loss: 1.0488 - val_accuracy: 0.4530\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8990 - accuracy: 0.5667 - val_loss: 1.0497 - val_accuracy: 0.4530\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8983 - accuracy: 0.5519 - val_loss: 1.0485 - val_accuracy: 0.4530\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9019 - accuracy: 0.5667 - val_loss: 1.0507 - val_accuracy: 0.4530\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8994 - accuracy: 0.5630 - val_loss: 1.0496 - val_accuracy: 0.4530\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8994 - accuracy: 0.5630 - val_loss: 1.0508 - val_accuracy: 0.4530\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8981 - accuracy: 0.5630 - val_loss: 1.0508 - val_accuracy: 0.4530\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8969 - accuracy: 0.5667 - val_loss: 1.0512 - val_accuracy: 0.4530\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8957 - accuracy: 0.5667 - val_loss: 1.0516 - val_accuracy: 0.4530\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8959 - accuracy: 0.5667 - val_loss: 1.0527 - val_accuracy: 0.4530\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8969 - accuracy: 0.5667 - val_loss: 1.0520 - val_accuracy: 0.4530\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8952 - accuracy: 0.5667 - val_loss: 1.0526 - val_accuracy: 0.4530\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8951 - accuracy: 0.5667 - val_loss: 1.0518 - val_accuracy: 0.4530\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8953 - accuracy: 0.5667 - val_loss: 1.0535 - val_accuracy: 0.4530\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8977 - accuracy: 0.5667 - val_loss: 1.0513 - val_accuracy: 0.4530\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 256us/step - loss: 0.8955 - accuracy: 0.5667 - val_loss: 1.0500 - val_accuracy: 0.4530\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8948 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4530\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.8963 - accuracy: 0.5704 - val_loss: 1.0498 - val_accuracy: 0.4530\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8941 - accuracy: 0.5704 - val_loss: 1.0483 - val_accuracy: 0.4530\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8938 - accuracy: 0.5704 - val_loss: 1.0525 - val_accuracy: 0.4530\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8981 - accuracy: 0.5481 - val_loss: 1.0531 - val_accuracy: 0.4530\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8998 - accuracy: 0.5667 - val_loss: 1.0483 - val_accuracy: 0.4530\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.8951 - accuracy: 0.5667 - val_loss: 1.0439 - val_accuracy: 0.4530\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8978 - accuracy: 0.5704 - val_loss: 1.0447 - val_accuracy: 0.4530\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8977 - accuracy: 0.5741 - val_loss: 1.0445 - val_accuracy: 0.4444\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8961 - accuracy: 0.5704 - val_loss: 1.0427 - val_accuracy: 0.4530\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8932 - accuracy: 0.5704 - val_loss: 1.0420 - val_accuracy: 0.4530\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8925 - accuracy: 0.5704 - val_loss: 1.0450 - val_accuracy: 0.4530\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8922 - accuracy: 0.5667 - val_loss: 1.0462 - val_accuracy: 0.4530\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8931 - accuracy: 0.5667 - val_loss: 1.0486 - val_accuracy: 0.4444\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8947 - accuracy: 0.5704 - val_loss: 1.0508 - val_accuracy: 0.4444\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8956 - accuracy: 0.5704 - val_loss: 1.0466 - val_accuracy: 0.4444\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8896 - accuracy: 0.5704 - val_loss: 1.0450 - val_accuracy: 0.4530\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8925 - accuracy: 0.5704 - val_loss: 1.0496 - val_accuracy: 0.4530\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8926 - accuracy: 0.5667 - val_loss: 1.0483 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8911 - accuracy: 0.5667 - val_loss: 1.0477 - val_accuracy: 0.4530\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8894 - accuracy: 0.5704 - val_loss: 1.0480 - val_accuracy: 0.4530\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8892 - accuracy: 0.5667 - val_loss: 1.0480 - val_accuracy: 0.4530\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8891 - accuracy: 0.5667 - val_loss: 1.0487 - val_accuracy: 0.4530\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8888 - accuracy: 0.5667 - val_loss: 1.0496 - val_accuracy: 0.4530\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8887 - accuracy: 0.5667 - val_loss: 1.0524 - val_accuracy: 0.4530\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8912 - accuracy: 0.5667 - val_loss: 1.0542 - val_accuracy: 0.4530\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8899 - accuracy: 0.5667 - val_loss: 1.0523 - val_accuracy: 0.4530\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8896 - accuracy: 0.5704 - val_loss: 1.0519 - val_accuracy: 0.4530\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8874 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4530\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8871 - accuracy: 0.5704 - val_loss: 1.0506 - val_accuracy: 0.4530\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8887 - accuracy: 0.5593 - val_loss: 1.0514 - val_accuracy: 0.4530\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8878 - accuracy: 0.5704 - val_loss: 1.0521 - val_accuracy: 0.4530\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8862 - accuracy: 0.5704 - val_loss: 1.0526 - val_accuracy: 0.4444\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8860 - accuracy: 0.5704 - val_loss: 1.0531 - val_accuracy: 0.4444\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8874 - accuracy: 0.5667 - val_loss: 1.0540 - val_accuracy: 0.4444\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8870 - accuracy: 0.5630 - val_loss: 1.0540 - val_accuracy: 0.4530\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8853 - accuracy: 0.5667 - val_loss: 1.0530 - val_accuracy: 0.4530\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8859 - accuracy: 0.5667 - val_loss: 1.0538 - val_accuracy: 0.4444\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8872 - accuracy: 0.5704 - val_loss: 1.0535 - val_accuracy: 0.4530\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8853 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.4530\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8846 - accuracy: 0.5704 - val_loss: 1.0555 - val_accuracy: 0.4530\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8852 - accuracy: 0.5667 - val_loss: 1.0553 - val_accuracy: 0.4530\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8841 - accuracy: 0.5667 - val_loss: 1.0550 - val_accuracy: 0.4530\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8843 - accuracy: 0.5667 - val_loss: 1.0553 - val_accuracy: 0.4530\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8849 - accuracy: 0.5667 - val_loss: 1.0548 - val_accuracy: 0.4444\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8849 - accuracy: 0.5704 - val_loss: 1.0537 - val_accuracy: 0.4530\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8839 - accuracy: 0.5889 - val_loss: 1.0543 - val_accuracy: 0.4530\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8863 - accuracy: 0.5519 - val_loss: 1.0546 - val_accuracy: 0.4530\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8847 - accuracy: 0.5519 - val_loss: 1.0522 - val_accuracy: 0.4530\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8824 - accuracy: 0.5704 - val_loss: 1.0517 - val_accuracy: 0.4530\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8831 - accuracy: 0.5741 - val_loss: 1.0527 - val_accuracy: 0.4530\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8835 - accuracy: 0.5741 - val_loss: 1.0524 - val_accuracy: 0.4530\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8825 - accuracy: 0.5667 - val_loss: 1.0525 - val_accuracy: 0.4530\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8827 - accuracy: 0.5667 - val_loss: 1.0539 - val_accuracy: 0.4530\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8834 - accuracy: 0.5630 - val_loss: 1.0555 - val_accuracy: 0.4530\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8827 - accuracy: 0.5519 - val_loss: 1.0546 - val_accuracy: 0.4530\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8819 - accuracy: 0.5704 - val_loss: 1.0538 - val_accuracy: 0.4530\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8808 - accuracy: 0.5704 - val_loss: 1.0544 - val_accuracy: 0.4530\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8810 - accuracy: 0.5704 - val_loss: 1.0543 - val_accuracy: 0.4530\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8803 - accuracy: 0.5704 - val_loss: 1.0555 - val_accuracy: 0.4444\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8831 - accuracy: 0.5741 - val_loss: 1.0583 - val_accuracy: 0.4444\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8840 - accuracy: 0.5741 - val_loss: 1.0543 - val_accuracy: 0.4444\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8822 - accuracy: 0.5630 - val_loss: 1.0560 - val_accuracy: 0.4530\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8814 - accuracy: 0.5333 - val_loss: 1.0550 - val_accuracy: 0.4530\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8801 - accuracy: 0.5667 - val_loss: 1.0558 - val_accuracy: 0.4530\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8837 - accuracy: 0.5667 - val_loss: 1.0566 - val_accuracy: 0.4444\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8820 - accuracy: 0.5704 - val_loss: 1.0539 - val_accuracy: 0.4444\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8795 - accuracy: 0.5667 - val_loss: 1.0547 - val_accuracy: 0.4530\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8797 - accuracy: 0.5667 - val_loss: 1.0554 - val_accuracy: 0.4530\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8802 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.4530\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8794 - accuracy: 0.5630 - val_loss: 1.0551 - val_accuracy: 0.4530\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8791 - accuracy: 0.5667 - val_loss: 1.0545 - val_accuracy: 0.4530\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8782 - accuracy: 0.5704 - val_loss: 1.0548 - val_accuracy: 0.4530\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8804 - accuracy: 0.5519 - val_loss: 1.0549 - val_accuracy: 0.4530\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8781 - accuracy: 0.5519 - val_loss: 1.0535 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8772 - accuracy: 0.5704 - val_loss: 1.0555 - val_accuracy: 0.4444\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8786 - accuracy: 0.5741 - val_loss: 1.0575 - val_accuracy: 0.4444\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8794 - accuracy: 0.5741 - val_loss: 1.0550 - val_accuracy: 0.4444\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8784 - accuracy: 0.5741 - val_loss: 1.0524 - val_accuracy: 0.4444\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8756 - accuracy: 0.5704 - val_loss: 1.0531 - val_accuracy: 0.4530\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8775 - accuracy: 0.5519 - val_loss: 1.0555 - val_accuracy: 0.4530\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8797 - accuracy: 0.5519 - val_loss: 1.0545 - val_accuracy: 0.4530\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8791 - accuracy: 0.5481 - val_loss: 1.0508 - val_accuracy: 0.4530\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8767 - accuracy: 0.5704 - val_loss: 1.0514 - val_accuracy: 0.4530\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8769 - accuracy: 0.5741 - val_loss: 1.0519 - val_accuracy: 0.4530\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8772 - accuracy: 0.5741 - val_loss: 1.0517 - val_accuracy: 0.4444\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8754 - accuracy: 0.5741 - val_loss: 1.0514 - val_accuracy: 0.4444\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8766 - accuracy: 0.5519 - val_loss: 1.0545 - val_accuracy: 0.4444\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8784 - accuracy: 0.5481 - val_loss: 1.0544 - val_accuracy: 0.4444\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8761 - accuracy: 0.5926 - val_loss: 1.0513 - val_accuracy: 0.4444\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8761 - accuracy: 0.5741 - val_loss: 1.0524 - val_accuracy: 0.4444\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8751 - accuracy: 0.5778 - val_loss: 1.0536 - val_accuracy: 0.4530\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8753 - accuracy: 0.5741 - val_loss: 1.0540 - val_accuracy: 0.4444\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8736 - accuracy: 0.5741 - val_loss: 1.0535 - val_accuracy: 0.4444\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8743 - accuracy: 0.5704 - val_loss: 1.0552 - val_accuracy: 0.4530\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8737 - accuracy: 0.5704 - val_loss: 1.0560 - val_accuracy: 0.4444\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8753 - accuracy: 0.5704 - val_loss: 1.0572 - val_accuracy: 0.4444\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8745 - accuracy: 0.5704 - val_loss: 1.0561 - val_accuracy: 0.4444\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8723 - accuracy: 0.5704 - val_loss: 1.0556 - val_accuracy: 0.4530\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8721 - accuracy: 0.5704 - val_loss: 1.0571 - val_accuracy: 0.4530\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8769 - accuracy: 0.5667 - val_loss: 1.0610 - val_accuracy: 0.4530\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8753 - accuracy: 0.5667 - val_loss: 1.0576 - val_accuracy: 0.4530\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8724 - accuracy: 0.5704 - val_loss: 1.0572 - val_accuracy: 0.4530\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8718 - accuracy: 0.5704 - val_loss: 1.0568 - val_accuracy: 0.4444\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8739 - accuracy: 0.5741 - val_loss: 1.0615 - val_accuracy: 0.4444\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8756 - accuracy: 0.5704 - val_loss: 1.0591 - val_accuracy: 0.4444\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8719 - accuracy: 0.5704 - val_loss: 1.0572 - val_accuracy: 0.4444\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8709 - accuracy: 0.5667 - val_loss: 1.0595 - val_accuracy: 0.4530\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8737 - accuracy: 0.5667 - val_loss: 1.0608 - val_accuracy: 0.4530\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8718 - accuracy: 0.5667 - val_loss: 1.0610 - val_accuracy: 0.4444\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8730 - accuracy: 0.5741 - val_loss: 1.0643 - val_accuracy: 0.4444\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8721 - accuracy: 0.5741 - val_loss: 1.0614 - val_accuracy: 0.4444\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8706 - accuracy: 0.5630 - val_loss: 1.0624 - val_accuracy: 0.4530\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8717 - accuracy: 0.5704 - val_loss: 1.0623 - val_accuracy: 0.4530\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8723 - accuracy: 0.5667 - val_loss: 1.0625 - val_accuracy: 0.4530\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8705 - accuracy: 0.5704 - val_loss: 1.0616 - val_accuracy: 0.4444\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8708 - accuracy: 0.5741 - val_loss: 1.0615 - val_accuracy: 0.4444\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8704 - accuracy: 0.5741 - val_loss: 1.0593 - val_accuracy: 0.4444\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8692 - accuracy: 0.5778 - val_loss: 1.0587 - val_accuracy: 0.4530\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8714 - accuracy: 0.5519 - val_loss: 1.0590 - val_accuracy: 0.4530\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8693 - accuracy: 0.5481 - val_loss: 1.0568 - val_accuracy: 0.4530\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0575 - val_accuracy: 0.4444\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8696 - accuracy: 0.5741 - val_loss: 1.0592 - val_accuracy: 0.4444\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8708 - accuracy: 0.5741 - val_loss: 1.0602 - val_accuracy: 0.4444\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8700 - accuracy: 0.5741 - val_loss: 1.0596 - val_accuracy: 0.4444\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8689 - accuracy: 0.5741 - val_loss: 1.0603 - val_accuracy: 0.4444\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8694 - accuracy: 0.5741 - val_loss: 1.0609 - val_accuracy: 0.4444\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8694 - accuracy: 0.5741 - val_loss: 1.0593 - val_accuracy: 0.4444\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8703 - accuracy: 0.5704 - val_loss: 1.0598 - val_accuracy: 0.4530\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8699 - accuracy: 0.5407 - val_loss: 1.0604 - val_accuracy: 0.4530\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8696 - accuracy: 0.5519 - val_loss: 1.0591 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8708 - accuracy: 0.5519 - val_loss: 1.0599 - val_accuracy: 0.4530\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8703 - accuracy: 0.5259 - val_loss: 1.0576 - val_accuracy: 0.4444\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8680 - accuracy: 0.5741 - val_loss: 1.0583 - val_accuracy: 0.4444\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8682 - accuracy: 0.5741 - val_loss: 1.0578 - val_accuracy: 0.4444\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8683 - accuracy: 0.5741 - val_loss: 1.0560 - val_accuracy: 0.4444\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8665 - accuracy: 0.5741 - val_loss: 1.0567 - val_accuracy: 0.4530\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0592 - val_accuracy: 0.4530\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8687 - accuracy: 0.5704 - val_loss: 1.0564 - val_accuracy: 0.4530\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8673 - accuracy: 0.5667 - val_loss: 1.0566 - val_accuracy: 0.4444\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8654 - accuracy: 0.5741 - val_loss: 1.0564 - val_accuracy: 0.4444\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8648 - accuracy: 0.5667 - val_loss: 1.0571 - val_accuracy: 0.4444\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8657 - accuracy: 0.5444 - val_loss: 1.0585 - val_accuracy: 0.4444\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8658 - accuracy: 0.5667 - val_loss: 1.0585 - val_accuracy: 0.4444\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8650 - accuracy: 0.5667 - val_loss: 1.0571 - val_accuracy: 0.4444\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8665 - accuracy: 0.5741 - val_loss: 1.0580 - val_accuracy: 0.4444\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0587 - val_accuracy: 0.4444\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0583 - val_accuracy: 0.4444\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8638 - accuracy: 0.5704 - val_loss: 1.0595 - val_accuracy: 0.4444\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4444\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8673 - accuracy: 0.5519 - val_loss: 1.0640 - val_accuracy: 0.4444\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8664 - accuracy: 0.5519 - val_loss: 1.0619 - val_accuracy: 0.4444\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8654 - accuracy: 0.5556 - val_loss: 1.0614 - val_accuracy: 0.4444\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8651 - accuracy: 0.5704 - val_loss: 1.0643 - val_accuracy: 0.4444\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0636 - val_accuracy: 0.4444\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0626 - val_accuracy: 0.4444\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8621 - accuracy: 0.5704 - val_loss: 1.0617 - val_accuracy: 0.4444\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8631 - accuracy: 0.5481 - val_loss: 1.0622 - val_accuracy: 0.4444\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8641 - accuracy: 0.5630 - val_loss: 1.0626 - val_accuracy: 0.4444\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0614 - val_accuracy: 0.4444\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0601 - val_accuracy: 0.4444\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8628 - accuracy: 0.5741 - val_loss: 1.0616 - val_accuracy: 0.4444\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8638 - accuracy: 0.5741 - val_loss: 1.0611 - val_accuracy: 0.4444\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8628 - accuracy: 0.5741 - val_loss: 1.0609 - val_accuracy: 0.4444\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8624 - accuracy: 0.5741 - val_loss: 1.0615 - val_accuracy: 0.4444\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8615 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4444\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4444\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8610 - accuracy: 0.5704 - val_loss: 1.0598 - val_accuracy: 0.4444\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.4444\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0602 - val_accuracy: 0.4444\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8624 - accuracy: 0.5741 - val_loss: 1.0606 - val_accuracy: 0.4444\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8633 - accuracy: 0.5741 - val_loss: 1.0598 - val_accuracy: 0.4444\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8616 - accuracy: 0.5741 - val_loss: 1.0602 - val_accuracy: 0.4444\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0613 - val_accuracy: 0.4444\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0612 - val_accuracy: 0.4444\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8608 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4444\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8623 - accuracy: 0.5741 - val_loss: 1.0627 - val_accuracy: 0.4444\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8608 - accuracy: 0.5741 - val_loss: 1.0606 - val_accuracy: 0.4444\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8596 - accuracy: 0.5741 - val_loss: 1.0601 - val_accuracy: 0.4444\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8602 - accuracy: 0.5481 - val_loss: 1.0622 - val_accuracy: 0.4444\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8596 - accuracy: 0.5370 - val_loss: 1.0606 - val_accuracy: 0.4444\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8589 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4444\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8595 - accuracy: 0.5741 - val_loss: 1.0607 - val_accuracy: 0.4444\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8580 - accuracy: 0.5741 - val_loss: 1.0612 - val_accuracy: 0.4444\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8585 - accuracy: 0.5741 - val_loss: 1.0607 - val_accuracy: 0.4444\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8592 - accuracy: 0.5296 - val_loss: 1.0614 - val_accuracy: 0.4444\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8589 - accuracy: 0.5370 - val_loss: 1.0631 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0630 - val_accuracy: 0.4444\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8576 - accuracy: 0.5704 - val_loss: 1.0640 - val_accuracy: 0.4444\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8566 - accuracy: 0.5704 - val_loss: 1.0630 - val_accuracy: 0.4444\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8572 - accuracy: 0.5741 - val_loss: 1.0628 - val_accuracy: 0.4444\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8620 - accuracy: 0.5778 - val_loss: 1.0653 - val_accuracy: 0.4444\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8589 - accuracy: 0.5778 - val_loss: 1.0637 - val_accuracy: 0.4444\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8562 - accuracy: 0.5741 - val_loss: 1.0643 - val_accuracy: 0.4444\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8567 - accuracy: 0.5741 - val_loss: 1.0651 - val_accuracy: 0.4444\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8579 - accuracy: 0.5741 - val_loss: 1.0659 - val_accuracy: 0.4444\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8586 - accuracy: 0.5667 - val_loss: 1.0649 - val_accuracy: 0.4444\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8559 - accuracy: 0.5741 - val_loss: 1.0636 - val_accuracy: 0.4444\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8568 - accuracy: 0.5704 - val_loss: 1.0646 - val_accuracy: 0.4444\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8570 - accuracy: 0.5704 - val_loss: 1.0647 - val_accuracy: 0.4444\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8565 - accuracy: 0.5741 - val_loss: 1.0648 - val_accuracy: 0.4444\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8564 - accuracy: 0.5741 - val_loss: 1.0648 - val_accuracy: 0.4444\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8573 - accuracy: 0.5778 - val_loss: 1.0648 - val_accuracy: 0.4444\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8569 - accuracy: 0.5741 - val_loss: 1.0654 - val_accuracy: 0.4444\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8573 - accuracy: 0.5741 - val_loss: 1.0658 - val_accuracy: 0.4444\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8563 - accuracy: 0.5778 - val_loss: 1.0658 - val_accuracy: 0.4444\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8563 - accuracy: 0.5519 - val_loss: 1.0671 - val_accuracy: 0.4444\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8577 - accuracy: 0.5519 - val_loss: 1.0667 - val_accuracy: 0.4530\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8551 - accuracy: 0.5741 - val_loss: 1.0654 - val_accuracy: 0.4444\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8530 - accuracy: 0.5741 - val_loss: 1.0671 - val_accuracy: 0.4444\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8569 - accuracy: 0.5741 - val_loss: 1.0703 - val_accuracy: 0.4444\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8583 - accuracy: 0.5741 - val_loss: 1.0700 - val_accuracy: 0.4444\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8568 - accuracy: 0.5741 - val_loss: 1.0691 - val_accuracy: 0.4444\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8560 - accuracy: 0.5741 - val_loss: 1.0699 - val_accuracy: 0.4444\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8570 - accuracy: 0.5556 - val_loss: 1.0706 - val_accuracy: 0.4444\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8527 - accuracy: 0.5778 - val_loss: 1.0684 - val_accuracy: 0.4444\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8609 - accuracy: 0.5778 - val_loss: 1.0765 - val_accuracy: 0.4444\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8650 - accuracy: 0.5778 - val_loss: 1.0718 - val_accuracy: 0.4444\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8576 - accuracy: 0.5778 - val_loss: 1.0663 - val_accuracy: 0.4444\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8529 - accuracy: 0.5778 - val_loss: 1.0682 - val_accuracy: 0.4444\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8566 - accuracy: 0.5556 - val_loss: 1.0711 - val_accuracy: 0.4444\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8574 - accuracy: 0.5407 - val_loss: 1.0684 - val_accuracy: 0.4444\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8540 - accuracy: 0.5556 - val_loss: 1.0673 - val_accuracy: 0.4444\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8529 - accuracy: 0.6037 - val_loss: 1.0685 - val_accuracy: 0.4444\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8549 - accuracy: 0.5741 - val_loss: 1.0704 - val_accuracy: 0.4444\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8566 - accuracy: 0.5741 - val_loss: 1.0700 - val_accuracy: 0.4444\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8538 - accuracy: 0.5778 - val_loss: 1.0662 - val_accuracy: 0.4444\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8540 - accuracy: 0.5481 - val_loss: 1.0685 - val_accuracy: 0.4444\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8548 - accuracy: 0.5556 - val_loss: 1.0684 - val_accuracy: 0.4444\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8534 - accuracy: 0.5444 - val_loss: 1.0670 - val_accuracy: 0.4444\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8524 - accuracy: 0.5778 - val_loss: 1.0677 - val_accuracy: 0.4444\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8520 - accuracy: 0.5778 - val_loss: 1.0675 - val_accuracy: 0.4444\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8514 - accuracy: 0.5778 - val_loss: 1.0675 - val_accuracy: 0.4444\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8514 - accuracy: 0.5778 - val_loss: 1.0710 - val_accuracy: 0.4444\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8532 - accuracy: 0.5778 - val_loss: 1.0709 - val_accuracy: 0.4444\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8514 - accuracy: 0.5815 - val_loss: 1.0695 - val_accuracy: 0.4444\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8522 - accuracy: 0.5815 - val_loss: 1.0738 - val_accuracy: 0.4444\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8572 - accuracy: 0.5741 - val_loss: 1.0726 - val_accuracy: 0.4444\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8525 - accuracy: 0.5815 - val_loss: 1.0699 - val_accuracy: 0.4444\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8501 - accuracy: 0.5778 - val_loss: 1.0720 - val_accuracy: 0.4444\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8529 - accuracy: 0.5778 - val_loss: 1.0742 - val_accuracy: 0.4444\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8537 - accuracy: 0.5778 - val_loss: 1.0717 - val_accuracy: 0.4444\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8503 - accuracy: 0.5741 - val_loss: 1.0694 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8504 - accuracy: 0.5778 - val_loss: 1.0689 - val_accuracy: 0.4444\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8502 - accuracy: 0.5815 - val_loss: 1.0688 - val_accuracy: 0.4444\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8509 - accuracy: 0.5815 - val_loss: 1.0715 - val_accuracy: 0.4444\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8516 - accuracy: 0.5815 - val_loss: 1.0710 - val_accuracy: 0.4444\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8501 - accuracy: 0.5778 - val_loss: 1.0715 - val_accuracy: 0.4444\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8494 - accuracy: 0.5778 - val_loss: 1.0719 - val_accuracy: 0.4444\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8504 - accuracy: 0.5778 - val_loss: 1.0720 - val_accuracy: 0.4444\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8497 - accuracy: 0.5815 - val_loss: 1.0715 - val_accuracy: 0.4444\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8499 - accuracy: 0.5778 - val_loss: 1.0713 - val_accuracy: 0.4444\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8512 - accuracy: 0.5778 - val_loss: 1.0708 - val_accuracy: 0.4444\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8485 - accuracy: 0.5815 - val_loss: 1.0716 - val_accuracy: 0.4444\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8492 - accuracy: 0.5815 - val_loss: 1.0699 - val_accuracy: 0.4444\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8479 - accuracy: 0.5815 - val_loss: 1.0694 - val_accuracy: 0.4444\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8479 - accuracy: 0.5778 - val_loss: 1.0680 - val_accuracy: 0.4444\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8481 - accuracy: 0.5741 - val_loss: 1.0667 - val_accuracy: 0.4444\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8484 - accuracy: 0.5778 - val_loss: 1.0654 - val_accuracy: 0.4444\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8491 - accuracy: 0.5778 - val_loss: 1.0650 - val_accuracy: 0.4444\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8483 - accuracy: 0.5778 - val_loss: 1.0643 - val_accuracy: 0.4444\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8510 - accuracy: 0.5815 - val_loss: 1.0649 - val_accuracy: 0.4444\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8482 - accuracy: 0.5815 - val_loss: 1.0647 - val_accuracy: 0.4444\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8472 - accuracy: 0.5926 - val_loss: 1.0676 - val_accuracy: 0.4444\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8487 - accuracy: 0.5519 - val_loss: 1.0685 - val_accuracy: 0.4530\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0667 - val_accuracy: 0.4530\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8496 - accuracy: 0.5630 - val_loss: 1.0651 - val_accuracy: 0.4444\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.8472 - accuracy: 0.5815 - val_loss: 1.0642 - val_accuracy: 0.4444\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8464 - accuracy: 0.5815 - val_loss: 1.0658 - val_accuracy: 0.4444\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8476 - accuracy: 0.5815 - val_loss: 1.0660 - val_accuracy: 0.4444\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0676 - val_accuracy: 0.4444\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 32us/step - loss: 0.8462 - accuracy: 0.5852 - val_loss: 1.0695 - val_accuracy: 0.4530\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 32us/step - loss: 0.8489 - accuracy: 0.5852 - val_loss: 1.0675 - val_accuracy: 0.4444\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 30us/step - loss: 0.8458 - accuracy: 0.5815 - val_loss: 1.0670 - val_accuracy: 0.4444\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.8457 - accuracy: 0.5815 - val_loss: 1.0704 - val_accuracy: 0.4530\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 31us/step - loss: 0.8484 - accuracy: 0.5815 - val_loss: 1.0706 - val_accuracy: 0.4444\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 30us/step - loss: 0.8470 - accuracy: 0.5778 - val_loss: 1.0700 - val_accuracy: 0.4444\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 29us/step - loss: 0.8466 - accuracy: 0.5815 - val_loss: 1.0712 - val_accuracy: 0.4530\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 31us/step - loss: 0.8460 - accuracy: 0.5852 - val_loss: 1.0698 - val_accuracy: 0.4444\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 30us/step - loss: 0.8461 - accuracy: 0.5815 - val_loss: 1.0697 - val_accuracy: 0.4444\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 31us/step - loss: 0.8465 - accuracy: 0.5815 - val_loss: 1.0707 - val_accuracy: 0.4530\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 30us/step - loss: 0.8463 - accuracy: 0.5852 - val_loss: 1.0716 - val_accuracy: 0.4530\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8467 - accuracy: 0.5852 - val_loss: 1.0708 - val_accuracy: 0.4530\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8447 - accuracy: 0.5815 - val_loss: 1.0708 - val_accuracy: 0.4444\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8463 - accuracy: 0.5593 - val_loss: 1.0735 - val_accuracy: 0.4530\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0725 - val_accuracy: 0.4444\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8453 - accuracy: 0.5741 - val_loss: 1.0728 - val_accuracy: 0.4530\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8447 - accuracy: 0.5815 - val_loss: 1.0721 - val_accuracy: 0.4444\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8447 - accuracy: 0.5815 - val_loss: 1.0725 - val_accuracy: 0.4444\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8453 - accuracy: 0.5852 - val_loss: 1.0739 - val_accuracy: 0.4530\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8442 - accuracy: 0.5852 - val_loss: 1.0727 - val_accuracy: 0.4530\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8465 - accuracy: 0.5852 - val_loss: 1.0725 - val_accuracy: 0.4530\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8432 - accuracy: 0.5852 - val_loss: 1.0726 - val_accuracy: 0.4530\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 516us/step - loss: 0.8438 - accuracy: 0.5815 - val_loss: 1.0754 - val_accuracy: 0.4530\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8450 - accuracy: 0.5630 - val_loss: 1.0774 - val_accuracy: 0.4444\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0771 - val_accuracy: 0.4444\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8450 - accuracy: 0.5593 - val_loss: 1.0774 - val_accuracy: 0.4530\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0765 - val_accuracy: 0.4530\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8423 - accuracy: 0.5741 - val_loss: 1.0762 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8444 - accuracy: 0.5852 - val_loss: 1.0795 - val_accuracy: 0.4444\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8488 - accuracy: 0.5852 - val_loss: 1.0788 - val_accuracy: 0.4530\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8465 - accuracy: 0.5852 - val_loss: 1.0779 - val_accuracy: 0.4444\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8429 - accuracy: 0.5815 - val_loss: 1.0798 - val_accuracy: 0.4530\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0811 - val_accuracy: 0.4530\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.8453 - accuracy: 0.5593 - val_loss: 1.0796 - val_accuracy: 0.4530\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8453 - accuracy: 0.6185 - val_loss: 1.0790 - val_accuracy: 0.4530\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8440 - accuracy: 0.5852 - val_loss: 1.0776 - val_accuracy: 0.4530\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8425 - accuracy: 0.5852 - val_loss: 1.0764 - val_accuracy: 0.4530\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8425 - accuracy: 0.5815 - val_loss: 1.0761 - val_accuracy: 0.4444\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8441 - accuracy: 0.5815 - val_loss: 1.0798 - val_accuracy: 0.4530\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8479 - accuracy: 0.5630 - val_loss: 1.0756 - val_accuracy: 0.4444\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8433 - accuracy: 0.5630 - val_loss: 1.0721 - val_accuracy: 0.4530\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.0712 - val_accuracy: 0.4530\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8421 - accuracy: 0.5852 - val_loss: 1.0707 - val_accuracy: 0.4530\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8436 - accuracy: 0.5852 - val_loss: 1.0720 - val_accuracy: 0.4530\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8422 - accuracy: 0.5852 - val_loss: 1.0715 - val_accuracy: 0.4530\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8407 - accuracy: 0.5815 - val_loss: 1.0759 - val_accuracy: 0.4444\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0794 - val_accuracy: 0.4530\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8449 - accuracy: 0.5667 - val_loss: 1.0729 - val_accuracy: 0.4530\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8431 - accuracy: 0.5852 - val_loss: 1.0745 - val_accuracy: 0.4530\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8437 - accuracy: 0.5852 - val_loss: 1.0762 - val_accuracy: 0.4530\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8436 - accuracy: 0.5852 - val_loss: 1.0776 - val_accuracy: 0.4530\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8435 - accuracy: 0.5852 - val_loss: 1.0757 - val_accuracy: 0.4530\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8414 - accuracy: 0.5852 - val_loss: 1.0760 - val_accuracy: 0.4530\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8436 - accuracy: 0.5852 - val_loss: 1.0745 - val_accuracy: 0.4530\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8398 - accuracy: 0.5852 - val_loss: 1.0743 - val_accuracy: 0.4530\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8419 - accuracy: 0.5852 - val_loss: 1.0774 - val_accuracy: 0.4530\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8439 - accuracy: 0.5852 - val_loss: 1.0753 - val_accuracy: 0.4530\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8401 - accuracy: 0.5852 - val_loss: 1.0739 - val_accuracy: 0.4530\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8397 - accuracy: 0.5852 - val_loss: 1.0748 - val_accuracy: 0.4530\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8406 - accuracy: 0.5444 - val_loss: 1.0750 - val_accuracy: 0.4530\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8404 - accuracy: 0.5704 - val_loss: 1.0721 - val_accuracy: 0.4530\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8402 - accuracy: 0.5852 - val_loss: 1.0721 - val_accuracy: 0.4530\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8435 - accuracy: 0.5852 - val_loss: 1.0719 - val_accuracy: 0.4530\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8426 - accuracy: 0.5852 - val_loss: 1.0732 - val_accuracy: 0.4530\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8409 - accuracy: 0.5852 - val_loss: 1.0740 - val_accuracy: 0.4530\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8393 - accuracy: 0.5852 - val_loss: 1.0727 - val_accuracy: 0.4530\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8387 - accuracy: 0.5852 - val_loss: 1.0741 - val_accuracy: 0.4530\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8384 - accuracy: 0.5852 - val_loss: 1.0778 - val_accuracy: 0.4530\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8398 - accuracy: 0.5852 - val_loss: 1.0781 - val_accuracy: 0.4530\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8407 - accuracy: 0.5852 - val_loss: 1.0757 - val_accuracy: 0.4530\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8384 - accuracy: 0.5852 - val_loss: 1.0739 - val_accuracy: 0.4530\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8384 - accuracy: 0.5704 - val_loss: 1.0768 - val_accuracy: 0.4615\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8413 - accuracy: 0.5593 - val_loss: 1.0756 - val_accuracy: 0.4530\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8384 - accuracy: 0.5519 - val_loss: 1.0724 - val_accuracy: 0.4530\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8398 - accuracy: 0.5852 - val_loss: 1.0731 - val_accuracy: 0.4530\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8397 - accuracy: 0.5852 - val_loss: 1.0718 - val_accuracy: 0.4530\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8380 - accuracy: 0.5852 - val_loss: 1.0712 - val_accuracy: 0.4530\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8376 - accuracy: 0.5815 - val_loss: 1.0719 - val_accuracy: 0.4530\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8391 - accuracy: 0.5667 - val_loss: 1.0721 - val_accuracy: 0.4530\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8384 - accuracy: 0.5704 - val_loss: 1.0703 - val_accuracy: 0.4530\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8379 - accuracy: 0.5852 - val_loss: 1.0718 - val_accuracy: 0.4530\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8379 - accuracy: 0.5852 - val_loss: 1.0716 - val_accuracy: 0.4530\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8358 - accuracy: 0.5852 - val_loss: 1.0722 - val_accuracy: 0.4530\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8420 - accuracy: 0.5852 - val_loss: 1.0756 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8422 - accuracy: 0.5852 - val_loss: 1.0727 - val_accuracy: 0.4530\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8403 - accuracy: 0.5852 - val_loss: 1.0709 - val_accuracy: 0.4530\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8364 - accuracy: 0.5852 - val_loss: 1.0714 - val_accuracy: 0.4530\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8382 - accuracy: 0.5852 - val_loss: 1.0710 - val_accuracy: 0.4530\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8351 - accuracy: 0.5852 - val_loss: 1.0728 - val_accuracy: 0.4530\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8391 - accuracy: 0.5667 - val_loss: 1.0768 - val_accuracy: 0.4530\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8399 - accuracy: 0.5630 - val_loss: 1.0773 - val_accuracy: 0.4530\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8381 - accuracy: 0.5667 - val_loss: 1.0751 - val_accuracy: 0.4530\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8383 - accuracy: 0.5667 - val_loss: 1.0735 - val_accuracy: 0.4530\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8373 - accuracy: 0.5852 - val_loss: 1.0742 - val_accuracy: 0.4530\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8374 - accuracy: 0.5852 - val_loss: 1.0755 - val_accuracy: 0.4530\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8391 - accuracy: 0.5741 - val_loss: 1.0815 - val_accuracy: 0.4530\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8405 - accuracy: 0.5630 - val_loss: 1.0828 - val_accuracy: 0.4530\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8383 - accuracy: 0.5667 - val_loss: 1.0810 - val_accuracy: 0.4530\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8369 - accuracy: 0.5704 - val_loss: 1.0799 - val_accuracy: 0.4530\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8357 - accuracy: 0.5852 - val_loss: 1.0797 - val_accuracy: 0.4530\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8353 - accuracy: 0.5852 - val_loss: 1.0789 - val_accuracy: 0.4530\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8380 - accuracy: 0.5852 - val_loss: 1.0792 - val_accuracy: 0.4530\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8364 - accuracy: 0.5852 - val_loss: 1.0793 - val_accuracy: 0.4530\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8369 - accuracy: 0.5778 - val_loss: 1.0805 - val_accuracy: 0.4530\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8356 - accuracy: 0.5556 - val_loss: 1.0796 - val_accuracy: 0.4530\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8341 - accuracy: 0.5852 - val_loss: 1.0789 - val_accuracy: 0.4530\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8367 - accuracy: 0.5852 - val_loss: 1.0822 - val_accuracy: 0.4444\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8405 - accuracy: 0.5815 - val_loss: 1.0805 - val_accuracy: 0.4530\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8376 - accuracy: 0.5852 - val_loss: 1.0769 - val_accuracy: 0.4530\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8358 - accuracy: 0.5852 - val_loss: 1.0783 - val_accuracy: 0.4530\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8351 - accuracy: 0.5852 - val_loss: 1.0788 - val_accuracy: 0.4530\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8349 - accuracy: 0.5852 - val_loss: 1.0786 - val_accuracy: 0.4530\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8352 - accuracy: 0.5852 - val_loss: 1.0798 - val_accuracy: 0.4530\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8352 - accuracy: 0.5852 - val_loss: 1.0793 - val_accuracy: 0.4530\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8356 - accuracy: 0.5852 - val_loss: 1.0798 - val_accuracy: 0.4530\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8378 - accuracy: 0.5704 - val_loss: 1.0828 - val_accuracy: 0.4530\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 1.0783 - val_accuracy: 0.4530\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8339 - accuracy: 0.5852 - val_loss: 1.0774 - val_accuracy: 0.4530\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8350 - accuracy: 0.5852 - val_loss: 1.0764 - val_accuracy: 0.4530\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8343 - accuracy: 0.5852 - val_loss: 1.0749 - val_accuracy: 0.4530\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8328 - accuracy: 0.5852 - val_loss: 1.0742 - val_accuracy: 0.4530\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8341 - accuracy: 0.5852 - val_loss: 1.0733 - val_accuracy: 0.4530\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8332 - accuracy: 0.5852 - val_loss: 1.0720 - val_accuracy: 0.4530\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8382 - accuracy: 0.5481 - val_loss: 1.0780 - val_accuracy: 0.4530\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8385 - accuracy: 0.5667 - val_loss: 1.0759 - val_accuracy: 0.4530\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8362 - accuracy: 0.5556 - val_loss: 1.0729 - val_accuracy: 0.4530\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8351 - accuracy: 0.5852 - val_loss: 1.0734 - val_accuracy: 0.4530\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8341 - accuracy: 0.5852 - val_loss: 1.0704 - val_accuracy: 0.4530\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8352 - accuracy: 0.5852 - val_loss: 1.0704 - val_accuracy: 0.4530\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8334 - accuracy: 0.5852 - val_loss: 1.0720 - val_accuracy: 0.4530\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8340 - accuracy: 0.5852 - val_loss: 1.0732 - val_accuracy: 0.4530\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8328 - accuracy: 0.5852 - val_loss: 1.0745 - val_accuracy: 0.4530\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8321 - accuracy: 0.5852 - val_loss: 1.0755 - val_accuracy: 0.4530\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8351 - accuracy: 0.5852 - val_loss: 1.0766 - val_accuracy: 0.4530\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8349 - accuracy: 0.5852 - val_loss: 1.0777 - val_accuracy: 0.4530\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8335 - accuracy: 0.5852 - val_loss: 1.0785 - val_accuracy: 0.4530\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8322 - accuracy: 0.5852 - val_loss: 1.0800 - val_accuracy: 0.4530\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8330 - accuracy: 0.5852 - val_loss: 1.0805 - val_accuracy: 0.4530\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8311 - accuracy: 0.5852 - val_loss: 1.0801 - val_accuracy: 0.4530\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8328 - accuracy: 0.5852 - val_loss: 1.0799 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8343 - accuracy: 0.5852 - val_loss: 1.0777 - val_accuracy: 0.4530\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8333 - accuracy: 0.5852 - val_loss: 1.0776 - val_accuracy: 0.4530\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8330 - accuracy: 0.5852 - val_loss: 1.0767 - val_accuracy: 0.4530\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8319 - accuracy: 0.5852 - val_loss: 1.0775 - val_accuracy: 0.4530\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8303 - accuracy: 0.5852 - val_loss: 1.0803 - val_accuracy: 0.4530\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8324 - accuracy: 0.5741 - val_loss: 1.0845 - val_accuracy: 0.4530\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8346 - accuracy: 0.5667 - val_loss: 1.0836 - val_accuracy: 0.4530\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8328 - accuracy: 0.5667 - val_loss: 1.0779 - val_accuracy: 0.4530\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8330 - accuracy: 0.5852 - val_loss: 1.0767 - val_accuracy: 0.4530\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8352 - accuracy: 0.5852 - val_loss: 1.0773 - val_accuracy: 0.4530\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8333 - accuracy: 0.5852 - val_loss: 1.0787 - val_accuracy: 0.4530\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8349 - accuracy: 0.5852 - val_loss: 1.0752 - val_accuracy: 0.4530\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8357 - accuracy: 0.5519 - val_loss: 1.0758 - val_accuracy: 0.4615\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8335 - accuracy: 0.5852 - val_loss: 1.0759 - val_accuracy: 0.4615\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8339 - accuracy: 0.5852 - val_loss: 1.0776 - val_accuracy: 0.4530\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8341 - accuracy: 0.5852 - val_loss: 1.0761 - val_accuracy: 0.4530\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8324 - accuracy: 0.5852 - val_loss: 1.0752 - val_accuracy: 0.4530\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8316 - accuracy: 0.5852 - val_loss: 1.0770 - val_accuracy: 0.4530\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8306 - accuracy: 0.5852 - val_loss: 1.0792 - val_accuracy: 0.4530\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8310 - accuracy: 0.5852 - val_loss: 1.0806 - val_accuracy: 0.4530\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8301 - accuracy: 0.5852 - val_loss: 1.0826 - val_accuracy: 0.4530\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8312 - accuracy: 0.5852 - val_loss: 1.0836 - val_accuracy: 0.4530\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8330 - accuracy: 0.5852 - val_loss: 1.0820 - val_accuracy: 0.4530\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8302 - accuracy: 0.5852 - val_loss: 1.0803 - val_accuracy: 0.4530\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8305 - accuracy: 0.5852 - val_loss: 1.0795 - val_accuracy: 0.4530\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8322 - accuracy: 0.5815 - val_loss: 1.0804 - val_accuracy: 0.4615\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8312 - accuracy: 0.5889 - val_loss: 1.0785 - val_accuracy: 0.4530\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8311 - accuracy: 0.5852 - val_loss: 1.0778 - val_accuracy: 0.4530\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8302 - accuracy: 0.5852 - val_loss: 1.0768 - val_accuracy: 0.4530\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8305 - accuracy: 0.5852 - val_loss: 1.0759 - val_accuracy: 0.4530\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8288 - accuracy: 0.5852 - val_loss: 1.0755 - val_accuracy: 0.4530\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8298 - accuracy: 0.5852 - val_loss: 1.0752 - val_accuracy: 0.4530\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8303 - accuracy: 0.5852 - val_loss: 1.0757 - val_accuracy: 0.4530\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8309 - accuracy: 0.5852 - val_loss: 1.0775 - val_accuracy: 0.4530\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8284 - accuracy: 0.5852 - val_loss: 1.0782 - val_accuracy: 0.4530\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8297 - accuracy: 0.5852 - val_loss: 1.0778 - val_accuracy: 0.4530\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8288 - accuracy: 0.5852 - val_loss: 1.0790 - val_accuracy: 0.4530\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8293 - accuracy: 0.5852 - val_loss: 1.0771 - val_accuracy: 0.4530\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8292 - accuracy: 0.5852 - val_loss: 1.0769 - val_accuracy: 0.4530\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8303 - accuracy: 0.5259 - val_loss: 1.0753 - val_accuracy: 0.4530\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8297 - accuracy: 0.5556 - val_loss: 1.0761 - val_accuracy: 0.4530\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8305 - accuracy: 0.5667 - val_loss: 1.0761 - val_accuracy: 0.4530\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8304 - accuracy: 0.5778 - val_loss: 1.0748 - val_accuracy: 0.4530\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8292 - accuracy: 0.5852 - val_loss: 1.0769 - val_accuracy: 0.4530\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8325 - accuracy: 0.5852 - val_loss: 1.0806 - val_accuracy: 0.4530\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8321 - accuracy: 0.5852 - val_loss: 1.0795 - val_accuracy: 0.4530\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8297 - accuracy: 0.5852 - val_loss: 1.0793 - val_accuracy: 0.4530\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8286 - accuracy: 0.5852 - val_loss: 1.0807 - val_accuracy: 0.4530\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8314 - accuracy: 0.5852 - val_loss: 1.0853 - val_accuracy: 0.4530\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8329 - accuracy: 0.5852 - val_loss: 1.0823 - val_accuracy: 0.4530\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8291 - accuracy: 0.5852 - val_loss: 1.0810 - val_accuracy: 0.4530\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8300 - accuracy: 0.5852 - val_loss: 1.0817 - val_accuracy: 0.4530\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8304 - accuracy: 0.5778 - val_loss: 1.0838 - val_accuracy: 0.4530\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8309 - accuracy: 0.5222 - val_loss: 1.0822 - val_accuracy: 0.4530\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8287 - accuracy: 0.5852 - val_loss: 1.0843 - val_accuracy: 0.4530\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8296 - accuracy: 0.5852 - val_loss: 1.0832 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8340 - accuracy: 0.5852 - val_loss: 1.0839 - val_accuracy: 0.4530\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8292 - accuracy: 0.5852 - val_loss: 1.0837 - val_accuracy: 0.4530\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8301 - accuracy: 0.5852 - val_loss: 1.0861 - val_accuracy: 0.4530\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8309 - accuracy: 0.5667 - val_loss: 1.0873 - val_accuracy: 0.4530\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8311 - accuracy: 0.5852 - val_loss: 1.0836 - val_accuracy: 0.4530\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8286 - accuracy: 0.5852 - val_loss: 1.0835 - val_accuracy: 0.4530\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8271 - accuracy: 0.5852 - val_loss: 1.0867 - val_accuracy: 0.4530\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8292 - accuracy: 0.5889 - val_loss: 1.0890 - val_accuracy: 0.4530\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8308 - accuracy: 0.5667 - val_loss: 1.0901 - val_accuracy: 0.4530\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8301 - accuracy: 0.5667 - val_loss: 1.0841 - val_accuracy: 0.4530\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8263 - accuracy: 0.5852 - val_loss: 1.0818 - val_accuracy: 0.4530\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8274 - accuracy: 0.5852 - val_loss: 1.0813 - val_accuracy: 0.4530\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8286 - accuracy: 0.5852 - val_loss: 1.0808 - val_accuracy: 0.4530\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8274 - accuracy: 0.5852 - val_loss: 1.0803 - val_accuracy: 0.4530\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8295 - accuracy: 0.5852 - val_loss: 1.0802 - val_accuracy: 0.4530\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8273 - accuracy: 0.5852 - val_loss: 1.0783 - val_accuracy: 0.4530\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8269 - accuracy: 0.5852 - val_loss: 1.0771 - val_accuracy: 0.4530\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8294 - accuracy: 0.5704 - val_loss: 1.0774 - val_accuracy: 0.4530\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8276 - accuracy: 0.5741 - val_loss: 1.0775 - val_accuracy: 0.4530\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8281 - accuracy: 0.5852 - val_loss: 1.0786 - val_accuracy: 0.4530\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8270 - accuracy: 0.5852 - val_loss: 1.0788 - val_accuracy: 0.4530\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8271 - accuracy: 0.5852 - val_loss: 1.0814 - val_accuracy: 0.4530\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8315 - accuracy: 0.5667 - val_loss: 1.0861 - val_accuracy: 0.4530\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8289 - accuracy: 0.5593 - val_loss: 1.0819 - val_accuracy: 0.4530\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8267 - accuracy: 0.5852 - val_loss: 1.0823 - val_accuracy: 0.4530\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8259 - accuracy: 0.5852 - val_loss: 1.0840 - val_accuracy: 0.4530\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8272 - accuracy: 0.5852 - val_loss: 1.0845 - val_accuracy: 0.4530\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8271 - accuracy: 0.5852 - val_loss: 1.0828 - val_accuracy: 0.4530\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8265 - accuracy: 0.5852 - val_loss: 1.0817 - val_accuracy: 0.4530\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8286 - accuracy: 0.5556 - val_loss: 1.0821 - val_accuracy: 0.4530\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8258 - accuracy: 0.5926 - val_loss: 1.0788 - val_accuracy: 0.4530\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8287 - accuracy: 0.5852 - val_loss: 1.0798 - val_accuracy: 0.4530\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8329 - accuracy: 0.5852 - val_loss: 1.0801 - val_accuracy: 0.4530\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8279 - accuracy: 0.5852 - val_loss: 1.0795 - val_accuracy: 0.4530\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8262 - accuracy: 0.5852 - val_loss: 1.0823 - val_accuracy: 0.4530\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8258 - accuracy: 0.5852 - val_loss: 1.0843 - val_accuracy: 0.4530\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8248 - accuracy: 0.5704 - val_loss: 1.0849 - val_accuracy: 0.4530\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8248 - accuracy: 0.5519 - val_loss: 1.0851 - val_accuracy: 0.4530\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8278 - accuracy: 0.5852 - val_loss: 1.0878 - val_accuracy: 0.4530\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8312 - accuracy: 0.5852 - val_loss: 1.0851 - val_accuracy: 0.4530\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8285 - accuracy: 0.5852 - val_loss: 1.0801 - val_accuracy: 0.4530\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8245 - accuracy: 0.5741 - val_loss: 1.0809 - val_accuracy: 0.4530\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8252 - accuracy: 0.5704 - val_loss: 1.0809 - val_accuracy: 0.4530\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8257 - accuracy: 0.5852 - val_loss: 1.0799 - val_accuracy: 0.4530\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8258 - accuracy: 0.5852 - val_loss: 1.0795 - val_accuracy: 0.4530\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8285 - accuracy: 0.5852 - val_loss: 1.0815 - val_accuracy: 0.4444\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8266 - accuracy: 0.5630 - val_loss: 1.0801 - val_accuracy: 0.4615\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8243 - accuracy: 0.5852 - val_loss: 1.0808 - val_accuracy: 0.4530\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8235 - accuracy: 0.5852 - val_loss: 1.0816 - val_accuracy: 0.4530\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8256 - accuracy: 0.5852 - val_loss: 1.0828 - val_accuracy: 0.4530\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8257 - accuracy: 0.5852 - val_loss: 1.0824 - val_accuracy: 0.4530\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8267 - accuracy: 0.5852 - val_loss: 1.0839 - val_accuracy: 0.4530\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8279 - accuracy: 0.5296 - val_loss: 1.0824 - val_accuracy: 0.4530\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8260 - accuracy: 0.5667 - val_loss: 1.0805 - val_accuracy: 0.4530\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8252 - accuracy: 0.5630 - val_loss: 1.0782 - val_accuracy: 0.4530\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8235 - accuracy: 0.5852 - val_loss: 1.0791 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8234 - accuracy: 0.5852 - val_loss: 1.0809 - val_accuracy: 0.4530\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8236 - accuracy: 0.5852 - val_loss: 1.0828 - val_accuracy: 0.4530\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8249 - accuracy: 0.5852 - val_loss: 1.0845 - val_accuracy: 0.4530\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8249 - accuracy: 0.5852 - val_loss: 1.0841 - val_accuracy: 0.4530\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8237 - accuracy: 0.5852 - val_loss: 1.0840 - val_accuracy: 0.4530\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8229 - accuracy: 0.5852 - val_loss: 1.0851 - val_accuracy: 0.4530\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8219 - accuracy: 0.5889 - val_loss: 1.0875 - val_accuracy: 0.4444\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8265 - accuracy: 0.5741 - val_loss: 1.0905 - val_accuracy: 0.4444\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8271 - accuracy: 0.5704 - val_loss: 1.0878 - val_accuracy: 0.4444\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8264 - accuracy: 0.5852 - val_loss: 1.0875 - val_accuracy: 0.4530\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8267 - accuracy: 0.5852 - val_loss: 1.0884 - val_accuracy: 0.4530\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8256 - accuracy: 0.5852 - val_loss: 1.0904 - val_accuracy: 0.4530\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8273 - accuracy: 0.5852 - val_loss: 1.0888 - val_accuracy: 0.4530\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8255 - accuracy: 0.5852 - val_loss: 1.0856 - val_accuracy: 0.4530\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8248 - accuracy: 0.5852 - val_loss: 1.0856 - val_accuracy: 0.4615\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8232 - accuracy: 0.5889 - val_loss: 1.0858 - val_accuracy: 0.4615\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8235 - accuracy: 0.5852 - val_loss: 1.0869 - val_accuracy: 0.4530\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8229 - accuracy: 0.5852 - val_loss: 1.0900 - val_accuracy: 0.4530\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8245 - accuracy: 0.5556 - val_loss: 1.0896 - val_accuracy: 0.4530\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8226 - accuracy: 0.5852 - val_loss: 1.0888 - val_accuracy: 0.4530\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8232 - accuracy: 0.5852 - val_loss: 1.0894 - val_accuracy: 0.4530\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8249 - accuracy: 0.5852 - val_loss: 1.0896 - val_accuracy: 0.4530\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8236 - accuracy: 0.5852 - val_loss: 1.0884 - val_accuracy: 0.4530\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8223 - accuracy: 0.5852 - val_loss: 1.0866 - val_accuracy: 0.4530\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8230 - accuracy: 0.5852 - val_loss: 1.0861 - val_accuracy: 0.4530\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8241 - accuracy: 0.5852 - val_loss: 1.0852 - val_accuracy: 0.4530\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8223 - accuracy: 0.5852 - val_loss: 1.0851 - val_accuracy: 0.4530\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8231 - accuracy: 0.5889 - val_loss: 1.0866 - val_accuracy: 0.4615\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8210 - accuracy: 0.5963 - val_loss: 1.0895 - val_accuracy: 0.4615\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8221 - accuracy: 0.5704 - val_loss: 1.0926 - val_accuracy: 0.4530\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8237 - accuracy: 0.5667 - val_loss: 1.0921 - val_accuracy: 0.4530\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8215 - accuracy: 0.5852 - val_loss: 1.0896 - val_accuracy: 0.4530\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8227 - accuracy: 0.5852 - val_loss: 1.0889 - val_accuracy: 0.4530\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8219 - accuracy: 0.5852 - val_loss: 1.0888 - val_accuracy: 0.4615\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8207 - accuracy: 0.5889 - val_loss: 1.0891 - val_accuracy: 0.4359\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8211 - accuracy: 0.5889 - val_loss: 1.0918 - val_accuracy: 0.4359\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8221 - accuracy: 0.5519 - val_loss: 1.0928 - val_accuracy: 0.4359\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8229 - accuracy: 0.5778 - val_loss: 1.0958 - val_accuracy: 0.4444\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8263 - accuracy: 0.5741 - val_loss: 1.0988 - val_accuracy: 0.4444\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8250 - accuracy: 0.5556 - val_loss: 1.0907 - val_accuracy: 0.4444\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8200 - accuracy: 0.5889 - val_loss: 1.0896 - val_accuracy: 0.4359\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8219 - accuracy: 0.5852 - val_loss: 1.0925 - val_accuracy: 0.4530\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8249 - accuracy: 0.5852 - val_loss: 1.0918 - val_accuracy: 0.4530\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8234 - accuracy: 0.5852 - val_loss: 1.0878 - val_accuracy: 0.4444\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8236 - accuracy: 0.5926 - val_loss: 1.0895 - val_accuracy: 0.4444\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8245 - accuracy: 0.5926 - val_loss: 1.0875 - val_accuracy: 0.4444\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8213 - accuracy: 0.5889 - val_loss: 1.0879 - val_accuracy: 0.4444\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8223 - accuracy: 0.5778 - val_loss: 1.0901 - val_accuracy: 0.4444\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8213 - accuracy: 0.5852 - val_loss: 1.0884 - val_accuracy: 0.4444\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8213 - accuracy: 0.5926 - val_loss: 1.0883 - val_accuracy: 0.4444\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8220 - accuracy: 0.5926 - val_loss: 1.0876 - val_accuracy: 0.4359\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8204 - accuracy: 0.5889 - val_loss: 1.0884 - val_accuracy: 0.4530\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8215 - accuracy: 0.5852 - val_loss: 1.0915 - val_accuracy: 0.4530\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8229 - accuracy: 0.5852 - val_loss: 1.0910 - val_accuracy: 0.4530\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8219 - accuracy: 0.5852 - val_loss: 1.0900 - val_accuracy: 0.4530\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8202 - accuracy: 0.5852 - val_loss: 1.0898 - val_accuracy: 0.4359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8199 - accuracy: 0.5889 - val_loss: 1.0914 - val_accuracy: 0.4444\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8206 - accuracy: 0.5926 - val_loss: 1.0931 - val_accuracy: 0.4444\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8199 - accuracy: 0.5926 - val_loss: 1.0933 - val_accuracy: 0.4444\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8205 - accuracy: 0.5704 - val_loss: 1.0912 - val_accuracy: 0.4359\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8204 - accuracy: 0.5889 - val_loss: 1.0893 - val_accuracy: 0.4615\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8213 - accuracy: 0.5630 - val_loss: 1.0906 - val_accuracy: 0.4444\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8200 - accuracy: 0.5741 - val_loss: 1.0903 - val_accuracy: 0.4444\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8199 - accuracy: 0.5926 - val_loss: 1.0906 - val_accuracy: 0.4444\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8194 - accuracy: 0.5926 - val_loss: 1.0912 - val_accuracy: 0.4444\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8198 - accuracy: 0.5889 - val_loss: 1.0903 - val_accuracy: 0.4359\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8194 - accuracy: 0.5889 - val_loss: 1.0903 - val_accuracy: 0.4359\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8206 - accuracy: 0.5889 - val_loss: 1.0912 - val_accuracy: 0.4359\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8186 - accuracy: 0.5889 - val_loss: 1.0946 - val_accuracy: 0.4530\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8234 - accuracy: 0.5630 - val_loss: 1.0963 - val_accuracy: 0.4530\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8218 - accuracy: 0.5778 - val_loss: 1.0906 - val_accuracy: 0.4444\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8194 - accuracy: 0.5926 - val_loss: 1.0910 - val_accuracy: 0.4444\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8190 - accuracy: 0.5926 - val_loss: 1.0917 - val_accuracy: 0.4444\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8188 - accuracy: 0.5926 - val_loss: 1.0935 - val_accuracy: 0.4359\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8201 - accuracy: 0.5852 - val_loss: 1.0942 - val_accuracy: 0.4530\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8211 - accuracy: 0.5889 - val_loss: 1.0938 - val_accuracy: 0.4359\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8191 - accuracy: 0.5889 - val_loss: 1.0940 - val_accuracy: 0.4444\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8192 - accuracy: 0.5926 - val_loss: 1.0947 - val_accuracy: 0.4444\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8189 - accuracy: 0.5926 - val_loss: 1.0953 - val_accuracy: 0.4444\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8216 - accuracy: 0.5741 - val_loss: 1.0964 - val_accuracy: 0.4444\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8195 - accuracy: 0.5815 - val_loss: 1.0938 - val_accuracy: 0.4444\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8185 - accuracy: 0.5926 - val_loss: 1.0955 - val_accuracy: 0.4444\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8215 - accuracy: 0.5926 - val_loss: 1.0951 - val_accuracy: 0.4444\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8185 - accuracy: 0.5926 - val_loss: 1.0917 - val_accuracy: 0.4444\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8178 - accuracy: 0.5889 - val_loss: 1.0939 - val_accuracy: 0.4359\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8209 - accuracy: 0.5889 - val_loss: 1.0933 - val_accuracy: 0.4359\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8198 - accuracy: 0.5889 - val_loss: 1.0917 - val_accuracy: 0.4359\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8188 - accuracy: 0.5889 - val_loss: 1.0921 - val_accuracy: 0.4359\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8202 - accuracy: 0.5926 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8192 - accuracy: 0.5926 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8197 - accuracy: 0.5926 - val_loss: 1.0933 - val_accuracy: 0.4444\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8220 - accuracy: 0.5926 - val_loss: 1.0940 - val_accuracy: 0.4444\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8222 - accuracy: 0.5926 - val_loss: 1.0922 - val_accuracy: 0.4444\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8181 - accuracy: 0.5926 - val_loss: 1.0933 - val_accuracy: 0.4444\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8186 - accuracy: 0.5926 - val_loss: 1.0927 - val_accuracy: 0.4444\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8210 - accuracy: 0.5926 - val_loss: 1.0905 - val_accuracy: 0.4359\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8191 - accuracy: 0.5889 - val_loss: 1.0904 - val_accuracy: 0.4530\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8231 - accuracy: 0.5778 - val_loss: 1.0968 - val_accuracy: 0.4530\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8248 - accuracy: 0.5667 - val_loss: 1.0936 - val_accuracy: 0.4444\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8217 - accuracy: 0.5889 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8221 - accuracy: 0.5926 - val_loss: 1.0886 - val_accuracy: 0.4444\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8186 - accuracy: 0.5926 - val_loss: 1.0887 - val_accuracy: 0.4444\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8167 - accuracy: 0.5926 - val_loss: 1.0919 - val_accuracy: 0.4359\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8218 - accuracy: 0.5889 - val_loss: 1.0928 - val_accuracy: 0.4359\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8199 - accuracy: 0.5889 - val_loss: 1.0906 - val_accuracy: 0.4359\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8189 - accuracy: 0.5889 - val_loss: 1.0917 - val_accuracy: 0.4444\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8177 - accuracy: 0.5926 - val_loss: 1.0942 - val_accuracy: 0.4444\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8190 - accuracy: 0.5741 - val_loss: 1.0971 - val_accuracy: 0.4444\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8209 - accuracy: 0.5741 - val_loss: 1.0958 - val_accuracy: 0.4444\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8196 - accuracy: 0.5963 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8193 - accuracy: 0.5889 - val_loss: 1.0951 - val_accuracy: 0.4359\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8206 - accuracy: 0.5889 - val_loss: 1.0942 - val_accuracy: 0.4359\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8194 - accuracy: 0.5889 - val_loss: 1.0957 - val_accuracy: 0.4359\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8201 - accuracy: 0.5704 - val_loss: 1.0965 - val_accuracy: 0.4359\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8204 - accuracy: 0.5630 - val_loss: 1.0953 - val_accuracy: 0.4359\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8198 - accuracy: 0.5556 - val_loss: 1.0946 - val_accuracy: 0.4359\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8183 - accuracy: 0.5704 - val_loss: 1.0945 - val_accuracy: 0.4359\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8177 - accuracy: 0.5741 - val_loss: 1.0961 - val_accuracy: 0.4444\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8199 - accuracy: 0.5926 - val_loss: 1.0971 - val_accuracy: 0.4444\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8202 - accuracy: 0.5889 - val_loss: 1.0951 - val_accuracy: 0.4359\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8169 - accuracy: 0.5889 - val_loss: 1.0955 - val_accuracy: 0.4359\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8177 - accuracy: 0.5889 - val_loss: 1.0942 - val_accuracy: 0.4444\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8186 - accuracy: 0.5889 - val_loss: 1.0950 - val_accuracy: 0.4359\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8212 - accuracy: 0.5926 - val_loss: 1.0923 - val_accuracy: 0.4444\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8191 - accuracy: 0.6000 - val_loss: 1.0975 - val_accuracy: 0.4444\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8215 - accuracy: 0.5741 - val_loss: 1.1048 - val_accuracy: 0.4444\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8236 - accuracy: 0.5704 - val_loss: 1.1013 - val_accuracy: 0.4530\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8207 - accuracy: 0.5741 - val_loss: 1.0987 - val_accuracy: 0.4359\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8204 - accuracy: 0.5889 - val_loss: 1.0972 - val_accuracy: 0.4359\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8178 - accuracy: 0.5926 - val_loss: 1.0978 - val_accuracy: 0.4444\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8226 - accuracy: 0.5667 - val_loss: 1.1013 - val_accuracy: 0.4444\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8172 - accuracy: 0.5963 - val_loss: 1.1007 - val_accuracy: 0.4444\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8205 - accuracy: 0.5926 - val_loss: 1.0992 - val_accuracy: 0.4444\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8213 - accuracy: 0.5889 - val_loss: 1.0948 - val_accuracy: 0.4359\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8174 - accuracy: 0.5889 - val_loss: 1.0947 - val_accuracy: 0.4359\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8202 - accuracy: 0.5889 - val_loss: 1.0970 - val_accuracy: 0.4359\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8191 - accuracy: 0.5741 - val_loss: 1.0945 - val_accuracy: 0.4444\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8164 - accuracy: 0.5926 - val_loss: 1.0969 - val_accuracy: 0.4444\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8183 - accuracy: 0.5926 - val_loss: 1.0968 - val_accuracy: 0.4444\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8199 - accuracy: 0.5926 - val_loss: 1.0958 - val_accuracy: 0.4444\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8184 - accuracy: 0.5926 - val_loss: 1.0939 - val_accuracy: 0.4444\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8142 - accuracy: 0.5852 - val_loss: 1.0965 - val_accuracy: 0.4444\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8167 - accuracy: 0.5741 - val_loss: 1.0961 - val_accuracy: 0.4444\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8163 - accuracy: 0.5741 - val_loss: 1.0941 - val_accuracy: 0.4444\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8166 - accuracy: 0.5926 - val_loss: 1.0957 - val_accuracy: 0.4444\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8175 - accuracy: 0.5926 - val_loss: 1.0937 - val_accuracy: 0.4444\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8153 - accuracy: 0.5926 - val_loss: 1.0948 - val_accuracy: 0.4444\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8166 - accuracy: 0.5444 - val_loss: 1.0966 - val_accuracy: 0.4444\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8173 - accuracy: 0.5741 - val_loss: 1.0926 - val_accuracy: 0.4444\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8166 - accuracy: 0.5852 - val_loss: 1.0904 - val_accuracy: 0.4444\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8172 - accuracy: 0.5926 - val_loss: 1.0899 - val_accuracy: 0.4444\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8166 - accuracy: 0.5926 - val_loss: 1.0915 - val_accuracy: 0.4444\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8193 - accuracy: 0.5926 - val_loss: 1.0948 - val_accuracy: 0.4444\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8204 - accuracy: 0.5667 - val_loss: 1.0985 - val_accuracy: 0.4444\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8168 - accuracy: 0.5741 - val_loss: 1.0968 - val_accuracy: 0.4444\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8160 - accuracy: 0.5778 - val_loss: 1.0960 - val_accuracy: 0.4359\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8150 - accuracy: 0.5889 - val_loss: 1.0973 - val_accuracy: 0.4359\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8151 - accuracy: 0.5889 - val_loss: 1.0991 - val_accuracy: 0.4359\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8166 - accuracy: 0.5889 - val_loss: 1.1000 - val_accuracy: 0.4359\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8171 - accuracy: 0.5889 - val_loss: 1.0980 - val_accuracy: 0.4444\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8140 - accuracy: 0.5926 - val_loss: 1.0980 - val_accuracy: 0.4444\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8156 - accuracy: 0.5926 - val_loss: 1.0987 - val_accuracy: 0.4444\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8168 - accuracy: 0.5926 - val_loss: 1.0988 - val_accuracy: 0.4444\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8154 - accuracy: 0.5926 - val_loss: 1.0997 - val_accuracy: 0.4444\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8149 - accuracy: 0.5926 - val_loss: 1.0999 - val_accuracy: 0.4444\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8158 - accuracy: 0.5815 - val_loss: 1.1042 - val_accuracy: 0.4444\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8160 - accuracy: 0.5741 - val_loss: 1.1026 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8145 - accuracy: 0.5704 - val_loss: 1.1000 - val_accuracy: 0.4444\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8143 - accuracy: 0.5926 - val_loss: 1.0995 - val_accuracy: 0.4444\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8143 - accuracy: 0.5926 - val_loss: 1.1001 - val_accuracy: 0.4444\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8137 - accuracy: 0.5926 - val_loss: 1.0993 - val_accuracy: 0.4444\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8150 - accuracy: 0.5926 - val_loss: 1.0971 - val_accuracy: 0.4444\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.0969 - val_accuracy: 0.4444\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8154 - accuracy: 0.5741 - val_loss: 1.0980 - val_accuracy: 0.4444\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8158 - accuracy: 0.5741 - val_loss: 1.0973 - val_accuracy: 0.4444\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8151 - accuracy: 0.5926 - val_loss: 1.0967 - val_accuracy: 0.4444\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8143 - accuracy: 0.5926 - val_loss: 1.0986 - val_accuracy: 0.4444\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8141 - accuracy: 0.5926 - val_loss: 1.1010 - val_accuracy: 0.4444\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8136 - accuracy: 0.5963 - val_loss: 1.1040 - val_accuracy: 0.4444\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8156 - accuracy: 0.5741 - val_loss: 1.1054 - val_accuracy: 0.4444\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8177 - accuracy: 0.5741 - val_loss: 1.1034 - val_accuracy: 0.4444\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8153 - accuracy: 0.5667 - val_loss: 1.0982 - val_accuracy: 0.4444\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8146 - accuracy: 0.5926 - val_loss: 1.0996 - val_accuracy: 0.4444\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8192 - accuracy: 0.5926 - val_loss: 1.0988 - val_accuracy: 0.4444\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8157 - accuracy: 0.5926 - val_loss: 1.0968 - val_accuracy: 0.4444\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8169 - accuracy: 0.5704 - val_loss: 1.1041 - val_accuracy: 0.4444\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8226 - accuracy: 0.5741 - val_loss: 1.1063 - val_accuracy: 0.4444\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8185 - accuracy: 0.5593 - val_loss: 1.1009 - val_accuracy: 0.4359\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.62 - 0s 96us/step - loss: 0.8155 - accuracy: 0.5889 - val_loss: 1.1044 - val_accuracy: 0.4359\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8166 - accuracy: 0.5704 - val_loss: 1.1058 - val_accuracy: 0.4359\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8180 - accuracy: 0.5407 - val_loss: 1.1046 - val_accuracy: 0.4359\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8157 - accuracy: 0.5889 - val_loss: 1.1033 - val_accuracy: 0.4359\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8154 - accuracy: 0.5889 - val_loss: 1.1031 - val_accuracy: 0.4359\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8152 - accuracy: 0.5889 - val_loss: 1.1033 - val_accuracy: 0.4444\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8149 - accuracy: 0.5926 - val_loss: 1.1013 - val_accuracy: 0.4359\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8156 - accuracy: 0.5926 - val_loss: 1.0989 - val_accuracy: 0.4359\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8151 - accuracy: 0.5926 - val_loss: 1.0980 - val_accuracy: 0.4359\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8171 - accuracy: 0.5926 - val_loss: 1.0975 - val_accuracy: 0.4359\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8144 - accuracy: 0.5963 - val_loss: 1.0952 - val_accuracy: 0.4444\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8135 - accuracy: 0.6222 - val_loss: 1.1006 - val_accuracy: 0.4444\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8202 - accuracy: 0.5741 - val_loss: 1.1055 - val_accuracy: 0.4444\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8215 - accuracy: 0.5741 - val_loss: 1.0991 - val_accuracy: 0.4444\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8165 - accuracy: 0.5926 - val_loss: 1.0950 - val_accuracy: 0.4359\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8152 - accuracy: 0.5926 - val_loss: 1.0943 - val_accuracy: 0.4359\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8128 - accuracy: 0.5963 - val_loss: 1.0964 - val_accuracy: 0.4444\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8166 - accuracy: 0.5741 - val_loss: 1.1017 - val_accuracy: 0.4444\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8169 - accuracy: 0.5741 - val_loss: 1.0982 - val_accuracy: 0.4444\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8129 - accuracy: 0.6111 - val_loss: 1.0947 - val_accuracy: 0.4444\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8157 - accuracy: 0.5926 - val_loss: 1.0965 - val_accuracy: 0.4359\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8174 - accuracy: 0.5963 - val_loss: 1.0964 - val_accuracy: 0.4444\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8153 - accuracy: 0.5926 - val_loss: 1.0964 - val_accuracy: 0.4444\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8138 - accuracy: 0.5926 - val_loss: 1.0982 - val_accuracy: 0.4444\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8133 - accuracy: 0.5926 - val_loss: 1.0971 - val_accuracy: 0.4444\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.0980 - val_accuracy: 0.4444\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8135 - accuracy: 0.5926 - val_loss: 1.0992 - val_accuracy: 0.4444\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8131 - accuracy: 0.5926 - val_loss: 1.1017 - val_accuracy: 0.4444\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1026 - val_accuracy: 0.4444\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1037 - val_accuracy: 0.4444\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1035 - val_accuracy: 0.4444\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1024 - val_accuracy: 0.4444\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.1016 - val_accuracy: 0.4444\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8129 - accuracy: 0.5926 - val_loss: 1.1023 - val_accuracy: 0.4444\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1036 - val_accuracy: 0.4444\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8110 - accuracy: 0.5889 - val_loss: 1.1083 - val_accuracy: 0.4444\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8204 - accuracy: 0.5741 - val_loss: 1.1127 - val_accuracy: 0.4444\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8179 - accuracy: 0.5667 - val_loss: 1.1096 - val_accuracy: 0.4444\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8184 - accuracy: 0.5926 - val_loss: 1.1065 - val_accuracy: 0.4444\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1024 - val_accuracy: 0.4444\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8123 - accuracy: 0.5926 - val_loss: 1.1039 - val_accuracy: 0.4444\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8130 - accuracy: 0.5926 - val_loss: 1.1070 - val_accuracy: 0.4444\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8145 - accuracy: 0.5741 - val_loss: 1.1042 - val_accuracy: 0.4444\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8112 - accuracy: 0.5667 - val_loss: 1.1016 - val_accuracy: 0.4444\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8122 - accuracy: 0.5926 - val_loss: 1.1032 - val_accuracy: 0.4444\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8149 - accuracy: 0.5926 - val_loss: 1.1016 - val_accuracy: 0.4444\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1018 - val_accuracy: 0.4444\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8120 - accuracy: 0.5926 - val_loss: 1.1047 - val_accuracy: 0.4444\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8125 - accuracy: 0.5926 - val_loss: 1.1042 - val_accuracy: 0.4444\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8112 - accuracy: 0.5926 - val_loss: 1.1051 - val_accuracy: 0.4444\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1061 - val_accuracy: 0.4444\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8125 - accuracy: 0.5926 - val_loss: 1.1049 - val_accuracy: 0.4444\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8104 - accuracy: 0.5926 - val_loss: 1.1052 - val_accuracy: 0.4444\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8118 - accuracy: 0.5926 - val_loss: 1.1073 - val_accuracy: 0.4444\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8125 - accuracy: 0.5741 - val_loss: 1.1074 - val_accuracy: 0.4444\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8119 - accuracy: 0.5704 - val_loss: 1.1055 - val_accuracy: 0.4444\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1044 - val_accuracy: 0.4444\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1054 - val_accuracy: 0.4444\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8103 - accuracy: 0.5926 - val_loss: 1.1066 - val_accuracy: 0.4444\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8140 - accuracy: 0.5741 - val_loss: 1.1102 - val_accuracy: 0.4444\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8158 - accuracy: 0.5704 - val_loss: 1.1079 - val_accuracy: 0.4444\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8140 - accuracy: 0.5926 - val_loss: 1.1039 - val_accuracy: 0.4444\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8160 - accuracy: 0.5926 - val_loss: 1.1053 - val_accuracy: 0.4444\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8123 - accuracy: 0.5926 - val_loss: 1.1047 - val_accuracy: 0.4444\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8143 - accuracy: 0.5926 - val_loss: 1.1073 - val_accuracy: 0.4444\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8139 - accuracy: 0.5926 - val_loss: 1.1060 - val_accuracy: 0.4444\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1041 - val_accuracy: 0.4444\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8108 - accuracy: 0.5926 - val_loss: 1.1050 - val_accuracy: 0.4444\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8111 - accuracy: 0.5704 - val_loss: 1.1061 - val_accuracy: 0.4444\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8132 - accuracy: 0.5741 - val_loss: 1.1076 - val_accuracy: 0.4444\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8110 - accuracy: 0.5852 - val_loss: 1.1058 - val_accuracy: 0.4444\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8111 - accuracy: 0.5963 - val_loss: 1.1058 - val_accuracy: 0.4359\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8135 - accuracy: 0.5926 - val_loss: 1.1066 - val_accuracy: 0.4359\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8119 - accuracy: 0.5926 - val_loss: 1.1064 - val_accuracy: 0.4444\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8106 - accuracy: 0.5926 - val_loss: 1.1071 - val_accuracy: 0.4444\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8100 - accuracy: 0.5926 - val_loss: 1.1066 - val_accuracy: 0.4444\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8105 - accuracy: 0.5926 - val_loss: 1.1066 - val_accuracy: 0.4444\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8116 - accuracy: 0.5926 - val_loss: 1.1080 - val_accuracy: 0.4444\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8110 - accuracy: 0.5926 - val_loss: 1.1078 - val_accuracy: 0.4444\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8103 - accuracy: 0.5852 - val_loss: 1.1070 - val_accuracy: 0.4444\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8127 - accuracy: 0.5741 - val_loss: 1.1067 - val_accuracy: 0.4444\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8135 - accuracy: 0.5926 - val_loss: 1.1050 - val_accuracy: 0.4444\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8131 - accuracy: 0.5926 - val_loss: 1.1046 - val_accuracy: 0.4444\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8130 - accuracy: 0.5926 - val_loss: 1.1051 - val_accuracy: 0.4444\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8117 - accuracy: 0.5593 - val_loss: 1.1093 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38ff60b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 79us/step\n",
      "over-sampling test accuracy: 45.30%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
       "       2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1,\n",
       "       0, 1, 1, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa25     1     1\n",
       "1       CFBRSa07     0     1\n",
       "2         NRS247     0     0\n",
       "3          NY439     2     2\n",
       "4    CFBREBSa110     1     1\n",
       "..           ...   ...   ...\n",
       "112       SR1129     0     1\n",
       "113       NRS172     0     1\n",
       "114       NRS205     2     2\n",
       "115        NY439     2     2\n",
       "116       NRS249     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366434</td>\n",
       "      <td>4.095403e-01</td>\n",
       "      <td>0.224026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068183</td>\n",
       "      <td>8.598678e-01</td>\n",
       "      <td>0.071949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622689</td>\n",
       "      <td>2.851807e-01</td>\n",
       "      <td>0.092130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000686</td>\n",
       "      <td>7.877519e-04</td>\n",
       "      <td>0.998526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366434</td>\n",
       "      <td>4.095403e-01</td>\n",
       "      <td>0.224026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.366434</td>\n",
       "      <td>4.095403e-01</td>\n",
       "      <td>0.224026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.188536</td>\n",
       "      <td>5.454503e-01</td>\n",
       "      <td>0.266014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>9.435421e-07</td>\n",
       "      <td>0.998980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000686</td>\n",
       "      <td>7.877519e-04</td>\n",
       "      <td>0.998526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.188536</td>\n",
       "      <td>5.454503e-01</td>\n",
       "      <td>0.266014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1         2\n",
       "0    0.366434  4.095403e-01  0.224026\n",
       "1    0.068183  8.598678e-01  0.071949\n",
       "2    0.622689  2.851807e-01  0.092130\n",
       "3    0.000686  7.877519e-04  0.998526\n",
       "4    0.366434  4.095403e-01  0.224026\n",
       "..        ...           ...       ...\n",
       "112  0.366434  4.095403e-01  0.224026\n",
       "113  0.188536  5.454503e-01  0.266014\n",
       "114  0.001019  9.435421e-07  0.998980\n",
       "115  0.000686  7.877519e-04  0.998526\n",
       "116  0.188536  5.454503e-01  0.266014\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8280 - accuracy: 0.5852 - val_loss: 1.1341 - val_accuracy: 0.4530\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8207 - accuracy: 0.5889 - val_loss: 1.1390 - val_accuracy: 0.4359\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8276 - accuracy: 0.5926 - val_loss: 1.1380 - val_accuracy: 0.4359\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8235 - accuracy: 0.5926 - val_loss: 1.1393 - val_accuracy: 0.4530\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8303 - accuracy: 0.5667 - val_loss: 1.1347 - val_accuracy: 0.4530\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8239 - accuracy: 0.5667 - val_loss: 1.1350 - val_accuracy: 0.4530\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8225 - accuracy: 0.5889 - val_loss: 1.1379 - val_accuracy: 0.4359\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8291 - accuracy: 0.5667 - val_loss: 1.1430 - val_accuracy: 0.4530\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8217 - accuracy: 0.5778 - val_loss: 1.1305 - val_accuracy: 0.4530\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8231 - accuracy: 0.5852 - val_loss: 1.1316 - val_accuracy: 0.4530\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8218 - accuracy: 0.5630 - val_loss: 1.1346 - val_accuracy: 0.4530\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8229 - accuracy: 0.5667 - val_loss: 1.1327 - val_accuracy: 0.4530\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8212 - accuracy: 0.5889 - val_loss: 1.1312 - val_accuracy: 0.4530\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8236 - accuracy: 0.5889 - val_loss: 1.1400 - val_accuracy: 0.4359\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8248 - accuracy: 0.5926 - val_loss: 1.1362 - val_accuracy: 0.4530\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8247 - accuracy: 0.5593 - val_loss: 1.1386 - val_accuracy: 0.4530\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8302 - accuracy: 0.5852 - val_loss: 1.1396 - val_accuracy: 0.4530\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8242 - accuracy: 0.5889 - val_loss: 1.1401 - val_accuracy: 0.4530\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8251 - accuracy: 0.5370 - val_loss: 1.1388 - val_accuracy: 0.4530\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 1.1349 - val_accuracy: 0.4530\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8191 - accuracy: 0.6111 - val_loss: 1.1352 - val_accuracy: 0.4530\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8237 - accuracy: 0.5889 - val_loss: 1.1383 - val_accuracy: 0.4530\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8214 - accuracy: 0.5889 - val_loss: 1.1328 - val_accuracy: 0.4530\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8234 - accuracy: 0.5852 - val_loss: 1.1324 - val_accuracy: 0.4530\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8210 - accuracy: 0.5926 - val_loss: 1.1368 - val_accuracy: 0.4530\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8216 - accuracy: 0.5667 - val_loss: 1.1358 - val_accuracy: 0.4530\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8211 - accuracy: 0.5889 - val_loss: 1.1344 - val_accuracy: 0.4530\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8211 - accuracy: 0.5519 - val_loss: 1.1343 - val_accuracy: 0.4530\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8267 - accuracy: 0.5704 - val_loss: 1.1377 - val_accuracy: 0.4359\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8226 - accuracy: 0.5889 - val_loss: 1.1314 - val_accuracy: 0.4530\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8238 - accuracy: 0.5889 - val_loss: 1.1384 - val_accuracy: 0.4359\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8201 - accuracy: 0.5667 - val_loss: 1.1405 - val_accuracy: 0.4530\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8208 - accuracy: 0.5630 - val_loss: 1.1355 - val_accuracy: 0.4530\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8249 - accuracy: 0.5889 - val_loss: 1.1347 - val_accuracy: 0.4530\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8208 - accuracy: 0.5889 - val_loss: 1.1411 - val_accuracy: 0.4530\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8238 - accuracy: 0.5889 - val_loss: 1.1391 - val_accuracy: 0.4530\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8228 - accuracy: 0.5519 - val_loss: 1.1389 - val_accuracy: 0.4530\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8208 - accuracy: 0.5926 - val_loss: 1.1355 - val_accuracy: 0.4530\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8234 - accuracy: 0.5889 - val_loss: 1.1364 - val_accuracy: 0.4530\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8292 - accuracy: 0.5704 - val_loss: 1.1415 - val_accuracy: 0.4530\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8200 - accuracy: 0.5815 - val_loss: 1.1358 - val_accuracy: 0.4530\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8205 - accuracy: 0.5889 - val_loss: 1.1329 - val_accuracy: 0.4530\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8235 - accuracy: 0.5889 - val_loss: 1.1372 - val_accuracy: 0.4530\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8232 - accuracy: 0.5889 - val_loss: 1.1385 - val_accuracy: 0.4530\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8194 - accuracy: 0.5889 - val_loss: 1.1391 - val_accuracy: 0.4530\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8240 - accuracy: 0.5926 - val_loss: 1.1383 - val_accuracy: 0.4359\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8209 - accuracy: 0.5889 - val_loss: 1.1350 - val_accuracy: 0.4530\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8213 - accuracy: 0.5889 - val_loss: 1.1415 - val_accuracy: 0.4530\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8214 - accuracy: 0.5593 - val_loss: 1.1417 - val_accuracy: 0.4530\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8210 - accuracy: 0.5889 - val_loss: 1.1375 - val_accuracy: 0.4530\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8241 - accuracy: 0.5259 - val_loss: 1.1352 - val_accuracy: 0.4530\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8183 - accuracy: 0.5889 - val_loss: 1.1372 - val_accuracy: 0.4530\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8193 - accuracy: 0.5889 - val_loss: 1.1426 - val_accuracy: 0.4359\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8194 - accuracy: 0.5889 - val_loss: 1.1415 - val_accuracy: 0.4530\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8211 - accuracy: 0.5889 - val_loss: 1.1445 - val_accuracy: 0.4530\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8204 - accuracy: 0.5889 - val_loss: 1.1369 - val_accuracy: 0.4530\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8233 - accuracy: 0.5926 - val_loss: 1.1383 - val_accuracy: 0.4530\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8204 - accuracy: 0.5741 - val_loss: 1.1396 - val_accuracy: 0.4530\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8217 - accuracy: 0.5704 - val_loss: 1.1445 - val_accuracy: 0.4359\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8238 - accuracy: 0.6000 - val_loss: 1.1396 - val_accuracy: 0.4530\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8191 - accuracy: 0.5889 - val_loss: 1.1394 - val_accuracy: 0.4530\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8191 - accuracy: 0.5667 - val_loss: 1.1401 - val_accuracy: 0.4530\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8201 - accuracy: 0.5704 - val_loss: 1.1403 - val_accuracy: 0.4530\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8181 - accuracy: 0.5889 - val_loss: 1.1406 - val_accuracy: 0.4530\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8194 - accuracy: 0.5778 - val_loss: 1.1438 - val_accuracy: 0.4530\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8184 - accuracy: 0.5741 - val_loss: 1.1387 - val_accuracy: 0.4530\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8234 - accuracy: 0.5889 - val_loss: 1.1393 - val_accuracy: 0.4530\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8272 - accuracy: 0.5259 - val_loss: 1.1411 - val_accuracy: 0.4530\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8193 - accuracy: 0.5889 - val_loss: 1.1407 - val_accuracy: 0.4530\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8187 - accuracy: 0.5889 - val_loss: 1.1436 - val_accuracy: 0.4530\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8201 - accuracy: 0.5667 - val_loss: 1.1385 - val_accuracy: 0.4530\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8216 - accuracy: 0.5889 - val_loss: 1.1413 - val_accuracy: 0.4359\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8226 - accuracy: 0.5630 - val_loss: 1.1444 - val_accuracy: 0.4530\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8184 - accuracy: 0.5815 - val_loss: 1.1389 - val_accuracy: 0.4530\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8161 - accuracy: 0.5889 - val_loss: 1.1423 - val_accuracy: 0.4359\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8227 - accuracy: 0.5926 - val_loss: 1.1441 - val_accuracy: 0.4359\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8309 - accuracy: 0.5889 - val_loss: 1.1428 - val_accuracy: 0.4530\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8156 - accuracy: 0.5889 - val_loss: 1.1436 - val_accuracy: 0.4359\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8224 - accuracy: 0.5926 - val_loss: 1.1465 - val_accuracy: 0.4359\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8181 - accuracy: 0.5889 - val_loss: 1.1478 - val_accuracy: 0.4530\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8222 - accuracy: 0.5889 - val_loss: 1.1445 - val_accuracy: 0.4530\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.8236 - accuracy: 0.5889 - val_loss: 1.1495 - val_accuracy: 0.4359\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 327us/step - loss: 0.8181 - accuracy: 0.5926 - val_loss: 1.1410 - val_accuracy: 0.4530\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8212 - accuracy: 0.5889 - val_loss: 1.1391 - val_accuracy: 0.4530\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8193 - accuracy: 0.5889 - val_loss: 1.1429 - val_accuracy: 0.4530\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8210 - accuracy: 0.5741 - val_loss: 1.1436 - val_accuracy: 0.4530\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8195 - accuracy: 0.5704 - val_loss: 1.1436 - val_accuracy: 0.4530\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8197 - accuracy: 0.6000 - val_loss: 1.1456 - val_accuracy: 0.4530\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8197 - accuracy: 0.5889 - val_loss: 1.1444 - val_accuracy: 0.4530\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8193 - accuracy: 0.5556 - val_loss: 1.1479 - val_accuracy: 0.4530\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8184 - accuracy: 0.5741 - val_loss: 1.1403 - val_accuracy: 0.4530\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8204 - accuracy: 0.5926 - val_loss: 1.1447 - val_accuracy: 0.4359\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8199 - accuracy: 0.5556 - val_loss: 1.1441 - val_accuracy: 0.4359\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8156 - accuracy: 0.5889 - val_loss: 1.1397 - val_accuracy: 0.4530\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 373us/step - loss: 0.8186 - accuracy: 0.5889 - val_loss: 1.1369 - val_accuracy: 0.4530\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8154 - accuracy: 0.5926 - val_loss: 1.1427 - val_accuracy: 0.4359\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8220 - accuracy: 0.5852 - val_loss: 1.1517 - val_accuracy: 0.4359\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8173 - accuracy: 0.5926 - val_loss: 1.1431 - val_accuracy: 0.4530\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8253 - accuracy: 0.5889 - val_loss: 1.1462 - val_accuracy: 0.4530\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8225 - accuracy: 0.5926 - val_loss: 1.1379 - val_accuracy: 0.4359\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8206 - accuracy: 0.5889 - val_loss: 1.1386 - val_accuracy: 0.4359\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8152 - accuracy: 0.5593 - val_loss: 1.1485 - val_accuracy: 0.4530\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8182 - accuracy: 0.5889 - val_loss: 1.1426 - val_accuracy: 0.4530\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8169 - accuracy: 0.5889 - val_loss: 1.1436 - val_accuracy: 0.4530\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8174 - accuracy: 0.5889 - val_loss: 1.1453 - val_accuracy: 0.4530\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8150 - accuracy: 0.5889 - val_loss: 1.1403 - val_accuracy: 0.4530\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 535us/step - loss: 0.8222 - accuracy: 0.5926 - val_loss: 1.1432 - val_accuracy: 0.4359\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8206 - accuracy: 0.5926 - val_loss: 1.1404 - val_accuracy: 0.4530\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8187 - accuracy: 0.5815 - val_loss: 1.1447 - val_accuracy: 0.4359\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8165 - accuracy: 0.5741 - val_loss: 1.1440 - val_accuracy: 0.4359\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8160 - accuracy: 0.5926 - val_loss: 1.1435 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8188 - accuracy: 0.5926 - val_loss: 1.1453 - val_accuracy: 0.4359\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8188 - accuracy: 0.5852 - val_loss: 1.1494 - val_accuracy: 0.4359\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8169 - accuracy: 0.5852 - val_loss: 1.1421 - val_accuracy: 0.4359\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8174 - accuracy: 0.5926 - val_loss: 1.1450 - val_accuracy: 0.4530\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8182 - accuracy: 0.5889 - val_loss: 1.1499 - val_accuracy: 0.4530\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8175 - accuracy: 0.5926 - val_loss: 1.1518 - val_accuracy: 0.4359\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8173 - accuracy: 0.5926 - val_loss: 1.1506 - val_accuracy: 0.4359\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8175 - accuracy: 0.5889 - val_loss: 1.1459 - val_accuracy: 0.4530\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8170 - accuracy: 0.5926 - val_loss: 1.1426 - val_accuracy: 0.4359\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8156 - accuracy: 0.5741 - val_loss: 1.1490 - val_accuracy: 0.4359\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8152 - accuracy: 0.5630 - val_loss: 1.1463 - val_accuracy: 0.4359\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8172 - accuracy: 0.5926 - val_loss: 1.1429 - val_accuracy: 0.4530\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8162 - accuracy: 0.5926 - val_loss: 1.1491 - val_accuracy: 0.4359\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8230 - accuracy: 0.5926 - val_loss: 1.1413 - val_accuracy: 0.4530\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8159 - accuracy: 0.5963 - val_loss: 1.1483 - val_accuracy: 0.4359\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8180 - accuracy: 0.5741 - val_loss: 1.1456 - val_accuracy: 0.4359\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8158 - accuracy: 0.5889 - val_loss: 1.1415 - val_accuracy: 0.4359\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8181 - accuracy: 0.5926 - val_loss: 1.1491 - val_accuracy: 0.4359\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8160 - accuracy: 0.5926 - val_loss: 1.1435 - val_accuracy: 0.4359\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8237 - accuracy: 0.5926 - val_loss: 1.1407 - val_accuracy: 0.4530\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8192 - accuracy: 0.5889 - val_loss: 1.1469 - val_accuracy: 0.4359\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8220 - accuracy: 0.5815 - val_loss: 1.1512 - val_accuracy: 0.4359\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8212 - accuracy: 0.5519 - val_loss: 1.1458 - val_accuracy: 0.4359\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8180 - accuracy: 0.5926 - val_loss: 1.1452 - val_accuracy: 0.4359\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8199 - accuracy: 0.5926 - val_loss: 1.1465 - val_accuracy: 0.4359\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8163 - accuracy: 0.5852 - val_loss: 1.1492 - val_accuracy: 0.4359\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8167 - accuracy: 0.5630 - val_loss: 1.1476 - val_accuracy: 0.4359\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8155 - accuracy: 0.5926 - val_loss: 1.1456 - val_accuracy: 0.4359\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8163 - accuracy: 0.5741 - val_loss: 1.1491 - val_accuracy: 0.4530\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8164 - accuracy: 0.5704 - val_loss: 1.1501 - val_accuracy: 0.4359\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8148 - accuracy: 0.5926 - val_loss: 1.1566 - val_accuracy: 0.4359\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8160 - accuracy: 0.5741 - val_loss: 1.1499 - val_accuracy: 0.4359\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8153 - accuracy: 0.5926 - val_loss: 1.1437 - val_accuracy: 0.4359\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8169 - accuracy: 0.5630 - val_loss: 1.1490 - val_accuracy: 0.4359\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8143 - accuracy: 0.5778 - val_loss: 1.1458 - val_accuracy: 0.4359\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8140 - accuracy: 0.5926 - val_loss: 1.1421 - val_accuracy: 0.4359\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8165 - accuracy: 0.5926 - val_loss: 1.1442 - val_accuracy: 0.4359\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8162 - accuracy: 0.5704 - val_loss: 1.1502 - val_accuracy: 0.4359\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8161 - accuracy: 0.5704 - val_loss: 1.1487 - val_accuracy: 0.4359\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8165 - accuracy: 0.5593 - val_loss: 1.1463 - val_accuracy: 0.4359\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8152 - accuracy: 0.5926 - val_loss: 1.1445 - val_accuracy: 0.4359\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8158 - accuracy: 0.5926 - val_loss: 1.1483 - val_accuracy: 0.4359\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8150 - accuracy: 0.5926 - val_loss: 1.1480 - val_accuracy: 0.4359\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8165 - accuracy: 0.5926 - val_loss: 1.1554 - val_accuracy: 0.4359\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8198 - accuracy: 0.5926 - val_loss: 1.1506 - val_accuracy: 0.4359\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8152 - accuracy: 0.5926 - val_loss: 1.1495 - val_accuracy: 0.4359\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8139 - accuracy: 0.5926 - val_loss: 1.1483 - val_accuracy: 0.4359\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.8155 - accuracy: 0.5889 - val_loss: 1.1472 - val_accuracy: 0.4530\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8164 - accuracy: 0.5889 - val_loss: 1.1506 - val_accuracy: 0.4359\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8164 - accuracy: 0.5556 - val_loss: 1.1516 - val_accuracy: 0.4359\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8178 - accuracy: 0.5889 - val_loss: 1.1455 - val_accuracy: 0.4359\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 248us/step - loss: 0.8159 - accuracy: 0.5667 - val_loss: 1.1537 - val_accuracy: 0.4359\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 657us/step - loss: 0.8130 - accuracy: 0.6000 - val_loss: 1.1484 - val_accuracy: 0.4359\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 402us/step - loss: 0.8163 - accuracy: 0.5926 - val_loss: 1.1457 - val_accuracy: 0.4359\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8167 - accuracy: 0.5926 - val_loss: 1.1471 - val_accuracy: 0.4274\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8193 - accuracy: 0.5778 - val_loss: 1.1540 - val_accuracy: 0.4359\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8154 - accuracy: 0.6000 - val_loss: 1.1545 - val_accuracy: 0.4274\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8177 - accuracy: 0.5926 - val_loss: 1.1524 - val_accuracy: 0.4359\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8150 - accuracy: 0.5741 - val_loss: 1.1524 - val_accuracy: 0.4359\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8151 - accuracy: 0.5926 - val_loss: 1.1461 - val_accuracy: 0.4359\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8148 - accuracy: 0.5926 - val_loss: 1.1470 - val_accuracy: 0.4359\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8129 - accuracy: 0.5926 - val_loss: 1.1542 - val_accuracy: 0.4359\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8217 - accuracy: 0.5370 - val_loss: 1.1536 - val_accuracy: 0.4359\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8139 - accuracy: 0.5963 - val_loss: 1.1493 - val_accuracy: 0.4359\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8153 - accuracy: 0.5926 - val_loss: 1.1473 - val_accuracy: 0.4359\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8181 - accuracy: 0.5926 - val_loss: 1.1522 - val_accuracy: 0.4274\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1517 - val_accuracy: 0.4359\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8147 - accuracy: 0.5704 - val_loss: 1.1525 - val_accuracy: 0.4359\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8149 - accuracy: 0.5926 - val_loss: 1.1506 - val_accuracy: 0.4359\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8134 - accuracy: 0.5926 - val_loss: 1.1514 - val_accuracy: 0.4359\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8178 - accuracy: 0.5889 - val_loss: 1.1502 - val_accuracy: 0.4359\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8182 - accuracy: 0.5630 - val_loss: 1.1644 - val_accuracy: 0.4359\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8143 - accuracy: 0.5963 - val_loss: 1.1539 - val_accuracy: 0.4359\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8210 - accuracy: 0.5926 - val_loss: 1.1530 - val_accuracy: 0.4530\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8147 - accuracy: 0.5926 - val_loss: 1.1534 - val_accuracy: 0.4359\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8116 - accuracy: 0.5926 - val_loss: 1.1552 - val_accuracy: 0.4359\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8178 - accuracy: 0.5630 - val_loss: 1.1569 - val_accuracy: 0.4359\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.8138 - accuracy: 0.5852 - val_loss: 1.1523 - val_accuracy: 0.4359\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8142 - accuracy: 0.5926 - val_loss: 1.1522 - val_accuracy: 0.4359\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8142 - accuracy: 0.5519 - val_loss: 1.1554 - val_accuracy: 0.4359\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8150 - accuracy: 0.5926 - val_loss: 1.1526 - val_accuracy: 0.4359\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1502 - val_accuracy: 0.4359\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8140 - accuracy: 0.5926 - val_loss: 1.1558 - val_accuracy: 0.4359\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8138 - accuracy: 0.5926 - val_loss: 1.1533 - val_accuracy: 0.4359\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1571 - val_accuracy: 0.4359\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8168 - accuracy: 0.5556 - val_loss: 1.1620 - val_accuracy: 0.4359\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8166 - accuracy: 0.5926 - val_loss: 1.1548 - val_accuracy: 0.4359\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8137 - accuracy: 0.5926 - val_loss: 1.1600 - val_accuracy: 0.4359\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8139 - accuracy: 0.5926 - val_loss: 1.1566 - val_accuracy: 0.4359\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8125 - accuracy: 0.5926 - val_loss: 1.1536 - val_accuracy: 0.4359\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8161 - accuracy: 0.5926 - val_loss: 1.1567 - val_accuracy: 0.4359\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8137 - accuracy: 0.5926 - val_loss: 1.1571 - val_accuracy: 0.4359\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8130 - accuracy: 0.5926 - val_loss: 1.1526 - val_accuracy: 0.4359\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8131 - accuracy: 0.5926 - val_loss: 1.1552 - val_accuracy: 0.4359\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8124 - accuracy: 0.5741 - val_loss: 1.1570 - val_accuracy: 0.4359\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8196 - accuracy: 0.5926 - val_loss: 1.1596 - val_accuracy: 0.4359\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 495us/step - loss: 0.8113 - accuracy: 0.5926 - val_loss: 1.1627 - val_accuracy: 0.4359\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8145 - accuracy: 0.5593 - val_loss: 1.1616 - val_accuracy: 0.4359\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8152 - accuracy: 0.5704 - val_loss: 1.1607 - val_accuracy: 0.4359\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8143 - accuracy: 0.5630 - val_loss: 1.1567 - val_accuracy: 0.4359\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8145 - accuracy: 0.5926 - val_loss: 1.1558 - val_accuracy: 0.4274\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8128 - accuracy: 0.5889 - val_loss: 1.1547 - val_accuracy: 0.4359\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8145 - accuracy: 0.5926 - val_loss: 1.1572 - val_accuracy: 0.4359\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8208 - accuracy: 0.5741 - val_loss: 1.1595 - val_accuracy: 0.4359\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 423us/step - loss: 0.8135 - accuracy: 0.5815 - val_loss: 1.1592 - val_accuracy: 0.4359\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8177 - accuracy: 0.5926 - val_loss: 1.1634 - val_accuracy: 0.4359\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8120 - accuracy: 0.5926 - val_loss: 1.1644 - val_accuracy: 0.4359\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8187 - accuracy: 0.5741 - val_loss: 1.1631 - val_accuracy: 0.4359\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8132 - accuracy: 0.5963 - val_loss: 1.1558 - val_accuracy: 0.4274\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8166 - accuracy: 0.5889 - val_loss: 1.1524 - val_accuracy: 0.4359\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 134us/step - loss: 0.8114 - accuracy: 0.5741 - val_loss: 1.1592 - val_accuracy: 0.4359\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8115 - accuracy: 0.5926 - val_loss: 1.1577 - val_accuracy: 0.4274\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8118 - accuracy: 0.5963 - val_loss: 1.1557 - val_accuracy: 0.4274\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8119 - accuracy: 0.5963 - val_loss: 1.1588 - val_accuracy: 0.4359\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.1596 - val_accuracy: 0.4359\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8135 - accuracy: 0.5926 - val_loss: 1.1539 - val_accuracy: 0.4359\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8125 - accuracy: 0.5926 - val_loss: 1.1516 - val_accuracy: 0.4359\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8115 - accuracy: 0.5889 - val_loss: 1.1546 - val_accuracy: 0.4359\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8144 - accuracy: 0.5519 - val_loss: 1.1571 - val_accuracy: 0.4274\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8141 - accuracy: 0.5630 - val_loss: 1.1551 - val_accuracy: 0.4359\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8212 - accuracy: 0.5926 - val_loss: 1.1601 - val_accuracy: 0.4359\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8138 - accuracy: 0.5444 - val_loss: 1.1606 - val_accuracy: 0.4359\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8158 - accuracy: 0.5926 - val_loss: 1.1603 - val_accuracy: 0.4359\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8123 - accuracy: 0.5926 - val_loss: 1.1658 - val_accuracy: 0.4359\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8205 - accuracy: 0.5667 - val_loss: 1.1624 - val_accuracy: 0.4359\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8206 - accuracy: 0.5926 - val_loss: 1.1594 - val_accuracy: 0.4359\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8127 - accuracy: 0.5815 - val_loss: 1.1582 - val_accuracy: 0.4359\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8155 - accuracy: 0.5741 - val_loss: 1.1611 - val_accuracy: 0.4359\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8099 - accuracy: 0.5926 - val_loss: 1.1641 - val_accuracy: 0.4359\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8151 - accuracy: 0.5926 - val_loss: 1.1618 - val_accuracy: 0.4359\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.71 - 0s 73us/step - loss: 0.8119 - accuracy: 0.5926 - val_loss: 1.1645 - val_accuracy: 0.4359\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8158 - accuracy: 0.5593 - val_loss: 1.1645 - val_accuracy: 0.4359\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8185 - accuracy: 0.5889 - val_loss: 1.1580 - val_accuracy: 0.4359\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8178 - accuracy: 0.5889 - val_loss: 1.1613 - val_accuracy: 0.4359\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8144 - accuracy: 0.5556 - val_loss: 1.1576 - val_accuracy: 0.4274\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8147 - accuracy: 0.5926 - val_loss: 1.1600 - val_accuracy: 0.4274\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8162 - accuracy: 0.5741 - val_loss: 1.1619 - val_accuracy: 0.4359\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8116 - accuracy: 0.5704 - val_loss: 1.1563 - val_accuracy: 0.4359\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8112 - accuracy: 0.5926 - val_loss: 1.1561 - val_accuracy: 0.4359\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8159 - accuracy: 0.5926 - val_loss: 1.1626 - val_accuracy: 0.4359\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8131 - accuracy: 0.5926 - val_loss: 1.1641 - val_accuracy: 0.4274\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8109 - accuracy: 0.5926 - val_loss: 1.1601 - val_accuracy: 0.4359\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1542 - val_accuracy: 0.4359\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8117 - accuracy: 0.5889 - val_loss: 1.1645 - val_accuracy: 0.4359\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1606 - val_accuracy: 0.4359\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8138 - accuracy: 0.5926 - val_loss: 1.1577 - val_accuracy: 0.4359\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8146 - accuracy: 0.5926 - val_loss: 1.1585 - val_accuracy: 0.4274\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8127 - accuracy: 0.5741 - val_loss: 1.1586 - val_accuracy: 0.4359\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8108 - accuracy: 0.5926 - val_loss: 1.1548 - val_accuracy: 0.4359\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8118 - accuracy: 0.5926 - val_loss: 1.1555 - val_accuracy: 0.4359\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8122 - accuracy: 0.5926 - val_loss: 1.1588 - val_accuracy: 0.4359\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8134 - accuracy: 0.5889 - val_loss: 1.1639 - val_accuracy: 0.4274\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8103 - accuracy: 0.5778 - val_loss: 1.1606 - val_accuracy: 0.4359\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8137 - accuracy: 0.5926 - val_loss: 1.1590 - val_accuracy: 0.4359\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.1624 - val_accuracy: 0.4359\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8106 - accuracy: 0.5815 - val_loss: 1.1624 - val_accuracy: 0.4359\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8114 - accuracy: 0.5778 - val_loss: 1.1633 - val_accuracy: 0.4359\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.1601 - val_accuracy: 0.4359\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8132 - accuracy: 0.5926 - val_loss: 1.1591 - val_accuracy: 0.4359\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1611 - val_accuracy: 0.4359\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8099 - accuracy: 0.5926 - val_loss: 1.1616 - val_accuracy: 0.4359\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8117 - accuracy: 0.5778 - val_loss: 1.1635 - val_accuracy: 0.4359\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8129 - accuracy: 0.5926 - val_loss: 1.1612 - val_accuracy: 0.4359\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8120 - accuracy: 0.5926 - val_loss: 1.1623 - val_accuracy: 0.4359\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8153 - accuracy: 0.5704 - val_loss: 1.1724 - val_accuracy: 0.4359\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8122 - accuracy: 0.6000 - val_loss: 1.1668 - val_accuracy: 0.4274\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8134 - accuracy: 0.5926 - val_loss: 1.1633 - val_accuracy: 0.4274\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8079 - accuracy: 0.5926 - val_loss: 1.1645 - val_accuracy: 0.4359\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8180 - accuracy: 0.5519 - val_loss: 1.1658 - val_accuracy: 0.4359\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8094 - accuracy: 0.5852 - val_loss: 1.1594 - val_accuracy: 0.4274\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8123 - accuracy: 0.5963 - val_loss: 1.1586 - val_accuracy: 0.4359\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8142 - accuracy: 0.5926 - val_loss: 1.1606 - val_accuracy: 0.4274\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8161 - accuracy: 0.5556 - val_loss: 1.1703 - val_accuracy: 0.4359\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8123 - accuracy: 0.5852 - val_loss: 1.1632 - val_accuracy: 0.4359\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8093 - accuracy: 0.5963 - val_loss: 1.1656 - val_accuracy: 0.4274\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8115 - accuracy: 0.5926 - val_loss: 1.1653 - val_accuracy: 0.4359\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8090 - accuracy: 0.5889 - val_loss: 1.1623 - val_accuracy: 0.4274\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8102 - accuracy: 0.5593 - val_loss: 1.1625 - val_accuracy: 0.4274\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8129 - accuracy: 0.5778 - val_loss: 1.1583 - val_accuracy: 0.4359\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8112 - accuracy: 0.5778 - val_loss: 1.1662 - val_accuracy: 0.4359\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8091 - accuracy: 0.5926 - val_loss: 1.1637 - val_accuracy: 0.4359\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8087 - accuracy: 0.5889 - val_loss: 1.1659 - val_accuracy: 0.4359\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8096 - accuracy: 0.5926 - val_loss: 1.1688 - val_accuracy: 0.4359\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8118 - accuracy: 0.5926 - val_loss: 1.1670 - val_accuracy: 0.4359\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8098 - accuracy: 0.5926 - val_loss: 1.1685 - val_accuracy: 0.4359\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8086 - accuracy: 0.5926 - val_loss: 1.1656 - val_accuracy: 0.4359\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8088 - accuracy: 0.5926 - val_loss: 1.1671 - val_accuracy: 0.4359\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8105 - accuracy: 0.5926 - val_loss: 1.1658 - val_accuracy: 0.4274\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8119 - accuracy: 0.5926 - val_loss: 1.1650 - val_accuracy: 0.4274\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8086 - accuracy: 0.5778 - val_loss: 1.1670 - val_accuracy: 0.4359\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8110 - accuracy: 0.5741 - val_loss: 1.1659 - val_accuracy: 0.4359\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8116 - accuracy: 0.5889 - val_loss: 1.1672 - val_accuracy: 0.4359\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1649 - val_accuracy: 0.4274\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8118 - accuracy: 0.5963 - val_loss: 1.1655 - val_accuracy: 0.4359\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8130 - accuracy: 0.5926 - val_loss: 1.1642 - val_accuracy: 0.4359\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8144 - accuracy: 0.5926 - val_loss: 1.1706 - val_accuracy: 0.4274\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8144 - accuracy: 0.5926 - val_loss: 1.1604 - val_accuracy: 0.4274\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8147 - accuracy: 0.5704 - val_loss: 1.1746 - val_accuracy: 0.4359\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8157 - accuracy: 0.5519 - val_loss: 1.1666 - val_accuracy: 0.4274\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8128 - accuracy: 0.5593 - val_loss: 1.1663 - val_accuracy: 0.4359\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1604 - val_accuracy: 0.4274\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8135 - accuracy: 0.5926 - val_loss: 1.1599 - val_accuracy: 0.4274\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8119 - accuracy: 0.5926 - val_loss: 1.1604 - val_accuracy: 0.4274\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1645 - val_accuracy: 0.4359\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8103 - accuracy: 0.5926 - val_loss: 1.1627 - val_accuracy: 0.4274\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8104 - accuracy: 0.5926 - val_loss: 1.1648 - val_accuracy: 0.4359\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8096 - accuracy: 0.5889 - val_loss: 1.1635 - val_accuracy: 0.4274\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8083 - accuracy: 0.5926 - val_loss: 1.1675 - val_accuracy: 0.4359\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8078 - accuracy: 0.5926 - val_loss: 1.1655 - val_accuracy: 0.4359\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8075 - accuracy: 0.5926 - val_loss: 1.1640 - val_accuracy: 0.4359\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8089 - accuracy: 0.5926 - val_loss: 1.1698 - val_accuracy: 0.4359\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8083 - accuracy: 0.5926 - val_loss: 1.1691 - val_accuracy: 0.4359\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8086 - accuracy: 0.5926 - val_loss: 1.1632 - val_accuracy: 0.4359\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8114 - accuracy: 0.5926 - val_loss: 1.1677 - val_accuracy: 0.4359\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8073 - accuracy: 0.5926 - val_loss: 1.1677 - val_accuracy: 0.4274\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1666 - val_accuracy: 0.4274\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1609 - val_accuracy: 0.4274\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8106 - accuracy: 0.5926 - val_loss: 1.1664 - val_accuracy: 0.4359\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8114 - accuracy: 0.5704 - val_loss: 1.1731 - val_accuracy: 0.4359\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8117 - accuracy: 0.5852 - val_loss: 1.1684 - val_accuracy: 0.4274\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8125 - accuracy: 0.5926 - val_loss: 1.1650 - val_accuracy: 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1626 - val_accuracy: 0.4359\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8105 - accuracy: 0.5630 - val_loss: 1.1619 - val_accuracy: 0.4359\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8105 - accuracy: 0.5926 - val_loss: 1.1621 - val_accuracy: 0.4274\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8104 - accuracy: 0.5852 - val_loss: 1.1663 - val_accuracy: 0.4359\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8095 - accuracy: 0.5593 - val_loss: 1.1646 - val_accuracy: 0.4359\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8082 - accuracy: 0.5926 - val_loss: 1.1661 - val_accuracy: 0.4274\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8110 - accuracy: 0.5926 - val_loss: 1.1667 - val_accuracy: 0.4274\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8059 - accuracy: 0.5926 - val_loss: 1.1723 - val_accuracy: 0.4359\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8102 - accuracy: 0.5741 - val_loss: 1.1673 - val_accuracy: 0.4359\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8069 - accuracy: 0.5815 - val_loss: 1.1647 - val_accuracy: 0.4274\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8096 - accuracy: 0.5926 - val_loss: 1.1653 - val_accuracy: 0.4274\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8179 - accuracy: 0.5519 - val_loss: 1.1777 - val_accuracy: 0.4359\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8110 - accuracy: 0.5926 - val_loss: 1.1720 - val_accuracy: 0.4274\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8101 - accuracy: 0.5963 - val_loss: 1.1661 - val_accuracy: 0.4359\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8117 - accuracy: 0.5852 - val_loss: 1.1708 - val_accuracy: 0.4359\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8132 - accuracy: 0.5630 - val_loss: 1.1742 - val_accuracy: 0.4359\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8067 - accuracy: 0.5852 - val_loss: 1.1708 - val_accuracy: 0.4274\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8153 - accuracy: 0.5926 - val_loss: 1.1666 - val_accuracy: 0.4274\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8063 - accuracy: 0.6000 - val_loss: 1.1720 - val_accuracy: 0.4359\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8174 - accuracy: 0.5741 - val_loss: 1.1739 - val_accuracy: 0.4359\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8110 - accuracy: 0.5815 - val_loss: 1.1702 - val_accuracy: 0.4274\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8102 - accuracy: 0.5889 - val_loss: 1.1682 - val_accuracy: 0.4359\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8131 - accuracy: 0.5407 - val_loss: 1.1734 - val_accuracy: 0.4359\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8089 - accuracy: 0.5926 - val_loss: 1.1687 - val_accuracy: 0.4359\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8124 - accuracy: 0.5926 - val_loss: 1.1667 - val_accuracy: 0.4274\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8140 - accuracy: 0.5407 - val_loss: 1.1739 - val_accuracy: 0.4359\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8092 - accuracy: 0.5778 - val_loss: 1.1683 - val_accuracy: 0.4274\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8102 - accuracy: 0.5926 - val_loss: 1.1725 - val_accuracy: 0.4274\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8094 - accuracy: 0.5926 - val_loss: 1.1767 - val_accuracy: 0.4359\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8073 - accuracy: 0.5926 - val_loss: 1.1733 - val_accuracy: 0.4274\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.8100 - accuracy: 0.5926 - val_loss: 1.1693 - val_accuracy: 0.4274\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8098 - accuracy: 0.5926 - val_loss: 1.1680 - val_accuracy: 0.4274\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8084 - accuracy: 0.5926 - val_loss: 1.1693 - val_accuracy: 0.4274\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8098 - accuracy: 0.5889 - val_loss: 1.1774 - val_accuracy: 0.4359\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8085 - accuracy: 0.5852 - val_loss: 1.1739 - val_accuracy: 0.4274\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.8138 - accuracy: 0.5926 - val_loss: 1.1685 - val_accuracy: 0.4274\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8109 - accuracy: 0.5444 - val_loss: 1.1744 - val_accuracy: 0.4359\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8089 - accuracy: 0.5704 - val_loss: 1.1688 - val_accuracy: 0.4274\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8072 - accuracy: 0.5926 - val_loss: 1.1663 - val_accuracy: 0.4274\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8071 - accuracy: 0.5963 - val_loss: 1.1672 - val_accuracy: 0.4359\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1716 - val_accuracy: 0.4359\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8132 - accuracy: 0.5444 - val_loss: 1.1693 - val_accuracy: 0.4359\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 294us/step - loss: 0.8101 - accuracy: 0.5815 - val_loss: 1.1709 - val_accuracy: 0.4274\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8127 - accuracy: 0.5370 - val_loss: 1.1712 - val_accuracy: 0.4359\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8138 - accuracy: 0.5593 - val_loss: 1.1657 - val_accuracy: 0.4359\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8093 - accuracy: 0.5926 - val_loss: 1.1707 - val_accuracy: 0.4274\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8106 - accuracy: 0.5926 - val_loss: 1.1677 - val_accuracy: 0.4274\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.1710 - val_accuracy: 0.4359\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8096 - accuracy: 0.5778 - val_loss: 1.1793 - val_accuracy: 0.4274\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8160 - accuracy: 0.5926 - val_loss: 1.1674 - val_accuracy: 0.4274\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.1690 - val_accuracy: 0.4359\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8177 - accuracy: 0.5519 - val_loss: 1.1815 - val_accuracy: 0.4359\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8127 - accuracy: 0.6111 - val_loss: 1.1698 - val_accuracy: 0.4274\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8084 - accuracy: 0.5926 - val_loss: 1.1728 - val_accuracy: 0.4274\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8123 - accuracy: 0.5963 - val_loss: 1.1717 - val_accuracy: 0.4359\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8106 - accuracy: 0.5926 - val_loss: 1.1763 - val_accuracy: 0.4274\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8119 - accuracy: 0.5926 - val_loss: 1.1800 - val_accuracy: 0.4274\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8067 - accuracy: 0.5889 - val_loss: 1.1771 - val_accuracy: 0.4359\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8081 - accuracy: 0.5926 - val_loss: 1.1733 - val_accuracy: 0.4359\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8064 - accuracy: 0.5926 - val_loss: 1.1690 - val_accuracy: 0.4274\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8142 - accuracy: 0.5926 - val_loss: 1.1698 - val_accuracy: 0.4359\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1657 - val_accuracy: 0.4359\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8129 - accuracy: 0.5926 - val_loss: 1.1698 - val_accuracy: 0.4274\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.8102 - accuracy: 0.5926 - val_loss: 1.1706 - val_accuracy: 0.4274\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8071 - accuracy: 0.5926 - val_loss: 1.1682 - val_accuracy: 0.4274\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8086 - accuracy: 0.5926 - val_loss: 1.1672 - val_accuracy: 0.4274\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8068 - accuracy: 0.5889 - val_loss: 1.1714 - val_accuracy: 0.4359\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1731 - val_accuracy: 0.4274\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8085 - accuracy: 0.5963 - val_loss: 1.1717 - val_accuracy: 0.4274\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8063 - accuracy: 0.5889 - val_loss: 1.1729 - val_accuracy: 0.4274\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8092 - accuracy: 0.5926 - val_loss: 1.1701 - val_accuracy: 0.4359\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8066 - accuracy: 0.5926 - val_loss: 1.1737 - val_accuracy: 0.4274\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1759 - val_accuracy: 0.4274\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8155 - accuracy: 0.5667 - val_loss: 1.1757 - val_accuracy: 0.4359\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8081 - accuracy: 0.5926 - val_loss: 1.1742 - val_accuracy: 0.4274\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8136 - accuracy: 0.5926 - val_loss: 1.1818 - val_accuracy: 0.4274\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8128 - accuracy: 0.5926 - val_loss: 1.1739 - val_accuracy: 0.4359\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8233 - accuracy: 0.5741 - val_loss: 1.1814 - val_accuracy: 0.4359\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8068 - accuracy: 0.6111 - val_loss: 1.1702 - val_accuracy: 0.4274\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8133 - accuracy: 0.5926 - val_loss: 1.1667 - val_accuracy: 0.4274\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8168 - accuracy: 0.5815 - val_loss: 1.1764 - val_accuracy: 0.4359\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8137 - accuracy: 0.5667 - val_loss: 1.1734 - val_accuracy: 0.4274\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8065 - accuracy: 0.5926 - val_loss: 1.1767 - val_accuracy: 0.4274\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8087 - accuracy: 0.5778 - val_loss: 1.1782 - val_accuracy: 0.4274\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8075 - accuracy: 0.6000 - val_loss: 1.1729 - val_accuracy: 0.4274\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8075 - accuracy: 0.5926 - val_loss: 1.1766 - val_accuracy: 0.4274\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8081 - accuracy: 0.5926 - val_loss: 1.1782 - val_accuracy: 0.4359\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8118 - accuracy: 0.5519 - val_loss: 1.1729 - val_accuracy: 0.4274\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8095 - accuracy: 0.5926 - val_loss: 1.1680 - val_accuracy: 0.4274\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8050 - accuracy: 0.5889 - val_loss: 1.1752 - val_accuracy: 0.4359\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8104 - accuracy: 0.5407 - val_loss: 1.1794 - val_accuracy: 0.4359\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8077 - accuracy: 0.5963 - val_loss: 1.1740 - val_accuracy: 0.4274\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8086 - accuracy: 0.5926 - val_loss: 1.1730 - val_accuracy: 0.4274\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8065 - accuracy: 0.5852 - val_loss: 1.1762 - val_accuracy: 0.4274\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8050 - accuracy: 0.5741 - val_loss: 1.1722 - val_accuracy: 0.4274\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8073 - accuracy: 0.5926 - val_loss: 1.1719 - val_accuracy: 0.4274\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8106 - accuracy: 0.5704 - val_loss: 1.1788 - val_accuracy: 0.4359\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8102 - accuracy: 0.5926 - val_loss: 1.1748 - val_accuracy: 0.4274\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8080 - accuracy: 0.5926 - val_loss: 1.1738 - val_accuracy: 0.4274\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8059 - accuracy: 0.5926 - val_loss: 1.1748 - val_accuracy: 0.4274\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8057 - accuracy: 0.5926 - val_loss: 1.1732 - val_accuracy: 0.4274\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8065 - accuracy: 0.5926 - val_loss: 1.1804 - val_accuracy: 0.4274\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8065 - accuracy: 0.5889 - val_loss: 1.1737 - val_accuracy: 0.4274\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8075 - accuracy: 0.5926 - val_loss: 1.1748 - val_accuracy: 0.4274\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8092 - accuracy: 0.5519 - val_loss: 1.1770 - val_accuracy: 0.4359\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 312us/step - loss: 0.8078 - accuracy: 0.5704 - val_loss: 1.1718 - val_accuracy: 0.4274\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8080 - accuracy: 0.5926 - val_loss: 1.1690 - val_accuracy: 0.4274\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8095 - accuracy: 0.5926 - val_loss: 1.1794 - val_accuracy: 0.4274\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.1728 - val_accuracy: 0.4274\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8077 - accuracy: 0.5741 - val_loss: 1.1721 - val_accuracy: 0.4359\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 128us/step - loss: 0.8075 - accuracy: 0.5630 - val_loss: 1.1713 - val_accuracy: 0.4274\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8068 - accuracy: 0.5926 - val_loss: 1.1754 - val_accuracy: 0.4274\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8100 - accuracy: 0.5593 - val_loss: 1.1808 - val_accuracy: 0.4359\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8065 - accuracy: 0.5593 - val_loss: 1.1773 - val_accuracy: 0.4359\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8110 - accuracy: 0.5926 - val_loss: 1.1747 - val_accuracy: 0.4274\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8051 - accuracy: 0.5926 - val_loss: 1.1747 - val_accuracy: 0.4359\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8113 - accuracy: 0.5667 - val_loss: 1.1797 - val_accuracy: 0.4359\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8067 - accuracy: 0.5889 - val_loss: 1.1806 - val_accuracy: 0.4359\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1808 - val_accuracy: 0.4274\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1878 - val_accuracy: 0.4274\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8081 - accuracy: 0.5519 - val_loss: 1.1794 - val_accuracy: 0.4274\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8079 - accuracy: 0.5741 - val_loss: 1.1739 - val_accuracy: 0.4274\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8101 - accuracy: 0.6000 - val_loss: 1.1716 - val_accuracy: 0.4274\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8046 - accuracy: 0.5926 - val_loss: 1.1787 - val_accuracy: 0.4274\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8093 - accuracy: 0.5667 - val_loss: 1.1911 - val_accuracy: 0.4359\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8068 - accuracy: 0.5741 - val_loss: 1.1813 - val_accuracy: 0.4359\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8105 - accuracy: 0.5926 - val_loss: 1.1733 - val_accuracy: 0.4274\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8144 - accuracy: 0.5926 - val_loss: 1.1836 - val_accuracy: 0.4274\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8084 - accuracy: 0.5593 - val_loss: 1.1807 - val_accuracy: 0.4359\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8113 - accuracy: 0.5889 - val_loss: 1.1788 - val_accuracy: 0.4359\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8092 - accuracy: 0.5926 - val_loss: 1.1785 - val_accuracy: 0.4274\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8076 - accuracy: 0.5926 - val_loss: 1.1870 - val_accuracy: 0.4274\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8116 - accuracy: 0.5704 - val_loss: 1.1831 - val_accuracy: 0.4274\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8084 - accuracy: 0.5741 - val_loss: 1.1802 - val_accuracy: 0.4359\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8072 - accuracy: 0.5926 - val_loss: 1.1745 - val_accuracy: 0.4274\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8059 - accuracy: 0.5926 - val_loss: 1.1751 - val_accuracy: 0.4274\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8065 - accuracy: 0.5926 - val_loss: 1.1725 - val_accuracy: 0.4274\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8102 - accuracy: 0.5926 - val_loss: 1.1732 - val_accuracy: 0.4274\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8066 - accuracy: 0.5444 - val_loss: 1.1755 - val_accuracy: 0.4359\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8058 - accuracy: 0.5593 - val_loss: 1.1783 - val_accuracy: 0.4274\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.1746 - val_accuracy: 0.4274\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8090 - accuracy: 0.5926 - val_loss: 1.1790 - val_accuracy: 0.4274\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8078 - accuracy: 0.5926 - val_loss: 1.1811 - val_accuracy: 0.4274\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8088 - accuracy: 0.5926 - val_loss: 1.1792 - val_accuracy: 0.4359\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8099 - accuracy: 0.5926 - val_loss: 1.1768 - val_accuracy: 0.4274\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8094 - accuracy: 0.5741 - val_loss: 1.1839 - val_accuracy: 0.4274\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8082 - accuracy: 0.5778 - val_loss: 1.1765 - val_accuracy: 0.4359\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8080 - accuracy: 0.5926 - val_loss: 1.1767 - val_accuracy: 0.4274\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8052 - accuracy: 0.5926 - val_loss: 1.1778 - val_accuracy: 0.4274\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8083 - accuracy: 0.5778 - val_loss: 1.1839 - val_accuracy: 0.4359\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8072 - accuracy: 0.5852 - val_loss: 1.1745 - val_accuracy: 0.4274\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8092 - accuracy: 0.5926 - val_loss: 1.1715 - val_accuracy: 0.4274\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8079 - accuracy: 0.5667 - val_loss: 1.1822 - val_accuracy: 0.4274\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8121 - accuracy: 0.5741 - val_loss: 1.1797 - val_accuracy: 0.4274\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8065 - accuracy: 0.5704 - val_loss: 1.1739 - val_accuracy: 0.4274\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8073 - accuracy: 0.5926 - val_loss: 1.1800 - val_accuracy: 0.4274\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8101 - accuracy: 0.5741 - val_loss: 1.1794 - val_accuracy: 0.4359\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8071 - accuracy: 0.5741 - val_loss: 1.1783 - val_accuracy: 0.4274\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8072 - accuracy: 0.5926 - val_loss: 1.1800 - val_accuracy: 0.4359\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8052 - accuracy: 0.5926 - val_loss: 1.1816 - val_accuracy: 0.4359\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8089 - accuracy: 0.5852 - val_loss: 1.1889 - val_accuracy: 0.4359\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8064 - accuracy: 0.5741 - val_loss: 1.1810 - val_accuracy: 0.4274\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8089 - accuracy: 0.5926 - val_loss: 1.1791 - val_accuracy: 0.4274\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8109 - accuracy: 0.5556 - val_loss: 1.1808 - val_accuracy: 0.4359\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8066 - accuracy: 0.5889 - val_loss: 1.1814 - val_accuracy: 0.4274\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8054 - accuracy: 0.5926 - val_loss: 1.1789 - val_accuracy: 0.4274\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8066 - accuracy: 0.5926 - val_loss: 1.1821 - val_accuracy: 0.4274\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8081 - accuracy: 0.5926 - val_loss: 1.1767 - val_accuracy: 0.4274\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1718 - val_accuracy: 0.4274\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8084 - accuracy: 0.5926 - val_loss: 1.1776 - val_accuracy: 0.4359\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8091 - accuracy: 0.5778 - val_loss: 1.1966 - val_accuracy: 0.4274\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8062 - accuracy: 0.5778 - val_loss: 1.1765 - val_accuracy: 0.4274\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8063 - accuracy: 0.5926 - val_loss: 1.1778 - val_accuracy: 0.4359\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8062 - accuracy: 0.5593 - val_loss: 1.1784 - val_accuracy: 0.4359\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8081 - accuracy: 0.5519 - val_loss: 1.1812 - val_accuracy: 0.4274\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8044 - accuracy: 0.5926 - val_loss: 1.1811 - val_accuracy: 0.4359\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8077 - accuracy: 0.5556 - val_loss: 1.1847 - val_accuracy: 0.4359\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8073 - accuracy: 0.5815 - val_loss: 1.1802 - val_accuracy: 0.4274\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8068 - accuracy: 0.5926 - val_loss: 1.1840 - val_accuracy: 0.4274\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8061 - accuracy: 0.5778 - val_loss: 1.1839 - val_accuracy: 0.4359\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8050 - accuracy: 0.5593 - val_loss: 1.1811 - val_accuracy: 0.4274\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8083 - accuracy: 0.5667 - val_loss: 1.1802 - val_accuracy: 0.4274\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8039 - accuracy: 0.5926 - val_loss: 1.1828 - val_accuracy: 0.4274\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8102 - accuracy: 0.5444 - val_loss: 1.1819 - val_accuracy: 0.4274\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8040 - accuracy: 0.5889 - val_loss: 1.1787 - val_accuracy: 0.4274\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8067 - accuracy: 0.5926 - val_loss: 1.1841 - val_accuracy: 0.4274\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8120 - accuracy: 0.5889 - val_loss: 1.1831 - val_accuracy: 0.4359\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8055 - accuracy: 0.5556 - val_loss: 1.1822 - val_accuracy: 0.4274\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8037 - accuracy: 0.5926 - val_loss: 1.1805 - val_accuracy: 0.4274\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8173 - accuracy: 0.5926 - val_loss: 1.1820 - val_accuracy: 0.4274\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8011 - accuracy: 0.6074 - val_loss: 1.1916 - val_accuracy: 0.4359\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9500 - accuracy: 0.40 - 0s 170us/step - loss: 0.8098 - accuracy: 0.5704 - val_loss: 1.1881 - val_accuracy: 0.4274\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8077 - accuracy: 0.5741 - val_loss: 1.1847 - val_accuracy: 0.4274\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8062 - accuracy: 0.5741 - val_loss: 1.1828 - val_accuracy: 0.4274\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8098 - accuracy: 0.5926 - val_loss: 1.1848 - val_accuracy: 0.4274\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8092 - accuracy: 0.5704 - val_loss: 1.1870 - val_accuracy: 0.4359\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8075 - accuracy: 0.5815 - val_loss: 1.1860 - val_accuracy: 0.4274\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8050 - accuracy: 0.5926 - val_loss: 1.1844 - val_accuracy: 0.4359\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8090 - accuracy: 0.5926 - val_loss: 1.1809 - val_accuracy: 0.4274\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8166 - accuracy: 0.5852 - val_loss: 1.1971 - val_accuracy: 0.4359\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8219 - accuracy: 0.5407 - val_loss: 1.1903 - val_accuracy: 0.4274\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8127 - accuracy: 0.5926 - val_loss: 1.1835 - val_accuracy: 0.4274\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8068 - accuracy: 0.5444 - val_loss: 1.1765 - val_accuracy: 0.4274\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1774 - val_accuracy: 0.4274\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8075 - accuracy: 0.5926 - val_loss: 1.1834 - val_accuracy: 0.4274\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8044 - accuracy: 0.5926 - val_loss: 1.1795 - val_accuracy: 0.4274\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8040 - accuracy: 0.5926 - val_loss: 1.1769 - val_accuracy: 0.4274\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8059 - accuracy: 0.5926 - val_loss: 1.1825 - val_accuracy: 0.4274\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.1783 - val_accuracy: 0.4274\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.1791 - val_accuracy: 0.4274\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8072 - accuracy: 0.5741 - val_loss: 1.1826 - val_accuracy: 0.4274\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8032 - accuracy: 0.5926 - val_loss: 1.1800 - val_accuracy: 0.4274\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8080 - accuracy: 0.5889 - val_loss: 1.1800 - val_accuracy: 0.4274\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8039 - accuracy: 0.5926 - val_loss: 1.1861 - val_accuracy: 0.4274\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8060 - accuracy: 0.5741 - val_loss: 1.1845 - val_accuracy: 0.4359\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8015 - accuracy: 0.6037 - val_loss: 1.1812 - val_accuracy: 0.4274\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8111 - accuracy: 0.5926 - val_loss: 1.1815 - val_accuracy: 0.4274\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8083 - accuracy: 0.5926 - val_loss: 1.1912 - val_accuracy: 0.4359\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8077 - accuracy: 0.5741 - val_loss: 1.1896 - val_accuracy: 0.4274\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1847 - val_accuracy: 0.4274\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 146us/step - loss: 0.8072 - accuracy: 0.5926 - val_loss: 1.1802 - val_accuracy: 0.4274\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8071 - accuracy: 0.5556 - val_loss: 1.1814 - val_accuracy: 0.4359\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8058 - accuracy: 0.5778 - val_loss: 1.1805 - val_accuracy: 0.4359\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8073 - accuracy: 0.5926 - val_loss: 1.1864 - val_accuracy: 0.4359\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8065 - accuracy: 0.5926 - val_loss: 1.1883 - val_accuracy: 0.4274\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8040 - accuracy: 0.5926 - val_loss: 1.1843 - val_accuracy: 0.4274\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 508us/step - loss: 0.8068 - accuracy: 0.5481 - val_loss: 1.1797 - val_accuracy: 0.4274\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 381us/step - loss: 0.8029 - accuracy: 0.5926 - val_loss: 1.1808 - val_accuracy: 0.4274\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8054 - accuracy: 0.5926 - val_loss: 1.1868 - val_accuracy: 0.4274\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.1873 - val_accuracy: 0.4359\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8052 - accuracy: 0.5926 - val_loss: 1.1877 - val_accuracy: 0.4359\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8036 - accuracy: 0.5963 - val_loss: 1.1865 - val_accuracy: 0.4274\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8050 - accuracy: 0.5741 - val_loss: 1.1803 - val_accuracy: 0.4274\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8092 - accuracy: 0.5815 - val_loss: 1.1797 - val_accuracy: 0.4274\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8080 - accuracy: 0.5926 - val_loss: 1.1853 - val_accuracy: 0.4359\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8057 - accuracy: 0.5926 - val_loss: 1.1826 - val_accuracy: 0.4274\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8033 - accuracy: 0.5926 - val_loss: 1.1843 - val_accuracy: 0.4274\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8053 - accuracy: 0.5741 - val_loss: 1.1830 - val_accuracy: 0.4274\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8055 - accuracy: 0.5926 - val_loss: 1.1840 - val_accuracy: 0.4274\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8063 - accuracy: 0.5444 - val_loss: 1.1812 - val_accuracy: 0.4274\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8041 - accuracy: 0.5926 - val_loss: 1.1822 - val_accuracy: 0.4274\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8093 - accuracy: 0.5926 - val_loss: 1.1872 - val_accuracy: 0.4274\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8065 - accuracy: 0.5926 - val_loss: 1.1786 - val_accuracy: 0.4274\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8048 - accuracy: 0.5926 - val_loss: 1.1809 - val_accuracy: 0.4274\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8042 - accuracy: 0.5852 - val_loss: 1.1852 - val_accuracy: 0.4359\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8036 - accuracy: 0.5926 - val_loss: 1.1829 - val_accuracy: 0.4359\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8064 - accuracy: 0.5889 - val_loss: 1.1835 - val_accuracy: 0.4274\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8072 - accuracy: 0.5407 - val_loss: 1.1891 - val_accuracy: 0.4274\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8043 - accuracy: 0.5926 - val_loss: 1.1855 - val_accuracy: 0.4274\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8045 - accuracy: 0.5926 - val_loss: 1.1874 - val_accuracy: 0.4359\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8041 - accuracy: 0.5926 - val_loss: 1.1886 - val_accuracy: 0.4359\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8069 - accuracy: 0.5778 - val_loss: 1.1875 - val_accuracy: 0.4274\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.1875 - val_accuracy: 0.4274\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8063 - accuracy: 0.5926 - val_loss: 1.1869 - val_accuracy: 0.4274\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.1911 - val_accuracy: 0.4359\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8047 - accuracy: 0.5593 - val_loss: 1.1940 - val_accuracy: 0.4359\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8087 - accuracy: 0.5704 - val_loss: 1.1861 - val_accuracy: 0.4274\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8079 - accuracy: 0.5926 - val_loss: 1.1880 - val_accuracy: 0.4359\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8086 - accuracy: 0.5926 - val_loss: 1.1909 - val_accuracy: 0.4274\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8027 - accuracy: 0.5926 - val_loss: 1.1880 - val_accuracy: 0.4359\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8050 - accuracy: 0.5667 - val_loss: 1.1919 - val_accuracy: 0.4359\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8053 - accuracy: 0.5741 - val_loss: 1.1936 - val_accuracy: 0.4274\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8026 - accuracy: 0.5926 - val_loss: 1.1927 - val_accuracy: 0.4274\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8040 - accuracy: 0.5926 - val_loss: 1.1910 - val_accuracy: 0.4274\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8044 - accuracy: 0.5889 - val_loss: 1.1896 - val_accuracy: 0.4359\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8094 - accuracy: 0.5963 - val_loss: 1.1868 - val_accuracy: 0.4274\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1952 - val_accuracy: 0.4274\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8069 - accuracy: 0.5519 - val_loss: 1.1823 - val_accuracy: 0.4274\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8047 - accuracy: 0.5556 - val_loss: 1.1838 - val_accuracy: 0.4359\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8048 - accuracy: 0.5556 - val_loss: 1.1827 - val_accuracy: 0.4274\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8130 - accuracy: 0.5926 - val_loss: 1.1841 - val_accuracy: 0.4274\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7999 - accuracy: 0.6074 - val_loss: 1.1897 - val_accuracy: 0.4274\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8070 - accuracy: 0.5741 - val_loss: 1.1897 - val_accuracy: 0.4274\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8069 - accuracy: 0.5593 - val_loss: 1.1866 - val_accuracy: 0.4274\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8015 - accuracy: 0.5926 - val_loss: 1.1895 - val_accuracy: 0.4359\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8041 - accuracy: 0.5630 - val_loss: 1.1896 - val_accuracy: 0.4359\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1882 - val_accuracy: 0.4359\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8024 - accuracy: 0.5926 - val_loss: 1.1872 - val_accuracy: 0.4274\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8048 - accuracy: 0.5778 - val_loss: 1.1897 - val_accuracy: 0.4274\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8057 - accuracy: 0.5704 - val_loss: 1.1889 - val_accuracy: 0.4274\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.1913 - val_accuracy: 0.4274\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8124 - accuracy: 0.5926 - val_loss: 1.1940 - val_accuracy: 0.4359\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8075 - accuracy: 0.5593 - val_loss: 1.1952 - val_accuracy: 0.4274\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8043 - accuracy: 0.5926 - val_loss: 1.1883 - val_accuracy: 0.4274\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8083 - accuracy: 0.5889 - val_loss: 1.1874 - val_accuracy: 0.4359\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8070 - accuracy: 0.5630 - val_loss: 1.1935 - val_accuracy: 0.4359\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8035 - accuracy: 0.5667 - val_loss: 1.1940 - val_accuracy: 0.4274\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8051 - accuracy: 0.5926 - val_loss: 1.1899 - val_accuracy: 0.4274\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8082 - accuracy: 0.5926 - val_loss: 1.1859 - val_accuracy: 0.4274\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8137 - accuracy: 0.5519 - val_loss: 1.1949 - val_accuracy: 0.4359\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8077 - accuracy: 0.5778 - val_loss: 1.1960 - val_accuracy: 0.4274\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8032 - accuracy: 0.6037 - val_loss: 1.1923 - val_accuracy: 0.4274\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8079 - accuracy: 0.5926 - val_loss: 1.1938 - val_accuracy: 0.4274\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8129 - accuracy: 0.5630 - val_loss: 1.2068 - val_accuracy: 0.4359\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8099 - accuracy: 0.5704 - val_loss: 1.1956 - val_accuracy: 0.4274\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8084 - accuracy: 0.5926 - val_loss: 1.1940 - val_accuracy: 0.4274\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8071 - accuracy: 0.5704 - val_loss: 1.2024 - val_accuracy: 0.4359\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8036 - accuracy: 0.5926 - val_loss: 1.1926 - val_accuracy: 0.4274\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8047 - accuracy: 0.5926 - val_loss: 1.1962 - val_accuracy: 0.4274\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.1942 - val_accuracy: 0.4359\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8013 - accuracy: 0.5926 - val_loss: 1.1925 - val_accuracy: 0.4274\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8033 - accuracy: 0.5630 - val_loss: 1.1900 - val_accuracy: 0.4274\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8044 - accuracy: 0.5741 - val_loss: 1.1907 - val_accuracy: 0.4359\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8050 - accuracy: 0.5889 - val_loss: 1.1913 - val_accuracy: 0.4274\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8029 - accuracy: 0.5926 - val_loss: 1.1956 - val_accuracy: 0.4274\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8056 - accuracy: 0.5926 - val_loss: 1.1922 - val_accuracy: 0.4274\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.8097 - accuracy: 0.5741 - val_loss: 1.1966 - val_accuracy: 0.4359\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8041 - accuracy: 0.5704 - val_loss: 1.1904 - val_accuracy: 0.4274\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8091 - accuracy: 0.5926 - val_loss: 1.1904 - val_accuracy: 0.4274\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.1893 - val_accuracy: 0.4274\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8035 - accuracy: 0.5926 - val_loss: 1.1950 - val_accuracy: 0.4359\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8022 - accuracy: 0.5926 - val_loss: 1.1937 - val_accuracy: 0.4359\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8026 - accuracy: 0.5926 - val_loss: 1.1912 - val_accuracy: 0.4274\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.8035 - accuracy: 0.5926 - val_loss: 1.1935 - val_accuracy: 0.4274\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8058 - accuracy: 0.5741 - val_loss: 1.1972 - val_accuracy: 0.4359\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.8027 - accuracy: 0.5926 - val_loss: 1.1938 - val_accuracy: 0.4274\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.8048 - accuracy: 0.5926 - val_loss: 1.1989 - val_accuracy: 0.4274\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8043 - accuracy: 0.5778 - val_loss: 1.2054 - val_accuracy: 0.4359\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8058 - accuracy: 0.5630 - val_loss: 1.1979 - val_accuracy: 0.4359\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8039 - accuracy: 0.5889 - val_loss: 1.1895 - val_accuracy: 0.4274\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 332us/step - loss: 0.8061 - accuracy: 0.5667 - val_loss: 1.1949 - val_accuracy: 0.4274\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.8056 - accuracy: 0.5926 - val_loss: 1.1933 - val_accuracy: 0.4274\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8058 - accuracy: 0.5741 - val_loss: 1.2016 - val_accuracy: 0.4359\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8021 - accuracy: 0.5963 - val_loss: 1.1938 - val_accuracy: 0.4274\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8077 - accuracy: 0.5926 - val_loss: 1.1962 - val_accuracy: 0.4274\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8034 - accuracy: 0.5815 - val_loss: 1.1925 - val_accuracy: 0.4274\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.1924 - val_accuracy: 0.4274\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8085 - accuracy: 0.5370 - val_loss: 1.2008 - val_accuracy: 0.4274\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8076 - accuracy: 0.5667 - val_loss: 1.1938 - val_accuracy: 0.4274\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8041 - accuracy: 0.5926 - val_loss: 1.2017 - val_accuracy: 0.4274\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 102us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.1986 - val_accuracy: 0.4274\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8023 - accuracy: 0.5926 - val_loss: 1.1997 - val_accuracy: 0.4359\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.1992 - val_accuracy: 0.4274\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8066 - accuracy: 0.5926 - val_loss: 1.1922 - val_accuracy: 0.4274\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8010 - accuracy: 0.5852 - val_loss: 1.1943 - val_accuracy: 0.4274\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8037 - accuracy: 0.5741 - val_loss: 1.1950 - val_accuracy: 0.4274\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8037 - accuracy: 0.5926 - val_loss: 1.1889 - val_accuracy: 0.4274\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8024 - accuracy: 0.5926 - val_loss: 1.1882 - val_accuracy: 0.4274\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8068 - accuracy: 0.5593 - val_loss: 1.1977 - val_accuracy: 0.4274\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8019 - accuracy: 0.5778 - val_loss: 1.1874 - val_accuracy: 0.4274\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8049 - accuracy: 0.5926 - val_loss: 1.1908 - val_accuracy: 0.4274\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8048 - accuracy: 0.5926 - val_loss: 1.1974 - val_accuracy: 0.4359\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8091 - accuracy: 0.5630 - val_loss: 1.2010 - val_accuracy: 0.4274\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8035 - accuracy: 0.5741 - val_loss: 1.1969 - val_accuracy: 0.4359\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8034 - accuracy: 0.5667 - val_loss: 1.1961 - val_accuracy: 0.4359\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8003 - accuracy: 0.5926 - val_loss: 1.1906 - val_accuracy: 0.4274\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8037 - accuracy: 0.5926 - val_loss: 1.1908 - val_accuracy: 0.4274\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8000 - accuracy: 0.5778 - val_loss: 1.1927 - val_accuracy: 0.4274\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8053 - accuracy: 0.5630 - val_loss: 1.1926 - val_accuracy: 0.4274\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8055 - accuracy: 0.5407 - val_loss: 1.1990 - val_accuracy: 0.4359\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8108 - accuracy: 0.5741 - val_loss: 1.1987 - val_accuracy: 0.4274\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8019 - accuracy: 0.5926 - val_loss: 1.1998 - val_accuracy: 0.4359\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8026 - accuracy: 0.5926 - val_loss: 1.1980 - val_accuracy: 0.4274\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8019 - accuracy: 0.5926 - val_loss: 1.1970 - val_accuracy: 0.4274\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8123 - accuracy: 0.5926 - val_loss: 1.1955 - val_accuracy: 0.4274\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8014 - accuracy: 0.5926 - val_loss: 1.1995 - val_accuracy: 0.4359\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8053 - accuracy: 0.5889 - val_loss: 1.1972 - val_accuracy: 0.4274\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8058 - accuracy: 0.5704 - val_loss: 1.2057 - val_accuracy: 0.4274\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8062 - accuracy: 0.5778 - val_loss: 1.1933 - val_accuracy: 0.4274\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8046 - accuracy: 0.5926 - val_loss: 1.1948 - val_accuracy: 0.4274\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8040 - accuracy: 0.5741 - val_loss: 1.2005 - val_accuracy: 0.4274\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.8038 - accuracy: 0.5741 - val_loss: 1.1968 - val_accuracy: 0.4274\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8054 - accuracy: 0.5926 - val_loss: 1.1954 - val_accuracy: 0.4274\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8091 - accuracy: 0.5926 - val_loss: 1.1971 - val_accuracy: 0.4274\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8035 - accuracy: 0.5741 - val_loss: 1.1953 - val_accuracy: 0.4274\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8028 - accuracy: 0.5704 - val_loss: 1.1960 - val_accuracy: 0.4274\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8049 - accuracy: 0.5926 - val_loss: 1.1955 - val_accuracy: 0.4274\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8015 - accuracy: 0.5963 - val_loss: 1.1985 - val_accuracy: 0.4359\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8047 - accuracy: 0.5852 - val_loss: 1.1920 - val_accuracy: 0.4274\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8045 - accuracy: 0.5926 - val_loss: 1.1928 - val_accuracy: 0.4274\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8011 - accuracy: 0.5926 - val_loss: 1.1954 - val_accuracy: 0.4274\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8055 - accuracy: 0.5926 - val_loss: 1.1974 - val_accuracy: 0.4274\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8040 - accuracy: 0.5852 - val_loss: 1.2061 - val_accuracy: 0.4359\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8047 - accuracy: 0.5704 - val_loss: 1.1946 - val_accuracy: 0.4274\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8027 - accuracy: 0.5926 - val_loss: 1.1910 - val_accuracy: 0.4274\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8005 - accuracy: 0.5926 - val_loss: 1.1936 - val_accuracy: 0.4274\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8041 - accuracy: 0.5889 - val_loss: 1.1922 - val_accuracy: 0.4274\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8055 - accuracy: 0.5519 - val_loss: 1.1990 - val_accuracy: 0.4274\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8058 - accuracy: 0.5963 - val_loss: 1.1933 - val_accuracy: 0.4274\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8069 - accuracy: 0.5926 - val_loss: 1.1991 - val_accuracy: 0.4274\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8028 - accuracy: 0.5926 - val_loss: 1.1956 - val_accuracy: 0.4274\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8057 - accuracy: 0.5889 - val_loss: 1.1939 - val_accuracy: 0.4274\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8007 - accuracy: 0.5704 - val_loss: 1.2004 - val_accuracy: 0.4274\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8032 - accuracy: 0.5926 - val_loss: 1.2010 - val_accuracy: 0.4274\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8061 - accuracy: 0.5926 - val_loss: 1.1978 - val_accuracy: 0.4274\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8037 - accuracy: 0.5926 - val_loss: 1.1969 - val_accuracy: 0.4359\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8036 - accuracy: 0.5926 - val_loss: 1.1974 - val_accuracy: 0.4274\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8046 - accuracy: 0.5926 - val_loss: 1.1989 - val_accuracy: 0.4274\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8019 - accuracy: 0.5815 - val_loss: 1.1980 - val_accuracy: 0.4274\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8038 - accuracy: 0.5741 - val_loss: 1.1995 - val_accuracy: 0.4274\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8038 - accuracy: 0.5778 - val_loss: 1.1982 - val_accuracy: 0.4274\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2014 - val_accuracy: 0.4274\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8011 - accuracy: 0.6000 - val_loss: 1.2121 - val_accuracy: 0.4274\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8035 - accuracy: 0.5741 - val_loss: 1.2003 - val_accuracy: 0.4274\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8034 - accuracy: 0.5926 - val_loss: 1.1977 - val_accuracy: 0.4274\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8005 - accuracy: 0.5926 - val_loss: 1.1994 - val_accuracy: 0.4274\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8058 - accuracy: 0.5926 - val_loss: 1.2021 - val_accuracy: 0.4359\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.2002 - val_accuracy: 0.4274\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8027 - accuracy: 0.5926 - val_loss: 1.2018 - val_accuracy: 0.4274\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8063 - accuracy: 0.5519 - val_loss: 1.2053 - val_accuracy: 0.4359\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8043 - accuracy: 0.5926 - val_loss: 1.1985 - val_accuracy: 0.4274\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8026 - accuracy: 0.5630 - val_loss: 1.1964 - val_accuracy: 0.4274\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8032 - accuracy: 0.5926 - val_loss: 1.2013 - val_accuracy: 0.4274\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8014 - accuracy: 0.5926 - val_loss: 1.1978 - val_accuracy: 0.4274\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8013 - accuracy: 0.5926 - val_loss: 1.1984 - val_accuracy: 0.4274\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8009 - accuracy: 0.5741 - val_loss: 1.1968 - val_accuracy: 0.4274\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8063 - accuracy: 0.5741 - val_loss: 1.1969 - val_accuracy: 0.4274\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8063 - accuracy: 0.6074 - val_loss: 1.1907 - val_accuracy: 0.4274\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8036 - accuracy: 0.5926 - val_loss: 1.1984 - val_accuracy: 0.4274\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8034 - accuracy: 0.5667 - val_loss: 1.2032 - val_accuracy: 0.4274\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8035 - accuracy: 0.5926 - val_loss: 1.1981 - val_accuracy: 0.4274\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8056 - accuracy: 0.5889 - val_loss: 1.1998 - val_accuracy: 0.4359\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7998 - accuracy: 0.5704 - val_loss: 1.2007 - val_accuracy: 0.4274\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8039 - accuracy: 0.5815 - val_loss: 1.2006 - val_accuracy: 0.4274\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8020 - accuracy: 0.5926 - val_loss: 1.1998 - val_accuracy: 0.4274\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8018 - accuracy: 0.5926 - val_loss: 1.2023 - val_accuracy: 0.4274\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 1.1976 - val_accuracy: 0.4274\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.1956 - val_accuracy: 0.4274\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.1992 - val_accuracy: 0.4274\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8017 - accuracy: 0.5926 - val_loss: 1.2034 - val_accuracy: 0.4274\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8008 - accuracy: 0.5926 - val_loss: 1.2009 - val_accuracy: 0.4274\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2004 - val_accuracy: 0.4274\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8033 - accuracy: 0.5667 - val_loss: 1.1992 - val_accuracy: 0.4274\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8022 - accuracy: 0.5926 - val_loss: 1.2003 - val_accuracy: 0.4274\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 1.2009 - val_accuracy: 0.4274\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8009 - accuracy: 0.5926 - val_loss: 1.2074 - val_accuracy: 0.4274\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8042 - accuracy: 0.5704 - val_loss: 1.2102 - val_accuracy: 0.4274\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7997 - accuracy: 0.5926 - val_loss: 1.2035 - val_accuracy: 0.4274\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8024 - accuracy: 0.5926 - val_loss: 1.1997 - val_accuracy: 0.4274\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8080 - accuracy: 0.5815 - val_loss: 1.2096 - val_accuracy: 0.4359\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8046 - accuracy: 0.6000 - val_loss: 1.2017 - val_accuracy: 0.4274\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.1998 - val_accuracy: 0.4274\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8048 - accuracy: 0.5926 - val_loss: 1.2033 - val_accuracy: 0.4274\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8015 - accuracy: 0.5926 - val_loss: 1.2067 - val_accuracy: 0.4274\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8031 - accuracy: 0.5926 - val_loss: 1.2029 - val_accuracy: 0.4274\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8012 - accuracy: 0.5815 - val_loss: 1.2076 - val_accuracy: 0.4274\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8045 - accuracy: 0.5704 - val_loss: 1.2047 - val_accuracy: 0.4359\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.7988 - accuracy: 0.5963 - val_loss: 1.2014 - val_accuracy: 0.4274\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8058 - accuracy: 0.5926 - val_loss: 1.1993 - val_accuracy: 0.4274\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8029 - accuracy: 0.5704 - val_loss: 1.2032 - val_accuracy: 0.4274\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 181us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.2059 - val_accuracy: 0.4274\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8060 - accuracy: 0.5926 - val_loss: 1.1985 - val_accuracy: 0.4274\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8080 - accuracy: 0.5407 - val_loss: 1.2130 - val_accuracy: 0.4274\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8056 - accuracy: 0.5778 - val_loss: 1.2002 - val_accuracy: 0.4274\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8045 - accuracy: 0.5926 - val_loss: 1.1971 - val_accuracy: 0.4274\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8028 - accuracy: 0.5926 - val_loss: 1.1988 - val_accuracy: 0.4359\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.2031 - val_accuracy: 0.4274\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.2028 - val_accuracy: 0.4274\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7998 - accuracy: 0.5926 - val_loss: 1.2008 - val_accuracy: 0.4274\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8050 - accuracy: 0.5926 - val_loss: 1.1982 - val_accuracy: 0.4274\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8010 - accuracy: 0.5926 - val_loss: 1.2047 - val_accuracy: 0.4274\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8018 - accuracy: 0.5630 - val_loss: 1.2057 - val_accuracy: 0.4274\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8070 - accuracy: 0.5926 - val_loss: 1.2033 - val_accuracy: 0.4274\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8033 - accuracy: 0.5926 - val_loss: 1.2079 - val_accuracy: 0.4274\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8068 - accuracy: 0.5407 - val_loss: 1.2091 - val_accuracy: 0.4274\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8044 - accuracy: 0.5926 - val_loss: 1.2014 - val_accuracy: 0.4274\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8024 - accuracy: 0.5963 - val_loss: 1.2036 - val_accuracy: 0.4274\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8010 - accuracy: 0.5926 - val_loss: 1.2016 - val_accuracy: 0.4274\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8025 - accuracy: 0.5630 - val_loss: 1.1916 - val_accuracy: 0.4274\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8109 - accuracy: 0.5926 - val_loss: 1.1966 - val_accuracy: 0.4274\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8078 - accuracy: 0.5667 - val_loss: 1.2066 - val_accuracy: 0.4359\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8115 - accuracy: 0.5704 - val_loss: 1.1962 - val_accuracy: 0.4274\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8074 - accuracy: 0.5852 - val_loss: 1.2051 - val_accuracy: 0.4274\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.2011 - val_accuracy: 0.4274\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.7997 - accuracy: 0.5926 - val_loss: 1.2065 - val_accuracy: 0.4274\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8015 - accuracy: 0.5704 - val_loss: 1.2030 - val_accuracy: 0.4274\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8070 - accuracy: 0.5667 - val_loss: 1.2071 - val_accuracy: 0.4359\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.7996 - accuracy: 0.6000 - val_loss: 1.2065 - val_accuracy: 0.4274\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8046 - accuracy: 0.5926 - val_loss: 1.2040 - val_accuracy: 0.4274\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8040 - accuracy: 0.5815 - val_loss: 1.2089 - val_accuracy: 0.4359\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8041 - accuracy: 0.5852 - val_loss: 1.2001 - val_accuracy: 0.4274\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8029 - accuracy: 0.5926 - val_loss: 1.2028 - val_accuracy: 0.4274\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8005 - accuracy: 0.5926 - val_loss: 1.2003 - val_accuracy: 0.4359\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8031 - accuracy: 0.5481 - val_loss: 1.1999 - val_accuracy: 0.4274\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8029 - accuracy: 0.5926 - val_loss: 1.2055 - val_accuracy: 0.4274\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8067 - accuracy: 0.5407 - val_loss: 1.2094 - val_accuracy: 0.4274\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8039 - accuracy: 0.5926 - val_loss: 1.2072 - val_accuracy: 0.4274\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8026 - accuracy: 0.5926 - val_loss: 1.2057 - val_accuracy: 0.4274\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8051 - accuracy: 0.5926 - val_loss: 1.2039 - val_accuracy: 0.4359\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8002 - accuracy: 0.5926 - val_loss: 1.2086 - val_accuracy: 0.4274\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8022 - accuracy: 0.5704 - val_loss: 1.2076 - val_accuracy: 0.4274\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8034 - accuracy: 0.5926 - val_loss: 1.2053 - val_accuracy: 0.4274\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8079 - accuracy: 0.5926 - val_loss: 1.2112 - val_accuracy: 0.4359\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8000 - accuracy: 0.5926 - val_loss: 1.2061 - val_accuracy: 0.4274\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8036 - accuracy: 0.5926 - val_loss: 1.2084 - val_accuracy: 0.4274\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8008 - accuracy: 0.5815 - val_loss: 1.2095 - val_accuracy: 0.4359\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8043 - accuracy: 0.5741 - val_loss: 1.2035 - val_accuracy: 0.4274\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8003 - accuracy: 0.5926 - val_loss: 1.2055 - val_accuracy: 0.4274\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7992 - accuracy: 0.5926 - val_loss: 1.2067 - val_accuracy: 0.4274\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2074 - val_accuracy: 0.4274\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8004 - accuracy: 0.5926 - val_loss: 1.2124 - val_accuracy: 0.4359\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8027 - accuracy: 0.5889 - val_loss: 1.2109 - val_accuracy: 0.4274\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8030 - accuracy: 0.5852 - val_loss: 1.2101 - val_accuracy: 0.4359\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8011 - accuracy: 0.5778 - val_loss: 1.2036 - val_accuracy: 0.4274\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2034 - val_accuracy: 0.4274\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8003 - accuracy: 0.5630 - val_loss: 1.2067 - val_accuracy: 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 282us/step - loss: 0.8024 - accuracy: 0.5926 - val_loss: 1.2115 - val_accuracy: 0.4274\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8008 - accuracy: 0.5926 - val_loss: 1.2068 - val_accuracy: 0.4274\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.8028 - accuracy: 0.5963 - val_loss: 1.2049 - val_accuracy: 0.4359\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8024 - accuracy: 0.5926 - val_loss: 1.2042 - val_accuracy: 0.4274\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8015 - accuracy: 0.5926 - val_loss: 1.2030 - val_accuracy: 0.4274\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8052 - accuracy: 0.5889 - val_loss: 1.2030 - val_accuracy: 0.4274\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.7998 - accuracy: 0.5815 - val_loss: 1.2089 - val_accuracy: 0.4274\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.2059 - val_accuracy: 0.4274\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7999 - accuracy: 0.5926 - val_loss: 1.2033 - val_accuracy: 0.4274\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8025 - accuracy: 0.5852 - val_loss: 1.2122 - val_accuracy: 0.4359\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8024 - accuracy: 0.5852 - val_loss: 1.2094 - val_accuracy: 0.4274\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 1.2062 - val_accuracy: 0.4274\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7994 - accuracy: 0.5926 - val_loss: 1.2075 - val_accuracy: 0.4274\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8001 - accuracy: 0.5926 - val_loss: 1.2023 - val_accuracy: 0.4274\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8038 - accuracy: 0.5852 - val_loss: 1.2106 - val_accuracy: 0.4274\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8028 - accuracy: 0.5778 - val_loss: 1.2067 - val_accuracy: 0.4274\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8023 - accuracy: 0.5667 - val_loss: 1.2081 - val_accuracy: 0.4274\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8040 - accuracy: 0.5889 - val_loss: 1.2050 - val_accuracy: 0.4359\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8044 - accuracy: 0.5926 - val_loss: 1.2037 - val_accuracy: 0.4274\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7993 - accuracy: 0.5889 - val_loss: 1.2137 - val_accuracy: 0.4274\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8029 - accuracy: 0.5741 - val_loss: 1.2119 - val_accuracy: 0.4274\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.7980 - accuracy: 0.6037 - val_loss: 1.2051 - val_accuracy: 0.4274\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8061 - accuracy: 0.5926 - val_loss: 1.2071 - val_accuracy: 0.4274\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8027 - accuracy: 0.5926 - val_loss: 1.2125 - val_accuracy: 0.4359\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.2067 - val_accuracy: 0.4274\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.7993 - accuracy: 0.5926 - val_loss: 1.2024 - val_accuracy: 0.4274\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8210 - accuracy: 0.5926 - val_loss: 1.2064 - val_accuracy: 0.4274\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8079 - accuracy: 0.5630 - val_loss: 1.2183 - val_accuracy: 0.4444\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8014 - accuracy: 0.5852 - val_loss: 1.2126 - val_accuracy: 0.4274\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8029 - accuracy: 0.5926 - val_loss: 1.2119 - val_accuracy: 0.4274\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8083 - accuracy: 0.5926 - val_loss: 1.2125 - val_accuracy: 0.4359\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8022 - accuracy: 0.5963 - val_loss: 1.2201 - val_accuracy: 0.4274\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8042 - accuracy: 0.5926 - val_loss: 1.2101 - val_accuracy: 0.4274\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8012 - accuracy: 0.5667 - val_loss: 1.2115 - val_accuracy: 0.4359\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8019 - accuracy: 0.5889 - val_loss: 1.2107 - val_accuracy: 0.4274\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8003 - accuracy: 0.5704 - val_loss: 1.2140 - val_accuracy: 0.4274\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7999 - accuracy: 0.5926 - val_loss: 1.2113 - val_accuracy: 0.4274\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8009 - accuracy: 0.5926 - val_loss: 1.2074 - val_accuracy: 0.4274\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8065 - accuracy: 0.5556 - val_loss: 1.2121 - val_accuracy: 0.4359\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8034 - accuracy: 0.5778 - val_loss: 1.2111 - val_accuracy: 0.4274\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7999 - accuracy: 0.5926 - val_loss: 1.2159 - val_accuracy: 0.4274\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8006 - accuracy: 0.5926 - val_loss: 1.2141 - val_accuracy: 0.4274\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8051 - accuracy: 0.5926 - val_loss: 1.2135 - val_accuracy: 0.4359\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8044 - accuracy: 0.5926 - val_loss: 1.2127 - val_accuracy: 0.4274\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7986 - accuracy: 0.5926 - val_loss: 1.2065 - val_accuracy: 0.4274\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8030 - accuracy: 0.5926 - val_loss: 1.2112 - val_accuracy: 0.4359\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8043 - accuracy: 0.5889 - val_loss: 1.2101 - val_accuracy: 0.4274\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8031 - accuracy: 0.5926 - val_loss: 1.2143 - val_accuracy: 0.4359\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.2102 - val_accuracy: 0.4274\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8005 - accuracy: 0.5926 - val_loss: 1.2081 - val_accuracy: 0.4274\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8001 - accuracy: 0.5926 - val_loss: 1.2081 - val_accuracy: 0.4274\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.7998 - accuracy: 0.5926 - val_loss: 1.2131 - val_accuracy: 0.4274\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8009 - accuracy: 0.5926 - val_loss: 1.2142 - val_accuracy: 0.4274\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8013 - accuracy: 0.5630 - val_loss: 1.2084 - val_accuracy: 0.4274\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7998 - accuracy: 0.5926 - val_loss: 1.2078 - val_accuracy: 0.4274\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2069 - val_accuracy: 0.4274\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8018 - accuracy: 0.5926 - val_loss: 1.2129 - val_accuracy: 0.4274\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8023 - accuracy: 0.5926 - val_loss: 1.2085 - val_accuracy: 0.4274\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8086 - accuracy: 0.5963 - val_loss: 1.2133 - val_accuracy: 0.4359\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8018 - accuracy: 0.5926 - val_loss: 1.2164 - val_accuracy: 0.4274\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8082 - accuracy: 0.5926 - val_loss: 1.2090 - val_accuracy: 0.4274\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8000 - accuracy: 0.5926 - val_loss: 1.2089 - val_accuracy: 0.4274\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7999 - accuracy: 0.5963 - val_loss: 1.2105 - val_accuracy: 0.4274\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7987 - accuracy: 0.5926 - val_loss: 1.2103 - val_accuracy: 0.4274\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8013 - accuracy: 0.5926 - val_loss: 1.2144 - val_accuracy: 0.4274\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8021 - accuracy: 0.5519 - val_loss: 1.2172 - val_accuracy: 0.4274\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7992 - accuracy: 0.5852 - val_loss: 1.2157 - val_accuracy: 0.4274\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 1.2130 - val_accuracy: 0.4274\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.7995 - accuracy: 0.5926 - val_loss: 1.2140 - val_accuracy: 0.4274\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7982 - accuracy: 0.5926 - val_loss: 1.2121 - val_accuracy: 0.4274\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.2073 - val_accuracy: 0.4274\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8120 - accuracy: 0.5519 - val_loss: 1.2196 - val_accuracy: 0.4274\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8056 - accuracy: 0.5741 - val_loss: 1.2118 - val_accuracy: 0.4274\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8021 - accuracy: 0.5926 - val_loss: 1.2101 - val_accuracy: 0.4274\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.7993 - accuracy: 0.5815 - val_loss: 1.2184 - val_accuracy: 0.4359\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7992 - accuracy: 0.5815 - val_loss: 1.2130 - val_accuracy: 0.4274\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8052 - accuracy: 0.5926 - val_loss: 1.2096 - val_accuracy: 0.4274\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8027 - accuracy: 0.5963 - val_loss: 1.2126 - val_accuracy: 0.4274\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8006 - accuracy: 0.5926 - val_loss: 1.2102 - val_accuracy: 0.4274\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8058 - accuracy: 0.5926 - val_loss: 1.2106 - val_accuracy: 0.4274\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8024 - accuracy: 0.5630 - val_loss: 1.2176 - val_accuracy: 0.4274\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8013 - accuracy: 0.5704 - val_loss: 1.2183 - val_accuracy: 0.4274\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8021 - accuracy: 0.5926 - val_loss: 1.2153 - val_accuracy: 0.4274\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7987 - accuracy: 0.5926 - val_loss: 1.2123 - val_accuracy: 0.4274\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7989 - accuracy: 0.5926 - val_loss: 1.2140 - val_accuracy: 0.4274\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8010 - accuracy: 0.5704 - val_loss: 1.2125 - val_accuracy: 0.4274\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8014 - accuracy: 0.5963 - val_loss: 1.2102 - val_accuracy: 0.4274\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8017 - accuracy: 0.5556 - val_loss: 1.2132 - val_accuracy: 0.4274\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8109 - accuracy: 0.5704 - val_loss: 1.2142 - val_accuracy: 0.4274\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7991 - accuracy: 0.5926 - val_loss: 1.2187 - val_accuracy: 0.4274\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8018 - accuracy: 0.5630 - val_loss: 1.2141 - val_accuracy: 0.4274\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8008 - accuracy: 0.5519 - val_loss: 1.2155 - val_accuracy: 0.4274\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8010 - accuracy: 0.5889 - val_loss: 1.2118 - val_accuracy: 0.4274\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2158 - val_accuracy: 0.4359\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8014 - accuracy: 0.5630 - val_loss: 1.2232 - val_accuracy: 0.4274\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8050 - accuracy: 0.5741 - val_loss: 1.2209 - val_accuracy: 0.4274\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.7998 - accuracy: 0.6037 - val_loss: 1.2174 - val_accuracy: 0.4274\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8003 - accuracy: 0.5926 - val_loss: 1.2142 - val_accuracy: 0.4274\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8006 - accuracy: 0.5926 - val_loss: 1.2147 - val_accuracy: 0.4274\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8003 - accuracy: 0.5741 - val_loss: 1.2180 - val_accuracy: 0.4274\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8051 - accuracy: 0.5815 - val_loss: 1.2126 - val_accuracy: 0.4274\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8021 - accuracy: 0.5926 - val_loss: 1.2166 - val_accuracy: 0.4274\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 1.2189 - val_accuracy: 0.4274\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8023 - accuracy: 0.5926 - val_loss: 1.2197 - val_accuracy: 0.4359\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.7977 - accuracy: 0.5889 - val_loss: 1.2190 - val_accuracy: 0.4274\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8026 - accuracy: 0.5926 - val_loss: 1.2130 - val_accuracy: 0.4274\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.2091 - val_accuracy: 0.4274\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8038 - accuracy: 0.5926 - val_loss: 1.2189 - val_accuracy: 0.4274\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8026 - accuracy: 0.5667 - val_loss: 1.2157 - val_accuracy: 0.4274\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8011 - accuracy: 0.5889 - val_loss: 1.2190 - val_accuracy: 0.4274\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 144us/step - loss: 0.8011 - accuracy: 0.5926 - val_loss: 1.2180 - val_accuracy: 0.4274\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8000 - accuracy: 0.5741 - val_loss: 1.2150 - val_accuracy: 0.4274\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8031 - accuracy: 0.5778 - val_loss: 1.2059 - val_accuracy: 0.4274\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8000 - accuracy: 0.5926 - val_loss: 1.2048 - val_accuracy: 0.4274\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8017 - accuracy: 0.5926 - val_loss: 1.2117 - val_accuracy: 0.4274\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.7998 - accuracy: 0.5926 - val_loss: 1.2109 - val_accuracy: 0.4274\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8021 - accuracy: 0.5630 - val_loss: 1.2171 - val_accuracy: 0.4274\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8037 - accuracy: 0.5778 - val_loss: 1.2127 - val_accuracy: 0.4274\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8005 - accuracy: 0.5926 - val_loss: 1.2192 - val_accuracy: 0.4274\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.7983 - accuracy: 0.5926 - val_loss: 1.2147 - val_accuracy: 0.4274\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 489us/step - loss: 0.8025 - accuracy: 0.5926 - val_loss: 1.2123 - val_accuracy: 0.4274\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7984 - accuracy: 0.5926 - val_loss: 1.2147 - val_accuracy: 0.4274\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7980 - accuracy: 0.5926 - val_loss: 1.2223 - val_accuracy: 0.4274\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8030 - accuracy: 0.5556 - val_loss: 1.2154 - val_accuracy: 0.4274\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8002 - accuracy: 0.5704 - val_loss: 1.2251 - val_accuracy: 0.4274\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8004 - accuracy: 0.5778 - val_loss: 1.2195 - val_accuracy: 0.4274\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7989 - accuracy: 0.5889 - val_loss: 1.2177 - val_accuracy: 0.4359\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8005 - accuracy: 0.5963 - val_loss: 1.2161 - val_accuracy: 0.4274\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8006 - accuracy: 0.5926 - val_loss: 1.2153 - val_accuracy: 0.4274\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.7993 - accuracy: 0.5704 - val_loss: 1.2187 - val_accuracy: 0.4274\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2215 - val_accuracy: 0.4274\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7997 - accuracy: 0.5926 - val_loss: 1.2179 - val_accuracy: 0.4274\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7998 - accuracy: 0.5926 - val_loss: 1.2175 - val_accuracy: 0.4359\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8009 - accuracy: 0.5778 - val_loss: 1.2235 - val_accuracy: 0.4274\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8022 - accuracy: 0.5741 - val_loss: 1.2188 - val_accuracy: 0.4274\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8014 - accuracy: 0.5926 - val_loss: 1.2202 - val_accuracy: 0.4274\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8031 - accuracy: 0.5889 - val_loss: 1.2279 - val_accuracy: 0.4444\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8008 - accuracy: 0.5778 - val_loss: 1.2177 - val_accuracy: 0.4274\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8050 - accuracy: 0.5926 - val_loss: 1.2197 - val_accuracy: 0.4274\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 1.2238 - val_accuracy: 0.4274\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8020 - accuracy: 0.5704 - val_loss: 1.2245 - val_accuracy: 0.4274\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.7998 - accuracy: 0.5630 - val_loss: 1.2195 - val_accuracy: 0.4274\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.7996 - accuracy: 0.5926 - val_loss: 1.2156 - val_accuracy: 0.4274\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.7979 - accuracy: 0.5852 - val_loss: 1.2211 - val_accuracy: 0.4274\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8031 - accuracy: 0.5481 - val_loss: 1.2224 - val_accuracy: 0.4359\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7979 - accuracy: 0.5926 - val_loss: 1.2233 - val_accuracy: 0.4274\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8016 - accuracy: 0.5926 - val_loss: 1.2229 - val_accuracy: 0.4274\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8098 - accuracy: 0.5926 - val_loss: 1.2184 - val_accuracy: 0.4274\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.7976 - accuracy: 0.5889 - val_loss: 1.2270 - val_accuracy: 0.4274\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8018 - accuracy: 0.5778 - val_loss: 1.2239 - val_accuracy: 0.4274\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8003 - accuracy: 0.5815 - val_loss: 1.2152 - val_accuracy: 0.4274\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7993 - accuracy: 0.5926 - val_loss: 1.2159 - val_accuracy: 0.4274\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8030 - accuracy: 0.5667 - val_loss: 1.2228 - val_accuracy: 0.4359\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8017 - accuracy: 0.5778 - val_loss: 1.2176 - val_accuracy: 0.4274\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8002 - accuracy: 0.5926 - val_loss: 1.2192 - val_accuracy: 0.4274\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8012 - accuracy: 0.5630 - val_loss: 1.2274 - val_accuracy: 0.4274\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8060 - accuracy: 0.5926 - val_loss: 1.2204 - val_accuracy: 0.4274\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8070 - accuracy: 0.5556 - val_loss: 1.2248 - val_accuracy: 0.4359\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.7987 - accuracy: 0.5852 - val_loss: 1.2155 - val_accuracy: 0.4274\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8022 - accuracy: 0.5926 - val_loss: 1.2165 - val_accuracy: 0.4274\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8006 - accuracy: 0.5926 - val_loss: 1.2209 - val_accuracy: 0.4274\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7992 - accuracy: 0.5926 - val_loss: 1.2219 - val_accuracy: 0.4274\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8012 - accuracy: 0.5963 - val_loss: 1.2201 - val_accuracy: 0.4274\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8009 - accuracy: 0.5926 - val_loss: 1.2228 - val_accuracy: 0.4274\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7993 - accuracy: 0.5926 - val_loss: 1.2173 - val_accuracy: 0.4274\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8034 - accuracy: 0.5630 - val_loss: 1.2208 - val_accuracy: 0.4274\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.7979 - accuracy: 0.5926 - val_loss: 1.2218 - val_accuracy: 0.4274\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8008 - accuracy: 0.5926 - val_loss: 1.2218 - val_accuracy: 0.4274\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8003 - accuracy: 0.5926 - val_loss: 1.2204 - val_accuracy: 0.4274\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7992 - accuracy: 0.5926 - val_loss: 1.2210 - val_accuracy: 0.4274\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.7993 - accuracy: 0.5926 - val_loss: 1.2163 - val_accuracy: 0.4274\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 248us/step - loss: 0.8004 - accuracy: 0.5926 - val_loss: 1.2171 - val_accuracy: 0.4274\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 58.42%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [6.8182690e-02, 8.5986780e-01, 7.1949480e-02],\n",
       "       [6.2268910e-01, 2.8518075e-01, 9.2130050e-02],\n",
       "       [6.8591950e-04, 7.8775187e-04, 9.9852633e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [7.9174160e-03, 2.4257533e-02, 9.6782506e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [2.9292464e-02, 1.8446264e-01, 7.8624487e-01],\n",
       "       [2.5603467e-01, 6.2875860e-02, 6.8108946e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.6901304e-01, 7.4548430e-02, 7.5643850e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.0941633e-05, 8.1089765e-06, 9.9998090e-01],\n",
       "       [7.2926060e-04, 5.6405934e-03, 9.9363010e-01],\n",
       "       [3.1739306e-01, 4.2363402e-01, 2.5897294e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.1224116e-03, 2.0826228e-01, 7.9061530e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.0821265e-03, 8.8765650e-01, 1.1126135e-01],\n",
       "       [1.0874787e-02, 6.3070540e-01, 3.5841972e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [9.8244240e-01, 1.9925663e-03, 1.5564967e-02],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.0753356e-01, 1.4092480e-01, 7.5154170e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [6.2268910e-01, 2.8518075e-01, 9.2130050e-02],\n",
       "       [1.0268954e-03, 1.0029237e-03, 9.9797016e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [6.2268910e-01, 2.8518075e-01, 9.2130050e-02],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.1224116e-03, 2.0826228e-01, 7.9061530e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [4.3241537e-01, 2.3519428e-01, 3.3239037e-01],\n",
       "       [6.2268910e-01, 2.8518075e-01, 9.2130050e-02],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [2.5603467e-01, 6.2875860e-02, 6.8108946e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [2.9292464e-02, 1.8446264e-01, 7.8624487e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.3470599e-01, 4.2020700e-01, 4.4508700e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [7.2926060e-04, 5.6405934e-03, 9.9363010e-01],\n",
       "       [4.1654752e-05, 4.9749815e-07, 9.9995780e-01],\n",
       "       [1.0190089e-03, 9.4354210e-07, 9.9898000e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [7.1729475e-01, 1.5175846e-01, 1.3094673e-01],\n",
       "       [2.5603467e-01, 6.2875860e-02, 6.8108946e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.0874787e-02, 6.3070540e-01, 3.5841972e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [2.9292464e-02, 1.8446264e-01, 7.8624487e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [2.9292464e-02, 1.8446264e-01, 7.8624487e-01],\n",
       "       [4.8279120e-01, 2.7384590e-01, 2.4336290e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [9.8244240e-01, 1.9925663e-03, 1.5564967e-02],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [3.6643374e-01, 4.0954033e-01, 2.2402598e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01],\n",
       "       [1.0190089e-03, 9.4354210e-07, 9.9898000e-01],\n",
       "       [6.8591950e-04, 7.8775187e-04, 9.9852633e-01],\n",
       "       [1.8853603e-01, 5.4545030e-01, 2.6601360e-01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375191759807145"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375191759807145"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871301775147929"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037399122427101535"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6871301775147929"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037399122427101535"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 51.71%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.03893348678044613\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 56.00%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.014425634\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 18\n",
      "selected features: 15\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 15, 17]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTAATTTAATAGA', 'TTAACATAATAAT', 'TGCAATCTCTTTAT',\n",
       "       'TATTATGTTAATG', 'TACATACCGAT', 'GTGTATCATAAT', 'GCAAACATGCG',\n",
       "       'GAGTCCTGTT', 'GAGTCCTGTTT',\n",
       "       'GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG',\n",
       "       'CTTTTTCACCTGT', 'CTTGTGAATTTAG',\n",
       "       'CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG',\n",
       "       'CGCCATTATGTT', 'ACAATTACTATATTT'], dtype='<U99')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>GAGTCCTGTTT</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>CTTTTTCACCTGT</th>\n",
       "      <th>CTTGTGAATTTAG</th>\n",
       "      <th>CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG</th>\n",
       "      <th>CGCCATTATGTT</th>\n",
       "      <th>ACAATTACTATATTT</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  TATTATGTTAATG  TACATACCGAT  \\\n",
       "0                1              1               1              1            1   \n",
       "1                1              1               1              1            1   \n",
       "2                1              1               1              1            1   \n",
       "3                1              1               1              1            1   \n",
       "4                1              1               1              1            1   \n",
       "..             ...            ...             ...            ...          ...   \n",
       "248              1              1               1              1            1   \n",
       "249              1              1               1              1            1   \n",
       "250              1              1               1              1            1   \n",
       "251              1              1               1              1            1   \n",
       "252              1              1               1              1            1   \n",
       "\n",
       "     GTGTATCATAAT  GCAAACATGCG  GAGTCCTGTT  GAGTCCTGTTT  \\\n",
       "0               1            1           1            1   \n",
       "1               1            1           1            1   \n",
       "2               1            1           1            1   \n",
       "3               1            1           1            1   \n",
       "4               1            1           1            1   \n",
       "..            ...          ...         ...          ...   \n",
       "248             1            1           1            1   \n",
       "249             1            1           1            1   \n",
       "250             1            1           1            1   \n",
       "251             1            1           1            1   \n",
       "252             1            1           1            1   \n",
       "\n",
       "     GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                    0                                                     \n",
       "1                                                    0                                                     \n",
       "2                                                    0                                                     \n",
       "3                                                    0                                                     \n",
       "4                                                    0                                                     \n",
       "..                                                 ...                                                     \n",
       "248                                                  0                                                     \n",
       "249                                                  0                                                     \n",
       "250                                                  0                                                     \n",
       "251                                                  0                                                     \n",
       "252                                                  0                                                     \n",
       "\n",
       "     CTTTTTCACCTGT  CTTGTGAATTTAG  \\\n",
       "0                1              1   \n",
       "1                1              1   \n",
       "2                1              1   \n",
       "3                1              1   \n",
       "4                1              1   \n",
       "..             ...            ...   \n",
       "248              1              1   \n",
       "249              1              1   \n",
       "250              1              1   \n",
       "251              1              1   \n",
       "252              1              1   \n",
       "\n",
       "     CTTATAACAATTACTATATTTGGCATTATATGTAGTATTATTTTCACGAG  CGCCATTATGTT  \\\n",
       "0                                                    1              0   \n",
       "1                                                    1              0   \n",
       "2                                                    1              1   \n",
       "3                                                    1              0   \n",
       "4                                                    1              0   \n",
       "..                                                 ...            ...   \n",
       "248                                                  1              0   \n",
       "249                                                  1              0   \n",
       "250                                                  1              0   \n",
       "251                                                  1              0   \n",
       "252                                                  1              0   \n",
       "\n",
       "     ACAATTACTATATTT  pheno  strain  \n",
       "0                  1      1     107  \n",
       "1                  1      0     109  \n",
       "2                  1      1     115  \n",
       "3                  1      1  120335  \n",
       "4                  1      1  120337  \n",
       "..               ...    ...     ...  \n",
       "248                1      1  SR4152  \n",
       "249                1      0  SR4153  \n",
       "250                1      0  SR4155  \n",
       "251                1      0  SR4156  \n",
       "252                1      0  SR4187  \n",
       "\n",
       "[253 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 16) (253,) (253, 17)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS245     1\n",
       "1          NY439     2\n",
       "2          CA544     1\n",
       "3          CA541     2\n",
       "4          EUH15     1\n",
       "..           ...   ...\n",
       "112       NRS112     0\n",
       "113     CFBRSa51     2\n",
       "114       NRS383     1\n",
       "115       NRS247     0\n",
       "116  CFBREBSa103     0\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 486us/step - loss: 1.1115 - accuracy: 0.3222 - val_loss: 1.0999 - val_accuracy: 0.3504\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 1.1029 - accuracy: 0.3444 - val_loss: 1.0936 - val_accuracy: 0.3932\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.0954 - accuracy: 0.3741 - val_loss: 1.0868 - val_accuracy: 0.3932\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 1.0880 - accuracy: 0.4037 - val_loss: 1.0795 - val_accuracy: 0.4530\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0800 - accuracy: 0.4185 - val_loss: 1.0731 - val_accuracy: 0.4615\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 1.0733 - accuracy: 0.4296 - val_loss: 1.0669 - val_accuracy: 0.4615\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 1.0665 - accuracy: 0.4593 - val_loss: 1.0606 - val_accuracy: 0.4615\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0592 - accuracy: 0.4593 - val_loss: 1.0558 - val_accuracy: 0.4615\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 1.0544 - accuracy: 0.4593 - val_loss: 1.0512 - val_accuracy: 0.4444\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 1.0491 - accuracy: 0.4519 - val_loss: 1.0463 - val_accuracy: 0.4444\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0456 - accuracy: 0.4630 - val_loss: 1.0422 - val_accuracy: 0.4615\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0416 - accuracy: 0.4296 - val_loss: 1.0389 - val_accuracy: 0.4615\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 1.0367 - accuracy: 0.4667 - val_loss: 1.0365 - val_accuracy: 0.4615\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 1.0320 - accuracy: 0.4741 - val_loss: 1.0343 - val_accuracy: 0.4701\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 1.0275 - accuracy: 0.4852 - val_loss: 1.0317 - val_accuracy: 0.4872\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0234 - accuracy: 0.4889 - val_loss: 1.0293 - val_accuracy: 0.5043\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 1.0211 - accuracy: 0.4778 - val_loss: 1.0281 - val_accuracy: 0.4872\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.0172 - accuracy: 0.4593 - val_loss: 1.0257 - val_accuracy: 0.5043\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 1.0138 - accuracy: 0.4852 - val_loss: 1.0237 - val_accuracy: 0.4444\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 1.0112 - accuracy: 0.4630 - val_loss: 1.0215 - val_accuracy: 0.4444\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 1.0092 - accuracy: 0.4704 - val_loss: 1.0171 - val_accuracy: 0.5128\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 1.0046 - accuracy: 0.4926 - val_loss: 1.0141 - val_accuracy: 0.5128\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 1.0025 - accuracy: 0.4926 - val_loss: 1.0110 - val_accuracy: 0.5043\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9999 - accuracy: 0.4926 - val_loss: 1.0086 - val_accuracy: 0.5128\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9974 - accuracy: 0.4926 - val_loss: 1.0063 - val_accuracy: 0.5128\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9954 - accuracy: 0.4926 - val_loss: 1.0044 - val_accuracy: 0.5043\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9920 - accuracy: 0.4926 - val_loss: 1.0021 - val_accuracy: 0.5128\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9925 - accuracy: 0.4926 - val_loss: 1.0013 - val_accuracy: 0.5128\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9907 - accuracy: 0.4926 - val_loss: 1.0004 - val_accuracy: 0.5128\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9888 - accuracy: 0.4926 - val_loss: 0.9977 - val_accuracy: 0.5043\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9864 - accuracy: 0.4926 - val_loss: 0.9952 - val_accuracy: 0.5043\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9842 - accuracy: 0.4926 - val_loss: 0.9940 - val_accuracy: 0.5043\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9825 - accuracy: 0.4926 - val_loss: 0.9941 - val_accuracy: 0.5043\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.9831 - accuracy: 0.4926 - val_loss: 0.9941 - val_accuracy: 0.5043\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9809 - accuracy: 0.4926 - val_loss: 0.9933 - val_accuracy: 0.5043\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9783 - accuracy: 0.5074 - val_loss: 0.9934 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9774 - accuracy: 0.5037 - val_loss: 0.9932 - val_accuracy: 0.5043\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9759 - accuracy: 0.5037 - val_loss: 0.9927 - val_accuracy: 0.5043\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9752 - accuracy: 0.5037 - val_loss: 0.9913 - val_accuracy: 0.5043\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9743 - accuracy: 0.5037 - val_loss: 0.9905 - val_accuracy: 0.5043\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9738 - accuracy: 0.5037 - val_loss: 0.9893 - val_accuracy: 0.5214\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9722 - accuracy: 0.5111 - val_loss: 0.9888 - val_accuracy: 0.5214\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9716 - accuracy: 0.5111 - val_loss: 0.9896 - val_accuracy: 0.5214\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9708 - accuracy: 0.5111 - val_loss: 0.9888 - val_accuracy: 0.5214\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.9692 - accuracy: 0.5111 - val_loss: 0.9893 - val_accuracy: 0.5214\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9699 - accuracy: 0.5111 - val_loss: 0.9895 - val_accuracy: 0.5214\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9691 - accuracy: 0.5111 - val_loss: 0.9861 - val_accuracy: 0.5214\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9674 - accuracy: 0.5111 - val_loss: 0.9845 - val_accuracy: 0.5214\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9661 - accuracy: 0.5111 - val_loss: 0.9852 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9652 - accuracy: 0.5222 - val_loss: 0.9861 - val_accuracy: 0.5214\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9653 - accuracy: 0.5185 - val_loss: 0.9863 - val_accuracy: 0.5214\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9635 - accuracy: 0.5222 - val_loss: 0.9849 - val_accuracy: 0.5214\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9652 - accuracy: 0.5222 - val_loss: 0.9843 - val_accuracy: 0.5214\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9631 - accuracy: 0.5222 - val_loss: 0.9844 - val_accuracy: 0.5214\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9632 - accuracy: 0.5185 - val_loss: 0.9848 - val_accuracy: 0.5214\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9616 - accuracy: 0.5222 - val_loss: 0.9830 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9610 - accuracy: 0.5222 - val_loss: 0.9826 - val_accuracy: 0.5214\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9606 - accuracy: 0.5222 - val_loss: 0.9828 - val_accuracy: 0.5214\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9599 - accuracy: 0.5222 - val_loss: 0.9840 - val_accuracy: 0.5214\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9596 - accuracy: 0.5222 - val_loss: 0.9841 - val_accuracy: 0.5043\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9597 - accuracy: 0.4741 - val_loss: 0.9824 - val_accuracy: 0.5214\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9585 - accuracy: 0.5222 - val_loss: 0.9820 - val_accuracy: 0.5214\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9585 - accuracy: 0.5185 - val_loss: 0.9828 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9578 - accuracy: 0.5185 - val_loss: 0.9817 - val_accuracy: 0.5214\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9568 - accuracy: 0.5185 - val_loss: 0.9819 - val_accuracy: 0.5214\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9566 - accuracy: 0.5222 - val_loss: 0.9823 - val_accuracy: 0.5214\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9568 - accuracy: 0.5222 - val_loss: 0.9822 - val_accuracy: 0.5214\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9570 - accuracy: 0.5222 - val_loss: 0.9815 - val_accuracy: 0.5214\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9565 - accuracy: 0.5222 - val_loss: 0.9806 - val_accuracy: 0.5214\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9553 - accuracy: 0.5222 - val_loss: 0.9788 - val_accuracy: 0.5214\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9551 - accuracy: 0.5222 - val_loss: 0.9780 - val_accuracy: 0.5214\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9558 - accuracy: 0.5222 - val_loss: 0.9782 - val_accuracy: 0.5214\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9546 - accuracy: 0.4963 - val_loss: 0.9791 - val_accuracy: 0.5043\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9537 - accuracy: 0.5111 - val_loss: 0.9792 - val_accuracy: 0.5214\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9534 - accuracy: 0.5222 - val_loss: 0.9796 - val_accuracy: 0.5214\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9530 - accuracy: 0.5222 - val_loss: 0.9804 - val_accuracy: 0.5214\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9527 - accuracy: 0.5222 - val_loss: 0.9797 - val_accuracy: 0.5214\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9521 - accuracy: 0.5185 - val_loss: 0.9799 - val_accuracy: 0.5214\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9521 - accuracy: 0.4852 - val_loss: 0.9817 - val_accuracy: 0.5043\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9544 - accuracy: 0.5148 - val_loss: 0.9841 - val_accuracy: 0.5214\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9538 - accuracy: 0.5148 - val_loss: 0.9809 - val_accuracy: 0.5214\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9522 - accuracy: 0.5185 - val_loss: 0.9794 - val_accuracy: 0.5214\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9510 - accuracy: 0.5296 - val_loss: 0.9796 - val_accuracy: 0.5043\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9504 - accuracy: 0.5037 - val_loss: 0.9791 - val_accuracy: 0.5214\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.9499 - accuracy: 0.5185 - val_loss: 0.9788 - val_accuracy: 0.5214\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9516 - accuracy: 0.5259 - val_loss: 0.9786 - val_accuracy: 0.5043\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9510 - accuracy: 0.5111 - val_loss: 0.9782 - val_accuracy: 0.5043\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9495 - accuracy: 0.5074 - val_loss: 0.9782 - val_accuracy: 0.5043\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9519 - accuracy: 0.5000 - val_loss: 0.9795 - val_accuracy: 0.5214\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9488 - accuracy: 0.5185 - val_loss: 0.9781 - val_accuracy: 0.5214\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9476 - accuracy: 0.5185 - val_loss: 0.9768 - val_accuracy: 0.5214\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9490 - accuracy: 0.5185 - val_loss: 0.9774 - val_accuracy: 0.5214\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9484 - accuracy: 0.5222 - val_loss: 0.9769 - val_accuracy: 0.5214\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9474 - accuracy: 0.5222 - val_loss: 0.9759 - val_accuracy: 0.5214\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9473 - accuracy: 0.5185 - val_loss: 0.9768 - val_accuracy: 0.5214\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9467 - accuracy: 0.5185 - val_loss: 0.9758 - val_accuracy: 0.5214\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9476 - accuracy: 0.5185 - val_loss: 0.9748 - val_accuracy: 0.5214\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9471 - accuracy: 0.5185 - val_loss: 0.9765 - val_accuracy: 0.5214\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9462 - accuracy: 0.5185 - val_loss: 0.9764 - val_accuracy: 0.5214\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9462 - accuracy: 0.5222 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9465 - accuracy: 0.5222 - val_loss: 0.9767 - val_accuracy: 0.5214\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9458 - accuracy: 0.5222 - val_loss: 0.9766 - val_accuracy: 0.5214\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9454 - accuracy: 0.5185 - val_loss: 0.9762 - val_accuracy: 0.5214\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9453 - accuracy: 0.5185 - val_loss: 0.9761 - val_accuracy: 0.5214\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9441 - accuracy: 0.5185 - val_loss: 0.9764 - val_accuracy: 0.5214\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9439 - accuracy: 0.5185 - val_loss: 0.9770 - val_accuracy: 0.5214\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9439 - accuracy: 0.5185 - val_loss: 0.9765 - val_accuracy: 0.5214\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9437 - accuracy: 0.5222 - val_loss: 0.9762 - val_accuracy: 0.5214\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9439 - accuracy: 0.5222 - val_loss: 0.9759 - val_accuracy: 0.5214\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9432 - accuracy: 0.5222 - val_loss: 0.9756 - val_accuracy: 0.5214\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9441 - accuracy: 0.4778 - val_loss: 0.9764 - val_accuracy: 0.5043\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9433 - accuracy: 0.5111 - val_loss: 0.9761 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9421 - accuracy: 0.5370 - val_loss: 0.9759 - val_accuracy: 0.5214\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9430 - accuracy: 0.5222 - val_loss: 0.9773 - val_accuracy: 0.5214\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9423 - accuracy: 0.5222 - val_loss: 0.9796 - val_accuracy: 0.5214\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9432 - accuracy: 0.5185 - val_loss: 0.9811 - val_accuracy: 0.5214\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9431 - accuracy: 0.5185 - val_loss: 0.9787 - val_accuracy: 0.5214\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9411 - accuracy: 0.5037 - val_loss: 0.9778 - val_accuracy: 0.5043\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9423 - accuracy: 0.5074 - val_loss: 0.9769 - val_accuracy: 0.5043\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 431us/step - loss: 0.9427 - accuracy: 0.5111 - val_loss: 0.9762 - val_accuracy: 0.5043\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9428 - accuracy: 0.5111 - val_loss: 0.9766 - val_accuracy: 0.5043\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9414 - accuracy: 0.5111 - val_loss: 0.9763 - val_accuracy: 0.5214\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9395 - accuracy: 0.5222 - val_loss: 0.9768 - val_accuracy: 0.5214\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9398 - accuracy: 0.5185 - val_loss: 0.9795 - val_accuracy: 0.5214\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9403 - accuracy: 0.5185 - val_loss: 0.9800 - val_accuracy: 0.5214\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9410 - accuracy: 0.5185 - val_loss: 0.9781 - val_accuracy: 0.5214\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9396 - accuracy: 0.5185 - val_loss: 0.9742 - val_accuracy: 0.5214\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9419 - accuracy: 0.5222 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9403 - accuracy: 0.5296 - val_loss: 0.9755 - val_accuracy: 0.5214\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9394 - accuracy: 0.5000 - val_loss: 0.9754 - val_accuracy: 0.5043\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9386 - accuracy: 0.5148 - val_loss: 0.9744 - val_accuracy: 0.5214\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9382 - accuracy: 0.5222 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9374 - accuracy: 0.5222 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9383 - accuracy: 0.5185 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9371 - accuracy: 0.5185 - val_loss: 0.9746 - val_accuracy: 0.5214\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9369 - accuracy: 0.5185 - val_loss: 0.9748 - val_accuracy: 0.5214\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9370 - accuracy: 0.5185 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9367 - accuracy: 0.5185 - val_loss: 0.9731 - val_accuracy: 0.5043\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9369 - accuracy: 0.5148 - val_loss: 0.9722 - val_accuracy: 0.5043\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9369 - accuracy: 0.5185 - val_loss: 0.9717 - val_accuracy: 0.5214\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9372 - accuracy: 0.5296 - val_loss: 0.9723 - val_accuracy: 0.5214\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9377 - accuracy: 0.5296 - val_loss: 0.9723 - val_accuracy: 0.5214\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9382 - accuracy: 0.5296 - val_loss: 0.9728 - val_accuracy: 0.5214\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9398 - accuracy: 0.5222 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9374 - accuracy: 0.5222 - val_loss: 0.9739 - val_accuracy: 0.5214\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9362 - accuracy: 0.5222 - val_loss: 0.9727 - val_accuracy: 0.5214\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9348 - accuracy: 0.5222 - val_loss: 0.9714 - val_accuracy: 0.5214\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9349 - accuracy: 0.5222 - val_loss: 0.9718 - val_accuracy: 0.5043\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9373 - accuracy: 0.5185 - val_loss: 0.9730 - val_accuracy: 0.5043\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9377 - accuracy: 0.5148 - val_loss: 0.9766 - val_accuracy: 0.5043\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9379 - accuracy: 0.5148 - val_loss: 0.9765 - val_accuracy: 0.5043\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9349 - accuracy: 0.5074 - val_loss: 0.9742 - val_accuracy: 0.5214\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9347 - accuracy: 0.5296 - val_loss: 0.9742 - val_accuracy: 0.5214\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9339 - accuracy: 0.5296 - val_loss: 0.9737 - val_accuracy: 0.5214\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9361 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9373 - accuracy: 0.5296 - val_loss: 0.9729 - val_accuracy: 0.5214\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9344 - accuracy: 0.5296 - val_loss: 0.9737 - val_accuracy: 0.5214\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9347 - accuracy: 0.5296 - val_loss: 0.9790 - val_accuracy: 0.5214\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9356 - accuracy: 0.5185 - val_loss: 0.9818 - val_accuracy: 0.5214\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9366 - accuracy: 0.5185 - val_loss: 0.9796 - val_accuracy: 0.5214\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9331 - accuracy: 0.5259 - val_loss: 0.9761 - val_accuracy: 0.5214\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9326 - accuracy: 0.5296 - val_loss: 0.9747 - val_accuracy: 0.5214\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9340 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9337 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.9316 - accuracy: 0.5333 - val_loss: 0.9753 - val_accuracy: 0.5043\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9320 - accuracy: 0.5185 - val_loss: 0.9760 - val_accuracy: 0.5043\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9317 - accuracy: 0.5222 - val_loss: 0.9760 - val_accuracy: 0.5214\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9322 - accuracy: 0.5296 - val_loss: 0.9765 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9317 - accuracy: 0.5259 - val_loss: 0.9751 - val_accuracy: 0.5214\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9311 - accuracy: 0.5259 - val_loss: 0.9739 - val_accuracy: 0.5214\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9319 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5214\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9312 - accuracy: 0.5296 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9313 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9341 - accuracy: 0.5296 - val_loss: 0.9725 - val_accuracy: 0.5214\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9316 - accuracy: 0.5296 - val_loss: 0.9719 - val_accuracy: 0.5214\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9307 - accuracy: 0.5148 - val_loss: 0.9728 - val_accuracy: 0.5043\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9305 - accuracy: 0.5185 - val_loss: 0.9741 - val_accuracy: 0.5043\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9297 - accuracy: 0.5333 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9302 - accuracy: 0.5296 - val_loss: 0.9744 - val_accuracy: 0.5214\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9290 - accuracy: 0.5296 - val_loss: 0.9733 - val_accuracy: 0.5214\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9305 - accuracy: 0.5185 - val_loss: 0.9727 - val_accuracy: 0.5043\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9299 - accuracy: 0.5185 - val_loss: 0.9748 - val_accuracy: 0.5043\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9304 - accuracy: 0.5185 - val_loss: 0.9768 - val_accuracy: 0.5043\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9314 - accuracy: 0.5148 - val_loss: 0.9776 - val_accuracy: 0.5043\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9304 - accuracy: 0.5111 - val_loss: 0.9751 - val_accuracy: 0.5214\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9286 - accuracy: 0.5296 - val_loss: 0.9742 - val_accuracy: 0.5214\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9286 - accuracy: 0.5296 - val_loss: 0.9732 - val_accuracy: 0.5214\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9279 - accuracy: 0.5296 - val_loss: 0.9735 - val_accuracy: 0.5214\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9276 - accuracy: 0.5296 - val_loss: 0.9743 - val_accuracy: 0.5214\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9277 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5214\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9274 - accuracy: 0.5296 - val_loss: 0.9736 - val_accuracy: 0.5214\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9288 - accuracy: 0.5000 - val_loss: 0.9737 - val_accuracy: 0.5043\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9281 - accuracy: 0.5185 - val_loss: 0.9748 - val_accuracy: 0.5043\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9269 - accuracy: 0.5259 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9272 - accuracy: 0.5296 - val_loss: 0.9745 - val_accuracy: 0.5214\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9262 - accuracy: 0.5296 - val_loss: 0.9756 - val_accuracy: 0.5214\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9275 - accuracy: 0.5296 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9267 - accuracy: 0.5296 - val_loss: 0.9719 - val_accuracy: 0.5214\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9259 - accuracy: 0.5296 - val_loss: 0.9715 - val_accuracy: 0.5214\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9267 - accuracy: 0.5296 - val_loss: 0.9714 - val_accuracy: 0.5214\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9255 - accuracy: 0.5296 - val_loss: 0.9693 - val_accuracy: 0.5214\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9273 - accuracy: 0.5333 - val_loss: 0.9698 - val_accuracy: 0.5214\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9267 - accuracy: 0.5333 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9258 - accuracy: 0.5296 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9253 - accuracy: 0.5296 - val_loss: 0.9708 - val_accuracy: 0.5214\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9253 - accuracy: 0.4963 - val_loss: 0.9713 - val_accuracy: 0.5043\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9248 - accuracy: 0.5185 - val_loss: 0.9721 - val_accuracy: 0.5214\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9247 - accuracy: 0.5296 - val_loss: 0.9739 - val_accuracy: 0.5214\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9246 - accuracy: 0.5296 - val_loss: 0.9751 - val_accuracy: 0.5214\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9251 - accuracy: 0.5296 - val_loss: 0.9752 - val_accuracy: 0.5214\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9256 - accuracy: 0.5296 - val_loss: 0.9732 - val_accuracy: 0.5043\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9246 - accuracy: 0.5185 - val_loss: 0.9723 - val_accuracy: 0.5043\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9247 - accuracy: 0.5185 - val_loss: 0.9714 - val_accuracy: 0.5043\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9241 - accuracy: 0.5333 - val_loss: 0.9708 - val_accuracy: 0.5214\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9244 - accuracy: 0.5333 - val_loss: 0.9704 - val_accuracy: 0.5214\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9248 - accuracy: 0.5333 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9242 - accuracy: 0.5296 - val_loss: 0.9716 - val_accuracy: 0.5214\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9247 - accuracy: 0.5296 - val_loss: 0.9713 - val_accuracy: 0.5214\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9237 - accuracy: 0.5296 - val_loss: 0.9694 - val_accuracy: 0.5214\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9253 - accuracy: 0.5333 - val_loss: 0.9713 - val_accuracy: 0.5214\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9269 - accuracy: 0.5333 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9250 - accuracy: 0.5333 - val_loss: 0.9700 - val_accuracy: 0.5214\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9226 - accuracy: 0.5296 - val_loss: 0.9724 - val_accuracy: 0.5214\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9233 - accuracy: 0.5185 - val_loss: 0.9767 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9258 - accuracy: 0.5185 - val_loss: 0.9776 - val_accuracy: 0.5043\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9269 - accuracy: 0.5185 - val_loss: 0.9786 - val_accuracy: 0.5214\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9256 - accuracy: 0.5296 - val_loss: 0.9746 - val_accuracy: 0.5214\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9243 - accuracy: 0.5296 - val_loss: 0.9720 - val_accuracy: 0.5214\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9231 - accuracy: 0.5333 - val_loss: 0.9713 - val_accuracy: 0.5214\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9243 - accuracy: 0.5333 - val_loss: 0.9714 - val_accuracy: 0.5214\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9214 - accuracy: 0.5333 - val_loss: 0.9724 - val_accuracy: 0.5214\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9222 - accuracy: 0.5333 - val_loss: 0.9748 - val_accuracy: 0.5214\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9216 - accuracy: 0.5333 - val_loss: 0.9743 - val_accuracy: 0.5214\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9212 - accuracy: 0.5333 - val_loss: 0.9727 - val_accuracy: 0.5214\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9202 - accuracy: 0.5333 - val_loss: 0.9728 - val_accuracy: 0.5214\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9216 - accuracy: 0.5333 - val_loss: 0.9737 - val_accuracy: 0.5043\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9214 - accuracy: 0.5222 - val_loss: 0.9719 - val_accuracy: 0.5043\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9210 - accuracy: 0.5222 - val_loss: 0.9709 - val_accuracy: 0.5043\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9216 - accuracy: 0.5259 - val_loss: 0.9705 - val_accuracy: 0.5214\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9212 - accuracy: 0.5333 - val_loss: 0.9709 - val_accuracy: 0.5214\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9207 - accuracy: 0.5333 - val_loss: 0.9723 - val_accuracy: 0.5214\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9233 - accuracy: 0.5333 - val_loss: 0.9776 - val_accuracy: 0.5214\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9215 - accuracy: 0.5333 - val_loss: 0.9752 - val_accuracy: 0.5214\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9204 - accuracy: 0.5333 - val_loss: 0.9724 - val_accuracy: 0.5214\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9196 - accuracy: 0.5333 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9200 - accuracy: 0.5333 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9199 - accuracy: 0.5333 - val_loss: 0.9690 - val_accuracy: 0.5214\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9196 - accuracy: 0.5333 - val_loss: 0.9684 - val_accuracy: 0.5214\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9191 - accuracy: 0.5333 - val_loss: 0.9683 - val_accuracy: 0.5214\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9186 - accuracy: 0.5333 - val_loss: 0.9691 - val_accuracy: 0.5214\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9181 - accuracy: 0.5333 - val_loss: 0.9710 - val_accuracy: 0.5214\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9193 - accuracy: 0.5333 - val_loss: 0.9743 - val_accuracy: 0.5214\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9190 - accuracy: 0.5333 - val_loss: 0.9728 - val_accuracy: 0.5214\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9191 - accuracy: 0.5333 - val_loss: 0.9705 - val_accuracy: 0.5214\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9194 - accuracy: 0.5000 - val_loss: 0.9693 - val_accuracy: 0.5043\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9191 - accuracy: 0.5222 - val_loss: 0.9694 - val_accuracy: 0.5043\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9187 - accuracy: 0.5222 - val_loss: 0.9715 - val_accuracy: 0.5214\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9188 - accuracy: 0.5333 - val_loss: 0.9726 - val_accuracy: 0.5214\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9179 - accuracy: 0.5333 - val_loss: 0.9710 - val_accuracy: 0.5214\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9189 - accuracy: 0.5333 - val_loss: 0.9677 - val_accuracy: 0.5214\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9173 - accuracy: 0.5333 - val_loss: 0.9679 - val_accuracy: 0.5214\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9167 - accuracy: 0.5333 - val_loss: 0.9688 - val_accuracy: 0.5214\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9180 - accuracy: 0.5333 - val_loss: 0.9704 - val_accuracy: 0.5214\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9167 - accuracy: 0.5333 - val_loss: 0.9695 - val_accuracy: 0.5214\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9159 - accuracy: 0.5333 - val_loss: 0.9689 - val_accuracy: 0.5214\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9163 - accuracy: 0.5333 - val_loss: 0.9696 - val_accuracy: 0.5214\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9167 - accuracy: 0.5333 - val_loss: 0.9699 - val_accuracy: 0.5214\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9156 - accuracy: 0.5333 - val_loss: 0.9716 - val_accuracy: 0.5214\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9171 - accuracy: 0.5333 - val_loss: 0.9735 - val_accuracy: 0.5214\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9166 - accuracy: 0.5333 - val_loss: 0.9713 - val_accuracy: 0.5214\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9175 - accuracy: 0.5333 - val_loss: 0.9698 - val_accuracy: 0.5299\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9158 - accuracy: 0.5333 - val_loss: 0.9703 - val_accuracy: 0.5299\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9163 - accuracy: 0.5333 - val_loss: 0.9697 - val_accuracy: 0.5214\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9152 - accuracy: 0.5333 - val_loss: 0.9680 - val_accuracy: 0.5214\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9152 - accuracy: 0.5333 - val_loss: 0.9666 - val_accuracy: 0.5214\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9149 - accuracy: 0.5333 - val_loss: 0.9665 - val_accuracy: 0.5214\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9148 - accuracy: 0.5333 - val_loss: 0.9656 - val_accuracy: 0.5214\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9156 - accuracy: 0.5333 - val_loss: 0.9659 - val_accuracy: 0.5214\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9153 - accuracy: 0.5333 - val_loss: 0.9667 - val_accuracy: 0.5214\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9149 - accuracy: 0.5333 - val_loss: 0.9691 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9143 - accuracy: 0.5333 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9145 - accuracy: 0.5333 - val_loss: 0.9705 - val_accuracy: 0.5299\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9143 - accuracy: 0.5333 - val_loss: 0.9707 - val_accuracy: 0.5214\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9144 - accuracy: 0.5333 - val_loss: 0.9694 - val_accuracy: 0.5214\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9137 - accuracy: 0.5407 - val_loss: 0.9711 - val_accuracy: 0.5043\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9169 - accuracy: 0.5222 - val_loss: 0.9749 - val_accuracy: 0.5214\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9153 - accuracy: 0.5333 - val_loss: 0.9708 - val_accuracy: 0.5214\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9134 - accuracy: 0.5333 - val_loss: 0.9689 - val_accuracy: 0.5299\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9148 - accuracy: 0.5333 - val_loss: 0.9688 - val_accuracy: 0.5299\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9128 - accuracy: 0.5333 - val_loss: 0.9708 - val_accuracy: 0.5214\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9138 - accuracy: 0.5333 - val_loss: 0.9727 - val_accuracy: 0.5214\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9150 - accuracy: 0.5333 - val_loss: 0.9728 - val_accuracy: 0.5214\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9155 - accuracy: 0.5333 - val_loss: 0.9723 - val_accuracy: 0.5214\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9142 - accuracy: 0.5333 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9129 - accuracy: 0.5333 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9138 - accuracy: 0.5333 - val_loss: 0.9660 - val_accuracy: 0.5214\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9148 - accuracy: 0.4889 - val_loss: 0.9669 - val_accuracy: 0.5043\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9133 - accuracy: 0.5222 - val_loss: 0.9688 - val_accuracy: 0.5043\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9130 - accuracy: 0.5222 - val_loss: 0.9724 - val_accuracy: 0.5043\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9146 - accuracy: 0.5259 - val_loss: 0.9746 - val_accuracy: 0.5214\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9137 - accuracy: 0.5333 - val_loss: 0.9737 - val_accuracy: 0.5299\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9134 - accuracy: 0.5333 - val_loss: 0.9727 - val_accuracy: 0.5299\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9139 - accuracy: 0.5333 - val_loss: 0.9749 - val_accuracy: 0.5299\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9135 - accuracy: 0.5333 - val_loss: 0.9716 - val_accuracy: 0.5299\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9123 - accuracy: 0.5333 - val_loss: 0.9691 - val_accuracy: 0.5214\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9110 - accuracy: 0.5333 - val_loss: 0.9690 - val_accuracy: 0.5214\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9111 - accuracy: 0.5333 - val_loss: 0.9695 - val_accuracy: 0.5043\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9120 - accuracy: 0.5074 - val_loss: 0.9696 - val_accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9107 - accuracy: 0.5111 - val_loss: 0.9692 - val_accuracy: 0.5214\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9103 - accuracy: 0.5333 - val_loss: 0.9681 - val_accuracy: 0.5214\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9109 - accuracy: 0.5333 - val_loss: 0.9684 - val_accuracy: 0.5214\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9099 - accuracy: 0.5333 - val_loss: 0.9687 - val_accuracy: 0.5214\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9105 - accuracy: 0.5333 - val_loss: 0.9689 - val_accuracy: 0.5214\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9119 - accuracy: 0.5333 - val_loss: 0.9670 - val_accuracy: 0.5299\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9115 - accuracy: 0.5333 - val_loss: 0.9684 - val_accuracy: 0.5299\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9108 - accuracy: 0.5333 - val_loss: 0.9685 - val_accuracy: 0.5299\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9111 - accuracy: 0.5333 - val_loss: 0.9657 - val_accuracy: 0.5299\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9095 - accuracy: 0.5333 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9090 - accuracy: 0.5333 - val_loss: 0.9674 - val_accuracy: 0.5299\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9115 - accuracy: 0.5333 - val_loss: 0.9667 - val_accuracy: 0.5299\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9093 - accuracy: 0.5333 - val_loss: 0.9670 - val_accuracy: 0.5299\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9084 - accuracy: 0.5333 - val_loss: 0.9691 - val_accuracy: 0.5299\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9089 - accuracy: 0.5333 - val_loss: 0.9695 - val_accuracy: 0.5214\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9097 - accuracy: 0.5333 - val_loss: 0.9693 - val_accuracy: 0.5299\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9095 - accuracy: 0.5333 - val_loss: 0.9682 - val_accuracy: 0.5299\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9099 - accuracy: 0.5037 - val_loss: 0.9684 - val_accuracy: 0.5043\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9088 - accuracy: 0.5148 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9081 - accuracy: 0.5333 - val_loss: 0.9662 - val_accuracy: 0.5299\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9082 - accuracy: 0.5333 - val_loss: 0.9672 - val_accuracy: 0.5299\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9080 - accuracy: 0.5333 - val_loss: 0.9683 - val_accuracy: 0.5299\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9082 - accuracy: 0.5333 - val_loss: 0.9684 - val_accuracy: 0.5299\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9077 - accuracy: 0.5333 - val_loss: 0.9658 - val_accuracy: 0.5299\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9092 - accuracy: 0.5333 - val_loss: 0.9661 - val_accuracy: 0.5385\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9092 - accuracy: 0.5333 - val_loss: 0.9675 - val_accuracy: 0.5385\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9087 - accuracy: 0.5333 - val_loss: 0.9682 - val_accuracy: 0.5299\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9077 - accuracy: 0.5333 - val_loss: 0.9686 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9072 - accuracy: 0.5333 - val_loss: 0.9684 - val_accuracy: 0.5299\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9071 - accuracy: 0.5370 - val_loss: 0.9680 - val_accuracy: 0.5299\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9073 - accuracy: 0.5444 - val_loss: 0.9668 - val_accuracy: 0.5128\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9070 - accuracy: 0.5259 - val_loss: 0.9685 - val_accuracy: 0.5128\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9071 - accuracy: 0.5370 - val_loss: 0.9703 - val_accuracy: 0.5299\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9075 - accuracy: 0.5370 - val_loss: 0.9689 - val_accuracy: 0.5299\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.9063 - accuracy: 0.5333 - val_loss: 0.9662 - val_accuracy: 0.5299\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9062 - accuracy: 0.5333 - val_loss: 0.9644 - val_accuracy: 0.5128\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9069 - accuracy: 0.5185 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9059 - accuracy: 0.5370 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9058 - accuracy: 0.5370 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9063 - accuracy: 0.5370 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9052 - accuracy: 0.5370 - val_loss: 0.9664 - val_accuracy: 0.5299\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9057 - accuracy: 0.5370 - val_loss: 0.9685 - val_accuracy: 0.5299\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9061 - accuracy: 0.5370 - val_loss: 0.9669 - val_accuracy: 0.5299\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9061 - accuracy: 0.5370 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9066 - accuracy: 0.5259 - val_loss: 0.9629 - val_accuracy: 0.5128\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9052 - accuracy: 0.5296 - val_loss: 0.9639 - val_accuracy: 0.5128\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9045 - accuracy: 0.5444 - val_loss: 0.9666 - val_accuracy: 0.5299\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9048 - accuracy: 0.5444 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9056 - accuracy: 0.5444 - val_loss: 0.9700 - val_accuracy: 0.5299\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9064 - accuracy: 0.5370 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9068 - accuracy: 0.5333 - val_loss: 0.9667 - val_accuracy: 0.5299\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9048 - accuracy: 0.5333 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9039 - accuracy: 0.5519 - val_loss: 0.9640 - val_accuracy: 0.5043\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9063 - accuracy: 0.5333 - val_loss: 0.9686 - val_accuracy: 0.4957\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9086 - accuracy: 0.5333 - val_loss: 0.9692 - val_accuracy: 0.4957\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.9067 - accuracy: 0.5333 - val_loss: 0.9655 - val_accuracy: 0.5043\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9050 - accuracy: 0.5407 - val_loss: 0.9645 - val_accuracy: 0.5299\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.9046 - accuracy: 0.5370 - val_loss: 0.9660 - val_accuracy: 0.5385\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9047 - accuracy: 0.5333 - val_loss: 0.9654 - val_accuracy: 0.5385\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9042 - accuracy: 0.5333 - val_loss: 0.9647 - val_accuracy: 0.5299\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9045 - accuracy: 0.5370 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9039 - accuracy: 0.5370 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9029 - accuracy: 0.5407 - val_loss: 0.9629 - val_accuracy: 0.5299\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9036 - accuracy: 0.5444 - val_loss: 0.9624 - val_accuracy: 0.5299\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9045 - accuracy: 0.5407 - val_loss: 0.9636 - val_accuracy: 0.5043\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9028 - accuracy: 0.5222 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9024 - accuracy: 0.5444 - val_loss: 0.9649 - val_accuracy: 0.5299\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9018 - accuracy: 0.5444 - val_loss: 0.9665 - val_accuracy: 0.5214\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9023 - accuracy: 0.5444 - val_loss: 0.9685 - val_accuracy: 0.5214\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9035 - accuracy: 0.5444 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9029 - accuracy: 0.5444 - val_loss: 0.9696 - val_accuracy: 0.5214\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9029 - accuracy: 0.5444 - val_loss: 0.9686 - val_accuracy: 0.5214\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9037 - accuracy: 0.5111 - val_loss: 0.9678 - val_accuracy: 0.5214\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9011 - accuracy: 0.5444 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9022 - accuracy: 0.5444 - val_loss: 0.9650 - val_accuracy: 0.5385\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.9007 - accuracy: 0.5407 - val_loss: 0.9666 - val_accuracy: 0.5385\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.9022 - accuracy: 0.5370 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.9024 - accuracy: 0.5370 - val_loss: 0.9676 - val_accuracy: 0.5214\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.9019 - accuracy: 0.5370 - val_loss: 0.9678 - val_accuracy: 0.5299\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.9025 - accuracy: 0.5370 - val_loss: 0.9667 - val_accuracy: 0.5385\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9019 - accuracy: 0.5370 - val_loss: 0.9647 - val_accuracy: 0.5299\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.9022 - accuracy: 0.5444 - val_loss: 0.9672 - val_accuracy: 0.5214\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9002 - accuracy: 0.5444 - val_loss: 0.9659 - val_accuracy: 0.5214\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8999 - accuracy: 0.5444 - val_loss: 0.9653 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9002 - accuracy: 0.5444 - val_loss: 0.9670 - val_accuracy: 0.5214\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8997 - accuracy: 0.5444 - val_loss: 0.9678 - val_accuracy: 0.5214\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9004 - accuracy: 0.5444 - val_loss: 0.9681 - val_accuracy: 0.5214\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8991 - accuracy: 0.5444 - val_loss: 0.9719 - val_accuracy: 0.5214\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.9002 - accuracy: 0.5444 - val_loss: 0.9721 - val_accuracy: 0.5214\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9004 - accuracy: 0.5556 - val_loss: 0.9689 - val_accuracy: 0.5043\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.9008 - accuracy: 0.5333 - val_loss: 0.9646 - val_accuracy: 0.5043\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9015 - accuracy: 0.5333 - val_loss: 0.9633 - val_accuracy: 0.5043\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.9009 - accuracy: 0.5333 - val_loss: 0.9674 - val_accuracy: 0.5043\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8996 - accuracy: 0.5407 - val_loss: 0.9703 - val_accuracy: 0.5214\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9008 - accuracy: 0.5444 - val_loss: 0.9712 - val_accuracy: 0.5299\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.9005 - accuracy: 0.5444 - val_loss: 0.9671 - val_accuracy: 0.5385\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9023 - accuracy: 0.5444 - val_loss: 0.9641 - val_accuracy: 0.5385\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9028 - accuracy: 0.5444 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9009 - accuracy: 0.5444 - val_loss: 0.9627 - val_accuracy: 0.5299\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.9001 - accuracy: 0.5333 - val_loss: 0.9625 - val_accuracy: 0.5214\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8983 - accuracy: 0.5444 - val_loss: 0.9640 - val_accuracy: 0.5214\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8984 - accuracy: 0.5444 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.9023 - accuracy: 0.5444 - val_loss: 0.9737 - val_accuracy: 0.5299\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9004 - accuracy: 0.5444 - val_loss: 0.9681 - val_accuracy: 0.5299\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8980 - accuracy: 0.5444 - val_loss: 0.9626 - val_accuracy: 0.5214\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8970 - accuracy: 0.5444 - val_loss: 0.9573 - val_accuracy: 0.5214\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.9015 - accuracy: 0.5444 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9001 - accuracy: 0.5444 - val_loss: 0.9587 - val_accuracy: 0.5214\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8977 - accuracy: 0.5444 - val_loss: 0.9612 - val_accuracy: 0.5214\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8976 - accuracy: 0.5444 - val_loss: 0.9627 - val_accuracy: 0.5214\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8989 - accuracy: 0.5444 - val_loss: 0.9644 - val_accuracy: 0.5214\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8978 - accuracy: 0.5444 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8976 - accuracy: 0.5444 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8970 - accuracy: 0.5444 - val_loss: 0.9641 - val_accuracy: 0.5299\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8985 - accuracy: 0.5444 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8966 - accuracy: 0.5444 - val_loss: 0.9610 - val_accuracy: 0.5299\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8962 - accuracy: 0.5444 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8960 - accuracy: 0.5444 - val_loss: 0.9644 - val_accuracy: 0.5214\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8975 - accuracy: 0.5444 - val_loss: 0.9676 - val_accuracy: 0.5214\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8981 - accuracy: 0.5481 - val_loss: 0.9648 - val_accuracy: 0.5214\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8954 - accuracy: 0.5519 - val_loss: 0.9604 - val_accuracy: 0.5214\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8962 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5043\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8968 - accuracy: 0.5407 - val_loss: 0.9579 - val_accuracy: 0.5043\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8970 - accuracy: 0.5407 - val_loss: 0.9573 - val_accuracy: 0.5043\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8969 - accuracy: 0.5407 - val_loss: 0.9577 - val_accuracy: 0.5043\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8958 - accuracy: 0.5667 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8953 - accuracy: 0.5444 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8967 - accuracy: 0.5444 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8964 - accuracy: 0.5444 - val_loss: 0.9604 - val_accuracy: 0.5299\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8956 - accuracy: 0.5444 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8952 - accuracy: 0.5519 - val_loss: 0.9578 - val_accuracy: 0.5299\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8953 - accuracy: 0.5370 - val_loss: 0.9594 - val_accuracy: 0.5043\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8962 - accuracy: 0.5407 - val_loss: 0.9661 - val_accuracy: 0.5043\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8985 - accuracy: 0.5407 - val_loss: 0.9677 - val_accuracy: 0.5043\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8975 - accuracy: 0.5556 - val_loss: 0.9641 - val_accuracy: 0.5299\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8941 - accuracy: 0.5519 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8942 - accuracy: 0.5519 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8961 - accuracy: 0.5519 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8954 - accuracy: 0.5519 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8945 - accuracy: 0.5519 - val_loss: 0.9587 - val_accuracy: 0.5214\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8945 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5214\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8945 - accuracy: 0.5519 - val_loss: 0.9576 - val_accuracy: 0.5299\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8940 - accuracy: 0.5519 - val_loss: 0.9581 - val_accuracy: 0.5299\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8933 - accuracy: 0.5519 - val_loss: 0.9595 - val_accuracy: 0.5299\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8926 - accuracy: 0.5593 - val_loss: 0.9616 - val_accuracy: 0.5043\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8945 - accuracy: 0.5407 - val_loss: 0.9629 - val_accuracy: 0.5043\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8949 - accuracy: 0.5407 - val_loss: 0.9607 - val_accuracy: 0.5043\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8947 - accuracy: 0.5370 - val_loss: 0.9596 - val_accuracy: 0.5214\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8936 - accuracy: 0.5519 - val_loss: 0.9634 - val_accuracy: 0.5299\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8933 - accuracy: 0.5519 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8941 - accuracy: 0.5519 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8933 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5214\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8928 - accuracy: 0.5185 - val_loss: 0.9574 - val_accuracy: 0.5043\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8933 - accuracy: 0.5407 - val_loss: 0.9576 - val_accuracy: 0.5043\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8925 - accuracy: 0.5407 - val_loss: 0.9576 - val_accuracy: 0.5043\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8925 - accuracy: 0.5296 - val_loss: 0.9576 - val_accuracy: 0.5299\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8939 - accuracy: 0.5519 - val_loss: 0.9576 - val_accuracy: 0.5299\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8940 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8910 - accuracy: 0.5519 - val_loss: 0.9581 - val_accuracy: 0.5214\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8921 - accuracy: 0.5519 - val_loss: 0.9629 - val_accuracy: 0.5299\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8959 - accuracy: 0.5519 - val_loss: 0.9664 - val_accuracy: 0.5299\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8968 - accuracy: 0.5519 - val_loss: 0.9618 - val_accuracy: 0.5299\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8926 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5299\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8923 - accuracy: 0.5519 - val_loss: 0.9531 - val_accuracy: 0.5299\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8946 - accuracy: 0.5519 - val_loss: 0.9536 - val_accuracy: 0.5299\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8944 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8927 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5299\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8899 - accuracy: 0.5519 - val_loss: 0.9607 - val_accuracy: 0.5299\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8934 - accuracy: 0.5519 - val_loss: 0.9660 - val_accuracy: 0.5299\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8933 - accuracy: 0.5519 - val_loss: 0.9609 - val_accuracy: 0.5214\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8890 - accuracy: 0.5519 - val_loss: 0.9562 - val_accuracy: 0.5214\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8916 - accuracy: 0.5333 - val_loss: 0.9549 - val_accuracy: 0.5043\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8929 - accuracy: 0.5481 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8927 - accuracy: 0.5519 - val_loss: 0.9566 - val_accuracy: 0.5299\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8898 - accuracy: 0.5519 - val_loss: 0.9599 - val_accuracy: 0.5299\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8916 - accuracy: 0.5519 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8934 - accuracy: 0.5519 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8908 - accuracy: 0.5519 - val_loss: 0.9566 - val_accuracy: 0.5299\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8898 - accuracy: 0.5519 - val_loss: 0.9544 - val_accuracy: 0.5299\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8903 - accuracy: 0.5519 - val_loss: 0.9547 - val_accuracy: 0.5299\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8895 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8896 - accuracy: 0.5519 - val_loss: 0.9564 - val_accuracy: 0.5299\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8897 - accuracy: 0.5519 - val_loss: 0.9546 - val_accuracy: 0.5299\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8893 - accuracy: 0.5519 - val_loss: 0.9543 - val_accuracy: 0.5299\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8892 - accuracy: 0.5519 - val_loss: 0.9562 - val_accuracy: 0.5299\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8887 - accuracy: 0.5519 - val_loss: 0.9585 - val_accuracy: 0.5299\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8896 - accuracy: 0.5519 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8910 - accuracy: 0.5519 - val_loss: 0.9619 - val_accuracy: 0.5299\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8892 - accuracy: 0.5519 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8878 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8885 - accuracy: 0.5519 - val_loss: 0.9560 - val_accuracy: 0.5299\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8903 - accuracy: 0.5519 - val_loss: 0.9560 - val_accuracy: 0.5299\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8896 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8879 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5299\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8880 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8894 - accuracy: 0.5519 - val_loss: 0.9602 - val_accuracy: 0.5299\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8887 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8913 - accuracy: 0.5519 - val_loss: 0.9578 - val_accuracy: 0.5299\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8871 - accuracy: 0.5481 - val_loss: 0.9600 - val_accuracy: 0.5128\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8871 - accuracy: 0.5407 - val_loss: 0.9609 - val_accuracy: 0.5128\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8891 - accuracy: 0.5407 - val_loss: 0.9614 - val_accuracy: 0.5128\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8879 - accuracy: 0.5519 - val_loss: 0.9576 - val_accuracy: 0.5299\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8869 - accuracy: 0.5519 - val_loss: 0.9569 - val_accuracy: 0.5299\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8865 - accuracy: 0.5519 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8860 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5299\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8874 - accuracy: 0.5519 - val_loss: 0.9569 - val_accuracy: 0.5214\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8883 - accuracy: 0.5519 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8884 - accuracy: 0.5519 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8881 - accuracy: 0.5519 - val_loss: 0.9574 - val_accuracy: 0.5299\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8866 - accuracy: 0.5519 - val_loss: 0.9617 - val_accuracy: 0.5299\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8872 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5299\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8851 - accuracy: 0.5519 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8867 - accuracy: 0.5519 - val_loss: 0.9549 - val_accuracy: 0.5299\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8889 - accuracy: 0.5519 - val_loss: 0.9547 - val_accuracy: 0.5299\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8872 - accuracy: 0.5519 - val_loss: 0.9540 - val_accuracy: 0.5299\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8868 - accuracy: 0.5519 - val_loss: 0.9535 - val_accuracy: 0.5299\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8844 - accuracy: 0.5519 - val_loss: 0.9587 - val_accuracy: 0.5299\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8854 - accuracy: 0.5519 - val_loss: 0.9619 - val_accuracy: 0.5128\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8857 - accuracy: 0.5407 - val_loss: 0.9587 - val_accuracy: 0.5128\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8867 - accuracy: 0.5148 - val_loss: 0.9550 - val_accuracy: 0.5299\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8848 - accuracy: 0.5519 - val_loss: 0.9546 - val_accuracy: 0.5299\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8862 - accuracy: 0.5519 - val_loss: 0.9535 - val_accuracy: 0.5299\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8860 - accuracy: 0.5519 - val_loss: 0.9535 - val_accuracy: 0.5299\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8854 - accuracy: 0.5519 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8846 - accuracy: 0.5519 - val_loss: 0.9573 - val_accuracy: 0.5299\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8869 - accuracy: 0.5519 - val_loss: 0.9581 - val_accuracy: 0.5299\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8857 - accuracy: 0.5519 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8851 - accuracy: 0.5444 - val_loss: 0.9573 - val_accuracy: 0.5128\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8846 - accuracy: 0.5259 - val_loss: 0.9550 - val_accuracy: 0.5299\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8841 - accuracy: 0.5519 - val_loss: 0.9561 - val_accuracy: 0.5299\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8842 - accuracy: 0.5519 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8845 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5299\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8835 - accuracy: 0.5519 - val_loss: 0.9567 - val_accuracy: 0.5299\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8849 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8855 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5299\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8877 - accuracy: 0.5519 - val_loss: 0.9627 - val_accuracy: 0.5299\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8889 - accuracy: 0.5519 - val_loss: 0.9612 - val_accuracy: 0.5299\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8866 - accuracy: 0.5519 - val_loss: 0.9599 - val_accuracy: 0.5299\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8859 - accuracy: 0.5259 - val_loss: 0.9589 - val_accuracy: 0.5128\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8835 - accuracy: 0.5407 - val_loss: 0.9555 - val_accuracy: 0.5128\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8862 - accuracy: 0.5407 - val_loss: 0.9546 - val_accuracy: 0.5128\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8873 - accuracy: 0.5407 - val_loss: 0.9546 - val_accuracy: 0.5128\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8850 - accuracy: 0.5407 - val_loss: 0.9558 - val_accuracy: 0.5128\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8831 - accuracy: 0.5407 - val_loss: 0.9578 - val_accuracy: 0.5128\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8829 - accuracy: 0.5704 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8865 - accuracy: 0.5407 - val_loss: 0.9675 - val_accuracy: 0.4701\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8886 - accuracy: 0.5259 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8859 - accuracy: 0.5519 - val_loss: 0.9570 - val_accuracy: 0.5299\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8835 - accuracy: 0.5519 - val_loss: 0.9523 - val_accuracy: 0.5299\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8838 - accuracy: 0.5444 - val_loss: 0.9520 - val_accuracy: 0.5128\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8835 - accuracy: 0.5333 - val_loss: 0.9529 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8823 - accuracy: 0.5519 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8815 - accuracy: 0.5519 - val_loss: 0.9573 - val_accuracy: 0.5299\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8819 - accuracy: 0.5519 - val_loss: 0.9559 - val_accuracy: 0.5299\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8812 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8817 - accuracy: 0.5519 - val_loss: 0.9555 - val_accuracy: 0.5299\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8812 - accuracy: 0.5519 - val_loss: 0.9546 - val_accuracy: 0.5299\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8809 - accuracy: 0.5519 - val_loss: 0.9557 - val_accuracy: 0.5299\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8809 - accuracy: 0.5519 - val_loss: 0.9573 - val_accuracy: 0.5299\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8824 - accuracy: 0.5519 - val_loss: 0.9602 - val_accuracy: 0.5299\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8839 - accuracy: 0.5519 - val_loss: 0.9598 - val_accuracy: 0.5299\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8822 - accuracy: 0.5519 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8825 - accuracy: 0.5519 - val_loss: 0.9508 - val_accuracy: 0.5299\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8808 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8808 - accuracy: 0.5519 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8809 - accuracy: 0.5519 - val_loss: 0.9527 - val_accuracy: 0.5299\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8805 - accuracy: 0.5519 - val_loss: 0.9547 - val_accuracy: 0.5299\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8812 - accuracy: 0.5519 - val_loss: 0.9539 - val_accuracy: 0.5299\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8807 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8808 - accuracy: 0.5111 - val_loss: 0.9524 - val_accuracy: 0.5128\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8808 - accuracy: 0.5370 - val_loss: 0.9532 - val_accuracy: 0.5299\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8803 - accuracy: 0.5519 - val_loss: 0.9574 - val_accuracy: 0.5299\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8811 - accuracy: 0.5519 - val_loss: 0.9575 - val_accuracy: 0.5299\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8817 - accuracy: 0.5519 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8814 - accuracy: 0.5519 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8821 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8805 - accuracy: 0.5407 - val_loss: 0.9538 - val_accuracy: 0.5128\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8807 - accuracy: 0.5407 - val_loss: 0.9545 - val_accuracy: 0.5128\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8804 - accuracy: 0.5185 - val_loss: 0.9571 - val_accuracy: 0.5299\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8796 - accuracy: 0.5519 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8801 - accuracy: 0.5519 - val_loss: 0.9613 - val_accuracy: 0.5299\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8817 - accuracy: 0.5519 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8794 - accuracy: 0.5519 - val_loss: 0.9553 - val_accuracy: 0.5299\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8783 - accuracy: 0.5556 - val_loss: 0.9553 - val_accuracy: 0.5128\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8805 - accuracy: 0.5407 - val_loss: 0.9561 - val_accuracy: 0.5128\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8802 - accuracy: 0.5407 - val_loss: 0.9540 - val_accuracy: 0.5128\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8791 - accuracy: 0.5407 - val_loss: 0.9537 - val_accuracy: 0.5299\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8799 - accuracy: 0.5519 - val_loss: 0.9562 - val_accuracy: 0.5299\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8810 - accuracy: 0.5519 - val_loss: 0.9592 - val_accuracy: 0.5299\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8795 - accuracy: 0.5519 - val_loss: 0.9561 - val_accuracy: 0.5299\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8784 - accuracy: 0.5519 - val_loss: 0.9554 - val_accuracy: 0.5299\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8787 - accuracy: 0.5519 - val_loss: 0.9538 - val_accuracy: 0.5299\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8804 - accuracy: 0.5519 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9572 - val_accuracy: 0.5299\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8786 - accuracy: 0.5519 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9549 - val_accuracy: 0.5299\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8792 - accuracy: 0.5370 - val_loss: 0.9612 - val_accuracy: 0.5128\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8793 - accuracy: 0.5407 - val_loss: 0.9648 - val_accuracy: 0.5299\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8811 - accuracy: 0.5519 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8807 - accuracy: 0.5519 - val_loss: 0.9620 - val_accuracy: 0.5299\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8789 - accuracy: 0.5407 - val_loss: 0.9600 - val_accuracy: 0.5128\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8776 - accuracy: 0.5407 - val_loss: 0.9580 - val_accuracy: 0.5128\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8795 - accuracy: 0.5370 - val_loss: 0.9548 - val_accuracy: 0.5128\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8785 - accuracy: 0.5407 - val_loss: 0.9537 - val_accuracy: 0.5128\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8804 - accuracy: 0.5333 - val_loss: 0.9542 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8800 - accuracy: 0.5148 - val_loss: 0.9569 - val_accuracy: 0.5128\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8778 - accuracy: 0.5370 - val_loss: 0.9569 - val_accuracy: 0.5299\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8767 - accuracy: 0.5519 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8767 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8770 - accuracy: 0.5519 - val_loss: 0.9626 - val_accuracy: 0.5299\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8775 - accuracy: 0.5519 - val_loss: 0.9631 - val_accuracy: 0.5299\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8773 - accuracy: 0.5519 - val_loss: 0.9612 - val_accuracy: 0.5299\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8770 - accuracy: 0.5481 - val_loss: 0.9581 - val_accuracy: 0.5128\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8771 - accuracy: 0.5222 - val_loss: 0.9579 - val_accuracy: 0.5299\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8768 - accuracy: 0.5519 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8763 - accuracy: 0.5519 - val_loss: 0.9576 - val_accuracy: 0.5299\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8764 - accuracy: 0.5519 - val_loss: 0.9574 - val_accuracy: 0.5299\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8785 - accuracy: 0.5519 - val_loss: 0.9584 - val_accuracy: 0.5299\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8782 - accuracy: 0.5519 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8774 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8761 - accuracy: 0.5630 - val_loss: 0.9585 - val_accuracy: 0.5128\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8767 - accuracy: 0.5407 - val_loss: 0.9581 - val_accuracy: 0.5128\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8780 - accuracy: 0.5407 - val_loss: 0.9570 - val_accuracy: 0.5128\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8775 - accuracy: 0.5407 - val_loss: 0.9590 - val_accuracy: 0.5128\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8764 - accuracy: 0.5407 - val_loss: 0.9604 - val_accuracy: 0.5299\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8770 - accuracy: 0.5519 - val_loss: 0.9585 - val_accuracy: 0.5299\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8759 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5299\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8769 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8763 - accuracy: 0.5519 - val_loss: 0.9604 - val_accuracy: 0.5299\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8768 - accuracy: 0.5519 - val_loss: 0.9603 - val_accuracy: 0.5299\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8760 - accuracy: 0.5519 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8769 - accuracy: 0.5519 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8765 - accuracy: 0.5407 - val_loss: 0.9566 - val_accuracy: 0.5128\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8768 - accuracy: 0.5296 - val_loss: 0.9547 - val_accuracy: 0.5299\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8764 - accuracy: 0.5519 - val_loss: 0.9579 - val_accuracy: 0.5299\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8747 - accuracy: 0.5519 - val_loss: 0.9579 - val_accuracy: 0.5299\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8751 - accuracy: 0.5519 - val_loss: 0.9570 - val_accuracy: 0.5299\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8749 - accuracy: 0.5519 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8772 - accuracy: 0.5519 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8765 - accuracy: 0.5519 - val_loss: 0.9630 - val_accuracy: 0.5299\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8759 - accuracy: 0.5519 - val_loss: 0.9657 - val_accuracy: 0.5299\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8759 - accuracy: 0.5519 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8748 - accuracy: 0.5519 - val_loss: 0.9600 - val_accuracy: 0.5299\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8744 - accuracy: 0.5519 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8754 - accuracy: 0.5519 - val_loss: 0.9567 - val_accuracy: 0.5299\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8786 - accuracy: 0.5185 - val_loss: 0.9582 - val_accuracy: 0.5128\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8785 - accuracy: 0.5407 - val_loss: 0.9577 - val_accuracy: 0.5128\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8751 - accuracy: 0.5370 - val_loss: 0.9602 - val_accuracy: 0.5299\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.8786 - accuracy: 0.5519 - val_loss: 0.9672 - val_accuracy: 0.5299\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8762 - accuracy: 0.5519 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8771 - accuracy: 0.5519 - val_loss: 0.9623 - val_accuracy: 0.5299\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8772 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5299\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8747 - accuracy: 0.5519 - val_loss: 0.9597 - val_accuracy: 0.5299\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8728 - accuracy: 0.5519 - val_loss: 0.9610 - val_accuracy: 0.5299\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8737 - accuracy: 0.5370 - val_loss: 0.9645 - val_accuracy: 0.5128\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8780 - accuracy: 0.5407 - val_loss: 0.9653 - val_accuracy: 0.5128\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8774 - accuracy: 0.5407 - val_loss: 0.9648 - val_accuracy: 0.5128\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8761 - accuracy: 0.5259 - val_loss: 0.9587 - val_accuracy: 0.5299\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8727 - accuracy: 0.5519 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5299\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8762 - accuracy: 0.5519 - val_loss: 0.9531 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8726 - accuracy: 0.5296 - val_loss: 0.9552 - val_accuracy: 0.5128\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8724 - accuracy: 0.5407 - val_loss: 0.9571 - val_accuracy: 0.5128\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8743 - accuracy: 0.5407 - val_loss: 0.9591 - val_accuracy: 0.5128\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8733 - accuracy: 0.5407 - val_loss: 0.9563 - val_accuracy: 0.5299\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8732 - accuracy: 0.5519 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8745 - accuracy: 0.5519 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8737 - accuracy: 0.5519 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8732 - accuracy: 0.5519 - val_loss: 0.9498 - val_accuracy: 0.5299\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8721 - accuracy: 0.5519 - val_loss: 0.9514 - val_accuracy: 0.5128\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8754 - accuracy: 0.5407 - val_loss: 0.9561 - val_accuracy: 0.5128\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8751 - accuracy: 0.5407 - val_loss: 0.9574 - val_accuracy: 0.5299\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8744 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5299\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8754 - accuracy: 0.5519 - val_loss: 0.9537 - val_accuracy: 0.5299\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8723 - accuracy: 0.5519 - val_loss: 0.9510 - val_accuracy: 0.5299\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8723 - accuracy: 0.5519 - val_loss: 0.9497 - val_accuracy: 0.5299\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8728 - accuracy: 0.5370 - val_loss: 0.9494 - val_accuracy: 0.5128\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8728 - accuracy: 0.5407 - val_loss: 0.9491 - val_accuracy: 0.5299\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8763 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8764 - accuracy: 0.5519 - val_loss: 0.9548 - val_accuracy: 0.5299\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8732 - accuracy: 0.5519 - val_loss: 0.9510 - val_accuracy: 0.5299\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8727 - accuracy: 0.5519 - val_loss: 0.9506 - val_accuracy: 0.5299\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8722 - accuracy: 0.5519 - val_loss: 0.9509 - val_accuracy: 0.5299\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8731 - accuracy: 0.5519 - val_loss: 0.9533 - val_accuracy: 0.5299\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8716 - accuracy: 0.5519 - val_loss: 0.9540 - val_accuracy: 0.5299\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8707 - accuracy: 0.5593 - val_loss: 0.9549 - val_accuracy: 0.5128\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8720 - accuracy: 0.5407 - val_loss: 0.9553 - val_accuracy: 0.5128\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8727 - accuracy: 0.5407 - val_loss: 0.9550 - val_accuracy: 0.5128\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8723 - accuracy: 0.5370 - val_loss: 0.9553 - val_accuracy: 0.5299\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8704 - accuracy: 0.5519 - val_loss: 0.9586 - val_accuracy: 0.5299\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8712 - accuracy: 0.5519 - val_loss: 0.9607 - val_accuracy: 0.5299\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8717 - accuracy: 0.5704 - val_loss: 0.9598 - val_accuracy: 0.5128\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8714 - accuracy: 0.5333 - val_loss: 0.9571 - val_accuracy: 0.5128\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8713 - accuracy: 0.5407 - val_loss: 0.9547 - val_accuracy: 0.5128\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8709 - accuracy: 0.5407 - val_loss: 0.9541 - val_accuracy: 0.5128\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8707 - accuracy: 0.5667 - val_loss: 0.9544 - val_accuracy: 0.5299\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8708 - accuracy: 0.5519 - val_loss: 0.9542 - val_accuracy: 0.5299\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8714 - accuracy: 0.5519 - val_loss: 0.9545 - val_accuracy: 0.5299\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8716 - accuracy: 0.5074 - val_loss: 0.9531 - val_accuracy: 0.5128\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8712 - accuracy: 0.5407 - val_loss: 0.9523 - val_accuracy: 0.5128\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8734 - accuracy: 0.5444 - val_loss: 0.9519 - val_accuracy: 0.5128\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8723 - accuracy: 0.5444 - val_loss: 0.9530 - val_accuracy: 0.5128\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8721 - accuracy: 0.5444 - val_loss: 0.9551 - val_accuracy: 0.5128\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8705 - accuracy: 0.5407 - val_loss: 0.9570 - val_accuracy: 0.5128\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8703 - accuracy: 0.5333 - val_loss: 0.9620 - val_accuracy: 0.5299\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8738 - accuracy: 0.5519 - val_loss: 0.9658 - val_accuracy: 0.5299\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8725 - accuracy: 0.5519 - val_loss: 0.9617 - val_accuracy: 0.5299\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8707 - accuracy: 0.5519 - val_loss: 0.9595 - val_accuracy: 0.5299\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8707 - accuracy: 0.5519 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8697 - accuracy: 0.5519 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8704 - accuracy: 0.5370 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8742 - accuracy: 0.5407 - val_loss: 0.9655 - val_accuracy: 0.5128\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8741 - accuracy: 0.5296 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8708 - accuracy: 0.5519 - val_loss: 0.9587 - val_accuracy: 0.5299\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8712 - accuracy: 0.5444 - val_loss: 0.9589 - val_accuracy: 0.5128\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8717 - accuracy: 0.5148 - val_loss: 0.9565 - val_accuracy: 0.5299\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8694 - accuracy: 0.5519 - val_loss: 0.9564 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8700 - accuracy: 0.5519 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8691 - accuracy: 0.5519 - val_loss: 0.9585 - val_accuracy: 0.5299\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8702 - accuracy: 0.5519 - val_loss: 0.9568 - val_accuracy: 0.5299\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8698 - accuracy: 0.5370 - val_loss: 0.9569 - val_accuracy: 0.5128\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8697 - accuracy: 0.5407 - val_loss: 0.9576 - val_accuracy: 0.5128\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8702 - accuracy: 0.5407 - val_loss: 0.9593 - val_accuracy: 0.5128\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8693 - accuracy: 0.5407 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8698 - accuracy: 0.5519 - val_loss: 0.9621 - val_accuracy: 0.5299\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8708 - accuracy: 0.5519 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8734 - accuracy: 0.5519 - val_loss: 0.9648 - val_accuracy: 0.5299\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8720 - accuracy: 0.5519 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8703 - accuracy: 0.5519 - val_loss: 0.9566 - val_accuracy: 0.5299\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8702 - accuracy: 0.5556 - val_loss: 0.9564 - val_accuracy: 0.5299\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8699 - accuracy: 0.5556 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8688 - accuracy: 0.5519 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 0.9592 - val_accuracy: 0.5299\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8685 - accuracy: 0.5519 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8704 - accuracy: 0.5519 - val_loss: 0.9583 - val_accuracy: 0.5299\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8711 - accuracy: 0.5333 - val_loss: 0.9562 - val_accuracy: 0.5299\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8688 - accuracy: 0.5556 - val_loss: 0.9560 - val_accuracy: 0.5299\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 0.9571 - val_accuracy: 0.5299\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8688 - accuracy: 0.5519 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8689 - accuracy: 0.5519 - val_loss: 0.9601 - val_accuracy: 0.5299\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8686 - accuracy: 0.5519 - val_loss: 0.9582 - val_accuracy: 0.5299\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8706 - accuracy: 0.5519 - val_loss: 0.9581 - val_accuracy: 0.5299\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8688 - accuracy: 0.5519 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8683 - accuracy: 0.5556 - val_loss: 0.9515 - val_accuracy: 0.5299\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8678 - accuracy: 0.5556 - val_loss: 0.9515 - val_accuracy: 0.5299\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8686 - accuracy: 0.5481 - val_loss: 0.9525 - val_accuracy: 0.5128\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8676 - accuracy: 0.5556 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8679 - accuracy: 0.5519 - val_loss: 0.9526 - val_accuracy: 0.5299\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8676 - accuracy: 0.5519 - val_loss: 0.9511 - val_accuracy: 0.5299\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8680 - accuracy: 0.5556 - val_loss: 0.9503 - val_accuracy: 0.5299\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8675 - accuracy: 0.5556 - val_loss: 0.9516 - val_accuracy: 0.5299\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8672 - accuracy: 0.5556 - val_loss: 0.9518 - val_accuracy: 0.5299\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8672 - accuracy: 0.5556 - val_loss: 0.9524 - val_accuracy: 0.5299\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8667 - accuracy: 0.5556 - val_loss: 0.9519 - val_accuracy: 0.5299\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.8677 - accuracy: 0.5556 - val_loss: 0.9530 - val_accuracy: 0.5299\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8671 - accuracy: 0.5556 - val_loss: 0.9562 - val_accuracy: 0.5128\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8682 - accuracy: 0.5407 - val_loss: 0.9588 - val_accuracy: 0.5128\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8687 - accuracy: 0.5556 - val_loss: 0.9591 - val_accuracy: 0.5299\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8678 - accuracy: 0.5519 - val_loss: 0.9597 - val_accuracy: 0.5299\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8675 - accuracy: 0.5519 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8684 - accuracy: 0.5519 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8678 - accuracy: 0.5556 - val_loss: 0.9560 - val_accuracy: 0.5128\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8674 - accuracy: 0.5444 - val_loss: 0.9585 - val_accuracy: 0.5128\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8668 - accuracy: 0.5407 - val_loss: 0.9609 - val_accuracy: 0.5128\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8671 - accuracy: 0.5407 - val_loss: 0.9625 - val_accuracy: 0.5128\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8681 - accuracy: 0.5407 - val_loss: 0.9654 - val_accuracy: 0.5128\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8684 - accuracy: 0.5407 - val_loss: 0.9639 - val_accuracy: 0.5299\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8679 - accuracy: 0.5519 - val_loss: 0.9647 - val_accuracy: 0.5299\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8680 - accuracy: 0.5519 - val_loss: 0.9619 - val_accuracy: 0.5299\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8673 - accuracy: 0.5519 - val_loss: 0.9601 - val_accuracy: 0.5299\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8669 - accuracy: 0.5519 - val_loss: 0.9600 - val_accuracy: 0.5299\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8661 - accuracy: 0.5481 - val_loss: 0.9593 - val_accuracy: 0.5128\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8670 - accuracy: 0.5222 - val_loss: 0.9584 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8669 - accuracy: 0.5111 - val_loss: 0.9596 - val_accuracy: 0.5128\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8655 - accuracy: 0.5444 - val_loss: 0.9615 - val_accuracy: 0.5128\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8670 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8676 - accuracy: 0.5519 - val_loss: 0.9682 - val_accuracy: 0.5299\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8678 - accuracy: 0.5519 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8670 - accuracy: 0.5519 - val_loss: 0.9600 - val_accuracy: 0.5299\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8658 - accuracy: 0.5333 - val_loss: 0.9586 - val_accuracy: 0.5128\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8669 - accuracy: 0.5444 - val_loss: 0.9569 - val_accuracy: 0.5299\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.8661 - accuracy: 0.5556 - val_loss: 0.9588 - val_accuracy: 0.5299\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8653 - accuracy: 0.5519 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.8664 - accuracy: 0.5519 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8660 - accuracy: 0.5519 - val_loss: 0.9626 - val_accuracy: 0.5128\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8667 - accuracy: 0.5407 - val_loss: 0.9601 - val_accuracy: 0.5128\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8654 - accuracy: 0.5407 - val_loss: 0.9578 - val_accuracy: 0.5299\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8654 - accuracy: 0.5556 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8647 - accuracy: 0.5556 - val_loss: 0.9592 - val_accuracy: 0.5299\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8656 - accuracy: 0.5519 - val_loss: 0.9618 - val_accuracy: 0.5299\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8659 - accuracy: 0.5519 - val_loss: 0.9610 - val_accuracy: 0.5299\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8661 - accuracy: 0.5519 - val_loss: 0.9595 - val_accuracy: 0.5299\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8649 - accuracy: 0.5519 - val_loss: 0.9597 - val_accuracy: 0.5299\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8654 - accuracy: 0.5556 - val_loss: 0.9558 - val_accuracy: 0.5299\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8665 - accuracy: 0.5556 - val_loss: 0.9552 - val_accuracy: 0.5299\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8660 - accuracy: 0.5556 - val_loss: 0.9560 - val_accuracy: 0.5299\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8648 - accuracy: 0.5519 - val_loss: 0.9600 - val_accuracy: 0.5299\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8644 - accuracy: 0.5519 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8699 - accuracy: 0.5519 - val_loss: 0.9696 - val_accuracy: 0.5299\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8681 - accuracy: 0.5519 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8654 - accuracy: 0.5519 - val_loss: 0.9575 - val_accuracy: 0.5299\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8659 - accuracy: 0.5556 - val_loss: 0.9553 - val_accuracy: 0.5299\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8659 - accuracy: 0.5556 - val_loss: 0.9551 - val_accuracy: 0.5299\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8656 - accuracy: 0.5407 - val_loss: 0.9562 - val_accuracy: 0.5128\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8657 - accuracy: 0.5444 - val_loss: 0.9577 - val_accuracy: 0.5128\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8656 - accuracy: 0.5444 - val_loss: 0.9571 - val_accuracy: 0.5128\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8672 - accuracy: 0.5259 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8648 - accuracy: 0.5556 - val_loss: 0.9573 - val_accuracy: 0.5299\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8670 - accuracy: 0.5333 - val_loss: 0.9618 - val_accuracy: 0.5128\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8661 - accuracy: 0.5444 - val_loss: 0.9590 - val_accuracy: 0.5128\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 0.9584 - val_accuracy: 0.5299\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8646 - accuracy: 0.5333 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8643 - accuracy: 0.5556 - val_loss: 0.9609 - val_accuracy: 0.5299\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8638 - accuracy: 0.5667 - val_loss: 0.9605 - val_accuracy: 0.5128\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8652 - accuracy: 0.5444 - val_loss: 0.9581 - val_accuracy: 0.5128\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8650 - accuracy: 0.5444 - val_loss: 0.9601 - val_accuracy: 0.5128\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8646 - accuracy: 0.5370 - val_loss: 0.9618 - val_accuracy: 0.5299\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8637 - accuracy: 0.5556 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8656 - accuracy: 0.5519 - val_loss: 0.9716 - val_accuracy: 0.5299\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8677 - accuracy: 0.5519 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8666 - accuracy: 0.5519 - val_loss: 0.9660 - val_accuracy: 0.5299\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8651 - accuracy: 0.5519 - val_loss: 0.9614 - val_accuracy: 0.5299\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8667 - accuracy: 0.5519 - val_loss: 0.9582 - val_accuracy: 0.5214\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8660 - accuracy: 0.5556 - val_loss: 0.9599 - val_accuracy: 0.5299\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8641 - accuracy: 0.5481 - val_loss: 0.9636 - val_accuracy: 0.5128\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8645 - accuracy: 0.5444 - val_loss: 0.9654 - val_accuracy: 0.5128\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8661 - accuracy: 0.5407 - val_loss: 0.9660 - val_accuracy: 0.5128\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8654 - accuracy: 0.5519 - val_loss: 0.9631 - val_accuracy: 0.5299\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8627 - accuracy: 0.5556 - val_loss: 0.9594 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8634 - accuracy: 0.5556 - val_loss: 0.9577 - val_accuracy: 0.5299\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8645 - accuracy: 0.5556 - val_loss: 0.9574 - val_accuracy: 0.5299\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8640 - accuracy: 0.5556 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8638 - accuracy: 0.5556 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8633 - accuracy: 0.5556 - val_loss: 0.9604 - val_accuracy: 0.5128\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8636 - accuracy: 0.5444 - val_loss: 0.9598 - val_accuracy: 0.5128\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8635 - accuracy: 0.5444 - val_loss: 0.9580 - val_accuracy: 0.5299\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8651 - accuracy: 0.5519 - val_loss: 0.9586 - val_accuracy: 0.5214\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8654 - accuracy: 0.5556 - val_loss: 0.9616 - val_accuracy: 0.5299\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8627 - accuracy: 0.5556 - val_loss: 0.9597 - val_accuracy: 0.5299\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8632 - accuracy: 0.5593 - val_loss: 0.9584 - val_accuracy: 0.5214\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8634 - accuracy: 0.5407 - val_loss: 0.9598 - val_accuracy: 0.5128\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8682 - accuracy: 0.5444 - val_loss: 0.9641 - val_accuracy: 0.5128\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8639 - accuracy: 0.5444 - val_loss: 0.9615 - val_accuracy: 0.5299\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8629 - accuracy: 0.5556 - val_loss: 0.9620 - val_accuracy: 0.5299\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8647 - accuracy: 0.5556 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8653 - accuracy: 0.5556 - val_loss: 0.9654 - val_accuracy: 0.5299\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8636 - accuracy: 0.5556 - val_loss: 0.9667 - val_accuracy: 0.5299\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8631 - accuracy: 0.5519 - val_loss: 0.9675 - val_accuracy: 0.5299\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8641 - accuracy: 0.5185 - val_loss: 0.9636 - val_accuracy: 0.5128\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8637 - accuracy: 0.5444 - val_loss: 0.9637 - val_accuracy: 0.5128\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8634 - accuracy: 0.5444 - val_loss: 0.9651 - val_accuracy: 0.5128\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8629 - accuracy: 0.5333 - val_loss: 0.9641 - val_accuracy: 0.5299\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8622 - accuracy: 0.5556 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8617 - accuracy: 0.5556 - val_loss: 0.9665 - val_accuracy: 0.5299\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8631 - accuracy: 0.5519 - val_loss: 0.9676 - val_accuracy: 0.5299\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8637 - accuracy: 0.5519 - val_loss: 0.9667 - val_accuracy: 0.5299\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8633 - accuracy: 0.5556 - val_loss: 0.9618 - val_accuracy: 0.5299\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8619 - accuracy: 0.5556 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8631 - accuracy: 0.5481 - val_loss: 0.9590 - val_accuracy: 0.5128\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8630 - accuracy: 0.5444 - val_loss: 0.9599 - val_accuracy: 0.5128\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8638 - accuracy: 0.5444 - val_loss: 0.9630 - val_accuracy: 0.5128\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8655 - accuracy: 0.5444 - val_loss: 0.9623 - val_accuracy: 0.5128\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8636 - accuracy: 0.5444 - val_loss: 0.9581 - val_accuracy: 0.5299\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8618 - accuracy: 0.5556 - val_loss: 0.9611 - val_accuracy: 0.5214\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8636 - accuracy: 0.5556 - val_loss: 0.9643 - val_accuracy: 0.5214\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8686 - accuracy: 0.5556 - val_loss: 0.9668 - val_accuracy: 0.5214\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8682 - accuracy: 0.5556 - val_loss: 0.9651 - val_accuracy: 0.5299\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8634 - accuracy: 0.5556 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8623 - accuracy: 0.5556 - val_loss: 0.9621 - val_accuracy: 0.5299\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8621 - accuracy: 0.5556 - val_loss: 0.9603 - val_accuracy: 0.5299\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8618 - accuracy: 0.5556 - val_loss: 0.9577 - val_accuracy: 0.5214\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8617 - accuracy: 0.5556 - val_loss: 0.9573 - val_accuracy: 0.5214\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8634 - accuracy: 0.5556 - val_loss: 0.9590 - val_accuracy: 0.5214\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8636 - accuracy: 0.5556 - val_loss: 0.9622 - val_accuracy: 0.5214\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8625 - accuracy: 0.5556 - val_loss: 0.9608 - val_accuracy: 0.5299\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8627 - accuracy: 0.5556 - val_loss: 0.9593 - val_accuracy: 0.5214\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8626 - accuracy: 0.5333 - val_loss: 0.9605 - val_accuracy: 0.5214\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8617 - accuracy: 0.5593 - val_loss: 0.9634 - val_accuracy: 0.5299\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8615 - accuracy: 0.5556 - val_loss: 0.9659 - val_accuracy: 0.5299\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8618 - accuracy: 0.5556 - val_loss: 0.9624 - val_accuracy: 0.5214\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8634 - accuracy: 0.5556 - val_loss: 0.9631 - val_accuracy: 0.5214\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8648 - accuracy: 0.5519 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8633 - accuracy: 0.5556 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8617 - accuracy: 0.5556 - val_loss: 0.9638 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.8612 - accuracy: 0.5296 - val_loss: 0.9681 - val_accuracy: 0.5128\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8622 - accuracy: 0.5444 - val_loss: 0.9685 - val_accuracy: 0.5128\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.8636 - accuracy: 0.5111 - val_loss: 0.9691 - val_accuracy: 0.5128\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.8640 - accuracy: 0.5444 - val_loss: 0.9646 - val_accuracy: 0.5128\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.8653 - accuracy: 0.5444 - val_loss: 0.9668 - val_accuracy: 0.5128\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8644 - accuracy: 0.5444 - val_loss: 0.9641 - val_accuracy: 0.5128\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 0.9630 - val_accuracy: 0.5299\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8610 - accuracy: 0.5556 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8610 - accuracy: 0.5556 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8608 - accuracy: 0.5556 - val_loss: 0.9637 - val_accuracy: 0.5299\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8599 - accuracy: 0.5556 - val_loss: 0.9636 - val_accuracy: 0.5299\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8617 - accuracy: 0.5519 - val_loss: 0.9646 - val_accuracy: 0.5214\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8613 - accuracy: 0.5519 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8612 - accuracy: 0.5630 - val_loss: 0.9647 - val_accuracy: 0.5128\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8612 - accuracy: 0.5444 - val_loss: 0.9679 - val_accuracy: 0.5128\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8613 - accuracy: 0.5444 - val_loss: 0.9679 - val_accuracy: 0.5128\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8616 - accuracy: 0.5407 - val_loss: 0.9668 - val_accuracy: 0.5128\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8629 - accuracy: 0.5593 - val_loss: 0.9658 - val_accuracy: 0.5214\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8608 - accuracy: 0.5556 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8604 - accuracy: 0.5556 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8600 - accuracy: 0.5556 - val_loss: 0.9631 - val_accuracy: 0.5299\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8603 - accuracy: 0.5556 - val_loss: 0.9630 - val_accuracy: 0.5299\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8608 - accuracy: 0.5556 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8607 - accuracy: 0.5407 - val_loss: 0.9658 - val_accuracy: 0.5128\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8616 - accuracy: 0.5444 - val_loss: 0.9625 - val_accuracy: 0.5128\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8622 - accuracy: 0.5444 - val_loss: 0.9598 - val_accuracy: 0.5128\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8614 - accuracy: 0.5704 - val_loss: 0.9593 - val_accuracy: 0.5299\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8618 - accuracy: 0.5519 - val_loss: 0.9589 - val_accuracy: 0.5299\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8610 - accuracy: 0.5556 - val_loss: 0.9613 - val_accuracy: 0.5299\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8607 - accuracy: 0.5556 - val_loss: 0.9639 - val_accuracy: 0.5299\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8603 - accuracy: 0.5519 - val_loss: 0.9619 - val_accuracy: 0.5214\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8605 - accuracy: 0.5556 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8603 - accuracy: 0.5519 - val_loss: 0.9602 - val_accuracy: 0.5214\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8604 - accuracy: 0.5556 - val_loss: 0.9622 - val_accuracy: 0.5214\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8606 - accuracy: 0.5556 - val_loss: 0.9645 - val_accuracy: 0.5214\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8619 - accuracy: 0.5593 - val_loss: 0.9687 - val_accuracy: 0.5299\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8621 - accuracy: 0.5519 - val_loss: 0.9702 - val_accuracy: 0.5299\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8621 - accuracy: 0.5519 - val_loss: 0.9678 - val_accuracy: 0.5299\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8603 - accuracy: 0.5519 - val_loss: 0.9605 - val_accuracy: 0.5128\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8603 - accuracy: 0.5407 - val_loss: 0.9591 - val_accuracy: 0.5043\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8626 - accuracy: 0.5444 - val_loss: 0.9606 - val_accuracy: 0.5128\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8632 - accuracy: 0.5444 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8589 - accuracy: 0.5556 - val_loss: 0.9678 - val_accuracy: 0.5299\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8594 - accuracy: 0.5556 - val_loss: 0.9673 - val_accuracy: 0.5299\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8605 - accuracy: 0.5556 - val_loss: 0.9662 - val_accuracy: 0.5214\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8605 - accuracy: 0.5556 - val_loss: 0.9643 - val_accuracy: 0.5214\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8600 - accuracy: 0.5556 - val_loss: 0.9636 - val_accuracy: 0.5299\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8596 - accuracy: 0.5556 - val_loss: 0.9650 - val_accuracy: 0.5299\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8596 - accuracy: 0.5556 - val_loss: 0.9676 - val_accuracy: 0.5299\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8633 - accuracy: 0.5111 - val_loss: 0.9689 - val_accuracy: 0.5128\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8607 - accuracy: 0.5259 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8598 - accuracy: 0.5074 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8594 - accuracy: 0.5519 - val_loss: 0.9634 - val_accuracy: 0.5214\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8603 - accuracy: 0.5556 - val_loss: 0.9654 - val_accuracy: 0.5214\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8599 - accuracy: 0.5556 - val_loss: 0.9665 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8604 - accuracy: 0.5556 - val_loss: 0.9655 - val_accuracy: 0.5299\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8601 - accuracy: 0.5556 - val_loss: 0.9650 - val_accuracy: 0.5299\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8591 - accuracy: 0.5556 - val_loss: 0.9612 - val_accuracy: 0.5299\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8624 - accuracy: 0.5556 - val_loss: 0.9579 - val_accuracy: 0.5214\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8625 - accuracy: 0.5556 - val_loss: 0.9579 - val_accuracy: 0.5214\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8611 - accuracy: 0.5556 - val_loss: 0.9610 - val_accuracy: 0.5214\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8591 - accuracy: 0.5556 - val_loss: 0.9637 - val_accuracy: 0.5214\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8603 - accuracy: 0.5556 - val_loss: 0.9628 - val_accuracy: 0.5214\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8600 - accuracy: 0.5519 - val_loss: 0.9654 - val_accuracy: 0.5299\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8605 - accuracy: 0.5556 - val_loss: 0.9654 - val_accuracy: 0.5299\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8598 - accuracy: 0.5556 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8587 - accuracy: 0.5556 - val_loss: 0.9621 - val_accuracy: 0.5299\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8591 - accuracy: 0.5556 - val_loss: 0.9604 - val_accuracy: 0.5214\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8611 - accuracy: 0.5556 - val_loss: 0.9617 - val_accuracy: 0.5214\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8605 - accuracy: 0.5556 - val_loss: 0.9624 - val_accuracy: 0.5299\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8594 - accuracy: 0.5556 - val_loss: 0.9647 - val_accuracy: 0.5299\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8587 - accuracy: 0.5556 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8588 - accuracy: 0.5556 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8582 - accuracy: 0.5556 - val_loss: 0.9602 - val_accuracy: 0.5299\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8590 - accuracy: 0.5556 - val_loss: 0.9590 - val_accuracy: 0.5299\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8600 - accuracy: 0.5556 - val_loss: 0.9622 - val_accuracy: 0.5299\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8582 - accuracy: 0.5556 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8587 - accuracy: 0.5556 - val_loss: 0.9611 - val_accuracy: 0.5128\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8583 - accuracy: 0.5444 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8587 - accuracy: 0.5444 - val_loss: 0.9635 - val_accuracy: 0.5128\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8583 - accuracy: 0.5444 - val_loss: 0.9645 - val_accuracy: 0.5128\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8584 - accuracy: 0.5444 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8584 - accuracy: 0.5556 - val_loss: 0.9658 - val_accuracy: 0.5299\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8615 - accuracy: 0.5556 - val_loss: 0.9652 - val_accuracy: 0.5299\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8596 - accuracy: 0.5556 - val_loss: 0.9676 - val_accuracy: 0.5299\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8582 - accuracy: 0.5444 - val_loss: 0.9683 - val_accuracy: 0.5299\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8581 - accuracy: 0.5556 - val_loss: 0.9707 - val_accuracy: 0.5299\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8581 - accuracy: 0.5556 - val_loss: 0.9684 - val_accuracy: 0.5299\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8598 - accuracy: 0.5556 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8579 - accuracy: 0.5556 - val_loss: 0.9664 - val_accuracy: 0.5299\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8571 - accuracy: 0.5556 - val_loss: 0.9700 - val_accuracy: 0.5299\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8580 - accuracy: 0.5556 - val_loss: 0.9722 - val_accuracy: 0.5299\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8586 - accuracy: 0.5556 - val_loss: 0.9716 - val_accuracy: 0.5299\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8611 - accuracy: 0.5556 - val_loss: 0.9733 - val_accuracy: 0.5299\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8615 - accuracy: 0.5444 - val_loss: 0.9712 - val_accuracy: 0.5128\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8604 - accuracy: 0.5444 - val_loss: 0.9703 - val_accuracy: 0.5128\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8592 - accuracy: 0.5444 - val_loss: 0.9670 - val_accuracy: 0.5128\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8591 - accuracy: 0.5444 - val_loss: 0.9658 - val_accuracy: 0.5299\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8590 - accuracy: 0.5556 - val_loss: 0.9675 - val_accuracy: 0.5214\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8606 - accuracy: 0.5556 - val_loss: 0.9674 - val_accuracy: 0.5299\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8587 - accuracy: 0.5556 - val_loss: 0.9677 - val_accuracy: 0.5299\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8591 - accuracy: 0.5333 - val_loss: 0.9677 - val_accuracy: 0.5128\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8579 - accuracy: 0.5630 - val_loss: 0.9682 - val_accuracy: 0.5299\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8577 - accuracy: 0.5556 - val_loss: 0.9740 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39522438>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 66us/step\n",
      "over-sampling test accuracy: 52.14%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 2, 1, 2, 1, 2, 0, 0, 1, 2, 1,\n",
       "       0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2,\n",
       "       0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0,\n",
       "       1, 1, 0, 1, 2, 1, 0, 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 0, 2, 0, 0, 0, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS245     1     2\n",
       "1          NY439     2     2\n",
       "2          CA544     1     0\n",
       "3          CA541     2     0\n",
       "4          EUH15     1     0\n",
       "..           ...   ...   ...\n",
       "112       NRS112     0     0\n",
       "113     CFBRSa51     2     0\n",
       "114       NRS383     1     0\n",
       "115       NRS247     0     0\n",
       "116  CFBREBSa103     0     0\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013458</td>\n",
       "      <td>0.216479</td>\n",
       "      <td>0.770063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026742</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.972329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.414748</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>0.222618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.414748</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>0.222618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414748</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>0.222618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.672051</td>\n",
       "      <td>0.276171</td>\n",
       "      <td>0.051778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.414748</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>0.222618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.672051</td>\n",
       "      <td>0.276171</td>\n",
       "      <td>0.051778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.672051</td>\n",
       "      <td>0.276171</td>\n",
       "      <td>0.051778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.414748</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>0.222618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.013458  0.216479  0.770063\n",
       "1    0.026742  0.000929  0.972329\n",
       "2    0.414748  0.362633  0.222618\n",
       "3    0.414748  0.362633  0.222618\n",
       "4    0.414748  0.362633  0.222618\n",
       "..        ...       ...       ...\n",
       "112  0.672051  0.276171  0.051778\n",
       "113  0.414748  0.362633  0.222618\n",
       "114  0.672051  0.276171  0.051778\n",
       "115  0.672051  0.276171  0.051778\n",
       "116  0.414748  0.362633  0.222618\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.0148 - val_accuracy: 0.5214\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8541 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.5214\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0110 - val_accuracy: 0.5043\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0111 - val_accuracy: 0.5043\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8516 - accuracy: 0.5444 - val_loss: 1.0080 - val_accuracy: 0.5043\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0063 - val_accuracy: 0.5043\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8475 - accuracy: 0.5667 - val_loss: 1.0060 - val_accuracy: 0.5214\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8521 - accuracy: 0.5556 - val_loss: 1.0076 - val_accuracy: 0.5214\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8558 - accuracy: 0.5556 - val_loss: 1.0068 - val_accuracy: 0.5214\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8506 - accuracy: 0.5556 - val_loss: 1.0107 - val_accuracy: 0.5214\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8491 - accuracy: 0.5630 - val_loss: 1.0189 - val_accuracy: 0.5128\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8530 - accuracy: 0.5444 - val_loss: 1.0236 - val_accuracy: 0.5128\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8537 - accuracy: 0.5444 - val_loss: 1.0200 - val_accuracy: 0.5299\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.0175 - val_accuracy: 0.5299\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8513 - accuracy: 0.5444 - val_loss: 1.0128 - val_accuracy: 0.5299\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.0077 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0090 - val_accuracy: 0.5214\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.0118 - val_accuracy: 0.5214\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8528 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.5214\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8553 - accuracy: 0.5556 - val_loss: 1.0124 - val_accuracy: 0.5214\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8511 - accuracy: 0.5556 - val_loss: 1.0099 - val_accuracy: 0.5299\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8516 - accuracy: 0.5630 - val_loss: 1.0150 - val_accuracy: 0.5128\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8548 - accuracy: 0.5444 - val_loss: 1.0158 - val_accuracy: 0.5043\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8521 - accuracy: 0.5481 - val_loss: 1.0078 - val_accuracy: 0.4957\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8475 - accuracy: 0.5519 - val_loss: 1.0069 - val_accuracy: 0.5128\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.0092 - val_accuracy: 0.5128\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.0073 - val_accuracy: 0.5128\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8499 - accuracy: 0.5296 - val_loss: 1.0098 - val_accuracy: 0.4957\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8511 - accuracy: 0.5444 - val_loss: 1.0100 - val_accuracy: 0.4957\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8510 - accuracy: 0.5444 - val_loss: 1.0147 - val_accuracy: 0.5214\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0139 - val_accuracy: 0.5214\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.0137 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8560 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.5214\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8535 - accuracy: 0.5556 - val_loss: 1.0038 - val_accuracy: 0.5214\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 0.9968 - val_accuracy: 0.5214\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8517 - accuracy: 0.5667 - val_loss: 0.9996 - val_accuracy: 0.5043\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8527 - accuracy: 0.5444 - val_loss: 1.0004 - val_accuracy: 0.5043\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8485 - accuracy: 0.5704 - val_loss: 1.0030 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 1.0078 - val_accuracy: 0.5214\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.0071 - val_accuracy: 0.5214\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8481 - accuracy: 0.5630 - val_loss: 1.0050 - val_accuracy: 0.5043\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8504 - accuracy: 0.5444 - val_loss: 1.0037 - val_accuracy: 0.5043\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8506 - accuracy: 0.5519 - val_loss: 1.0045 - val_accuracy: 0.5214\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8549 - accuracy: 0.5556 - val_loss: 1.0067 - val_accuracy: 0.5214\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8525 - accuracy: 0.5556 - val_loss: 1.0064 - val_accuracy: 0.5214\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0068 - val_accuracy: 0.5043\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 1.0069 - val_accuracy: 0.5214\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0099 - val_accuracy: 0.5214\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0134 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.5214\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.0162 - val_accuracy: 0.5214\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.0074 - val_accuracy: 0.5214\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0065 - val_accuracy: 0.5214\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0062 - val_accuracy: 0.5214\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8496 - accuracy: 0.5370 - val_loss: 1.0074 - val_accuracy: 0.4957\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8501 - accuracy: 0.5444 - val_loss: 1.0053 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0052 - val_accuracy: 0.5214\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0083 - val_accuracy: 0.5214\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.0094 - val_accuracy: 0.5214\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0115 - val_accuracy: 0.5214\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0126 - val_accuracy: 0.5214\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.0138 - val_accuracy: 0.5214\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.0103 - val_accuracy: 0.5214\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0064 - val_accuracy: 0.5214\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0033 - val_accuracy: 0.5214\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0023 - val_accuracy: 0.5214\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0034 - val_accuracy: 0.5214\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8483 - accuracy: 0.5333 - val_loss: 1.0074 - val_accuracy: 0.4957\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8524 - accuracy: 0.5444 - val_loss: 1.0103 - val_accuracy: 0.4957\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8495 - accuracy: 0.5444 - val_loss: 1.0133 - val_accuracy: 0.5214\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.5214\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8506 - accuracy: 0.5556 - val_loss: 1.0159 - val_accuracy: 0.5214\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.0047 - val_accuracy: 0.5214\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0015 - val_accuracy: 0.5214\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.0001 - val_accuracy: 0.5043\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8493 - accuracy: 0.5222 - val_loss: 1.0018 - val_accuracy: 0.5214\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 1.0064 - val_accuracy: 0.5214\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.0043 - val_accuracy: 0.5214\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8487 - accuracy: 0.5444 - val_loss: 1.0055 - val_accuracy: 0.5043\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8483 - accuracy: 0.5444 - val_loss: 1.0030 - val_accuracy: 0.5128\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8511 - accuracy: 0.5556 - val_loss: 1.0015 - val_accuracy: 0.5128\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8507 - accuracy: 0.5519 - val_loss: 1.0047 - val_accuracy: 0.5214\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.0119 - val_accuracy: 0.5043\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8497 - accuracy: 0.5444 - val_loss: 1.0151 - val_accuracy: 0.5043\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8505 - accuracy: 0.5444 - val_loss: 1.0137 - val_accuracy: 0.5043\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8495 - accuracy: 0.5481 - val_loss: 1.0128 - val_accuracy: 0.5214\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.5214\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.0114 - val_accuracy: 0.5214\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0087 - val_accuracy: 0.5214\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0071 - val_accuracy: 0.5214\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0087 - val_accuracy: 0.5214\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8489 - accuracy: 0.5741 - val_loss: 1.0109 - val_accuracy: 0.5043\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8488 - accuracy: 0.5481 - val_loss: 1.0085 - val_accuracy: 0.4957\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8495 - accuracy: 0.5074 - val_loss: 1.0061 - val_accuracy: 0.5128\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8512 - accuracy: 0.5185 - val_loss: 1.0069 - val_accuracy: 0.5128\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8493 - accuracy: 0.5519 - val_loss: 1.0119 - val_accuracy: 0.5214\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.0182 - val_accuracy: 0.5214\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.5214\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.5299\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8489 - accuracy: 0.5370 - val_loss: 1.0170 - val_accuracy: 0.5128\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0108 - val_accuracy: 0.5043\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.0065 - val_accuracy: 0.5214\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0035 - val_accuracy: 0.5214\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8507 - accuracy: 0.5593 - val_loss: 1.0012 - val_accuracy: 0.5128\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8505 - accuracy: 0.5556 - val_loss: 1.0019 - val_accuracy: 0.5214\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0050 - val_accuracy: 0.5214\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0105 - val_accuracy: 0.5214\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8483 - accuracy: 0.5259 - val_loss: 1.0160 - val_accuracy: 0.5128\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8497 - accuracy: 0.5444 - val_loss: 1.0189 - val_accuracy: 0.5299\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8485 - accuracy: 0.5519 - val_loss: 1.0139 - val_accuracy: 0.5214\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8496 - accuracy: 0.5593 - val_loss: 1.0147 - val_accuracy: 0.5299\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0122 - val_accuracy: 0.5299\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8484 - accuracy: 0.5593 - val_loss: 1.0080 - val_accuracy: 0.5128\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8482 - accuracy: 0.5481 - val_loss: 1.0081 - val_accuracy: 0.4957\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8479 - accuracy: 0.5741 - val_loss: 1.0076 - val_accuracy: 0.5128\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.0120 - val_accuracy: 0.5214\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.5214\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8478 - accuracy: 0.5593 - val_loss: 1.0196 - val_accuracy: 0.5299\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.0219 - val_accuracy: 0.5299\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.0192 - val_accuracy: 0.5299\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0142 - val_accuracy: 0.5214\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0110 - val_accuracy: 0.5214\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8483 - accuracy: 0.5333 - val_loss: 1.0103 - val_accuracy: 0.5214\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0069 - val_accuracy: 0.5214\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0005 - val_accuracy: 0.5214\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 0.9989 - val_accuracy: 0.5128\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 0.9986 - val_accuracy: 0.5128\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0011 - val_accuracy: 0.4957\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8504 - accuracy: 0.5444 - val_loss: 1.0041 - val_accuracy: 0.4957\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8495 - accuracy: 0.5444 - val_loss: 1.0026 - val_accuracy: 0.5214\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0055 - val_accuracy: 0.5214\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.0083 - val_accuracy: 0.5214\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0117 - val_accuracy: 0.5214\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.5214\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.0135 - val_accuracy: 0.5214\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8492 - accuracy: 0.5185 - val_loss: 1.0136 - val_accuracy: 0.5043\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0135 - val_accuracy: 0.5043\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.0131 - val_accuracy: 0.5043\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.8490 - accuracy: 0.5296 - val_loss: 1.0128 - val_accuracy: 0.5214\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.0114 - val_accuracy: 0.5214\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8480 - accuracy: 0.5222 - val_loss: 1.0110 - val_accuracy: 0.5043\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8477 - accuracy: 0.5444 - val_loss: 1.0080 - val_accuracy: 0.5214\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.0066 - val_accuracy: 0.5214\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8491 - accuracy: 0.5481 - val_loss: 1.0048 - val_accuracy: 0.5043\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8494 - accuracy: 0.5148 - val_loss: 1.0076 - val_accuracy: 0.5214\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0095 - val_accuracy: 0.5043\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 370us/step - loss: 0.8478 - accuracy: 0.5370 - val_loss: 1.0099 - val_accuracy: 0.5043\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8493 - accuracy: 0.5259 - val_loss: 1.0108 - val_accuracy: 0.5214\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8485 - accuracy: 0.5296 - val_loss: 1.0130 - val_accuracy: 0.5043\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8489 - accuracy: 0.5444 - val_loss: 1.0128 - val_accuracy: 0.5043\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8492 - accuracy: 0.5444 - val_loss: 1.0120 - val_accuracy: 0.5043\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8473 - accuracy: 0.5444 - val_loss: 1.0133 - val_accuracy: 0.5214\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0127 - val_accuracy: 0.5214\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0113 - val_accuracy: 0.5214\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0107 - val_accuracy: 0.5214\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0110 - val_accuracy: 0.5214\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0107 - val_accuracy: 0.5214\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0091 - val_accuracy: 0.5214\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0083 - val_accuracy: 0.5214\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0061 - val_accuracy: 0.5214\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8489 - accuracy: 0.5481 - val_loss: 1.0017 - val_accuracy: 0.5043\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8489 - accuracy: 0.5444 - val_loss: 1.0044 - val_accuracy: 0.5043\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8514 - accuracy: 0.5444 - val_loss: 1.0075 - val_accuracy: 0.5043\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 1.0067 - val_accuracy: 0.5214\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8483 - accuracy: 0.5519 - val_loss: 1.0082 - val_accuracy: 0.5128\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.0138 - val_accuracy: 0.5214\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.5214\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.0109 - val_accuracy: 0.5043\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8495 - accuracy: 0.5444 - val_loss: 1.0111 - val_accuracy: 0.4957\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8537 - accuracy: 0.5444 - val_loss: 1.0069 - val_accuracy: 0.4957\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 1.0062 - val_accuracy: 0.5128\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0113 - val_accuracy: 0.5128\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0176 - val_accuracy: 0.5214\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.5299\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.5299\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0095 - val_accuracy: 0.5128\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0097 - val_accuracy: 0.5128\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0109 - val_accuracy: 0.5128\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0100 - val_accuracy: 0.5128\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0105 - val_accuracy: 0.5128\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8471 - accuracy: 0.5519 - val_loss: 1.0122 - val_accuracy: 0.5214\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0173 - val_accuracy: 0.5299\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.5299\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8491 - accuracy: 0.5407 - val_loss: 1.0163 - val_accuracy: 0.5214\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0121 - val_accuracy: 0.5214\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0081 - val_accuracy: 0.5128\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.0044 - val_accuracy: 0.5128\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.0035 - val_accuracy: 0.5128\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8504 - accuracy: 0.5222 - val_loss: 1.0092 - val_accuracy: 0.4957\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0101 - val_accuracy: 0.5214\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0086 - val_accuracy: 0.5214\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0074 - val_accuracy: 0.5214\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0069 - val_accuracy: 0.5128\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0091 - val_accuracy: 0.5128\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8478 - accuracy: 0.5704 - val_loss: 1.0135 - val_accuracy: 0.5043\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8471 - accuracy: 0.5444 - val_loss: 1.0133 - val_accuracy: 0.5043\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0126 - val_accuracy: 0.5043\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8481 - accuracy: 0.5370 - val_loss: 1.0137 - val_accuracy: 0.5214\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0123 - val_accuracy: 0.5214\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0149 - val_accuracy: 0.5214\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8489 - accuracy: 0.5259 - val_loss: 1.0186 - val_accuracy: 0.5128\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8491 - accuracy: 0.5444 - val_loss: 1.0161 - val_accuracy: 0.5128\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8481 - accuracy: 0.5444 - val_loss: 1.0109 - val_accuracy: 0.5214\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0082 - val_accuracy: 0.5214\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.0111 - val_accuracy: 0.5214\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.5214\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8537 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.5214\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0187 - val_accuracy: 0.5214\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8525 - accuracy: 0.5111 - val_loss: 1.0241 - val_accuracy: 0.5128\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8520 - accuracy: 0.5444 - val_loss: 1.0159 - val_accuracy: 0.5043\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8475 - accuracy: 0.5333 - val_loss: 1.0116 - val_accuracy: 0.5214\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0098 - val_accuracy: 0.5214\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.0065 - val_accuracy: 0.5214\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.0078 - val_accuracy: 0.5214\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.5214\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0158 - val_accuracy: 0.5214\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.5214\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.0130 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0113 - val_accuracy: 0.5214\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8472 - accuracy: 0.5630 - val_loss: 1.0104 - val_accuracy: 0.5043\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8494 - accuracy: 0.5444 - val_loss: 1.0113 - val_accuracy: 0.5043\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.0074 - val_accuracy: 0.5128\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8517 - accuracy: 0.5556 - val_loss: 1.0096 - val_accuracy: 0.5214\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.0105 - val_accuracy: 0.5214\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0125 - val_accuracy: 0.5214\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0147 - val_accuracy: 0.5214\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8475 - accuracy: 0.5222 - val_loss: 1.0161 - val_accuracy: 0.5043\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.0111 - val_accuracy: 0.5043\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8465 - accuracy: 0.5481 - val_loss: 1.0099 - val_accuracy: 0.5214\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.0107 - val_accuracy: 0.5214\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.0121 - val_accuracy: 0.5214\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8488 - accuracy: 0.5704 - val_loss: 1.0189 - val_accuracy: 0.5043\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8539 - accuracy: 0.5444 - val_loss: 1.0167 - val_accuracy: 0.5043\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8494 - accuracy: 0.5444 - val_loss: 1.0122 - val_accuracy: 0.5214\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0144 - val_accuracy: 0.5214\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0201 - val_accuracy: 0.5214\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.5214\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0131 - val_accuracy: 0.5214\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0109 - val_accuracy: 0.5214\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0050 - val_accuracy: 0.5128\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0030 - val_accuracy: 0.5128\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8502 - accuracy: 0.5630 - val_loss: 1.0084 - val_accuracy: 0.4957\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8517 - accuracy: 0.5444 - val_loss: 1.0099 - val_accuracy: 0.4957\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8501 - accuracy: 0.5407 - val_loss: 1.0106 - val_accuracy: 0.5043\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0133 - val_accuracy: 0.5043\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.0177 - val_accuracy: 0.5214\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8505 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5214\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0179 - val_accuracy: 0.5214\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0145 - val_accuracy: 0.5043\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0122 - val_accuracy: 0.5043\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8492 - accuracy: 0.5407 - val_loss: 1.0079 - val_accuracy: 0.5128\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.0067 - val_accuracy: 0.5214\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0085 - val_accuracy: 0.5214\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0138 - val_accuracy: 0.5043\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0151 - val_accuracy: 0.5043\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8496 - accuracy: 0.5296 - val_loss: 1.0134 - val_accuracy: 0.5214\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8488 - accuracy: 0.5333 - val_loss: 1.0099 - val_accuracy: 0.5043\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8475 - accuracy: 0.5481 - val_loss: 1.0072 - val_accuracy: 0.5214\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8480 - accuracy: 0.5407 - val_loss: 1.0067 - val_accuracy: 0.5043\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8505 - accuracy: 0.5444 - val_loss: 1.0073 - val_accuracy: 0.5214\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8510 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.5214\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8493 - accuracy: 0.5296 - val_loss: 1.0201 - val_accuracy: 0.5128\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8494 - accuracy: 0.5333 - val_loss: 1.0194 - val_accuracy: 0.5214\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8478 - accuracy: 0.5370 - val_loss: 1.0205 - val_accuracy: 0.5214\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0185 - val_accuracy: 0.5214\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0202 - val_accuracy: 0.5214\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0192 - val_accuracy: 0.5214\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0175 - val_accuracy: 0.5214\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.5214\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.5214\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0119 - val_accuracy: 0.5214\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.0172 - val_accuracy: 0.5214\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0199 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0215 - val_accuracy: 0.5043\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8504 - accuracy: 0.5296 - val_loss: 1.0214 - val_accuracy: 0.5214\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0182 - val_accuracy: 0.5214\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 385us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0183 - val_accuracy: 0.5214\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8479 - accuracy: 0.5185 - val_loss: 1.0192 - val_accuracy: 0.5043\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8479 - accuracy: 0.5444 - val_loss: 1.0197 - val_accuracy: 0.5043\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8476 - accuracy: 0.5519 - val_loss: 1.0189 - val_accuracy: 0.5214\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0198 - val_accuracy: 0.5214\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0187 - val_accuracy: 0.5214\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 349us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0172 - val_accuracy: 0.5214\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8505 - accuracy: 0.4852 - val_loss: 1.0166 - val_accuracy: 0.5214\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 451us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.5214\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0161 - val_accuracy: 0.5214\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.0093 - val_accuracy: 0.5214\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0037 - val_accuracy: 0.5043\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 1.0037 - val_accuracy: 0.5043\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8463 - accuracy: 0.5481 - val_loss: 1.0013 - val_accuracy: 0.5214\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0067 - val_accuracy: 0.5214\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.0084 - val_accuracy: 0.5214\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8498 - accuracy: 0.5370 - val_loss: 1.0128 - val_accuracy: 0.5043\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8481 - accuracy: 0.5444 - val_loss: 1.0130 - val_accuracy: 0.5043\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8481 - accuracy: 0.5407 - val_loss: 1.0138 - val_accuracy: 0.5214\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.5214\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.5214\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8495 - accuracy: 0.5148 - val_loss: 1.0178 - val_accuracy: 0.5043\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8514 - accuracy: 0.5444 - val_loss: 1.0169 - val_accuracy: 0.5043\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8515 - accuracy: 0.5444 - val_loss: 1.0181 - val_accuracy: 0.5043\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0147 - val_accuracy: 0.5043\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8527 - accuracy: 0.5111 - val_loss: 1.0158 - val_accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0125 - val_accuracy: 0.5214\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8469 - accuracy: 0.5778 - val_loss: 1.0104 - val_accuracy: 0.4957\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8487 - accuracy: 0.5444 - val_loss: 1.0130 - val_accuracy: 0.4957\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8505 - accuracy: 0.5444 - val_loss: 1.0087 - val_accuracy: 0.4957\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8492 - accuracy: 0.5519 - val_loss: 1.0082 - val_accuracy: 0.5128\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8505 - accuracy: 0.5556 - val_loss: 1.0132 - val_accuracy: 0.5214\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8532 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.5214\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.0160 - val_accuracy: 0.5214\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.0135 - val_accuracy: 0.5128\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0137 - val_accuracy: 0.5214\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0147 - val_accuracy: 0.5214\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.5214\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.5214\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8470 - accuracy: 0.5407 - val_loss: 1.0188 - val_accuracy: 0.5043\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8473 - accuracy: 0.5222 - val_loss: 1.0200 - val_accuracy: 0.5214\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.5043\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0148 - val_accuracy: 0.5043\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0174 - val_accuracy: 0.5043\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0156 - val_accuracy: 0.5214\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.5214\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.0160 - val_accuracy: 0.5214\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8470 - accuracy: 0.5593 - val_loss: 1.0192 - val_accuracy: 0.5043\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0201 - val_accuracy: 0.5043\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8492 - accuracy: 0.5630 - val_loss: 1.0185 - val_accuracy: 0.5214\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8461 - accuracy: 0.5481 - val_loss: 1.0178 - val_accuracy: 0.5043\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8485 - accuracy: 0.5407 - val_loss: 1.0184 - val_accuracy: 0.4957\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8514 - accuracy: 0.5444 - val_loss: 1.0160 - val_accuracy: 0.4957\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0163 - val_accuracy: 0.5214\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0173 - val_accuracy: 0.5214\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8517 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.5214\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0235 - val_accuracy: 0.5214\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8480 - accuracy: 0.5519 - val_loss: 1.0255 - val_accuracy: 0.5128\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8509 - accuracy: 0.5444 - val_loss: 1.0202 - val_accuracy: 0.5043\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8494 - accuracy: 0.5185 - val_loss: 1.0145 - val_accuracy: 0.5214\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0129 - val_accuracy: 0.5214\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.0176 - val_accuracy: 0.5214\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.5214\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8470 - accuracy: 0.5667 - val_loss: 1.0154 - val_accuracy: 0.4957\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8473 - accuracy: 0.5444 - val_loss: 1.0158 - val_accuracy: 0.4957\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0166 - val_accuracy: 0.4957\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8492 - accuracy: 0.5444 - val_loss: 1.0145 - val_accuracy: 0.4957\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8468 - accuracy: 0.5444 - val_loss: 1.0153 - val_accuracy: 0.4957\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8471 - accuracy: 0.5148 - val_loss: 1.0150 - val_accuracy: 0.5128\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8476 - accuracy: 0.5222 - val_loss: 1.0120 - val_accuracy: 0.5128\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.5128\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.5128\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0085 - val_accuracy: 0.5128\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0095 - val_accuracy: 0.5128\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8479 - accuracy: 0.5333 - val_loss: 1.0140 - val_accuracy: 0.5043\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8473 - accuracy: 0.5444 - val_loss: 1.0113 - val_accuracy: 0.5214\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0095 - val_accuracy: 0.5214\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0101 - val_accuracy: 0.5214\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0118 - val_accuracy: 0.5214\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.5214\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8473 - accuracy: 0.5407 - val_loss: 1.0174 - val_accuracy: 0.5299\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.5214\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0193 - val_accuracy: 0.5214\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0228 - val_accuracy: 0.5214\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8475 - accuracy: 0.5593 - val_loss: 1.0280 - val_accuracy: 0.5299\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0291 - val_accuracy: 0.5128\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.0285 - val_accuracy: 0.5128\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8484 - accuracy: 0.5407 - val_loss: 1.0207 - val_accuracy: 0.5043\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8484 - accuracy: 0.5333 - val_loss: 1.0179 - val_accuracy: 0.5214\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8473 - accuracy: 0.5481 - val_loss: 1.0160 - val_accuracy: 0.4957\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8489 - accuracy: 0.5444 - val_loss: 1.0163 - val_accuracy: 0.4957\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0155 - val_accuracy: 0.5043\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.0156 - val_accuracy: 0.5214\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.5214\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0243 - val_accuracy: 0.5214\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8480 - accuracy: 0.5630 - val_loss: 1.0250 - val_accuracy: 0.5128\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0226 - val_accuracy: 0.5128\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0150 - val_accuracy: 0.5043\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0113 - val_accuracy: 0.5214\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0088 - val_accuracy: 0.5214\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8503 - accuracy: 0.5556 - val_loss: 1.0081 - val_accuracy: 0.5214\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8496 - accuracy: 0.5481 - val_loss: 1.0098 - val_accuracy: 0.5043\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8469 - accuracy: 0.5370 - val_loss: 1.0131 - val_accuracy: 0.5214\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0121 - val_accuracy: 0.5214\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0109 - val_accuracy: 0.4957\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0153 - val_accuracy: 0.4957\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0142 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0134 - val_accuracy: 0.5214\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8496 - accuracy: 0.5593 - val_loss: 1.0144 - val_accuracy: 0.5128\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8446 - accuracy: 0.5852 - val_loss: 1.0238 - val_accuracy: 0.5043\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8493 - accuracy: 0.5444 - val_loss: 1.0277 - val_accuracy: 0.5043\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8501 - accuracy: 0.5444 - val_loss: 1.0216 - val_accuracy: 0.5043\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8471 - accuracy: 0.5444 - val_loss: 1.0185 - val_accuracy: 0.5043\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8486 - accuracy: 0.5148 - val_loss: 1.0157 - val_accuracy: 0.5128\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0175 - val_accuracy: 0.5128\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8473 - accuracy: 0.5407 - val_loss: 1.0216 - val_accuracy: 0.5043\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0228 - val_accuracy: 0.5043\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.0196 - val_accuracy: 0.5043\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.0168 - val_accuracy: 0.5214\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.0204 - val_accuracy: 0.5214\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0229 - val_accuracy: 0.5214\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0240 - val_accuracy: 0.5214\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0206 - val_accuracy: 0.5214\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8376 - accuracy: 0.53 - 0s 92us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.0187 - val_accuracy: 0.4957\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0176 - val_accuracy: 0.4957\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0182 - val_accuracy: 0.4957\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0193 - val_accuracy: 0.5214\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0178 - val_accuracy: 0.5214\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0191 - val_accuracy: 0.5214\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0221 - val_accuracy: 0.5214\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8511 - accuracy: 0.5370 - val_loss: 1.0206 - val_accuracy: 0.5043\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 1.0126 - val_accuracy: 0.5214\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.5128\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8543 - accuracy: 0.5556 - val_loss: 1.0123 - val_accuracy: 0.5128\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8510 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.5214\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.0197 - val_accuracy: 0.5214\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8478 - accuracy: 0.5370 - val_loss: 1.0203 - val_accuracy: 0.5043\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.0137 - val_accuracy: 0.5128\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0105 - val_accuracy: 0.5128\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0095 - val_accuracy: 0.5128\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8472 - accuracy: 0.5519 - val_loss: 1.0119 - val_accuracy: 0.5214\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0148 - val_accuracy: 0.5043\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8512 - accuracy: 0.5444 - val_loss: 1.0212 - val_accuracy: 0.5128\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8495 - accuracy: 0.5481 - val_loss: 1.0146 - val_accuracy: 0.5214\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0151 - val_accuracy: 0.5214\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0139 - val_accuracy: 0.5214\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0134 - val_accuracy: 0.5214\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0148 - val_accuracy: 0.5214\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0140 - val_accuracy: 0.5214\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.5214\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0201 - val_accuracy: 0.5214\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0190 - val_accuracy: 0.5043\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.0205 - val_accuracy: 0.5043\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0201 - val_accuracy: 0.5043\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8483 - accuracy: 0.5481 - val_loss: 1.0166 - val_accuracy: 0.5214\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.5043\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0129 - val_accuracy: 0.5043\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8472 - accuracy: 0.5407 - val_loss: 1.0123 - val_accuracy: 0.5214\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.5214\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.0230 - val_accuracy: 0.5214\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.5214\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8469 - accuracy: 0.5259 - val_loss: 1.0172 - val_accuracy: 0.5043\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8510 - accuracy: 0.5444 - val_loss: 1.0189 - val_accuracy: 0.5043\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8510 - accuracy: 0.5444 - val_loss: 1.0173 - val_accuracy: 0.5043\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8472 - accuracy: 0.5481 - val_loss: 1.0213 - val_accuracy: 0.5214\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.5214\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.5214\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0253 - val_accuracy: 0.5214\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0223 - val_accuracy: 0.5214\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8475 - accuracy: 0.5333 - val_loss: 1.0244 - val_accuracy: 0.4957\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8476 - accuracy: 0.5444 - val_loss: 1.0227 - val_accuracy: 0.5043\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0192 - val_accuracy: 0.5043\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0178 - val_accuracy: 0.5214\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0170 - val_accuracy: 0.5214\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0178 - val_accuracy: 0.5214\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8454 - accuracy: 0.5741 - val_loss: 1.0200 - val_accuracy: 0.4957\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0232 - val_accuracy: 0.4957\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8497 - accuracy: 0.5444 - val_loss: 1.0235 - val_accuracy: 0.4957\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8493 - accuracy: 0.5444 - val_loss: 1.0244 - val_accuracy: 0.4957\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8469 - accuracy: 0.5370 - val_loss: 1.0254 - val_accuracy: 0.5214\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0309 - val_accuracy: 0.5214\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0367 - val_accuracy: 0.5214\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0341 - val_accuracy: 0.5214\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0270 - val_accuracy: 0.5214\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0208 - val_accuracy: 0.5214\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0202 - val_accuracy: 0.5214\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0196 - val_accuracy: 0.5214\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0203 - val_accuracy: 0.5214\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.5214\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.5214\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.5214\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0246 - val_accuracy: 0.5214\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.0221 - val_accuracy: 0.5043\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8464 - accuracy: 0.5481 - val_loss: 1.0210 - val_accuracy: 0.4957\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8468 - accuracy: 0.5444 - val_loss: 1.0186 - val_accuracy: 0.5128\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0212 - val_accuracy: 0.5214\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0235 - val_accuracy: 0.5214\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.0236 - val_accuracy: 0.5214\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.5214\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0287 - val_accuracy: 0.5043\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8486 - accuracy: 0.5444 - val_loss: 1.0269 - val_accuracy: 0.5043\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8468 - accuracy: 0.5519 - val_loss: 1.0181 - val_accuracy: 0.5214\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0154 - val_accuracy: 0.5214\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0159 - val_accuracy: 0.5214\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0194 - val_accuracy: 0.5214\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0196 - val_accuracy: 0.5214\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0211 - val_accuracy: 0.5214\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.5214\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.5043\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0240 - val_accuracy: 0.5043\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0249 - val_accuracy: 0.5043\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8458 - accuracy: 0.5333 - val_loss: 1.0272 - val_accuracy: 0.5214\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0307 - val_accuracy: 0.5214\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0246 - val_accuracy: 0.5214\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.0207 - val_accuracy: 0.4957\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8469 - accuracy: 0.5519 - val_loss: 1.0194 - val_accuracy: 0.5214\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5214\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.5214\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0225 - val_accuracy: 0.5214\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0223 - val_accuracy: 0.5214\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8513 - accuracy: 0.5556 - val_loss: 1.0242 - val_accuracy: 0.5214\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8521 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.5214\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.5214\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8482 - accuracy: 0.5519 - val_loss: 1.0213 - val_accuracy: 0.5043\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8480 - accuracy: 0.5444 - val_loss: 1.0192 - val_accuracy: 0.4957\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8478 - accuracy: 0.5296 - val_loss: 1.0203 - val_accuracy: 0.5128\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8464 - accuracy: 0.5407 - val_loss: 1.0240 - val_accuracy: 0.4957\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.0274 - val_accuracy: 0.4957\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0251 - val_accuracy: 0.4957\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8467 - accuracy: 0.5296 - val_loss: 1.0257 - val_accuracy: 0.5214\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0258 - val_accuracy: 0.5214\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8483 - accuracy: 0.5407 - val_loss: 1.0258 - val_accuracy: 0.4957\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8503 - accuracy: 0.4963 - val_loss: 1.0273 - val_accuracy: 0.5214\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.5128\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0227 - val_accuracy: 0.5128\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.5214\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0258 - val_accuracy: 0.5214\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5214\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.5043\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8478 - accuracy: 0.5481 - val_loss: 1.0154 - val_accuracy: 0.4957\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8475 - accuracy: 0.5519 - val_loss: 1.0139 - val_accuracy: 0.5128\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8681 - accuracy: 0.51 - 0s 124us/step - loss: 0.8457 - accuracy: 0.5519 - val_loss: 1.0179 - val_accuracy: 0.5214\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0243 - val_accuracy: 0.5214\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0218 - val_accuracy: 0.5214\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.0181 - val_accuracy: 0.5043\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8484 - accuracy: 0.5444 - val_loss: 1.0180 - val_accuracy: 0.5043\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8489 - accuracy: 0.5444 - val_loss: 1.0220 - val_accuracy: 0.5043\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8477 - accuracy: 0.5444 - val_loss: 1.0255 - val_accuracy: 0.5128\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8450 - accuracy: 0.5704 - val_loss: 1.0286 - val_accuracy: 0.5214\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.0293 - val_accuracy: 0.5214\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0213 - val_accuracy: 0.5128\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8473 - accuracy: 0.5593 - val_loss: 1.0253 - val_accuracy: 0.4957\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8542 - accuracy: 0.5444 - val_loss: 1.0262 - val_accuracy: 0.4957\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8517 - accuracy: 0.5444 - val_loss: 1.0204 - val_accuracy: 0.4957\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8453 - accuracy: 0.5778 - val_loss: 1.0147 - val_accuracy: 0.5128\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.0187 - val_accuracy: 0.5128\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.0152 - val_accuracy: 0.5128\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0122 - val_accuracy: 0.5128\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8484 - accuracy: 0.5370 - val_loss: 1.0121 - val_accuracy: 0.4957\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8507 - accuracy: 0.5444 - val_loss: 1.0127 - val_accuracy: 0.4957\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0116 - val_accuracy: 0.5128\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0158 - val_accuracy: 0.5214\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.5214\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0237 - val_accuracy: 0.5214\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0262 - val_accuracy: 0.5214\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.5214\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8497 - accuracy: 0.5370 - val_loss: 1.0264 - val_accuracy: 0.4957\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.0256 - val_accuracy: 0.4957\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8472 - accuracy: 0.5444 - val_loss: 1.0234 - val_accuracy: 0.5214\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0238 - val_accuracy: 0.5214\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8469 - accuracy: 0.5407 - val_loss: 1.0248 - val_accuracy: 0.5043\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0263 - val_accuracy: 0.5214\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0273 - val_accuracy: 0.5214\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0257 - val_accuracy: 0.5214\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0249 - val_accuracy: 0.5214\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0194 - val_accuracy: 0.5214\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0169 - val_accuracy: 0.5214\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0175 - val_accuracy: 0.5128\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8468 - accuracy: 0.5074 - val_loss: 1.0198 - val_accuracy: 0.5043\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8458 - accuracy: 0.5370 - val_loss: 1.0229 - val_accuracy: 0.5214\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8460 - accuracy: 0.5222 - val_loss: 1.0255 - val_accuracy: 0.5043\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8463 - accuracy: 0.5444 - val_loss: 1.0266 - val_accuracy: 0.5043\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8460 - accuracy: 0.5333 - val_loss: 1.0279 - val_accuracy: 0.5214\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0302 - val_accuracy: 0.5214\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0286 - val_accuracy: 0.5214\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0265 - val_accuracy: 0.5214\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0256 - val_accuracy: 0.5043\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8456 - accuracy: 0.5444 - val_loss: 1.0236 - val_accuracy: 0.5043\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.0238 - val_accuracy: 0.5043\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8450 - accuracy: 0.5333 - val_loss: 1.0201 - val_accuracy: 0.5214\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0170 - val_accuracy: 0.5214\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8465 - accuracy: 0.5407 - val_loss: 1.0127 - val_accuracy: 0.5043\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8471 - accuracy: 0.5370 - val_loss: 1.0118 - val_accuracy: 0.5214\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0113 - val_accuracy: 0.5214\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.5214\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8489 - accuracy: 0.5296 - val_loss: 1.0249 - val_accuracy: 0.5128\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 1.0208 - val_accuracy: 0.5214\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0185 - val_accuracy: 0.5214\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8449 - accuracy: 0.5630 - val_loss: 1.0191 - val_accuracy: 0.4957\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0198 - val_accuracy: 0.4957\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8475 - accuracy: 0.5519 - val_loss: 1.0183 - val_accuracy: 0.5128\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.0232 - val_accuracy: 0.5128\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.0268 - val_accuracy: 0.5214\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0273 - val_accuracy: 0.5214\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0262 - val_accuracy: 0.5214\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8482 - accuracy: 0.5481 - val_loss: 1.0302 - val_accuracy: 0.5128\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8477 - accuracy: 0.5519 - val_loss: 1.0288 - val_accuracy: 0.5299\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.5214\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0238 - val_accuracy: 0.5214\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.5128\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.0208 - val_accuracy: 0.5128\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0229 - val_accuracy: 0.5128\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0251 - val_accuracy: 0.5128\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0252 - val_accuracy: 0.5214\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0258 - val_accuracy: 0.5214\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8465 - accuracy: 0.5630 - val_loss: 1.0197 - val_accuracy: 0.5043\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8488 - accuracy: 0.5481 - val_loss: 1.0163 - val_accuracy: 0.4957\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0171 - val_accuracy: 0.5214\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0221 - val_accuracy: 0.5214\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8469 - accuracy: 0.5333 - val_loss: 1.0236 - val_accuracy: 0.5043\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8477 - accuracy: 0.5444 - val_loss: 1.0232 - val_accuracy: 0.5043\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8465 - accuracy: 0.5444 - val_loss: 1.0232 - val_accuracy: 0.5043\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.0247 - val_accuracy: 0.5214\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0209 - val_accuracy: 0.5214\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8486 - accuracy: 0.5185 - val_loss: 1.0237 - val_accuracy: 0.5128\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0197 - val_accuracy: 0.5043\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8455 - accuracy: 0.5481 - val_loss: 1.0188 - val_accuracy: 0.5214\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0201 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8511 - accuracy: 0.5556 - val_loss: 1.0191 - val_accuracy: 0.5214\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.5214\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0169 - val_accuracy: 0.5043\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0208 - val_accuracy: 0.5043\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.0227 - val_accuracy: 0.5043\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0222 - val_accuracy: 0.5043\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8464 - accuracy: 0.5630 - val_loss: 1.0193 - val_accuracy: 0.5214\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.0235 - val_accuracy: 0.5214\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0274 - val_accuracy: 0.5214\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.5214\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0304 - val_accuracy: 0.5214\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8471 - accuracy: 0.5481 - val_loss: 1.0286 - val_accuracy: 0.5043\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0251 - val_accuracy: 0.5043\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8465 - accuracy: 0.5296 - val_loss: 1.0308 - val_accuracy: 0.5043\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8472 - accuracy: 0.5444 - val_loss: 1.0375 - val_accuracy: 0.5128\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8492 - accuracy: 0.5185 - val_loss: 1.0356 - val_accuracy: 0.5214\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0300 - val_accuracy: 0.5214\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0291 - val_accuracy: 0.5214\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.0273 - val_accuracy: 0.5043\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.0304 - val_accuracy: 0.5043\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8486 - accuracy: 0.5444 - val_loss: 1.0240 - val_accuracy: 0.5043\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8447 - accuracy: 0.5407 - val_loss: 1.0170 - val_accuracy: 0.5214\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.5128\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.5214\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0201 - val_accuracy: 0.5043\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8465 - accuracy: 0.5444 - val_loss: 1.0246 - val_accuracy: 0.5043\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8464 - accuracy: 0.5444 - val_loss: 1.0243 - val_accuracy: 0.5043\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8473 - accuracy: 0.5333 - val_loss: 1.0211 - val_accuracy: 0.5214\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0219 - val_accuracy: 0.5043\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8460 - accuracy: 0.5407 - val_loss: 1.0209 - val_accuracy: 0.5214\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0264 - val_accuracy: 0.5214\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0301 - val_accuracy: 0.5214\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.0273 - val_accuracy: 0.5214\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.5214\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.5043\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.0193 - val_accuracy: 0.5043\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8491 - accuracy: 0.5444 - val_loss: 1.0259 - val_accuracy: 0.5128\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8444 - accuracy: 0.5704 - val_loss: 1.0282 - val_accuracy: 0.5214\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.0355 - val_accuracy: 0.5214\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.0308 - val_accuracy: 0.5214\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0287 - val_accuracy: 0.5214\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8484 - accuracy: 0.5407 - val_loss: 1.0295 - val_accuracy: 0.5043\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8511 - accuracy: 0.5444 - val_loss: 1.0241 - val_accuracy: 0.5043\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8452 - accuracy: 0.5407 - val_loss: 1.0209 - val_accuracy: 0.5214\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0236 - val_accuracy: 0.5214\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.5214\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0192 - val_accuracy: 0.5214\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8468 - accuracy: 0.5407 - val_loss: 1.0222 - val_accuracy: 0.5043\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.0236 - val_accuracy: 0.5214\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.0288 - val_accuracy: 0.5214\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.0315 - val_accuracy: 0.5214\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8527 - accuracy: 0.5556 - val_loss: 1.0318 - val_accuracy: 0.5214\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0297 - val_accuracy: 0.5214\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.0307 - val_accuracy: 0.5043\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.64 - 0s 58us/step - loss: 0.8483 - accuracy: 0.5444 - val_loss: 1.0314 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8476 - accuracy: 0.5444 - val_loss: 1.0285 - val_accuracy: 0.5043\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.0252 - val_accuracy: 0.5214\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0286 - val_accuracy: 0.5214\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0320 - val_accuracy: 0.5214\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0324 - val_accuracy: 0.5214\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.0314 - val_accuracy: 0.5043\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8476 - accuracy: 0.5444 - val_loss: 1.0319 - val_accuracy: 0.5043\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.0313 - val_accuracy: 0.5043\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.0279 - val_accuracy: 0.5214\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0271 - val_accuracy: 0.5214\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0279 - val_accuracy: 0.5214\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0260 - val_accuracy: 0.5214\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0252 - val_accuracy: 0.5214\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8467 - accuracy: 0.5333 - val_loss: 1.0256 - val_accuracy: 0.4957\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8456 - accuracy: 0.5444 - val_loss: 1.0277 - val_accuracy: 0.4957\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8472 - accuracy: 0.5407 - val_loss: 1.0313 - val_accuracy: 0.5214\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8469 - accuracy: 0.5185 - val_loss: 1.0238 - val_accuracy: 0.5128\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.5128\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.5128\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0165 - val_accuracy: 0.5128\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 1.0235 - val_accuracy: 0.5128\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8496 - accuracy: 0.5444 - val_loss: 1.0252 - val_accuracy: 0.5128\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8507 - accuracy: 0.5296 - val_loss: 1.0233 - val_accuracy: 0.5214\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0244 - val_accuracy: 0.5214\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0213 - val_accuracy: 0.5214\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.0240 - val_accuracy: 0.5043\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.0254 - val_accuracy: 0.5043\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0253 - val_accuracy: 0.5214\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0254 - val_accuracy: 0.5214\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0236 - val_accuracy: 0.5214\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8448 - accuracy: 0.5593 - val_loss: 1.0209 - val_accuracy: 0.5128\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.5128\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.5128\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.5128\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8480 - accuracy: 0.5593 - val_loss: 1.0176 - val_accuracy: 0.4957\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8502 - accuracy: 0.5444 - val_loss: 1.0245 - val_accuracy: 0.4957\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8452 - accuracy: 0.5407 - val_loss: 1.0263 - val_accuracy: 0.5214\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0296 - val_accuracy: 0.5214\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.5043\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8461 - accuracy: 0.5444 - val_loss: 1.0335 - val_accuracy: 0.5043\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8461 - accuracy: 0.5444 - val_loss: 1.0368 - val_accuracy: 0.5214\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0364 - val_accuracy: 0.5214\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0305 - val_accuracy: 0.5214\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0249 - val_accuracy: 0.5128\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8446 - accuracy: 0.5630 - val_loss: 1.0214 - val_accuracy: 0.4957\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8506 - accuracy: 0.5444 - val_loss: 1.0229 - val_accuracy: 0.4957\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8460 - accuracy: 0.5444 - val_loss: 1.0220 - val_accuracy: 0.5128\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8479 - accuracy: 0.5519 - val_loss: 1.0307 - val_accuracy: 0.5214\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.0319 - val_accuracy: 0.5214\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.0321 - val_accuracy: 0.5214\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0293 - val_accuracy: 0.5214\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0284 - val_accuracy: 0.5214\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0285 - val_accuracy: 0.5214\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.0328 - val_accuracy: 0.5043\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8463 - accuracy: 0.5444 - val_loss: 1.0338 - val_accuracy: 0.5043\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8466 - accuracy: 0.5370 - val_loss: 1.0315 - val_accuracy: 0.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0270 - val_accuracy: 0.5214\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0252 - val_accuracy: 0.5214\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8485 - accuracy: 0.5259 - val_loss: 1.0253 - val_accuracy: 0.5043\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8460 - accuracy: 0.5630 - val_loss: 1.0299 - val_accuracy: 0.5214\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0347 - val_accuracy: 0.5043\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0331 - val_accuracy: 0.5128\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8489 - accuracy: 0.5444 - val_loss: 1.0257 - val_accuracy: 0.5043\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8466 - accuracy: 0.5444 - val_loss: 1.0180 - val_accuracy: 0.5043\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8483 - accuracy: 0.5333 - val_loss: 1.0138 - val_accuracy: 0.5128\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8474 - accuracy: 0.5519 - val_loss: 1.0191 - val_accuracy: 0.5214\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0283 - val_accuracy: 0.5214\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8496 - accuracy: 0.5593 - val_loss: 1.0351 - val_accuracy: 0.5299\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8502 - accuracy: 0.5519 - val_loss: 1.0272 - val_accuracy: 0.5214\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8466 - accuracy: 0.5593 - val_loss: 1.0222 - val_accuracy: 0.5128\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8457 - accuracy: 0.5704 - val_loss: 1.0197 - val_accuracy: 0.4957\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8468 - accuracy: 0.5444 - val_loss: 1.0194 - val_accuracy: 0.5128\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0206 - val_accuracy: 0.5128\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0218 - val_accuracy: 0.5128\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0249 - val_accuracy: 0.5128\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0284 - val_accuracy: 0.5128\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0285 - val_accuracy: 0.5128\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0299 - val_accuracy: 0.5128\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8436 - accuracy: 0.5630 - val_loss: 1.0314 - val_accuracy: 0.4957\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8497 - accuracy: 0.5444 - val_loss: 1.0407 - val_accuracy: 0.5043\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8469 - accuracy: 0.5519 - val_loss: 1.0393 - val_accuracy: 0.5214\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0398 - val_accuracy: 0.5214\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0349 - val_accuracy: 0.5214\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0329 - val_accuracy: 0.5214\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8458 - accuracy: 0.5333 - val_loss: 1.0314 - val_accuracy: 0.5043\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8498 - accuracy: 0.5444 - val_loss: 1.0355 - val_accuracy: 0.4957\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8504 - accuracy: 0.5444 - val_loss: 1.0332 - val_accuracy: 0.4957\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8468 - accuracy: 0.5444 - val_loss: 1.0256 - val_accuracy: 0.5043\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8488 - accuracy: 0.5296 - val_loss: 1.0254 - val_accuracy: 0.5214\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0255 - val_accuracy: 0.5214\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8506 - accuracy: 0.5370 - val_loss: 1.0297 - val_accuracy: 0.4957\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8485 - accuracy: 0.5444 - val_loss: 1.0237 - val_accuracy: 0.4957\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0227 - val_accuracy: 0.5214\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0247 - val_accuracy: 0.5214\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.0283 - val_accuracy: 0.5214\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0244 - val_accuracy: 0.5214\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0249 - val_accuracy: 0.5128\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8463 - accuracy: 0.5519 - val_loss: 1.0252 - val_accuracy: 0.4957\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8500 - accuracy: 0.5444 - val_loss: 1.0224 - val_accuracy: 0.4957\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.0215 - val_accuracy: 0.5128\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0314 - val_accuracy: 0.5128\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.0350 - val_accuracy: 0.5128\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0314 - val_accuracy: 0.5128\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0338 - val_accuracy: 0.5214\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.0356 - val_accuracy: 0.5214\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.0336 - val_accuracy: 0.5214\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8480 - accuracy: 0.5111 - val_loss: 1.0303 - val_accuracy: 0.5128\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0301 - val_accuracy: 0.5128\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.0283 - val_accuracy: 0.5128\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.5128\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8441 - accuracy: 0.5519 - val_loss: 1.0254 - val_accuracy: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8459 - accuracy: 0.5444 - val_loss: 1.0284 - val_accuracy: 0.4957\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.0337 - val_accuracy: 0.5043\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.0290 - val_accuracy: 0.5043\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8451 - accuracy: 0.5407 - val_loss: 1.0299 - val_accuracy: 0.5214\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.0357 - val_accuracy: 0.5214\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.0352 - val_accuracy: 0.5214\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.0305 - val_accuracy: 0.5214\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.4957\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.8461 - accuracy: 0.5444 - val_loss: 1.0237 - val_accuracy: 0.4957\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8462 - accuracy: 0.5444 - val_loss: 1.0216 - val_accuracy: 0.4957\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5128\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.0253 - val_accuracy: 0.5128\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0290 - val_accuracy: 0.5214\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.0311 - val_accuracy: 0.5214\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8478 - accuracy: 0.5296 - val_loss: 1.0311 - val_accuracy: 0.4957\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7582 - accuracy: 0.54 - 0s 51us/step - loss: 0.8447 - accuracy: 0.5630 - val_loss: 1.0288 - val_accuracy: 0.5128\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.0299 - val_accuracy: 0.5128\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0287 - val_accuracy: 0.5128\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0322 - val_accuracy: 0.5214\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8467 - accuracy: 0.5481 - val_loss: 1.0387 - val_accuracy: 0.5128\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.0406 - val_accuracy: 0.5128\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8464 - accuracy: 0.5444 - val_loss: 1.0327 - val_accuracy: 0.5128\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.0253 - val_accuracy: 0.5128\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.5128\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.0203 - val_accuracy: 0.5128\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8486 - accuracy: 0.5370 - val_loss: 1.0223 - val_accuracy: 0.4957\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8464 - accuracy: 0.5444 - val_loss: 1.0240 - val_accuracy: 0.5128\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.0274 - val_accuracy: 0.5128\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.0342 - val_accuracy: 0.5214\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.0354 - val_accuracy: 0.5214\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.0371 - val_accuracy: 0.5043\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8493 - accuracy: 0.5407 - val_loss: 1.0335 - val_accuracy: 0.4957\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8452 - accuracy: 0.5481 - val_loss: 1.0333 - val_accuracy: 0.5214\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0352 - val_accuracy: 0.5214\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0370 - val_accuracy: 0.5214\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0296 - val_accuracy: 0.5214\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.0262 - val_accuracy: 0.5214\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0229 - val_accuracy: 0.5214\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0210 - val_accuracy: 0.5214\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0240 - val_accuracy: 0.5214\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0228 - val_accuracy: 0.5214\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0206 - val_accuracy: 0.5214\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8465 - accuracy: 0.5667 - val_loss: 1.0224 - val_accuracy: 0.5043\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0277 - val_accuracy: 0.5043\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0284 - val_accuracy: 0.5043\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8459 - accuracy: 0.5333 - val_loss: 1.0299 - val_accuracy: 0.5214\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0357 - val_accuracy: 0.5214\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.0360 - val_accuracy: 0.5214\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.0373 - val_accuracy: 0.5043\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.0335 - val_accuracy: 0.5214\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0322 - val_accuracy: 0.5214\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0290 - val_accuracy: 0.5214\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0303 - val_accuracy: 0.5214\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8450 - accuracy: 0.5222 - val_loss: 1.0276 - val_accuracy: 0.5043\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8450 - accuracy: 0.5444 - val_loss: 1.0240 - val_accuracy: 0.5128\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.5128\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.5128\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0263 - val_accuracy: 0.5128\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0297 - val_accuracy: 0.5128\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0321 - val_accuracy: 0.5128\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8450 - accuracy: 0.5370 - val_loss: 1.0312 - val_accuracy: 0.4957\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8456 - accuracy: 0.5444 - val_loss: 1.0301 - val_accuracy: 0.4957\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8461 - accuracy: 0.5148 - val_loss: 1.0326 - val_accuracy: 0.5128\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0356 - val_accuracy: 0.5128\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.0333 - val_accuracy: 0.4957\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8455 - accuracy: 0.5444 - val_loss: 1.0290 - val_accuracy: 0.4957\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8457 - accuracy: 0.5222 - val_loss: 1.0259 - val_accuracy: 0.5128\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.5128\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.5128\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0327 - val_accuracy: 0.5128\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.0320 - val_accuracy: 0.5128\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.0305 - val_accuracy: 0.4957\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8478 - accuracy: 0.5444 - val_loss: 1.0228 - val_accuracy: 0.4957\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.0169 - val_accuracy: 0.5128\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0209 - val_accuracy: 0.5128\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.0234 - val_accuracy: 0.5128\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8482 - accuracy: 0.5593 - val_loss: 1.0259 - val_accuracy: 0.4957\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8451 - accuracy: 0.5444 - val_loss: 1.0255 - val_accuracy: 0.5128\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.5128\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.0294 - val_accuracy: 0.5214\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.5214\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8456 - accuracy: 0.5407 - val_loss: 1.0316 - val_accuracy: 0.5043\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.0316 - val_accuracy: 0.5043\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.0280 - val_accuracy: 0.5214\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.0290 - val_accuracy: 0.5214\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0320 - val_accuracy: 0.5214\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8527 - accuracy: 0.5556 - val_loss: 1.0344 - val_accuracy: 0.5214\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.0308 - val_accuracy: 0.5214\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8445 - accuracy: 0.5481 - val_loss: 1.0280 - val_accuracy: 0.5043\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.0210 - val_accuracy: 0.4957\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8460 - accuracy: 0.5444 - val_loss: 1.0177 - val_accuracy: 0.4957\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8459 - accuracy: 0.5407 - val_loss: 1.0186 - val_accuracy: 0.5128\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8470 - accuracy: 0.5481 - val_loss: 1.0193 - val_accuracy: 0.4957\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0195 - val_accuracy: 0.4957\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8452 - accuracy: 0.5481 - val_loss: 1.0203 - val_accuracy: 0.5128\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0255 - val_accuracy: 0.5128\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0285 - val_accuracy: 0.5128\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0314 - val_accuracy: 0.5128\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8453 - accuracy: 0.5481 - val_loss: 1.0317 - val_accuracy: 0.4957\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.0264 - val_accuracy: 0.4957\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8443 - accuracy: 0.5444 - val_loss: 1.0239 - val_accuracy: 0.4957\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8444 - accuracy: 0.5333 - val_loss: 1.0234 - val_accuracy: 0.5128\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0274 - val_accuracy: 0.5128\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0335 - val_accuracy: 0.5214\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0379 - val_accuracy: 0.5214\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.0396 - val_accuracy: 0.5043\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0385 - val_accuracy: 0.5043\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8464 - accuracy: 0.5185 - val_loss: 1.0354 - val_accuracy: 0.5214\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.0341 - val_accuracy: 0.5214\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0289 - val_accuracy: 0.5214\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8466 - accuracy: 0.5111 - val_loss: 1.0278 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.0279 - val_accuracy: 0.5214\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0313 - val_accuracy: 0.5214\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0321 - val_accuracy: 0.5214\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8447 - accuracy: 0.5444 - val_loss: 1.0300 - val_accuracy: 0.5043\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8443 - accuracy: 0.5370 - val_loss: 1.0240 - val_accuracy: 0.5128\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 374us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0230 - val_accuracy: 0.5128\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.0252 - val_accuracy: 0.5214\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.0331 - val_accuracy: 0.5214\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0298 - val_accuracy: 0.5214\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8451 - accuracy: 0.5704 - val_loss: 1.0277 - val_accuracy: 0.5043\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0229 - val_accuracy: 0.4957\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.0200 - val_accuracy: 0.4957\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0232 - val_accuracy: 0.5214\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0264 - val_accuracy: 0.5214\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8457 - accuracy: 0.5148 - val_loss: 1.0320 - val_accuracy: 0.5214\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0344 - val_accuracy: 0.5214\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0312 - val_accuracy: 0.5214\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0309 - val_accuracy: 0.5214\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.0327 - val_accuracy: 0.5214\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.0335 - val_accuracy: 0.5214\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8450 - accuracy: 0.5407 - val_loss: 1.0255 - val_accuracy: 0.4957\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8475 - accuracy: 0.5444 - val_loss: 1.0203 - val_accuracy: 0.4957\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8464 - accuracy: 0.5444 - val_loss: 1.0184 - val_accuracy: 0.5128\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.0232 - val_accuracy: 0.5128\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.0257 - val_accuracy: 0.5128\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.0273 - val_accuracy: 0.5214\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.0290 - val_accuracy: 0.5128\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.0300 - val_accuracy: 0.5128\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0316 - val_accuracy: 0.5128\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8450 - accuracy: 0.5222 - val_loss: 1.0289 - val_accuracy: 0.4957\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8452 - accuracy: 0.5407 - val_loss: 1.0279 - val_accuracy: 0.5128\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0233 - val_accuracy: 0.5128\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.5128\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0270 - val_accuracy: 0.5128\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8444 - accuracy: 0.5444 - val_loss: 1.0315 - val_accuracy: 0.5043\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8459 - accuracy: 0.5222 - val_loss: 1.0353 - val_accuracy: 0.5299\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.0393 - val_accuracy: 0.5214\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0369 - val_accuracy: 0.5128\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8445 - accuracy: 0.5444 - val_loss: 1.0368 - val_accuracy: 0.4957\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8471 - accuracy: 0.5444 - val_loss: 1.0405 - val_accuracy: 0.5043\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8469 - accuracy: 0.5444 - val_loss: 1.0385 - val_accuracy: 0.4957\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.0362 - val_accuracy: 0.5128\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.0319 - val_accuracy: 0.5128\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8456 - accuracy: 0.5407 - val_loss: 1.0352 - val_accuracy: 0.4957\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8458 - accuracy: 0.5444 - val_loss: 1.0356 - val_accuracy: 0.4957\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.8447 - accuracy: 0.5444 - val_loss: 1.0355 - val_accuracy: 0.4957\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.8441 - accuracy: 0.5593 - val_loss: 1.0349 - val_accuracy: 0.5128\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0337 - val_accuracy: 0.5128\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.0371 - val_accuracy: 0.5128\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.8481 - accuracy: 0.5111 - val_loss: 1.0391 - val_accuracy: 0.4957\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.0297 - val_accuracy: 0.5128\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.0257 - val_accuracy: 0.5128\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0240 - val_accuracy: 0.5128\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0233 - val_accuracy: 0.5128\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.0224 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0237 - val_accuracy: 0.5128\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.5128\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0303 - val_accuracy: 0.5128\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.0353 - val_accuracy: 0.5128\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.0398 - val_accuracy: 0.5214\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8478 - accuracy: 0.5519 - val_loss: 1.0374 - val_accuracy: 0.5128\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0348 - val_accuracy: 0.5128\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8425 - accuracy: 0.5444 - val_loss: 1.0289 - val_accuracy: 0.5128\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0234 - val_accuracy: 0.5128\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.0219 - val_accuracy: 0.5128\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.0217 - val_accuracy: 0.5128\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.0264 - val_accuracy: 0.5214\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0302 - val_accuracy: 0.5214\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.0330 - val_accuracy: 0.5214\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.0322 - val_accuracy: 0.5214\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8446 - accuracy: 0.5481 - val_loss: 1.0308 - val_accuracy: 0.5128\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.0297 - val_accuracy: 0.5128\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.0294 - val_accuracy: 0.5128\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.0320 - val_accuracy: 0.5214\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.0340 - val_accuracy: 0.5214\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.0351 - val_accuracy: 0.5214\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.0305 - val_accuracy: 0.5214\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.0282 - val_accuracy: 0.5128\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8439 - accuracy: 0.5444 - val_loss: 1.0317 - val_accuracy: 0.4957\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8464 - accuracy: 0.5444 - val_loss: 1.0328 - val_accuracy: 0.4957\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.8471 - accuracy: 0.5370 - val_loss: 1.0286 - val_accuracy: 0.4957\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.54 - 0s 176us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.0281 - val_accuracy: 0.4957\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.0285 - val_accuracy: 0.5128\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.0281 - val_accuracy: 0.5128\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.0287 - val_accuracy: 0.5128\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.0304 - val_accuracy: 0.5128\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8441 - accuracy: 0.5778 - val_loss: 1.0369 - val_accuracy: 0.5043\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.8460 - accuracy: 0.5407 - val_loss: 1.0383 - val_accuracy: 0.5128\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8483 - accuracy: 0.5074 - val_loss: 1.0417 - val_accuracy: 0.5299\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8478 - accuracy: 0.5333 - val_loss: 1.0383 - val_accuracy: 0.5299\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.0312 - val_accuracy: 0.5214\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.0278 - val_accuracy: 0.5128\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 295us/step - loss: 0.8520 - accuracy: 0.5444 - val_loss: 1.0331 - val_accuracy: 0.5128\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8509 - accuracy: 0.5444 - val_loss: 1.0324 - val_accuracy: 0.5128\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.0298 - val_accuracy: 0.5214\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0294 - val_accuracy: 0.5214\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.0289 - val_accuracy: 0.5214\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.0303 - val_accuracy: 0.5214\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8455 - accuracy: 0.5407 - val_loss: 1.0348 - val_accuracy: 0.5043\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8474 - accuracy: 0.5407 - val_loss: 1.0363 - val_accuracy: 0.5128\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8487 - accuracy: 0.5444 - val_loss: 1.0396 - val_accuracy: 0.5128\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.0353 - val_accuracy: 0.5214\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.0393 - val_accuracy: 0.5214\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.0328 - val_accuracy: 0.5214\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.0306 - val_accuracy: 0.5214\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.0298 - val_accuracy: 0.5214\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8445 - accuracy: 0.5333 - val_loss: 1.0268 - val_accuracy: 0.5043\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.0274 - val_accuracy: 0.5214\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 54.99%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3458068e-02, 2.1647884e-01, 7.7006304e-01],\n",
       "       [2.6741534e-02, 9.2942297e-04, 9.7232900e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [7.8940870e-01, 1.7715381e-01, 3.3437528e-02],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.6736180e-01, 1.2357602e-01, 6.0906225e-01],\n",
       "       [7.7902250e-02, 1.6777480e-01, 7.5432295e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.0215075e-01, 9.9052295e-02, 4.9879685e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [3.9979957e-02, 5.7650580e-02, 9.0236950e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [1.4712583e-05, 5.5170218e-05, 9.9993014e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [1.3458068e-02, 2.1647884e-01, 7.7006304e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [1.1182583e-03, 1.2702123e-05, 9.9886900e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [1.3458068e-02, 2.1647884e-01, 7.7006304e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [5.1816315e-03, 5.4752715e-03, 9.8934305e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [7.7902250e-02, 1.6777480e-01, 7.5432295e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [7.7902250e-02, 1.6777480e-01, 7.5432295e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.6741534e-02, 9.2942297e-04, 9.7232900e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [7.3185354e-02, 7.9005560e-01, 1.3675904e-01],\n",
       "       [2.6741534e-02, 9.2942297e-04, 9.7232900e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.6736180e-01, 1.2357602e-01, 6.0906225e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.2389372e-01, 1.0539745e-01, 6.7070884e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [3.9979957e-02, 5.7650580e-02, 9.0236950e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [1.6368449e-01, 4.8528448e-02, 7.8778710e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [6.9037310e-01, 2.1375363e-01, 9.5873290e-02],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [1.9884875e-04, 3.7690240e-02, 9.6211100e-01],\n",
       "       [6.0312230e-01, 1.3043718e-01, 2.6644054e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [9.5616750e-01, 1.1166568e-02, 3.2665930e-02],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [8.9357070e-06, 4.7956460e-06, 9.9998630e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [3.9979957e-02, 5.7650580e-02, 9.0236950e-01],\n",
       "       [9.2829380e-01, 3.9893743e-02, 3.1812440e-02],\n",
       "       [1.3458068e-02, 2.1647884e-01, 7.7006304e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.2389372e-01, 1.0539745e-01, 6.7070884e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.2272366e-04, 3.3082208e-03, 9.9606910e-01],\n",
       "       [1.1182583e-03, 1.2702123e-05, 9.9886900e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.0789202e-02, 3.4889752e-01, 6.3031320e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [2.3190995e-01, 4.0615067e-01, 3.6193937e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [3.9979957e-02, 5.7650580e-02, 9.0236950e-01],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [6.7205080e-01, 2.7617100e-01, 5.1778210e-02],\n",
       "       [4.1474843e-01, 3.6263310e-01, 2.2261843e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6949375410913872"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6949375410913872"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS249     2\n",
       "1         NRS188     1\n",
       "2         NRS232     2\n",
       "3          NY439     2\n",
       "4           GA27     2\n",
       "..           ...   ...\n",
       "112       SR3569     0\n",
       "113       NRS204     0\n",
       "114       NRS203     0\n",
       "115     CFBRSa25     1\n",
       "116  CFBREBSa131     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 682us/step - loss: 1.1482 - accuracy: 0.3370 - val_loss: 1.1163 - val_accuracy: 0.3590\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.0679 - accuracy: 0.4667 - val_loss: 1.0888 - val_accuracy: 0.3761\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 1.0398 - accuracy: 0.4778 - val_loss: 1.0831 - val_accuracy: 0.3932\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 1.0272 - accuracy: 0.4593 - val_loss: 1.0818 - val_accuracy: 0.3419\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 1.0165 - accuracy: 0.4222 - val_loss: 1.0775 - val_accuracy: 0.3761\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 1.0033 - accuracy: 0.4889 - val_loss: 1.0740 - val_accuracy: 0.4274\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9925 - accuracy: 0.4963 - val_loss: 1.0735 - val_accuracy: 0.4274\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9854 - accuracy: 0.4963 - val_loss: 1.0681 - val_accuracy: 0.4359\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9785 - accuracy: 0.4926 - val_loss: 1.0634 - val_accuracy: 0.4359\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.9710 - accuracy: 0.5111 - val_loss: 1.0619 - val_accuracy: 0.4359\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.9644 - accuracy: 0.4963 - val_loss: 1.0589 - val_accuracy: 0.4274\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9600 - accuracy: 0.4926 - val_loss: 1.0532 - val_accuracy: 0.4786\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.9565 - accuracy: 0.4889 - val_loss: 1.0492 - val_accuracy: 0.4786\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9499 - accuracy: 0.5259 - val_loss: 1.0486 - val_accuracy: 0.4786\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.9465 - accuracy: 0.5259 - val_loss: 1.0469 - val_accuracy: 0.4786\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9418 - accuracy: 0.5259 - val_loss: 1.0437 - val_accuracy: 0.4786\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9450 - accuracy: 0.5000 - val_loss: 1.0432 - val_accuracy: 0.4786\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9381 - accuracy: 0.5259 - val_loss: 1.0438 - val_accuracy: 0.4786\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9377 - accuracy: 0.5259 - val_loss: 1.0478 - val_accuracy: 0.4786\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9390 - accuracy: 0.4926 - val_loss: 1.0506 - val_accuracy: 0.4701\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9348 - accuracy: 0.5259 - val_loss: 1.0452 - val_accuracy: 0.4786\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9329 - accuracy: 0.5259 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.9317 - accuracy: 0.5259 - val_loss: 1.0433 - val_accuracy: 0.4786\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9291 - accuracy: 0.5259 - val_loss: 1.0458 - val_accuracy: 0.4786\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9288 - accuracy: 0.5333 - val_loss: 1.0438 - val_accuracy: 0.4786\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9279 - accuracy: 0.4667 - val_loss: 1.0425 - val_accuracy: 0.4786\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.9259 - accuracy: 0.5259 - val_loss: 1.0384 - val_accuracy: 0.4786\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9299 - accuracy: 0.5333 - val_loss: 1.0432 - val_accuracy: 0.4530\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9229 - accuracy: 0.5370 - val_loss: 1.0376 - val_accuracy: 0.4786\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.9231 - accuracy: 0.5370 - val_loss: 1.0394 - val_accuracy: 0.4872\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9248 - accuracy: 0.5370 - val_loss: 1.0440 - val_accuracy: 0.4786\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9316 - accuracy: 0.5370 - val_loss: 1.0485 - val_accuracy: 0.4615\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9167 - accuracy: 0.5444 - val_loss: 1.0414 - val_accuracy: 0.4872\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9329 - accuracy: 0.5074 - val_loss: 1.0393 - val_accuracy: 0.4872\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9189 - accuracy: 0.5370 - val_loss: 1.0530 - val_accuracy: 0.4786\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9227 - accuracy: 0.5407 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9176 - accuracy: 0.5407 - val_loss: 1.0445 - val_accuracy: 0.4872\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9165 - accuracy: 0.5407 - val_loss: 1.0480 - val_accuracy: 0.4872\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9164 - accuracy: 0.5407 - val_loss: 1.0445 - val_accuracy: 0.4872\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9143 - accuracy: 0.5370 - val_loss: 1.0452 - val_accuracy: 0.4615\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9152 - accuracy: 0.5407 - val_loss: 1.0438 - val_accuracy: 0.4872\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9171 - accuracy: 0.5444 - val_loss: 1.0509 - val_accuracy: 0.4701\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9149 - accuracy: 0.5407 - val_loss: 1.0481 - val_accuracy: 0.4872\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9139 - accuracy: 0.5370 - val_loss: 1.0453 - val_accuracy: 0.4615\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9111 - accuracy: 0.5370 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9117 - accuracy: 0.5407 - val_loss: 1.0454 - val_accuracy: 0.4872\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9150 - accuracy: 0.5370 - val_loss: 1.0495 - val_accuracy: 0.4615\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.9110 - accuracy: 0.5407 - val_loss: 1.0470 - val_accuracy: 0.4872\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9110 - accuracy: 0.5407 - val_loss: 1.0495 - val_accuracy: 0.4615\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.9071 - accuracy: 0.5407 - val_loss: 1.0475 - val_accuracy: 0.4615\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.9098 - accuracy: 0.5370 - val_loss: 1.0478 - val_accuracy: 0.4701\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9118 - accuracy: 0.5074 - val_loss: 1.0483 - val_accuracy: 0.4530\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9156 - accuracy: 0.5296 - val_loss: 1.0474 - val_accuracy: 0.4957\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.9125 - accuracy: 0.5074 - val_loss: 1.0511 - val_accuracy: 0.4444\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9096 - accuracy: 0.5333 - val_loss: 1.0474 - val_accuracy: 0.4786\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9057 - accuracy: 0.5444 - val_loss: 1.0479 - val_accuracy: 0.4786\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9084 - accuracy: 0.5481 - val_loss: 1.0485 - val_accuracy: 0.4530\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9076 - accuracy: 0.5407 - val_loss: 1.0519 - val_accuracy: 0.4786\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9049 - accuracy: 0.5481 - val_loss: 1.0514 - val_accuracy: 0.4530\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9060 - accuracy: 0.5407 - val_loss: 1.0458 - val_accuracy: 0.4786\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.9060 - accuracy: 0.5444 - val_loss: 1.0496 - val_accuracy: 0.4530\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.9011 - accuracy: 0.5444 - val_loss: 1.0498 - val_accuracy: 0.4444\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.9056 - accuracy: 0.4852 - val_loss: 1.0481 - val_accuracy: 0.4786\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9064 - accuracy: 0.5000 - val_loss: 1.0521 - val_accuracy: 0.4530\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9030 - accuracy: 0.5444 - val_loss: 1.0493 - val_accuracy: 0.4786\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.9038 - accuracy: 0.5444 - val_loss: 1.0533 - val_accuracy: 0.4786\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9032 - accuracy: 0.5481 - val_loss: 1.0513 - val_accuracy: 0.4786\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9062 - accuracy: 0.5407 - val_loss: 1.0576 - val_accuracy: 0.4530\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.9041 - accuracy: 0.5296 - val_loss: 1.0485 - val_accuracy: 0.4444\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9013 - accuracy: 0.5259 - val_loss: 1.0444 - val_accuracy: 0.4786\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9006 - accuracy: 0.5444 - val_loss: 1.0458 - val_accuracy: 0.4786\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8989 - accuracy: 0.5481 - val_loss: 1.0542 - val_accuracy: 0.4786\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9014 - accuracy: 0.5444 - val_loss: 1.0503 - val_accuracy: 0.4786\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8982 - accuracy: 0.5259 - val_loss: 1.0533 - val_accuracy: 0.4530\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8959 - accuracy: 0.5481 - val_loss: 1.0506 - val_accuracy: 0.4786\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8966 - accuracy: 0.5481 - val_loss: 1.0512 - val_accuracy: 0.4786\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8953 - accuracy: 0.5481 - val_loss: 1.0533 - val_accuracy: 0.4786\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8985 - accuracy: 0.5481 - val_loss: 1.0526 - val_accuracy: 0.4530\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8979 - accuracy: 0.5259 - val_loss: 1.0513 - val_accuracy: 0.4701\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8991 - accuracy: 0.5481 - val_loss: 1.0504 - val_accuracy: 0.4530\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8963 - accuracy: 0.5481 - val_loss: 1.0576 - val_accuracy: 0.4786\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8961 - accuracy: 0.5481 - val_loss: 1.0550 - val_accuracy: 0.4786\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8981 - accuracy: 0.5481 - val_loss: 1.0573 - val_accuracy: 0.4530\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8932 - accuracy: 0.5481 - val_loss: 1.0520 - val_accuracy: 0.4530\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8942 - accuracy: 0.5519 - val_loss: 1.0516 - val_accuracy: 0.4786\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8934 - accuracy: 0.5481 - val_loss: 1.0552 - val_accuracy: 0.4786\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8947 - accuracy: 0.5481 - val_loss: 1.0574 - val_accuracy: 0.4786\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8940 - accuracy: 0.5481 - val_loss: 1.0544 - val_accuracy: 0.4786\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8927 - accuracy: 0.5519 - val_loss: 1.0560 - val_accuracy: 0.4786\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8910 - accuracy: 0.5519 - val_loss: 1.0597 - val_accuracy: 0.4786\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8938 - accuracy: 0.5519 - val_loss: 1.0601 - val_accuracy: 0.4786\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 407us/step - loss: 0.8932 - accuracy: 0.5519 - val_loss: 1.0600 - val_accuracy: 0.4786\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8893 - accuracy: 0.5519 - val_loss: 1.0613 - val_accuracy: 0.4530\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8952 - accuracy: 0.5519 - val_loss: 1.0630 - val_accuracy: 0.4530\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8976 - accuracy: 0.5296 - val_loss: 1.0563 - val_accuracy: 0.4786\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8907 - accuracy: 0.5519 - val_loss: 1.0612 - val_accuracy: 0.4530\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8919 - accuracy: 0.5444 - val_loss: 1.0626 - val_accuracy: 0.4786\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8894 - accuracy: 0.5519 - val_loss: 1.0581 - val_accuracy: 0.4786\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8908 - accuracy: 0.5519 - val_loss: 1.0578 - val_accuracy: 0.4786\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8906 - accuracy: 0.5519 - val_loss: 1.0636 - val_accuracy: 0.4786\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8885 - accuracy: 0.5519 - val_loss: 1.0625 - val_accuracy: 0.4786\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8906 - accuracy: 0.5481 - val_loss: 1.0640 - val_accuracy: 0.4530\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8893 - accuracy: 0.5556 - val_loss: 1.0586 - val_accuracy: 0.4786\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8880 - accuracy: 0.5519 - val_loss: 1.0619 - val_accuracy: 0.4786\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8923 - accuracy: 0.5370 - val_loss: 1.0609 - val_accuracy: 0.4444\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8870 - accuracy: 0.5296 - val_loss: 1.0605 - val_accuracy: 0.4444\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8875 - accuracy: 0.5519 - val_loss: 1.0600 - val_accuracy: 0.4701\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8930 - accuracy: 0.5407 - val_loss: 1.0672 - val_accuracy: 0.4786\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8863 - accuracy: 0.5519 - val_loss: 1.0711 - val_accuracy: 0.4444\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8871 - accuracy: 0.5519 - val_loss: 1.0677 - val_accuracy: 0.4786\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8905 - accuracy: 0.5519 - val_loss: 1.0638 - val_accuracy: 0.4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8857 - accuracy: 0.5519 - val_loss: 1.0630 - val_accuracy: 0.4444\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8879 - accuracy: 0.5185 - val_loss: 1.0635 - val_accuracy: 0.4444\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8868 - accuracy: 0.5296 - val_loss: 1.0641 - val_accuracy: 0.4786\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8843 - accuracy: 0.5519 - val_loss: 1.0660 - val_accuracy: 0.4786\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8846 - accuracy: 0.5519 - val_loss: 1.0633 - val_accuracy: 0.4701\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8862 - accuracy: 0.5481 - val_loss: 1.0639 - val_accuracy: 0.4701\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8862 - accuracy: 0.5148 - val_loss: 1.0687 - val_accuracy: 0.4444\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8832 - accuracy: 0.5296 - val_loss: 1.0640 - val_accuracy: 0.4786\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8839 - accuracy: 0.5519 - val_loss: 1.0665 - val_accuracy: 0.4786\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8885 - accuracy: 0.5519 - val_loss: 1.0673 - val_accuracy: 0.4701\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8865 - accuracy: 0.5556 - val_loss: 1.0712 - val_accuracy: 0.4701\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 296us/step - loss: 0.8831 - accuracy: 0.5407 - val_loss: 1.0681 - val_accuracy: 0.4444\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8844 - accuracy: 0.5556 - val_loss: 1.0681 - val_accuracy: 0.4786\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8816 - accuracy: 0.5519 - val_loss: 1.0644 - val_accuracy: 0.4786\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8819 - accuracy: 0.5519 - val_loss: 1.0678 - val_accuracy: 0.4701\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8896 - accuracy: 0.5481 - val_loss: 1.0681 - val_accuracy: 0.4444\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8892 - accuracy: 0.5259 - val_loss: 1.0711 - val_accuracy: 0.4701\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8874 - accuracy: 0.5407 - val_loss: 1.0673 - val_accuracy: 0.4701\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8938 - accuracy: 0.5481 - val_loss: 1.0672 - val_accuracy: 0.4701\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8932 - accuracy: 0.5407 - val_loss: 1.0705 - val_accuracy: 0.4701\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8974 - accuracy: 0.5407 - val_loss: 1.0728 - val_accuracy: 0.4444\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8842 - accuracy: 0.5519 - val_loss: 1.0670 - val_accuracy: 0.4701\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8840 - accuracy: 0.5519 - val_loss: 1.0761 - val_accuracy: 0.4786\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8811 - accuracy: 0.5074 - val_loss: 1.0705 - val_accuracy: 0.4444\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8875 - accuracy: 0.5519 - val_loss: 1.0609 - val_accuracy: 0.4701\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8823 - accuracy: 0.5519 - val_loss: 1.0591 - val_accuracy: 0.4701\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8809 - accuracy: 0.5370 - val_loss: 1.0686 - val_accuracy: 0.4444\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8840 - accuracy: 0.5444 - val_loss: 1.0676 - val_accuracy: 0.4786\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8783 - accuracy: 0.5481 - val_loss: 1.0723 - val_accuracy: 0.4444\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8833 - accuracy: 0.5185 - val_loss: 1.0681 - val_accuracy: 0.4359\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8777 - accuracy: 0.5333 - val_loss: 1.0701 - val_accuracy: 0.4786\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8794 - accuracy: 0.5519 - val_loss: 1.0728 - val_accuracy: 0.4786\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8816 - accuracy: 0.5519 - val_loss: 1.0745 - val_accuracy: 0.4444\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8806 - accuracy: 0.5593 - val_loss: 1.0692 - val_accuracy: 0.4701\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8800 - accuracy: 0.5444 - val_loss: 1.0728 - val_accuracy: 0.4444\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8779 - accuracy: 0.5481 - val_loss: 1.0689 - val_accuracy: 0.4701\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8776 - accuracy: 0.5593 - val_loss: 1.0741 - val_accuracy: 0.4786\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8854 - accuracy: 0.5222 - val_loss: 1.0780 - val_accuracy: 0.4786\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8770 - accuracy: 0.5556 - val_loss: 1.0761 - val_accuracy: 0.4444\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8792 - accuracy: 0.5481 - val_loss: 1.0701 - val_accuracy: 0.4701\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8755 - accuracy: 0.5519 - val_loss: 1.0742 - val_accuracy: 0.4786\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8770 - accuracy: 0.5519 - val_loss: 1.0740 - val_accuracy: 0.4444\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8820 - accuracy: 0.5556 - val_loss: 1.0678 - val_accuracy: 0.4701\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8747 - accuracy: 0.5444 - val_loss: 1.0780 - val_accuracy: 0.4444\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8812 - accuracy: 0.5296 - val_loss: 1.0799 - val_accuracy: 0.4530\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8851 - accuracy: 0.5481 - val_loss: 1.0760 - val_accuracy: 0.4701\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8751 - accuracy: 0.5556 - val_loss: 1.0788 - val_accuracy: 0.4786\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8765 - accuracy: 0.5519 - val_loss: 1.0866 - val_accuracy: 0.4444\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8748 - accuracy: 0.5556 - val_loss: 1.0710 - val_accuracy: 0.4701\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8749 - accuracy: 0.5519 - val_loss: 1.0707 - val_accuracy: 0.4701\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8755 - accuracy: 0.5519 - val_loss: 1.0781 - val_accuracy: 0.4701\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8755 - accuracy: 0.5444 - val_loss: 1.0846 - val_accuracy: 0.4701\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8831 - accuracy: 0.5481 - val_loss: 1.0929 - val_accuracy: 0.4701\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8778 - accuracy: 0.5667 - val_loss: 1.0786 - val_accuracy: 0.4701\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8784 - accuracy: 0.5519 - val_loss: 1.0774 - val_accuracy: 0.4701\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8759 - accuracy: 0.5519 - val_loss: 1.0850 - val_accuracy: 0.4786\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8792 - accuracy: 0.5333 - val_loss: 1.0926 - val_accuracy: 0.4359\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8766 - accuracy: 0.5333 - val_loss: 1.0870 - val_accuracy: 0.4701\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8801 - accuracy: 0.5370 - val_loss: 1.0815 - val_accuracy: 0.4701\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8709 - accuracy: 0.5481 - val_loss: 1.0844 - val_accuracy: 0.4444\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8782 - accuracy: 0.5519 - val_loss: 1.0779 - val_accuracy: 0.4701\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8732 - accuracy: 0.5519 - val_loss: 1.0867 - val_accuracy: 0.4701\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8751 - accuracy: 0.5481 - val_loss: 1.0821 - val_accuracy: 0.4701\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8757 - accuracy: 0.5519 - val_loss: 1.0812 - val_accuracy: 0.4701\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8745 - accuracy: 0.5333 - val_loss: 1.0849 - val_accuracy: 0.4701\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8765 - accuracy: 0.5333 - val_loss: 1.0927 - val_accuracy: 0.4444\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8780 - accuracy: 0.5444 - val_loss: 1.0953 - val_accuracy: 0.4786\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8736 - accuracy: 0.5519 - val_loss: 1.0852 - val_accuracy: 0.4701\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8710 - accuracy: 0.5519 - val_loss: 1.0796 - val_accuracy: 0.4701\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8750 - accuracy: 0.5519 - val_loss: 1.0881 - val_accuracy: 0.4701\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8756 - accuracy: 0.5519 - val_loss: 1.0898 - val_accuracy: 0.4701\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8743 - accuracy: 0.5556 - val_loss: 1.0863 - val_accuracy: 0.4444\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8715 - accuracy: 0.5333 - val_loss: 1.0879 - val_accuracy: 0.4615\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8734 - accuracy: 0.5296 - val_loss: 1.0919 - val_accuracy: 0.4786\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8715 - accuracy: 0.5481 - val_loss: 1.0853 - val_accuracy: 0.4701\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8750 - accuracy: 0.5519 - val_loss: 1.0886 - val_accuracy: 0.4701\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8707 - accuracy: 0.5481 - val_loss: 1.0947 - val_accuracy: 0.4701\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8720 - accuracy: 0.5333 - val_loss: 1.0829 - val_accuracy: 0.4701\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8724 - accuracy: 0.5556 - val_loss: 1.0821 - val_accuracy: 0.4701\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8733 - accuracy: 0.5296 - val_loss: 1.0833 - val_accuracy: 0.4615\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8763 - accuracy: 0.5556 - val_loss: 1.0901 - val_accuracy: 0.4444\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8766 - accuracy: 0.5148 - val_loss: 1.0937 - val_accuracy: 0.4701\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8752 - accuracy: 0.5333 - val_loss: 1.0851 - val_accuracy: 0.4701\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8754 - accuracy: 0.5519 - val_loss: 1.0844 - val_accuracy: 0.4701\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8728 - accuracy: 0.5407 - val_loss: 1.0954 - val_accuracy: 0.4701\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8684 - accuracy: 0.5444 - val_loss: 1.0948 - val_accuracy: 0.4444\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8714 - accuracy: 0.5593 - val_loss: 1.0924 - val_accuracy: 0.4701\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8787 - accuracy: 0.5481 - val_loss: 1.0927 - val_accuracy: 0.4701\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8755 - accuracy: 0.5519 - val_loss: 1.1049 - val_accuracy: 0.4444\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8745 - accuracy: 0.5519 - val_loss: 1.0898 - val_accuracy: 0.4701\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8712 - accuracy: 0.5259 - val_loss: 1.0897 - val_accuracy: 0.4615\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8703 - accuracy: 0.5111 - val_loss: 1.0957 - val_accuracy: 0.4444\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8690 - accuracy: 0.5444 - val_loss: 1.0904 - val_accuracy: 0.4701\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8712 - accuracy: 0.5444 - val_loss: 1.0954 - val_accuracy: 0.4444\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8727 - accuracy: 0.5333 - val_loss: 1.0950 - val_accuracy: 0.4701\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8717 - accuracy: 0.5444 - val_loss: 1.0850 - val_accuracy: 0.4444\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8677 - accuracy: 0.5481 - val_loss: 1.0841 - val_accuracy: 0.4701\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8670 - accuracy: 0.5370 - val_loss: 1.0942 - val_accuracy: 0.4786\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8750 - accuracy: 0.5185 - val_loss: 1.0981 - val_accuracy: 0.4786\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8638 - accuracy: 0.5519 - val_loss: 1.0906 - val_accuracy: 0.4701\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8696 - accuracy: 0.5519 - val_loss: 1.0893 - val_accuracy: 0.4701\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8688 - accuracy: 0.5370 - val_loss: 1.0944 - val_accuracy: 0.4701\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8684 - accuracy: 0.5519 - val_loss: 1.1030 - val_accuracy: 0.4701\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8702 - accuracy: 0.5519 - val_loss: 1.1071 - val_accuracy: 0.4444\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8682 - accuracy: 0.5444 - val_loss: 1.0992 - val_accuracy: 0.4701\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8683 - accuracy: 0.5481 - val_loss: 1.0995 - val_accuracy: 0.4444\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8700 - accuracy: 0.5148 - val_loss: 1.0895 - val_accuracy: 0.4615\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8675 - accuracy: 0.5519 - val_loss: 1.0944 - val_accuracy: 0.4701\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8705 - accuracy: 0.5481 - val_loss: 1.1019 - val_accuracy: 0.4444\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8667 - accuracy: 0.5185 - val_loss: 1.1027 - val_accuracy: 0.4615\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8681 - accuracy: 0.5407 - val_loss: 1.1018 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8685 - accuracy: 0.5519 - val_loss: 1.0975 - val_accuracy: 0.4701\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8661 - accuracy: 0.5519 - val_loss: 1.1018 - val_accuracy: 0.4701\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8669 - accuracy: 0.5519 - val_loss: 1.1059 - val_accuracy: 0.4444\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8683 - accuracy: 0.5519 - val_loss: 1.1027 - val_accuracy: 0.4701\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8660 - accuracy: 0.5519 - val_loss: 1.1010 - val_accuracy: 0.4701\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8666 - accuracy: 0.5519 - val_loss: 1.0968 - val_accuracy: 0.4701\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8692 - accuracy: 0.5111 - val_loss: 1.1051 - val_accuracy: 0.4359\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8688 - accuracy: 0.5222 - val_loss: 1.1081 - val_accuracy: 0.4701\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8657 - accuracy: 0.5519 - val_loss: 1.0989 - val_accuracy: 0.4444\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8681 - accuracy: 0.5333 - val_loss: 1.1021 - val_accuracy: 0.4359\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8667 - accuracy: 0.5556 - val_loss: 1.1111 - val_accuracy: 0.4701\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8665 - accuracy: 0.5593 - val_loss: 1.1117 - val_accuracy: 0.4701\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8660 - accuracy: 0.5519 - val_loss: 1.1021 - val_accuracy: 0.4701\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8644 - accuracy: 0.5519 - val_loss: 1.1051 - val_accuracy: 0.4444\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8708 - accuracy: 0.5481 - val_loss: 1.0959 - val_accuracy: 0.4444\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8649 - accuracy: 0.5556 - val_loss: 1.1107 - val_accuracy: 0.4701\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8693 - accuracy: 0.5519 - val_loss: 1.1118 - val_accuracy: 0.4444\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8645 - accuracy: 0.5519 - val_loss: 1.1070 - val_accuracy: 0.4615\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8667 - accuracy: 0.5407 - val_loss: 1.1034 - val_accuracy: 0.4701\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8643 - accuracy: 0.5519 - val_loss: 1.1001 - val_accuracy: 0.4701\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8670 - accuracy: 0.5481 - val_loss: 1.1088 - val_accuracy: 0.4701\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8650 - accuracy: 0.5519 - val_loss: 1.1055 - val_accuracy: 0.4701\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8636 - accuracy: 0.5259 - val_loss: 1.1014 - val_accuracy: 0.4444\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8640 - accuracy: 0.5519 - val_loss: 1.1047 - val_accuracy: 0.4444\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8679 - accuracy: 0.5259 - val_loss: 1.1051 - val_accuracy: 0.4701\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8634 - accuracy: 0.5519 - val_loss: 1.1034 - val_accuracy: 0.4444\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8666 - accuracy: 0.5481 - val_loss: 1.1148 - val_accuracy: 0.4444\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8656 - accuracy: 0.5556 - val_loss: 1.1076 - val_accuracy: 0.4701\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8674 - accuracy: 0.5370 - val_loss: 1.1022 - val_accuracy: 0.4444\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8638 - accuracy: 0.5481 - val_loss: 1.1062 - val_accuracy: 0.4701\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8663 - accuracy: 0.5519 - val_loss: 1.1072 - val_accuracy: 0.4444\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8670 - accuracy: 0.4963 - val_loss: 1.1065 - val_accuracy: 0.4701\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8663 - accuracy: 0.5519 - val_loss: 1.1078 - val_accuracy: 0.4701\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8644 - accuracy: 0.5519 - val_loss: 1.1061 - val_accuracy: 0.4701\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8688 - accuracy: 0.5519 - val_loss: 1.1183 - val_accuracy: 0.4444\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 1.1243 - val_accuracy: 0.4786\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8681 - accuracy: 0.5519 - val_loss: 1.1128 - val_accuracy: 0.4701\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8660 - accuracy: 0.5444 - val_loss: 1.1152 - val_accuracy: 0.4444\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8755 - accuracy: 0.5556 - val_loss: 1.1159 - val_accuracy: 0.4444\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 1.1225 - val_accuracy: 0.4701\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8650 - accuracy: 0.5259 - val_loss: 1.1143 - val_accuracy: 0.4701\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8627 - accuracy: 0.5444 - val_loss: 1.1093 - val_accuracy: 0.4444\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8629 - accuracy: 0.5444 - val_loss: 1.1185 - val_accuracy: 0.4701\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8644 - accuracy: 0.5519 - val_loss: 1.1238 - val_accuracy: 0.4701\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8639 - accuracy: 0.5519 - val_loss: 1.1171 - val_accuracy: 0.4444\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8618 - accuracy: 0.5481 - val_loss: 1.1175 - val_accuracy: 0.4701\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8627 - accuracy: 0.5593 - val_loss: 1.1145 - val_accuracy: 0.4615\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8626 - accuracy: 0.5370 - val_loss: 1.1157 - val_accuracy: 0.4444\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8623 - accuracy: 0.5519 - val_loss: 1.1091 - val_accuracy: 0.4701\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8618 - accuracy: 0.5519 - val_loss: 1.1066 - val_accuracy: 0.4701\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8631 - accuracy: 0.5519 - val_loss: 1.1149 - val_accuracy: 0.4444\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8633 - accuracy: 0.5519 - val_loss: 1.1163 - val_accuracy: 0.4444\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8692 - accuracy: 0.5481 - val_loss: 1.1164 - val_accuracy: 0.4701\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8608 - accuracy: 0.5519 - val_loss: 1.1021 - val_accuracy: 0.4444\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8619 - accuracy: 0.5519 - val_loss: 1.0989 - val_accuracy: 0.4444\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8637 - accuracy: 0.5556 - val_loss: 1.1055 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8619 - accuracy: 0.5519 - val_loss: 1.1093 - val_accuracy: 0.4701\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8613 - accuracy: 0.5370 - val_loss: 1.1107 - val_accuracy: 0.4701\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8603 - accuracy: 0.5519 - val_loss: 1.1141 - val_accuracy: 0.4701\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8614 - accuracy: 0.5519 - val_loss: 1.1210 - val_accuracy: 0.4701\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8628 - accuracy: 0.5519 - val_loss: 1.1203 - val_accuracy: 0.4701\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8648 - accuracy: 0.5111 - val_loss: 1.1200 - val_accuracy: 0.4359\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8601 - accuracy: 0.5444 - val_loss: 1.1146 - val_accuracy: 0.4701\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8622 - accuracy: 0.5519 - val_loss: 1.1177 - val_accuracy: 0.4701\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8605 - accuracy: 0.5519 - val_loss: 1.1244 - val_accuracy: 0.4701\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8640 - accuracy: 0.5259 - val_loss: 1.1249 - val_accuracy: 0.4701\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8669 - accuracy: 0.5519 - val_loss: 1.1128 - val_accuracy: 0.4701\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8651 - accuracy: 0.5111 - val_loss: 1.1253 - val_accuracy: 0.4701\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8622 - accuracy: 0.5259 - val_loss: 1.1264 - val_accuracy: 0.4701\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8599 - accuracy: 0.5519 - val_loss: 1.1194 - val_accuracy: 0.4701\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8622 - accuracy: 0.5074 - val_loss: 1.1129 - val_accuracy: 0.4701\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8623 - accuracy: 0.5074 - val_loss: 1.1195 - val_accuracy: 0.4701\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8637 - accuracy: 0.5519 - val_loss: 1.1270 - val_accuracy: 0.4701\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8634 - accuracy: 0.5519 - val_loss: 1.1302 - val_accuracy: 0.4786\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8616 - accuracy: 0.5556 - val_loss: 1.1132 - val_accuracy: 0.4444\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8600 - accuracy: 0.5481 - val_loss: 1.1136 - val_accuracy: 0.4701\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8595 - accuracy: 0.5519 - val_loss: 1.1126 - val_accuracy: 0.4701\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8637 - accuracy: 0.5148 - val_loss: 1.1199 - val_accuracy: 0.4701\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8617 - accuracy: 0.5481 - val_loss: 1.1194 - val_accuracy: 0.4444\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8621 - accuracy: 0.5519 - val_loss: 1.1212 - val_accuracy: 0.4701\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8605 - accuracy: 0.5519 - val_loss: 1.1219 - val_accuracy: 0.4701\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.1296 - val_accuracy: 0.4359\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8622 - accuracy: 0.5333 - val_loss: 1.1214 - val_accuracy: 0.4701\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8624 - accuracy: 0.5444 - val_loss: 1.1171 - val_accuracy: 0.4359\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8691 - accuracy: 0.5407 - val_loss: 1.1121 - val_accuracy: 0.4701\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8610 - accuracy: 0.5519 - val_loss: 1.1220 - val_accuracy: 0.4701\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8613 - accuracy: 0.5481 - val_loss: 1.1271 - val_accuracy: 0.4444\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8590 - accuracy: 0.5519 - val_loss: 1.1229 - val_accuracy: 0.4444\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8598 - accuracy: 0.5519 - val_loss: 1.1228 - val_accuracy: 0.4701\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8593 - accuracy: 0.5519 - val_loss: 1.1206 - val_accuracy: 0.4701\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8611 - accuracy: 0.5296 - val_loss: 1.1295 - val_accuracy: 0.4444\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8602 - accuracy: 0.5593 - val_loss: 1.1272 - val_accuracy: 0.4701\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8600 - accuracy: 0.5519 - val_loss: 1.1305 - val_accuracy: 0.4701\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8630 - accuracy: 0.5481 - val_loss: 1.1255 - val_accuracy: 0.4359\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8594 - accuracy: 0.5222 - val_loss: 1.1197 - val_accuracy: 0.4615\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8664 - accuracy: 0.5333 - val_loss: 1.1234 - val_accuracy: 0.4701\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8716 - accuracy: 0.5519 - val_loss: 1.1265 - val_accuracy: 0.4701\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8570 - accuracy: 0.5407 - val_loss: 1.1268 - val_accuracy: 0.4359\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8588 - accuracy: 0.5407 - val_loss: 1.1239 - val_accuracy: 0.4444\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8587 - accuracy: 0.5519 - val_loss: 1.1232 - val_accuracy: 0.4444\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8622 - accuracy: 0.5222 - val_loss: 1.1255 - val_accuracy: 0.4615\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8601 - accuracy: 0.5407 - val_loss: 1.1294 - val_accuracy: 0.4701\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8597 - accuracy: 0.5519 - val_loss: 1.1285 - val_accuracy: 0.4701\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8600 - accuracy: 0.5444 - val_loss: 1.1249 - val_accuracy: 0.4701\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8588 - accuracy: 0.5519 - val_loss: 1.1308 - val_accuracy: 0.4701\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8653 - accuracy: 0.5481 - val_loss: 1.1376 - val_accuracy: 0.4786\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8573 - accuracy: 0.5593 - val_loss: 1.1288 - val_accuracy: 0.4444\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8599 - accuracy: 0.5519 - val_loss: 1.1218 - val_accuracy: 0.4701\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8631 - accuracy: 0.5074 - val_loss: 1.1232 - val_accuracy: 0.4615\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8591 - accuracy: 0.5481 - val_loss: 1.1289 - val_accuracy: 0.4701\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8582 - accuracy: 0.5593 - val_loss: 1.1344 - val_accuracy: 0.4444\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8594 - accuracy: 0.5444 - val_loss: 1.1334 - val_accuracy: 0.4359\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8600 - accuracy: 0.5519 - val_loss: 1.1355 - val_accuracy: 0.4444\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8580 - accuracy: 0.5556 - val_loss: 1.1215 - val_accuracy: 0.4701\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8627 - accuracy: 0.5519 - val_loss: 1.1212 - val_accuracy: 0.4701\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 1.1230 - val_accuracy: 0.4701\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8558 - accuracy: 0.5519 - val_loss: 1.1233 - val_accuracy: 0.4701\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8586 - accuracy: 0.5481 - val_loss: 1.1304 - val_accuracy: 0.4444\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8594 - accuracy: 0.5556 - val_loss: 1.1200 - val_accuracy: 0.4701\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8582 - accuracy: 0.5519 - val_loss: 1.1266 - val_accuracy: 0.4701\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8569 - accuracy: 0.5556 - val_loss: 1.1271 - val_accuracy: 0.4615\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8591 - accuracy: 0.5444 - val_loss: 1.1339 - val_accuracy: 0.4701\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8599 - accuracy: 0.5556 - val_loss: 1.1277 - val_accuracy: 0.4701\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.8583 - accuracy: 0.5407 - val_loss: 1.1357 - val_accuracy: 0.4701\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8568 - accuracy: 0.5556 - val_loss: 1.1304 - val_accuracy: 0.4701\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8570 - accuracy: 0.5556 - val_loss: 1.1330 - val_accuracy: 0.4701\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8592 - accuracy: 0.5481 - val_loss: 1.1327 - val_accuracy: 0.4701\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8548 - accuracy: 0.5556 - val_loss: 1.1287 - val_accuracy: 0.4701\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8564 - accuracy: 0.5556 - val_loss: 1.1270 - val_accuracy: 0.4701\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8567 - accuracy: 0.5407 - val_loss: 1.1341 - val_accuracy: 0.4615\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8594 - accuracy: 0.5370 - val_loss: 1.1452 - val_accuracy: 0.4444\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8615 - accuracy: 0.5519 - val_loss: 1.1264 - val_accuracy: 0.4701\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8596 - accuracy: 0.5222 - val_loss: 1.1244 - val_accuracy: 0.4615\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8572 - accuracy: 0.5407 - val_loss: 1.1301 - val_accuracy: 0.4701\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8592 - accuracy: 0.5556 - val_loss: 1.1338 - val_accuracy: 0.4701\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8593 - accuracy: 0.5407 - val_loss: 1.1334 - val_accuracy: 0.4615\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8594 - accuracy: 0.5333 - val_loss: 1.1316 - val_accuracy: 0.4701\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8585 - accuracy: 0.5519 - val_loss: 1.1367 - val_accuracy: 0.4701\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8563 - accuracy: 0.5593 - val_loss: 1.1401 - val_accuracy: 0.4359\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8612 - accuracy: 0.5444 - val_loss: 1.1290 - val_accuracy: 0.4701\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8758 - accuracy: 0.5519 - val_loss: 1.1352 - val_accuracy: 0.4701\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.8715 - accuracy: 0.5148 - val_loss: 1.1529 - val_accuracy: 0.4444\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.59 - 0s 210us/step - loss: 0.8536 - accuracy: 0.5667 - val_loss: 1.1449 - val_accuracy: 0.4444\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8672 - accuracy: 0.5556 - val_loss: 1.1368 - val_accuracy: 0.4701\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8585 - accuracy: 0.5519 - val_loss: 1.1361 - val_accuracy: 0.4786\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8642 - accuracy: 0.5222 - val_loss: 1.1348 - val_accuracy: 0.4359\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8567 - accuracy: 0.5704 - val_loss: 1.1391 - val_accuracy: 0.4701\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8584 - accuracy: 0.5519 - val_loss: 1.1482 - val_accuracy: 0.4786\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8579 - accuracy: 0.5296 - val_loss: 1.1357 - val_accuracy: 0.4444\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8590 - accuracy: 0.5556 - val_loss: 1.1356 - val_accuracy: 0.4444\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8546 - accuracy: 0.5556 - val_loss: 1.1359 - val_accuracy: 0.4701\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8587 - accuracy: 0.5444 - val_loss: 1.1357 - val_accuracy: 0.4444\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8576 - accuracy: 0.5556 - val_loss: 1.1410 - val_accuracy: 0.4444\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8624 - accuracy: 0.5519 - val_loss: 1.1468 - val_accuracy: 0.4786\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8557 - accuracy: 0.5519 - val_loss: 1.1381 - val_accuracy: 0.4444\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8552 - accuracy: 0.5444 - val_loss: 1.1300 - val_accuracy: 0.4701\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8561 - accuracy: 0.5333 - val_loss: 1.1319 - val_accuracy: 0.4701\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8599 - accuracy: 0.5333 - val_loss: 1.1398 - val_accuracy: 0.4701\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8625 - accuracy: 0.5519 - val_loss: 1.1555 - val_accuracy: 0.4444\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8545 - accuracy: 0.5556 - val_loss: 1.1494 - val_accuracy: 0.4701\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8583 - accuracy: 0.5519 - val_loss: 1.1336 - val_accuracy: 0.4701\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8579 - accuracy: 0.5407 - val_loss: 1.1386 - val_accuracy: 0.4359\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8603 - accuracy: 0.5074 - val_loss: 1.1345 - val_accuracy: 0.4701\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8597 - accuracy: 0.4963 - val_loss: 1.1305 - val_accuracy: 0.4615\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8554 - accuracy: 0.5370 - val_loss: 1.1425 - val_accuracy: 0.4444\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8563 - accuracy: 0.5556 - val_loss: 1.1408 - val_accuracy: 0.4701\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 89us/step - loss: 0.8566 - accuracy: 0.5296 - val_loss: 1.1338 - val_accuracy: 0.4701\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8569 - accuracy: 0.5556 - val_loss: 1.1430 - val_accuracy: 0.4444\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8582 - accuracy: 0.5481 - val_loss: 1.1373 - val_accuracy: 0.4701\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8606 - accuracy: 0.5074 - val_loss: 1.1416 - val_accuracy: 0.4701\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8634 - accuracy: 0.5519 - val_loss: 1.1551 - val_accuracy: 0.4444\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8632 - accuracy: 0.5148 - val_loss: 1.1377 - val_accuracy: 0.4615\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8592 - accuracy: 0.5407 - val_loss: 1.1190 - val_accuracy: 0.4444\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8571 - accuracy: 0.5593 - val_loss: 1.1189 - val_accuracy: 0.4615\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8546 - accuracy: 0.5370 - val_loss: 1.1243 - val_accuracy: 0.4701\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8567 - accuracy: 0.5556 - val_loss: 1.1316 - val_accuracy: 0.4701\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8607 - accuracy: 0.5333 - val_loss: 1.1333 - val_accuracy: 0.4701\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8577 - accuracy: 0.5296 - val_loss: 1.1355 - val_accuracy: 0.4701\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8559 - accuracy: 0.5556 - val_loss: 1.1321 - val_accuracy: 0.4701\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8567 - accuracy: 0.5074 - val_loss: 1.1338 - val_accuracy: 0.4701\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8555 - accuracy: 0.5556 - val_loss: 1.1441 - val_accuracy: 0.4701\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8558 - accuracy: 0.5593 - val_loss: 1.1429 - val_accuracy: 0.4444\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8572 - accuracy: 0.5556 - val_loss: 1.1424 - val_accuracy: 0.4444\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8553 - accuracy: 0.5556 - val_loss: 1.1504 - val_accuracy: 0.4786\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 1.1414 - val_accuracy: 0.4701\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8602 - accuracy: 0.5519 - val_loss: 1.1497 - val_accuracy: 0.4359\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8557 - accuracy: 0.5481 - val_loss: 1.1503 - val_accuracy: 0.4701\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8531 - accuracy: 0.5556 - val_loss: 1.1538 - val_accuracy: 0.4701\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8551 - accuracy: 0.5556 - val_loss: 1.1488 - val_accuracy: 0.4701\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8578 - accuracy: 0.5185 - val_loss: 1.1515 - val_accuracy: 0.4359\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8563 - accuracy: 0.5259 - val_loss: 1.1474 - val_accuracy: 0.4701\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8562 - accuracy: 0.5519 - val_loss: 1.1504 - val_accuracy: 0.4701\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8538 - accuracy: 0.5185 - val_loss: 1.1493 - val_accuracy: 0.4701\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8615 - accuracy: 0.5556 - val_loss: 1.1636 - val_accuracy: 0.4701\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8636 - accuracy: 0.5444 - val_loss: 1.1641 - val_accuracy: 0.4701\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8579 - accuracy: 0.5556 - val_loss: 1.1485 - val_accuracy: 0.4444\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8566 - accuracy: 0.5519 - val_loss: 1.1527 - val_accuracy: 0.4701\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8595 - accuracy: 0.5000 - val_loss: 1.1485 - val_accuracy: 0.4701\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8544 - accuracy: 0.5556 - val_loss: 1.1529 - val_accuracy: 0.4444\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8576 - accuracy: 0.5556 - val_loss: 1.1411 - val_accuracy: 0.4701\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8542 - accuracy: 0.5407 - val_loss: 1.1503 - val_accuracy: 0.4359\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8579 - accuracy: 0.5556 - val_loss: 1.1485 - val_accuracy: 0.4444\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8534 - accuracy: 0.5556 - val_loss: 1.1523 - val_accuracy: 0.4701\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8654 - accuracy: 0.5407 - val_loss: 1.1422 - val_accuracy: 0.4701\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8569 - accuracy: 0.5630 - val_loss: 1.1427 - val_accuracy: 0.4444\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8567 - accuracy: 0.5407 - val_loss: 1.1494 - val_accuracy: 0.4359\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8518 - accuracy: 0.5370 - val_loss: 1.1496 - val_accuracy: 0.4786\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8660 - accuracy: 0.5519 - val_loss: 1.1473 - val_accuracy: 0.4701\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8538 - accuracy: 0.5630 - val_loss: 1.1545 - val_accuracy: 0.4359\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8546 - accuracy: 0.5407 - val_loss: 1.1515 - val_accuracy: 0.4359\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8554 - accuracy: 0.5296 - val_loss: 1.1545 - val_accuracy: 0.4701\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8546 - accuracy: 0.5556 - val_loss: 1.1597 - val_accuracy: 0.4444\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8557 - accuracy: 0.5556 - val_loss: 1.1625 - val_accuracy: 0.4701\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8539 - accuracy: 0.5519 - val_loss: 1.1553 - val_accuracy: 0.4701\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8530 - accuracy: 0.5556 - val_loss: 1.1457 - val_accuracy: 0.4701\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8567 - accuracy: 0.5296 - val_loss: 1.1417 - val_accuracy: 0.4359\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8522 - accuracy: 0.5593 - val_loss: 1.1490 - val_accuracy: 0.4701\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8594 - accuracy: 0.5556 - val_loss: 1.1590 - val_accuracy: 0.4701\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8611 - accuracy: 0.5333 - val_loss: 1.1623 - val_accuracy: 0.4444\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8603 - accuracy: 0.5148 - val_loss: 1.1445 - val_accuracy: 0.4701\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8556 - accuracy: 0.5556 - val_loss: 1.1460 - val_accuracy: 0.4701\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8516 - accuracy: 0.5630 - val_loss: 1.1551 - val_accuracy: 0.4359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8560 - accuracy: 0.5333 - val_loss: 1.1539 - val_accuracy: 0.4444\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8542 - accuracy: 0.5556 - val_loss: 1.1600 - val_accuracy: 0.4701\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8632 - accuracy: 0.5148 - val_loss: 1.1605 - val_accuracy: 0.4786\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8511 - accuracy: 0.5556 - val_loss: 1.1442 - val_accuracy: 0.4444\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8572 - accuracy: 0.5370 - val_loss: 1.1365 - val_accuracy: 0.4444\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8562 - accuracy: 0.5519 - val_loss: 1.1495 - val_accuracy: 0.4786\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8555 - accuracy: 0.5556 - val_loss: 1.1507 - val_accuracy: 0.4701\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8534 - accuracy: 0.5556 - val_loss: 1.1448 - val_accuracy: 0.4701\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8551 - accuracy: 0.5556 - val_loss: 1.1537 - val_accuracy: 0.4444\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.1575 - val_accuracy: 0.4444\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8536 - accuracy: 0.5556 - val_loss: 1.1597 - val_accuracy: 0.4444\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8608 - accuracy: 0.5519 - val_loss: 1.1600 - val_accuracy: 0.4701\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8520 - accuracy: 0.5259 - val_loss: 1.1632 - val_accuracy: 0.4359\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8631 - accuracy: 0.5556 - val_loss: 1.1669 - val_accuracy: 0.4444\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8656 - accuracy: 0.5259 - val_loss: 1.1710 - val_accuracy: 0.4701\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 1.1561 - val_accuracy: 0.4701\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8546 - accuracy: 0.5519 - val_loss: 1.1600 - val_accuracy: 0.4615\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8555 - accuracy: 0.5296 - val_loss: 1.1646 - val_accuracy: 0.4444\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8528 - accuracy: 0.5556 - val_loss: 1.1632 - val_accuracy: 0.4444\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8677 - accuracy: 0.5407 - val_loss: 1.1628 - val_accuracy: 0.4786\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8575 - accuracy: 0.5556 - val_loss: 1.1461 - val_accuracy: 0.4444\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8587 - accuracy: 0.5556 - val_loss: 1.1428 - val_accuracy: 0.4359\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8626 - accuracy: 0.5370 - val_loss: 1.1627 - val_accuracy: 0.4701\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8597 - accuracy: 0.5481 - val_loss: 1.1573 - val_accuracy: 0.4701\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8568 - accuracy: 0.5556 - val_loss: 1.1500 - val_accuracy: 0.4701\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8530 - accuracy: 0.5481 - val_loss: 1.1597 - val_accuracy: 0.4359\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8545 - accuracy: 0.5407 - val_loss: 1.1523 - val_accuracy: 0.4701\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8529 - accuracy: 0.5556 - val_loss: 1.1555 - val_accuracy: 0.4701\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8611 - accuracy: 0.4889 - val_loss: 1.1601 - val_accuracy: 0.4701\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8567 - accuracy: 0.5593 - val_loss: 1.1644 - val_accuracy: 0.4701\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8523 - accuracy: 0.5556 - val_loss: 1.1674 - val_accuracy: 0.4786\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8532 - accuracy: 0.5556 - val_loss: 1.1597 - val_accuracy: 0.4701\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8546 - accuracy: 0.5259 - val_loss: 1.1616 - val_accuracy: 0.4359\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8570 - accuracy: 0.5185 - val_loss: 1.1579 - val_accuracy: 0.4701\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8585 - accuracy: 0.5556 - val_loss: 1.1619 - val_accuracy: 0.4444\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8520 - accuracy: 0.5593 - val_loss: 1.1652 - val_accuracy: 0.4701\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8543 - accuracy: 0.5481 - val_loss: 1.1624 - val_accuracy: 0.4701\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8531 - accuracy: 0.5407 - val_loss: 1.1577 - val_accuracy: 0.4701\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8524 - accuracy: 0.5556 - val_loss: 1.1601 - val_accuracy: 0.4701\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8533 - accuracy: 0.5519 - val_loss: 1.1722 - val_accuracy: 0.4444\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8527 - accuracy: 0.5593 - val_loss: 1.1595 - val_accuracy: 0.4701\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8527 - accuracy: 0.5556 - val_loss: 1.1506 - val_accuracy: 0.4701\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8547 - accuracy: 0.5259 - val_loss: 1.1545 - val_accuracy: 0.4359\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8518 - accuracy: 0.5407 - val_loss: 1.1576 - val_accuracy: 0.4359\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8554 - accuracy: 0.5593 - val_loss: 1.1658 - val_accuracy: 0.4701\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8538 - accuracy: 0.5556 - val_loss: 1.1674 - val_accuracy: 0.4444\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8536 - accuracy: 0.5222 - val_loss: 1.1645 - val_accuracy: 0.4786\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.1585 - val_accuracy: 0.4701\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.1556 - val_accuracy: 0.4701\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.1558 - val_accuracy: 0.4701\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8536 - accuracy: 0.5407 - val_loss: 1.1659 - val_accuracy: 0.4359\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8515 - accuracy: 0.5481 - val_loss: 1.1717 - val_accuracy: 0.4444\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8522 - accuracy: 0.5556 - val_loss: 1.1775 - val_accuracy: 0.4701\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.1717 - val_accuracy: 0.4444\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8527 - accuracy: 0.5556 - val_loss: 1.1715 - val_accuracy: 0.4444\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8532 - accuracy: 0.5519 - val_loss: 1.1743 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.1553 - val_accuracy: 0.4359\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8519 - accuracy: 0.5296 - val_loss: 1.1530 - val_accuracy: 0.4359\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8540 - accuracy: 0.5333 - val_loss: 1.1526 - val_accuracy: 0.4444\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8550 - accuracy: 0.5556 - val_loss: 1.1586 - val_accuracy: 0.4444\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8533 - accuracy: 0.5556 - val_loss: 1.1671 - val_accuracy: 0.4701\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8566 - accuracy: 0.5444 - val_loss: 1.1597 - val_accuracy: 0.4701\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8509 - accuracy: 0.5556 - val_loss: 1.1633 - val_accuracy: 0.4359\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8519 - accuracy: 0.5407 - val_loss: 1.1605 - val_accuracy: 0.4359\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8526 - accuracy: 0.5407 - val_loss: 1.1662 - val_accuracy: 0.4359\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8542 - accuracy: 0.5000 - val_loss: 1.1684 - val_accuracy: 0.4786\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8506 - accuracy: 0.5556 - val_loss: 1.1661 - val_accuracy: 0.4701\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8559 - accuracy: 0.5074 - val_loss: 1.1707 - val_accuracy: 0.4359\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8563 - accuracy: 0.5481 - val_loss: 1.1694 - val_accuracy: 0.4701\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8519 - accuracy: 0.5519 - val_loss: 1.1733 - val_accuracy: 0.4444\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8522 - accuracy: 0.5481 - val_loss: 1.1761 - val_accuracy: 0.4786\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8537 - accuracy: 0.5296 - val_loss: 1.1643 - val_accuracy: 0.4444\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8532 - accuracy: 0.5556 - val_loss: 1.1712 - val_accuracy: 0.4444\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8509 - accuracy: 0.5556 - val_loss: 1.1758 - val_accuracy: 0.4444\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8545 - accuracy: 0.5370 - val_loss: 1.1801 - val_accuracy: 0.4786\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8574 - accuracy: 0.5556 - val_loss: 1.1654 - val_accuracy: 0.4701\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8554 - accuracy: 0.5556 - val_loss: 1.1637 - val_accuracy: 0.4701\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8529 - accuracy: 0.5593 - val_loss: 1.1605 - val_accuracy: 0.4444\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8534 - accuracy: 0.5593 - val_loss: 1.1596 - val_accuracy: 0.4701\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.1698 - val_accuracy: 0.4701\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8521 - accuracy: 0.5481 - val_loss: 1.1793 - val_accuracy: 0.4444\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8543 - accuracy: 0.5296 - val_loss: 1.1795 - val_accuracy: 0.4701\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8502 - accuracy: 0.5630 - val_loss: 1.1776 - val_accuracy: 0.4701\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8563 - accuracy: 0.5593 - val_loss: 1.1750 - val_accuracy: 0.4444\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8488 - accuracy: 0.5593 - val_loss: 1.1861 - val_accuracy: 0.4701\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8555 - accuracy: 0.5333 - val_loss: 1.1844 - val_accuracy: 0.4786\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8498 - accuracy: 0.5519 - val_loss: 1.1784 - val_accuracy: 0.4444\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.1721 - val_accuracy: 0.4444\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.1689 - val_accuracy: 0.4701\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8529 - accuracy: 0.5556 - val_loss: 1.1727 - val_accuracy: 0.4701\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8516 - accuracy: 0.5556 - val_loss: 1.1724 - val_accuracy: 0.4701\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.1849 - val_accuracy: 0.4701\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8523 - accuracy: 0.5556 - val_loss: 1.1700 - val_accuracy: 0.4444\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8583 - accuracy: 0.5593 - val_loss: 1.1736 - val_accuracy: 0.4701\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.1669 - val_accuracy: 0.4701\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8507 - accuracy: 0.5333 - val_loss: 1.1676 - val_accuracy: 0.4359\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8514 - accuracy: 0.5481 - val_loss: 1.1750 - val_accuracy: 0.4701\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8516 - accuracy: 0.5519 - val_loss: 1.1762 - val_accuracy: 0.4701\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8552 - accuracy: 0.5556 - val_loss: 1.1698 - val_accuracy: 0.4786\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8524 - accuracy: 0.5296 - val_loss: 1.1612 - val_accuracy: 0.4615\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8525 - accuracy: 0.5407 - val_loss: 1.1686 - val_accuracy: 0.4444\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8491 - accuracy: 0.5556 - val_loss: 1.1740 - val_accuracy: 0.4444\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8579 - accuracy: 0.5148 - val_loss: 1.1787 - val_accuracy: 0.4359\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8506 - accuracy: 0.5519 - val_loss: 1.1733 - val_accuracy: 0.4444\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8501 - accuracy: 0.5593 - val_loss: 1.1776 - val_accuracy: 0.4701\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8531 - accuracy: 0.5556 - val_loss: 1.1830 - val_accuracy: 0.4701\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8522 - accuracy: 0.5519 - val_loss: 1.1837 - val_accuracy: 0.4701\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8516 - accuracy: 0.5333 - val_loss: 1.1751 - val_accuracy: 0.4701\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8513 - accuracy: 0.5556 - val_loss: 1.1756 - val_accuracy: 0.4701\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8550 - accuracy: 0.5519 - val_loss: 1.1842 - val_accuracy: 0.4359\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8563 - accuracy: 0.5370 - val_loss: 1.1879 - val_accuracy: 0.4786\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8510 - accuracy: 0.5556 - val_loss: 1.1637 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8618 - accuracy: 0.5556 - val_loss: 1.1603 - val_accuracy: 0.4444\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8513 - accuracy: 0.5296 - val_loss: 1.1648 - val_accuracy: 0.4701\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 1.1553 - val_accuracy: 0.4701\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.1590 - val_accuracy: 0.4701\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8503 - accuracy: 0.5556 - val_loss: 1.1663 - val_accuracy: 0.4701\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8541 - accuracy: 0.5148 - val_loss: 1.1604 - val_accuracy: 0.4359\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8510 - accuracy: 0.5037 - val_loss: 1.1743 - val_accuracy: 0.4701\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8560 - accuracy: 0.5333 - val_loss: 1.1780 - val_accuracy: 0.4444\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8473 - accuracy: 0.5370 - val_loss: 1.1802 - val_accuracy: 0.4701\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8538 - accuracy: 0.5481 - val_loss: 1.1699 - val_accuracy: 0.4701\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8518 - accuracy: 0.5222 - val_loss: 1.1747 - val_accuracy: 0.4359\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8522 - accuracy: 0.5481 - val_loss: 1.1779 - val_accuracy: 0.4444\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8528 - accuracy: 0.5556 - val_loss: 1.1854 - val_accuracy: 0.4701\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8546 - accuracy: 0.5593 - val_loss: 1.1826 - val_accuracy: 0.4444\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8514 - accuracy: 0.5333 - val_loss: 1.1741 - val_accuracy: 0.4359\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8497 - accuracy: 0.5407 - val_loss: 1.1713 - val_accuracy: 0.4701\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8525 - accuracy: 0.5111 - val_loss: 1.1639 - val_accuracy: 0.4701\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8547 - accuracy: 0.5556 - val_loss: 1.1683 - val_accuracy: 0.4444\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8531 - accuracy: 0.5148 - val_loss: 1.1732 - val_accuracy: 0.4359\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8490 - accuracy: 0.5556 - val_loss: 1.1736 - val_accuracy: 0.4701\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.1748 - val_accuracy: 0.4701\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8511 - accuracy: 0.5556 - val_loss: 1.1794 - val_accuracy: 0.4444\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.1839 - val_accuracy: 0.4444\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8609 - accuracy: 0.5556 - val_loss: 1.1776 - val_accuracy: 0.4701\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8484 - accuracy: 0.5519 - val_loss: 1.1613 - val_accuracy: 0.4444\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8551 - accuracy: 0.5556 - val_loss: 1.1614 - val_accuracy: 0.4444\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8495 - accuracy: 0.5593 - val_loss: 1.1698 - val_accuracy: 0.4786\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.1775 - val_accuracy: 0.4786\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.1772 - val_accuracy: 0.4701\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.1724 - val_accuracy: 0.4701\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8518 - accuracy: 0.5037 - val_loss: 1.1719 - val_accuracy: 0.4359\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8503 - accuracy: 0.5333 - val_loss: 1.1783 - val_accuracy: 0.4701\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8525 - accuracy: 0.5593 - val_loss: 1.1799 - val_accuracy: 0.4786\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8507 - accuracy: 0.5519 - val_loss: 1.1845 - val_accuracy: 0.4444\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8520 - accuracy: 0.5556 - val_loss: 1.1975 - val_accuracy: 0.4701\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.1993 - val_accuracy: 0.4786\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8528 - accuracy: 0.5556 - val_loss: 1.1944 - val_accuracy: 0.4786\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.1717 - val_accuracy: 0.4444\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8507 - accuracy: 0.5370 - val_loss: 1.1709 - val_accuracy: 0.4701\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8554 - accuracy: 0.5556 - val_loss: 1.1746 - val_accuracy: 0.4701\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8503 - accuracy: 0.5370 - val_loss: 1.1791 - val_accuracy: 0.4701\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8551 - accuracy: 0.5222 - val_loss: 1.1793 - val_accuracy: 0.4701\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8517 - accuracy: 0.5296 - val_loss: 1.1757 - val_accuracy: 0.4359\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8501 - accuracy: 0.5333 - val_loss: 1.1760 - val_accuracy: 0.4701\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8507 - accuracy: 0.5185 - val_loss: 1.1803 - val_accuracy: 0.4701\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8571 - accuracy: 0.5556 - val_loss: 1.1852 - val_accuracy: 0.4701\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8551 - accuracy: 0.5407 - val_loss: 1.1950 - val_accuracy: 0.4359\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8493 - accuracy: 0.5370 - val_loss: 1.1943 - val_accuracy: 0.4786\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8553 - accuracy: 0.5556 - val_loss: 1.1960 - val_accuracy: 0.4786\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8522 - accuracy: 0.5259 - val_loss: 1.1787 - val_accuracy: 0.4701\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8501 - accuracy: 0.5444 - val_loss: 1.1784 - val_accuracy: 0.4701\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8547 - accuracy: 0.5556 - val_loss: 1.1950 - val_accuracy: 0.4701\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8618 - accuracy: 0.5185 - val_loss: 1.1983 - val_accuracy: 0.4444\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8536 - accuracy: 0.5259 - val_loss: 1.1876 - val_accuracy: 0.4701\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8495 - accuracy: 0.5519 - val_loss: 1.1881 - val_accuracy: 0.4615\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8487 - accuracy: 0.5407 - val_loss: 1.1914 - val_accuracy: 0.4701\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8587 - accuracy: 0.5407 - val_loss: 1.1874 - val_accuracy: 0.4444\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8487 - accuracy: 0.5519 - val_loss: 1.1887 - val_accuracy: 0.4701\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8538 - accuracy: 0.5556 - val_loss: 1.1910 - val_accuracy: 0.4701\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8519 - accuracy: 0.5481 - val_loss: 1.1926 - val_accuracy: 0.4701\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8534 - accuracy: 0.5111 - val_loss: 1.1900 - val_accuracy: 0.4444\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.1935 - val_accuracy: 0.4701\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8512 - accuracy: 0.5556 - val_loss: 1.1651 - val_accuracy: 0.4701\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8490 - accuracy: 0.5296 - val_loss: 1.1648 - val_accuracy: 0.4701\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.1693 - val_accuracy: 0.4701\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8520 - accuracy: 0.5556 - val_loss: 1.1754 - val_accuracy: 0.4701\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8503 - accuracy: 0.5519 - val_loss: 1.1879 - val_accuracy: 0.4701\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8495 - accuracy: 0.5407 - val_loss: 1.1772 - val_accuracy: 0.4701\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8504 - accuracy: 0.5259 - val_loss: 1.1654 - val_accuracy: 0.4701\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8544 - accuracy: 0.5481 - val_loss: 1.1735 - val_accuracy: 0.4615\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8507 - accuracy: 0.5407 - val_loss: 1.1743 - val_accuracy: 0.4444\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8529 - accuracy: 0.5630 - val_loss: 1.1862 - val_accuracy: 0.4786\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.1863 - val_accuracy: 0.4786\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8530 - accuracy: 0.4889 - val_loss: 1.1790 - val_accuracy: 0.4701\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8487 - accuracy: 0.5259 - val_loss: 1.1788 - val_accuracy: 0.4444\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8510 - accuracy: 0.5037 - val_loss: 1.1831 - val_accuracy: 0.4615\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8523 - accuracy: 0.5519 - val_loss: 1.1872 - val_accuracy: 0.4701\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8501 - accuracy: 0.5481 - val_loss: 1.1871 - val_accuracy: 0.4701\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8564 - accuracy: 0.5407 - val_loss: 1.1905 - val_accuracy: 0.4615\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8518 - accuracy: 0.5481 - val_loss: 1.2004 - val_accuracy: 0.4701\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8518 - accuracy: 0.5593 - val_loss: 1.2018 - val_accuracy: 0.4786\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8493 - accuracy: 0.5333 - val_loss: 1.1920 - val_accuracy: 0.4359\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8526 - accuracy: 0.5222 - val_loss: 1.1878 - val_accuracy: 0.4701\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8493 - accuracy: 0.5519 - val_loss: 1.1900 - val_accuracy: 0.4786\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8488 - accuracy: 0.5370 - val_loss: 1.1948 - val_accuracy: 0.4701\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8505 - accuracy: 0.5296 - val_loss: 1.1814 - val_accuracy: 0.4701\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8610 - accuracy: 0.5556 - val_loss: 1.1822 - val_accuracy: 0.4701\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8470 - accuracy: 0.5667 - val_loss: 1.1874 - val_accuracy: 0.4615\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8558 - accuracy: 0.5407 - val_loss: 1.1892 - val_accuracy: 0.4615\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8491 - accuracy: 0.5519 - val_loss: 1.1835 - val_accuracy: 0.4701\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8544 - accuracy: 0.5556 - val_loss: 1.1819 - val_accuracy: 0.4701\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.8597 - accuracy: 0.5185 - val_loss: 1.1964 - val_accuracy: 0.4701\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8491 - accuracy: 0.5407 - val_loss: 1.1954 - val_accuracy: 0.4444\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8516 - accuracy: 0.5556 - val_loss: 1.1870 - val_accuracy: 0.4701\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.1878 - val_accuracy: 0.4701\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8572 - accuracy: 0.5370 - val_loss: 1.1958 - val_accuracy: 0.4701\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8530 - accuracy: 0.5444 - val_loss: 1.1764 - val_accuracy: 0.4701\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8521 - accuracy: 0.5259 - val_loss: 1.1743 - val_accuracy: 0.4615\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8476 - accuracy: 0.5296 - val_loss: 1.1779 - val_accuracy: 0.4701\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.1828 - val_accuracy: 0.4701\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8516 - accuracy: 0.5222 - val_loss: 1.1751 - val_accuracy: 0.4701\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8560 - accuracy: 0.5556 - val_loss: 1.1789 - val_accuracy: 0.4444\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8496 - accuracy: 0.5519 - val_loss: 1.1809 - val_accuracy: 0.4701\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8496 - accuracy: 0.5407 - val_loss: 1.1853 - val_accuracy: 0.4701\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.1937 - val_accuracy: 0.4444\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8492 - accuracy: 0.5444 - val_loss: 1.1916 - val_accuracy: 0.4701\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8506 - accuracy: 0.5444 - val_loss: 1.1831 - val_accuracy: 0.4701\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.1926 - val_accuracy: 0.4701\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8515 - accuracy: 0.5556 - val_loss: 1.1943 - val_accuracy: 0.4701\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8516 - accuracy: 0.5370 - val_loss: 1.1941 - val_accuracy: 0.4615\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 140us/step - loss: 0.8505 - accuracy: 0.5148 - val_loss: 1.1877 - val_accuracy: 0.4701\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.1864 - val_accuracy: 0.4701\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.1827 - val_accuracy: 0.4701\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8500 - accuracy: 0.5481 - val_loss: 1.1922 - val_accuracy: 0.4701\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.1971 - val_accuracy: 0.4701\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.1988 - val_accuracy: 0.4444\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.1908 - val_accuracy: 0.4701\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8494 - accuracy: 0.5444 - val_loss: 1.1941 - val_accuracy: 0.4701\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.1919 - val_accuracy: 0.4701\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.2013 - val_accuracy: 0.4701\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8538 - accuracy: 0.5556 - val_loss: 1.2030 - val_accuracy: 0.4701\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8569 - accuracy: 0.5296 - val_loss: 1.1941 - val_accuracy: 0.4444\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8532 - accuracy: 0.5556 - val_loss: 1.1859 - val_accuracy: 0.4701\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8527 - accuracy: 0.5556 - val_loss: 1.1924 - val_accuracy: 0.4701\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.1984 - val_accuracy: 0.4701\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.2021 - val_accuracy: 0.4701\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.2020 - val_accuracy: 0.4701\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8499 - accuracy: 0.5519 - val_loss: 1.1906 - val_accuracy: 0.4701\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.1926 - val_accuracy: 0.4701\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8526 - accuracy: 0.5556 - val_loss: 1.1872 - val_accuracy: 0.4359\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8496 - accuracy: 0.5407 - val_loss: 1.1933 - val_accuracy: 0.4359\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8483 - accuracy: 0.5259 - val_loss: 1.2091 - val_accuracy: 0.4786\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.1945 - val_accuracy: 0.4786\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.1832 - val_accuracy: 0.4444\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.8481 - accuracy: 0.5481 - val_loss: 1.1876 - val_accuracy: 0.4615\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8507 - accuracy: 0.5481 - val_loss: 1.1885 - val_accuracy: 0.4786\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.1953 - val_accuracy: 0.4444\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.2017 - val_accuracy: 0.4444\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8526 - accuracy: 0.5444 - val_loss: 1.1961 - val_accuracy: 0.4444\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8519 - accuracy: 0.5481 - val_loss: 1.2048 - val_accuracy: 0.4786\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8467 - accuracy: 0.5593 - val_loss: 1.1986 - val_accuracy: 0.4444\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.1994 - val_accuracy: 0.4444\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8497 - accuracy: 0.5333 - val_loss: 1.1936 - val_accuracy: 0.4615\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8518 - accuracy: 0.4926 - val_loss: 1.1852 - val_accuracy: 0.4615\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8504 - accuracy: 0.5556 - val_loss: 1.1906 - val_accuracy: 0.4701\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8490 - accuracy: 0.5519 - val_loss: 1.2023 - val_accuracy: 0.4530\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8479 - accuracy: 0.5630 - val_loss: 1.1990 - val_accuracy: 0.4444\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8510 - accuracy: 0.5556 - val_loss: 1.2057 - val_accuracy: 0.4444\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8531 - accuracy: 0.5556 - val_loss: 1.2132 - val_accuracy: 0.4444\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8557 - accuracy: 0.5481 - val_loss: 1.2178 - val_accuracy: 0.4786\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8493 - accuracy: 0.5444 - val_loss: 1.1848 - val_accuracy: 0.4359\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8583 - accuracy: 0.5444 - val_loss: 1.1811 - val_accuracy: 0.4444\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8507 - accuracy: 0.5556 - val_loss: 1.1806 - val_accuracy: 0.4701\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.1895 - val_accuracy: 0.4786\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8536 - accuracy: 0.5259 - val_loss: 1.1981 - val_accuracy: 0.4444\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8477 - accuracy: 0.5593 - val_loss: 1.2033 - val_accuracy: 0.4444\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8526 - accuracy: 0.5556 - val_loss: 1.2022 - val_accuracy: 0.4530\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8506 - accuracy: 0.5370 - val_loss: 1.2120 - val_accuracy: 0.4701\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8503 - accuracy: 0.5667 - val_loss: 1.2169 - val_accuracy: 0.4444\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8512 - accuracy: 0.5481 - val_loss: 1.2127 - val_accuracy: 0.4786\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.1973 - val_accuracy: 0.4701\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8504 - accuracy: 0.5185 - val_loss: 1.1930 - val_accuracy: 0.4444\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8517 - accuracy: 0.5407 - val_loss: 1.1978 - val_accuracy: 0.4615\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.8519 - accuracy: 0.5444 - val_loss: 1.2106 - val_accuracy: 0.4701\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.2144 - val_accuracy: 0.4701\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8505 - accuracy: 0.5481 - val_loss: 1.2163 - val_accuracy: 0.4786\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8506 - accuracy: 0.5519 - val_loss: 1.1999 - val_accuracy: 0.4615\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8496 - accuracy: 0.5407 - val_loss: 1.2019 - val_accuracy: 0.4615\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8496 - accuracy: 0.5333 - val_loss: 1.1982 - val_accuracy: 0.4701\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.1961 - val_accuracy: 0.4615\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8509 - accuracy: 0.5370 - val_loss: 1.2128 - val_accuracy: 0.4701\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 1.2116 - val_accuracy: 0.4701\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8498 - accuracy: 0.5370 - val_loss: 1.2129 - val_accuracy: 0.4615\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8480 - accuracy: 0.5370 - val_loss: 1.2065 - val_accuracy: 0.4701\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.2081 - val_accuracy: 0.4701\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.2182 - val_accuracy: 0.4701\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8519 - accuracy: 0.5185 - val_loss: 1.2195 - val_accuracy: 0.4701\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8509 - accuracy: 0.5519 - val_loss: 1.2112 - val_accuracy: 0.4701\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.2056 - val_accuracy: 0.4701\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8507 - accuracy: 0.5296 - val_loss: 1.2091 - val_accuracy: 0.4615\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8497 - accuracy: 0.5259 - val_loss: 1.2136 - val_accuracy: 0.4701\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8496 - accuracy: 0.5519 - val_loss: 1.2147 - val_accuracy: 0.4701\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8517 - accuracy: 0.5481 - val_loss: 1.2046 - val_accuracy: 0.4444\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8560 - accuracy: 0.5148 - val_loss: 1.2110 - val_accuracy: 0.4701\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8503 - accuracy: 0.5370 - val_loss: 1.2047 - val_accuracy: 0.4701\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.2135 - val_accuracy: 0.4701\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8546 - accuracy: 0.5037 - val_loss: 1.1994 - val_accuracy: 0.4701\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8482 - accuracy: 0.5407 - val_loss: 1.2018 - val_accuracy: 0.4701\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8550 - accuracy: 0.5000 - val_loss: 1.2100 - val_accuracy: 0.4359\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8465 - accuracy: 0.5444 - val_loss: 1.2073 - val_accuracy: 0.4701\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.2037 - val_accuracy: 0.4701\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.2096 - val_accuracy: 0.4615\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8471 - accuracy: 0.5370 - val_loss: 1.2140 - val_accuracy: 0.4701\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8489 - accuracy: 0.5296 - val_loss: 1.2130 - val_accuracy: 0.4701\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.2165 - val_accuracy: 0.4701\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8488 - accuracy: 0.5519 - val_loss: 1.2130 - val_accuracy: 0.4701\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8492 - accuracy: 0.5407 - val_loss: 1.2147 - val_accuracy: 0.4701\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.2147 - val_accuracy: 0.4701\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8464 - accuracy: 0.5741 - val_loss: 1.2163 - val_accuracy: 0.4359\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8515 - accuracy: 0.5407 - val_loss: 1.2216 - val_accuracy: 0.4359\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8472 - accuracy: 0.5407 - val_loss: 1.2178 - val_accuracy: 0.4701\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.2227 - val_accuracy: 0.4701\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.2258 - val_accuracy: 0.4786\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.2222 - val_accuracy: 0.4786\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.2070 - val_accuracy: 0.4701\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.2096 - val_accuracy: 0.4701\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8510 - accuracy: 0.5519 - val_loss: 1.2087 - val_accuracy: 0.4359\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8470 - accuracy: 0.5370 - val_loss: 1.2112 - val_accuracy: 0.4701\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8492 - accuracy: 0.5556 - val_loss: 1.2121 - val_accuracy: 0.4786\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8464 - accuracy: 0.5333 - val_loss: 1.2135 - val_accuracy: 0.4701\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8509 - accuracy: 0.5519 - val_loss: 1.2160 - val_accuracy: 0.4444\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8502 - accuracy: 0.5481 - val_loss: 1.2154 - val_accuracy: 0.4701\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8488 - accuracy: 0.5667 - val_loss: 1.2173 - val_accuracy: 0.4701\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8503 - accuracy: 0.5556 - val_loss: 1.2072 - val_accuracy: 0.4701\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.2231 - val_accuracy: 0.4701\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8468 - accuracy: 0.5667 - val_loss: 1.2157 - val_accuracy: 0.4359\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8498 - accuracy: 0.5407 - val_loss: 1.2194 - val_accuracy: 0.4359\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8493 - accuracy: 0.5000 - val_loss: 1.2209 - val_accuracy: 0.4786\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.2148 - val_accuracy: 0.4701\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8490 - accuracy: 0.5444 - val_loss: 1.2166 - val_accuracy: 0.4701\n",
      "Epoch 777/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 140us/step - loss: 0.8552 - accuracy: 0.5296 - val_loss: 1.2148 - val_accuracy: 0.4444\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8495 - accuracy: 0.5519 - val_loss: 1.2156 - val_accuracy: 0.4701\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.2227 - val_accuracy: 0.4701\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8478 - accuracy: 0.5593 - val_loss: 1.2321 - val_accuracy: 0.4444\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8486 - accuracy: 0.5444 - val_loss: 1.2394 - val_accuracy: 0.4701\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8477 - accuracy: 0.5519 - val_loss: 1.1954 - val_accuracy: 0.4701\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.1867 - val_accuracy: 0.4701\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.1926 - val_accuracy: 0.4701\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.2037 - val_accuracy: 0.4444\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8505 - accuracy: 0.5259 - val_loss: 1.2091 - val_accuracy: 0.4444\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8472 - accuracy: 0.5593 - val_loss: 1.2070 - val_accuracy: 0.4444\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8518 - accuracy: 0.5556 - val_loss: 1.2104 - val_accuracy: 0.4701\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.2241 - val_accuracy: 0.4786\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8488 - accuracy: 0.5185 - val_loss: 1.2024 - val_accuracy: 0.4701\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.2047 - val_accuracy: 0.4701\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.2225 - val_accuracy: 0.4701\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.2193 - val_accuracy: 0.4444\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.2341 - val_accuracy: 0.4786\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8479 - accuracy: 0.5259 - val_loss: 1.2308 - val_accuracy: 0.4444\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8537 - accuracy: 0.5593 - val_loss: 1.2342 - val_accuracy: 0.4701\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8482 - accuracy: 0.5407 - val_loss: 1.2153 - val_accuracy: 0.4701\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8503 - accuracy: 0.5333 - val_loss: 1.2104 - val_accuracy: 0.4701\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.2129 - val_accuracy: 0.4701\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.2270 - val_accuracy: 0.4444\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8508 - accuracy: 0.5444 - val_loss: 1.2092 - val_accuracy: 0.4444\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.2186 - val_accuracy: 0.4786\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8542 - accuracy: 0.5556 - val_loss: 1.2318 - val_accuracy: 0.4786\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.2156 - val_accuracy: 0.4444\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8491 - accuracy: 0.5444 - val_loss: 1.2084 - val_accuracy: 0.4359\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8510 - accuracy: 0.5481 - val_loss: 1.2045 - val_accuracy: 0.4701\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.2107 - val_accuracy: 0.4701\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.2267 - val_accuracy: 0.4530\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8481 - accuracy: 0.5481 - val_loss: 1.2329 - val_accuracy: 0.4530\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8533 - accuracy: 0.5556 - val_loss: 1.2266 - val_accuracy: 0.4444\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.2305 - val_accuracy: 0.4786\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8481 - accuracy: 0.5333 - val_loss: 1.2222 - val_accuracy: 0.4786\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8467 - accuracy: 0.5630 - val_loss: 1.2191 - val_accuracy: 0.4444\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.2199 - val_accuracy: 0.4444\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8487 - accuracy: 0.5481 - val_loss: 1.2248 - val_accuracy: 0.4359\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8477 - accuracy: 0.5481 - val_loss: 1.2249 - val_accuracy: 0.4786\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8482 - accuracy: 0.5519 - val_loss: 1.2198 - val_accuracy: 0.4444\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.2246 - val_accuracy: 0.4444\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8601 - accuracy: 0.5111 - val_loss: 1.2277 - val_accuracy: 0.4701\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8466 - accuracy: 0.5370 - val_loss: 1.2251 - val_accuracy: 0.4444\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.2331 - val_accuracy: 0.4701\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8511 - accuracy: 0.5481 - val_loss: 1.2413 - val_accuracy: 0.4701\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8481 - accuracy: 0.5481 - val_loss: 1.2347 - val_accuracy: 0.4444\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8491 - accuracy: 0.5519 - val_loss: 1.2404 - val_accuracy: 0.4701\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.2413 - val_accuracy: 0.4786\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8481 - accuracy: 0.5593 - val_loss: 1.2323 - val_accuracy: 0.4701\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.2305 - val_accuracy: 0.4701\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8521 - accuracy: 0.5519 - val_loss: 1.2435 - val_accuracy: 0.4444\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8517 - accuracy: 0.5074 - val_loss: 1.2400 - val_accuracy: 0.4786\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.2310 - val_accuracy: 0.4701\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.2302 - val_accuracy: 0.4701\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8562 - accuracy: 0.5074 - val_loss: 1.2300 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 1.2352 - val_accuracy: 0.4701\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.2381 - val_accuracy: 0.4786\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8484 - accuracy: 0.5370 - val_loss: 1.2425 - val_accuracy: 0.4701\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8523 - accuracy: 0.5444 - val_loss: 1.2316 - val_accuracy: 0.4359\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.2236 - val_accuracy: 0.4701\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8549 - accuracy: 0.5148 - val_loss: 1.2376 - val_accuracy: 0.4701\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8645 - accuracy: 0.5259 - val_loss: 1.2348 - val_accuracy: 0.4701\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8554 - accuracy: 0.5148 - val_loss: 1.2334 - val_accuracy: 0.4701\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8492 - accuracy: 0.5296 - val_loss: 1.2295 - val_accuracy: 0.4786\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8585 - accuracy: 0.5556 - val_loss: 1.2235 - val_accuracy: 0.4701\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8579 - accuracy: 0.5259 - val_loss: 1.2389 - val_accuracy: 0.4444\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8509 - accuracy: 0.5333 - val_loss: 1.2266 - val_accuracy: 0.4701\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.2263 - val_accuracy: 0.4701\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8460 - accuracy: 0.5704 - val_loss: 1.2385 - val_accuracy: 0.4701\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8494 - accuracy: 0.5407 - val_loss: 1.2027 - val_accuracy: 0.4701\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8544 - accuracy: 0.5556 - val_loss: 1.2010 - val_accuracy: 0.4701\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8522 - accuracy: 0.5037 - val_loss: 1.2137 - val_accuracy: 0.4444\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.2079 - val_accuracy: 0.4444\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8507 - accuracy: 0.5370 - val_loss: 1.2110 - val_accuracy: 0.4701\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8555 - accuracy: 0.5556 - val_loss: 1.2239 - val_accuracy: 0.4701\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8519 - accuracy: 0.5556 - val_loss: 1.2347 - val_accuracy: 0.4786\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8536 - accuracy: 0.5222 - val_loss: 1.2229 - val_accuracy: 0.4444\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.2215 - val_accuracy: 0.4444\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8487 - accuracy: 0.5593 - val_loss: 1.2259 - val_accuracy: 0.4786\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8494 - accuracy: 0.5296 - val_loss: 1.2238 - val_accuracy: 0.4359\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8484 - accuracy: 0.5407 - val_loss: 1.2268 - val_accuracy: 0.4701\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.2305 - val_accuracy: 0.4701\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8495 - accuracy: 0.5148 - val_loss: 1.2364 - val_accuracy: 0.4701\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.2390 - val_accuracy: 0.4444\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.2420 - val_accuracy: 0.4444\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.2430 - val_accuracy: 0.4701\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8519 - accuracy: 0.5519 - val_loss: 1.2412 - val_accuracy: 0.4701\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.2388 - val_accuracy: 0.4701\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8558 - accuracy: 0.5259 - val_loss: 1.2483 - val_accuracy: 0.4701\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8462 - accuracy: 0.5481 - val_loss: 1.2373 - val_accuracy: 0.4701\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8538 - accuracy: 0.5148 - val_loss: 1.2320 - val_accuracy: 0.4359\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8490 - accuracy: 0.5593 - val_loss: 1.2340 - val_accuracy: 0.4701\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.2418 - val_accuracy: 0.4786\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8495 - accuracy: 0.5481 - val_loss: 1.2418 - val_accuracy: 0.4444\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8522 - accuracy: 0.5296 - val_loss: 1.2412 - val_accuracy: 0.4701\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8486 - accuracy: 0.5519 - val_loss: 1.2285 - val_accuracy: 0.4701\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8501 - accuracy: 0.5556 - val_loss: 1.2422 - val_accuracy: 0.4701\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8480 - accuracy: 0.5296 - val_loss: 1.2420 - val_accuracy: 0.4615\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8506 - accuracy: 0.5444 - val_loss: 1.2152 - val_accuracy: 0.4615\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8488 - accuracy: 0.5444 - val_loss: 1.2094 - val_accuracy: 0.4701\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 1.2217 - val_accuracy: 0.4701\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8538 - accuracy: 0.5037 - val_loss: 1.2237 - val_accuracy: 0.4701\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.2248 - val_accuracy: 0.4701\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8525 - accuracy: 0.5556 - val_loss: 1.2234 - val_accuracy: 0.4444\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.2048 - val_accuracy: 0.4701\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8521 - accuracy: 0.5037 - val_loss: 1.2124 - val_accuracy: 0.4786\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8491 - accuracy: 0.5333 - val_loss: 1.2211 - val_accuracy: 0.4786\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.2189 - val_accuracy: 0.4701\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.2157 - val_accuracy: 0.4444\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8504 - accuracy: 0.5481 - val_loss: 1.2300 - val_accuracy: 0.4701\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8477 - accuracy: 0.5407 - val_loss: 1.2365 - val_accuracy: 0.4701\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8544 - accuracy: 0.5519 - val_loss: 1.2461 - val_accuracy: 0.4786\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8513 - accuracy: 0.5481 - val_loss: 1.2324 - val_accuracy: 0.4444\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8500 - accuracy: 0.5556 - val_loss: 1.2291 - val_accuracy: 0.4701\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8541 - accuracy: 0.5519 - val_loss: 1.2361 - val_accuracy: 0.4444\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 1.2464 - val_accuracy: 0.4786\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.2506 - val_accuracy: 0.4786\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8478 - accuracy: 0.5556 - val_loss: 1.2399 - val_accuracy: 0.4701\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2420 - val_accuracy: 0.4444\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8528 - accuracy: 0.4926 - val_loss: 1.2277 - val_accuracy: 0.4786\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8463 - accuracy: 0.5259 - val_loss: 1.2363 - val_accuracy: 0.4444\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8491 - accuracy: 0.5296 - val_loss: 1.2409 - val_accuracy: 0.4530\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.2440 - val_accuracy: 0.4701\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8491 - accuracy: 0.5519 - val_loss: 1.2469 - val_accuracy: 0.4786\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8491 - accuracy: 0.5370 - val_loss: 1.2098 - val_accuracy: 0.4615\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8479 - accuracy: 0.5444 - val_loss: 1.2020 - val_accuracy: 0.4701\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.2034 - val_accuracy: 0.4444\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8468 - accuracy: 0.5296 - val_loss: 1.2073 - val_accuracy: 0.4701\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8472 - accuracy: 0.5259 - val_loss: 1.2121 - val_accuracy: 0.4786\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.2130 - val_accuracy: 0.4701\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8455 - accuracy: 0.5667 - val_loss: 1.2172 - val_accuracy: 0.4701\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8471 - accuracy: 0.5185 - val_loss: 1.2198 - val_accuracy: 0.4444\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8477 - accuracy: 0.5222 - val_loss: 1.2230 - val_accuracy: 0.4701\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8503 - accuracy: 0.5519 - val_loss: 1.2293 - val_accuracy: 0.4701\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.2307 - val_accuracy: 0.4444\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8502 - accuracy: 0.5370 - val_loss: 1.2393 - val_accuracy: 0.4444\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8512 - accuracy: 0.5407 - val_loss: 1.2389 - val_accuracy: 0.4359\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8487 - accuracy: 0.5444 - val_loss: 1.2351 - val_accuracy: 0.4786\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8513 - accuracy: 0.5556 - val_loss: 1.2314 - val_accuracy: 0.4701\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.2265 - val_accuracy: 0.4444\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.2282 - val_accuracy: 0.4444\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8500 - accuracy: 0.5333 - val_loss: 1.2421 - val_accuracy: 0.4444\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8468 - accuracy: 0.4926 - val_loss: 1.2348 - val_accuracy: 0.4786\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8486 - accuracy: 0.5556 - val_loss: 1.2377 - val_accuracy: 0.4701\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.2418 - val_accuracy: 0.4444\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.2454 - val_accuracy: 0.4444\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.2352 - val_accuracy: 0.4444\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8474 - accuracy: 0.5519 - val_loss: 1.2421 - val_accuracy: 0.4786\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.2386 - val_accuracy: 0.4444\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8497 - accuracy: 0.5111 - val_loss: 1.2466 - val_accuracy: 0.4444\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8476 - accuracy: 0.5185 - val_loss: 1.2493 - val_accuracy: 0.4444\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8468 - accuracy: 0.5519 - val_loss: 1.2498 - val_accuracy: 0.4701\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.2501 - val_accuracy: 0.4786\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8498 - accuracy: 0.5556 - val_loss: 1.2513 - val_accuracy: 0.4701\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8535 - accuracy: 0.5222 - val_loss: 1.2303 - val_accuracy: 0.4701\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.2384 - val_accuracy: 0.4701\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.2429 - val_accuracy: 0.4786\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8460 - accuracy: 0.5407 - val_loss: 1.2367 - val_accuracy: 0.4444\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.2330 - val_accuracy: 0.4701\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.2344 - val_accuracy: 0.4701\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8502 - accuracy: 0.5222 - val_loss: 1.2422 - val_accuracy: 0.4444\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8510 - accuracy: 0.5481 - val_loss: 1.2426 - val_accuracy: 0.4444\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8490 - accuracy: 0.5519 - val_loss: 1.2594 - val_accuracy: 0.4786\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8467 - accuracy: 0.5481 - val_loss: 1.2450 - val_accuracy: 0.4530\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.2254 - val_accuracy: 0.4701\n",
      "Epoch 943/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 142us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.2196 - val_accuracy: 0.4701\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8534 - accuracy: 0.5556 - val_loss: 1.2367 - val_accuracy: 0.4444\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8448 - accuracy: 0.5407 - val_loss: 1.2453 - val_accuracy: 0.4786\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.2485 - val_accuracy: 0.4786\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.2493 - val_accuracy: 0.4701\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8450 - accuracy: 0.5222 - val_loss: 1.2524 - val_accuracy: 0.4359\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8478 - accuracy: 0.5111 - val_loss: 1.2501 - val_accuracy: 0.4359\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8473 - accuracy: 0.5148 - val_loss: 1.2580 - val_accuracy: 0.4444\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8476 - accuracy: 0.5519 - val_loss: 1.2509 - val_accuracy: 0.4701\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.2491 - val_accuracy: 0.4530\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8512 - accuracy: 0.5481 - val_loss: 1.2477 - val_accuracy: 0.4444\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.8528 - accuracy: 0.5148 - val_loss: 1.2585 - val_accuracy: 0.4444\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8515 - accuracy: 0.5407 - val_loss: 1.2606 - val_accuracy: 0.4359\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8454 - accuracy: 0.5593 - val_loss: 1.2576 - val_accuracy: 0.4444\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.2555 - val_accuracy: 0.4786\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.2568 - val_accuracy: 0.4786\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.2505 - val_accuracy: 0.4786\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8489 - accuracy: 0.5556 - val_loss: 1.2600 - val_accuracy: 0.4530\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8488 - accuracy: 0.5593 - val_loss: 1.2425 - val_accuracy: 0.4444\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8470 - accuracy: 0.5296 - val_loss: 1.2433 - val_accuracy: 0.4701\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8490 - accuracy: 0.5370 - val_loss: 1.2435 - val_accuracy: 0.4701\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.2478 - val_accuracy: 0.4701\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8511 - accuracy: 0.5148 - val_loss: 1.2616 - val_accuracy: 0.4444\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8489 - accuracy: 0.5259 - val_loss: 1.2573 - val_accuracy: 0.4786\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8478 - accuracy: 0.5593 - val_loss: 1.2497 - val_accuracy: 0.4444\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.2457 - val_accuracy: 0.4701\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8510 - accuracy: 0.5185 - val_loss: 1.2511 - val_accuracy: 0.4701\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8440 - accuracy: 0.5593 - val_loss: 1.2474 - val_accuracy: 0.4701\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8564 - accuracy: 0.5519 - val_loss: 1.2616 - val_accuracy: 0.4444\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8432 - accuracy: 0.5259 - val_loss: 1.2563 - val_accuracy: 0.4786\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.2702 - val_accuracy: 0.4786\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8480 - accuracy: 0.5593 - val_loss: 1.2663 - val_accuracy: 0.4701\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.2444 - val_accuracy: 0.4444\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8444 - accuracy: 0.5259 - val_loss: 1.2374 - val_accuracy: 0.4701\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.2420 - val_accuracy: 0.4786\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8506 - accuracy: 0.5556 - val_loss: 1.2404 - val_accuracy: 0.4701\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8493 - accuracy: 0.5296 - val_loss: 1.2470 - val_accuracy: 0.4359\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8480 - accuracy: 0.5370 - val_loss: 1.2547 - val_accuracy: 0.4444\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8503 - accuracy: 0.5481 - val_loss: 1.2387 - val_accuracy: 0.4701\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8465 - accuracy: 0.5593 - val_loss: 1.2500 - val_accuracy: 0.4444\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8479 - accuracy: 0.5296 - val_loss: 1.2429 - val_accuracy: 0.4359\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8464 - accuracy: 0.5185 - val_loss: 1.2673 - val_accuracy: 0.4530\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8460 - accuracy: 0.5481 - val_loss: 1.2718 - val_accuracy: 0.4444\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8483 - accuracy: 0.5407 - val_loss: 1.2654 - val_accuracy: 0.4530\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.2520 - val_accuracy: 0.4701\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8485 - accuracy: 0.5370 - val_loss: 1.2462 - val_accuracy: 0.4359\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8468 - accuracy: 0.5407 - val_loss: 1.2529 - val_accuracy: 0.4444\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.2641 - val_accuracy: 0.4786\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8529 - accuracy: 0.5222 - val_loss: 1.2712 - val_accuracy: 0.4444\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8493 - accuracy: 0.5333 - val_loss: 1.2579 - val_accuracy: 0.4444\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.2557 - val_accuracy: 0.4701\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.2615 - val_accuracy: 0.4786\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.2614 - val_accuracy: 0.4530\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.2576 - val_accuracy: 0.4359\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8459 - accuracy: 0.5444 - val_loss: 1.2563 - val_accuracy: 0.4701\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.2605 - val_accuracy: 0.4701\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.2740 - val_accuracy: 0.4444\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.2669 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39b5a2e8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 47.01%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 1, 1, 1, 0, 1, 2, 2, 2, 1, 0, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1,\n",
       "       1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2,\n",
       "       0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS249     2     1\n",
       "1         NRS188     1     1\n",
       "2         NRS232     2     2\n",
       "3          NY439     2     2\n",
       "4           GA27     2     1\n",
       "..           ...   ...   ...\n",
       "112       SR3569     0     1\n",
       "113       NRS204     0     0\n",
       "114       NRS203     0     0\n",
       "115     CFBRSa25     1     1\n",
       "116  CFBREBSa131     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188887</td>\n",
       "      <td>0.510804</td>\n",
       "      <td>0.300309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188887</td>\n",
       "      <td>0.510804</td>\n",
       "      <td>0.300309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.422291</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.507410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394097</td>\n",
       "      <td>0.418422</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.394097</td>\n",
       "      <td>0.418422</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.731846</td>\n",
       "      <td>0.199811</td>\n",
       "      <td>0.068343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.044885</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.394097</td>\n",
       "      <td>0.418422</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.394097</td>\n",
       "      <td>0.418422</td>\n",
       "      <td>0.187481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.188887  0.510804  0.300309\n",
       "1    0.188887  0.510804  0.300309\n",
       "2    0.422291  0.070299  0.507410\n",
       "3    0.000356  0.000298  0.999347\n",
       "4    0.394097  0.418422  0.187481\n",
       "..        ...       ...       ...\n",
       "112  0.394097  0.418422  0.187481\n",
       "113  0.731846  0.199811  0.068343\n",
       "114  0.925632  0.044885  0.029483\n",
       "115  0.394097  0.418422  0.187481\n",
       "116  0.394097  0.418422  0.187481\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1620 - val_accuracy: 0.4444\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.1627 - val_accuracy: 0.4444\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8491 - accuracy: 0.5630 - val_loss: 1.1629 - val_accuracy: 0.4701\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8466 - accuracy: 0.5296 - val_loss: 1.1595 - val_accuracy: 0.4444\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.1615 - val_accuracy: 0.4444\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8454 - accuracy: 0.5481 - val_loss: 1.1654 - val_accuracy: 0.4701\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.1652 - val_accuracy: 0.4444\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8477 - accuracy: 0.5148 - val_loss: 1.1663 - val_accuracy: 0.4701\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.1681 - val_accuracy: 0.4444\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.1603 - val_accuracy: 0.4444\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.1643 - val_accuracy: 0.4701\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8483 - accuracy: 0.5222 - val_loss: 1.1614 - val_accuracy: 0.4359\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8461 - accuracy: 0.5481 - val_loss: 1.1716 - val_accuracy: 0.4701\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.1660 - val_accuracy: 0.4444\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1679 - val_accuracy: 0.4444\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.1656 - val_accuracy: 0.4701\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8466 - accuracy: 0.5481 - val_loss: 1.1688 - val_accuracy: 0.4359\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8470 - accuracy: 0.5444 - val_loss: 1.1687 - val_accuracy: 0.4701\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8509 - accuracy: 0.5556 - val_loss: 1.1769 - val_accuracy: 0.4701\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1635 - val_accuracy: 0.4444\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8450 - accuracy: 0.5296 - val_loss: 1.1625 - val_accuracy: 0.4359\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8461 - accuracy: 0.5407 - val_loss: 1.1668 - val_accuracy: 0.4444\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.1692 - val_accuracy: 0.4701\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1778 - val_accuracy: 0.4786\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.1750 - val_accuracy: 0.4530\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1704 - val_accuracy: 0.4786\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1691 - val_accuracy: 0.4701\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1714 - val_accuracy: 0.4701\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1680 - val_accuracy: 0.4701\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1694 - val_accuracy: 0.4701\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.1783 - val_accuracy: 0.4444\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1721 - val_accuracy: 0.4444\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8491 - accuracy: 0.5481 - val_loss: 1.1708 - val_accuracy: 0.4701\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8474 - accuracy: 0.5370 - val_loss: 1.1688 - val_accuracy: 0.4444\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.1722 - val_accuracy: 0.4444\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8566 - accuracy: 0.5519 - val_loss: 1.1813 - val_accuracy: 0.4701\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.1709 - val_accuracy: 0.4444\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8519 - accuracy: 0.5333 - val_loss: 1.1769 - val_accuracy: 0.4444\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8486 - accuracy: 0.5407 - val_loss: 1.1783 - val_accuracy: 0.4701\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1680 - val_accuracy: 0.4701\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.1698 - val_accuracy: 0.4444\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8519 - accuracy: 0.5556 - val_loss: 1.1633 - val_accuracy: 0.4701\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.1536 - val_accuracy: 0.4359\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8483 - accuracy: 0.5333 - val_loss: 1.1512 - val_accuracy: 0.4444\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1592 - val_accuracy: 0.4701\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1603 - val_accuracy: 0.4701\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8468 - accuracy: 0.5370 - val_loss: 1.1639 - val_accuracy: 0.4615\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8462 - accuracy: 0.5444 - val_loss: 1.1647 - val_accuracy: 0.4701\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.1689 - val_accuracy: 0.4444\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1640 - val_accuracy: 0.4444\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.1613 - val_accuracy: 0.4444\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8463 - accuracy: 0.5370 - val_loss: 1.1625 - val_accuracy: 0.4615\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8510 - accuracy: 0.5407 - val_loss: 1.1798 - val_accuracy: 0.4701\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.1669 - val_accuracy: 0.4615\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8453 - accuracy: 0.4926 - val_loss: 1.1677 - val_accuracy: 0.4444\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8441 - accuracy: 0.5593 - val_loss: 1.1698 - val_accuracy: 0.4701\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.1681 - val_accuracy: 0.4444\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8466 - accuracy: 0.5333 - val_loss: 1.1684 - val_accuracy: 0.4359\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.1682 - val_accuracy: 0.4701\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.1702 - val_accuracy: 0.4701\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.8486 - accuracy: 0.5519 - val_loss: 1.1714 - val_accuracy: 0.4444\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8505 - accuracy: 0.5407 - val_loss: 1.1657 - val_accuracy: 0.4701\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1706 - val_accuracy: 0.4701\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1763 - val_accuracy: 0.4530\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.1718 - val_accuracy: 0.4444\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8469 - accuracy: 0.5185 - val_loss: 1.1680 - val_accuracy: 0.4701\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8492 - accuracy: 0.5519 - val_loss: 1.1704 - val_accuracy: 0.4701\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8477 - accuracy: 0.5593 - val_loss: 1.1767 - val_accuracy: 0.4444\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8507 - accuracy: 0.5111 - val_loss: 1.1721 - val_accuracy: 0.4444\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8451 - accuracy: 0.5407 - val_loss: 1.1728 - val_accuracy: 0.4444\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1785 - val_accuracy: 0.4530\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.1775 - val_accuracy: 0.4701\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 539us/step - loss: 0.8469 - accuracy: 0.5296 - val_loss: 1.1780 - val_accuracy: 0.4530\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8448 - accuracy: 0.5222 - val_loss: 1.1739 - val_accuracy: 0.4530\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8434 - accuracy: 0.5111 - val_loss: 1.1719 - val_accuracy: 0.4701\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.1678 - val_accuracy: 0.4701\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1716 - val_accuracy: 0.4530\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8497 - accuracy: 0.5556 - val_loss: 1.1733 - val_accuracy: 0.4530\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8445 - accuracy: 0.5370 - val_loss: 1.1689 - val_accuracy: 0.4444\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8497 - accuracy: 0.5259 - val_loss: 1.1751 - val_accuracy: 0.4872\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1669 - val_accuracy: 0.4615\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8495 - accuracy: 0.4963 - val_loss: 1.1670 - val_accuracy: 0.4444\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8476 - accuracy: 0.5222 - val_loss: 1.1747 - val_accuracy: 0.4444\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.1641 - val_accuracy: 0.4530\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1635 - val_accuracy: 0.4444\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8459 - accuracy: 0.5407 - val_loss: 1.1619 - val_accuracy: 0.4444\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.1640 - val_accuracy: 0.4872\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1621 - val_accuracy: 0.4530\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8505 - accuracy: 0.5519 - val_loss: 1.1676 - val_accuracy: 0.4530\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8447 - accuracy: 0.5407 - val_loss: 1.1712 - val_accuracy: 0.4530\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8493 - accuracy: 0.5556 - val_loss: 1.1657 - val_accuracy: 0.4530\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.1607 - val_accuracy: 0.4615\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1656 - val_accuracy: 0.4872\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8452 - accuracy: 0.5370 - val_loss: 1.1661 - val_accuracy: 0.4786\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.1638 - val_accuracy: 0.4786\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8464 - accuracy: 0.5519 - val_loss: 1.1674 - val_accuracy: 0.4444\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1669 - val_accuracy: 0.4786\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8518 - accuracy: 0.5519 - val_loss: 1.1814 - val_accuracy: 0.4701\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.1847 - val_accuracy: 0.4530\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8461 - accuracy: 0.5407 - val_loss: 1.1846 - val_accuracy: 0.4701\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1902 - val_accuracy: 0.4701\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1891 - val_accuracy: 0.4701\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1772 - val_accuracy: 0.4701\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8467 - accuracy: 0.5037 - val_loss: 1.1737 - val_accuracy: 0.4701\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.1727 - val_accuracy: 0.4701\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1712 - val_accuracy: 0.4701\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8435 - accuracy: 0.5593 - val_loss: 1.1705 - val_accuracy: 0.4359\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8541 - accuracy: 0.5407 - val_loss: 1.1724 - val_accuracy: 0.4359\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8466 - accuracy: 0.5481 - val_loss: 1.1812 - val_accuracy: 0.4786\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8504 - accuracy: 0.5519 - val_loss: 1.1697 - val_accuracy: 0.4444\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 440us/step - loss: 0.8482 - accuracy: 0.5111 - val_loss: 1.1730 - val_accuracy: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1777 - val_accuracy: 0.4701\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.1760 - val_accuracy: 0.4701\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8520 - accuracy: 0.5037 - val_loss: 1.1698 - val_accuracy: 0.4615\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8491 - accuracy: 0.5481 - val_loss: 1.1751 - val_accuracy: 0.4701\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1694 - val_accuracy: 0.4701\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8488 - accuracy: 0.5333 - val_loss: 1.1732 - val_accuracy: 0.4359\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8463 - accuracy: 0.5444 - val_loss: 1.1762 - val_accuracy: 0.4701\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.1750 - val_accuracy: 0.4701\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1687 - val_accuracy: 0.4444\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1756 - val_accuracy: 0.4444\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1755 - val_accuracy: 0.4701\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1707 - val_accuracy: 0.4444\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8514 - accuracy: 0.5556 - val_loss: 1.1764 - val_accuracy: 0.4701\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8467 - accuracy: 0.5593 - val_loss: 1.1719 - val_accuracy: 0.4444\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8509 - accuracy: 0.5185 - val_loss: 1.1711 - val_accuracy: 0.4530\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8516 - accuracy: 0.5519 - val_loss: 1.1673 - val_accuracy: 0.4786\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8461 - accuracy: 0.5481 - val_loss: 1.1611 - val_accuracy: 0.4701\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.1690 - val_accuracy: 0.4444\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.1758 - val_accuracy: 0.4701\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1788 - val_accuracy: 0.4701\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1701 - val_accuracy: 0.4701\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8451 - accuracy: 0.5222 - val_loss: 1.1703 - val_accuracy: 0.4615\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8451 - accuracy: 0.5185 - val_loss: 1.1732 - val_accuracy: 0.4701\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1801 - val_accuracy: 0.4786\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.1802 - val_accuracy: 0.4530\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8436 - accuracy: 0.5222 - val_loss: 1.1828 - val_accuracy: 0.4701\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1821 - val_accuracy: 0.4701\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.1666 - val_accuracy: 0.4444\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.1664 - val_accuracy: 0.4444\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.1611 - val_accuracy: 0.4701\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 428us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.1601 - val_accuracy: 0.4444\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1644 - val_accuracy: 0.4701\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8475 - accuracy: 0.5222 - val_loss: 1.1614 - val_accuracy: 0.4444\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 403us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1645 - val_accuracy: 0.4444\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.1647 - val_accuracy: 0.4444\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 481us/step - loss: 0.8472 - accuracy: 0.5556 - val_loss: 1.1676 - val_accuracy: 0.4530\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.1678 - val_accuracy: 0.4786\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8431 - accuracy: 0.5593 - val_loss: 1.1687 - val_accuracy: 0.4530\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 256us/step - loss: 0.8458 - accuracy: 0.5296 - val_loss: 1.1685 - val_accuracy: 0.4444\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8515 - accuracy: 0.5148 - val_loss: 1.1665 - val_accuracy: 0.4615\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.8464 - accuracy: 0.5296 - val_loss: 1.1574 - val_accuracy: 0.4444\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8456 - accuracy: 0.5407 - val_loss: 1.1579 - val_accuracy: 0.4530\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1619 - val_accuracy: 0.4444\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8462 - accuracy: 0.5444 - val_loss: 1.1551 - val_accuracy: 0.4786\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8465 - accuracy: 0.5481 - val_loss: 1.1618 - val_accuracy: 0.4786\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8483 - accuracy: 0.5556 - val_loss: 1.1603 - val_accuracy: 0.4701\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1623 - val_accuracy: 0.4444\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1613 - val_accuracy: 0.4444\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8465 - accuracy: 0.5407 - val_loss: 1.1650 - val_accuracy: 0.4786\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8528 - accuracy: 0.5556 - val_loss: 1.1677 - val_accuracy: 0.4530\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8480 - accuracy: 0.5259 - val_loss: 1.1648 - val_accuracy: 0.4786\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1654 - val_accuracy: 0.4786\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.1628 - val_accuracy: 0.4530\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.1599 - val_accuracy: 0.4786\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8475 - accuracy: 0.5556 - val_loss: 1.1612 - val_accuracy: 0.4701\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.1629 - val_accuracy: 0.4701\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.8467 - accuracy: 0.5111 - val_loss: 1.1657 - val_accuracy: 0.4701\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.1731 - val_accuracy: 0.4444\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.8456 - accuracy: 0.5222 - val_loss: 1.1732 - val_accuracy: 0.4359\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8492 - accuracy: 0.5259 - val_loss: 1.1753 - val_accuracy: 0.4786\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8496 - accuracy: 0.5556 - val_loss: 1.1810 - val_accuracy: 0.4444\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8467 - accuracy: 0.5444 - val_loss: 1.1711 - val_accuracy: 0.4444\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1725 - val_accuracy: 0.4786\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8458 - accuracy: 0.5593 - val_loss: 1.1742 - val_accuracy: 0.4786\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.1794 - val_accuracy: 0.4444\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8419 - accuracy: 0.5519 - val_loss: 1.1722 - val_accuracy: 0.4786\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.1714 - val_accuracy: 0.4444\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8461 - accuracy: 0.5333 - val_loss: 1.1729 - val_accuracy: 0.4444\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1773 - val_accuracy: 0.4530\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8457 - accuracy: 0.5593 - val_loss: 1.1746 - val_accuracy: 0.4701\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.1706 - val_accuracy: 0.4701\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1691 - val_accuracy: 0.4701\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8453 - accuracy: 0.5148 - val_loss: 1.1692 - val_accuracy: 0.4701\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1736 - val_accuracy: 0.4701\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8455 - accuracy: 0.5222 - val_loss: 1.1770 - val_accuracy: 0.4701\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8459 - accuracy: 0.5148 - val_loss: 1.1774 - val_accuracy: 0.4701\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.1903 - val_accuracy: 0.4701\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.1797 - val_accuracy: 0.4444\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8473 - accuracy: 0.5407 - val_loss: 1.1756 - val_accuracy: 0.4444\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8443 - accuracy: 0.5481 - val_loss: 1.1761 - val_accuracy: 0.4701\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1822 - val_accuracy: 0.4786\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1764 - val_accuracy: 0.4444\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8448 - accuracy: 0.5407 - val_loss: 1.1760 - val_accuracy: 0.4444\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8474 - accuracy: 0.5556 - val_loss: 1.1861 - val_accuracy: 0.4701\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1856 - val_accuracy: 0.4444\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.1841 - val_accuracy: 0.4701\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8431 - accuracy: 0.5333 - val_loss: 1.1812 - val_accuracy: 0.4359\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 432us/step - loss: 0.8442 - accuracy: 0.5407 - val_loss: 1.1819 - val_accuracy: 0.4786\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1797 - val_accuracy: 0.4786\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.1810 - val_accuracy: 0.4530\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8453 - accuracy: 0.5519 - val_loss: 1.1881 - val_accuracy: 0.4872\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1844 - val_accuracy: 0.4786\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1761 - val_accuracy: 0.4786\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8439 - accuracy: 0.5111 - val_loss: 1.1767 - val_accuracy: 0.4530\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8529 - accuracy: 0.5556 - val_loss: 1.1771 - val_accuracy: 0.4786\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8469 - accuracy: 0.5407 - val_loss: 1.1751 - val_accuracy: 0.4444\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.1770 - val_accuracy: 0.4701\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1834 - val_accuracy: 0.4701\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.8457 - accuracy: 0.5333 - val_loss: 1.1827 - val_accuracy: 0.4701\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 333us/step - loss: 0.8544 - accuracy: 0.5148 - val_loss: 1.1888 - val_accuracy: 0.4530\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 1.1927 - val_accuracy: 0.4786\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1931 - val_accuracy: 0.4786\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8487 - accuracy: 0.5222 - val_loss: 1.1939 - val_accuracy: 0.4530\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8466 - accuracy: 0.5222 - val_loss: 1.1932 - val_accuracy: 0.4530\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.2040 - val_accuracy: 0.4530\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.2010 - val_accuracy: 0.4786\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.1909 - val_accuracy: 0.4872\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.1898 - val_accuracy: 0.4530\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8485 - accuracy: 0.5185 - val_loss: 1.1825 - val_accuracy: 0.4444\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8504 - accuracy: 0.5370 - val_loss: 1.1903 - val_accuracy: 0.4530\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 137us/step - loss: 0.8433 - accuracy: 0.5519 - val_loss: 1.1815 - val_accuracy: 0.4530\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1830 - val_accuracy: 0.4530\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8464 - accuracy: 0.5370 - val_loss: 1.1827 - val_accuracy: 0.4444\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1876 - val_accuracy: 0.4530\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.1928 - val_accuracy: 0.4530\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.1934 - val_accuracy: 0.4530\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1882 - val_accuracy: 0.4444\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8460 - accuracy: 0.5333 - val_loss: 1.1744 - val_accuracy: 0.4359\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8463 - accuracy: 0.5296 - val_loss: 1.1732 - val_accuracy: 0.4444\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1742 - val_accuracy: 0.4530\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8472 - accuracy: 0.5222 - val_loss: 1.1759 - val_accuracy: 0.4530\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1806 - val_accuracy: 0.4530\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.1876 - val_accuracy: 0.4444\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.1791 - val_accuracy: 0.4444\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8449 - accuracy: 0.5481 - val_loss: 1.1822 - val_accuracy: 0.4530\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1742 - val_accuracy: 0.4444\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8447 - accuracy: 0.5370 - val_loss: 1.1759 - val_accuracy: 0.4615\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1738 - val_accuracy: 0.4530\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8476 - accuracy: 0.5111 - val_loss: 1.1749 - val_accuracy: 0.4530\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1812 - val_accuracy: 0.4701\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8466 - accuracy: 0.5481 - val_loss: 1.1775 - val_accuracy: 0.4530\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8451 - accuracy: 0.5037 - val_loss: 1.1810 - val_accuracy: 0.4444\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8456 - accuracy: 0.5222 - val_loss: 1.1840 - val_accuracy: 0.4530\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8445 - accuracy: 0.5370 - val_loss: 1.1805 - val_accuracy: 0.4530\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8443 - accuracy: 0.5148 - val_loss: 1.1826 - val_accuracy: 0.4530\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1789 - val_accuracy: 0.4530\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1773 - val_accuracy: 0.4530\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.1777 - val_accuracy: 0.4530\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1805 - val_accuracy: 0.4530\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8479 - accuracy: 0.5222 - val_loss: 1.1805 - val_accuracy: 0.4530\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.8414 - accuracy: 0.5741 - val_loss: 1.1891 - val_accuracy: 0.4530\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8540 - accuracy: 0.5556 - val_loss: 1.1890 - val_accuracy: 0.4786\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8447 - accuracy: 0.5630 - val_loss: 1.1709 - val_accuracy: 0.4444\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8483 - accuracy: 0.5407 - val_loss: 1.1657 - val_accuracy: 0.4444\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8422 - accuracy: 0.5630 - val_loss: 1.1703 - val_accuracy: 0.4872\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.1782 - val_accuracy: 0.4615\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8450 - accuracy: 0.5148 - val_loss: 1.1753 - val_accuracy: 0.4444\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8474 - accuracy: 0.5407 - val_loss: 1.1787 - val_accuracy: 0.4786\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.1749 - val_accuracy: 0.4615\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1790 - val_accuracy: 0.4530\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1846 - val_accuracy: 0.4444\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.1848 - val_accuracy: 0.4444\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1883 - val_accuracy: 0.4444\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1887 - val_accuracy: 0.4530\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1857 - val_accuracy: 0.4530\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8468 - accuracy: 0.4963 - val_loss: 1.1838 - val_accuracy: 0.4530\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8440 - accuracy: 0.5185 - val_loss: 1.1830 - val_accuracy: 0.4615\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.1869 - val_accuracy: 0.4872\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8451 - accuracy: 0.5037 - val_loss: 1.1876 - val_accuracy: 0.4786\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1868 - val_accuracy: 0.4530\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.1860 - val_accuracy: 0.4872\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1870 - val_accuracy: 0.4872\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8494 - accuracy: 0.4963 - val_loss: 1.1827 - val_accuracy: 0.4701\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8484 - accuracy: 0.5333 - val_loss: 1.1915 - val_accuracy: 0.4872\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1848 - val_accuracy: 0.4786\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1854 - val_accuracy: 0.4872\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.1909 - val_accuracy: 0.4530\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8431 - accuracy: 0.5333 - val_loss: 1.1863 - val_accuracy: 0.4701\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.1932 - val_accuracy: 0.4786\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8477 - accuracy: 0.5519 - val_loss: 1.2020 - val_accuracy: 0.4530\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.1987 - val_accuracy: 0.4786\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1965 - val_accuracy: 0.4444\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8456 - accuracy: 0.5296 - val_loss: 1.2007 - val_accuracy: 0.4444\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8466 - accuracy: 0.5593 - val_loss: 1.2080 - val_accuracy: 0.4786\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8530 - accuracy: 0.5556 - val_loss: 1.2146 - val_accuracy: 0.4701\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8449 - accuracy: 0.5630 - val_loss: 1.2036 - val_accuracy: 0.4701\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8482 - accuracy: 0.5407 - val_loss: 1.2039 - val_accuracy: 0.4701\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8468 - accuracy: 0.5333 - val_loss: 1.2106 - val_accuracy: 0.4701\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8489 - accuracy: 0.5519 - val_loss: 1.2064 - val_accuracy: 0.4530\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8451 - accuracy: 0.5407 - val_loss: 1.1996 - val_accuracy: 0.4701\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.1895 - val_accuracy: 0.4701\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1886 - val_accuracy: 0.4444\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1901 - val_accuracy: 0.4701\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 1.1861 - val_accuracy: 0.4530\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8461 - accuracy: 0.5481 - val_loss: 1.1860 - val_accuracy: 0.4701\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8447 - accuracy: 0.5407 - val_loss: 1.1861 - val_accuracy: 0.4359\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8545 - accuracy: 0.5148 - val_loss: 1.1943 - val_accuracy: 0.4530\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8464 - accuracy: 0.5185 - val_loss: 1.1927 - val_accuracy: 0.4701\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.1968 - val_accuracy: 0.4701\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1912 - val_accuracy: 0.4701\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 304us/step - loss: 0.8516 - accuracy: 0.5407 - val_loss: 1.1897 - val_accuracy: 0.4444\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.8442 - accuracy: 0.5407 - val_loss: 1.1921 - val_accuracy: 0.4701\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8508 - accuracy: 0.5556 - val_loss: 1.1924 - val_accuracy: 0.4872\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 507us/step - loss: 0.8480 - accuracy: 0.5222 - val_loss: 1.1927 - val_accuracy: 0.4444\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8448 - accuracy: 0.5259 - val_loss: 1.1926 - val_accuracy: 0.4530\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.2016 - val_accuracy: 0.4786\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.1972 - val_accuracy: 0.4530\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 321us/step - loss: 0.8426 - accuracy: 0.5519 - val_loss: 1.1944 - val_accuracy: 0.4701\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8481 - accuracy: 0.5074 - val_loss: 1.1907 - val_accuracy: 0.4701\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8481 - accuracy: 0.5222 - val_loss: 1.1952 - val_accuracy: 0.4530\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8476 - accuracy: 0.5519 - val_loss: 1.1901 - val_accuracy: 0.4701\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1933 - val_accuracy: 0.4786\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1891 - val_accuracy: 0.4530\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.1913 - val_accuracy: 0.4701\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8443 - accuracy: 0.5481 - val_loss: 1.1882 - val_accuracy: 0.4444\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8438 - accuracy: 0.5370 - val_loss: 1.1930 - val_accuracy: 0.4786\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.2015 - val_accuracy: 0.4786\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8511 - accuracy: 0.5222 - val_loss: 1.2006 - val_accuracy: 0.4786\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8543 - accuracy: 0.5259 - val_loss: 1.1973 - val_accuracy: 0.4530\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8455 - accuracy: 0.5593 - val_loss: 1.1945 - val_accuracy: 0.4786\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1976 - val_accuracy: 0.4786\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.2057 - val_accuracy: 0.4786\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.2012 - val_accuracy: 0.4701\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8470 - accuracy: 0.5407 - val_loss: 1.1995 - val_accuracy: 0.4786\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.2074 - val_accuracy: 0.4786\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.2083 - val_accuracy: 0.4786\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8503 - accuracy: 0.5333 - val_loss: 1.2058 - val_accuracy: 0.4701\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8482 - accuracy: 0.5259 - val_loss: 1.2089 - val_accuracy: 0.4530\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8485 - accuracy: 0.5593 - val_loss: 1.2111 - val_accuracy: 0.4701\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8458 - accuracy: 0.5296 - val_loss: 1.1973 - val_accuracy: 0.4444\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 91us/step - loss: 0.8478 - accuracy: 0.5407 - val_loss: 1.1994 - val_accuracy: 0.4530\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.2020 - val_accuracy: 0.4444\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.2026 - val_accuracy: 0.4786\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1992 - val_accuracy: 0.4530\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8457 - accuracy: 0.5111 - val_loss: 1.1972 - val_accuracy: 0.4444\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8466 - accuracy: 0.5296 - val_loss: 1.2045 - val_accuracy: 0.4530\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.2128 - val_accuracy: 0.4530\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8474 - accuracy: 0.5444 - val_loss: 1.2017 - val_accuracy: 0.4444\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.2111 - val_accuracy: 0.4786\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8477 - accuracy: 0.5556 - val_loss: 1.2167 - val_accuracy: 0.4530\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8450 - accuracy: 0.5259 - val_loss: 1.2052 - val_accuracy: 0.4444\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8432 - accuracy: 0.5444 - val_loss: 1.2102 - val_accuracy: 0.4444\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.2101 - val_accuracy: 0.4701\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8442 - accuracy: 0.5481 - val_loss: 1.2082 - val_accuracy: 0.4530\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.2156 - val_accuracy: 0.4530\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.2244 - val_accuracy: 0.4701\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8465 - accuracy: 0.5333 - val_loss: 1.2170 - val_accuracy: 0.4359\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8456 - accuracy: 0.5370 - val_loss: 1.2094 - val_accuracy: 0.4701\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1895 - val_accuracy: 0.4530\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8460 - accuracy: 0.5296 - val_loss: 1.1850 - val_accuracy: 0.4615\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8453 - accuracy: 0.5222 - val_loss: 1.1858 - val_accuracy: 0.4444\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8452 - accuracy: 0.5481 - val_loss: 1.1820 - val_accuracy: 0.4444\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1814 - val_accuracy: 0.4530\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1875 - val_accuracy: 0.4444\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8448 - accuracy: 0.5593 - val_loss: 1.1876 - val_accuracy: 0.4701\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8434 - accuracy: 0.5593 - val_loss: 1.1806 - val_accuracy: 0.4701\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8495 - accuracy: 0.5556 - val_loss: 1.1857 - val_accuracy: 0.4701\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8426 - accuracy: 0.5259 - val_loss: 1.1852 - val_accuracy: 0.4359\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8476 - accuracy: 0.5407 - val_loss: 1.1858 - val_accuracy: 0.4530\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8486 - accuracy: 0.5519 - val_loss: 1.1864 - val_accuracy: 0.4701\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1820 - val_accuracy: 0.4786\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8461 - accuracy: 0.5296 - val_loss: 1.1830 - val_accuracy: 0.4444\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8445 - accuracy: 0.5407 - val_loss: 1.1848 - val_accuracy: 0.4444\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8445 - accuracy: 0.5630 - val_loss: 1.1938 - val_accuracy: 0.4786\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1878 - val_accuracy: 0.4701\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.1885 - val_accuracy: 0.4786\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1952 - val_accuracy: 0.4786\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8541 - accuracy: 0.4815 - val_loss: 1.1876 - val_accuracy: 0.4444\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8502 - accuracy: 0.5370 - val_loss: 1.1916 - val_accuracy: 0.4786\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.1811 - val_accuracy: 0.4872\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8444 - accuracy: 0.5370 - val_loss: 1.1806 - val_accuracy: 0.4530\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.8479 - accuracy: 0.5444 - val_loss: 1.1831 - val_accuracy: 0.4530\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1874 - val_accuracy: 0.4786\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1871 - val_accuracy: 0.4786\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8443 - accuracy: 0.5481 - val_loss: 1.1879 - val_accuracy: 0.4530\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 365us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1878 - val_accuracy: 0.4530\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.1854 - val_accuracy: 0.4786\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.1865 - val_accuracy: 0.4786\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8468 - accuracy: 0.5519 - val_loss: 1.1916 - val_accuracy: 0.4786\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1945 - val_accuracy: 0.4701\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8489 - accuracy: 0.5407 - val_loss: 1.1868 - val_accuracy: 0.4701\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.1948 - val_accuracy: 0.4786\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.1956 - val_accuracy: 0.4786\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.1998 - val_accuracy: 0.4530\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8439 - accuracy: 0.5444 - val_loss: 1.1915 - val_accuracy: 0.4615\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8457 - accuracy: 0.5296 - val_loss: 1.1995 - val_accuracy: 0.4786\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1920 - val_accuracy: 0.4701\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8457 - accuracy: 0.5704 - val_loss: 1.1984 - val_accuracy: 0.4786\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.2067 - val_accuracy: 0.4530\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8468 - accuracy: 0.5222 - val_loss: 1.2017 - val_accuracy: 0.4359\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8430 - accuracy: 0.5333 - val_loss: 1.2035 - val_accuracy: 0.4444\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.2052 - val_accuracy: 0.4701\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.1964 - val_accuracy: 0.4786\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1986 - val_accuracy: 0.4701\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8471 - accuracy: 0.5593 - val_loss: 1.2023 - val_accuracy: 0.4701\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.2088 - val_accuracy: 0.4530\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8463 - accuracy: 0.5630 - val_loss: 1.2060 - val_accuracy: 0.4786\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8448 - accuracy: 0.5185 - val_loss: 1.2067 - val_accuracy: 0.4444\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8431 - accuracy: 0.5333 - val_loss: 1.2075 - val_accuracy: 0.4530\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.2022 - val_accuracy: 0.4530\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8436 - accuracy: 0.5593 - val_loss: 1.2001 - val_accuracy: 0.4786\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8488 - accuracy: 0.5333 - val_loss: 1.1944 - val_accuracy: 0.4786\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8456 - accuracy: 0.5259 - val_loss: 1.2021 - val_accuracy: 0.4530\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1995 - val_accuracy: 0.4786\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.1865 - val_accuracy: 0.4615\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8483 - accuracy: 0.5370 - val_loss: 1.1820 - val_accuracy: 0.4444\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8449 - accuracy: 0.5667 - val_loss: 1.1774 - val_accuracy: 0.4615\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.1786 - val_accuracy: 0.4615\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1788 - val_accuracy: 0.4530\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1794 - val_accuracy: 0.4615\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8479 - accuracy: 0.5556 - val_loss: 1.2028 - val_accuracy: 0.4530\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1768 - val_accuracy: 0.4615\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8448 - accuracy: 0.5593 - val_loss: 1.1738 - val_accuracy: 0.4872\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8479 - accuracy: 0.5370 - val_loss: 1.1736 - val_accuracy: 0.4615\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8503 - accuracy: 0.5222 - val_loss: 1.1729 - val_accuracy: 0.4530\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1732 - val_accuracy: 0.4786\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1614 - val_accuracy: 0.4786\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.1601 - val_accuracy: 0.4786\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.1675 - val_accuracy: 0.4444\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.1902 - val_accuracy: 0.4701\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1887 - val_accuracy: 0.4701\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8479 - accuracy: 0.5519 - val_loss: 1.1868 - val_accuracy: 0.4444\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8451 - accuracy: 0.5370 - val_loss: 1.1783 - val_accuracy: 0.4701\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8446 - accuracy: 0.5333 - val_loss: 1.1752 - val_accuracy: 0.4786\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 1.1771 - val_accuracy: 0.4786\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1807 - val_accuracy: 0.4444\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.1868 - val_accuracy: 0.4786\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.1818 - val_accuracy: 0.4530\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8464 - accuracy: 0.5370 - val_loss: 1.1763 - val_accuracy: 0.4444\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8444 - accuracy: 0.5519 - val_loss: 1.1861 - val_accuracy: 0.4786\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1928 - val_accuracy: 0.4786\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8463 - accuracy: 0.5556 - val_loss: 1.1896 - val_accuracy: 0.4530\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.1824 - val_accuracy: 0.4615\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1879 - val_accuracy: 0.4786\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1859 - val_accuracy: 0.4786\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1859 - val_accuracy: 0.4530\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8461 - accuracy: 0.5519 - val_loss: 1.1826 - val_accuracy: 0.4530\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.1861 - val_accuracy: 0.4444\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8478 - accuracy: 0.5593 - val_loss: 1.1990 - val_accuracy: 0.4786\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8462 - accuracy: 0.5593 - val_loss: 1.1958 - val_accuracy: 0.4530\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 127us/step - loss: 0.8482 - accuracy: 0.5593 - val_loss: 1.1978 - val_accuracy: 0.4701\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8473 - accuracy: 0.5407 - val_loss: 1.1910 - val_accuracy: 0.4444\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.1969 - val_accuracy: 0.4530\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.2041 - val_accuracy: 0.4786\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1931 - val_accuracy: 0.4701\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8449 - accuracy: 0.5630 - val_loss: 1.1884 - val_accuracy: 0.4530\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8463 - accuracy: 0.5222 - val_loss: 1.1852 - val_accuracy: 0.4359\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1911 - val_accuracy: 0.4786\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.2090 - val_accuracy: 0.4786\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8454 - accuracy: 0.5481 - val_loss: 1.2075 - val_accuracy: 0.4530\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8483 - accuracy: 0.5407 - val_loss: 1.2081 - val_accuracy: 0.4615\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8464 - accuracy: 0.5593 - val_loss: 1.2002 - val_accuracy: 0.4530\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1971 - val_accuracy: 0.4530\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.2006 - val_accuracy: 0.4530\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8494 - accuracy: 0.5593 - val_loss: 1.1952 - val_accuracy: 0.4530\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.1978 - val_accuracy: 0.4530\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8481 - accuracy: 0.5185 - val_loss: 1.2003 - val_accuracy: 0.4359\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8445 - accuracy: 0.5407 - val_loss: 1.2090 - val_accuracy: 0.4530\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.2057 - val_accuracy: 0.4786\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.2009 - val_accuracy: 0.4444\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8465 - accuracy: 0.5185 - val_loss: 1.2032 - val_accuracy: 0.4359\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8474 - accuracy: 0.5667 - val_loss: 1.2128 - val_accuracy: 0.4701\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.2020 - val_accuracy: 0.4444\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8508 - accuracy: 0.5148 - val_loss: 1.2030 - val_accuracy: 0.4444\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8444 - accuracy: 0.5333 - val_loss: 1.1989 - val_accuracy: 0.4530\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.2049 - val_accuracy: 0.4786\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.2050 - val_accuracy: 0.4530\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.2138 - val_accuracy: 0.4444\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8465 - accuracy: 0.5148 - val_loss: 1.2096 - val_accuracy: 0.4359\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8455 - accuracy: 0.5407 - val_loss: 1.2156 - val_accuracy: 0.4701\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8494 - accuracy: 0.5519 - val_loss: 1.2181 - val_accuracy: 0.4701\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8423 - accuracy: 0.5593 - val_loss: 1.1954 - val_accuracy: 0.4444\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8497 - accuracy: 0.5148 - val_loss: 1.1881 - val_accuracy: 0.4530\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8436 - accuracy: 0.5370 - val_loss: 1.1748 - val_accuracy: 0.4444\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.1817 - val_accuracy: 0.4786\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8451 - accuracy: 0.5593 - val_loss: 1.1865 - val_accuracy: 0.4786\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1781 - val_accuracy: 0.4530\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8465 - accuracy: 0.5185 - val_loss: 1.1759 - val_accuracy: 0.4530\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8442 - accuracy: 0.5630 - val_loss: 1.1777 - val_accuracy: 0.4530\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1829 - val_accuracy: 0.4530\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1752 - val_accuracy: 0.4701\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1853 - val_accuracy: 0.4701\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8446 - accuracy: 0.5519 - val_loss: 1.1884 - val_accuracy: 0.4701\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1874 - val_accuracy: 0.4530\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8502 - accuracy: 0.5444 - val_loss: 1.1703 - val_accuracy: 0.4444\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8454 - accuracy: 0.5444 - val_loss: 1.1776 - val_accuracy: 0.4530\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1812 - val_accuracy: 0.4530\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8430 - accuracy: 0.5630 - val_loss: 1.1876 - val_accuracy: 0.4444\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8476 - accuracy: 0.5407 - val_loss: 1.1847 - val_accuracy: 0.4530\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8449 - accuracy: 0.5407 - val_loss: 1.1819 - val_accuracy: 0.4444\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8501 - accuracy: 0.5296 - val_loss: 1.1915 - val_accuracy: 0.4530\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.1851 - val_accuracy: 0.4786\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8487 - accuracy: 0.5556 - val_loss: 1.1857 - val_accuracy: 0.4786\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.1923 - val_accuracy: 0.4530\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8476 - accuracy: 0.5556 - val_loss: 1.1847 - val_accuracy: 0.4530\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.1815 - val_accuracy: 0.4530\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1757 - val_accuracy: 0.4530\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.1747 - val_accuracy: 0.4359\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.1749 - val_accuracy: 0.4444\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1886 - val_accuracy: 0.4530\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1897 - val_accuracy: 0.4444\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.1903 - val_accuracy: 0.4444\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8435 - accuracy: 0.5296 - val_loss: 1.1897 - val_accuracy: 0.4359\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.65 - 0s 101us/step - loss: 0.8484 - accuracy: 0.5407 - val_loss: 1.1904 - val_accuracy: 0.4359\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8450 - accuracy: 0.5222 - val_loss: 1.1985 - val_accuracy: 0.4444\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.2019 - val_accuracy: 0.4530\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1916 - val_accuracy: 0.4786\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1819 - val_accuracy: 0.4530\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8447 - accuracy: 0.5407 - val_loss: 1.1806 - val_accuracy: 0.4701\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8469 - accuracy: 0.5519 - val_loss: 1.1884 - val_accuracy: 0.4530\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1898 - val_accuracy: 0.4530\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8446 - accuracy: 0.5333 - val_loss: 1.1857 - val_accuracy: 0.4615\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8461 - accuracy: 0.5111 - val_loss: 1.1873 - val_accuracy: 0.4444\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1940 - val_accuracy: 0.4530\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1952 - val_accuracy: 0.4530\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8481 - accuracy: 0.5519 - val_loss: 1.1932 - val_accuracy: 0.4530\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8471 - accuracy: 0.5556 - val_loss: 1.1906 - val_accuracy: 0.4530\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 410us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1887 - val_accuracy: 0.4444\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 616us/step - loss: 0.8454 - accuracy: 0.5593 - val_loss: 1.1890 - val_accuracy: 0.4701\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1876 - val_accuracy: 0.4530\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.1851 - val_accuracy: 0.4701\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.1816 - val_accuracy: 0.4530\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1761 - val_accuracy: 0.4530\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8454 - accuracy: 0.5407 - val_loss: 1.1858 - val_accuracy: 0.4530\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.1963 - val_accuracy: 0.4615\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8432 - accuracy: 0.5222 - val_loss: 1.1970 - val_accuracy: 0.4444\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8480 - accuracy: 0.4889 - val_loss: 1.1976 - val_accuracy: 0.4615\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.2031 - val_accuracy: 0.4530\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.2005 - val_accuracy: 0.4530\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8455 - accuracy: 0.5370 - val_loss: 1.1935 - val_accuracy: 0.4701\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8448 - accuracy: 0.5370 - val_loss: 1.1907 - val_accuracy: 0.4530\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8430 - accuracy: 0.5333 - val_loss: 1.1968 - val_accuracy: 0.4530\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8465 - accuracy: 0.5259 - val_loss: 1.1957 - val_accuracy: 0.4444\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8484 - accuracy: 0.5481 - val_loss: 1.1968 - val_accuracy: 0.4530\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.1987 - val_accuracy: 0.4701\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.2011 - val_accuracy: 0.4786\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8414 - accuracy: 0.5556 - val_loss: 1.2053 - val_accuracy: 0.4530\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8444 - accuracy: 0.5333 - val_loss: 1.2029 - val_accuracy: 0.4530\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.2084 - val_accuracy: 0.4786\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.2096 - val_accuracy: 0.4786\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.2132 - val_accuracy: 0.4530\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.2147 - val_accuracy: 0.4530\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.2152 - val_accuracy: 0.4530\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8451 - accuracy: 0.5370 - val_loss: 1.2147 - val_accuracy: 0.4786\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.2175 - val_accuracy: 0.4530\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8454 - accuracy: 0.5519 - val_loss: 1.2197 - val_accuracy: 0.4530\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.2140 - val_accuracy: 0.4530\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.2152 - val_accuracy: 0.4530\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8454 - accuracy: 0.5556 - val_loss: 1.2170 - val_accuracy: 0.4786\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8466 - accuracy: 0.5333 - val_loss: 1.2101 - val_accuracy: 0.4444\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 118us/step - loss: 0.8461 - accuracy: 0.5185 - val_loss: 1.2157 - val_accuracy: 0.4786\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.2131 - val_accuracy: 0.4530\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.2132 - val_accuracy: 0.4444\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8434 - accuracy: 0.5407 - val_loss: 1.2138 - val_accuracy: 0.4444\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.2077 - val_accuracy: 0.4615\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8447 - accuracy: 0.5519 - val_loss: 1.2184 - val_accuracy: 0.4530\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8453 - accuracy: 0.5296 - val_loss: 1.2274 - val_accuracy: 0.4444\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8439 - accuracy: 0.5407 - val_loss: 1.2341 - val_accuracy: 0.4444\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8447 - accuracy: 0.5444 - val_loss: 1.2424 - val_accuracy: 0.4530\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.2372 - val_accuracy: 0.4530\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8456 - accuracy: 0.5519 - val_loss: 1.2027 - val_accuracy: 0.4530\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.1883 - val_accuracy: 0.4530\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8460 - accuracy: 0.5444 - val_loss: 1.1838 - val_accuracy: 0.4786\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8461 - accuracy: 0.5444 - val_loss: 1.1749 - val_accuracy: 0.4615\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1580 - val_accuracy: 0.4872\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8439 - accuracy: 0.5593 - val_loss: 1.1490 - val_accuracy: 0.4444\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8454 - accuracy: 0.5370 - val_loss: 1.1516 - val_accuracy: 0.4444\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8454 - accuracy: 0.5407 - val_loss: 1.1500 - val_accuracy: 0.4530\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1569 - val_accuracy: 0.4530\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8424 - accuracy: 0.5556 - val_loss: 1.1573 - val_accuracy: 0.4530\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1630 - val_accuracy: 0.4530\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1601 - val_accuracy: 0.4530\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.1705 - val_accuracy: 0.4786\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8427 - accuracy: 0.5519 - val_loss: 1.1697 - val_accuracy: 0.4530\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1677 - val_accuracy: 0.4530\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8485 - accuracy: 0.5556 - val_loss: 1.1659 - val_accuracy: 0.4701\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.1684 - val_accuracy: 0.4530\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1710 - val_accuracy: 0.4530\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 1.1688 - val_accuracy: 0.4786\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.1751 - val_accuracy: 0.4786\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1693 - val_accuracy: 0.4530\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.1693 - val_accuracy: 0.4701\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.4530\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1733 - val_accuracy: 0.4530\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1767 - val_accuracy: 0.4530\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1814 - val_accuracy: 0.4530\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8492 - accuracy: 0.5185 - val_loss: 1.1744 - val_accuracy: 0.4701\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8455 - accuracy: 0.5407 - val_loss: 1.1753 - val_accuracy: 0.4530\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1737 - val_accuracy: 0.4444\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1692 - val_accuracy: 0.4530\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8475 - accuracy: 0.5519 - val_loss: 1.1739 - val_accuracy: 0.4701\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1779 - val_accuracy: 0.4444\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8450 - accuracy: 0.5481 - val_loss: 1.1763 - val_accuracy: 0.4530\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1788 - val_accuracy: 0.4530\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8441 - accuracy: 0.5593 - val_loss: 1.1808 - val_accuracy: 0.4701\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.1763 - val_accuracy: 0.4530\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1706 - val_accuracy: 0.4786\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8528 - accuracy: 0.5593 - val_loss: 1.1657 - val_accuracy: 0.4786\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1714 - val_accuracy: 0.4786\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.1734 - val_accuracy: 0.4530\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1758 - val_accuracy: 0.4786\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.1819 - val_accuracy: 0.4530\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1812 - val_accuracy: 0.4530\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8439 - accuracy: 0.5593 - val_loss: 1.1720 - val_accuracy: 0.4701\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8443 - accuracy: 0.5296 - val_loss: 1.1751 - val_accuracy: 0.4444\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.1874 - val_accuracy: 0.4530\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1793 - val_accuracy: 0.4701\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1800 - val_accuracy: 0.4786\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8469 - accuracy: 0.5556 - val_loss: 1.1810 - val_accuracy: 0.4530\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8467 - accuracy: 0.5519 - val_loss: 1.1756 - val_accuracy: 0.4530\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8435 - accuracy: 0.5481 - val_loss: 1.1758 - val_accuracy: 0.4786\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1774 - val_accuracy: 0.4701\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8441 - accuracy: 0.5370 - val_loss: 1.1803 - val_accuracy: 0.4530\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.1853 - val_accuracy: 0.4444\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1845 - val_accuracy: 0.4444\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1847 - val_accuracy: 0.4444\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1858 - val_accuracy: 0.4444\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.1772 - val_accuracy: 0.4530\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8452 - accuracy: 0.4741 - val_loss: 1.1783 - val_accuracy: 0.4530\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.1776 - val_accuracy: 0.4444\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1796 - val_accuracy: 0.4530\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.1734 - val_accuracy: 0.4786\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8450 - accuracy: 0.5519 - val_loss: 1.1773 - val_accuracy: 0.4786\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8487 - accuracy: 0.5037 - val_loss: 1.1746 - val_accuracy: 0.4530\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8424 - accuracy: 0.5481 - val_loss: 1.1815 - val_accuracy: 0.4530\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1823 - val_accuracy: 0.4530\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.1837 - val_accuracy: 0.4872\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8432 - accuracy: 0.5185 - val_loss: 1.1859 - val_accuracy: 0.4786\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8453 - accuracy: 0.5259 - val_loss: 1.1874 - val_accuracy: 0.4530\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8422 - accuracy: 0.5481 - val_loss: 1.1814 - val_accuracy: 0.4786\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1792 - val_accuracy: 0.4530\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1800 - val_accuracy: 0.4530\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8442 - accuracy: 0.5333 - val_loss: 1.1791 - val_accuracy: 0.4444\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8448 - accuracy: 0.5444 - val_loss: 1.1829 - val_accuracy: 0.4530\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8448 - accuracy: 0.5630 - val_loss: 1.1843 - val_accuracy: 0.4530\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8493 - accuracy: 0.5593 - val_loss: 1.1858 - val_accuracy: 0.4530\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8499 - accuracy: 0.5556 - val_loss: 1.2003 - val_accuracy: 0.4530\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1881 - val_accuracy: 0.4530\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8450 - accuracy: 0.5481 - val_loss: 1.1893 - val_accuracy: 0.4530\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1798 - val_accuracy: 0.4530\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1784 - val_accuracy: 0.4530\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8447 - accuracy: 0.5593 - val_loss: 1.1762 - val_accuracy: 0.4786\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.1788 - val_accuracy: 0.4530\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.1803 - val_accuracy: 0.4615\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.1850 - val_accuracy: 0.4530\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1923 - val_accuracy: 0.4530\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8439 - accuracy: 0.5593 - val_loss: 1.1908 - val_accuracy: 0.4786\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.1890 - val_accuracy: 0.4530\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8430 - accuracy: 0.5481 - val_loss: 1.1920 - val_accuracy: 0.4530\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8482 - accuracy: 0.5407 - val_loss: 1.1954 - val_accuracy: 0.4444\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8464 - accuracy: 0.5333 - val_loss: 1.1933 - val_accuracy: 0.4786\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1922 - val_accuracy: 0.4786\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1889 - val_accuracy: 0.4530\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8454 - accuracy: 0.5593 - val_loss: 1.1772 - val_accuracy: 0.4872\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1891 - val_accuracy: 0.4872\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.1914 - val_accuracy: 0.4786\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.1876 - val_accuracy: 0.4530\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.1877 - val_accuracy: 0.4615\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8451 - accuracy: 0.5296 - val_loss: 1.1910 - val_accuracy: 0.4701\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8447 - accuracy: 0.5259 - val_loss: 1.1897 - val_accuracy: 0.4872\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 188us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.2028 - val_accuracy: 0.4786\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1995 - val_accuracy: 0.4786\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8426 - accuracy: 0.5593 - val_loss: 1.1917 - val_accuracy: 0.4530\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8488 - accuracy: 0.5259 - val_loss: 1.1940 - val_accuracy: 0.4701\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8441 - accuracy: 0.5444 - val_loss: 1.1892 - val_accuracy: 0.4786\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1903 - val_accuracy: 0.4786\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.2003 - val_accuracy: 0.4530\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8434 - accuracy: 0.5519 - val_loss: 1.1933 - val_accuracy: 0.4786\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8448 - accuracy: 0.5296 - val_loss: 1.1973 - val_accuracy: 0.4444\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8492 - accuracy: 0.5222 - val_loss: 1.2051 - val_accuracy: 0.4872\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8441 - accuracy: 0.5481 - val_loss: 1.1975 - val_accuracy: 0.4530\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1849 - val_accuracy: 0.4530\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8433 - accuracy: 0.5444 - val_loss: 1.1883 - val_accuracy: 0.4444\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8441 - accuracy: 0.5259 - val_loss: 1.1957 - val_accuracy: 0.4786\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8418 - accuracy: 0.5556 - val_loss: 1.2040 - val_accuracy: 0.4786\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1923 - val_accuracy: 0.4786\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1945 - val_accuracy: 0.4530\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8441 - accuracy: 0.5111 - val_loss: 1.2029 - val_accuracy: 0.4530\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8424 - accuracy: 0.5556 - val_loss: 1.2022 - val_accuracy: 0.4872\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.2035 - val_accuracy: 0.4872\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8440 - accuracy: 0.5222 - val_loss: 1.2034 - val_accuracy: 0.4615\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.2012 - val_accuracy: 0.4530\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1885 - val_accuracy: 0.4530\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1895 - val_accuracy: 0.4530\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.2040 - val_accuracy: 0.4444\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8447 - accuracy: 0.5111 - val_loss: 1.2048 - val_accuracy: 0.4444\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8437 - accuracy: 0.5519 - val_loss: 1.2068 - val_accuracy: 0.4786\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.2073 - val_accuracy: 0.4786\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.2090 - val_accuracy: 0.4786\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.2035 - val_accuracy: 0.4615\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8451 - accuracy: 0.5407 - val_loss: 1.2017 - val_accuracy: 0.4444\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8475 - accuracy: 0.5370 - val_loss: 1.2122 - val_accuracy: 0.4701\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8426 - accuracy: 0.5593 - val_loss: 1.2195 - val_accuracy: 0.4530\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.2140 - val_accuracy: 0.4530\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8433 - accuracy: 0.5593 - val_loss: 1.2075 - val_accuracy: 0.4615\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8446 - accuracy: 0.5370 - val_loss: 1.2046 - val_accuracy: 0.4530\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.2060 - val_accuracy: 0.4530\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.2064 - val_accuracy: 0.4530\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.2189 - val_accuracy: 0.4530\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8381 - accuracy: 0.56 - 0s 129us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.2187 - val_accuracy: 0.4530\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8456 - accuracy: 0.5556 - val_loss: 1.2212 - val_accuracy: 0.4530\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.2270 - val_accuracy: 0.4530\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.2243 - val_accuracy: 0.4530\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.2285 - val_accuracy: 0.4701\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8480 - accuracy: 0.5556 - val_loss: 1.2291 - val_accuracy: 0.4786\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8423 - accuracy: 0.5593 - val_loss: 1.2257 - val_accuracy: 0.4530\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.2279 - val_accuracy: 0.4444\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8426 - accuracy: 0.5407 - val_loss: 1.2336 - val_accuracy: 0.4530\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.2442 - val_accuracy: 0.4530\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.2463 - val_accuracy: 0.4530\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8441 - accuracy: 0.5444 - val_loss: 1.2388 - val_accuracy: 0.4530\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.2414 - val_accuracy: 0.4530\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.2388 - val_accuracy: 0.4530\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8457 - accuracy: 0.5222 - val_loss: 1.2446 - val_accuracy: 0.4444\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8459 - accuracy: 0.5444 - val_loss: 1.2754 - val_accuracy: 0.4444\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8510 - accuracy: 0.5556 - val_loss: 1.2587 - val_accuracy: 0.4786\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 306us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1872 - val_accuracy: 0.4786\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8446 - accuracy: 0.5481 - val_loss: 1.1631 - val_accuracy: 0.4530\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1472 - val_accuracy: 0.4615\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8468 - accuracy: 0.5519 - val_loss: 1.1470 - val_accuracy: 0.4872\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8434 - accuracy: 0.5370 - val_loss: 1.1443 - val_accuracy: 0.4530\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8477 - accuracy: 0.5407 - val_loss: 1.1480 - val_accuracy: 0.4530\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8434 - accuracy: 0.5111 - val_loss: 1.1521 - val_accuracy: 0.4786\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1521 - val_accuracy: 0.4872\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.1520 - val_accuracy: 0.4872\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1502 - val_accuracy: 0.4530\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1472 - val_accuracy: 0.4530\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8428 - accuracy: 0.5481 - val_loss: 1.1471 - val_accuracy: 0.4615\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8444 - accuracy: 0.5296 - val_loss: 1.1416 - val_accuracy: 0.4615\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1496 - val_accuracy: 0.4872\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8453 - accuracy: 0.5481 - val_loss: 1.1561 - val_accuracy: 0.4530\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8451 - accuracy: 0.5481 - val_loss: 1.1518 - val_accuracy: 0.4872\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8466 - accuracy: 0.5259 - val_loss: 1.1505 - val_accuracy: 0.4786\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8435 - accuracy: 0.5407 - val_loss: 1.1504 - val_accuracy: 0.4530\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8479 - accuracy: 0.5593 - val_loss: 1.1563 - val_accuracy: 0.4530\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8431 - accuracy: 0.5519 - val_loss: 1.1584 - val_accuracy: 0.4872\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1507 - val_accuracy: 0.4872\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8445 - accuracy: 0.5593 - val_loss: 1.1550 - val_accuracy: 0.4530\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1629 - val_accuracy: 0.4530\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8424 - accuracy: 0.5556 - val_loss: 1.1617 - val_accuracy: 0.4786\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8451 - accuracy: 0.5519 - val_loss: 1.1613 - val_accuracy: 0.4872\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8445 - accuracy: 0.5296 - val_loss: 1.1559 - val_accuracy: 0.4444\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8482 - accuracy: 0.5444 - val_loss: 1.1644 - val_accuracy: 0.4530\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1677 - val_accuracy: 0.4530\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8435 - accuracy: 0.5407 - val_loss: 1.1672 - val_accuracy: 0.4786\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8468 - accuracy: 0.5407 - val_loss: 1.1649 - val_accuracy: 0.4701\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8438 - accuracy: 0.5630 - val_loss: 1.1722 - val_accuracy: 0.4786\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1720 - val_accuracy: 0.4786\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1717 - val_accuracy: 0.4786\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8446 - accuracy: 0.5630 - val_loss: 1.1713 - val_accuracy: 0.4530\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.1774 - val_accuracy: 0.4444\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8447 - accuracy: 0.5556 - val_loss: 1.1758 - val_accuracy: 0.4530\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1718 - val_accuracy: 0.4530\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.1727 - val_accuracy: 0.4530\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8463 - accuracy: 0.5593 - val_loss: 1.1748 - val_accuracy: 0.4786\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8436 - accuracy: 0.5333 - val_loss: 1.1703 - val_accuracy: 0.4444\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8478 - accuracy: 0.5481 - val_loss: 1.1712 - val_accuracy: 0.4530\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.1666 - val_accuracy: 0.4701\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1660 - val_accuracy: 0.4786\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1667 - val_accuracy: 0.4786\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8448 - accuracy: 0.5519 - val_loss: 1.1681 - val_accuracy: 0.4786\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8452 - accuracy: 0.5407 - val_loss: 1.1657 - val_accuracy: 0.4444\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8436 - accuracy: 0.5407 - val_loss: 1.1719 - val_accuracy: 0.4786\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.1787 - val_accuracy: 0.4786\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1790 - val_accuracy: 0.4786\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8453 - accuracy: 0.5593 - val_loss: 1.1648 - val_accuracy: 0.4530\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8446 - accuracy: 0.5407 - val_loss: 1.1644 - val_accuracy: 0.4444\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8435 - accuracy: 0.5333 - val_loss: 1.1621 - val_accuracy: 0.4786\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8460 - accuracy: 0.5519 - val_loss: 1.1625 - val_accuracy: 0.4786\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1704 - val_accuracy: 0.4444\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 115us/step - loss: 0.8510 - accuracy: 0.5222 - val_loss: 1.1784 - val_accuracy: 0.4786\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8425 - accuracy: 0.5259 - val_loss: 1.1715 - val_accuracy: 0.4530\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.1659 - val_accuracy: 0.4530\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 1.1732 - val_accuracy: 0.4872\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8461 - accuracy: 0.5556 - val_loss: 1.1777 - val_accuracy: 0.4872\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.1732 - val_accuracy: 0.4786\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.1729 - val_accuracy: 0.4530\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8432 - accuracy: 0.5481 - val_loss: 1.1749 - val_accuracy: 0.4444\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8436 - accuracy: 0.5407 - val_loss: 1.1818 - val_accuracy: 0.4615\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8440 - accuracy: 0.4963 - val_loss: 1.1881 - val_accuracy: 0.4786\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8484 - accuracy: 0.5556 - val_loss: 1.1874 - val_accuracy: 0.4872\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8460 - accuracy: 0.5593 - val_loss: 1.1788 - val_accuracy: 0.4530\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8473 - accuracy: 0.5556 - val_loss: 1.1843 - val_accuracy: 0.4530\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8467 - accuracy: 0.5000 - val_loss: 1.1864 - val_accuracy: 0.4701\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8449 - accuracy: 0.5407 - val_loss: 1.1802 - val_accuracy: 0.4872\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1792 - val_accuracy: 0.4786\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8465 - accuracy: 0.5519 - val_loss: 1.1758 - val_accuracy: 0.4530\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.1727 - val_accuracy: 0.4872\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8423 - accuracy: 0.5444 - val_loss: 1.1702 - val_accuracy: 0.4615\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1717 - val_accuracy: 0.4530\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1779 - val_accuracy: 0.4530\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1733 - val_accuracy: 0.4530\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8459 - accuracy: 0.5519 - val_loss: 1.1755 - val_accuracy: 0.4872\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8469 - accuracy: 0.5519 - val_loss: 1.2047 - val_accuracy: 0.4530\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8564 - accuracy: 0.5519 - val_loss: 1.1380 - val_accuracy: 0.4444\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8527 - accuracy: 0.5407 - val_loss: 1.1313 - val_accuracy: 0.4444\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8530 - accuracy: 0.5259 - val_loss: 1.1255 - val_accuracy: 0.4615\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8489 - accuracy: 0.5296 - val_loss: 1.1262 - val_accuracy: 0.4615\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8465 - accuracy: 0.5556 - val_loss: 1.1492 - val_accuracy: 0.4615\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8466 - accuracy: 0.5556 - val_loss: 1.1346 - val_accuracy: 0.4615\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8445 - accuracy: 0.5593 - val_loss: 1.1298 - val_accuracy: 0.4872\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8501 - accuracy: 0.5222 - val_loss: 1.1268 - val_accuracy: 0.4786\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8502 - accuracy: 0.5556 - val_loss: 1.1226 - val_accuracy: 0.4615\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8444 - accuracy: 0.5593 - val_loss: 1.1397 - val_accuracy: 0.4872\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.1468 - val_accuracy: 0.4530\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8444 - accuracy: 0.5407 - val_loss: 1.1544 - val_accuracy: 0.4530\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8468 - accuracy: 0.5556 - val_loss: 1.1567 - val_accuracy: 0.4615\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1545 - val_accuracy: 0.4615\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8443 - accuracy: 0.5259 - val_loss: 1.1487 - val_accuracy: 0.4530\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8474 - accuracy: 0.5185 - val_loss: 1.1505 - val_accuracy: 0.4615\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8444 - accuracy: 0.5074 - val_loss: 1.1451 - val_accuracy: 0.4444\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8441 - accuracy: 0.5296 - val_loss: 1.1471 - val_accuracy: 0.4530\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8458 - accuracy: 0.5481 - val_loss: 1.1547 - val_accuracy: 0.4701\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1516 - val_accuracy: 0.4530\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8464 - accuracy: 0.5593 - val_loss: 1.1492 - val_accuracy: 0.4786\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8443 - accuracy: 0.5519 - val_loss: 1.1469 - val_accuracy: 0.4444\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1473 - val_accuracy: 0.4530\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8428 - accuracy: 0.5519 - val_loss: 1.1525 - val_accuracy: 0.4701\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8448 - accuracy: 0.5556 - val_loss: 1.1500 - val_accuracy: 0.4786\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1500 - val_accuracy: 0.4701\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8445 - accuracy: 0.5296 - val_loss: 1.1483 - val_accuracy: 0.4786\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8441 - accuracy: 0.5296 - val_loss: 1.1490 - val_accuracy: 0.4701\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8457 - accuracy: 0.5444 - val_loss: 1.1596 - val_accuracy: 0.4786\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8457 - accuracy: 0.5556 - val_loss: 1.1606 - val_accuracy: 0.4701\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1558 - val_accuracy: 0.4786\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8434 - accuracy: 0.5593 - val_loss: 1.1559 - val_accuracy: 0.4530\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1542 - val_accuracy: 0.4530\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8435 - accuracy: 0.5519 - val_loss: 1.1573 - val_accuracy: 0.4786\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.1570 - val_accuracy: 0.4530\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1608 - val_accuracy: 0.4530\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8442 - accuracy: 0.5185 - val_loss: 1.1546 - val_accuracy: 0.4444\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8450 - accuracy: 0.5556 - val_loss: 1.1417 - val_accuracy: 0.4615\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8450 - accuracy: 0.5407 - val_loss: 1.1425 - val_accuracy: 0.4872\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8430 - accuracy: 0.5593 - val_loss: 1.1388 - val_accuracy: 0.4872\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.1407 - val_accuracy: 0.4872\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8460 - accuracy: 0.5593 - val_loss: 1.1430 - val_accuracy: 0.4530\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8460 - accuracy: 0.5556 - val_loss: 1.1474 - val_accuracy: 0.4786\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8497 - accuracy: 0.5296 - val_loss: 1.1555 - val_accuracy: 0.4786\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8491 - accuracy: 0.5296 - val_loss: 1.1529 - val_accuracy: 0.4530\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1508 - val_accuracy: 0.4530\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8512 - accuracy: 0.5519 - val_loss: 1.1503 - val_accuracy: 0.4786\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8501 - accuracy: 0.5481 - val_loss: 1.1428 - val_accuracy: 0.4530\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8438 - accuracy: 0.5481 - val_loss: 1.1491 - val_accuracy: 0.4615\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8433 - accuracy: 0.5593 - val_loss: 1.1544 - val_accuracy: 0.4786\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.1591 - val_accuracy: 0.4786\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1595 - val_accuracy: 0.4530\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8438 - accuracy: 0.5519 - val_loss: 1.1589 - val_accuracy: 0.4530\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8414 - accuracy: 0.5556 - val_loss: 1.1570 - val_accuracy: 0.4530\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.1636 - val_accuracy: 0.4530\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.8444 - accuracy: 0.5556 - val_loss: 1.1573 - val_accuracy: 0.4615\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 402us/step - loss: 0.8458 - accuracy: 0.5111 - val_loss: 1.1553 - val_accuracy: 0.4872\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.1621 - val_accuracy: 0.4530\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1629 - val_accuracy: 0.4530\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 350us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1620 - val_accuracy: 0.4530\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8432 - accuracy: 0.5593 - val_loss: 1.1597 - val_accuracy: 0.4872\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8431 - accuracy: 0.5556 - val_loss: 1.1547 - val_accuracy: 0.4615\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1591 - val_accuracy: 0.4615\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1604 - val_accuracy: 0.4615\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8494 - accuracy: 0.5556 - val_loss: 1.1663 - val_accuracy: 0.4615\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1674 - val_accuracy: 0.4615\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1710 - val_accuracy: 0.4530\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1637 - val_accuracy: 0.4530\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.1661 - val_accuracy: 0.4530\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8437 - accuracy: 0.5481 - val_loss: 1.1611 - val_accuracy: 0.4872\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1630 - val_accuracy: 0.4872\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8430 - accuracy: 0.5519 - val_loss: 1.1619 - val_accuracy: 0.4615\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.1600 - val_accuracy: 0.4530\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1594 - val_accuracy: 0.4530\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1582 - val_accuracy: 0.4530\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8462 - accuracy: 0.5556 - val_loss: 1.1650 - val_accuracy: 0.4872\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1620 - val_accuracy: 0.4615\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8435 - accuracy: 0.5370 - val_loss: 1.1615 - val_accuracy: 0.4530\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8427 - accuracy: 0.5296 - val_loss: 1.1601 - val_accuracy: 0.4872\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1594 - val_accuracy: 0.4530\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1566 - val_accuracy: 0.4872\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1526 - val_accuracy: 0.4615\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8436 - accuracy: 0.5259 - val_loss: 1.1557 - val_accuracy: 0.4530\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.1596 - val_accuracy: 0.4530\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8468 - accuracy: 0.5593 - val_loss: 1.1706 - val_accuracy: 0.4786\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.1690 - val_accuracy: 0.4530\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 66us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1672 - val_accuracy: 0.4530\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8450 - accuracy: 0.5481 - val_loss: 1.1686 - val_accuracy: 0.4786\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8486 - accuracy: 0.5519 - val_loss: 1.1632 - val_accuracy: 0.4530\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8466 - accuracy: 0.5519 - val_loss: 1.1653 - val_accuracy: 0.4786\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.1735 - val_accuracy: 0.4872\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8442 - accuracy: 0.5519 - val_loss: 1.1682 - val_accuracy: 0.4786\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.1670 - val_accuracy: 0.4530\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8470 - accuracy: 0.5556 - val_loss: 1.1671 - val_accuracy: 0.4530\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8442 - accuracy: 0.5593 - val_loss: 1.1702 - val_accuracy: 0.4786\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1689 - val_accuracy: 0.4786\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8464 - accuracy: 0.5556 - val_loss: 1.1676 - val_accuracy: 0.4701\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8428 - accuracy: 0.5593 - val_loss: 1.1633 - val_accuracy: 0.4530\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1664 - val_accuracy: 0.4786\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8534 - accuracy: 0.5296 - val_loss: 1.1700 - val_accuracy: 0.4786\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1552 - val_accuracy: 0.4530\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8446 - accuracy: 0.5556 - val_loss: 1.1591 - val_accuracy: 0.4530\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1668 - val_accuracy: 0.4615\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.4530\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8428 - accuracy: 0.5556 - val_loss: 1.1666 - val_accuracy: 0.4615\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8442 - accuracy: 0.5000 - val_loss: 1.1685 - val_accuracy: 0.4786\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8446 - accuracy: 0.5444 - val_loss: 1.1630 - val_accuracy: 0.4872\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8452 - accuracy: 0.5556 - val_loss: 1.1655 - val_accuracy: 0.4530\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8434 - accuracy: 0.5593 - val_loss: 1.1712 - val_accuracy: 0.4872\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8438 - accuracy: 0.5556 - val_loss: 1.1741 - val_accuracy: 0.4615\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1683 - val_accuracy: 0.4872\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.1666 - val_accuracy: 0.4615\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8462 - accuracy: 0.5519 - val_loss: 1.1713 - val_accuracy: 0.4530\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1700 - val_accuracy: 0.4615\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8455 - accuracy: 0.5556 - val_loss: 1.1684 - val_accuracy: 0.4872\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8452 - accuracy: 0.5519 - val_loss: 1.1673 - val_accuracy: 0.4530\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8440 - accuracy: 0.5519 - val_loss: 1.1662 - val_accuracy: 0.4615\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1642 - val_accuracy: 0.4872\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8429 - accuracy: 0.5519 - val_loss: 1.1694 - val_accuracy: 0.4530\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8433 - accuracy: 0.5296 - val_loss: 1.1678 - val_accuracy: 0.4444\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8423 - accuracy: 0.5407 - val_loss: 1.1701 - val_accuracy: 0.4615\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8429 - accuracy: 0.5556 - val_loss: 1.1721 - val_accuracy: 0.4530\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8435 - accuracy: 0.5481 - val_loss: 1.1698 - val_accuracy: 0.4615\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8444 - accuracy: 0.5519 - val_loss: 1.1698 - val_accuracy: 0.4872\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1700 - val_accuracy: 0.4615\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8434 - accuracy: 0.5259 - val_loss: 1.1701 - val_accuracy: 0.4530\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8448 - accuracy: 0.5333 - val_loss: 1.1837 - val_accuracy: 0.4786\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1801 - val_accuracy: 0.4444\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8423 - accuracy: 0.5444 - val_loss: 1.1843 - val_accuracy: 0.4530\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.1894 - val_accuracy: 0.4530\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.1960 - val_accuracy: 0.4530\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1934 - val_accuracy: 0.4530\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8452 - accuracy: 0.5444 - val_loss: 1.1832 - val_accuracy: 0.4530\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8432 - accuracy: 0.5519 - val_loss: 1.1808 - val_accuracy: 0.4872\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8427 - accuracy: 0.5556 - val_loss: 1.1791 - val_accuracy: 0.4872\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.1768 - val_accuracy: 0.4872\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8439 - accuracy: 0.5519 - val_loss: 1.1806 - val_accuracy: 0.4530\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.1814 - val_accuracy: 0.4530\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.1775 - val_accuracy: 0.4530\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.1777 - val_accuracy: 0.4530\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8449 - accuracy: 0.5556 - val_loss: 1.1719 - val_accuracy: 0.4530\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.1712 - val_accuracy: 0.4530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8441 - accuracy: 0.5556 - val_loss: 1.1802 - val_accuracy: 0.4786\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.1788 - val_accuracy: 0.4786\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8438 - accuracy: 0.5370 - val_loss: 1.1831 - val_accuracy: 0.4444\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8438 - accuracy: 0.5185 - val_loss: 1.1834 - val_accuracy: 0.4530\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8434 - accuracy: 0.5370 - val_loss: 1.1839 - val_accuracy: 0.4444\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8444 - accuracy: 0.5481 - val_loss: 1.1828 - val_accuracy: 0.4872\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.1819 - val_accuracy: 0.4786\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.1850 - val_accuracy: 0.4872\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1845 - val_accuracy: 0.4872\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.1867 - val_accuracy: 0.4872\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.1857 - val_accuracy: 0.4530\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8476 - accuracy: 0.5444 - val_loss: 1.1879 - val_accuracy: 0.4872\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8425 - accuracy: 0.5556 - val_loss: 1.1934 - val_accuracy: 0.4530\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8488 - accuracy: 0.5556 - val_loss: 1.1972 - val_accuracy: 0.4530\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8459 - accuracy: 0.5556 - val_loss: 1.1981 - val_accuracy: 0.4872\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8451 - accuracy: 0.5556 - val_loss: 1.1901 - val_accuracy: 0.4530\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8439 - accuracy: 0.5148 - val_loss: 1.1921 - val_accuracy: 0.4786\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8458 - accuracy: 0.5296 - val_loss: 1.1868 - val_accuracy: 0.4530\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8444 - accuracy: 0.5481 - val_loss: 1.1954 - val_accuracy: 0.4872\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.1979 - val_accuracy: 0.4786\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8470 - accuracy: 0.5519 - val_loss: 1.1961 - val_accuracy: 0.4530\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1962 - val_accuracy: 0.4786\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8436 - accuracy: 0.5556 - val_loss: 1.1926 - val_accuracy: 0.4530\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8433 - accuracy: 0.5556 - val_loss: 1.1977 - val_accuracy: 0.4530\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8440 - accuracy: 0.5407 - val_loss: 1.2010 - val_accuracy: 0.4701\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8445 - accuracy: 0.5407 - val_loss: 1.2053 - val_accuracy: 0.4444\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8475 - accuracy: 0.5296 - val_loss: 1.2029 - val_accuracy: 0.4786\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8426 - accuracy: 0.5556 - val_loss: 1.2060 - val_accuracy: 0.4786\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.2039 - val_accuracy: 0.4786\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8423 - accuracy: 0.5556 - val_loss: 1.1983 - val_accuracy: 0.4786\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8445 - accuracy: 0.5519 - val_loss: 1.1944 - val_accuracy: 0.4786\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2097 - val_accuracy: 0.4786\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8458 - accuracy: 0.5519 - val_loss: 1.2252 - val_accuracy: 0.4786\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2261 - val_accuracy: 0.4530\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8481 - accuracy: 0.5556 - val_loss: 1.2149 - val_accuracy: 0.4530\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8418 - accuracy: 0.5556 - val_loss: 1.2143 - val_accuracy: 0.4530\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8439 - accuracy: 0.5556 - val_loss: 1.2197 - val_accuracy: 0.4872\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8453 - accuracy: 0.5259 - val_loss: 1.2179 - val_accuracy: 0.4530\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.2155 - val_accuracy: 0.4530\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8453 - accuracy: 0.5556 - val_loss: 1.2092 - val_accuracy: 0.4530\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8458 - accuracy: 0.5556 - val_loss: 1.2097 - val_accuracy: 0.4530\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8482 - accuracy: 0.5556 - val_loss: 1.2081 - val_accuracy: 0.4872\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8467 - accuracy: 0.5556 - val_loss: 1.2050 - val_accuracy: 0.4530\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8432 - accuracy: 0.5556 - val_loss: 1.2110 - val_accuracy: 0.4530\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8443 - accuracy: 0.5556 - val_loss: 1.2167 - val_accuracy: 0.4530\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8434 - accuracy: 0.5556 - val_loss: 1.2287 - val_accuracy: 0.4786\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2267 - val_accuracy: 0.4786\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8425 - accuracy: 0.5481 - val_loss: 1.2167 - val_accuracy: 0.4530\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8445 - accuracy: 0.5556 - val_loss: 1.2219 - val_accuracy: 0.4530\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8442 - accuracy: 0.5556 - val_loss: 1.2193 - val_accuracy: 0.4530\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8436 - accuracy: 0.5519 - val_loss: 1.2252 - val_accuracy: 0.4786\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8467 - accuracy: 0.5148 - val_loss: 1.2189 - val_accuracy: 0.4444\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8458 - accuracy: 0.5407 - val_loss: 1.2241 - val_accuracy: 0.4530\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2249 - val_accuracy: 0.4530\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8452 - accuracy: 0.5407 - val_loss: 1.2229 - val_accuracy: 0.4530\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8428 - accuracy: 0.5407 - val_loss: 1.2266 - val_accuracy: 0.4530\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8430 - accuracy: 0.5556 - val_loss: 1.2314 - val_accuracy: 0.4530\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8435 - accuracy: 0.5556 - val_loss: 1.2348 - val_accuracy: 0.4786\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8449 - accuracy: 0.5519 - val_loss: 1.2346 - val_accuracy: 0.4530\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.2230 - val_accuracy: 0.4530\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8449 - accuracy: 0.5444 - val_loss: 1.2171 - val_accuracy: 0.4530\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8440 - accuracy: 0.5556 - val_loss: 1.2209 - val_accuracy: 0.4786\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8437 - accuracy: 0.5556 - val_loss: 1.2246 - val_accuracy: 0.4786\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 54.77%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [4.2229065e-01, 7.0299245e-02, 5.0741010e-01],\n",
       "       [3.5584080e-04, 2.9760180e-04, 9.9934655e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [9.8233277e-01, 1.4282453e-02, 3.3847615e-03],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.5584080e-04, 2.9760180e-04, 9.9934655e-01],\n",
       "       [2.5331424e-04, 1.0664241e-02, 9.8908246e-01],\n",
       "       [5.9236000e-04, 3.8518402e-01, 6.1422360e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [9.0621240e-01, 7.6262460e-02, 1.7525123e-02],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [2.2520465e-04, 4.0490914e-07, 9.9977440e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [2.5331424e-04, 1.0664241e-02, 9.8908246e-01],\n",
       "       [1.9486574e-04, 9.9582577e-01, 3.9793520e-03],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.1938135e-02, 3.7536868e-01, 6.1269320e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [2.2520465e-04, 4.0490914e-07, 9.9977440e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [1.6052416e-01, 4.7008064e-01, 3.6939520e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.6052416e-01, 4.7008064e-01, 3.6939520e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [9.8233277e-01, 1.4282453e-02, 3.3847615e-03],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8212768e-01, 1.9866760e-03, 8.1588560e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [8.4582376e-01, 1.3802408e-01, 1.6152145e-02],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [2.3722443e-05, 1.5258322e-03, 9.9845040e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.6052416e-01, 4.7008064e-01, 3.6939520e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [2.3722443e-05, 1.5258322e-03, 9.9845040e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [4.0619925e-06, 1.2319603e-02, 9.8767640e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [8.4582376e-01, 1.3802408e-01, 1.6152145e-02],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [6.3066940e-02, 3.1967202e-01, 6.1726110e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [9.3394680e-01, 5.0133534e-02, 1.5919713e-02],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [6.3066940e-02, 3.1967202e-01, 6.1726110e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [2.0050247e-01, 4.1814085e-02, 7.5768346e-01],\n",
       "       [5.9236000e-04, 3.8518402e-01, 6.1422360e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [9.8233277e-01, 1.4282453e-02, 3.3847615e-03],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [8.3245265e-01, 1.5887062e-01, 8.6766630e-03],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [2.4723057e-02, 8.0947500e-01, 1.6580194e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.8888690e-01, 5.1080380e-01, 3.0030936e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [1.6052416e-01, 4.7008064e-01, 3.6939520e-01],\n",
       "       [6.3066940e-02, 3.1967202e-01, 6.1726110e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [6.3066940e-02, 3.1967202e-01, 6.1726110e-01],\n",
       "       [4.0619925e-06, 1.2319603e-02, 9.8767640e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [6.3066940e-02, 3.1967202e-01, 6.1726110e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [7.3184556e-01, 1.9981107e-01, 6.8343300e-02],\n",
       "       [9.2563224e-01, 4.4884656e-02, 2.9483106e-02],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01],\n",
       "       [3.9409712e-01, 4.1842150e-01, 1.8748140e-01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6386149463072539"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6386149463072539"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS210     0\n",
       "1         NRS205     2\n",
       "2            312     2\n",
       "3           GA15     2\n",
       "4         SR4035     0\n",
       "..           ...   ...\n",
       "112       NRS265     2\n",
       "113  CFBREBSa108     1\n",
       "114        NY224     1\n",
       "115       NRS386     2\n",
       "116       NRS168     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 485us/step - loss: 1.2622 - accuracy: 0.3333 - val_loss: 1.1851 - val_accuracy: 0.3419\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 1.1526 - accuracy: 0.3333 - val_loss: 1.1185 - val_accuracy: 0.3675\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.1122 - accuracy: 0.3741 - val_loss: 1.1030 - val_accuracy: 0.4359\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 1.1027 - accuracy: 0.3333 - val_loss: 1.0976 - val_accuracy: 0.3333\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 1.0942 - accuracy: 0.3259 - val_loss: 1.0875 - val_accuracy: 0.3590\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 476us/step - loss: 1.0844 - accuracy: 0.3852 - val_loss: 1.0797 - val_accuracy: 0.3932\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 392us/step - loss: 1.0771 - accuracy: 0.3926 - val_loss: 1.0723 - val_accuracy: 0.4103\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 1.0720 - accuracy: 0.4111 - val_loss: 1.0651 - val_accuracy: 0.4701\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 1.0654 - accuracy: 0.4259 - val_loss: 1.0587 - val_accuracy: 0.4786\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 1.0612 - accuracy: 0.4519 - val_loss: 1.0529 - val_accuracy: 0.5043\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 1.0540 - accuracy: 0.4519 - val_loss: 1.0462 - val_accuracy: 0.5043\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 1.0485 - accuracy: 0.4519 - val_loss: 1.0404 - val_accuracy: 0.5043\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 1.0441 - accuracy: 0.4667 - val_loss: 1.0354 - val_accuracy: 0.4872\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 1.0396 - accuracy: 0.4593 - val_loss: 1.0300 - val_accuracy: 0.4786\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 1.0333 - accuracy: 0.4704 - val_loss: 1.0247 - val_accuracy: 0.4957\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 1.0309 - accuracy: 0.4556 - val_loss: 1.0199 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 1.0258 - accuracy: 0.4963 - val_loss: 1.0146 - val_accuracy: 0.4615\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 1.0213 - accuracy: 0.4630 - val_loss: 1.0094 - val_accuracy: 0.4957\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 1.0192 - accuracy: 0.4778 - val_loss: 1.0040 - val_accuracy: 0.4957\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 1.0123 - accuracy: 0.4778 - val_loss: 0.9967 - val_accuracy: 0.4957\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 1.0075 - accuracy: 0.4741 - val_loss: 0.9917 - val_accuracy: 0.4615\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 1.0037 - accuracy: 0.4741 - val_loss: 0.9877 - val_accuracy: 0.4957\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 1.0024 - accuracy: 0.4852 - val_loss: 0.9849 - val_accuracy: 0.5043\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 1.0016 - accuracy: 0.4815 - val_loss: 0.9834 - val_accuracy: 0.4957\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9959 - accuracy: 0.4778 - val_loss: 0.9795 - val_accuracy: 0.5556\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9943 - accuracy: 0.5111 - val_loss: 0.9770 - val_accuracy: 0.5556\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9917 - accuracy: 0.4963 - val_loss: 0.9760 - val_accuracy: 0.4957\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9933 - accuracy: 0.4815 - val_loss: 0.9775 - val_accuracy: 0.4957\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.9910 - accuracy: 0.4889 - val_loss: 0.9717 - val_accuracy: 0.5214\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.9887 - accuracy: 0.5037 - val_loss: 0.9706 - val_accuracy: 0.5214\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9869 - accuracy: 0.4778 - val_loss: 0.9713 - val_accuracy: 0.4957\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9863 - accuracy: 0.4926 - val_loss: 0.9682 - val_accuracy: 0.5556\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9835 - accuracy: 0.5037 - val_loss: 0.9677 - val_accuracy: 0.4957\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9830 - accuracy: 0.4630 - val_loss: 0.9669 - val_accuracy: 0.4957\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9813 - accuracy: 0.4852 - val_loss: 0.9656 - val_accuracy: 0.4957\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9803 - accuracy: 0.4889 - val_loss: 0.9639 - val_accuracy: 0.4957\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.9796 - accuracy: 0.4852 - val_loss: 0.9630 - val_accuracy: 0.4957\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.9795 - accuracy: 0.4926 - val_loss: 0.9605 - val_accuracy: 0.5556\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.9773 - accuracy: 0.5074 - val_loss: 0.9616 - val_accuracy: 0.4957\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9769 - accuracy: 0.4852 - val_loss: 0.9608 - val_accuracy: 0.4957\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9748 - accuracy: 0.4815 - val_loss: 0.9603 - val_accuracy: 0.4957\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9733 - accuracy: 0.4815 - val_loss: 0.9580 - val_accuracy: 0.5556\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9732 - accuracy: 0.5111 - val_loss: 0.9569 - val_accuracy: 0.5556\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9713 - accuracy: 0.4926 - val_loss: 0.9577 - val_accuracy: 0.5214\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9731 - accuracy: 0.5037 - val_loss: 0.9566 - val_accuracy: 0.5556\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9731 - accuracy: 0.5111 - val_loss: 0.9558 - val_accuracy: 0.5556\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.9705 - accuracy: 0.4926 - val_loss: 0.9575 - val_accuracy: 0.4615\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.9690 - accuracy: 0.5000 - val_loss: 0.9558 - val_accuracy: 0.5214\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.9686 - accuracy: 0.5037 - val_loss: 0.9542 - val_accuracy: 0.5556\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9692 - accuracy: 0.5074 - val_loss: 0.9544 - val_accuracy: 0.5556\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9669 - accuracy: 0.5111 - val_loss: 0.9551 - val_accuracy: 0.4957\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.9667 - accuracy: 0.4778 - val_loss: 0.9550 - val_accuracy: 0.5214\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9668 - accuracy: 0.4667 - val_loss: 0.9538 - val_accuracy: 0.5556\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.9654 - accuracy: 0.4963 - val_loss: 0.9525 - val_accuracy: 0.5556\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9655 - accuracy: 0.5111 - val_loss: 0.9517 - val_accuracy: 0.5556\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.9648 - accuracy: 0.5111 - val_loss: 0.9531 - val_accuracy: 0.5556\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9630 - accuracy: 0.5074 - val_loss: 0.9519 - val_accuracy: 0.5214\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9629 - accuracy: 0.5037 - val_loss: 0.9515 - val_accuracy: 0.5214\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9651 - accuracy: 0.4889 - val_loss: 0.9510 - val_accuracy: 0.5556\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9616 - accuracy: 0.5111 - val_loss: 0.9502 - val_accuracy: 0.5556\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9611 - accuracy: 0.5111 - val_loss: 0.9501 - val_accuracy: 0.5556\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9621 - accuracy: 0.5111 - val_loss: 0.9507 - val_accuracy: 0.5556\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9639 - accuracy: 0.5111 - val_loss: 0.9512 - val_accuracy: 0.5556\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9597 - accuracy: 0.5111 - val_loss: 0.9495 - val_accuracy: 0.5556\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9595 - accuracy: 0.5074 - val_loss: 0.9502 - val_accuracy: 0.5556\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9665 - accuracy: 0.4778 - val_loss: 0.9531 - val_accuracy: 0.5214\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.9599 - accuracy: 0.4741 - val_loss: 0.9508 - val_accuracy: 0.5556\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8994 - accuracy: 0.59 - 0s 136us/step - loss: 0.9583 - accuracy: 0.5111 - val_loss: 0.9508 - val_accuracy: 0.5556\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9584 - accuracy: 0.5111 - val_loss: 0.9519 - val_accuracy: 0.5556\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9570 - accuracy: 0.4778 - val_loss: 0.9501 - val_accuracy: 0.5556\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9621 - accuracy: 0.5000 - val_loss: 0.9499 - val_accuracy: 0.5214\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9554 - accuracy: 0.5074 - val_loss: 0.9498 - val_accuracy: 0.5556\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9564 - accuracy: 0.5111 - val_loss: 0.9496 - val_accuracy: 0.5556\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.9558 - accuracy: 0.5074 - val_loss: 0.9502 - val_accuracy: 0.5556\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9549 - accuracy: 0.4926 - val_loss: 0.9490 - val_accuracy: 0.5556\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9550 - accuracy: 0.5111 - val_loss: 0.9485 - val_accuracy: 0.5556\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9549 - accuracy: 0.5111 - val_loss: 0.9499 - val_accuracy: 0.5556\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.9538 - accuracy: 0.5074 - val_loss: 0.9491 - val_accuracy: 0.5556\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9584 - accuracy: 0.5111 - val_loss: 0.9494 - val_accuracy: 0.5556\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9519 - accuracy: 0.5111 - val_loss: 0.9474 - val_accuracy: 0.5556\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.9535 - accuracy: 0.4963 - val_loss: 0.9485 - val_accuracy: 0.5214\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9536 - accuracy: 0.5000 - val_loss: 0.9488 - val_accuracy: 0.5214\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9538 - accuracy: 0.4815 - val_loss: 0.9475 - val_accuracy: 0.5556\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9513 - accuracy: 0.5148 - val_loss: 0.9471 - val_accuracy: 0.5556\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9521 - accuracy: 0.5148 - val_loss: 0.9467 - val_accuracy: 0.5556\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9525 - accuracy: 0.5148 - val_loss: 0.9468 - val_accuracy: 0.5556\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9529 - accuracy: 0.4815 - val_loss: 0.9485 - val_accuracy: 0.5214\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9545 - accuracy: 0.5037 - val_loss: 0.9483 - val_accuracy: 0.5556\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9495 - accuracy: 0.5000 - val_loss: 0.9481 - val_accuracy: 0.5214\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9509 - accuracy: 0.4889 - val_loss: 0.9468 - val_accuracy: 0.5556\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9504 - accuracy: 0.4889 - val_loss: 0.9469 - val_accuracy: 0.5214\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9500 - accuracy: 0.4667 - val_loss: 0.9476 - val_accuracy: 0.5214\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9488 - accuracy: 0.4963 - val_loss: 0.9493 - val_accuracy: 0.5556\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9492 - accuracy: 0.5074 - val_loss: 0.9467 - val_accuracy: 0.5556\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9502 - accuracy: 0.5111 - val_loss: 0.9458 - val_accuracy: 0.5556\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9494 - accuracy: 0.5111 - val_loss: 0.9457 - val_accuracy: 0.5556\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9483 - accuracy: 0.4963 - val_loss: 0.9467 - val_accuracy: 0.5214\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.9479 - accuracy: 0.4889 - val_loss: 0.9454 - val_accuracy: 0.5556\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.9478 - accuracy: 0.5111 - val_loss: 0.9453 - val_accuracy: 0.5556\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9482 - accuracy: 0.5111 - val_loss: 0.9452 - val_accuracy: 0.5556\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.9497 - accuracy: 0.5111 - val_loss: 0.9471 - val_accuracy: 0.5556\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.9479 - accuracy: 0.5037 - val_loss: 0.9465 - val_accuracy: 0.5214\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9476 - accuracy: 0.4667 - val_loss: 0.9463 - val_accuracy: 0.5214\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9485 - accuracy: 0.5148 - val_loss: 0.9476 - val_accuracy: 0.5556\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9461 - accuracy: 0.5148 - val_loss: 0.9453 - val_accuracy: 0.5556\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9459 - accuracy: 0.5148 - val_loss: 0.9453 - val_accuracy: 0.5556\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9450 - accuracy: 0.5000 - val_loss: 0.9458 - val_accuracy: 0.5214\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9473 - accuracy: 0.5074 - val_loss: 0.9479 - val_accuracy: 0.5214\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9451 - accuracy: 0.5074 - val_loss: 0.9460 - val_accuracy: 0.5214\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9473 - accuracy: 0.5037 - val_loss: 0.9456 - val_accuracy: 0.5556\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 65us/step - loss: 0.9476 - accuracy: 0.4778 - val_loss: 0.9460 - val_accuracy: 0.5214\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9452 - accuracy: 0.4741 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9439 - accuracy: 0.5148 - val_loss: 0.9460 - val_accuracy: 0.5556\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9439 - accuracy: 0.5148 - val_loss: 0.9450 - val_accuracy: 0.5556\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9447 - accuracy: 0.5148 - val_loss: 0.9461 - val_accuracy: 0.5556\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9427 - accuracy: 0.5148 - val_loss: 0.9455 - val_accuracy: 0.5556\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9461 - accuracy: 0.5074 - val_loss: 0.9470 - val_accuracy: 0.5214\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9440 - accuracy: 0.4778 - val_loss: 0.9448 - val_accuracy: 0.5556\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9423 - accuracy: 0.5037 - val_loss: 0.9448 - val_accuracy: 0.5214\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9418 - accuracy: 0.5111 - val_loss: 0.9448 - val_accuracy: 0.5556\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.9450 - accuracy: 0.4889 - val_loss: 0.9468 - val_accuracy: 0.5214\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9454 - accuracy: 0.5074 - val_loss: 0.9456 - val_accuracy: 0.5556\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9412 - accuracy: 0.5148 - val_loss: 0.9453 - val_accuracy: 0.5556\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9413 - accuracy: 0.4926 - val_loss: 0.9459 - val_accuracy: 0.5214\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9420 - accuracy: 0.4889 - val_loss: 0.9444 - val_accuracy: 0.5556\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9409 - accuracy: 0.5148 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9418 - accuracy: 0.5148 - val_loss: 0.9464 - val_accuracy: 0.5556\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9417 - accuracy: 0.5259 - val_loss: 0.9452 - val_accuracy: 0.5214\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.9446 - accuracy: 0.4704 - val_loss: 0.9473 - val_accuracy: 0.5556\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9398 - accuracy: 0.5148 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9394 - accuracy: 0.5148 - val_loss: 0.9444 - val_accuracy: 0.5556\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.9400 - accuracy: 0.5148 - val_loss: 0.9445 - val_accuracy: 0.5556\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.9385 - accuracy: 0.5074 - val_loss: 0.9451 - val_accuracy: 0.5214\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9379 - accuracy: 0.5259 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9385 - accuracy: 0.5148 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9388 - accuracy: 0.5148 - val_loss: 0.9444 - val_accuracy: 0.5556\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9404 - accuracy: 0.4926 - val_loss: 0.9452 - val_accuracy: 0.5214\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9419 - accuracy: 0.5185 - val_loss: 0.9447 - val_accuracy: 0.5556\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9388 - accuracy: 0.5148 - val_loss: 0.9452 - val_accuracy: 0.5556\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9395 - accuracy: 0.4963 - val_loss: 0.9449 - val_accuracy: 0.5214\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9369 - accuracy: 0.5148 - val_loss: 0.9455 - val_accuracy: 0.5556\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9372 - accuracy: 0.5148 - val_loss: 0.9452 - val_accuracy: 0.5556\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.9366 - accuracy: 0.5148 - val_loss: 0.9442 - val_accuracy: 0.5556\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9367 - accuracy: 0.5148 - val_loss: 0.9444 - val_accuracy: 0.5556\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9365 - accuracy: 0.5148 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9382 - accuracy: 0.5148 - val_loss: 0.9445 - val_accuracy: 0.5556\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9378 - accuracy: 0.5148 - val_loss: 0.9488 - val_accuracy: 0.5556\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.9358 - accuracy: 0.4963 - val_loss: 0.9463 - val_accuracy: 0.5214\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.9367 - accuracy: 0.5074 - val_loss: 0.9454 - val_accuracy: 0.5214\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9364 - accuracy: 0.5074 - val_loss: 0.9455 - val_accuracy: 0.5556\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9349 - accuracy: 0.5148 - val_loss: 0.9441 - val_accuracy: 0.5556\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9349 - accuracy: 0.5148 - val_loss: 0.9441 - val_accuracy: 0.5556\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9350 - accuracy: 0.5148 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9350 - accuracy: 0.5000 - val_loss: 0.9465 - val_accuracy: 0.5214\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9369 - accuracy: 0.5111 - val_loss: 0.9467 - val_accuracy: 0.5214\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9366 - accuracy: 0.5111 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9344 - accuracy: 0.5148 - val_loss: 0.9437 - val_accuracy: 0.5556\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9340 - accuracy: 0.5148 - val_loss: 0.9442 - val_accuracy: 0.5556\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9340 - accuracy: 0.5148 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9331 - accuracy: 0.4963 - val_loss: 0.9447 - val_accuracy: 0.5214\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9327 - accuracy: 0.5074 - val_loss: 0.9449 - val_accuracy: 0.5214\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9333 - accuracy: 0.4815 - val_loss: 0.9438 - val_accuracy: 0.5556\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9313 - accuracy: 0.5148 - val_loss: 0.9440 - val_accuracy: 0.5556\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9338 - accuracy: 0.5148 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9323 - accuracy: 0.4852 - val_loss: 0.9442 - val_accuracy: 0.5556\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9310 - accuracy: 0.5185 - val_loss: 0.9442 - val_accuracy: 0.5556\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9323 - accuracy: 0.4963 - val_loss: 0.9440 - val_accuracy: 0.5556\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9309 - accuracy: 0.5148 - val_loss: 0.9443 - val_accuracy: 0.5556\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9301 - accuracy: 0.5148 - val_loss: 0.9433 - val_accuracy: 0.5556\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9314 - accuracy: 0.4889 - val_loss: 0.9445 - val_accuracy: 0.5214\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9297 - accuracy: 0.4963 - val_loss: 0.9441 - val_accuracy: 0.5556\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9295 - accuracy: 0.4926 - val_loss: 0.9445 - val_accuracy: 0.5556\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9299 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5556\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9311 - accuracy: 0.5185 - val_loss: 0.9433 - val_accuracy: 0.5556\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9335 - accuracy: 0.5000 - val_loss: 0.9493 - val_accuracy: 0.5214\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9312 - accuracy: 0.5111 - val_loss: 0.9444 - val_accuracy: 0.5214\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9289 - accuracy: 0.4852 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9287 - accuracy: 0.5185 - val_loss: 0.9456 - val_accuracy: 0.5556\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9290 - accuracy: 0.5185 - val_loss: 0.9447 - val_accuracy: 0.5556\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9295 - accuracy: 0.5185 - val_loss: 0.9440 - val_accuracy: 0.5556\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9292 - accuracy: 0.5185 - val_loss: 0.9430 - val_accuracy: 0.5556\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9273 - accuracy: 0.4889 - val_loss: 0.9437 - val_accuracy: 0.5556\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9286 - accuracy: 0.5185 - val_loss: 0.9436 - val_accuracy: 0.5556\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9276 - accuracy: 0.5222 - val_loss: 0.9458 - val_accuracy: 0.5214\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9270 - accuracy: 0.5037 - val_loss: 0.9442 - val_accuracy: 0.5556\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9275 - accuracy: 0.4778 - val_loss: 0.9457 - val_accuracy: 0.5556\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9261 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5556\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9271 - accuracy: 0.5037 - val_loss: 0.9435 - val_accuracy: 0.5556\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9265 - accuracy: 0.5185 - val_loss: 0.9430 - val_accuracy: 0.5556\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9283 - accuracy: 0.5185 - val_loss: 0.9428 - val_accuracy: 0.5556\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9246 - accuracy: 0.5333 - val_loss: 0.9469 - val_accuracy: 0.5043\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9335 - accuracy: 0.5111 - val_loss: 0.9487 - val_accuracy: 0.5043\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9292 - accuracy: 0.5074 - val_loss: 0.9437 - val_accuracy: 0.5556\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9288 - accuracy: 0.5185 - val_loss: 0.9451 - val_accuracy: 0.5556\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9274 - accuracy: 0.5185 - val_loss: 0.9427 - val_accuracy: 0.5556\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9254 - accuracy: 0.5185 - val_loss: 0.9431 - val_accuracy: 0.5556\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9245 - accuracy: 0.5296 - val_loss: 0.9452 - val_accuracy: 0.5043\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9242 - accuracy: 0.5222 - val_loss: 0.9432 - val_accuracy: 0.5556\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9241 - accuracy: 0.5185 - val_loss: 0.9428 - val_accuracy: 0.5556\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9242 - accuracy: 0.5185 - val_loss: 0.9436 - val_accuracy: 0.5214\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9233 - accuracy: 0.5000 - val_loss: 0.9433 - val_accuracy: 0.5556\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9237 - accuracy: 0.4926 - val_loss: 0.9437 - val_accuracy: 0.5556\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9247 - accuracy: 0.5185 - val_loss: 0.9440 - val_accuracy: 0.5556\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9232 - accuracy: 0.5185 - val_loss: 0.9441 - val_accuracy: 0.5556\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9272 - accuracy: 0.5000 - val_loss: 0.9479 - val_accuracy: 0.5043\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9256 - accuracy: 0.5222 - val_loss: 0.9466 - val_accuracy: 0.5556\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9230 - accuracy: 0.5185 - val_loss: 0.9439 - val_accuracy: 0.5556\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9220 - accuracy: 0.5185 - val_loss: 0.9430 - val_accuracy: 0.5556\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9231 - accuracy: 0.5185 - val_loss: 0.9427 - val_accuracy: 0.5556\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9230 - accuracy: 0.5037 - val_loss: 0.9449 - val_accuracy: 0.5556\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9260 - accuracy: 0.5185 - val_loss: 0.9457 - val_accuracy: 0.5556\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9208 - accuracy: 0.5185 - val_loss: 0.9430 - val_accuracy: 0.5556\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9220 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5214\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9221 - accuracy: 0.5148 - val_loss: 0.9456 - val_accuracy: 0.5128\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9211 - accuracy: 0.5185 - val_loss: 0.9439 - val_accuracy: 0.5214\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9206 - accuracy: 0.5259 - val_loss: 0.9428 - val_accuracy: 0.5556\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9217 - accuracy: 0.4889 - val_loss: 0.9434 - val_accuracy: 0.5556\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9217 - accuracy: 0.5185 - val_loss: 0.9427 - val_accuracy: 0.5556\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9231 - accuracy: 0.5111 - val_loss: 0.9431 - val_accuracy: 0.5641\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9202 - accuracy: 0.5185 - val_loss: 0.9433 - val_accuracy: 0.5556\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9216 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9218 - accuracy: 0.5185 - val_loss: 0.9450 - val_accuracy: 0.5299\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9208 - accuracy: 0.5185 - val_loss: 0.9441 - val_accuracy: 0.5299\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9197 - accuracy: 0.5185 - val_loss: 0.9432 - val_accuracy: 0.5641\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9224 - accuracy: 0.5000 - val_loss: 0.9443 - val_accuracy: 0.5128\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9193 - accuracy: 0.5185 - val_loss: 0.9437 - val_accuracy: 0.5641\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9190 - accuracy: 0.5222 - val_loss: 0.9445 - val_accuracy: 0.5641\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9204 - accuracy: 0.5222 - val_loss: 0.9436 - val_accuracy: 0.5641\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9182 - accuracy: 0.5259 - val_loss: 0.9453 - val_accuracy: 0.5299\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9203 - accuracy: 0.5185 - val_loss: 0.9458 - val_accuracy: 0.5128\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9186 - accuracy: 0.4963 - val_loss: 0.9426 - val_accuracy: 0.5641\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9208 - accuracy: 0.5222 - val_loss: 0.9430 - val_accuracy: 0.5641\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9189 - accuracy: 0.5222 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9199 - accuracy: 0.5074 - val_loss: 0.9457 - val_accuracy: 0.5299\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9191 - accuracy: 0.4963 - val_loss: 0.9436 - val_accuracy: 0.5641\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9174 - accuracy: 0.5148 - val_loss: 0.9422 - val_accuracy: 0.5641\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9198 - accuracy: 0.4963 - val_loss: 0.9426 - val_accuracy: 0.5299\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9184 - accuracy: 0.4963 - val_loss: 0.9444 - val_accuracy: 0.5641\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9190 - accuracy: 0.5148 - val_loss: 0.9440 - val_accuracy: 0.5128\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9179 - accuracy: 0.5259 - val_loss: 0.9433 - val_accuracy: 0.5641\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9176 - accuracy: 0.5222 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9189 - accuracy: 0.5222 - val_loss: 0.9426 - val_accuracy: 0.5641\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9177 - accuracy: 0.5222 - val_loss: 0.9429 - val_accuracy: 0.5641\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9186 - accuracy: 0.4926 - val_loss: 0.9436 - val_accuracy: 0.5128\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9175 - accuracy: 0.5185 - val_loss: 0.9437 - val_accuracy: 0.5299\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9165 - accuracy: 0.5259 - val_loss: 0.9429 - val_accuracy: 0.5641\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9186 - accuracy: 0.5222 - val_loss: 0.9418 - val_accuracy: 0.5641\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9163 - accuracy: 0.5222 - val_loss: 0.9428 - val_accuracy: 0.5641\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9183 - accuracy: 0.5000 - val_loss: 0.9460 - val_accuracy: 0.5128\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9169 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5641\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9176 - accuracy: 0.4963 - val_loss: 0.9448 - val_accuracy: 0.5641\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9175 - accuracy: 0.5222 - val_loss: 0.9444 - val_accuracy: 0.5641\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9165 - accuracy: 0.5222 - val_loss: 0.9429 - val_accuracy: 0.5299\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9183 - accuracy: 0.5185 - val_loss: 0.9441 - val_accuracy: 0.5128\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9156 - accuracy: 0.5185 - val_loss: 0.9417 - val_accuracy: 0.5641\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9153 - accuracy: 0.5222 - val_loss: 0.9443 - val_accuracy: 0.5641\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9147 - accuracy: 0.5259 - val_loss: 0.9456 - val_accuracy: 0.5128\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9175 - accuracy: 0.5185 - val_loss: 0.9454 - val_accuracy: 0.5128\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.9154 - accuracy: 0.5185 - val_loss: 0.9432 - val_accuracy: 0.5128\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9151 - accuracy: 0.5333 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9157 - accuracy: 0.5222 - val_loss: 0.9444 - val_accuracy: 0.5641\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9150 - accuracy: 0.5222 - val_loss: 0.9417 - val_accuracy: 0.5641\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.9137 - accuracy: 0.5222 - val_loss: 0.9415 - val_accuracy: 0.5641\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9161 - accuracy: 0.4852 - val_loss: 0.9449 - val_accuracy: 0.5128\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9144 - accuracy: 0.5111 - val_loss: 0.9417 - val_accuracy: 0.5641\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9145 - accuracy: 0.5222 - val_loss: 0.9431 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9142 - accuracy: 0.5222 - val_loss: 0.9433 - val_accuracy: 0.5641\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9143 - accuracy: 0.5185 - val_loss: 0.9438 - val_accuracy: 0.5128\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9164 - accuracy: 0.5185 - val_loss: 0.9440 - val_accuracy: 0.5128\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.9136 - accuracy: 0.5185 - val_loss: 0.9449 - val_accuracy: 0.5641\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.9141 - accuracy: 0.5222 - val_loss: 0.9431 - val_accuracy: 0.5470\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9142 - accuracy: 0.5074 - val_loss: 0.9437 - val_accuracy: 0.5470\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9127 - accuracy: 0.5000 - val_loss: 0.9434 - val_accuracy: 0.5470\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9143 - accuracy: 0.5222 - val_loss: 0.9433 - val_accuracy: 0.5641\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9144 - accuracy: 0.5222 - val_loss: 0.9428 - val_accuracy: 0.5641\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.9100 - accuracy: 0.5333 - val_loss: 0.9435 - val_accuracy: 0.5128\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.9169 - accuracy: 0.5185 - val_loss: 0.9464 - val_accuracy: 0.5128\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 373us/step - loss: 0.9181 - accuracy: 0.5074 - val_loss: 0.9447 - val_accuracy: 0.5641\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.9119 - accuracy: 0.5222 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9148 - accuracy: 0.5185 - val_loss: 0.9451 - val_accuracy: 0.5128\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.9120 - accuracy: 0.5000 - val_loss: 0.9424 - val_accuracy: 0.5641\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 456us/step - loss: 0.9168 - accuracy: 0.5222 - val_loss: 0.9470 - val_accuracy: 0.5641\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.9136 - accuracy: 0.5222 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.9128 - accuracy: 0.5222 - val_loss: 0.9435 - val_accuracy: 0.5470\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 0.9147 - accuracy: 0.5222 - val_loss: 0.9432 - val_accuracy: 0.5641\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.9117 - accuracy: 0.5148 - val_loss: 0.9448 - val_accuracy: 0.5128\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9124 - accuracy: 0.5185 - val_loss: 0.9459 - val_accuracy: 0.5128\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.9120 - accuracy: 0.5185 - val_loss: 0.9432 - val_accuracy: 0.5470\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9104 - accuracy: 0.5222 - val_loss: 0.9437 - val_accuracy: 0.5641\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9116 - accuracy: 0.5222 - val_loss: 0.9425 - val_accuracy: 0.5641\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9134 - accuracy: 0.5222 - val_loss: 0.9424 - val_accuracy: 0.5641\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9109 - accuracy: 0.5222 - val_loss: 0.9468 - val_accuracy: 0.5128\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9108 - accuracy: 0.5037 - val_loss: 0.9439 - val_accuracy: 0.5470\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9114 - accuracy: 0.5222 - val_loss: 0.9422 - val_accuracy: 0.5470\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9108 - accuracy: 0.5074 - val_loss: 0.9434 - val_accuracy: 0.5128\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9012 - accuracy: 0.43 - 0s 138us/step - loss: 0.9104 - accuracy: 0.5000 - val_loss: 0.9436 - val_accuracy: 0.5470\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9091 - accuracy: 0.5000 - val_loss: 0.9446 - val_accuracy: 0.5128\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9094 - accuracy: 0.5296 - val_loss: 0.9431 - val_accuracy: 0.5641\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.9100 - accuracy: 0.5222 - val_loss: 0.9426 - val_accuracy: 0.5641\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.9104 - accuracy: 0.5111 - val_loss: 0.9452 - val_accuracy: 0.5128\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9089 - accuracy: 0.5074 - val_loss: 0.9431 - val_accuracy: 0.5641\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9108 - accuracy: 0.5222 - val_loss: 0.9417 - val_accuracy: 0.5641\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9118 - accuracy: 0.5222 - val_loss: 0.9427 - val_accuracy: 0.5641\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.9089 - accuracy: 0.5259 - val_loss: 0.9462 - val_accuracy: 0.5128\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9087 - accuracy: 0.5185 - val_loss: 0.9443 - val_accuracy: 0.5641\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9088 - accuracy: 0.5222 - val_loss: 0.9431 - val_accuracy: 0.5641\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9094 - accuracy: 0.5000 - val_loss: 0.9434 - val_accuracy: 0.5470\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9074 - accuracy: 0.5222 - val_loss: 0.9432 - val_accuracy: 0.5641\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9087 - accuracy: 0.5222 - val_loss: 0.9426 - val_accuracy: 0.5641\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9088 - accuracy: 0.5222 - val_loss: 0.9434 - val_accuracy: 0.5641\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9092 - accuracy: 0.4926 - val_loss: 0.9461 - val_accuracy: 0.5128\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9088 - accuracy: 0.5074 - val_loss: 0.9433 - val_accuracy: 0.5128\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9072 - accuracy: 0.5185 - val_loss: 0.9441 - val_accuracy: 0.5128\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 368us/step - loss: 0.9083 - accuracy: 0.4963 - val_loss: 0.9434 - val_accuracy: 0.5641\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.9085 - accuracy: 0.5000 - val_loss: 0.9449 - val_accuracy: 0.5128\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9082 - accuracy: 0.4963 - val_loss: 0.9431 - val_accuracy: 0.5470\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9079 - accuracy: 0.5407 - val_loss: 0.9458 - val_accuracy: 0.5128\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9078 - accuracy: 0.5185 - val_loss: 0.9433 - val_accuracy: 0.5128\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9103 - accuracy: 0.5148 - val_loss: 0.9430 - val_accuracy: 0.5470\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.9077 - accuracy: 0.5259 - val_loss: 0.9439 - val_accuracy: 0.5641\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9088 - accuracy: 0.4852 - val_loss: 0.9495 - val_accuracy: 0.5128\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9060 - accuracy: 0.5185 - val_loss: 0.9448 - val_accuracy: 0.5470\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9183 - accuracy: 0.5222 - val_loss: 0.9462 - val_accuracy: 0.5641\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.9118 - accuracy: 0.5037 - val_loss: 0.9505 - val_accuracy: 0.5128\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9090 - accuracy: 0.5000 - val_loss: 0.9444 - val_accuracy: 0.5470\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9077 - accuracy: 0.5259 - val_loss: 0.9446 - val_accuracy: 0.5128\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9090 - accuracy: 0.5259 - val_loss: 0.9451 - val_accuracy: 0.5470\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9067 - accuracy: 0.5148 - val_loss: 0.9449 - val_accuracy: 0.5128\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9059 - accuracy: 0.5222 - val_loss: 0.9473 - val_accuracy: 0.5128\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9058 - accuracy: 0.5185 - val_loss: 0.9459 - val_accuracy: 0.5641\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9057 - accuracy: 0.5259 - val_loss: 0.9439 - val_accuracy: 0.5641\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 118us/step - loss: 0.9063 - accuracy: 0.5259 - val_loss: 0.9428 - val_accuracy: 0.5641\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9065 - accuracy: 0.5259 - val_loss: 0.9423 - val_accuracy: 0.5641\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9057 - accuracy: 0.5148 - val_loss: 0.9438 - val_accuracy: 0.5128\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9061 - accuracy: 0.5148 - val_loss: 0.9426 - val_accuracy: 0.5641\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9054 - accuracy: 0.5259 - val_loss: 0.9432 - val_accuracy: 0.5641\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9054 - accuracy: 0.5148 - val_loss: 0.9465 - val_accuracy: 0.5128\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9082 - accuracy: 0.5000 - val_loss: 0.9450 - val_accuracy: 0.5641\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9077 - accuracy: 0.5259 - val_loss: 0.9473 - val_accuracy: 0.5128\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9044 - accuracy: 0.5222 - val_loss: 0.9452 - val_accuracy: 0.5128\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9093 - accuracy: 0.4963 - val_loss: 0.9443 - val_accuracy: 0.5641\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9052 - accuracy: 0.5222 - val_loss: 0.9475 - val_accuracy: 0.5128\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9045 - accuracy: 0.5222 - val_loss: 0.9489 - val_accuracy: 0.5128\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9062 - accuracy: 0.5333 - val_loss: 0.9461 - val_accuracy: 0.5641\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9089 - accuracy: 0.5259 - val_loss: 0.9459 - val_accuracy: 0.5470\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9060 - accuracy: 0.5259 - val_loss: 0.9469 - val_accuracy: 0.5470\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9082 - accuracy: 0.4963 - val_loss: 0.9478 - val_accuracy: 0.5128\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9044 - accuracy: 0.5296 - val_loss: 0.9462 - val_accuracy: 0.5641\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9050 - accuracy: 0.5259 - val_loss: 0.9475 - val_accuracy: 0.5641\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9107 - accuracy: 0.4852 - val_loss: 0.9498 - val_accuracy: 0.5128\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9055 - accuracy: 0.5037 - val_loss: 0.9460 - val_accuracy: 0.5128\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9037 - accuracy: 0.5296 - val_loss: 0.9433 - val_accuracy: 0.5641\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9043 - accuracy: 0.5333 - val_loss: 0.9443 - val_accuracy: 0.5470\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9030 - accuracy: 0.5148 - val_loss: 0.9472 - val_accuracy: 0.5128\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9070 - accuracy: 0.5037 - val_loss: 0.9469 - val_accuracy: 0.5470\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9029 - accuracy: 0.5037 - val_loss: 0.9470 - val_accuracy: 0.5128\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9056 - accuracy: 0.5037 - val_loss: 0.9445 - val_accuracy: 0.5641\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9046 - accuracy: 0.5259 - val_loss: 0.9459 - val_accuracy: 0.5641\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9101 - accuracy: 0.5148 - val_loss: 0.9523 - val_accuracy: 0.5128\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9032 - accuracy: 0.5333 - val_loss: 0.9442 - val_accuracy: 0.5470\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9069 - accuracy: 0.5259 - val_loss: 0.9457 - val_accuracy: 0.5641\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9062 - accuracy: 0.4963 - val_loss: 0.9476 - val_accuracy: 0.5128\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9036 - accuracy: 0.5296 - val_loss: 0.9455 - val_accuracy: 0.5128\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9030 - accuracy: 0.5148 - val_loss: 0.9493 - val_accuracy: 0.5470\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9016 - accuracy: 0.5111 - val_loss: 0.9475 - val_accuracy: 0.5128\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.9031 - accuracy: 0.5222 - val_loss: 0.9456 - val_accuracy: 0.5470\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9029 - accuracy: 0.5037 - val_loss: 0.9469 - val_accuracy: 0.5128\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9016 - accuracy: 0.5259 - val_loss: 0.9476 - val_accuracy: 0.5128\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9014 - accuracy: 0.5148 - val_loss: 0.9451 - val_accuracy: 0.5470\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9016 - accuracy: 0.5259 - val_loss: 0.9446 - val_accuracy: 0.5641\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9042 - accuracy: 0.5296 - val_loss: 0.9447 - val_accuracy: 0.5641\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9064 - accuracy: 0.5148 - val_loss: 0.9520 - val_accuracy: 0.5128\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.9103 - accuracy: 0.4778 - val_loss: 0.9453 - val_accuracy: 0.5641\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9016 - accuracy: 0.5259 - val_loss: 0.9481 - val_accuracy: 0.5470\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9028 - accuracy: 0.5185 - val_loss: 0.9489 - val_accuracy: 0.5128\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9034 - accuracy: 0.5222 - val_loss: 0.9454 - val_accuracy: 0.5641\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9009 - accuracy: 0.5333 - val_loss: 0.9445 - val_accuracy: 0.5470\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9023 - accuracy: 0.5111 - val_loss: 0.9478 - val_accuracy: 0.5128\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9007 - accuracy: 0.5222 - val_loss: 0.9443 - val_accuracy: 0.5470\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9011 - accuracy: 0.5333 - val_loss: 0.9439 - val_accuracy: 0.5470\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9063 - accuracy: 0.4926 - val_loss: 0.9464 - val_accuracy: 0.5128\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9022 - accuracy: 0.5111 - val_loss: 0.9463 - val_accuracy: 0.5470\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9000 - accuracy: 0.5259 - val_loss: 0.9464 - val_accuracy: 0.5128\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8997 - accuracy: 0.5296 - val_loss: 0.9466 - val_accuracy: 0.5128\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9011 - accuracy: 0.5259 - val_loss: 0.9490 - val_accuracy: 0.5128\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9025 - accuracy: 0.5185 - val_loss: 0.9454 - val_accuracy: 0.5641\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9024 - accuracy: 0.5333 - val_loss: 0.9466 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.9003 - accuracy: 0.5333 - val_loss: 0.9451 - val_accuracy: 0.5470\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9000 - accuracy: 0.5333 - val_loss: 0.9473 - val_accuracy: 0.5128\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9009 - accuracy: 0.5296 - val_loss: 0.9489 - val_accuracy: 0.5043\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9012 - accuracy: 0.5111 - val_loss: 0.9454 - val_accuracy: 0.5470\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9000 - accuracy: 0.5519 - val_loss: 0.9477 - val_accuracy: 0.5043\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8996 - accuracy: 0.5259 - val_loss: 0.9461 - val_accuracy: 0.5470\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8989 - accuracy: 0.5000 - val_loss: 0.9471 - val_accuracy: 0.5470\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8987 - accuracy: 0.5333 - val_loss: 0.9472 - val_accuracy: 0.5470\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9010 - accuracy: 0.5333 - val_loss: 0.9479 - val_accuracy: 0.5385\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8983 - accuracy: 0.5333 - val_loss: 0.9487 - val_accuracy: 0.5043\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9002 - accuracy: 0.5296 - val_loss: 0.9477 - val_accuracy: 0.5043\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9022 - accuracy: 0.5296 - val_loss: 0.9469 - val_accuracy: 0.5641\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9000 - accuracy: 0.5333 - val_loss: 0.9462 - val_accuracy: 0.5470\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8977 - accuracy: 0.5333 - val_loss: 0.9446 - val_accuracy: 0.5470\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8983 - accuracy: 0.5333 - val_loss: 0.9448 - val_accuracy: 0.5385\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9046 - accuracy: 0.4852 - val_loss: 0.9461 - val_accuracy: 0.5641\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9036 - accuracy: 0.5222 - val_loss: 0.9497 - val_accuracy: 0.5043\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8980 - accuracy: 0.5444 - val_loss: 0.9465 - val_accuracy: 0.5385\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9054 - accuracy: 0.5333 - val_loss: 0.9459 - val_accuracy: 0.5641\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9016 - accuracy: 0.5185 - val_loss: 0.9494 - val_accuracy: 0.5043\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9001 - accuracy: 0.5148 - val_loss: 0.9452 - val_accuracy: 0.5385\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8985 - accuracy: 0.5333 - val_loss: 0.9458 - val_accuracy: 0.5385\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8987 - accuracy: 0.5333 - val_loss: 0.9459 - val_accuracy: 0.5385\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9010 - accuracy: 0.5259 - val_loss: 0.9480 - val_accuracy: 0.5043\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9001 - accuracy: 0.5444 - val_loss: 0.9487 - val_accuracy: 0.5385\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9004 - accuracy: 0.5333 - val_loss: 0.9479 - val_accuracy: 0.5556\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8979 - accuracy: 0.5333 - val_loss: 0.9481 - val_accuracy: 0.5385\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8971 - accuracy: 0.5370 - val_loss: 0.9484 - val_accuracy: 0.5043\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8999 - accuracy: 0.5296 - val_loss: 0.9471 - val_accuracy: 0.5043\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8991 - accuracy: 0.5296 - val_loss: 0.9455 - val_accuracy: 0.5385\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8975 - accuracy: 0.5333 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8984 - accuracy: 0.5185 - val_loss: 0.9480 - val_accuracy: 0.5043\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8964 - accuracy: 0.5481 - val_loss: 0.9466 - val_accuracy: 0.5385\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9004 - accuracy: 0.5074 - val_loss: 0.9463 - val_accuracy: 0.5385\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8986 - accuracy: 0.5333 - val_loss: 0.9466 - val_accuracy: 0.5556\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8961 - accuracy: 0.5333 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8972 - accuracy: 0.5148 - val_loss: 0.9487 - val_accuracy: 0.5043\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8967 - accuracy: 0.5444 - val_loss: 0.9478 - val_accuracy: 0.5385\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8979 - accuracy: 0.5333 - val_loss: 0.9472 - val_accuracy: 0.5385\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8988 - accuracy: 0.5333 - val_loss: 0.9490 - val_accuracy: 0.5385\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8961 - accuracy: 0.5333 - val_loss: 0.9472 - val_accuracy: 0.5385\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8954 - accuracy: 0.5333 - val_loss: 0.9466 - val_accuracy: 0.5385\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8980 - accuracy: 0.5148 - val_loss: 0.9476 - val_accuracy: 0.5043\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8961 - accuracy: 0.5259 - val_loss: 0.9465 - val_accuracy: 0.5385\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8964 - accuracy: 0.5185 - val_loss: 0.9492 - val_accuracy: 0.5385\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8978 - accuracy: 0.5333 - val_loss: 0.9481 - val_accuracy: 0.5385\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8974 - accuracy: 0.5333 - val_loss: 0.9457 - val_accuracy: 0.5385\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8952 - accuracy: 0.5259 - val_loss: 0.9475 - val_accuracy: 0.5043\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8954 - accuracy: 0.5296 - val_loss: 0.9496 - val_accuracy: 0.5043\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8961 - accuracy: 0.5370 - val_loss: 0.9483 - val_accuracy: 0.5385\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8956 - accuracy: 0.5333 - val_loss: 0.9464 - val_accuracy: 0.5556\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8965 - accuracy: 0.5333 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8963 - accuracy: 0.5259 - val_loss: 0.9497 - val_accuracy: 0.5043\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8954 - accuracy: 0.5296 - val_loss: 0.9486 - val_accuracy: 0.5385\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8958 - accuracy: 0.5074 - val_loss: 0.9480 - val_accuracy: 0.5385\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8955 - accuracy: 0.5185 - val_loss: 0.9487 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8952 - accuracy: 0.5333 - val_loss: 0.9479 - val_accuracy: 0.5385\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8968 - accuracy: 0.5074 - val_loss: 0.9490 - val_accuracy: 0.5043\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8937 - accuracy: 0.5148 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8973 - accuracy: 0.5333 - val_loss: 0.9473 - val_accuracy: 0.5385\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8957 - accuracy: 0.5333 - val_loss: 0.9480 - val_accuracy: 0.5043\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8947 - accuracy: 0.5296 - val_loss: 0.9505 - val_accuracy: 0.5043\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8982 - accuracy: 0.5259 - val_loss: 0.9486 - val_accuracy: 0.5385\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8980 - accuracy: 0.5333 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8948 - accuracy: 0.5222 - val_loss: 0.9462 - val_accuracy: 0.5043\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8966 - accuracy: 0.5185 - val_loss: 0.9443 - val_accuracy: 0.5385\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8962 - accuracy: 0.5185 - val_loss: 0.9456 - val_accuracy: 0.5043\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8951 - accuracy: 0.5370 - val_loss: 0.9481 - val_accuracy: 0.5385\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8951 - accuracy: 0.5333 - val_loss: 0.9463 - val_accuracy: 0.5385\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.50 - 0s 64us/step - loss: 0.8954 - accuracy: 0.5333 - val_loss: 0.9467 - val_accuracy: 0.5385\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8980 - accuracy: 0.5333 - val_loss: 0.9468 - val_accuracy: 0.5385\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8967 - accuracy: 0.5111 - val_loss: 0.9510 - val_accuracy: 0.5385\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8999 - accuracy: 0.5333 - val_loss: 0.9495 - val_accuracy: 0.5385\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8997 - accuracy: 0.5333 - val_loss: 0.9492 - val_accuracy: 0.5385\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8968 - accuracy: 0.5111 - val_loss: 0.9508 - val_accuracy: 0.5043\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8939 - accuracy: 0.5444 - val_loss: 0.9493 - val_accuracy: 0.5385\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8950 - accuracy: 0.5333 - val_loss: 0.9498 - val_accuracy: 0.5385\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8947 - accuracy: 0.4889 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8963 - accuracy: 0.5333 - val_loss: 0.9519 - val_accuracy: 0.5385\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8942 - accuracy: 0.5333 - val_loss: 0.9486 - val_accuracy: 0.5385\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8948 - accuracy: 0.5481 - val_loss: 0.9503 - val_accuracy: 0.5043\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8959 - accuracy: 0.5185 - val_loss: 0.9484 - val_accuracy: 0.5385\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8978 - accuracy: 0.5259 - val_loss: 0.9567 - val_accuracy: 0.5043\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8952 - accuracy: 0.5296 - val_loss: 0.9500 - val_accuracy: 0.5385\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8946 - accuracy: 0.5333 - val_loss: 0.9497 - val_accuracy: 0.5385\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8942 - accuracy: 0.5111 - val_loss: 0.9496 - val_accuracy: 0.5043\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8939 - accuracy: 0.5296 - val_loss: 0.9479 - val_accuracy: 0.5043\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8930 - accuracy: 0.5296 - val_loss: 0.9466 - val_accuracy: 0.5385\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8938 - accuracy: 0.5222 - val_loss: 0.9480 - val_accuracy: 0.5043\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8943 - accuracy: 0.5296 - val_loss: 0.9506 - val_accuracy: 0.5385\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8976 - accuracy: 0.5333 - val_loss: 0.9478 - val_accuracy: 0.5385\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.9009 - accuracy: 0.5222 - val_loss: 0.9518 - val_accuracy: 0.5043\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8934 - accuracy: 0.5296 - val_loss: 0.9490 - val_accuracy: 0.5385\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8963 - accuracy: 0.5333 - val_loss: 0.9504 - val_accuracy: 0.5385\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8981 - accuracy: 0.5185 - val_loss: 0.9540 - val_accuracy: 0.5043\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8935 - accuracy: 0.5444 - val_loss: 0.9504 - val_accuracy: 0.5385\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8923 - accuracy: 0.5333 - val_loss: 0.9508 - val_accuracy: 0.5385\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8934 - accuracy: 0.5333 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8930 - accuracy: 0.5333 - val_loss: 0.9473 - val_accuracy: 0.5385\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.56 - 0s 90us/step - loss: 0.8960 - accuracy: 0.5333 - val_loss: 0.9475 - val_accuracy: 0.5385\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8955 - accuracy: 0.5333 - val_loss: 0.9488 - val_accuracy: 0.5385\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8940 - accuracy: 0.5185 - val_loss: 0.9509 - val_accuracy: 0.5043\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8928 - accuracy: 0.5148 - val_loss: 0.9490 - val_accuracy: 0.5385\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8937 - accuracy: 0.5333 - val_loss: 0.9479 - val_accuracy: 0.5385\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8922 - accuracy: 0.5333 - val_loss: 0.9493 - val_accuracy: 0.5385\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8938 - accuracy: 0.5333 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8943 - accuracy: 0.5037 - val_loss: 0.9509 - val_accuracy: 0.5043\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.75 - 0s 65us/step - loss: 0.8939 - accuracy: 0.5185 - val_loss: 0.9512 - val_accuracy: 0.5385\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8934 - accuracy: 0.5333 - val_loss: 0.9501 - val_accuracy: 0.5385\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8933 - accuracy: 0.4926 - val_loss: 0.9508 - val_accuracy: 0.5043\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8941 - accuracy: 0.5296 - val_loss: 0.9506 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8918 - accuracy: 0.5296 - val_loss: 0.9508 - val_accuracy: 0.5043\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8919 - accuracy: 0.5296 - val_loss: 0.9510 - val_accuracy: 0.5043\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8942 - accuracy: 0.5333 - val_loss: 0.9498 - val_accuracy: 0.5385\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8920 - accuracy: 0.5185 - val_loss: 0.9542 - val_accuracy: 0.5043\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8937 - accuracy: 0.5185 - val_loss: 0.9495 - val_accuracy: 0.5385\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8922 - accuracy: 0.5259 - val_loss: 0.9520 - val_accuracy: 0.5043\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8932 - accuracy: 0.5296 - val_loss: 0.9521 - val_accuracy: 0.5043\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8893 - accuracy: 0.5481 - val_loss: 0.9515 - val_accuracy: 0.5385\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8948 - accuracy: 0.5333 - val_loss: 0.9507 - val_accuracy: 0.5385\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8910 - accuracy: 0.5148 - val_loss: 0.9536 - val_accuracy: 0.5043\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8939 - accuracy: 0.5296 - val_loss: 0.9537 - val_accuracy: 0.5043\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8901 - accuracy: 0.5222 - val_loss: 0.9492 - val_accuracy: 0.5385\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8916 - accuracy: 0.5222 - val_loss: 0.9495 - val_accuracy: 0.5385\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8927 - accuracy: 0.5333 - val_loss: 0.9504 - val_accuracy: 0.5385\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8902 - accuracy: 0.5333 - val_loss: 0.9515 - val_accuracy: 0.5385\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8925 - accuracy: 0.5333 - val_loss: 0.9507 - val_accuracy: 0.5385\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8908 - accuracy: 0.5222 - val_loss: 0.9530 - val_accuracy: 0.5043\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8908 - accuracy: 0.5296 - val_loss: 0.9498 - val_accuracy: 0.5385\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8909 - accuracy: 0.5333 - val_loss: 0.9479 - val_accuracy: 0.5385\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8929 - accuracy: 0.5333 - val_loss: 0.9487 - val_accuracy: 0.5385\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8906 - accuracy: 0.5333 - val_loss: 0.9524 - val_accuracy: 0.5043\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8910 - accuracy: 0.5296 - val_loss: 0.9544 - val_accuracy: 0.5043\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8907 - accuracy: 0.5333 - val_loss: 0.9520 - val_accuracy: 0.5385\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8911 - accuracy: 0.5148 - val_loss: 0.9531 - val_accuracy: 0.5043\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8911 - accuracy: 0.5296 - val_loss: 0.9520 - val_accuracy: 0.5043\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8915 - accuracy: 0.5185 - val_loss: 0.9517 - val_accuracy: 0.5385\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8904 - accuracy: 0.5148 - val_loss: 0.9527 - val_accuracy: 0.5043\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8894 - accuracy: 0.5111 - val_loss: 0.9523 - val_accuracy: 0.5385\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 431us/step - loss: 0.8907 - accuracy: 0.5333 - val_loss: 0.9525 - val_accuracy: 0.5385\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 687us/step - loss: 0.8884 - accuracy: 0.5259 - val_loss: 0.9529 - val_accuracy: 0.5043\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8898 - accuracy: 0.5259 - val_loss: 0.9516 - val_accuracy: 0.5385\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8897 - accuracy: 0.5333 - val_loss: 0.9529 - val_accuracy: 0.5385\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 519us/step - loss: 0.8889 - accuracy: 0.5148 - val_loss: 0.9517 - val_accuracy: 0.5043\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8905 - accuracy: 0.5296 - val_loss: 0.9507 - val_accuracy: 0.5385\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8908 - accuracy: 0.5333 - val_loss: 0.9494 - val_accuracy: 0.5385\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8887 - accuracy: 0.5333 - val_loss: 0.9526 - val_accuracy: 0.5385\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8907 - accuracy: 0.5111 - val_loss: 0.9575 - val_accuracy: 0.5043\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8944 - accuracy: 0.4963 - val_loss: 0.9511 - val_accuracy: 0.5385\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8900 - accuracy: 0.5259 - val_loss: 0.9527 - val_accuracy: 0.5043\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8904 - accuracy: 0.5296 - val_loss: 0.9532 - val_accuracy: 0.5043\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.8897 - accuracy: 0.5074 - val_loss: 0.9526 - val_accuracy: 0.5385\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.8895 - accuracy: 0.5333 - val_loss: 0.9522 - val_accuracy: 0.5043\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8924 - accuracy: 0.5296 - val_loss: 0.9536 - val_accuracy: 0.5043\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8877 - accuracy: 0.5370 - val_loss: 0.9534 - val_accuracy: 0.5385\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 0.8906 - accuracy: 0.5333 - val_loss: 0.9535 - val_accuracy: 0.5385\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8908 - accuracy: 0.5333 - val_loss: 0.9526 - val_accuracy: 0.5385\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8945 - accuracy: 0.5000 - val_loss: 0.9531 - val_accuracy: 0.5043\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8891 - accuracy: 0.5407 - val_loss: 0.9519 - val_accuracy: 0.5385\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8889 - accuracy: 0.5333 - val_loss: 0.9520 - val_accuracy: 0.5385\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 350us/step - loss: 0.8883 - accuracy: 0.5407 - val_loss: 0.9525 - val_accuracy: 0.5043\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8879 - accuracy: 0.5296 - val_loss: 0.9523 - val_accuracy: 0.5043\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8894 - accuracy: 0.5407 - val_loss: 0.9525 - val_accuracy: 0.5385\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8876 - accuracy: 0.5333 - val_loss: 0.9496 - val_accuracy: 0.5385\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8901 - accuracy: 0.5148 - val_loss: 0.9522 - val_accuracy: 0.5043\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.8950 - accuracy: 0.5222 - val_loss: 0.9548 - val_accuracy: 0.5385\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8871 - accuracy: 0.5333 - val_loss: 0.9549 - val_accuracy: 0.5043\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 524us/step - loss: 0.8887 - accuracy: 0.5296 - val_loss: 0.9541 - val_accuracy: 0.5043\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8892 - accuracy: 0.5296 - val_loss: 0.9524 - val_accuracy: 0.5043\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8875 - accuracy: 0.5296 - val_loss: 0.9522 - val_accuracy: 0.5385\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.8882 - accuracy: 0.5333 - val_loss: 0.9529 - val_accuracy: 0.5385\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8887 - accuracy: 0.5148 - val_loss: 0.9554 - val_accuracy: 0.5043\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8878 - accuracy: 0.5296 - val_loss: 0.9528 - val_accuracy: 0.5385\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8929 - accuracy: 0.5333 - val_loss: 0.9536 - val_accuracy: 0.5385\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8865 - accuracy: 0.5370 - val_loss: 0.9527 - val_accuracy: 0.5043\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8887 - accuracy: 0.5296 - val_loss: 0.9524 - val_accuracy: 0.5043\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8870 - accuracy: 0.5296 - val_loss: 0.9521 - val_accuracy: 0.5043\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8886 - accuracy: 0.5222 - val_loss: 0.9539 - val_accuracy: 0.5385\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8870 - accuracy: 0.5333 - val_loss: 0.9507 - val_accuracy: 0.5385\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8950 - accuracy: 0.5259 - val_loss: 0.9526 - val_accuracy: 0.5043\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8879 - accuracy: 0.5185 - val_loss: 0.9537 - val_accuracy: 0.5385\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8880 - accuracy: 0.5296 - val_loss: 0.9547 - val_accuracy: 0.5043\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8876 - accuracy: 0.5037 - val_loss: 0.9545 - val_accuracy: 0.5043\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8872 - accuracy: 0.5296 - val_loss: 0.9540 - val_accuracy: 0.5385\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8874 - accuracy: 0.5333 - val_loss: 0.9516 - val_accuracy: 0.5385\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8875 - accuracy: 0.5148 - val_loss: 0.9536 - val_accuracy: 0.5043\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8874 - accuracy: 0.4852 - val_loss: 0.9551 - val_accuracy: 0.5385\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8869 - accuracy: 0.5333 - val_loss: 0.9529 - val_accuracy: 0.5385\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8897 - accuracy: 0.5259 - val_loss: 0.9565 - val_accuracy: 0.5043\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8890 - accuracy: 0.5296 - val_loss: 0.9512 - val_accuracy: 0.5385\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8897 - accuracy: 0.4926 - val_loss: 0.9519 - val_accuracy: 0.5385\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8871 - accuracy: 0.5333 - val_loss: 0.9510 - val_accuracy: 0.5385\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8901 - accuracy: 0.5333 - val_loss: 0.9512 - val_accuracy: 0.5385\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8889 - accuracy: 0.5222 - val_loss: 0.9578 - val_accuracy: 0.5043\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8955 - accuracy: 0.4852 - val_loss: 0.9541 - val_accuracy: 0.5385\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8875 - accuracy: 0.5370 - val_loss: 0.9566 - val_accuracy: 0.5043\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8891 - accuracy: 0.5296 - val_loss: 0.9571 - val_accuracy: 0.5043\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8881 - accuracy: 0.5296 - val_loss: 0.9541 - val_accuracy: 0.5385\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8866 - accuracy: 0.5333 - val_loss: 0.9561 - val_accuracy: 0.5385\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8880 - accuracy: 0.5333 - val_loss: 0.9544 - val_accuracy: 0.5385\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8866 - accuracy: 0.5333 - val_loss: 0.9564 - val_accuracy: 0.5385\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8899 - accuracy: 0.5333 - val_loss: 0.9545 - val_accuracy: 0.5385\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8873 - accuracy: 0.4778 - val_loss: 0.9552 - val_accuracy: 0.5385\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8867 - accuracy: 0.5333 - val_loss: 0.9553 - val_accuracy: 0.5385\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8859 - accuracy: 0.5333 - val_loss: 0.9530 - val_accuracy: 0.5385\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8858 - accuracy: 0.5333 - val_loss: 0.9535 - val_accuracy: 0.5385\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8880 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8864 - accuracy: 0.5333 - val_loss: 0.9509 - val_accuracy: 0.5385\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8864 - accuracy: 0.5333 - val_loss: 0.9519 - val_accuracy: 0.5385\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8873 - accuracy: 0.5333 - val_loss: 0.9530 - val_accuracy: 0.5385\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8840 - accuracy: 0.5333 - val_loss: 0.9550 - val_accuracy: 0.5043\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8866 - accuracy: 0.5296 - val_loss: 0.9600 - val_accuracy: 0.5043\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8872 - accuracy: 0.5296 - val_loss: 0.9553 - val_accuracy: 0.5385\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8879 - accuracy: 0.5333 - val_loss: 0.9583 - val_accuracy: 0.5385\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8878 - accuracy: 0.5185 - val_loss: 0.9570 - val_accuracy: 0.5043\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8843 - accuracy: 0.5333 - val_loss: 0.9528 - val_accuracy: 0.5385\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8939 - accuracy: 0.5333 - val_loss: 0.9558 - val_accuracy: 0.5385\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8905 - accuracy: 0.5333 - val_loss: 0.9558 - val_accuracy: 0.5385\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8910 - accuracy: 0.5074 - val_loss: 0.9580 - val_accuracy: 0.5043\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8857 - accuracy: 0.5333 - val_loss: 0.9577 - val_accuracy: 0.5385\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8861 - accuracy: 0.5333 - val_loss: 0.9549 - val_accuracy: 0.5385\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 121us/step - loss: 0.8883 - accuracy: 0.5185 - val_loss: 0.9564 - val_accuracy: 0.5043\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8872 - accuracy: 0.5296 - val_loss: 0.9592 - val_accuracy: 0.5043\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8875 - accuracy: 0.5630 - val_loss: 0.9599 - val_accuracy: 0.5385\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8902 - accuracy: 0.5333 - val_loss: 0.9548 - val_accuracy: 0.5385\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8853 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8844 - accuracy: 0.5370 - val_loss: 0.9560 - val_accuracy: 0.5043\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8865 - accuracy: 0.5296 - val_loss: 0.9557 - val_accuracy: 0.5043\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8838 - accuracy: 0.5333 - val_loss: 0.9535 - val_accuracy: 0.5385\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8836 - accuracy: 0.5333 - val_loss: 0.9529 - val_accuracy: 0.5385\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.8861 - accuracy: 0.5333 - val_loss: 0.9557 - val_accuracy: 0.5385\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8839 - accuracy: 0.5259 - val_loss: 0.9563 - val_accuracy: 0.5043\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8898 - accuracy: 0.5296 - val_loss: 0.9551 - val_accuracy: 0.5043\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8849 - accuracy: 0.5185 - val_loss: 0.9532 - val_accuracy: 0.5385\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8833 - accuracy: 0.5333 - val_loss: 0.9551 - val_accuracy: 0.5385\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8854 - accuracy: 0.5333 - val_loss: 0.9544 - val_accuracy: 0.5385\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8854 - accuracy: 0.5333 - val_loss: 0.9552 - val_accuracy: 0.5385\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8838 - accuracy: 0.5296 - val_loss: 0.9575 - val_accuracy: 0.5043\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8916 - accuracy: 0.5296 - val_loss: 0.9631 - val_accuracy: 0.5043\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8859 - accuracy: 0.5296 - val_loss: 0.9517 - val_accuracy: 0.5385\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8874 - accuracy: 0.5333 - val_loss: 0.9534 - val_accuracy: 0.5385\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8840 - accuracy: 0.5333 - val_loss: 0.9540 - val_accuracy: 0.5385\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8845 - accuracy: 0.5370 - val_loss: 0.9542 - val_accuracy: 0.5043\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8839 - accuracy: 0.5296 - val_loss: 0.9556 - val_accuracy: 0.5043\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8834 - accuracy: 0.5296 - val_loss: 0.9547 - val_accuracy: 0.5385\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8840 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8844 - accuracy: 0.5333 - val_loss: 0.9542 - val_accuracy: 0.5385\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8818 - accuracy: 0.5185 - val_loss: 0.9567 - val_accuracy: 0.5043\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8862 - accuracy: 0.5296 - val_loss: 0.9587 - val_accuracy: 0.5043\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8850 - accuracy: 0.5481 - val_loss: 0.9577 - val_accuracy: 0.5385\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8874 - accuracy: 0.5333 - val_loss: 0.9524 - val_accuracy: 0.5385\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8862 - accuracy: 0.5296 - val_loss: 0.9554 - val_accuracy: 0.5043\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8836 - accuracy: 0.5407 - val_loss: 0.9533 - val_accuracy: 0.5385\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8871 - accuracy: 0.5148 - val_loss: 0.9555 - val_accuracy: 0.5385\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8858 - accuracy: 0.5333 - val_loss: 0.9542 - val_accuracy: 0.5385\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8855 - accuracy: 0.5333 - val_loss: 0.9545 - val_accuracy: 0.5385\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8854 - accuracy: 0.5333 - val_loss: 0.9534 - val_accuracy: 0.5385\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8873 - accuracy: 0.5333 - val_loss: 0.9532 - val_accuracy: 0.5385\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8888 - accuracy: 0.5148 - val_loss: 0.9581 - val_accuracy: 0.5043\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8901 - accuracy: 0.4963 - val_loss: 0.9557 - val_accuracy: 0.5385\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8839 - accuracy: 0.5407 - val_loss: 0.9562 - val_accuracy: 0.5043\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8839 - accuracy: 0.5148 - val_loss: 0.9528 - val_accuracy: 0.5385\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8844 - accuracy: 0.5111 - val_loss: 0.9553 - val_accuracy: 0.5043\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8826 - accuracy: 0.5296 - val_loss: 0.9547 - val_accuracy: 0.5385\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8829 - accuracy: 0.5333 - val_loss: 0.9528 - val_accuracy: 0.5385\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8840 - accuracy: 0.5074 - val_loss: 0.9538 - val_accuracy: 0.5043\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8836 - accuracy: 0.5074 - val_loss: 0.9536 - val_accuracy: 0.5385\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8844 - accuracy: 0.5444 - val_loss: 0.9561 - val_accuracy: 0.5043\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8830 - accuracy: 0.5296 - val_loss: 0.9561 - val_accuracy: 0.5043\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8839 - accuracy: 0.5296 - val_loss: 0.9551 - val_accuracy: 0.5385\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8843 - accuracy: 0.5333 - val_loss: 0.9536 - val_accuracy: 0.5385\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8836 - accuracy: 0.5333 - val_loss: 0.9555 - val_accuracy: 0.5385\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8814 - accuracy: 0.5407 - val_loss: 0.9574 - val_accuracy: 0.5043\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8867 - accuracy: 0.5296 - val_loss: 0.9629 - val_accuracy: 0.5043\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8826 - accuracy: 0.5296 - val_loss: 0.9567 - val_accuracy: 0.5385\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8820 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8921 - accuracy: 0.5333 - val_loss: 0.9541 - val_accuracy: 0.5385\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8900 - accuracy: 0.5037 - val_loss: 0.9643 - val_accuracy: 0.5043\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8904 - accuracy: 0.5296 - val_loss: 0.9559 - val_accuracy: 0.5043\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8873 - accuracy: 0.5259 - val_loss: 0.9556 - val_accuracy: 0.5385\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8816 - accuracy: 0.5333 - val_loss: 0.9551 - val_accuracy: 0.5385\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8820 - accuracy: 0.5333 - val_loss: 0.9581 - val_accuracy: 0.5043\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8829 - accuracy: 0.5296 - val_loss: 0.9548 - val_accuracy: 0.5043\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8828 - accuracy: 0.5259 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8831 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8831 - accuracy: 0.5259 - val_loss: 0.9582 - val_accuracy: 0.5043\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8834 - accuracy: 0.5296 - val_loss: 0.9591 - val_accuracy: 0.5043\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8830 - accuracy: 0.5222 - val_loss: 0.9569 - val_accuracy: 0.5385\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8835 - accuracy: 0.5333 - val_loss: 0.9566 - val_accuracy: 0.5385\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8804 - accuracy: 0.5296 - val_loss: 0.9561 - val_accuracy: 0.5043\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8810 - accuracy: 0.5296 - val_loss: 0.9562 - val_accuracy: 0.5043\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8813 - accuracy: 0.5148 - val_loss: 0.9556 - val_accuracy: 0.5385\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8806 - accuracy: 0.5333 - val_loss: 0.9549 - val_accuracy: 0.5385\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8829 - accuracy: 0.5037 - val_loss: 0.9559 - val_accuracy: 0.5043\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8826 - accuracy: 0.5111 - val_loss: 0.9539 - val_accuracy: 0.5385\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8838 - accuracy: 0.5333 - val_loss: 0.9571 - val_accuracy: 0.5385\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8836 - accuracy: 0.5333 - val_loss: 0.9549 - val_accuracy: 0.5385\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8816 - accuracy: 0.5259 - val_loss: 0.9586 - val_accuracy: 0.5043\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8819 - accuracy: 0.5296 - val_loss: 0.9572 - val_accuracy: 0.5043\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8821 - accuracy: 0.5333 - val_loss: 0.9542 - val_accuracy: 0.5385\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8843 - accuracy: 0.5333 - val_loss: 0.9565 - val_accuracy: 0.5385\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8803 - accuracy: 0.5222 - val_loss: 0.9554 - val_accuracy: 0.5043\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8818 - accuracy: 0.4963 - val_loss: 0.9536 - val_accuracy: 0.5043\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8810 - accuracy: 0.4926 - val_loss: 0.9548 - val_accuracy: 0.5043\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8807 - accuracy: 0.5111 - val_loss: 0.9535 - val_accuracy: 0.5385\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8805 - accuracy: 0.5444 - val_loss: 0.9554 - val_accuracy: 0.5043\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8816 - accuracy: 0.5296 - val_loss: 0.9574 - val_accuracy: 0.5043\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8807 - accuracy: 0.5259 - val_loss: 0.9554 - val_accuracy: 0.5385\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8829 - accuracy: 0.5074 - val_loss: 0.9552 - val_accuracy: 0.5043\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8818 - accuracy: 0.5222 - val_loss: 0.9549 - val_accuracy: 0.5385\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8812 - accuracy: 0.5185 - val_loss: 0.9539 - val_accuracy: 0.5043\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8815 - accuracy: 0.5370 - val_loss: 0.9522 - val_accuracy: 0.5385\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8826 - accuracy: 0.5333 - val_loss: 0.9540 - val_accuracy: 0.5385\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8822 - accuracy: 0.5370 - val_loss: 0.9579 - val_accuracy: 0.5043\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8820 - accuracy: 0.5111 - val_loss: 0.9567 - val_accuracy: 0.5385\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8842 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8804 - accuracy: 0.5333 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8803 - accuracy: 0.5259 - val_loss: 0.9571 - val_accuracy: 0.5043\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8807 - accuracy: 0.5370 - val_loss: 0.9553 - val_accuracy: 0.5385\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8836 - accuracy: 0.5333 - val_loss: 0.9541 - val_accuracy: 0.5385\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 393us/step - loss: 0.8813 - accuracy: 0.5333 - val_loss: 0.9564 - val_accuracy: 0.5385\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8809 - accuracy: 0.5000 - val_loss: 0.9584 - val_accuracy: 0.5043\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8847 - accuracy: 0.4963 - val_loss: 0.9556 - val_accuracy: 0.5385\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8835 - accuracy: 0.5111 - val_loss: 0.9596 - val_accuracy: 0.5043\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8796 - accuracy: 0.5296 - val_loss: 0.9552 - val_accuracy: 0.5385\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8844 - accuracy: 0.4963 - val_loss: 0.9568 - val_accuracy: 0.5043\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8815 - accuracy: 0.5222 - val_loss: 0.9565 - val_accuracy: 0.5385\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8802 - accuracy: 0.5074 - val_loss: 0.9577 - val_accuracy: 0.5043\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8797 - accuracy: 0.5185 - val_loss: 0.9566 - val_accuracy: 0.5385\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8795 - accuracy: 0.5333 - val_loss: 0.9566 - val_accuracy: 0.5385\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8864 - accuracy: 0.5259 - val_loss: 0.9588 - val_accuracy: 0.5043\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 97us/step - loss: 0.8827 - accuracy: 0.5407 - val_loss: 0.9585 - val_accuracy: 0.5385\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8873 - accuracy: 0.5333 - val_loss: 0.9574 - val_accuracy: 0.5385\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8904 - accuracy: 0.5037 - val_loss: 0.9647 - val_accuracy: 0.5043\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8816 - accuracy: 0.5259 - val_loss: 0.9567 - val_accuracy: 0.5385\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8803 - accuracy: 0.5333 - val_loss: 0.9564 - val_accuracy: 0.5385\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8811 - accuracy: 0.5333 - val_loss: 0.9620 - val_accuracy: 0.5385\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8818 - accuracy: 0.5296 - val_loss: 0.9634 - val_accuracy: 0.5043\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8787 - accuracy: 0.4926 - val_loss: 0.9588 - val_accuracy: 0.5043\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8798 - accuracy: 0.5222 - val_loss: 0.9581 - val_accuracy: 0.5385\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8797 - accuracy: 0.5111 - val_loss: 0.9570 - val_accuracy: 0.5385\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8803 - accuracy: 0.5296 - val_loss: 0.9590 - val_accuracy: 0.5043\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8789 - accuracy: 0.5296 - val_loss: 0.9592 - val_accuracy: 0.5385\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8813 - accuracy: 0.5333 - val_loss: 0.9559 - val_accuracy: 0.5385\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8800 - accuracy: 0.5185 - val_loss: 0.9580 - val_accuracy: 0.5043\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8806 - accuracy: 0.5037 - val_loss: 0.9575 - val_accuracy: 0.5043\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8793 - accuracy: 0.5296 - val_loss: 0.9588 - val_accuracy: 0.5385\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8804 - accuracy: 0.5000 - val_loss: 0.9589 - val_accuracy: 0.5385\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8802 - accuracy: 0.5333 - val_loss: 0.9553 - val_accuracy: 0.5385\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8864 - accuracy: 0.5333 - val_loss: 0.9554 - val_accuracy: 0.5385\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8795 - accuracy: 0.5259 - val_loss: 0.9606 - val_accuracy: 0.5043\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8790 - accuracy: 0.5296 - val_loss: 0.9618 - val_accuracy: 0.5043\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8816 - accuracy: 0.5259 - val_loss: 0.9632 - val_accuracy: 0.5385\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8791 - accuracy: 0.5333 - val_loss: 0.9578 - val_accuracy: 0.5385\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8792 - accuracy: 0.5333 - val_loss: 0.9582 - val_accuracy: 0.5385\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8790 - accuracy: 0.5148 - val_loss: 0.9611 - val_accuracy: 0.5385\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8792 - accuracy: 0.5185 - val_loss: 0.9634 - val_accuracy: 0.5043\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8810 - accuracy: 0.5148 - val_loss: 0.9591 - val_accuracy: 0.5385\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8847 - accuracy: 0.5333 - val_loss: 0.9598 - val_accuracy: 0.5043\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8813 - accuracy: 0.5296 - val_loss: 0.9569 - val_accuracy: 0.5385\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8784 - accuracy: 0.5333 - val_loss: 0.9574 - val_accuracy: 0.5385\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8784 - accuracy: 0.5333 - val_loss: 0.9592 - val_accuracy: 0.5385\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8813 - accuracy: 0.5185 - val_loss: 0.9622 - val_accuracy: 0.5043\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8814 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5043\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8796 - accuracy: 0.5148 - val_loss: 0.9567 - val_accuracy: 0.5385\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8772 - accuracy: 0.5333 - val_loss: 0.9579 - val_accuracy: 0.5385\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8791 - accuracy: 0.5333 - val_loss: 0.9624 - val_accuracy: 0.5128\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8804 - accuracy: 0.5333 - val_loss: 0.9582 - val_accuracy: 0.5043\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8777 - accuracy: 0.5370 - val_loss: 0.9566 - val_accuracy: 0.5385\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8821 - accuracy: 0.5333 - val_loss: 0.9597 - val_accuracy: 0.5385\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8815 - accuracy: 0.4815 - val_loss: 0.9587 - val_accuracy: 0.5043\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8802 - accuracy: 0.5259 - val_loss: 0.9574 - val_accuracy: 0.5385\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8782 - accuracy: 0.5333 - val_loss: 0.9564 - val_accuracy: 0.5385\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8794 - accuracy: 0.5222 - val_loss: 0.9618 - val_accuracy: 0.5128\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8786 - accuracy: 0.5333 - val_loss: 0.9571 - val_accuracy: 0.5043\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8773 - accuracy: 0.5296 - val_loss: 0.9567 - val_accuracy: 0.5043\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8808 - accuracy: 0.5407 - val_loss: 0.9570 - val_accuracy: 0.5385\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8759 - accuracy: 0.5333 - val_loss: 0.9607 - val_accuracy: 0.5385\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8829 - accuracy: 0.5000 - val_loss: 0.9622 - val_accuracy: 0.5128\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8910 - accuracy: 0.5333 - val_loss: 0.9590 - val_accuracy: 0.5385\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8803 - accuracy: 0.5444 - val_loss: 0.9588 - val_accuracy: 0.5128\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8792 - accuracy: 0.5296 - val_loss: 0.9599 - val_accuracy: 0.5043\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8791 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5043\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8814 - accuracy: 0.5222 - val_loss: 0.9570 - val_accuracy: 0.5385\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8789 - accuracy: 0.5259 - val_loss: 0.9607 - val_accuracy: 0.5128\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8808 - accuracy: 0.5333 - val_loss: 0.9596 - val_accuracy: 0.5128\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8811 - accuracy: 0.5000 - val_loss: 0.9592 - val_accuracy: 0.5385\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8775 - accuracy: 0.5556 - val_loss: 0.9648 - val_accuracy: 0.5128\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8775 - accuracy: 0.5333 - val_loss: 0.9609 - val_accuracy: 0.5128\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8786 - accuracy: 0.5333 - val_loss: 0.9590 - val_accuracy: 0.5128\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8799 - accuracy: 0.5370 - val_loss: 0.9578 - val_accuracy: 0.5385\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8821 - accuracy: 0.5333 - val_loss: 0.9594 - val_accuracy: 0.5385\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8770 - accuracy: 0.5333 - val_loss: 0.9653 - val_accuracy: 0.5128\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8797 - accuracy: 0.5333 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8831 - accuracy: 0.5185 - val_loss: 0.9578 - val_accuracy: 0.5385\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8792 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5128\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8785 - accuracy: 0.5148 - val_loss: 0.9593 - val_accuracy: 0.5470\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8778 - accuracy: 0.5370 - val_loss: 0.9596 - val_accuracy: 0.5470\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8779 - accuracy: 0.5037 - val_loss: 0.9594 - val_accuracy: 0.5470\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 360us/step - loss: 0.8769 - accuracy: 0.5370 - val_loss: 0.9593 - val_accuracy: 0.5470\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8776 - accuracy: 0.5259 - val_loss: 0.9610 - val_accuracy: 0.5128\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8768 - accuracy: 0.5333 - val_loss: 0.9624 - val_accuracy: 0.5128\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8757 - accuracy: 0.5444 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8765 - accuracy: 0.5370 - val_loss: 0.9618 - val_accuracy: 0.5470\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8770 - accuracy: 0.5259 - val_loss: 0.9605 - val_accuracy: 0.5128\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8765 - accuracy: 0.5333 - val_loss: 0.9593 - val_accuracy: 0.5470\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8772 - accuracy: 0.5370 - val_loss: 0.9579 - val_accuracy: 0.5470\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8758 - accuracy: 0.5407 - val_loss: 0.9635 - val_accuracy: 0.5128\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8771 - accuracy: 0.5333 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8810 - accuracy: 0.5148 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8754 - accuracy: 0.5407 - val_loss: 0.9638 - val_accuracy: 0.5128\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8796 - accuracy: 0.5333 - val_loss: 0.9642 - val_accuracy: 0.5128\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8763 - accuracy: 0.5444 - val_loss: 0.9590 - val_accuracy: 0.5470\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8824 - accuracy: 0.5370 - val_loss: 0.9634 - val_accuracy: 0.5470\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8757 - accuracy: 0.5296 - val_loss: 0.9616 - val_accuracy: 0.5128\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8773 - accuracy: 0.5148 - val_loss: 0.9604 - val_accuracy: 0.5470\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8774 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5128\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8781 - accuracy: 0.5444 - val_loss: 0.9618 - val_accuracy: 0.5470\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8775 - accuracy: 0.5370 - val_loss: 0.9597 - val_accuracy: 0.5470\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8781 - accuracy: 0.5370 - val_loss: 0.9591 - val_accuracy: 0.5470\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8761 - accuracy: 0.5370 - val_loss: 0.9606 - val_accuracy: 0.5470\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 0.9617 - val_accuracy: 0.5128\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8774 - accuracy: 0.5333 - val_loss: 0.9610 - val_accuracy: 0.5128\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8753 - accuracy: 0.5222 - val_loss: 0.9615 - val_accuracy: 0.5470\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8761 - accuracy: 0.5296 - val_loss: 0.9652 - val_accuracy: 0.5128\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8757 - accuracy: 0.5148 - val_loss: 0.9638 - val_accuracy: 0.5128\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8759 - accuracy: 0.5333 - val_loss: 0.9661 - val_accuracy: 0.5128\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8781 - accuracy: 0.5333 - val_loss: 0.9654 - val_accuracy: 0.5128\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8815 - accuracy: 0.5148 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8769 - accuracy: 0.5370 - val_loss: 0.9615 - val_accuracy: 0.5128\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8757 - accuracy: 0.5333 - val_loss: 0.9628 - val_accuracy: 0.5128\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8758 - accuracy: 0.5333 - val_loss: 0.9619 - val_accuracy: 0.5470\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8787 - accuracy: 0.5259 - val_loss: 0.9615 - val_accuracy: 0.5128\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8765 - accuracy: 0.5333 - val_loss: 0.9621 - val_accuracy: 0.5128\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8774 - accuracy: 0.5556 - val_loss: 0.9636 - val_accuracy: 0.5385\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8778 - accuracy: 0.5370 - val_loss: 0.9616 - val_accuracy: 0.5470\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8773 - accuracy: 0.5333 - val_loss: 0.9613 - val_accuracy: 0.5128\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8745 - accuracy: 0.5444 - val_loss: 0.9603 - val_accuracy: 0.5470\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8743 - accuracy: 0.5370 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8763 - accuracy: 0.5370 - val_loss: 0.9604 - val_accuracy: 0.5470\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8796 - accuracy: 0.5370 - val_loss: 0.9606 - val_accuracy: 0.5470\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 111us/step - loss: 0.8770 - accuracy: 0.5370 - val_loss: 0.9633 - val_accuracy: 0.5470\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8773 - accuracy: 0.5370 - val_loss: 0.9611 - val_accuracy: 0.5470\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8755 - accuracy: 0.5222 - val_loss: 0.9641 - val_accuracy: 0.5128\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8741 - accuracy: 0.5333 - val_loss: 0.9631 - val_accuracy: 0.5470\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8764 - accuracy: 0.5370 - val_loss: 0.9620 - val_accuracy: 0.5470\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8759 - accuracy: 0.5074 - val_loss: 0.9617 - val_accuracy: 0.5128\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8764 - accuracy: 0.5333 - val_loss: 0.9628 - val_accuracy: 0.5128\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8772 - accuracy: 0.5333 - val_loss: 0.9629 - val_accuracy: 0.5128\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8784 - accuracy: 0.5148 - val_loss: 0.9605 - val_accuracy: 0.5470\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8763 - accuracy: 0.5185 - val_loss: 0.9601 - val_accuracy: 0.5470\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8751 - accuracy: 0.5370 - val_loss: 0.9601 - val_accuracy: 0.5470\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8763 - accuracy: 0.5370 - val_loss: 0.9603 - val_accuracy: 0.5470\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8773 - accuracy: 0.5370 - val_loss: 0.9600 - val_accuracy: 0.5470\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8774 - accuracy: 0.5185 - val_loss: 0.9693 - val_accuracy: 0.5128\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8818 - accuracy: 0.5037 - val_loss: 0.9607 - val_accuracy: 0.5470\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8756 - accuracy: 0.5370 - val_loss: 0.9634 - val_accuracy: 0.5128\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8789 - accuracy: 0.5259 - val_loss: 0.9669 - val_accuracy: 0.5470\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8751 - accuracy: 0.5259 - val_loss: 0.9666 - val_accuracy: 0.5128\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8858 - accuracy: 0.5333 - val_loss: 0.9658 - val_accuracy: 0.5128\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8754 - accuracy: 0.5185 - val_loss: 0.9606 - val_accuracy: 0.5470\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8781 - accuracy: 0.5370 - val_loss: 0.9613 - val_accuracy: 0.5470\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8756 - accuracy: 0.5370 - val_loss: 0.9645 - val_accuracy: 0.5470\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8764 - accuracy: 0.5370 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8788 - accuracy: 0.5222 - val_loss: 0.9654 - val_accuracy: 0.5128\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8765 - accuracy: 0.5333 - val_loss: 0.9627 - val_accuracy: 0.5128\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8754 - accuracy: 0.5370 - val_loss: 0.9614 - val_accuracy: 0.5470\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8740 - accuracy: 0.5222 - val_loss: 0.9633 - val_accuracy: 0.5128\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8767 - accuracy: 0.5074 - val_loss: 0.9632 - val_accuracy: 0.5470\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8757 - accuracy: 0.5370 - val_loss: 0.9630 - val_accuracy: 0.5470\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8759 - accuracy: 0.5370 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8755 - accuracy: 0.5370 - val_loss: 0.9633 - val_accuracy: 0.5128\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8750 - accuracy: 0.5333 - val_loss: 0.9644 - val_accuracy: 0.5128\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8732 - accuracy: 0.5333 - val_loss: 0.9656 - val_accuracy: 0.5470\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8822 - accuracy: 0.5370 - val_loss: 0.9646 - val_accuracy: 0.5470\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8732 - accuracy: 0.5370 - val_loss: 0.9659 - val_accuracy: 0.5128\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8759 - accuracy: 0.5333 - val_loss: 0.9675 - val_accuracy: 0.5128\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8777 - accuracy: 0.5111 - val_loss: 0.9642 - val_accuracy: 0.5470\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8778 - accuracy: 0.5185 - val_loss: 0.9630 - val_accuracy: 0.5128\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8754 - accuracy: 0.5333 - val_loss: 0.9683 - val_accuracy: 0.5128\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8762 - accuracy: 0.5185 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8730 - accuracy: 0.5333 - val_loss: 0.9665 - val_accuracy: 0.5128\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8761 - accuracy: 0.5333 - val_loss: 0.9698 - val_accuracy: 0.5128\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8751 - accuracy: 0.5185 - val_loss: 0.9617 - val_accuracy: 0.5470\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8750 - accuracy: 0.5370 - val_loss: 0.9625 - val_accuracy: 0.5470\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8740 - accuracy: 0.5370 - val_loss: 0.9642 - val_accuracy: 0.5128\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8762 - accuracy: 0.5333 - val_loss: 0.9701 - val_accuracy: 0.5128\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8768 - accuracy: 0.5333 - val_loss: 0.9661 - val_accuracy: 0.5128\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8747 - accuracy: 0.5407 - val_loss: 0.9679 - val_accuracy: 0.5470\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8735 - accuracy: 0.5296 - val_loss: 0.9643 - val_accuracy: 0.5128\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8755 - accuracy: 0.5333 - val_loss: 0.9625 - val_accuracy: 0.5470\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8752 - accuracy: 0.5185 - val_loss: 0.9639 - val_accuracy: 0.5128\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8747 - accuracy: 0.5148 - val_loss: 0.9628 - val_accuracy: 0.5470\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8734 - accuracy: 0.5370 - val_loss: 0.9649 - val_accuracy: 0.5470\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8732 - accuracy: 0.5296 - val_loss: 0.9673 - val_accuracy: 0.5128\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8741 - accuracy: 0.5333 - val_loss: 0.9643 - val_accuracy: 0.5128\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8738 - accuracy: 0.5333 - val_loss: 0.9647 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8735 - accuracy: 0.5333 - val_loss: 0.9653 - val_accuracy: 0.5128\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8734 - accuracy: 0.5407 - val_loss: 0.9632 - val_accuracy: 0.5470\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8745 - accuracy: 0.5296 - val_loss: 0.9648 - val_accuracy: 0.5128\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8734 - accuracy: 0.5111 - val_loss: 0.9629 - val_accuracy: 0.5128\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8736 - accuracy: 0.5333 - val_loss: 0.9612 - val_accuracy: 0.5470\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8737 - accuracy: 0.5333 - val_loss: 0.9620 - val_accuracy: 0.5128\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8738 - accuracy: 0.5074 - val_loss: 0.9670 - val_accuracy: 0.5128\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8742 - accuracy: 0.5111 - val_loss: 0.9656 - val_accuracy: 0.5470\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8741 - accuracy: 0.5370 - val_loss: 0.9641 - val_accuracy: 0.5470\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8746 - accuracy: 0.5000 - val_loss: 0.9671 - val_accuracy: 0.5128\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8766 - accuracy: 0.5333 - val_loss: 0.9658 - val_accuracy: 0.5128\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8718 - accuracy: 0.5185 - val_loss: 0.9635 - val_accuracy: 0.5470\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8739 - accuracy: 0.5370 - val_loss: 0.9619 - val_accuracy: 0.5470\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8730 - accuracy: 0.5370 - val_loss: 0.9638 - val_accuracy: 0.5470\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8745 - accuracy: 0.5148 - val_loss: 0.9663 - val_accuracy: 0.5128\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8744 - accuracy: 0.5333 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8728 - accuracy: 0.5333 - val_loss: 0.9611 - val_accuracy: 0.5470\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8735 - accuracy: 0.5333 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8753 - accuracy: 0.5333 - val_loss: 0.9685 - val_accuracy: 0.5128\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8755 - accuracy: 0.5185 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8762 - accuracy: 0.5370 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8736 - accuracy: 0.5259 - val_loss: 0.9712 - val_accuracy: 0.5128\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8792 - accuracy: 0.5185 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8770 - accuracy: 0.5148 - val_loss: 0.9714 - val_accuracy: 0.5128\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8748 - accuracy: 0.5333 - val_loss: 0.9725 - val_accuracy: 0.5128\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8747 - accuracy: 0.5519 - val_loss: 0.9649 - val_accuracy: 0.5470\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8728 - accuracy: 0.5370 - val_loss: 0.9643 - val_accuracy: 0.5470\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8747 - accuracy: 0.5370 - val_loss: 0.9687 - val_accuracy: 0.5470\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8751 - accuracy: 0.5185 - val_loss: 0.9678 - val_accuracy: 0.5128\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8741 - accuracy: 0.5333 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8759 - accuracy: 0.5148 - val_loss: 0.9676 - val_accuracy: 0.5128\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8748 - accuracy: 0.5333 - val_loss: 0.9657 - val_accuracy: 0.5470\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8732 - accuracy: 0.5296 - val_loss: 0.9672 - val_accuracy: 0.5128\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8719 - accuracy: 0.5185 - val_loss: 0.9653 - val_accuracy: 0.5470\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8727 - accuracy: 0.5444 - val_loss: 0.9672 - val_accuracy: 0.5128\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8735 - accuracy: 0.5111 - val_loss: 0.9645 - val_accuracy: 0.5470\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8735 - accuracy: 0.5370 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8728 - accuracy: 0.5259 - val_loss: 0.9673 - val_accuracy: 0.5128\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8794 - accuracy: 0.5333 - val_loss: 0.9691 - val_accuracy: 0.5128\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8748 - accuracy: 0.5259 - val_loss: 0.9642 - val_accuracy: 0.5470\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8734 - accuracy: 0.5370 - val_loss: 0.9675 - val_accuracy: 0.5470\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8737 - accuracy: 0.4963 - val_loss: 0.9693 - val_accuracy: 0.5470\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8734 - accuracy: 0.5333 - val_loss: 0.9695 - val_accuracy: 0.5128\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8788 - accuracy: 0.5037 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8727 - accuracy: 0.5407 - val_loss: 0.9683 - val_accuracy: 0.5128\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8742 - accuracy: 0.5185 - val_loss: 0.9663 - val_accuracy: 0.5128\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8720 - accuracy: 0.5222 - val_loss: 0.9636 - val_accuracy: 0.5470\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8753 - accuracy: 0.5074 - val_loss: 0.9669 - val_accuracy: 0.5128\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8726 - accuracy: 0.5148 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8728 - accuracy: 0.5259 - val_loss: 0.9677 - val_accuracy: 0.5128\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8749 - accuracy: 0.5185 - val_loss: 0.9658 - val_accuracy: 0.5128\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8721 - accuracy: 0.5296 - val_loss: 0.9680 - val_accuracy: 0.5470\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8730 - accuracy: 0.4963 - val_loss: 0.9703 - val_accuracy: 0.5470\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8745 - accuracy: 0.5370 - val_loss: 0.9675 - val_accuracy: 0.5470\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8760 - accuracy: 0.5222 - val_loss: 0.9664 - val_accuracy: 0.5128\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8719 - accuracy: 0.5296 - val_loss: 0.9664 - val_accuracy: 0.5470\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8725 - accuracy: 0.5370 - val_loss: 0.9654 - val_accuracy: 0.5470\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8724 - accuracy: 0.5370 - val_loss: 0.9644 - val_accuracy: 0.5470\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8720 - accuracy: 0.5407 - val_loss: 0.9675 - val_accuracy: 0.5128\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8712 - accuracy: 0.5333 - val_loss: 0.9670 - val_accuracy: 0.5128\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8730 - accuracy: 0.5111 - val_loss: 0.9665 - val_accuracy: 0.5470\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8725 - accuracy: 0.4963 - val_loss: 0.9667 - val_accuracy: 0.5128\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8715 - accuracy: 0.5222 - val_loss: 0.9647 - val_accuracy: 0.5470\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8722 - accuracy: 0.5333 - val_loss: 0.9637 - val_accuracy: 0.5470\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8716 - accuracy: 0.5370 - val_loss: 0.9669 - val_accuracy: 0.5470\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8735 - accuracy: 0.5333 - val_loss: 0.9726 - val_accuracy: 0.5128\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8765 - accuracy: 0.5111 - val_loss: 0.9697 - val_accuracy: 0.5470\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8718 - accuracy: 0.5185 - val_loss: 0.9659 - val_accuracy: 0.5128\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8741 - accuracy: 0.5074 - val_loss: 0.9665 - val_accuracy: 0.5128\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8717 - accuracy: 0.5074 - val_loss: 0.9687 - val_accuracy: 0.5128\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8717 - accuracy: 0.5333 - val_loss: 0.9673 - val_accuracy: 0.5128\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8726 - accuracy: 0.5333 - val_loss: 0.9667 - val_accuracy: 0.5128\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8723 - accuracy: 0.5259 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8724 - accuracy: 0.5185 - val_loss: 0.9701 - val_accuracy: 0.5128\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8719 - accuracy: 0.5259 - val_loss: 0.9660 - val_accuracy: 0.5470\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8744 - accuracy: 0.5222 - val_loss: 0.9684 - val_accuracy: 0.5128\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8747 - accuracy: 0.5259 - val_loss: 0.9640 - val_accuracy: 0.5470\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8748 - accuracy: 0.5370 - val_loss: 0.9655 - val_accuracy: 0.5470\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8731 - accuracy: 0.5000 - val_loss: 0.9711 - val_accuracy: 0.5128\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8727 - accuracy: 0.5333 - val_loss: 0.9706 - val_accuracy: 0.5128\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8711 - accuracy: 0.5444 - val_loss: 0.9651 - val_accuracy: 0.5470\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8717 - accuracy: 0.5407 - val_loss: 0.9639 - val_accuracy: 0.5470\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8746 - accuracy: 0.5185 - val_loss: 0.9673 - val_accuracy: 0.5128\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8764 - accuracy: 0.5259 - val_loss: 0.9658 - val_accuracy: 0.5470\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8699 - accuracy: 0.5370 - val_loss: 0.9698 - val_accuracy: 0.5470\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8719 - accuracy: 0.5296 - val_loss: 0.9721 - val_accuracy: 0.5470\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8705 - accuracy: 0.5185 - val_loss: 0.9697 - val_accuracy: 0.5128\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8753 - accuracy: 0.5370 - val_loss: 0.9667 - val_accuracy: 0.5470\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8736 - accuracy: 0.5333 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8751 - accuracy: 0.5370 - val_loss: 0.9714 - val_accuracy: 0.5470\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8721 - accuracy: 0.5333 - val_loss: 0.9687 - val_accuracy: 0.5470\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8727 - accuracy: 0.5444 - val_loss: 0.9743 - val_accuracy: 0.5128\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8782 - accuracy: 0.4778 - val_loss: 0.9686 - val_accuracy: 0.5470\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8711 - accuracy: 0.5185 - val_loss: 0.9706 - val_accuracy: 0.5128\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.43 - 0s 78us/step - loss: 0.8723 - accuracy: 0.5407 - val_loss: 0.9689 - val_accuracy: 0.5470\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8707 - accuracy: 0.5370 - val_loss: 0.9687 - val_accuracy: 0.5470\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8725 - accuracy: 0.5370 - val_loss: 0.9682 - val_accuracy: 0.5470\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8720 - accuracy: 0.5222 - val_loss: 0.9715 - val_accuracy: 0.5470\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8729 - accuracy: 0.5370 - val_loss: 0.9696 - val_accuracy: 0.5470\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8725 - accuracy: 0.5074 - val_loss: 0.9707 - val_accuracy: 0.5128\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8707 - accuracy: 0.5296 - val_loss: 0.9681 - val_accuracy: 0.5470\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8698 - accuracy: 0.5370 - val_loss: 0.9667 - val_accuracy: 0.5470\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8713 - accuracy: 0.5333 - val_loss: 0.9682 - val_accuracy: 0.5470\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8699 - accuracy: 0.5111 - val_loss: 0.9693 - val_accuracy: 0.5128\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8722 - accuracy: 0.5296 - val_loss: 0.9677 - val_accuracy: 0.5470\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8722 - accuracy: 0.5370 - val_loss: 0.9676 - val_accuracy: 0.5470\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8721 - accuracy: 0.5333 - val_loss: 0.9696 - val_accuracy: 0.5128\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8719 - accuracy: 0.5148 - val_loss: 0.9690 - val_accuracy: 0.5470\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8702 - accuracy: 0.5333 - val_loss: 0.9682 - val_accuracy: 0.5470\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8705 - accuracy: 0.5370 - val_loss: 0.9677 - val_accuracy: 0.5470\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 87us/step - loss: 0.8720 - accuracy: 0.5185 - val_loss: 0.9698 - val_accuracy: 0.5128\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8743 - accuracy: 0.5148 - val_loss: 0.9691 - val_accuracy: 0.5470\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8763 - accuracy: 0.5074 - val_loss: 0.9744 - val_accuracy: 0.5128\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8723 - accuracy: 0.5222 - val_loss: 0.9691 - val_accuracy: 0.5470\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8705 - accuracy: 0.5370 - val_loss: 0.9710 - val_accuracy: 0.5470\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8708 - accuracy: 0.5296 - val_loss: 0.9740 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x10a4c2da0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 65us/step\n",
      "over-sampling test accuracy: 56.41%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1,\n",
       "       2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
       "       0, 1, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS210     0     0\n",
       "1         NRS205     2     2\n",
       "2            312     2     1\n",
       "3           GA15     2     1\n",
       "4         SR4035     0     1\n",
       "..           ...   ...   ...\n",
       "112       NRS265     2     2\n",
       "113  CFBREBSa108     1     1\n",
       "114        NY224     1     1\n",
       "115       NRS386     2     2\n",
       "116       NRS168     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613208</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>0.105574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358946</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358946</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.358946</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.047203</td>\n",
       "      <td>1.739226e-03</td>\n",
       "      <td>0.951057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.358946</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>0.242775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.221757</td>\n",
       "      <td>4.551860e-01</td>\n",
       "      <td>0.323057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.266153</td>\n",
       "      <td>1.839188e-01</td>\n",
       "      <td>0.549929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.027389</td>\n",
       "      <td>3.946544e-01</td>\n",
       "      <td>0.577957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1         2\n",
       "0    0.613208  2.812180e-01  0.105574\n",
       "1    0.000199  6.834937e-07  0.999800\n",
       "2    0.358946  3.982787e-01  0.242775\n",
       "3    0.358946  3.982787e-01  0.242775\n",
       "4    0.358946  3.982787e-01  0.242775\n",
       "..        ...           ...       ...\n",
       "112  0.047203  1.739226e-03  0.951057\n",
       "113  0.358946  3.982787e-01  0.242775\n",
       "114  0.221757  4.551860e-01  0.323057\n",
       "115  0.266153  1.839188e-01  0.549929\n",
       "116  0.027389  3.946544e-01  0.577957\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8684 - accuracy: 0.5370 - val_loss: 0.9881 - val_accuracy: 0.5641\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8686 - accuracy: 0.5407 - val_loss: 0.9894 - val_accuracy: 0.5299\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8683 - accuracy: 0.5333 - val_loss: 0.9900 - val_accuracy: 0.5299\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8681 - accuracy: 0.5148 - val_loss: 0.9910 - val_accuracy: 0.5641\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8708 - accuracy: 0.5333 - val_loss: 0.9943 - val_accuracy: 0.5641\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8703 - accuracy: 0.4926 - val_loss: 0.9944 - val_accuracy: 0.5641\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8698 - accuracy: 0.5370 - val_loss: 0.9945 - val_accuracy: 0.5641\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8690 - accuracy: 0.5370 - val_loss: 0.9955 - val_accuracy: 0.5641\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8685 - accuracy: 0.5370 - val_loss: 0.9976 - val_accuracy: 0.5641\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8701 - accuracy: 0.5259 - val_loss: 1.0033 - val_accuracy: 0.5299\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8705 - accuracy: 0.5259 - val_loss: 0.9973 - val_accuracy: 0.5641\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8712 - accuracy: 0.5333 - val_loss: 0.9973 - val_accuracy: 0.5641\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8670 - accuracy: 0.5370 - val_loss: 0.9999 - val_accuracy: 0.5641\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8678 - accuracy: 0.5370 - val_loss: 1.0020 - val_accuracy: 0.5299\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8680 - accuracy: 0.5333 - val_loss: 1.0024 - val_accuracy: 0.5299\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8687 - accuracy: 0.5333 - val_loss: 1.0036 - val_accuracy: 0.5299\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8699 - accuracy: 0.5296 - val_loss: 1.0026 - val_accuracy: 0.5641\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8710 - accuracy: 0.5370 - val_loss: 1.0055 - val_accuracy: 0.5641\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8679 - accuracy: 0.5296 - val_loss: 1.0096 - val_accuracy: 0.5299\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.8695 - accuracy: 0.5148 - val_loss: 1.0054 - val_accuracy: 0.5641\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8682 - accuracy: 0.5370 - val_loss: 1.0061 - val_accuracy: 0.5641\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8680 - accuracy: 0.5333 - val_loss: 1.0084 - val_accuracy: 0.5641\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8684 - accuracy: 0.5296 - val_loss: 1.0098 - val_accuracy: 0.5299\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8673 - accuracy: 0.5333 - val_loss: 1.0068 - val_accuracy: 0.5299\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8675 - accuracy: 0.5296 - val_loss: 1.0067 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8685 - accuracy: 0.5370 - val_loss: 1.0087 - val_accuracy: 0.5641\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8696 - accuracy: 0.5370 - val_loss: 1.0062 - val_accuracy: 0.5641\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8688 - accuracy: 0.5074 - val_loss: 1.0080 - val_accuracy: 0.5299\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8711 - accuracy: 0.5296 - val_loss: 1.0118 - val_accuracy: 0.5299\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8669 - accuracy: 0.5407 - val_loss: 1.0067 - val_accuracy: 0.5641\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8679 - accuracy: 0.5370 - val_loss: 1.0064 - val_accuracy: 0.5641\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8697 - accuracy: 0.5370 - val_loss: 1.0062 - val_accuracy: 0.5641\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8674 - accuracy: 0.5407 - val_loss: 1.0086 - val_accuracy: 0.5299\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8681 - accuracy: 0.5185 - val_loss: 1.0066 - val_accuracy: 0.5641\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8684 - accuracy: 0.5370 - val_loss: 1.0074 - val_accuracy: 0.5299\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8669 - accuracy: 0.5074 - val_loss: 1.0108 - val_accuracy: 0.5299\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8681 - accuracy: 0.5333 - val_loss: 1.0123 - val_accuracy: 0.5299\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8695 - accuracy: 0.5185 - val_loss: 1.0101 - val_accuracy: 0.5641\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8675 - accuracy: 0.5222 - val_loss: 1.0109 - val_accuracy: 0.5299\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8669 - accuracy: 0.5074 - val_loss: 1.0107 - val_accuracy: 0.5299\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8669 - accuracy: 0.5296 - val_loss: 1.0098 - val_accuracy: 0.5299\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8669 - accuracy: 0.5333 - val_loss: 1.0072 - val_accuracy: 0.5641\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8693 - accuracy: 0.5370 - val_loss: 1.0069 - val_accuracy: 0.5641\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8708 - accuracy: 0.5148 - val_loss: 1.0126 - val_accuracy: 0.5299\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8685 - accuracy: 0.5333 - val_loss: 1.0103 - val_accuracy: 0.5299\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8727 - accuracy: 0.4926 - val_loss: 1.0089 - val_accuracy: 0.5641\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8679 - accuracy: 0.5444 - val_loss: 1.0099 - val_accuracy: 0.5299\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8674 - accuracy: 0.5333 - val_loss: 1.0088 - val_accuracy: 0.5299\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8705 - accuracy: 0.5333 - val_loss: 1.0096 - val_accuracy: 0.5299\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8689 - accuracy: 0.5296 - val_loss: 1.0071 - val_accuracy: 0.5641\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8700 - accuracy: 0.5370 - val_loss: 1.0075 - val_accuracy: 0.5641\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8695 - accuracy: 0.5185 - val_loss: 1.0132 - val_accuracy: 0.5299\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8702 - accuracy: 0.5333 - val_loss: 1.0077 - val_accuracy: 0.5299\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8670 - accuracy: 0.5296 - val_loss: 1.0052 - val_accuracy: 0.5641\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8673 - accuracy: 0.5370 - val_loss: 1.0050 - val_accuracy: 0.5641\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8689 - accuracy: 0.5148 - val_loss: 1.0069 - val_accuracy: 0.5641\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8684 - accuracy: 0.5370 - val_loss: 1.0074 - val_accuracy: 0.5641\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8700 - accuracy: 0.5259 - val_loss: 1.0110 - val_accuracy: 0.5299\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8710 - accuracy: 0.5148 - val_loss: 1.0058 - val_accuracy: 0.5641\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8676 - accuracy: 0.5370 - val_loss: 1.0090 - val_accuracy: 0.5641\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8666 - accuracy: 0.5370 - val_loss: 1.0073 - val_accuracy: 0.5641\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8678 - accuracy: 0.5370 - val_loss: 1.0072 - val_accuracy: 0.5641\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8695 - accuracy: 0.5111 - val_loss: 1.0101 - val_accuracy: 0.5641\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8686 - accuracy: 0.5370 - val_loss: 1.0135 - val_accuracy: 0.5641\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8680 - accuracy: 0.5370 - val_loss: 1.0107 - val_accuracy: 0.5641\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8683 - accuracy: 0.5148 - val_loss: 1.0133 - val_accuracy: 0.5299\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 259us/step - loss: 0.8678 - accuracy: 0.5296 - val_loss: 1.0134 - val_accuracy: 0.5299\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.8676 - accuracy: 0.5111 - val_loss: 1.0123 - val_accuracy: 0.5641\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8675 - accuracy: 0.5370 - val_loss: 1.0128 - val_accuracy: 0.5641\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.8674 - accuracy: 0.5370 - val_loss: 1.0087 - val_accuracy: 0.5641\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8676 - accuracy: 0.5111 - val_loss: 1.0070 - val_accuracy: 0.5299\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8678 - accuracy: 0.5296 - val_loss: 1.0074 - val_accuracy: 0.5641\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8679 - accuracy: 0.5407 - val_loss: 1.0066 - val_accuracy: 0.5641\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8680 - accuracy: 0.5370 - val_loss: 1.0096 - val_accuracy: 0.5641\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8658 - accuracy: 0.5593 - val_loss: 1.0125 - val_accuracy: 0.5299\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8675 - accuracy: 0.5296 - val_loss: 1.0127 - val_accuracy: 0.5299\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8677 - accuracy: 0.5222 - val_loss: 1.0102 - val_accuracy: 0.5641\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 349us/step - loss: 0.8664 - accuracy: 0.5333 - val_loss: 1.0124 - val_accuracy: 0.5641\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8710 - accuracy: 0.5370 - val_loss: 1.0131 - val_accuracy: 0.5641\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8667 - accuracy: 0.5370 - val_loss: 1.0129 - val_accuracy: 0.5299\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8710 - accuracy: 0.5333 - val_loss: 1.0140 - val_accuracy: 0.5299\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 274us/step - loss: 0.8697 - accuracy: 0.5333 - val_loss: 1.0118 - val_accuracy: 0.5641\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8671 - accuracy: 0.5370 - val_loss: 1.0101 - val_accuracy: 0.5641\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8675 - accuracy: 0.5074 - val_loss: 1.0140 - val_accuracy: 0.5299\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8692 - accuracy: 0.5222 - val_loss: 1.0141 - val_accuracy: 0.5641\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8667 - accuracy: 0.5037 - val_loss: 1.0172 - val_accuracy: 0.5299\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8685 - accuracy: 0.5333 - val_loss: 1.0146 - val_accuracy: 0.5299\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8685 - accuracy: 0.5333 - val_loss: 1.0144 - val_accuracy: 0.5641\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8673 - accuracy: 0.5333 - val_loss: 1.0199 - val_accuracy: 0.5299\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8665 - accuracy: 0.5444 - val_loss: 1.0091 - val_accuracy: 0.5641\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8667 - accuracy: 0.5370 - val_loss: 1.0069 - val_accuracy: 0.5641\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8660 - accuracy: 0.5333 - val_loss: 1.0054 - val_accuracy: 0.5641\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8669 - accuracy: 0.5370 - val_loss: 1.0083 - val_accuracy: 0.5641\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8656 - accuracy: 0.5222 - val_loss: 1.0079 - val_accuracy: 0.5299\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8672 - accuracy: 0.5370 - val_loss: 1.0076 - val_accuracy: 0.5641\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8711 - accuracy: 0.5370 - val_loss: 1.0084 - val_accuracy: 0.5641\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8689 - accuracy: 0.5074 - val_loss: 1.0108 - val_accuracy: 0.5641\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8688 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.5299\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8670 - accuracy: 0.5333 - val_loss: 1.0147 - val_accuracy: 0.5299\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8669 - accuracy: 0.5333 - val_loss: 1.0158 - val_accuracy: 0.5299\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8656 - accuracy: 0.5259 - val_loss: 1.0146 - val_accuracy: 0.5641\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8679 - accuracy: 0.5370 - val_loss: 1.0151 - val_accuracy: 0.5641\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8695 - accuracy: 0.5222 - val_loss: 1.0180 - val_accuracy: 0.5299\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8684 - accuracy: 0.5333 - val_loss: 1.0150 - val_accuracy: 0.5641\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 436us/step - loss: 0.8671 - accuracy: 0.5000 - val_loss: 1.0153 - val_accuracy: 0.5641\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8634 - accuracy: 0.5370 - val_loss: 1.0163 - val_accuracy: 0.5641\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8703 - accuracy: 0.5185 - val_loss: 1.0210 - val_accuracy: 0.5299\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8683 - accuracy: 0.5370 - val_loss: 1.0155 - val_accuracy: 0.5641\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8680 - accuracy: 0.5185 - val_loss: 1.0148 - val_accuracy: 0.5299\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8673 - accuracy: 0.5185 - val_loss: 1.0120 - val_accuracy: 0.5641\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8721 - accuracy: 0.5370 - val_loss: 1.0184 - val_accuracy: 0.5641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8684 - accuracy: 0.5037 - val_loss: 1.0169 - val_accuracy: 0.5299\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8681 - accuracy: 0.5148 - val_loss: 1.0141 - val_accuracy: 0.5641\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8651 - accuracy: 0.5370 - val_loss: 1.0185 - val_accuracy: 0.5299\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8671 - accuracy: 0.5296 - val_loss: 1.0170 - val_accuracy: 0.5299\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8659 - accuracy: 0.5185 - val_loss: 1.0128 - val_accuracy: 0.5641\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8674 - accuracy: 0.5370 - val_loss: 1.0149 - val_accuracy: 0.5641\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8665 - accuracy: 0.5407 - val_loss: 1.0135 - val_accuracy: 0.5641\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8665 - accuracy: 0.5370 - val_loss: 1.0151 - val_accuracy: 0.5641\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8659 - accuracy: 0.5333 - val_loss: 1.0156 - val_accuracy: 0.5299\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8661 - accuracy: 0.5296 - val_loss: 1.0144 - val_accuracy: 0.5299\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8653 - accuracy: 0.5370 - val_loss: 1.0145 - val_accuracy: 0.5641\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8675 - accuracy: 0.5370 - val_loss: 1.0145 - val_accuracy: 0.5641\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8658 - accuracy: 0.5296 - val_loss: 1.0223 - val_accuracy: 0.5299\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8772 - accuracy: 0.5296 - val_loss: 1.0169 - val_accuracy: 0.5641\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8658 - accuracy: 0.5370 - val_loss: 1.0022 - val_accuracy: 0.5641\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8717 - accuracy: 0.4815 - val_loss: 0.9993 - val_accuracy: 0.5299\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8711 - accuracy: 0.5037 - val_loss: 1.0035 - val_accuracy: 0.5043\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 329us/step - loss: 0.8676 - accuracy: 0.5222 - val_loss: 0.9993 - val_accuracy: 0.5299\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8671 - accuracy: 0.5333 - val_loss: 0.9998 - val_accuracy: 0.5299\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8667 - accuracy: 0.5000 - val_loss: 1.0037 - val_accuracy: 0.5641\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8695 - accuracy: 0.5370 - val_loss: 1.0024 - val_accuracy: 0.5641\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8740 - accuracy: 0.5111 - val_loss: 1.0066 - val_accuracy: 0.5299\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8670 - accuracy: 0.5444 - val_loss: 1.0067 - val_accuracy: 0.5641\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8682 - accuracy: 0.5037 - val_loss: 1.0062 - val_accuracy: 0.5641\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 507us/step - loss: 0.8655 - accuracy: 0.5370 - val_loss: 1.0028 - val_accuracy: 0.5641\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.8679 - accuracy: 0.5370 - val_loss: 1.0047 - val_accuracy: 0.5641\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8639 - accuracy: 0.5370 - val_loss: 1.0095 - val_accuracy: 0.5299\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8664 - accuracy: 0.5333 - val_loss: 1.0124 - val_accuracy: 0.5299\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8673 - accuracy: 0.5333 - val_loss: 1.0116 - val_accuracy: 0.5299\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8660 - accuracy: 0.5370 - val_loss: 1.0097 - val_accuracy: 0.5641\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8663 - accuracy: 0.5370 - val_loss: 1.0116 - val_accuracy: 0.5641\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8673 - accuracy: 0.5111 - val_loss: 1.0110 - val_accuracy: 0.5641\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0122 - val_accuracy: 0.5641\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8684 - accuracy: 0.5370 - val_loss: 1.0126 - val_accuracy: 0.5641\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8658 - accuracy: 0.5370 - val_loss: 1.0125 - val_accuracy: 0.5641\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8659 - accuracy: 0.5296 - val_loss: 1.0121 - val_accuracy: 0.5641\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8675 - accuracy: 0.5222 - val_loss: 1.0126 - val_accuracy: 0.5641\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8663 - accuracy: 0.5370 - val_loss: 1.0121 - val_accuracy: 0.5641\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8691 - accuracy: 0.5370 - val_loss: 1.0117 - val_accuracy: 0.5641\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8675 - accuracy: 0.5370 - val_loss: 1.0123 - val_accuracy: 0.5299\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8670 - accuracy: 0.5333 - val_loss: 1.0188 - val_accuracy: 0.5299\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8708 - accuracy: 0.5185 - val_loss: 1.0134 - val_accuracy: 0.5641\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8685 - accuracy: 0.5370 - val_loss: 1.0153 - val_accuracy: 0.5641\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8661 - accuracy: 0.5370 - val_loss: 1.0146 - val_accuracy: 0.5641\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8667 - accuracy: 0.5222 - val_loss: 1.0168 - val_accuracy: 0.5299\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8659 - accuracy: 0.5222 - val_loss: 1.0165 - val_accuracy: 0.5641\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8676 - accuracy: 0.5370 - val_loss: 1.0153 - val_accuracy: 0.5641\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8658 - accuracy: 0.5444 - val_loss: 1.0183 - val_accuracy: 0.5299\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8656 - accuracy: 0.5333 - val_loss: 1.0177 - val_accuracy: 0.5299\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8654 - accuracy: 0.5333 - val_loss: 1.0175 - val_accuracy: 0.5299\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8655 - accuracy: 0.5259 - val_loss: 1.0151 - val_accuracy: 0.5641\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8691 - accuracy: 0.5370 - val_loss: 1.0193 - val_accuracy: 0.5641\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.8658 - accuracy: 0.5074 - val_loss: 1.0185 - val_accuracy: 0.5299\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8695 - accuracy: 0.5185 - val_loss: 1.0146 - val_accuracy: 0.5641\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8651 - accuracy: 0.5333 - val_loss: 1.0194 - val_accuracy: 0.5299\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8657 - accuracy: 0.5222 - val_loss: 1.0388 - val_accuracy: 0.5299\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8709 - accuracy: 0.5296 - val_loss: 1.0198 - val_accuracy: 0.5641\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8688 - accuracy: 0.5185 - val_loss: 1.0222 - val_accuracy: 0.5641\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0166 - val_accuracy: 0.5641\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0131 - val_accuracy: 0.5641\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8668 - accuracy: 0.5370 - val_loss: 1.0119 - val_accuracy: 0.5641\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8685 - accuracy: 0.5185 - val_loss: 1.0195 - val_accuracy: 0.5299\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8662 - accuracy: 0.5259 - val_loss: 1.0146 - val_accuracy: 0.5641\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8651 - accuracy: 0.5407 - val_loss: 1.0133 - val_accuracy: 0.5641\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8662 - accuracy: 0.5185 - val_loss: 1.0166 - val_accuracy: 0.5299\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8652 - accuracy: 0.5333 - val_loss: 1.0197 - val_accuracy: 0.5641\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8655 - accuracy: 0.5370 - val_loss: 1.0173 - val_accuracy: 0.5641\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8649 - accuracy: 0.5370 - val_loss: 1.0174 - val_accuracy: 0.5641\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8671 - accuracy: 0.5333 - val_loss: 1.0210 - val_accuracy: 0.5299\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.8647 - accuracy: 0.5222 - val_loss: 1.0179 - val_accuracy: 0.5299\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8673 - accuracy: 0.5333 - val_loss: 1.0188 - val_accuracy: 0.5299\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8695 - accuracy: 0.5259 - val_loss: 1.0153 - val_accuracy: 0.5641\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8706 - accuracy: 0.5000 - val_loss: 1.0203 - val_accuracy: 0.5299\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8665 - accuracy: 0.5333 - val_loss: 1.0179 - val_accuracy: 0.5299\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8663 - accuracy: 0.5296 - val_loss: 1.0169 - val_accuracy: 0.5641\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.8672 - accuracy: 0.5370 - val_loss: 1.0201 - val_accuracy: 0.5641\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 478us/step - loss: 0.8662 - accuracy: 0.5111 - val_loss: 1.0207 - val_accuracy: 0.5299\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8651 - accuracy: 0.5333 - val_loss: 1.0200 - val_accuracy: 0.5299\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8651 - accuracy: 0.5222 - val_loss: 1.0202 - val_accuracy: 0.5641\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8642 - accuracy: 0.5370 - val_loss: 1.0222 - val_accuracy: 0.5641\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8670 - accuracy: 0.5370 - val_loss: 1.0178 - val_accuracy: 0.5299\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8647 - accuracy: 0.5333 - val_loss: 1.0164 - val_accuracy: 0.5299\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8676 - accuracy: 0.4963 - val_loss: 1.0167 - val_accuracy: 0.5641\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8652 - accuracy: 0.5333 - val_loss: 1.0154 - val_accuracy: 0.5299\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8640 - accuracy: 0.5444 - val_loss: 1.0135 - val_accuracy: 0.5641\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0138 - val_accuracy: 0.5641\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8664 - accuracy: 0.5333 - val_loss: 1.0179 - val_accuracy: 0.5641\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8652 - accuracy: 0.5222 - val_loss: 1.0195 - val_accuracy: 0.5299\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8653 - accuracy: 0.5333 - val_loss: 1.0199 - val_accuracy: 0.5299\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8641 - accuracy: 0.5259 - val_loss: 1.0170 - val_accuracy: 0.5641\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8660 - accuracy: 0.4926 - val_loss: 1.0196 - val_accuracy: 0.5299\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8674 - accuracy: 0.5148 - val_loss: 1.0205 - val_accuracy: 0.5641\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8656 - accuracy: 0.5444 - val_loss: 1.0227 - val_accuracy: 0.5299\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8654 - accuracy: 0.5333 - val_loss: 1.0205 - val_accuracy: 0.5299\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 1.0213 - val_accuracy: 0.5641\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8641 - accuracy: 0.5370 - val_loss: 1.0196 - val_accuracy: 0.5641\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8649 - accuracy: 0.5370 - val_loss: 1.0193 - val_accuracy: 0.5641\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8631 - accuracy: 0.5519 - val_loss: 1.0225 - val_accuracy: 0.5299\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.8663 - accuracy: 0.5333 - val_loss: 1.0219 - val_accuracy: 0.5299\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8673 - accuracy: 0.5407 - val_loss: 1.0184 - val_accuracy: 0.5641\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8659 - accuracy: 0.5222 - val_loss: 1.0220 - val_accuracy: 0.5299\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8661 - accuracy: 0.5074 - val_loss: 1.0208 - val_accuracy: 0.5641\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8678 - accuracy: 0.5370 - val_loss: 1.0275 - val_accuracy: 0.5299\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8681 - accuracy: 0.5000 - val_loss: 1.0236 - val_accuracy: 0.5641\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8662 - accuracy: 0.5370 - val_loss: 1.0249 - val_accuracy: 0.5641\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8654 - accuracy: 0.5370 - val_loss: 1.0220 - val_accuracy: 0.5641\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8652 - accuracy: 0.5185 - val_loss: 1.0227 - val_accuracy: 0.5299\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8651 - accuracy: 0.5296 - val_loss: 1.0223 - val_accuracy: 0.5299\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8640 - accuracy: 0.5333 - val_loss: 1.0196 - val_accuracy: 0.5641\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8647 - accuracy: 0.5407 - val_loss: 1.0195 - val_accuracy: 0.5641\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 91us/step - loss: 0.8644 - accuracy: 0.5370 - val_loss: 1.0188 - val_accuracy: 0.5641\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8666 - accuracy: 0.5370 - val_loss: 1.0222 - val_accuracy: 0.5299\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8655 - accuracy: 0.5259 - val_loss: 1.0221 - val_accuracy: 0.5641\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8640 - accuracy: 0.5370 - val_loss: 1.0230 - val_accuracy: 0.5641\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 1.0221 - val_accuracy: 0.5641\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8655 - accuracy: 0.5370 - val_loss: 1.0244 - val_accuracy: 0.5299\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8643 - accuracy: 0.5259 - val_loss: 1.0234 - val_accuracy: 0.5641\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8644 - accuracy: 0.5333 - val_loss: 1.0246 - val_accuracy: 0.5299\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8637 - accuracy: 0.5333 - val_loss: 1.0238 - val_accuracy: 0.5641\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0243 - val_accuracy: 0.5641\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8675 - accuracy: 0.5370 - val_loss: 1.0274 - val_accuracy: 0.5641\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8655 - accuracy: 0.5481 - val_loss: 1.0311 - val_accuracy: 0.5299\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8651 - accuracy: 0.5296 - val_loss: 1.0247 - val_accuracy: 0.5299\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8674 - accuracy: 0.5407 - val_loss: 1.0216 - val_accuracy: 0.5641\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8722 - accuracy: 0.5370 - val_loss: 1.0283 - val_accuracy: 0.5641\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8654 - accuracy: 0.5296 - val_loss: 1.0275 - val_accuracy: 0.5299\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8691 - accuracy: 0.5333 - val_loss: 1.0297 - val_accuracy: 0.5299\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8647 - accuracy: 0.5333 - val_loss: 1.0150 - val_accuracy: 0.5641\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8643 - accuracy: 0.5370 - val_loss: 1.0117 - val_accuracy: 0.5641\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8705 - accuracy: 0.5148 - val_loss: 1.0165 - val_accuracy: 0.5299\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8655 - accuracy: 0.5333 - val_loss: 1.0124 - val_accuracy: 0.5299\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8654 - accuracy: 0.5333 - val_loss: 1.0144 - val_accuracy: 0.5299\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8679 - accuracy: 0.5185 - val_loss: 1.0184 - val_accuracy: 0.5641\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8669 - accuracy: 0.5370 - val_loss: 1.0149 - val_accuracy: 0.5641\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8689 - accuracy: 0.5148 - val_loss: 1.0184 - val_accuracy: 0.5299\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8687 - accuracy: 0.5259 - val_loss: 1.0161 - val_accuracy: 0.5641\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8657 - accuracy: 0.5370 - val_loss: 1.0174 - val_accuracy: 0.5641\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8722 - accuracy: 0.5333 - val_loss: 1.0160 - val_accuracy: 0.5641\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8667 - accuracy: 0.5259 - val_loss: 1.0216 - val_accuracy: 0.5299\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8688 - accuracy: 0.5333 - val_loss: 1.0249 - val_accuracy: 0.5299\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8693 - accuracy: 0.5037 - val_loss: 1.0199 - val_accuracy: 0.5641\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8651 - accuracy: 0.5370 - val_loss: 1.0199 - val_accuracy: 0.5641\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8643 - accuracy: 0.5370 - val_loss: 1.0213 - val_accuracy: 0.5641\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8657 - accuracy: 0.5333 - val_loss: 1.0241 - val_accuracy: 0.5299\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8634 - accuracy: 0.5333 - val_loss: 1.0236 - val_accuracy: 0.5641\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8657 - accuracy: 0.5333 - val_loss: 1.0223 - val_accuracy: 0.5641\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8659 - accuracy: 0.5259 - val_loss: 1.0258 - val_accuracy: 0.5641\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8658 - accuracy: 0.5185 - val_loss: 1.0232 - val_accuracy: 0.5641\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8660 - accuracy: 0.5370 - val_loss: 1.0245 - val_accuracy: 0.5641\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8682 - accuracy: 0.5148 - val_loss: 1.0240 - val_accuracy: 0.5299\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8641 - accuracy: 0.5333 - val_loss: 1.0244 - val_accuracy: 0.5299\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8630 - accuracy: 0.5407 - val_loss: 1.0241 - val_accuracy: 0.5641\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8649 - accuracy: 0.5333 - val_loss: 1.0266 - val_accuracy: 0.5641\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8652 - accuracy: 0.5111 - val_loss: 1.0273 - val_accuracy: 0.5299\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8650 - accuracy: 0.5222 - val_loss: 1.0249 - val_accuracy: 0.5641\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8650 - accuracy: 0.5074 - val_loss: 1.0256 - val_accuracy: 0.5641\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8659 - accuracy: 0.5148 - val_loss: 1.0295 - val_accuracy: 0.5299\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8639 - accuracy: 0.5370 - val_loss: 1.0243 - val_accuracy: 0.5641\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8648 - accuracy: 0.5370 - val_loss: 1.0238 - val_accuracy: 0.5641\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8674 - accuracy: 0.5111 - val_loss: 1.0308 - val_accuracy: 0.5299\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8687 - accuracy: 0.5074 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8662 - accuracy: 0.5370 - val_loss: 1.0247 - val_accuracy: 0.5641\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8666 - accuracy: 0.5111 - val_loss: 1.0247 - val_accuracy: 0.5641\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8651 - accuracy: 0.5370 - val_loss: 1.0205 - val_accuracy: 0.5641\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8638 - accuracy: 0.5296 - val_loss: 1.0224 - val_accuracy: 0.5641\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8647 - accuracy: 0.5370 - val_loss: 1.0223 - val_accuracy: 0.5641\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8673 - accuracy: 0.5296 - val_loss: 1.0250 - val_accuracy: 0.5299\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8673 - accuracy: 0.5222 - val_loss: 1.0258 - val_accuracy: 0.5641\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8646 - accuracy: 0.5333 - val_loss: 1.0275 - val_accuracy: 0.5299\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8640 - accuracy: 0.5333 - val_loss: 1.0284 - val_accuracy: 0.5299\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8650 - accuracy: 0.5333 - val_loss: 1.0266 - val_accuracy: 0.5299\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8638 - accuracy: 0.5593 - val_loss: 1.0242 - val_accuracy: 0.5641\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0252 - val_accuracy: 0.5641\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8634 - accuracy: 0.5481 - val_loss: 1.0304 - val_accuracy: 0.5299\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8683 - accuracy: 0.5333 - val_loss: 1.0356 - val_accuracy: 0.5299\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8678 - accuracy: 0.5296 - val_loss: 1.0286 - val_accuracy: 0.5641\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8695 - accuracy: 0.5074 - val_loss: 1.0307 - val_accuracy: 0.5299\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8640 - accuracy: 0.5296 - val_loss: 1.0261 - val_accuracy: 0.5641\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.0257 - val_accuracy: 0.5641\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8668 - accuracy: 0.5333 - val_loss: 1.0265 - val_accuracy: 0.5641\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8679 - accuracy: 0.5148 - val_loss: 1.0282 - val_accuracy: 0.5641\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0271 - val_accuracy: 0.5299\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8663 - accuracy: 0.5148 - val_loss: 1.0292 - val_accuracy: 0.5299\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8630 - accuracy: 0.5333 - val_loss: 1.0275 - val_accuracy: 0.5641\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0241 - val_accuracy: 0.5641\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8663 - accuracy: 0.5296 - val_loss: 1.0283 - val_accuracy: 0.5299\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8674 - accuracy: 0.5259 - val_loss: 1.0259 - val_accuracy: 0.5641\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8674 - accuracy: 0.5333 - val_loss: 1.0268 - val_accuracy: 0.5641\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8640 - accuracy: 0.5333 - val_loss: 1.0278 - val_accuracy: 0.5641\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8646 - accuracy: 0.5222 - val_loss: 1.0301 - val_accuracy: 0.5641\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8641 - accuracy: 0.5370 - val_loss: 1.0320 - val_accuracy: 0.5641\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8646 - accuracy: 0.5148 - val_loss: 1.0307 - val_accuracy: 0.5299\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8631 - accuracy: 0.5407 - val_loss: 1.0304 - val_accuracy: 0.5556\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0321 - val_accuracy: 0.5556\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8683 - accuracy: 0.5370 - val_loss: 1.0314 - val_accuracy: 0.5556\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8648 - accuracy: 0.5370 - val_loss: 1.0294 - val_accuracy: 0.5556\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8649 - accuracy: 0.5185 - val_loss: 1.0329 - val_accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8644 - accuracy: 0.5333 - val_loss: 1.0322 - val_accuracy: 0.5556\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8669 - accuracy: 0.5111 - val_loss: 1.0284 - val_accuracy: 0.5556\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8644 - accuracy: 0.5370 - val_loss: 1.0282 - val_accuracy: 0.5556\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8644 - accuracy: 0.5370 - val_loss: 1.0270 - val_accuracy: 0.5556\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8637 - accuracy: 0.5370 - val_loss: 1.0220 - val_accuracy: 0.5556\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8653 - accuracy: 0.5222 - val_loss: 1.0234 - val_accuracy: 0.5214\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8630 - accuracy: 0.5296 - val_loss: 1.0194 - val_accuracy: 0.5556\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8631 - accuracy: 0.5370 - val_loss: 1.0195 - val_accuracy: 0.5556\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0214 - val_accuracy: 0.5556\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.8652 - accuracy: 0.5259 - val_loss: 1.0245 - val_accuracy: 0.5214\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8642 - accuracy: 0.5037 - val_loss: 1.0236 - val_accuracy: 0.5556\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8635 - accuracy: 0.5370 - val_loss: 1.0247 - val_accuracy: 0.5556\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8657 - accuracy: 0.5037 - val_loss: 1.0280 - val_accuracy: 0.5214\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8672 - accuracy: 0.5259 - val_loss: 1.0255 - val_accuracy: 0.5556\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8635 - accuracy: 0.5259 - val_loss: 1.0269 - val_accuracy: 0.5556\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8680 - accuracy: 0.5370 - val_loss: 1.0296 - val_accuracy: 0.5556\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8664 - accuracy: 0.5370 - val_loss: 1.0267 - val_accuracy: 0.5556\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8641 - accuracy: 0.5296 - val_loss: 1.0288 - val_accuracy: 0.5214\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8633 - accuracy: 0.5296 - val_loss: 1.0293 - val_accuracy: 0.5556\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.8643 - accuracy: 0.5148 - val_loss: 1.0281 - val_accuracy: 0.5556\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0294 - val_accuracy: 0.5556\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8651 - accuracy: 0.5296 - val_loss: 1.0331 - val_accuracy: 0.5556\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8684 - accuracy: 0.5148 - val_loss: 1.0374 - val_accuracy: 0.5214\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 98us/step - loss: 0.8651 - accuracy: 0.5333 - val_loss: 1.0233 - val_accuracy: 0.5556\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8647 - accuracy: 0.5333 - val_loss: 1.0223 - val_accuracy: 0.5556\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0242 - val_accuracy: 0.5556\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8665 - accuracy: 0.5370 - val_loss: 1.0235 - val_accuracy: 0.5556\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8652 - accuracy: 0.5185 - val_loss: 1.0225 - val_accuracy: 0.5214\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8648 - accuracy: 0.5037 - val_loss: 1.0262 - val_accuracy: 0.5214\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.8623 - accuracy: 0.5556 - val_loss: 1.0260 - val_accuracy: 0.5556\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8735 - accuracy: 0.5370 - val_loss: 1.0284 - val_accuracy: 0.5641\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 1.0299 - val_accuracy: 0.5214\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8664 - accuracy: 0.5333 - val_loss: 1.0337 - val_accuracy: 0.5214\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8660 - accuracy: 0.4963 - val_loss: 1.0269 - val_accuracy: 0.5556\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8642 - accuracy: 0.5370 - val_loss: 1.0272 - val_accuracy: 0.5556\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 1.0295 - val_accuracy: 0.5556\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8669 - accuracy: 0.5185 - val_loss: 1.0340 - val_accuracy: 0.5214\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8642 - accuracy: 0.5370 - val_loss: 1.0264 - val_accuracy: 0.5641\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8626 - accuracy: 0.5370 - val_loss: 1.0298 - val_accuracy: 0.5556\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8644 - accuracy: 0.5259 - val_loss: 1.0358 - val_accuracy: 0.5214\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8658 - accuracy: 0.5333 - val_loss: 1.0323 - val_accuracy: 0.5214\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8645 - accuracy: 0.5333 - val_loss: 1.0326 - val_accuracy: 0.5214\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8641 - accuracy: 0.5407 - val_loss: 1.0284 - val_accuracy: 0.5556\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8640 - accuracy: 0.5370 - val_loss: 1.0313 - val_accuracy: 0.5556\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8652 - accuracy: 0.5370 - val_loss: 1.0307 - val_accuracy: 0.5556\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8623 - accuracy: 0.5444 - val_loss: 1.0326 - val_accuracy: 0.5214\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8700 - accuracy: 0.5333 - val_loss: 1.0388 - val_accuracy: 0.5214\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8666 - accuracy: 0.5296 - val_loss: 1.0299 - val_accuracy: 0.5556\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8661 - accuracy: 0.5370 - val_loss: 1.0326 - val_accuracy: 0.5556\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8634 - accuracy: 0.5370 - val_loss: 1.0303 - val_accuracy: 0.5556\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0316 - val_accuracy: 0.5214\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8636 - accuracy: 0.5333 - val_loss: 1.0317 - val_accuracy: 0.5214\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8628 - accuracy: 0.5185 - val_loss: 1.0307 - val_accuracy: 0.5641\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8636 - accuracy: 0.5370 - val_loss: 1.0292 - val_accuracy: 0.5641\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.0331 - val_accuracy: 0.5556\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0334 - val_accuracy: 0.5556\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8644 - accuracy: 0.5370 - val_loss: 1.0267 - val_accuracy: 0.5556\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8633 - accuracy: 0.5333 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8630 - accuracy: 0.5333 - val_loss: 1.0248 - val_accuracy: 0.5214\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8626 - accuracy: 0.5222 - val_loss: 1.0238 - val_accuracy: 0.5556\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0238 - val_accuracy: 0.5556\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8635 - accuracy: 0.5370 - val_loss: 1.0244 - val_accuracy: 0.5556\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8624 - accuracy: 0.5296 - val_loss: 1.0273 - val_accuracy: 0.5556\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8632 - accuracy: 0.5370 - val_loss: 1.0275 - val_accuracy: 0.5556\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0279 - val_accuracy: 0.5556\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8626 - accuracy: 0.5370 - val_loss: 1.0275 - val_accuracy: 0.5556\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8658 - accuracy: 0.5185 - val_loss: 1.0309 - val_accuracy: 0.5214\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8661 - accuracy: 0.5148 - val_loss: 1.0293 - val_accuracy: 0.5556\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8637 - accuracy: 0.5370 - val_loss: 1.0302 - val_accuracy: 0.5556\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 1.0299 - val_accuracy: 0.5556\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8628 - accuracy: 0.5407 - val_loss: 1.0323 - val_accuracy: 0.5214\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8628 - accuracy: 0.5333 - val_loss: 1.0322 - val_accuracy: 0.5214\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8666 - accuracy: 0.5111 - val_loss: 1.0287 - val_accuracy: 0.5556\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8652 - accuracy: 0.5296 - val_loss: 1.0339 - val_accuracy: 0.5214\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8661 - accuracy: 0.5148 - val_loss: 1.0352 - val_accuracy: 0.5214\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8648 - accuracy: 0.5259 - val_loss: 1.0305 - val_accuracy: 0.5556\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.8623 - accuracy: 0.5370 - val_loss: 1.0277 - val_accuracy: 0.5556\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8638 - accuracy: 0.5370 - val_loss: 1.0268 - val_accuracy: 0.5556\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8640 - accuracy: 0.5111 - val_loss: 1.0306 - val_accuracy: 0.5214\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0339 - val_accuracy: 0.5214\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8655 - accuracy: 0.5370 - val_loss: 1.0357 - val_accuracy: 0.5556\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8632 - accuracy: 0.5370 - val_loss: 1.0335 - val_accuracy: 0.5556\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0337 - val_accuracy: 0.5556\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8634 - accuracy: 0.5370 - val_loss: 1.0339 - val_accuracy: 0.5556\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8636 - accuracy: 0.5111 - val_loss: 1.0344 - val_accuracy: 0.5214\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8631 - accuracy: 0.5296 - val_loss: 1.0340 - val_accuracy: 0.5556\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8643 - accuracy: 0.5370 - val_loss: 1.0341 - val_accuracy: 0.5214\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8636 - accuracy: 0.5296 - val_loss: 1.0388 - val_accuracy: 0.5214\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0346 - val_accuracy: 0.5214\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8643 - accuracy: 0.5148 - val_loss: 1.0320 - val_accuracy: 0.5556\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.8631 - accuracy: 0.5370 - val_loss: 1.0332 - val_accuracy: 0.5556\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8628 - accuracy: 0.5333 - val_loss: 1.0332 - val_accuracy: 0.5556\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.0367 - val_accuracy: 0.5556\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8622 - accuracy: 0.5222 - val_loss: 1.0370 - val_accuracy: 0.5214\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8628 - accuracy: 0.5000 - val_loss: 1.0364 - val_accuracy: 0.5214\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8633 - accuracy: 0.5333 - val_loss: 1.0379 - val_accuracy: 0.5214\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8637 - accuracy: 0.5222 - val_loss: 1.0380 - val_accuracy: 0.5556\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8639 - accuracy: 0.5222 - val_loss: 1.0348 - val_accuracy: 0.5556\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8628 - accuracy: 0.5519 - val_loss: 1.0312 - val_accuracy: 0.5214\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.8630 - accuracy: 0.5259 - val_loss: 1.0253 - val_accuracy: 0.5556\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8624 - accuracy: 0.5370 - val_loss: 1.0264 - val_accuracy: 0.5556\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8647 - accuracy: 0.5370 - val_loss: 1.0283 - val_accuracy: 0.5556\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.0275 - val_accuracy: 0.5556\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8637 - accuracy: 0.5000 - val_loss: 1.0288 - val_accuracy: 0.5214\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8623 - accuracy: 0.5481 - val_loss: 1.0297 - val_accuracy: 0.5556\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8650 - accuracy: 0.5333 - val_loss: 1.0320 - val_accuracy: 0.5556\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8623 - accuracy: 0.5111 - val_loss: 1.0333 - val_accuracy: 0.5556\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8639 - accuracy: 0.5333 - val_loss: 1.0329 - val_accuracy: 0.5214\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8620 - accuracy: 0.5111 - val_loss: 1.0340 - val_accuracy: 0.5556\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0350 - val_accuracy: 0.5556\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8615 - accuracy: 0.5407 - val_loss: 1.0362 - val_accuracy: 0.5214\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8617 - accuracy: 0.5185 - val_loss: 1.0356 - val_accuracy: 0.5556\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0359 - val_accuracy: 0.5556\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8632 - accuracy: 0.5370 - val_loss: 1.0371 - val_accuracy: 0.5556\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8640 - accuracy: 0.5333 - val_loss: 1.0409 - val_accuracy: 0.5214\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8620 - accuracy: 0.5074 - val_loss: 1.0354 - val_accuracy: 0.5214\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8623 - accuracy: 0.5333 - val_loss: 1.0347 - val_accuracy: 0.5214\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8664 - accuracy: 0.5037 - val_loss: 1.0337 - val_accuracy: 0.5556\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8609 - accuracy: 0.5444 - val_loss: 1.0403 - val_accuracy: 0.5214\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8674 - accuracy: 0.5333 - val_loss: 1.0477 - val_accuracy: 0.5214\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8622 - accuracy: 0.5296 - val_loss: 1.0393 - val_accuracy: 0.5214\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8659 - accuracy: 0.5222 - val_loss: 1.0368 - val_accuracy: 0.5556\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8669 - accuracy: 0.5370 - val_loss: 1.0372 - val_accuracy: 0.5556\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8622 - accuracy: 0.5296 - val_loss: 1.0389 - val_accuracy: 0.5214\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8651 - accuracy: 0.5259 - val_loss: 1.0368 - val_accuracy: 0.5556\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8636 - accuracy: 0.5111 - val_loss: 1.0413 - val_accuracy: 0.5556\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8669 - accuracy: 0.5296 - val_loss: 1.0368 - val_accuracy: 0.5556\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8637 - accuracy: 0.5370 - val_loss: 1.0382 - val_accuracy: 0.5556\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8623 - accuracy: 0.5185 - val_loss: 1.0395 - val_accuracy: 0.5214\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 1.0386 - val_accuracy: 0.5214\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8651 - accuracy: 0.5296 - val_loss: 1.0357 - val_accuracy: 0.5556\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8621 - accuracy: 0.5296 - val_loss: 1.0379 - val_accuracy: 0.5214\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8632 - accuracy: 0.5037 - val_loss: 1.0238 - val_accuracy: 0.5556\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 163us/step - loss: 0.8634 - accuracy: 0.5259 - val_loss: 1.0202 - val_accuracy: 0.5214\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8650 - accuracy: 0.5333 - val_loss: 1.0196 - val_accuracy: 0.5556\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8623 - accuracy: 0.5370 - val_loss: 1.0229 - val_accuracy: 0.5556\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8645 - accuracy: 0.4963 - val_loss: 1.0261 - val_accuracy: 0.5214\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8617 - accuracy: 0.5259 - val_loss: 1.0243 - val_accuracy: 0.5556\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8633 - accuracy: 0.5333 - val_loss: 1.0284 - val_accuracy: 0.5556\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8625 - accuracy: 0.5111 - val_loss: 1.0316 - val_accuracy: 0.5214\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8639 - accuracy: 0.5333 - val_loss: 1.0325 - val_accuracy: 0.5214\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8629 - accuracy: 0.5296 - val_loss: 1.0285 - val_accuracy: 0.5556\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0295 - val_accuracy: 0.5556\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 1.0342 - val_accuracy: 0.5556\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8662 - accuracy: 0.5370 - val_loss: 1.0338 - val_accuracy: 0.5556\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8649 - accuracy: 0.5296 - val_loss: 1.0412 - val_accuracy: 0.5214\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8627 - accuracy: 0.5296 - val_loss: 1.0364 - val_accuracy: 0.5214\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8647 - accuracy: 0.5370 - val_loss: 1.0340 - val_accuracy: 0.5556\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8625 - accuracy: 0.5333 - val_loss: 1.0363 - val_accuracy: 0.5214\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8659 - accuracy: 0.5222 - val_loss: 1.0377 - val_accuracy: 0.5556\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8643 - accuracy: 0.5370 - val_loss: 1.0342 - val_accuracy: 0.5556\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8636 - accuracy: 0.5074 - val_loss: 1.0388 - val_accuracy: 0.5214\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8631 - accuracy: 0.4963 - val_loss: 1.0373 - val_accuracy: 0.5556\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8642 - accuracy: 0.5222 - val_loss: 1.0432 - val_accuracy: 0.5214\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8626 - accuracy: 0.5222 - val_loss: 1.0421 - val_accuracy: 0.5556\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8652 - accuracy: 0.5370 - val_loss: 1.0435 - val_accuracy: 0.5556\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8643 - accuracy: 0.5370 - val_loss: 1.0442 - val_accuracy: 0.5556\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0469 - val_accuracy: 0.5556\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8638 - accuracy: 0.5296 - val_loss: 1.0468 - val_accuracy: 0.5214\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8633 - accuracy: 0.5111 - val_loss: 1.0414 - val_accuracy: 0.5556\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8623 - accuracy: 0.5444 - val_loss: 1.0432 - val_accuracy: 0.5214\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8649 - accuracy: 0.5333 - val_loss: 1.0442 - val_accuracy: 0.5214\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8692 - accuracy: 0.5000 - val_loss: 1.0394 - val_accuracy: 0.5556\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8613 - accuracy: 0.5111 - val_loss: 1.0421 - val_accuracy: 0.5556\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8635 - accuracy: 0.5370 - val_loss: 1.0431 - val_accuracy: 0.5556\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0431 - val_accuracy: 0.5556\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7699 - accuracy: 0.59 - 0s 99us/step - loss: 0.8643 - accuracy: 0.5222 - val_loss: 1.0477 - val_accuracy: 0.5214\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8646 - accuracy: 0.5148 - val_loss: 1.0372 - val_accuracy: 0.5556\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8629 - accuracy: 0.5296 - val_loss: 1.0348 - val_accuracy: 0.5214\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8620 - accuracy: 0.5222 - val_loss: 1.0306 - val_accuracy: 0.5556\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8632 - accuracy: 0.5370 - val_loss: 1.0310 - val_accuracy: 0.5556\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8664 - accuracy: 0.5259 - val_loss: 1.0390 - val_accuracy: 0.5214\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8638 - accuracy: 0.5296 - val_loss: 1.0318 - val_accuracy: 0.5214\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8619 - accuracy: 0.5481 - val_loss: 1.0297 - val_accuracy: 0.5556\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8656 - accuracy: 0.5370 - val_loss: 1.0330 - val_accuracy: 0.5556\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8624 - accuracy: 0.5185 - val_loss: 1.0364 - val_accuracy: 0.5214\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8626 - accuracy: 0.5296 - val_loss: 1.0330 - val_accuracy: 0.5556\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0352 - val_accuracy: 0.5556\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 1.0354 - val_accuracy: 0.5556\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8635 - accuracy: 0.5370 - val_loss: 1.0388 - val_accuracy: 0.5556\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8611 - accuracy: 0.5444 - val_loss: 1.0440 - val_accuracy: 0.5214\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 1.0447 - val_accuracy: 0.5214\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8637 - accuracy: 0.5000 - val_loss: 1.0436 - val_accuracy: 0.5556\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8613 - accuracy: 0.5370 - val_loss: 1.0456 - val_accuracy: 0.5214\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8615 - accuracy: 0.5333 - val_loss: 1.0457 - val_accuracy: 0.5214\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8616 - accuracy: 0.5185 - val_loss: 1.0459 - val_accuracy: 0.5556\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8657 - accuracy: 0.5074 - val_loss: 1.0476 - val_accuracy: 0.5214\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8625 - accuracy: 0.5148 - val_loss: 1.0448 - val_accuracy: 0.5556\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8613 - accuracy: 0.5370 - val_loss: 1.0431 - val_accuracy: 0.5556\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0418 - val_accuracy: 0.5214\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8624 - accuracy: 0.5185 - val_loss: 1.0406 - val_accuracy: 0.5556\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8633 - accuracy: 0.5185 - val_loss: 1.0414 - val_accuracy: 0.5214\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8612 - accuracy: 0.5333 - val_loss: 1.0402 - val_accuracy: 0.5214\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8634 - accuracy: 0.5370 - val_loss: 1.0417 - val_accuracy: 0.5556\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8634 - accuracy: 0.5370 - val_loss: 1.0403 - val_accuracy: 0.5556\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.8615 - accuracy: 0.5370 - val_loss: 1.0444 - val_accuracy: 0.5214\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8649 - accuracy: 0.5333 - val_loss: 1.0495 - val_accuracy: 0.5214\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8615 - accuracy: 0.5148 - val_loss: 1.0416 - val_accuracy: 0.5556\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8632 - accuracy: 0.5370 - val_loss: 1.0414 - val_accuracy: 0.5556\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8637 - accuracy: 0.5370 - val_loss: 1.0402 - val_accuracy: 0.5556\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8608 - accuracy: 0.5370 - val_loss: 1.0412 - val_accuracy: 0.5214\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8610 - accuracy: 0.5333 - val_loss: 1.0439 - val_accuracy: 0.5214\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8619 - accuracy: 0.5074 - val_loss: 1.0429 - val_accuracy: 0.5556\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 1.0439 - val_accuracy: 0.5556\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0442 - val_accuracy: 0.5556\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8617 - accuracy: 0.5370 - val_loss: 1.0429 - val_accuracy: 0.5556\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 1.0452 - val_accuracy: 0.5214\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8648 - accuracy: 0.5333 - val_loss: 1.0465 - val_accuracy: 0.5556\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8612 - accuracy: 0.5296 - val_loss: 1.0499 - val_accuracy: 0.5214\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8645 - accuracy: 0.5333 - val_loss: 1.0510 - val_accuracy: 0.5214\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8664 - accuracy: 0.5259 - val_loss: 1.0453 - val_accuracy: 0.5556\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8621 - accuracy: 0.5370 - val_loss: 1.0482 - val_accuracy: 0.5556\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0479 - val_accuracy: 0.5556\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8609 - accuracy: 0.5370 - val_loss: 1.0459 - val_accuracy: 0.5556\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8624 - accuracy: 0.5185 - val_loss: 1.0419 - val_accuracy: 0.5214\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8615 - accuracy: 0.5296 - val_loss: 1.0376 - val_accuracy: 0.5556\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8618 - accuracy: 0.5148 - val_loss: 1.0411 - val_accuracy: 0.5556\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8620 - accuracy: 0.5222 - val_loss: 1.0425 - val_accuracy: 0.5214\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8630 - accuracy: 0.5074 - val_loss: 1.0414 - val_accuracy: 0.5556\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0439 - val_accuracy: 0.5556\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8621 - accuracy: 0.5333 - val_loss: 1.0458 - val_accuracy: 0.5556\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8618 - accuracy: 0.5222 - val_loss: 1.0529 - val_accuracy: 0.5214\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8634 - accuracy: 0.5222 - val_loss: 1.0569 - val_accuracy: 0.5214\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8638 - accuracy: 0.5296 - val_loss: 1.0348 - val_accuracy: 0.5556\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8640 - accuracy: 0.5370 - val_loss: 1.0308 - val_accuracy: 0.5556\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8620 - accuracy: 0.5370 - val_loss: 1.0286 - val_accuracy: 0.5556\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0293 - val_accuracy: 0.5556\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8631 - accuracy: 0.5370 - val_loss: 1.0305 - val_accuracy: 0.5556\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8600 - accuracy: 0.5370 - val_loss: 1.0334 - val_accuracy: 0.5556\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 366us/step - loss: 0.8636 - accuracy: 0.5259 - val_loss: 1.0413 - val_accuracy: 0.5214\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8608 - accuracy: 0.5111 - val_loss: 1.0358 - val_accuracy: 0.5556\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8609 - accuracy: 0.5370 - val_loss: 1.0388 - val_accuracy: 0.5556\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8630 - accuracy: 0.5222 - val_loss: 1.0387 - val_accuracy: 0.5214\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8628 - accuracy: 0.5333 - val_loss: 1.0393 - val_accuracy: 0.5214\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8618 - accuracy: 0.5222 - val_loss: 1.0378 - val_accuracy: 0.5556\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8623 - accuracy: 0.5370 - val_loss: 1.0384 - val_accuracy: 0.5556\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8648 - accuracy: 0.5037 - val_loss: 1.0419 - val_accuracy: 0.5214\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8646 - accuracy: 0.5333 - val_loss: 1.0394 - val_accuracy: 0.5556\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8624 - accuracy: 0.5370 - val_loss: 1.0402 - val_accuracy: 0.5556\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0408 - val_accuracy: 0.5556\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8650 - accuracy: 0.5074 - val_loss: 1.0450 - val_accuracy: 0.5214\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8619 - accuracy: 0.5333 - val_loss: 1.0425 - val_accuracy: 0.5556\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8609 - accuracy: 0.5370 - val_loss: 1.0452 - val_accuracy: 0.5556\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 190us/step - loss: 0.8612 - accuracy: 0.4963 - val_loss: 1.0501 - val_accuracy: 0.5214\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.8612 - accuracy: 0.5333 - val_loss: 1.0497 - val_accuracy: 0.5214\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8623 - accuracy: 0.5333 - val_loss: 1.0461 - val_accuracy: 0.5556\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8620 - accuracy: 0.5370 - val_loss: 1.0482 - val_accuracy: 0.5556\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8685 - accuracy: 0.4926 - val_loss: 1.0485 - val_accuracy: 0.5214\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8621 - accuracy: 0.5259 - val_loss: 1.0473 - val_accuracy: 0.5556\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0474 - val_accuracy: 0.5556\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0466 - val_accuracy: 0.5556\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8638 - accuracy: 0.5222 - val_loss: 1.0513 - val_accuracy: 0.5214\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.8616 - accuracy: 0.5296 - val_loss: 1.0477 - val_accuracy: 0.5556\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.8608 - accuracy: 0.5370 - val_loss: 1.0459 - val_accuracy: 0.5556\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8607 - accuracy: 0.5370 - val_loss: 1.0511 - val_accuracy: 0.5556\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8624 - accuracy: 0.5259 - val_loss: 1.0520 - val_accuracy: 0.5214\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8613 - accuracy: 0.4889 - val_loss: 1.0463 - val_accuracy: 0.5556\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8623 - accuracy: 0.5111 - val_loss: 1.0455 - val_accuracy: 0.5214\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 1.0485 - val_accuracy: 0.5214\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8613 - accuracy: 0.5259 - val_loss: 1.0464 - val_accuracy: 0.5556\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0487 - val_accuracy: 0.5556\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8638 - accuracy: 0.5333 - val_loss: 1.0532 - val_accuracy: 0.5214\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8632 - accuracy: 0.5333 - val_loss: 1.0526 - val_accuracy: 0.5214\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8606 - accuracy: 0.5111 - val_loss: 1.0514 - val_accuracy: 0.5214\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8611 - accuracy: 0.5333 - val_loss: 1.0511 - val_accuracy: 0.5214\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8613 - accuracy: 0.5333 - val_loss: 1.0456 - val_accuracy: 0.5556\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8625 - accuracy: 0.5037 - val_loss: 1.0468 - val_accuracy: 0.5556\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8603 - accuracy: 0.5370 - val_loss: 1.0501 - val_accuracy: 0.5556\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8655 - accuracy: 0.5370 - val_loss: 1.0499 - val_accuracy: 0.5556\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 1.0482 - val_accuracy: 0.5556\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8629 - accuracy: 0.5111 - val_loss: 1.0531 - val_accuracy: 0.5214\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8622 - accuracy: 0.5296 - val_loss: 1.0517 - val_accuracy: 0.5556\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0476 - val_accuracy: 0.5556\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8610 - accuracy: 0.5074 - val_loss: 1.0519 - val_accuracy: 0.5214\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8624 - accuracy: 0.5333 - val_loss: 1.0488 - val_accuracy: 0.5556\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8617 - accuracy: 0.5370 - val_loss: 1.0513 - val_accuracy: 0.5556\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8614 - accuracy: 0.5333 - val_loss: 1.0528 - val_accuracy: 0.5214\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8616 - accuracy: 0.5333 - val_loss: 1.0519 - val_accuracy: 0.5214\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8635 - accuracy: 0.5407 - val_loss: 1.0479 - val_accuracy: 0.5556\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8656 - accuracy: 0.5111 - val_loss: 1.0528 - val_accuracy: 0.5214\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8596 - accuracy: 0.5296 - val_loss: 1.0507 - val_accuracy: 0.5556\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 1.0526 - val_accuracy: 0.5556\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8616 - accuracy: 0.5333 - val_loss: 1.0542 - val_accuracy: 0.5214\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8630 - accuracy: 0.5333 - val_loss: 1.0542 - val_accuracy: 0.5214\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8650 - accuracy: 0.5037 - val_loss: 1.0519 - val_accuracy: 0.5556\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8691 - accuracy: 0.5111 - val_loss: 1.0545 - val_accuracy: 0.5214\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8601 - accuracy: 0.5185 - val_loss: 1.0509 - val_accuracy: 0.5214\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8615 - accuracy: 0.5407 - val_loss: 1.0514 - val_accuracy: 0.5556\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8637 - accuracy: 0.4926 - val_loss: 1.0589 - val_accuracy: 0.5214\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8658 - accuracy: 0.5333 - val_loss: 1.0547 - val_accuracy: 0.5214\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8602 - accuracy: 0.5407 - val_loss: 1.0493 - val_accuracy: 0.5556\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8626 - accuracy: 0.5333 - val_loss: 1.0493 - val_accuracy: 0.5556\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 1.0491 - val_accuracy: 0.5556\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0530 - val_accuracy: 0.5556\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0447 - val_accuracy: 0.5556\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 1.0352 - val_accuracy: 0.5556\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8626 - accuracy: 0.5333 - val_loss: 1.0376 - val_accuracy: 0.5214\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8619 - accuracy: 0.5333 - val_loss: 1.0353 - val_accuracy: 0.5214\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8660 - accuracy: 0.5333 - val_loss: 1.0370 - val_accuracy: 0.5214\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8611 - accuracy: 0.5259 - val_loss: 1.0344 - val_accuracy: 0.5556\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0347 - val_accuracy: 0.5556\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8635 - accuracy: 0.4963 - val_loss: 1.0427 - val_accuracy: 0.5214\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8642 - accuracy: 0.5222 - val_loss: 1.0436 - val_accuracy: 0.5214\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8605 - accuracy: 0.5333 - val_loss: 1.0443 - val_accuracy: 0.5214\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8608 - accuracy: 0.5333 - val_loss: 1.0462 - val_accuracy: 0.5214\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8613 - accuracy: 0.5222 - val_loss: 1.0451 - val_accuracy: 0.5556\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8604 - accuracy: 0.5074 - val_loss: 1.0455 - val_accuracy: 0.5556\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8612 - accuracy: 0.5148 - val_loss: 1.0490 - val_accuracy: 0.5214\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8620 - accuracy: 0.5333 - val_loss: 1.0540 - val_accuracy: 0.5214\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.8623 - accuracy: 0.5074 - val_loss: 1.0525 - val_accuracy: 0.5556\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8616 - accuracy: 0.5222 - val_loss: 1.0570 - val_accuracy: 0.5214\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8604 - accuracy: 0.5333 - val_loss: 1.0545 - val_accuracy: 0.5214\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8598 - accuracy: 0.5370 - val_loss: 1.0521 - val_accuracy: 0.5556\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8646 - accuracy: 0.5370 - val_loss: 1.0478 - val_accuracy: 0.5556\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8650 - accuracy: 0.5333 - val_loss: 1.0498 - val_accuracy: 0.5556\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8658 - accuracy: 0.5111 - val_loss: 1.0496 - val_accuracy: 0.5214\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8603 - accuracy: 0.5222 - val_loss: 1.0519 - val_accuracy: 0.5214\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0543 - val_accuracy: 0.5214\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.8615 - accuracy: 0.5185 - val_loss: 1.0540 - val_accuracy: 0.5556\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8611 - accuracy: 0.5370 - val_loss: 1.0535 - val_accuracy: 0.5556\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8650 - accuracy: 0.5333 - val_loss: 1.0623 - val_accuracy: 0.5214\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8675 - accuracy: 0.5333 - val_loss: 1.0626 - val_accuracy: 0.5214\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8642 - accuracy: 0.5444 - val_loss: 1.0519 - val_accuracy: 0.5556\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8681 - accuracy: 0.5370 - val_loss: 1.0541 - val_accuracy: 0.5556\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8630 - accuracy: 0.5370 - val_loss: 1.0517 - val_accuracy: 0.5556\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8617 - accuracy: 0.5037 - val_loss: 1.0517 - val_accuracy: 0.5214\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8611 - accuracy: 0.5259 - val_loss: 1.0485 - val_accuracy: 0.5556\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8644 - accuracy: 0.5370 - val_loss: 1.0493 - val_accuracy: 0.5556\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8602 - accuracy: 0.5370 - val_loss: 1.0522 - val_accuracy: 0.5214\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8612 - accuracy: 0.5333 - val_loss: 1.0553 - val_accuracy: 0.5214\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8619 - accuracy: 0.5333 - val_loss: 1.0562 - val_accuracy: 0.5214\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8606 - accuracy: 0.5148 - val_loss: 1.0524 - val_accuracy: 0.5556\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 1.0592 - val_accuracy: 0.5556\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8644 - accuracy: 0.5259 - val_loss: 1.0596 - val_accuracy: 0.5214\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 256us/step - loss: 0.8608 - accuracy: 0.5074 - val_loss: 1.0538 - val_accuracy: 0.5556\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8617 - accuracy: 0.5370 - val_loss: 1.0515 - val_accuracy: 0.5556\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8617 - accuracy: 0.5185 - val_loss: 1.0518 - val_accuracy: 0.5214\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8626 - accuracy: 0.4963 - val_loss: 1.0477 - val_accuracy: 0.5556\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8624 - accuracy: 0.5370 - val_loss: 1.0478 - val_accuracy: 0.5556\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8605 - accuracy: 0.5296 - val_loss: 1.0520 - val_accuracy: 0.5214\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8598 - accuracy: 0.5333 - val_loss: 1.0524 - val_accuracy: 0.5214\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8606 - accuracy: 0.5444 - val_loss: 1.0529 - val_accuracy: 0.5556\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8603 - accuracy: 0.5370 - val_loss: 1.0519 - val_accuracy: 0.5556\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8631 - accuracy: 0.5037 - val_loss: 1.0536 - val_accuracy: 0.5214\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8620 - accuracy: 0.5259 - val_loss: 1.0504 - val_accuracy: 0.5556\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8602 - accuracy: 0.5259 - val_loss: 1.0537 - val_accuracy: 0.5214\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 274us/step - loss: 0.8605 - accuracy: 0.5074 - val_loss: 1.0530 - val_accuracy: 0.5556\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8602 - accuracy: 0.5222 - val_loss: 1.0563 - val_accuracy: 0.5214\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8650 - accuracy: 0.5111 - val_loss: 1.0544 - val_accuracy: 0.5556\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0605 - val_accuracy: 0.5214\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8613 - accuracy: 0.5333 - val_loss: 1.0563 - val_accuracy: 0.5214\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 384us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 1.0521 - val_accuracy: 0.5556\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8636 - accuracy: 0.5370 - val_loss: 1.0516 - val_accuracy: 0.5556\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 149us/step - loss: 0.8627 - accuracy: 0.5074 - val_loss: 1.0569 - val_accuracy: 0.5214\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8617 - accuracy: 0.5333 - val_loss: 1.0545 - val_accuracy: 0.5556\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 487us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0556 - val_accuracy: 0.5556\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 393us/step - loss: 0.8599 - accuracy: 0.5259 - val_loss: 1.0554 - val_accuracy: 0.5556\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0544 - val_accuracy: 0.5556\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8595 - accuracy: 0.5370 - val_loss: 1.0565 - val_accuracy: 0.5556\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.8644 - accuracy: 0.5333 - val_loss: 1.0569 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.185678). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8614 - accuracy: 0.5407 - val_loss: 1.0553 - val_accuracy: 0.5214\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8603 - accuracy: 0.5333 - val_loss: 1.0574 - val_accuracy: 0.5214\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 520us/step - loss: 0.8621 - accuracy: 0.5148 - val_loss: 1.0550 - val_accuracy: 0.5556\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 313us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0516 - val_accuracy: 0.5556\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8600 - accuracy: 0.5370 - val_loss: 1.0544 - val_accuracy: 0.5556\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8603 - accuracy: 0.5185 - val_loss: 1.0582 - val_accuracy: 0.5214\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 418us/step - loss: 0.8613 - accuracy: 0.5333 - val_loss: 1.0586 - val_accuracy: 0.5214\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8628 - accuracy: 0.5481 - val_loss: 1.0574 - val_accuracy: 0.5556\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0584 - val_accuracy: 0.5556\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8594 - accuracy: 0.5370 - val_loss: 1.0582 - val_accuracy: 0.5556\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8633 - accuracy: 0.5333 - val_loss: 1.0595 - val_accuracy: 0.5556\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0579 - val_accuracy: 0.5556\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.8599 - accuracy: 0.5370 - val_loss: 1.0563 - val_accuracy: 0.5556\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8601 - accuracy: 0.5222 - val_loss: 1.0605 - val_accuracy: 0.5214\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8603 - accuracy: 0.5333 - val_loss: 1.0557 - val_accuracy: 0.5556\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.0551 - val_accuracy: 0.5556\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8633 - accuracy: 0.5370 - val_loss: 1.0569 - val_accuracy: 0.5556\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8621 - accuracy: 0.5370 - val_loss: 1.0629 - val_accuracy: 0.5214\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8626 - accuracy: 0.5333 - val_loss: 1.0575 - val_accuracy: 0.5214\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.8626 - accuracy: 0.5296 - val_loss: 1.0535 - val_accuracy: 0.5556\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0564 - val_accuracy: 0.5556\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8603 - accuracy: 0.5111 - val_loss: 1.0597 - val_accuracy: 0.5214\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8608 - accuracy: 0.5148 - val_loss: 1.0585 - val_accuracy: 0.5556\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8628 - accuracy: 0.5296 - val_loss: 1.0632 - val_accuracy: 0.5556\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8654 - accuracy: 0.5074 - val_loss: 1.0657 - val_accuracy: 0.5214\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 317us/step - loss: 0.8609 - accuracy: 0.5222 - val_loss: 1.0636 - val_accuracy: 0.5556\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.8624 - accuracy: 0.5370 - val_loss: 1.0651 - val_accuracy: 0.5556\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8597 - accuracy: 0.5370 - val_loss: 1.0655 - val_accuracy: 0.5214\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8622 - accuracy: 0.5333 - val_loss: 1.0640 - val_accuracy: 0.5214\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8605 - accuracy: 0.5185 - val_loss: 1.0616 - val_accuracy: 0.5556\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.8613 - accuracy: 0.5148 - val_loss: 1.0602 - val_accuracy: 0.5556\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.8609 - accuracy: 0.5556 - val_loss: 1.0617 - val_accuracy: 0.5214\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8596 - accuracy: 0.5333 - val_loss: 1.0636 - val_accuracy: 0.5214\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8609 - accuracy: 0.5074 - val_loss: 1.0650 - val_accuracy: 0.5214\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8596 - accuracy: 0.5111 - val_loss: 1.0635 - val_accuracy: 0.5556\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0642 - val_accuracy: 0.5556\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8598 - accuracy: 0.5370 - val_loss: 1.0619 - val_accuracy: 0.5556\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0611 - val_accuracy: 0.5214\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8608 - accuracy: 0.5333 - val_loss: 1.0570 - val_accuracy: 0.5214\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8611 - accuracy: 0.5222 - val_loss: 1.0571 - val_accuracy: 0.5556\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8644 - accuracy: 0.5259 - val_loss: 1.0585 - val_accuracy: 0.5214\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8600 - accuracy: 0.5333 - val_loss: 1.0579 - val_accuracy: 0.5556\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8605 - accuracy: 0.5370 - val_loss: 1.0568 - val_accuracy: 0.5556\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8605 - accuracy: 0.5370 - val_loss: 1.0583 - val_accuracy: 0.5556\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8607 - accuracy: 0.55 - 0s 279us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0592 - val_accuracy: 0.5556\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8610 - accuracy: 0.5296 - val_loss: 1.0635 - val_accuracy: 0.5214\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8600 - accuracy: 0.5333 - val_loss: 1.0632 - val_accuracy: 0.5214\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8627 - accuracy: 0.5111 - val_loss: 1.0601 - val_accuracy: 0.5556\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8625 - accuracy: 0.5333 - val_loss: 1.0632 - val_accuracy: 0.5214\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8636 - accuracy: 0.5333 - val_loss: 1.0670 - val_accuracy: 0.5214\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8624 - accuracy: 0.5259 - val_loss: 1.0628 - val_accuracy: 0.5556\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0591 - val_accuracy: 0.5556\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0585 - val_accuracy: 0.5556\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8606 - accuracy: 0.5259 - val_loss: 1.0615 - val_accuracy: 0.5214\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 593us/step - loss: 0.8646 - accuracy: 0.5333 - val_loss: 1.0600 - val_accuracy: 0.5214\n",
      "Epoch 724/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 391us/step - loss: 0.8621 - accuracy: 0.5333 - val_loss: 1.0600 - val_accuracy: 0.5214\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8649 - accuracy: 0.5333 - val_loss: 1.0657 - val_accuracy: 0.5214\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8649 - accuracy: 0.5000 - val_loss: 1.0585 - val_accuracy: 0.5556\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0605 - val_accuracy: 0.5556\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.62 - 0s 199us/step - loss: 0.8607 - accuracy: 0.5370 - val_loss: 1.0599 - val_accuracy: 0.5214\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 873us/step - loss: 0.8617 - accuracy: 0.5333 - val_loss: 1.0595 - val_accuracy: 0.5214\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8636 - accuracy: 0.5296 - val_loss: 1.0580 - val_accuracy: 0.5556\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 468us/step - loss: 0.8624 - accuracy: 0.5370 - val_loss: 1.0569 - val_accuracy: 0.5556\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8597 - accuracy: 0.5333 - val_loss: 1.0561 - val_accuracy: 0.5556\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8617 - accuracy: 0.5185 - val_loss: 1.0573 - val_accuracy: 0.5556\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8640 - accuracy: 0.5185 - val_loss: 1.0631 - val_accuracy: 0.5214\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.8597 - accuracy: 0.5370 - val_loss: 1.0580 - val_accuracy: 0.5556\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8639 - accuracy: 0.5333 - val_loss: 1.0642 - val_accuracy: 0.5556\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0637 - val_accuracy: 0.5556\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0614 - val_accuracy: 0.5556\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8629 - accuracy: 0.5370 - val_loss: 1.0601 - val_accuracy: 0.5556\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.8628 - accuracy: 0.5296 - val_loss: 1.0601 - val_accuracy: 0.5214\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8607 - accuracy: 0.5333 - val_loss: 1.0583 - val_accuracy: 0.5556\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0591 - val_accuracy: 0.5556\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8604 - accuracy: 0.5037 - val_loss: 1.0646 - val_accuracy: 0.5214\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8614 - accuracy: 0.5333 - val_loss: 1.0676 - val_accuracy: 0.5214\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8627 - accuracy: 0.5556 - val_loss: 1.0688 - val_accuracy: 0.5556\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8636 - accuracy: 0.5370 - val_loss: 1.0677 - val_accuracy: 0.5556\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8640 - accuracy: 0.5370 - val_loss: 1.0616 - val_accuracy: 0.5556\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8638 - accuracy: 0.5185 - val_loss: 1.0668 - val_accuracy: 0.5214\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8584 - accuracy: 0.5296 - val_loss: 1.0639 - val_accuracy: 0.5556\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8643 - accuracy: 0.5296 - val_loss: 1.0742 - val_accuracy: 0.5214\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8617 - accuracy: 0.5407 - val_loss: 1.0674 - val_accuracy: 0.5556\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8656 - accuracy: 0.5148 - val_loss: 1.0767 - val_accuracy: 0.5214\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8645 - accuracy: 0.5333 - val_loss: 1.0655 - val_accuracy: 0.5556\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8675 - accuracy: 0.4815 - val_loss: 1.0610 - val_accuracy: 0.5556\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8623 - accuracy: 0.5370 - val_loss: 1.0536 - val_accuracy: 0.5556\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8636 - accuracy: 0.5185 - val_loss: 1.0553 - val_accuracy: 0.5214\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8663 - accuracy: 0.5333 - val_loss: 1.0518 - val_accuracy: 0.5214\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8610 - accuracy: 0.5593 - val_loss: 1.0521 - val_accuracy: 0.5556\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0541 - val_accuracy: 0.5556\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8605 - accuracy: 0.5148 - val_loss: 1.0604 - val_accuracy: 0.5214\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8629 - accuracy: 0.5148 - val_loss: 1.0575 - val_accuracy: 0.5556\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8606 - accuracy: 0.5444 - val_loss: 1.0619 - val_accuracy: 0.5214\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8611 - accuracy: 0.5333 - val_loss: 1.0574 - val_accuracy: 0.5556\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8597 - accuracy: 0.5370 - val_loss: 1.0562 - val_accuracy: 0.5556\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8597 - accuracy: 0.5370 - val_loss: 1.0565 - val_accuracy: 0.5556\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0581 - val_accuracy: 0.5556\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0590 - val_accuracy: 0.5556\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0595 - val_accuracy: 0.5556\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0597 - val_accuracy: 0.5556\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8620 - accuracy: 0.5222 - val_loss: 1.0603 - val_accuracy: 0.5556\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8623 - accuracy: 0.5370 - val_loss: 1.0561 - val_accuracy: 0.5556\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8610 - accuracy: 0.5074 - val_loss: 1.0598 - val_accuracy: 0.5556\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8610 - accuracy: 0.5333 - val_loss: 1.0624 - val_accuracy: 0.5214\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8590 - accuracy: 0.5333 - val_loss: 1.0608 - val_accuracy: 0.5214\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0602 - val_accuracy: 0.5556\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8622 - accuracy: 0.5259 - val_loss: 1.0632 - val_accuracy: 0.5214\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8602 - accuracy: 0.5333 - val_loss: 1.0628 - val_accuracy: 0.5214\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8625 - accuracy: 0.5074 - val_loss: 1.0591 - val_accuracy: 0.5556\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8622 - accuracy: 0.5074 - val_loss: 1.0653 - val_accuracy: 0.5214\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8600 - accuracy: 0.5333 - val_loss: 1.0620 - val_accuracy: 0.5556\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8605 - accuracy: 0.5185 - val_loss: 1.0648 - val_accuracy: 0.5214\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0645 - val_accuracy: 0.5556\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8593 - accuracy: 0.5370 - val_loss: 1.0670 - val_accuracy: 0.5556\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0729 - val_accuracy: 0.5214\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8840 - accuracy: 0.5296 - val_loss: 1.0713 - val_accuracy: 0.5556\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0496 - val_accuracy: 0.5556\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8639 - accuracy: 0.5370 - val_loss: 1.0422 - val_accuracy: 0.5556\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8606 - accuracy: 0.5481 - val_loss: 1.0481 - val_accuracy: 0.5214\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8616 - accuracy: 0.5333 - val_loss: 1.0489 - val_accuracy: 0.5214\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8606 - accuracy: 0.5333 - val_loss: 1.0430 - val_accuracy: 0.5556\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8598 - accuracy: 0.5370 - val_loss: 1.0409 - val_accuracy: 0.5556\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8618 - accuracy: 0.5333 - val_loss: 1.0430 - val_accuracy: 0.5556\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0458 - val_accuracy: 0.5556\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8651 - accuracy: 0.5259 - val_loss: 1.0467 - val_accuracy: 0.5214\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8606 - accuracy: 0.5444 - val_loss: 1.0434 - val_accuracy: 0.5556\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0436 - val_accuracy: 0.5556\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8603 - accuracy: 0.5370 - val_loss: 1.0479 - val_accuracy: 0.5556\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8681 - accuracy: 0.5074 - val_loss: 1.0572 - val_accuracy: 0.5214\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8656 - accuracy: 0.5148 - val_loss: 1.0464 - val_accuracy: 0.5556\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8658 - accuracy: 0.5370 - val_loss: 1.0464 - val_accuracy: 0.5556\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.8626 - accuracy: 0.5074 - val_loss: 1.0511 - val_accuracy: 0.5214\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8597 - accuracy: 0.5074 - val_loss: 1.0509 - val_accuracy: 0.5556\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0492 - val_accuracy: 0.5556\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8599 - accuracy: 0.5259 - val_loss: 1.0528 - val_accuracy: 0.5214\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8610 - accuracy: 0.5333 - val_loss: 1.0528 - val_accuracy: 0.5214\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8620 - accuracy: 0.5259 - val_loss: 1.0523 - val_accuracy: 0.5556\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8603 - accuracy: 0.5370 - val_loss: 1.0482 - val_accuracy: 0.5556\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.0495 - val_accuracy: 0.5556\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8618 - accuracy: 0.5222 - val_loss: 1.0525 - val_accuracy: 0.5214\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8633 - accuracy: 0.5296 - val_loss: 1.0527 - val_accuracy: 0.5556\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8615 - accuracy: 0.5370 - val_loss: 1.0506 - val_accuracy: 0.5556\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8631 - accuracy: 0.5370 - val_loss: 1.0523 - val_accuracy: 0.5556\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8643 - accuracy: 0.4926 - val_loss: 1.0603 - val_accuracy: 0.5556\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8628 - accuracy: 0.5370 - val_loss: 1.0558 - val_accuracy: 0.5556\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8595 - accuracy: 0.5370 - val_loss: 1.0590 - val_accuracy: 0.5214\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8649 - accuracy: 0.5111 - val_loss: 1.0694 - val_accuracy: 0.4957\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8655 - accuracy: 0.5519 - val_loss: 1.0606 - val_accuracy: 0.5556\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8596 - accuracy: 0.5370 - val_loss: 1.0586 - val_accuracy: 0.5556\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8609 - accuracy: 0.5370 - val_loss: 1.0580 - val_accuracy: 0.5556\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8600 - accuracy: 0.5370 - val_loss: 1.0594 - val_accuracy: 0.5556\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8594 - accuracy: 0.5296 - val_loss: 1.0604 - val_accuracy: 0.5214\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8599 - accuracy: 0.5296 - val_loss: 1.0608 - val_accuracy: 0.5214\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8614 - accuracy: 0.5148 - val_loss: 1.0608 - val_accuracy: 0.5556\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8603 - accuracy: 0.5259 - val_loss: 1.0601 - val_accuracy: 0.5556\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8611 - accuracy: 0.4926 - val_loss: 1.0619 - val_accuracy: 0.5556\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8612 - accuracy: 0.5259 - val_loss: 1.0628 - val_accuracy: 0.5214\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8603 - accuracy: 0.5296 - val_loss: 1.0616 - val_accuracy: 0.5556\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8616 - accuracy: 0.5259 - val_loss: 1.0667 - val_accuracy: 0.5214\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8690 - accuracy: 0.5296 - val_loss: 1.0599 - val_accuracy: 0.5556\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 1.0580 - val_accuracy: 0.5556\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0559 - val_accuracy: 0.5556\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8609 - accuracy: 0.5296 - val_loss: 1.0581 - val_accuracy: 0.5128\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8662 - accuracy: 0.5259 - val_loss: 1.0584 - val_accuracy: 0.5556\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8591 - accuracy: 0.5370 - val_loss: 1.0610 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8617 - accuracy: 0.5296 - val_loss: 1.0663 - val_accuracy: 0.5128\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8604 - accuracy: 0.5333 - val_loss: 1.0623 - val_accuracy: 0.5556\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0601 - val_accuracy: 0.5556\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0599 - val_accuracy: 0.5556\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8596 - accuracy: 0.5370 - val_loss: 1.0617 - val_accuracy: 0.5556\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8623 - accuracy: 0.5037 - val_loss: 1.0669 - val_accuracy: 0.5214\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8592 - accuracy: 0.5333 - val_loss: 1.0632 - val_accuracy: 0.5214\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8694 - accuracy: 0.5259 - val_loss: 1.0615 - val_accuracy: 0.5556\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8622 - accuracy: 0.5370 - val_loss: 1.0643 - val_accuracy: 0.5556\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8618 - accuracy: 0.5407 - val_loss: 1.0651 - val_accuracy: 0.5214\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8585 - accuracy: 0.5296 - val_loss: 1.0619 - val_accuracy: 0.5556\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8607 - accuracy: 0.5370 - val_loss: 1.0607 - val_accuracy: 0.5556\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8602 - accuracy: 0.5333 - val_loss: 1.0607 - val_accuracy: 0.5556\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8614 - accuracy: 0.5370 - val_loss: 1.0622 - val_accuracy: 0.5556\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8611 - accuracy: 0.5370 - val_loss: 1.0643 - val_accuracy: 0.5556\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8608 - accuracy: 0.5333 - val_loss: 1.0693 - val_accuracy: 0.5214\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8610 - accuracy: 0.5296 - val_loss: 1.0643 - val_accuracy: 0.5214\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8591 - accuracy: 0.5333 - val_loss: 1.0619 - val_accuracy: 0.5556\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0627 - val_accuracy: 0.5556\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.8604 - accuracy: 0.5222 - val_loss: 1.0651 - val_accuracy: 0.5214\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.8595 - accuracy: 0.5333 - val_loss: 1.0663 - val_accuracy: 0.5214\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8611 - accuracy: 0.5185 - val_loss: 1.0642 - val_accuracy: 0.5556\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0644 - val_accuracy: 0.5214\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0592 - val_accuracy: 0.5556\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8605 - accuracy: 0.5370 - val_loss: 1.0633 - val_accuracy: 0.5556\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8589 - accuracy: 0.5370 - val_loss: 1.0652 - val_accuracy: 0.5214\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8617 - accuracy: 0.5333 - val_loss: 1.0655 - val_accuracy: 0.5214\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8592 - accuracy: 0.5333 - val_loss: 1.0648 - val_accuracy: 0.5214\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8601 - accuracy: 0.5074 - val_loss: 1.0637 - val_accuracy: 0.5556\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8578 - accuracy: 0.5370 - val_loss: 1.0643 - val_accuracy: 0.5556\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8602 - accuracy: 0.5370 - val_loss: 1.0642 - val_accuracy: 0.5556\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8601 - accuracy: 0.5111 - val_loss: 1.0687 - val_accuracy: 0.5214\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8617 - accuracy: 0.5111 - val_loss: 1.0693 - val_accuracy: 0.5214\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8599 - accuracy: 0.5333 - val_loss: 1.0668 - val_accuracy: 0.5556\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8596 - accuracy: 0.5370 - val_loss: 1.0661 - val_accuracy: 0.5556\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8637 - accuracy: 0.5074 - val_loss: 1.0710 - val_accuracy: 0.5214\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8625 - accuracy: 0.5333 - val_loss: 1.0680 - val_accuracy: 0.5214\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8606 - accuracy: 0.5444 - val_loss: 1.0644 - val_accuracy: 0.5556\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8586 - accuracy: 0.5370 - val_loss: 1.0654 - val_accuracy: 0.5556\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8606 - accuracy: 0.5333 - val_loss: 1.0661 - val_accuracy: 0.5214\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8612 - accuracy: 0.5333 - val_loss: 1.0683 - val_accuracy: 0.5214\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8597 - accuracy: 0.5444 - val_loss: 1.0640 - val_accuracy: 0.5556\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8625 - accuracy: 0.5370 - val_loss: 1.0611 - val_accuracy: 0.5556\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8608 - accuracy: 0.5370 - val_loss: 1.0636 - val_accuracy: 0.5556\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8589 - accuracy: 0.5370 - val_loss: 1.0674 - val_accuracy: 0.5214\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8603 - accuracy: 0.5296 - val_loss: 1.0697 - val_accuracy: 0.5214\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8625 - accuracy: 0.5333 - val_loss: 1.0726 - val_accuracy: 0.5214\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8594 - accuracy: 0.5333 - val_loss: 1.0670 - val_accuracy: 0.5556\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8608 - accuracy: 0.5370 - val_loss: 1.0652 - val_accuracy: 0.5556\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0677 - val_accuracy: 0.5556\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0680 - val_accuracy: 0.5556\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8607 - accuracy: 0.5296 - val_loss: 1.0703 - val_accuracy: 0.5214\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8611 - accuracy: 0.5111 - val_loss: 1.0634 - val_accuracy: 0.5556\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0682 - val_accuracy: 0.5556\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8587 - accuracy: 0.5370 - val_loss: 1.0683 - val_accuracy: 0.5556\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8592 - accuracy: 0.5185 - val_loss: 1.0701 - val_accuracy: 0.5214\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8597 - accuracy: 0.5222 - val_loss: 1.0678 - val_accuracy: 0.5214\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8600 - accuracy: 0.5259 - val_loss: 1.0668 - val_accuracy: 0.5556\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8615 - accuracy: 0.5370 - val_loss: 1.0707 - val_accuracy: 0.5556\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8609 - accuracy: 0.5296 - val_loss: 1.0726 - val_accuracy: 0.5556\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8648 - accuracy: 0.4963 - val_loss: 1.0750 - val_accuracy: 0.5556\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0712 - val_accuracy: 0.5556\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.0706 - val_accuracy: 0.5556\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8647 - accuracy: 0.5185 - val_loss: 1.0792 - val_accuracy: 0.5214\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8585 - accuracy: 0.5296 - val_loss: 1.0715 - val_accuracy: 0.5556\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8590 - accuracy: 0.5370 - val_loss: 1.0698 - val_accuracy: 0.5556\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8611 - accuracy: 0.5370 - val_loss: 1.0699 - val_accuracy: 0.5556\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8607 - accuracy: 0.5333 - val_loss: 1.0702 - val_accuracy: 0.5556\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0737 - val_accuracy: 0.5556\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0710 - val_accuracy: 0.5556\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8597 - accuracy: 0.5185 - val_loss: 1.0698 - val_accuracy: 0.5556\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8595 - accuracy: 0.5370 - val_loss: 1.0687 - val_accuracy: 0.5556\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8600 - accuracy: 0.5370 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8595 - accuracy: 0.5333 - val_loss: 1.0747 - val_accuracy: 0.5214\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8599 - accuracy: 0.5296 - val_loss: 1.0713 - val_accuracy: 0.5214\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8599 - accuracy: 0.5333 - val_loss: 1.0665 - val_accuracy: 0.5214\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8591 - accuracy: 0.5296 - val_loss: 1.0642 - val_accuracy: 0.5556\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8602 - accuracy: 0.5370 - val_loss: 1.0638 - val_accuracy: 0.5556\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8606 - accuracy: 0.5000 - val_loss: 1.0675 - val_accuracy: 0.5214\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8587 - accuracy: 0.5333 - val_loss: 1.0639 - val_accuracy: 0.5556\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0650 - val_accuracy: 0.5556\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8608 - accuracy: 0.5370 - val_loss: 1.0652 - val_accuracy: 0.5556\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8625 - accuracy: 0.5148 - val_loss: 1.0707 - val_accuracy: 0.5214\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8590 - accuracy: 0.5222 - val_loss: 1.0663 - val_accuracy: 0.5556\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8584 - accuracy: 0.5370 - val_loss: 1.0660 - val_accuracy: 0.5556\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8604 - accuracy: 0.5148 - val_loss: 1.0679 - val_accuracy: 0.5556\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8588 - accuracy: 0.5370 - val_loss: 1.0667 - val_accuracy: 0.5556\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0706 - val_accuracy: 0.5556\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8653 - accuracy: 0.5370 - val_loss: 1.0676 - val_accuracy: 0.5556\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8593 - accuracy: 0.5370 - val_loss: 1.0733 - val_accuracy: 0.5214\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8652 - accuracy: 0.5333 - val_loss: 1.0809 - val_accuracy: 0.5214\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8570 - accuracy: 0.5333 - val_loss: 1.0740 - val_accuracy: 0.5556\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8611 - accuracy: 0.5370 - val_loss: 1.0709 - val_accuracy: 0.5556\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8597 - accuracy: 0.5333 - val_loss: 1.0693 - val_accuracy: 0.5214\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8592 - accuracy: 0.5333 - val_loss: 1.0698 - val_accuracy: 0.5214\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8613 - accuracy: 0.5222 - val_loss: 1.0661 - val_accuracy: 0.5556\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8593 - accuracy: 0.5333 - val_loss: 1.0686 - val_accuracy: 0.5214\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8604 - accuracy: 0.5296 - val_loss: 1.0724 - val_accuracy: 0.5214\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8597 - accuracy: 0.5333 - val_loss: 1.0703 - val_accuracy: 0.5214\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8580 - accuracy: 0.5407 - val_loss: 1.0679 - val_accuracy: 0.5556\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8617 - accuracy: 0.5370 - val_loss: 1.0692 - val_accuracy: 0.5556\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8607 - accuracy: 0.5370 - val_loss: 1.0721 - val_accuracy: 0.5556\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8575 - accuracy: 0.5630 - val_loss: 1.0794 - val_accuracy: 0.5214\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8614 - accuracy: 0.5333 - val_loss: 1.0809 - val_accuracy: 0.5214\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8617 - accuracy: 0.5333 - val_loss: 1.0758 - val_accuracy: 0.5556\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 335us/step - loss: 0.8610 - accuracy: 0.4926 - val_loss: 1.0748 - val_accuracy: 0.5556\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8593 - accuracy: 0.5333 - val_loss: 1.0730 - val_accuracy: 0.5556\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8597 - accuracy: 0.5222 - val_loss: 1.0761 - val_accuracy: 0.5214\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8619 - accuracy: 0.5333 - val_loss: 1.0807 - val_accuracy: 0.5214\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 110us/step - loss: 0.8586 - accuracy: 0.5370 - val_loss: 1.0743 - val_accuracy: 0.5556\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8607 - accuracy: 0.5370 - val_loss: 1.0719 - val_accuracy: 0.5556\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.0758 - val_accuracy: 0.5556\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8592 - accuracy: 0.5333 - val_loss: 1.0749 - val_accuracy: 0.5556\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8577 - accuracy: 0.5407 - val_loss: 1.0747 - val_accuracy: 0.5214\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8591 - accuracy: 0.5296 - val_loss: 1.0802 - val_accuracy: 0.5556\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8754 - accuracy: 0.4889 - val_loss: 1.0754 - val_accuracy: 0.5214\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8649 - accuracy: 0.5148 - val_loss: 1.0723 - val_accuracy: 0.5556\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8594 - accuracy: 0.5259 - val_loss: 1.0729 - val_accuracy: 0.5214\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8597 - accuracy: 0.5333 - val_loss: 1.0719 - val_accuracy: 0.5214\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8588 - accuracy: 0.5407 - val_loss: 1.0693 - val_accuracy: 0.5556\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0712 - val_accuracy: 0.5556\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8629 - accuracy: 0.5148 - val_loss: 1.0775 - val_accuracy: 0.5214\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8588 - accuracy: 0.5333 - val_loss: 1.0737 - val_accuracy: 0.5556\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8618 - accuracy: 0.5370 - val_loss: 1.0742 - val_accuracy: 0.5556\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8586 - accuracy: 0.5333 - val_loss: 1.0749 - val_accuracy: 0.5214\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8611 - accuracy: 0.5148 - val_loss: 1.0694 - val_accuracy: 0.5556\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8588 - accuracy: 0.5370 - val_loss: 1.0724 - val_accuracy: 0.5556\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8605 - accuracy: 0.5296 - val_loss: 1.0733 - val_accuracy: 0.5556\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8646 - accuracy: 0.5370 - val_loss: 1.0726 - val_accuracy: 0.5556\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8601 - accuracy: 0.5370 - val_loss: 1.0750 - val_accuracy: 0.5556\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8590 - accuracy: 0.5259 - val_loss: 1.0754 - val_accuracy: 0.5214\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8593 - accuracy: 0.5000 - val_loss: 1.0751 - val_accuracy: 0.5214\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8610 - accuracy: 0.5370 - val_loss: 1.0727 - val_accuracy: 0.5556\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 360us/step - loss: 0.8616 - accuracy: 0.5370 - val_loss: 1.0733 - val_accuracy: 0.5556\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8650 - accuracy: 0.5037 - val_loss: 1.0822 - val_accuracy: 0.5214\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8614 - accuracy: 0.5333 - val_loss: 1.0741 - val_accuracy: 0.5556\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8588 - accuracy: 0.5370 - val_loss: 1.0686 - val_accuracy: 0.5556\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8619 - accuracy: 0.5037 - val_loss: 1.0675 - val_accuracy: 0.5214\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8632 - accuracy: 0.5296 - val_loss: 1.0675 - val_accuracy: 0.5385\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8606 - accuracy: 0.5370 - val_loss: 1.0685 - val_accuracy: 0.5556\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8598 - accuracy: 0.5296 - val_loss: 1.0714 - val_accuracy: 0.5214\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8587 - accuracy: 0.5148 - val_loss: 1.0703 - val_accuracy: 0.5556\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8607 - accuracy: 0.5444 - val_loss: 1.0721 - val_accuracy: 0.5214\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.8590 - accuracy: 0.5296 - val_loss: 1.0703 - val_accuracy: 0.5556\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8595 - accuracy: 0.5037 - val_loss: 1.0690 - val_accuracy: 0.5556\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8636 - accuracy: 0.5333 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8600 - accuracy: 0.5000 - val_loss: 1.0718 - val_accuracy: 0.5556\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8593 - accuracy: 0.5222 - val_loss: 1.0728 - val_accuracy: 0.5556\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8587 - accuracy: 0.5370 - val_loss: 1.0673 - val_accuracy: 0.5556\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8592 - accuracy: 0.5370 - val_loss: 1.0684 - val_accuracy: 0.5556\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8617 - accuracy: 0.5370 - val_loss: 1.0730 - val_accuracy: 0.5556\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8597 - accuracy: 0.5370 - val_loss: 1.0717 - val_accuracy: 0.5556\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8595 - accuracy: 0.5370 - val_loss: 1.0717 - val_accuracy: 0.5556\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8604 - accuracy: 0.5370 - val_loss: 1.0738 - val_accuracy: 0.5556\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8588 - accuracy: 0.5370 - val_loss: 1.0752 - val_accuracy: 0.5556\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8637 - accuracy: 0.5296 - val_loss: 1.0789 - val_accuracy: 0.5214\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8597 - accuracy: 0.5407 - val_loss: 1.0718 - val_accuracy: 0.5556\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8650 - accuracy: 0.5370 - val_loss: 1.0714 - val_accuracy: 0.5556\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8612 - accuracy: 0.5370 - val_loss: 1.0757 - val_accuracy: 0.5556\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8623 - accuracy: 0.5296 - val_loss: 1.0799 - val_accuracy: 0.5214\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8574 - accuracy: 0.5444 - val_loss: 1.0731 - val_accuracy: 0.5556\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8610 - accuracy: 0.5407 - val_loss: 1.0710 - val_accuracy: 0.5556\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8591 - accuracy: 0.5333 - val_loss: 1.0759 - val_accuracy: 0.5556\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8580 - accuracy: 0.5296 - val_loss: 1.0761 - val_accuracy: 0.5214\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8603 - accuracy: 0.5037 - val_loss: 1.0768 - val_accuracy: 0.5214\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 52.94%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.13207640e-01, 2.81218000e-01, 1.05574414e-01],\n",
       "       [1.99320160e-04, 6.83493700e-07, 9.99800000e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [6.13207640e-01, 2.81218000e-01, 1.05574414e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [8.99713340e-05, 4.12781740e-08, 9.99910000e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [1.20174850e-01, 8.68513400e-01, 1.13116530e-02],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [4.72033250e-02, 1.73922580e-03, 9.51057430e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [9.68788270e-01, 7.03257740e-03, 2.41791350e-02],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [9.66538370e-01, 1.40980900e-02, 1.93634780e-02],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [1.09392470e-02, 3.63250050e-01, 6.25810700e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [9.66538370e-01, 1.40980900e-02, 1.93634780e-02],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [1.09392470e-02, 3.63250050e-01, 6.25810700e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.69110020e-01, 7.14193600e-01, 1.66963770e-02],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [6.13207640e-01, 2.81218000e-01, 1.05574414e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [7.89961250e-04, 9.76182900e-04, 9.98233800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [1.07986670e-02, 5.90773930e-05, 9.89142300e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.31416350e-02, 2.54342240e-02, 9.41424130e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.66152500e-01, 1.83918850e-01, 5.49928670e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [8.88204600e-06, 9.87822800e-08, 9.99991060e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [7.89961250e-04, 9.76182900e-04, 9.98233800e-01],\n",
       "       [5.96923000e-03, 9.91775040e-01, 2.25568540e-03],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [8.90798300e-01, 7.50605700e-02, 3.41411870e-02],\n",
       "       [1.99320160e-04, 6.83493700e-07, 9.99800000e-01],\n",
       "       [6.98097800e-02, 1.24269105e-01, 8.05921140e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [6.98097800e-02, 1.24269105e-01, 8.05921140e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [1.95784750e-01, 4.76207730e-01, 3.28007520e-01],\n",
       "       [2.66152500e-01, 1.83918850e-01, 5.49928670e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [8.88204600e-06, 9.87822800e-08, 9.99991060e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.28212850e-01, 4.47686730e-01, 3.24100430e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.64562670e-02, 1.22786865e-01, 8.50756800e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [6.13207640e-01, 2.81218000e-01, 1.05574414e-01],\n",
       "       [2.28212850e-01, 4.47686730e-01, 3.24100430e-01],\n",
       "       [4.72033250e-02, 1.73922580e-03, 9.51057430e-01],\n",
       "       [3.58946260e-01, 3.98278740e-01, 2.42775010e-01],\n",
       "       [2.21757250e-01, 4.55185980e-01, 3.23056800e-01],\n",
       "       [2.66152500e-01, 1.83918850e-01, 5.49928670e-01],\n",
       "       [2.73889710e-02, 3.94654400e-01, 5.77956600e-01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072101687486304"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072101687486304"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS236     1\n",
       "1      NRS113     2\n",
       "2    CFBRSa23     0\n",
       "3      NRS249     2\n",
       "4         107     1\n",
       "..        ...   ...\n",
       "112     NY439     2\n",
       "113    NRS106     0\n",
       "114       221     0\n",
       "115    NRS386     2\n",
       "116  CFBRSa03     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 617us/step - loss: 1.0973 - accuracy: 0.2963 - val_loss: 1.0694 - val_accuracy: 0.3932\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 1.0744 - accuracy: 0.3815 - val_loss: 1.0552 - val_accuracy: 0.4701\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 1.0619 - accuracy: 0.4222 - val_loss: 1.0481 - val_accuracy: 0.4188\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 1.0544 - accuracy: 0.5000 - val_loss: 1.0420 - val_accuracy: 0.4786\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 1.0479 - accuracy: 0.4704 - val_loss: 1.0376 - val_accuracy: 0.4786\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 1.0428 - accuracy: 0.4741 - val_loss: 1.0322 - val_accuracy: 0.4786\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 1.0357 - accuracy: 0.4889 - val_loss: 1.0279 - val_accuracy: 0.4786\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.0307 - accuracy: 0.4889 - val_loss: 1.0243 - val_accuracy: 0.4530\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 1.0247 - accuracy: 0.4926 - val_loss: 1.0191 - val_accuracy: 0.4786\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 1.0188 - accuracy: 0.4963 - val_loss: 1.0160 - val_accuracy: 0.4786\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 1.0151 - accuracy: 0.4926 - val_loss: 1.0132 - val_accuracy: 0.4786\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 1.0114 - accuracy: 0.4926 - val_loss: 1.0101 - val_accuracy: 0.4786\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 1.0061 - accuracy: 0.4926 - val_loss: 1.0081 - val_accuracy: 0.4786\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 1.0060 - accuracy: 0.5148 - val_loss: 1.0086 - val_accuracy: 0.4274\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 1.0012 - accuracy: 0.5296 - val_loss: 1.0031 - val_accuracy: 0.4444\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9959 - accuracy: 0.5185 - val_loss: 1.0012 - val_accuracy: 0.4786\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9932 - accuracy: 0.5074 - val_loss: 0.9981 - val_accuracy: 0.5299\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.9892 - accuracy: 0.5000 - val_loss: 0.9965 - val_accuracy: 0.4786\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9861 - accuracy: 0.4963 - val_loss: 0.9948 - val_accuracy: 0.5299\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.9826 - accuracy: 0.5000 - val_loss: 0.9933 - val_accuracy: 0.4957\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9813 - accuracy: 0.5519 - val_loss: 0.9920 - val_accuracy: 0.4786\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9785 - accuracy: 0.5407 - val_loss: 0.9915 - val_accuracy: 0.4786\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.9750 - accuracy: 0.5148 - val_loss: 0.9894 - val_accuracy: 0.5299\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9726 - accuracy: 0.4889 - val_loss: 0.9883 - val_accuracy: 0.4786\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9716 - accuracy: 0.5185 - val_loss: 0.9879 - val_accuracy: 0.4786\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9681 - accuracy: 0.5370 - val_loss: 0.9877 - val_accuracy: 0.4786\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9666 - accuracy: 0.5370 - val_loss: 0.9871 - val_accuracy: 0.4786\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9643 - accuracy: 0.5370 - val_loss: 0.9854 - val_accuracy: 0.4786\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9618 - accuracy: 0.5370 - val_loss: 0.9862 - val_accuracy: 0.4786\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9620 - accuracy: 0.5407 - val_loss: 0.9851 - val_accuracy: 0.4786\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9583 - accuracy: 0.5370 - val_loss: 0.9846 - val_accuracy: 0.4786\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.9570 - accuracy: 0.5370 - val_loss: 0.9846 - val_accuracy: 0.4786\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.9550 - accuracy: 0.5370 - val_loss: 0.9846 - val_accuracy: 0.4786\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9537 - accuracy: 0.5370 - val_loss: 0.9855 - val_accuracy: 0.4786\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.9539 - accuracy: 0.5370 - val_loss: 0.9861 - val_accuracy: 0.4786\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9528 - accuracy: 0.5370 - val_loss: 0.9848 - val_accuracy: 0.4786\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9499 - accuracy: 0.5370 - val_loss: 0.9849 - val_accuracy: 0.4786\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9487 - accuracy: 0.5370 - val_loss: 0.9839 - val_accuracy: 0.4786\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9476 - accuracy: 0.5333 - val_loss: 0.9856 - val_accuracy: 0.4786\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9467 - accuracy: 0.5333 - val_loss: 0.9853 - val_accuracy: 0.4786\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9457 - accuracy: 0.5333 - val_loss: 0.9839 - val_accuracy: 0.4786\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9458 - accuracy: 0.5333 - val_loss: 0.9843 - val_accuracy: 0.4786\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9448 - accuracy: 0.5333 - val_loss: 0.9847 - val_accuracy: 0.4701\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9412 - accuracy: 0.5333 - val_loss: 0.9848 - val_accuracy: 0.4786\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9423 - accuracy: 0.5333 - val_loss: 0.9857 - val_accuracy: 0.4786\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9404 - accuracy: 0.5333 - val_loss: 0.9855 - val_accuracy: 0.4786\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9400 - accuracy: 0.5333 - val_loss: 0.9863 - val_accuracy: 0.4786\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9396 - accuracy: 0.5407 - val_loss: 0.9875 - val_accuracy: 0.4786\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.9387 - accuracy: 0.5407 - val_loss: 0.9869 - val_accuracy: 0.4872\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 346us/step - loss: 0.9373 - accuracy: 0.5370 - val_loss: 0.9877 - val_accuracy: 0.4786\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9376 - accuracy: 0.5333 - val_loss: 0.9892 - val_accuracy: 0.4786\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.9359 - accuracy: 0.5333 - val_loss: 0.9907 - val_accuracy: 0.4872\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.9354 - accuracy: 0.5407 - val_loss: 0.9919 - val_accuracy: 0.4872\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.9369 - accuracy: 0.5407 - val_loss: 0.9936 - val_accuracy: 0.4872\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.9366 - accuracy: 0.5407 - val_loss: 0.9920 - val_accuracy: 0.4786\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.9360 - accuracy: 0.5333 - val_loss: 0.9917 - val_accuracy: 0.4786\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9348 - accuracy: 0.5407 - val_loss: 0.9929 - val_accuracy: 0.4872\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.9354 - accuracy: 0.5407 - val_loss: 0.9914 - val_accuracy: 0.4786\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.9337 - accuracy: 0.5333 - val_loss: 0.9917 - val_accuracy: 0.4786\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.9328 - accuracy: 0.5333 - val_loss: 0.9928 - val_accuracy: 0.4701\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.9315 - accuracy: 0.5333 - val_loss: 0.9939 - val_accuracy: 0.4786\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.9328 - accuracy: 0.5407 - val_loss: 0.9938 - val_accuracy: 0.4786\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9321 - accuracy: 0.5333 - val_loss: 0.9929 - val_accuracy: 0.4786\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.9325 - accuracy: 0.5333 - val_loss: 0.9943 - val_accuracy: 0.4786\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.9362 - accuracy: 0.5370 - val_loss: 0.9982 - val_accuracy: 0.4786\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9304 - accuracy: 0.5407 - val_loss: 0.9955 - val_accuracy: 0.4786\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9295 - accuracy: 0.5333 - val_loss: 0.9951 - val_accuracy: 0.4786\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9318 - accuracy: 0.5333 - val_loss: 0.9967 - val_accuracy: 0.4786\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9298 - accuracy: 0.5333 - val_loss: 0.9963 - val_accuracy: 0.4701\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9286 - accuracy: 0.5333 - val_loss: 0.9964 - val_accuracy: 0.4786\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.9294 - accuracy: 0.5407 - val_loss: 1.0001 - val_accuracy: 0.4786\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.9299 - accuracy: 0.5407 - val_loss: 0.9957 - val_accuracy: 0.4786\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9279 - accuracy: 0.5407 - val_loss: 0.9957 - val_accuracy: 0.4786\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.9291 - accuracy: 0.5407 - val_loss: 0.9978 - val_accuracy: 0.4786\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9276 - accuracy: 0.5370 - val_loss: 0.9984 - val_accuracy: 0.4786\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9283 - accuracy: 0.5370 - val_loss: 0.9982 - val_accuracy: 0.4786\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.9273 - accuracy: 0.5481 - val_loss: 1.0003 - val_accuracy: 0.4786\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9264 - accuracy: 0.5481 - val_loss: 0.9993 - val_accuracy: 0.4786\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9258 - accuracy: 0.5481 - val_loss: 0.9992 - val_accuracy: 0.4786\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9258 - accuracy: 0.5407 - val_loss: 0.9984 - val_accuracy: 0.4701\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9259 - accuracy: 0.5407 - val_loss: 1.0001 - val_accuracy: 0.4786\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9260 - accuracy: 0.5481 - val_loss: 1.0003 - val_accuracy: 0.4786\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9249 - accuracy: 0.5481 - val_loss: 0.9998 - val_accuracy: 0.4701\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9282 - accuracy: 0.5407 - val_loss: 0.9993 - val_accuracy: 0.4701\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9254 - accuracy: 0.5444 - val_loss: 1.0020 - val_accuracy: 0.4872\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.9275 - accuracy: 0.5519 - val_loss: 1.0014 - val_accuracy: 0.4872\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9235 - accuracy: 0.5481 - val_loss: 1.0025 - val_accuracy: 0.4786\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9248 - accuracy: 0.5481 - val_loss: 1.0033 - val_accuracy: 0.4786\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9242 - accuracy: 0.5481 - val_loss: 1.0034 - val_accuracy: 0.4786\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9240 - accuracy: 0.5481 - val_loss: 1.0030 - val_accuracy: 0.4786\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.9229 - accuracy: 0.5481 - val_loss: 1.0040 - val_accuracy: 0.4786\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9239 - accuracy: 0.5481 - val_loss: 1.0023 - val_accuracy: 0.4786\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9246 - accuracy: 0.5481 - val_loss: 1.0049 - val_accuracy: 0.4786\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.9228 - accuracy: 0.5481 - val_loss: 1.0047 - val_accuracy: 0.4872\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9226 - accuracy: 0.5481 - val_loss: 1.0061 - val_accuracy: 0.4872\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.9245 - accuracy: 0.5481 - val_loss: 1.0040 - val_accuracy: 0.4786\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9213 - accuracy: 0.5481 - val_loss: 1.0069 - val_accuracy: 0.4786\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9244 - accuracy: 0.5481 - val_loss: 1.0068 - val_accuracy: 0.4786\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9223 - accuracy: 0.5481 - val_loss: 1.0055 - val_accuracy: 0.4786\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9223 - accuracy: 0.5481 - val_loss: 1.0044 - val_accuracy: 0.4786\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9224 - accuracy: 0.5444 - val_loss: 1.0037 - val_accuracy: 0.4872\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9221 - accuracy: 0.5481 - val_loss: 1.0062 - val_accuracy: 0.4786\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9214 - accuracy: 0.5481 - val_loss: 1.0049 - val_accuracy: 0.4786\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9238 - accuracy: 0.5444 - val_loss: 1.0033 - val_accuracy: 0.4872\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9227 - accuracy: 0.5481 - val_loss: 1.0076 - val_accuracy: 0.4872\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9226 - accuracy: 0.5481 - val_loss: 1.0075 - val_accuracy: 0.4786\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9212 - accuracy: 0.5481 - val_loss: 1.0059 - val_accuracy: 0.4786\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9201 - accuracy: 0.5481 - val_loss: 1.0056 - val_accuracy: 0.4786\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.9212 - accuracy: 0.5481 - val_loss: 1.0069 - val_accuracy: 0.4786\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.9203 - accuracy: 0.5481 - val_loss: 1.0079 - val_accuracy: 0.4786\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.9226 - accuracy: 0.5481 - val_loss: 1.0094 - val_accuracy: 0.4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9191 - accuracy: 0.5481 - val_loss: 1.0080 - val_accuracy: 0.4786\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9191 - accuracy: 0.5481 - val_loss: 1.0070 - val_accuracy: 0.4786\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.9202 - accuracy: 0.5519 - val_loss: 1.0086 - val_accuracy: 0.4872\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9192 - accuracy: 0.5519 - val_loss: 1.0054 - val_accuracy: 0.4786\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9178 - accuracy: 0.5481 - val_loss: 1.0065 - val_accuracy: 0.4786\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9212 - accuracy: 0.5481 - val_loss: 1.0089 - val_accuracy: 0.4786\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.9189 - accuracy: 0.5481 - val_loss: 1.0070 - val_accuracy: 0.4872\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.9213 - accuracy: 0.5481 - val_loss: 1.0071 - val_accuracy: 0.4872\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9182 - accuracy: 0.5481 - val_loss: 1.0070 - val_accuracy: 0.4872\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.50 - 0s 220us/step - loss: 0.9182 - accuracy: 0.5481 - val_loss: 1.0079 - val_accuracy: 0.4786\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.9174 - accuracy: 0.5481 - val_loss: 1.0086 - val_accuracy: 0.4872\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.9184 - accuracy: 0.5481 - val_loss: 1.0117 - val_accuracy: 0.4872\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9174 - accuracy: 0.5481 - val_loss: 1.0091 - val_accuracy: 0.4872\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9173 - accuracy: 0.5481 - val_loss: 1.0085 - val_accuracy: 0.4872\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9172 - accuracy: 0.5481 - val_loss: 1.0081 - val_accuracy: 0.4786\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9164 - accuracy: 0.5481 - val_loss: 1.0099 - val_accuracy: 0.4786\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9178 - accuracy: 0.5481 - val_loss: 1.0093 - val_accuracy: 0.4786\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9181 - accuracy: 0.5481 - val_loss: 1.0091 - val_accuracy: 0.4786\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9193 - accuracy: 0.5481 - val_loss: 1.0099 - val_accuracy: 0.4786\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9191 - accuracy: 0.5481 - val_loss: 1.0069 - val_accuracy: 0.4786\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9167 - accuracy: 0.5481 - val_loss: 1.0067 - val_accuracy: 0.4872\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9223 - accuracy: 0.5519 - val_loss: 1.0089 - val_accuracy: 0.4872\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.9149 - accuracy: 0.5519 - val_loss: 1.0066 - val_accuracy: 0.4786\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9166 - accuracy: 0.5481 - val_loss: 1.0078 - val_accuracy: 0.4786\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9159 - accuracy: 0.5481 - val_loss: 1.0073 - val_accuracy: 0.4872\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9163 - accuracy: 0.5519 - val_loss: 1.0090 - val_accuracy: 0.4872\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9154 - accuracy: 0.5519 - val_loss: 1.0096 - val_accuracy: 0.4872\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9151 - accuracy: 0.5481 - val_loss: 1.0113 - val_accuracy: 0.4872\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.9150 - accuracy: 0.5481 - val_loss: 1.0102 - val_accuracy: 0.4786\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9163 - accuracy: 0.5481 - val_loss: 1.0086 - val_accuracy: 0.4786\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9158 - accuracy: 0.5481 - val_loss: 1.0087 - val_accuracy: 0.4786\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9145 - accuracy: 0.5481 - val_loss: 1.0096 - val_accuracy: 0.4872\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9142 - accuracy: 0.5519 - val_loss: 1.0115 - val_accuracy: 0.4872\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.9141 - accuracy: 0.5519 - val_loss: 1.0129 - val_accuracy: 0.4872\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9162 - accuracy: 0.5519 - val_loss: 1.0097 - val_accuracy: 0.4872\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9158 - accuracy: 0.5519 - val_loss: 1.0131 - val_accuracy: 0.4872\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9168 - accuracy: 0.5556 - val_loss: 1.0071 - val_accuracy: 0.4872\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.9164 - accuracy: 0.5519 - val_loss: 1.0087 - val_accuracy: 0.4786\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9150 - accuracy: 0.5481 - val_loss: 1.0096 - val_accuracy: 0.4786\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.9138 - accuracy: 0.5481 - val_loss: 1.0078 - val_accuracy: 0.4786\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9166 - accuracy: 0.5481 - val_loss: 1.0108 - val_accuracy: 0.4786\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9135 - accuracy: 0.5481 - val_loss: 1.0089 - val_accuracy: 0.4786\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9149 - accuracy: 0.5556 - val_loss: 1.0101 - val_accuracy: 0.4872\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9138 - accuracy: 0.5519 - val_loss: 1.0097 - val_accuracy: 0.4786\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9119 - accuracy: 0.5519 - val_loss: 1.0094 - val_accuracy: 0.4786\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9123 - accuracy: 0.5481 - val_loss: 1.0103 - val_accuracy: 0.4786\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9121 - accuracy: 0.5481 - val_loss: 1.0108 - val_accuracy: 0.4786\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9118 - accuracy: 0.5519 - val_loss: 1.0105 - val_accuracy: 0.4872\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9118 - accuracy: 0.5556 - val_loss: 1.0089 - val_accuracy: 0.4872\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9128 - accuracy: 0.5519 - val_loss: 1.0103 - val_accuracy: 0.4786\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9148 - accuracy: 0.5481 - val_loss: 1.0132 - val_accuracy: 0.4786\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9118 - accuracy: 0.5556 - val_loss: 1.0094 - val_accuracy: 0.4872\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9142 - accuracy: 0.5556 - val_loss: 1.0110 - val_accuracy: 0.4872\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9110 - accuracy: 0.5556 - val_loss: 1.0125 - val_accuracy: 0.4872\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9135 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.4786\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9136 - accuracy: 0.5519 - val_loss: 1.0115 - val_accuracy: 0.4872\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9106 - accuracy: 0.5556 - val_loss: 1.0119 - val_accuracy: 0.4872\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9107 - accuracy: 0.5556 - val_loss: 1.0119 - val_accuracy: 0.4872\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9127 - accuracy: 0.5519 - val_loss: 1.0147 - val_accuracy: 0.4872\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9117 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.4786\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9102 - accuracy: 0.5519 - val_loss: 1.0124 - val_accuracy: 0.4872\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.9097 - accuracy: 0.5556 - val_loss: 1.0131 - val_accuracy: 0.4872\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.9103 - accuracy: 0.5556 - val_loss: 1.0152 - val_accuracy: 0.4872\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9122 - accuracy: 0.5519 - val_loss: 1.0133 - val_accuracy: 0.4786\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9102 - accuracy: 0.5556 - val_loss: 1.0133 - val_accuracy: 0.4872\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9097 - accuracy: 0.5556 - val_loss: 1.0141 - val_accuracy: 0.4872\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.9109 - accuracy: 0.5556 - val_loss: 1.0121 - val_accuracy: 0.4872\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.9092 - accuracy: 0.5556 - val_loss: 1.0123 - val_accuracy: 0.4872\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.9108 - accuracy: 0.5556 - val_loss: 1.0137 - val_accuracy: 0.4786\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9096 - accuracy: 0.5556 - val_loss: 1.0096 - val_accuracy: 0.4872\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9106 - accuracy: 0.5556 - val_loss: 1.0119 - val_accuracy: 0.4872\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9097 - accuracy: 0.5556 - val_loss: 1.0103 - val_accuracy: 0.4872\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9087 - accuracy: 0.5556 - val_loss: 1.0105 - val_accuracy: 0.4786\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.9132 - accuracy: 0.5556 - val_loss: 1.0102 - val_accuracy: 0.4786\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9101 - accuracy: 0.5556 - val_loss: 1.0111 - val_accuracy: 0.4872\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9085 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.4872\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9085 - accuracy: 0.5556 - val_loss: 1.0112 - val_accuracy: 0.4872\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9092 - accuracy: 0.5556 - val_loss: 1.0101 - val_accuracy: 0.4872\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9107 - accuracy: 0.5556 - val_loss: 1.0114 - val_accuracy: 0.4872\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9125 - accuracy: 0.5556 - val_loss: 1.0221 - val_accuracy: 0.4872\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9087 - accuracy: 0.5556 - val_loss: 1.0140 - val_accuracy: 0.4872\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9100 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.4872\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.9075 - accuracy: 0.5556 - val_loss: 1.0147 - val_accuracy: 0.4872\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9076 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.4872\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9086 - accuracy: 0.5556 - val_loss: 1.0149 - val_accuracy: 0.4786\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.9085 - accuracy: 0.5556 - val_loss: 1.0137 - val_accuracy: 0.4872\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9078 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.4872\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9094 - accuracy: 0.5556 - val_loss: 1.0123 - val_accuracy: 0.4872\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9080 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.4872\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9079 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.4872\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9059 - accuracy: 0.5556 - val_loss: 1.0131 - val_accuracy: 0.4872\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.9076 - accuracy: 0.5556 - val_loss: 1.0144 - val_accuracy: 0.4872\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9068 - accuracy: 0.5556 - val_loss: 1.0153 - val_accuracy: 0.4872\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9080 - accuracy: 0.5556 - val_loss: 1.0138 - val_accuracy: 0.4872\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9111 - accuracy: 0.5519 - val_loss: 1.0178 - val_accuracy: 0.4786\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9074 - accuracy: 0.5556 - val_loss: 1.0152 - val_accuracy: 0.4872\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9080 - accuracy: 0.5556 - val_loss: 1.0154 - val_accuracy: 0.4872\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9065 - accuracy: 0.5556 - val_loss: 1.0157 - val_accuracy: 0.4872\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.9074 - accuracy: 0.5556 - val_loss: 1.0173 - val_accuracy: 0.4786\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9065 - accuracy: 0.5556 - val_loss: 1.0185 - val_accuracy: 0.4872\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9087 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.4786\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9060 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.4872\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.9051 - accuracy: 0.5556 - val_loss: 1.0142 - val_accuracy: 0.4872\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.9079 - accuracy: 0.5556 - val_loss: 1.0133 - val_accuracy: 0.4872\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.9051 - accuracy: 0.5556 - val_loss: 1.0120 - val_accuracy: 0.4872\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.9044 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.4872\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.9053 - accuracy: 0.5556 - val_loss: 1.0138 - val_accuracy: 0.4872\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9045 - accuracy: 0.5556 - val_loss: 1.0167 - val_accuracy: 0.4872\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.9061 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.4872\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9058 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.4872\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.9053 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9049 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.4872\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.9066 - accuracy: 0.5556 - val_loss: 1.0160 - val_accuracy: 0.4872\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9044 - accuracy: 0.5556 - val_loss: 1.0121 - val_accuracy: 0.4872\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.9046 - accuracy: 0.5556 - val_loss: 1.0134 - val_accuracy: 0.4872\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9049 - accuracy: 0.5556 - val_loss: 1.0139 - val_accuracy: 0.4872\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.9064 - accuracy: 0.5556 - val_loss: 1.0125 - val_accuracy: 0.4872\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9043 - accuracy: 0.5556 - val_loss: 1.0133 - val_accuracy: 0.4872\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9043 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.4872\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9032 - accuracy: 0.5556 - val_loss: 1.0134 - val_accuracy: 0.4872\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9043 - accuracy: 0.5556 - val_loss: 1.0127 - val_accuracy: 0.4872\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9042 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.4872\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9045 - accuracy: 0.5556 - val_loss: 1.0126 - val_accuracy: 0.4872\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.9026 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.4872\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9050 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.4872\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.9079 - accuracy: 0.5556 - val_loss: 1.0139 - val_accuracy: 0.4872\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9063 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.4872\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9040 - accuracy: 0.5556 - val_loss: 1.0167 - val_accuracy: 0.4872\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.9043 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.4872\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.9021 - accuracy: 0.5556 - val_loss: 1.0128 - val_accuracy: 0.4872\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.9040 - accuracy: 0.5556 - val_loss: 1.0127 - val_accuracy: 0.4872\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9028 - accuracy: 0.5556 - val_loss: 1.0141 - val_accuracy: 0.4872\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.9038 - accuracy: 0.5556 - val_loss: 1.0142 - val_accuracy: 0.4872\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9045 - accuracy: 0.5556 - val_loss: 1.0181 - val_accuracy: 0.4872\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9031 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.4872\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9021 - accuracy: 0.5556 - val_loss: 1.0148 - val_accuracy: 0.4872\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9022 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.4872\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.9022 - accuracy: 0.5556 - val_loss: 1.0145 - val_accuracy: 0.4872\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.9030 - accuracy: 0.5556 - val_loss: 1.0153 - val_accuracy: 0.4872\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9037 - accuracy: 0.5556 - val_loss: 1.0154 - val_accuracy: 0.4872\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.9044 - accuracy: 0.5556 - val_loss: 1.0149 - val_accuracy: 0.4872\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.9020 - accuracy: 0.5556 - val_loss: 1.0152 - val_accuracy: 0.4872\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9035 - accuracy: 0.5556 - val_loss: 1.0160 - val_accuracy: 0.4872\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9019 - accuracy: 0.5556 - val_loss: 1.0131 - val_accuracy: 0.4872\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9026 - accuracy: 0.5556 - val_loss: 1.0154 - val_accuracy: 0.4872\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.9015 - accuracy: 0.5556 - val_loss: 1.0139 - val_accuracy: 0.4872\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.9037 - accuracy: 0.5556 - val_loss: 1.0148 - val_accuracy: 0.4872\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9037 - accuracy: 0.5556 - val_loss: 1.0172 - val_accuracy: 0.4872\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9007 - accuracy: 0.5556 - val_loss: 1.0156 - val_accuracy: 0.4872\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9010 - accuracy: 0.5556 - val_loss: 1.0161 - val_accuracy: 0.4872\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9013 - accuracy: 0.5556 - val_loss: 1.0170 - val_accuracy: 0.4872\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.9013 - accuracy: 0.5556 - val_loss: 1.0158 - val_accuracy: 0.4872\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9025 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.4872\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.9007 - accuracy: 0.5556 - val_loss: 1.0157 - val_accuracy: 0.4872\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9016 - accuracy: 0.5556 - val_loss: 1.0151 - val_accuracy: 0.4872\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 344us/step - loss: 0.9010 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.4872\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.9052 - accuracy: 0.5556 - val_loss: 1.0198 - val_accuracy: 0.4872\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.9021 - accuracy: 0.5556 - val_loss: 1.0136 - val_accuracy: 0.4872\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.9008 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.4872\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.9006 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.4872\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9027 - accuracy: 0.5556 - val_loss: 1.0160 - val_accuracy: 0.4872\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.9015 - accuracy: 0.5556 - val_loss: 1.0169 - val_accuracy: 0.4872\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.9016 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.4872\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.9008 - accuracy: 0.5556 - val_loss: 1.0155 - val_accuracy: 0.4872\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.9003 - accuracy: 0.5556 - val_loss: 1.0149 - val_accuracy: 0.4872\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.9001 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.4872\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8997 - accuracy: 0.5556 - val_loss: 1.0149 - val_accuracy: 0.4872\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.9009 - accuracy: 0.5556 - val_loss: 1.0185 - val_accuracy: 0.4872\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.9002 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.4872\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.9009 - accuracy: 0.5556 - val_loss: 1.0153 - val_accuracy: 0.4872\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.9029 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.4872\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.9000 - accuracy: 0.5556 - val_loss: 1.0150 - val_accuracy: 0.4872\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8993 - accuracy: 0.5556 - val_loss: 1.0167 - val_accuracy: 0.4872\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8995 - accuracy: 0.5556 - val_loss: 1.0185 - val_accuracy: 0.4872\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.9004 - accuracy: 0.5556 - val_loss: 1.0174 - val_accuracy: 0.4872\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8988 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.4872\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9006 - accuracy: 0.5556 - val_loss: 1.0169 - val_accuracy: 0.4872\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.9007 - accuracy: 0.5556 - val_loss: 1.0167 - val_accuracy: 0.4872\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8999 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.4872\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8999 - accuracy: 0.5556 - val_loss: 1.0193 - val_accuracy: 0.4872\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8996 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.4872\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8995 - accuracy: 0.5556 - val_loss: 1.0196 - val_accuracy: 0.4872\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8986 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.4872\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8993 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.4872\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9011 - accuracy: 0.5556 - val_loss: 1.0168 - val_accuracy: 0.4872\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9029 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.4872\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8997 - accuracy: 0.5556 - val_loss: 1.0141 - val_accuracy: 0.4872\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8983 - accuracy: 0.5556 - val_loss: 1.0143 - val_accuracy: 0.4872\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8985 - accuracy: 0.5556 - val_loss: 1.0161 - val_accuracy: 0.4872\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8986 - accuracy: 0.5556 - val_loss: 1.0169 - val_accuracy: 0.4872\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8980 - accuracy: 0.5556 - val_loss: 1.0159 - val_accuracy: 0.4872\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.9005 - accuracy: 0.5556 - val_loss: 1.0174 - val_accuracy: 0.4872\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8969 - accuracy: 0.5556 - val_loss: 1.0172 - val_accuracy: 0.4872\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8984 - accuracy: 0.5556 - val_loss: 1.0179 - val_accuracy: 0.4872\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8981 - accuracy: 0.5556 - val_loss: 1.0188 - val_accuracy: 0.4872\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8982 - accuracy: 0.5556 - val_loss: 1.0169 - val_accuracy: 0.4872\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8990 - accuracy: 0.5556 - val_loss: 1.0183 - val_accuracy: 0.4872\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8967 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.4872\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8989 - accuracy: 0.5556 - val_loss: 1.0170 - val_accuracy: 0.4872\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8989 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.4872\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8966 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.4872\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8989 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.4872\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8996 - accuracy: 0.5556 - val_loss: 1.0163 - val_accuracy: 0.4872\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8984 - accuracy: 0.5556 - val_loss: 1.0146 - val_accuracy: 0.4872\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8975 - accuracy: 0.5556 - val_loss: 1.0152 - val_accuracy: 0.4872\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8990 - accuracy: 0.5556 - val_loss: 1.0166 - val_accuracy: 0.4872\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.9001 - accuracy: 0.5556 - val_loss: 1.0179 - val_accuracy: 0.4872\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8971 - accuracy: 0.5556 - val_loss: 1.0197 - val_accuracy: 0.4872\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.9014 - accuracy: 0.5556 - val_loss: 1.0197 - val_accuracy: 0.4872\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8960 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.4872\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8975 - accuracy: 0.5556 - val_loss: 1.0210 - val_accuracy: 0.4872\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8962 - accuracy: 0.5556 - val_loss: 1.0192 - val_accuracy: 0.4872\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8973 - accuracy: 0.5556 - val_loss: 1.0204 - val_accuracy: 0.4872\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8978 - accuracy: 0.5556 - val_loss: 1.0221 - val_accuracy: 0.4872\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8962 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.4872\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8992 - accuracy: 0.5556 - val_loss: 1.0182 - val_accuracy: 0.4872\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8962 - accuracy: 0.5556 - val_loss: 1.0187 - val_accuracy: 0.4872\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9014 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.4872\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8967 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.4872\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8962 - accuracy: 0.5556 - val_loss: 1.0180 - val_accuracy: 0.4872\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8970 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.4872\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8953 - accuracy: 0.5556 - val_loss: 1.0250 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.9014 - accuracy: 0.5556 - val_loss: 1.0234 - val_accuracy: 0.4872\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8980 - accuracy: 0.5556 - val_loss: 1.0177 - val_accuracy: 0.4872\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8968 - accuracy: 0.5556 - val_loss: 1.0207 - val_accuracy: 0.4872\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8947 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.4872\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8981 - accuracy: 0.5556 - val_loss: 1.0194 - val_accuracy: 0.4872\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8960 - accuracy: 0.5556 - val_loss: 1.0200 - val_accuracy: 0.4872\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8959 - accuracy: 0.5556 - val_loss: 1.0192 - val_accuracy: 0.4872\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8950 - accuracy: 0.5556 - val_loss: 1.0206 - val_accuracy: 0.4872\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8999 - accuracy: 0.5556 - val_loss: 1.0213 - val_accuracy: 0.4872\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8957 - accuracy: 0.5556 - val_loss: 1.0195 - val_accuracy: 0.4872\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8969 - accuracy: 0.5556 - val_loss: 1.0182 - val_accuracy: 0.4872\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8959 - accuracy: 0.5556 - val_loss: 1.0187 - val_accuracy: 0.4872\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8957 - accuracy: 0.5556 - val_loss: 1.0179 - val_accuracy: 0.4872\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8961 - accuracy: 0.5556 - val_loss: 1.0172 - val_accuracy: 0.4872\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8969 - accuracy: 0.5556 - val_loss: 1.0199 - val_accuracy: 0.4872\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8966 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.4872\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8948 - accuracy: 0.5556 - val_loss: 1.0184 - val_accuracy: 0.4872\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8959 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.4872\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8963 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.4872\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8964 - accuracy: 0.5556 - val_loss: 1.0179 - val_accuracy: 0.4872\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8953 - accuracy: 0.5556 - val_loss: 1.0214 - val_accuracy: 0.4872\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8956 - accuracy: 0.5556 - val_loss: 1.0191 - val_accuracy: 0.4872\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8961 - accuracy: 0.5556 - val_loss: 1.0196 - val_accuracy: 0.4872\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8947 - accuracy: 0.5556 - val_loss: 1.0192 - val_accuracy: 0.4872\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8959 - accuracy: 0.5556 - val_loss: 1.0189 - val_accuracy: 0.4872\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8965 - accuracy: 0.5556 - val_loss: 1.0193 - val_accuracy: 0.4872\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8958 - accuracy: 0.5556 - val_loss: 1.0197 - val_accuracy: 0.4872\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8944 - accuracy: 0.5556 - val_loss: 1.0207 - val_accuracy: 0.4872\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8958 - accuracy: 0.5556 - val_loss: 1.0207 - val_accuracy: 0.4872\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8938 - accuracy: 0.5556 - val_loss: 1.0210 - val_accuracy: 0.4872\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8954 - accuracy: 0.5556 - val_loss: 1.0216 - val_accuracy: 0.4872\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8950 - accuracy: 0.5556 - val_loss: 1.0222 - val_accuracy: 0.4872\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8968 - accuracy: 0.5556 - val_loss: 1.0258 - val_accuracy: 0.4872\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.8965 - accuracy: 0.5556 - val_loss: 1.0218 - val_accuracy: 0.4872\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.9006 - accuracy: 0.5556 - val_loss: 1.0237 - val_accuracy: 0.4872\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8979 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.4872\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8956 - accuracy: 0.5556 - val_loss: 1.0202 - val_accuracy: 0.4872\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.8951 - accuracy: 0.5556 - val_loss: 1.0208 - val_accuracy: 0.4872\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8943 - accuracy: 0.5556 - val_loss: 1.0186 - val_accuracy: 0.4872\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8951 - accuracy: 0.5556 - val_loss: 1.0209 - val_accuracy: 0.4872\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8951 - accuracy: 0.5556 - val_loss: 1.0232 - val_accuracy: 0.4872\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8952 - accuracy: 0.5556 - val_loss: 1.0210 - val_accuracy: 0.4872\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8936 - accuracy: 0.5556 - val_loss: 1.0209 - val_accuracy: 0.4872\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8951 - accuracy: 0.5556 - val_loss: 1.0215 - val_accuracy: 0.4872\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.8931 - accuracy: 0.5556 - val_loss: 1.0207 - val_accuracy: 0.4872\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.8964 - accuracy: 0.5556 - val_loss: 1.0205 - val_accuracy: 0.4872\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8944 - accuracy: 0.5556 - val_loss: 1.0237 - val_accuracy: 0.4872\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.8942 - accuracy: 0.5556 - val_loss: 1.0213 - val_accuracy: 0.4872\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8932 - accuracy: 0.5556 - val_loss: 1.0193 - val_accuracy: 0.4872\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8937 - accuracy: 0.5556 - val_loss: 1.0186 - val_accuracy: 0.4872\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8955 - accuracy: 0.5556 - val_loss: 1.0196 - val_accuracy: 0.4872\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8964 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.4872\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.9002 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.4872\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.8924 - accuracy: 0.5556 - val_loss: 1.0225 - val_accuracy: 0.4872\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8945 - accuracy: 0.5556 - val_loss: 1.0208 - val_accuracy: 0.4872\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8914 - accuracy: 0.5556 - val_loss: 1.0230 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8959 - accuracy: 0.5556 - val_loss: 1.0260 - val_accuracy: 0.4872\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8936 - accuracy: 0.5556 - val_loss: 1.0222 - val_accuracy: 0.4872\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8922 - accuracy: 0.5556 - val_loss: 1.0222 - val_accuracy: 0.4872\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8932 - accuracy: 0.5556 - val_loss: 1.0231 - val_accuracy: 0.4872\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8941 - accuracy: 0.5556 - val_loss: 1.0202 - val_accuracy: 0.4872\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8935 - accuracy: 0.5556 - val_loss: 1.0198 - val_accuracy: 0.4872\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8947 - accuracy: 0.5556 - val_loss: 1.0226 - val_accuracy: 0.4872\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8926 - accuracy: 0.5556 - val_loss: 1.0224 - val_accuracy: 0.4872\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8945 - accuracy: 0.5556 - val_loss: 1.0223 - val_accuracy: 0.4872\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8944 - accuracy: 0.5556 - val_loss: 1.0216 - val_accuracy: 0.4872\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 402us/step - loss: 0.8967 - accuracy: 0.5556 - val_loss: 1.0228 - val_accuracy: 0.4872\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8951 - accuracy: 0.5556 - val_loss: 1.0221 - val_accuracy: 0.4872\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8954 - accuracy: 0.5556 - val_loss: 1.0246 - val_accuracy: 0.4872\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8932 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.4872\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8925 - accuracy: 0.5556 - val_loss: 1.0230 - val_accuracy: 0.4872\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8924 - accuracy: 0.5556 - val_loss: 1.0238 - val_accuracy: 0.4872\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8918 - accuracy: 0.5556 - val_loss: 1.0240 - val_accuracy: 0.4872\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8921 - accuracy: 0.5556 - val_loss: 1.0227 - val_accuracy: 0.4872\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8919 - accuracy: 0.5556 - val_loss: 1.0240 - val_accuracy: 0.4872\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8940 - accuracy: 0.5556 - val_loss: 1.0244 - val_accuracy: 0.4872\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8950 - accuracy: 0.5556 - val_loss: 1.0241 - val_accuracy: 0.4872\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8923 - accuracy: 0.5556 - val_loss: 1.0285 - val_accuracy: 0.4872\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8938 - accuracy: 0.5556 - val_loss: 1.0255 - val_accuracy: 0.4872\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8927 - accuracy: 0.5556 - val_loss: 1.0220 - val_accuracy: 0.4872\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8936 - accuracy: 0.5556 - val_loss: 1.0224 - val_accuracy: 0.4872\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8915 - accuracy: 0.5556 - val_loss: 1.0225 - val_accuracy: 0.4872\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8918 - accuracy: 0.5556 - val_loss: 1.0234 - val_accuracy: 0.4872\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8930 - accuracy: 0.5556 - val_loss: 1.0272 - val_accuracy: 0.4872\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8933 - accuracy: 0.5556 - val_loss: 1.0257 - val_accuracy: 0.4872\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8922 - accuracy: 0.5556 - val_loss: 1.0232 - val_accuracy: 0.4872\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8920 - accuracy: 0.5556 - val_loss: 1.0245 - val_accuracy: 0.4872\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8928 - accuracy: 0.5556 - val_loss: 1.0246 - val_accuracy: 0.4872\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8914 - accuracy: 0.5556 - val_loss: 1.0239 - val_accuracy: 0.4872\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8924 - accuracy: 0.5556 - val_loss: 1.0238 - val_accuracy: 0.4872\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8914 - accuracy: 0.5556 - val_loss: 1.0236 - val_accuracy: 0.4872\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8913 - accuracy: 0.5556 - val_loss: 1.0246 - val_accuracy: 0.4872\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8922 - accuracy: 0.5556 - val_loss: 1.0243 - val_accuracy: 0.4872\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8915 - accuracy: 0.5556 - val_loss: 1.0256 - val_accuracy: 0.4872\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8925 - accuracy: 0.5556 - val_loss: 1.0236 - val_accuracy: 0.4872\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8915 - accuracy: 0.5556 - val_loss: 1.0242 - val_accuracy: 0.4872\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8905 - accuracy: 0.5556 - val_loss: 1.0243 - val_accuracy: 0.4872\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8916 - accuracy: 0.5556 - val_loss: 1.0261 - val_accuracy: 0.4872\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8912 - accuracy: 0.5556 - val_loss: 1.0251 - val_accuracy: 0.4872\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8938 - accuracy: 0.5556 - val_loss: 1.0253 - val_accuracy: 0.4872\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8916 - accuracy: 0.5556 - val_loss: 1.0280 - val_accuracy: 0.4872\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8911 - accuracy: 0.5556 - val_loss: 1.0288 - val_accuracy: 0.4872\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8910 - accuracy: 0.5556 - val_loss: 1.0297 - val_accuracy: 0.4872\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8917 - accuracy: 0.5556 - val_loss: 1.0280 - val_accuracy: 0.4872\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8902 - accuracy: 0.5556 - val_loss: 1.0273 - val_accuracy: 0.4872\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8910 - accuracy: 0.5556 - val_loss: 1.0279 - val_accuracy: 0.4872\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8940 - accuracy: 0.5556 - val_loss: 1.0260 - val_accuracy: 0.4872\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8912 - accuracy: 0.5556 - val_loss: 1.0283 - val_accuracy: 0.4872\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8904 - accuracy: 0.5556 - val_loss: 1.0268 - val_accuracy: 0.4872\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8910 - accuracy: 0.5556 - val_loss: 1.0257 - val_accuracy: 0.4872\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8908 - accuracy: 0.5556 - val_loss: 1.0271 - val_accuracy: 0.4872\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8903 - accuracy: 0.5556 - val_loss: 1.0250 - val_accuracy: 0.4872\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8899 - accuracy: 0.5556 - val_loss: 1.0276 - val_accuracy: 0.4872\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8911 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.4872\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8900 - accuracy: 0.5556 - val_loss: 1.0281 - val_accuracy: 0.4872\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8902 - accuracy: 0.5556 - val_loss: 1.0279 - val_accuracy: 0.4872\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8898 - accuracy: 0.5556 - val_loss: 1.0268 - val_accuracy: 0.4872\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8917 - accuracy: 0.5556 - val_loss: 1.0253 - val_accuracy: 0.4872\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8912 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.4872\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8897 - accuracy: 0.5556 - val_loss: 1.0259 - val_accuracy: 0.4872\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8900 - accuracy: 0.5556 - val_loss: 1.0271 - val_accuracy: 0.4872\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8904 - accuracy: 0.5556 - val_loss: 1.0249 - val_accuracy: 0.4872\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8912 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.4872\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8910 - accuracy: 0.5556 - val_loss: 1.0264 - val_accuracy: 0.4872\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8888 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.4872\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8938 - accuracy: 0.5556 - val_loss: 1.0353 - val_accuracy: 0.4872\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8891 - accuracy: 0.5556 - val_loss: 1.0284 - val_accuracy: 0.4872\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8930 - accuracy: 0.5556 - val_loss: 1.0282 - val_accuracy: 0.4872\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8906 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.4872\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8898 - accuracy: 0.5556 - val_loss: 1.0265 - val_accuracy: 0.4872\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8925 - accuracy: 0.5556 - val_loss: 1.0321 - val_accuracy: 0.4872\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8888 - accuracy: 0.5556 - val_loss: 1.0298 - val_accuracy: 0.4872\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8889 - accuracy: 0.5556 - val_loss: 1.0261 - val_accuracy: 0.4872\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8917 - accuracy: 0.5556 - val_loss: 1.0281 - val_accuracy: 0.4872\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8890 - accuracy: 0.5556 - val_loss: 1.0277 - val_accuracy: 0.4872\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.8898 - accuracy: 0.5556 - val_loss: 1.0274 - val_accuracy: 0.4872\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8924 - accuracy: 0.5556 - val_loss: 1.0324 - val_accuracy: 0.4872\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8920 - accuracy: 0.5556 - val_loss: 1.0295 - val_accuracy: 0.4872\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8906 - accuracy: 0.5556 - val_loss: 1.0300 - val_accuracy: 0.4872\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8893 - accuracy: 0.5556 - val_loss: 1.0308 - val_accuracy: 0.4872\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8908 - accuracy: 0.5556 - val_loss: 1.0317 - val_accuracy: 0.4872\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8893 - accuracy: 0.5556 - val_loss: 1.0273 - val_accuracy: 0.4872\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8882 - accuracy: 0.5556 - val_loss: 1.0267 - val_accuracy: 0.4872\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8914 - accuracy: 0.5556 - val_loss: 1.0277 - val_accuracy: 0.4872\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8909 - accuracy: 0.5556 - val_loss: 1.0258 - val_accuracy: 0.4872\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8904 - accuracy: 0.5556 - val_loss: 1.0289 - val_accuracy: 0.4872\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8896 - accuracy: 0.5556 - val_loss: 1.0299 - val_accuracy: 0.4872\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8886 - accuracy: 0.5556 - val_loss: 1.0306 - val_accuracy: 0.4872\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8886 - accuracy: 0.5556 - val_loss: 1.0293 - val_accuracy: 0.4872\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8899 - accuracy: 0.5593 - val_loss: 1.0298 - val_accuracy: 0.4957\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8892 - accuracy: 0.5556 - val_loss: 1.0291 - val_accuracy: 0.4872\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8913 - accuracy: 0.5556 - val_loss: 1.0312 - val_accuracy: 0.4872\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8882 - accuracy: 0.5556 - val_loss: 1.0302 - val_accuracy: 0.4872\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8892 - accuracy: 0.5556 - val_loss: 1.0295 - val_accuracy: 0.4872\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8894 - accuracy: 0.5556 - val_loss: 1.0272 - val_accuracy: 0.4872\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8881 - accuracy: 0.5556 - val_loss: 1.0270 - val_accuracy: 0.4872\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8877 - accuracy: 0.5556 - val_loss: 1.0315 - val_accuracy: 0.4872\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8882 - accuracy: 0.5556 - val_loss: 1.0326 - val_accuracy: 0.4872\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8891 - accuracy: 0.5556 - val_loss: 1.0283 - val_accuracy: 0.4872\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8908 - accuracy: 0.5556 - val_loss: 1.0277 - val_accuracy: 0.4872\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8890 - accuracy: 0.5556 - val_loss: 1.0274 - val_accuracy: 0.4872\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8872 - accuracy: 0.5556 - val_loss: 1.0287 - val_accuracy: 0.4872\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.8893 - accuracy: 0.5556 - val_loss: 1.0318 - val_accuracy: 0.4872\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8901 - accuracy: 0.5556 - val_loss: 1.0275 - val_accuracy: 0.4872\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8888 - accuracy: 0.5556 - val_loss: 1.0280 - val_accuracy: 0.4872\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8913 - accuracy: 0.5556 - val_loss: 1.0288 - val_accuracy: 0.4872\n",
      "Epoch 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 139us/step - loss: 0.8877 - accuracy: 0.5556 - val_loss: 1.0286 - val_accuracy: 0.4872\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8875 - accuracy: 0.5556 - val_loss: 1.0266 - val_accuracy: 0.4872\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8883 - accuracy: 0.5556 - val_loss: 1.0278 - val_accuracy: 0.4872\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8882 - accuracy: 0.5556 - val_loss: 1.0319 - val_accuracy: 0.4872\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8888 - accuracy: 0.5556 - val_loss: 1.0323 - val_accuracy: 0.4872\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8885 - accuracy: 0.5556 - val_loss: 1.0340 - val_accuracy: 0.4872\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8876 - accuracy: 0.5556 - val_loss: 1.0370 - val_accuracy: 0.4872\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8875 - accuracy: 0.5556 - val_loss: 1.0342 - val_accuracy: 0.4872\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8873 - accuracy: 0.5556 - val_loss: 1.0310 - val_accuracy: 0.4872\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8881 - accuracy: 0.5556 - val_loss: 1.0311 - val_accuracy: 0.4872\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8886 - accuracy: 0.5556 - val_loss: 1.0299 - val_accuracy: 0.4872\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8861 - accuracy: 0.5556 - val_loss: 1.0318 - val_accuracy: 0.4872\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8905 - accuracy: 0.5556 - val_loss: 1.0356 - val_accuracy: 0.4872\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8868 - accuracy: 0.5556 - val_loss: 1.0284 - val_accuracy: 0.4872\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8879 - accuracy: 0.5593 - val_loss: 1.0291 - val_accuracy: 0.4872\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8910 - accuracy: 0.5556 - val_loss: 1.0322 - val_accuracy: 0.4872\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 309us/step - loss: 0.8856 - accuracy: 0.5556 - val_loss: 1.0324 - val_accuracy: 0.4872\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8871 - accuracy: 0.5556 - val_loss: 1.0333 - val_accuracy: 0.4957\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8872 - accuracy: 0.5556 - val_loss: 1.0340 - val_accuracy: 0.4872\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8858 - accuracy: 0.5556 - val_loss: 1.0340 - val_accuracy: 0.4872\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8876 - accuracy: 0.5556 - val_loss: 1.0378 - val_accuracy: 0.4872\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8882 - accuracy: 0.5556 - val_loss: 1.0318 - val_accuracy: 0.4872\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.8876 - accuracy: 0.5556 - val_loss: 1.0313 - val_accuracy: 0.4872\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.8864 - accuracy: 0.5556 - val_loss: 1.0348 - val_accuracy: 0.4872\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8908 - accuracy: 0.5556 - val_loss: 1.0402 - val_accuracy: 0.4872\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8900 - accuracy: 0.5556 - val_loss: 1.0373 - val_accuracy: 0.4872\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8858 - accuracy: 0.5593 - val_loss: 1.0317 - val_accuracy: 0.4957\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8872 - accuracy: 0.5593 - val_loss: 1.0306 - val_accuracy: 0.4957\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8869 - accuracy: 0.5593 - val_loss: 1.0328 - val_accuracy: 0.4872\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8851 - accuracy: 0.5556 - val_loss: 1.0364 - val_accuracy: 0.4872\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8859 - accuracy: 0.5556 - val_loss: 1.0356 - val_accuracy: 0.4872\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8868 - accuracy: 0.5556 - val_loss: 1.0338 - val_accuracy: 0.4872\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8864 - accuracy: 0.5556 - val_loss: 1.0330 - val_accuracy: 0.4872\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8857 - accuracy: 0.5556 - val_loss: 1.0318 - val_accuracy: 0.4872\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8865 - accuracy: 0.5556 - val_loss: 1.0335 - val_accuracy: 0.4872\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8887 - accuracy: 0.5556 - val_loss: 1.0358 - val_accuracy: 0.4872\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8850 - accuracy: 0.5556 - val_loss: 1.0352 - val_accuracy: 0.4957\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8868 - accuracy: 0.5593 - val_loss: 1.0326 - val_accuracy: 0.4957\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8863 - accuracy: 0.5556 - val_loss: 1.0365 - val_accuracy: 0.4872\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8846 - accuracy: 0.5556 - val_loss: 1.0348 - val_accuracy: 0.4872\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8854 - accuracy: 0.5556 - val_loss: 1.0322 - val_accuracy: 0.4957\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8865 - accuracy: 0.5593 - val_loss: 1.0316 - val_accuracy: 0.4872\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8878 - accuracy: 0.5556 - val_loss: 1.0308 - val_accuracy: 0.4957\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8861 - accuracy: 0.5556 - val_loss: 1.0337 - val_accuracy: 0.4872\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8866 - accuracy: 0.5556 - val_loss: 1.0355 - val_accuracy: 0.4872\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8865 - accuracy: 0.5556 - val_loss: 1.0358 - val_accuracy: 0.4872\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8850 - accuracy: 0.5556 - val_loss: 1.0346 - val_accuracy: 0.4872\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8857 - accuracy: 0.5593 - val_loss: 1.0355 - val_accuracy: 0.4957\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8859 - accuracy: 0.5556 - val_loss: 1.0357 - val_accuracy: 0.4957\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8856 - accuracy: 0.5593 - val_loss: 1.0336 - val_accuracy: 0.4957\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8938 - accuracy: 0.5593 - val_loss: 1.0388 - val_accuracy: 0.4872\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8861 - accuracy: 0.5593 - val_loss: 1.0346 - val_accuracy: 0.4957\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8891 - accuracy: 0.5593 - val_loss: 1.0341 - val_accuracy: 0.4957\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8832 - accuracy: 0.5593 - val_loss: 1.0381 - val_accuracy: 0.4872\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8875 - accuracy: 0.5556 - val_loss: 1.0353 - val_accuracy: 0.4872\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8864 - accuracy: 0.5556 - val_loss: 1.0368 - val_accuracy: 0.4872\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8869 - accuracy: 0.5556 - val_loss: 1.0371 - val_accuracy: 0.4872\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8857 - accuracy: 0.5556 - val_loss: 1.0349 - val_accuracy: 0.4872\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8846 - accuracy: 0.5556 - val_loss: 1.0363 - val_accuracy: 0.4957\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8863 - accuracy: 0.5556 - val_loss: 1.0396 - val_accuracy: 0.4872\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8853 - accuracy: 0.5556 - val_loss: 1.0345 - val_accuracy: 0.4957\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8883 - accuracy: 0.5593 - val_loss: 1.0323 - val_accuracy: 0.4957\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8856 - accuracy: 0.5556 - val_loss: 1.0357 - val_accuracy: 0.4872\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8873 - accuracy: 0.5556 - val_loss: 1.0357 - val_accuracy: 0.4872\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8860 - accuracy: 0.5593 - val_loss: 1.0339 - val_accuracy: 0.4957\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8861 - accuracy: 0.5593 - val_loss: 1.0396 - val_accuracy: 0.4957\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8844 - accuracy: 0.5593 - val_loss: 1.0386 - val_accuracy: 0.4957\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8857 - accuracy: 0.5593 - val_loss: 1.0341 - val_accuracy: 0.4957\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8852 - accuracy: 0.5556 - val_loss: 1.0395 - val_accuracy: 0.4872\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8853 - accuracy: 0.5556 - val_loss: 1.0377 - val_accuracy: 0.4957\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8847 - accuracy: 0.5593 - val_loss: 1.0325 - val_accuracy: 0.4957\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8839 - accuracy: 0.5593 - val_loss: 1.0330 - val_accuracy: 0.4957\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8324 - accuracy: 0.62 - 0s 129us/step - loss: 0.8857 - accuracy: 0.5556 - val_loss: 1.0354 - val_accuracy: 0.4872\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8853 - accuracy: 0.5556 - val_loss: 1.0378 - val_accuracy: 0.4957\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8856 - accuracy: 0.5593 - val_loss: 1.0357 - val_accuracy: 0.4957\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8823 - accuracy: 0.5593 - val_loss: 1.0347 - val_accuracy: 0.4957\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8866 - accuracy: 0.5556 - val_loss: 1.0359 - val_accuracy: 0.4872\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8833 - accuracy: 0.5556 - val_loss: 1.0341 - val_accuracy: 0.4957\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8841 - accuracy: 0.5593 - val_loss: 1.0383 - val_accuracy: 0.4957\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8878 - accuracy: 0.5593 - val_loss: 1.0395 - val_accuracy: 0.4957\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8841 - accuracy: 0.5593 - val_loss: 1.0359 - val_accuracy: 0.4957\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8871 - accuracy: 0.5593 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8837 - accuracy: 0.5593 - val_loss: 1.0366 - val_accuracy: 0.4957\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8813 - accuracy: 0.5593 - val_loss: 1.0402 - val_accuracy: 0.4957\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8840 - accuracy: 0.5593 - val_loss: 1.0390 - val_accuracy: 0.4957\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8836 - accuracy: 0.5593 - val_loss: 1.0373 - val_accuracy: 0.4957\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8835 - accuracy: 0.5593 - val_loss: 1.0358 - val_accuracy: 0.4957\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8896 - accuracy: 0.5593 - val_loss: 1.0346 - val_accuracy: 0.4957\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8867 - accuracy: 0.5593 - val_loss: 1.0359 - val_accuracy: 0.4957\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8837 - accuracy: 0.5593 - val_loss: 1.0371 - val_accuracy: 0.4957\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8825 - accuracy: 0.5593 - val_loss: 1.0396 - val_accuracy: 0.4872\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8850 - accuracy: 0.5556 - val_loss: 1.0403 - val_accuracy: 0.4872\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8844 - accuracy: 0.5593 - val_loss: 1.0385 - val_accuracy: 0.4957\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8828 - accuracy: 0.5593 - val_loss: 1.0408 - val_accuracy: 0.4957\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8839 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8829 - accuracy: 0.5593 - val_loss: 1.0368 - val_accuracy: 0.4957\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8833 - accuracy: 0.5593 - val_loss: 1.0374 - val_accuracy: 0.4957\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8836 - accuracy: 0.5593 - val_loss: 1.0378 - val_accuracy: 0.4957\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8832 - accuracy: 0.5593 - val_loss: 1.0377 - val_accuracy: 0.4957\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8836 - accuracy: 0.5593 - val_loss: 1.0370 - val_accuracy: 0.4957\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8824 - accuracy: 0.5593 - val_loss: 1.0404 - val_accuracy: 0.4957\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8840 - accuracy: 0.5556 - val_loss: 1.0382 - val_accuracy: 0.4957\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8826 - accuracy: 0.5593 - val_loss: 1.0362 - val_accuracy: 0.4957\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8851 - accuracy: 0.5593 - val_loss: 1.0346 - val_accuracy: 0.4957\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8905 - accuracy: 0.5593 - val_loss: 1.0378 - val_accuracy: 0.4872\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8847 - accuracy: 0.5556 - val_loss: 1.0381 - val_accuracy: 0.4957\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8821 - accuracy: 0.5593 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8867 - accuracy: 0.5593 - val_loss: 1.0362 - val_accuracy: 0.4957\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8817 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8850 - accuracy: 0.5556 - val_loss: 1.0410 - val_accuracy: 0.4872\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 111us/step - loss: 0.8858 - accuracy: 0.5556 - val_loss: 1.0436 - val_accuracy: 0.4872\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8830 - accuracy: 0.5556 - val_loss: 1.0388 - val_accuracy: 0.4957\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8842 - accuracy: 0.5593 - val_loss: 1.0393 - val_accuracy: 0.4957\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8844 - accuracy: 0.5593 - val_loss: 1.0352 - val_accuracy: 0.4957\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8869 - accuracy: 0.5296 - val_loss: 1.0369 - val_accuracy: 0.4957\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8834 - accuracy: 0.5593 - val_loss: 1.0346 - val_accuracy: 0.4957\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8867 - accuracy: 0.5593 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8837 - accuracy: 0.5593 - val_loss: 1.0375 - val_accuracy: 0.4957\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8821 - accuracy: 0.5593 - val_loss: 1.0349 - val_accuracy: 0.4957\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8811 - accuracy: 0.5593 - val_loss: 1.0331 - val_accuracy: 0.4957\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8818 - accuracy: 0.5593 - val_loss: 1.0346 - val_accuracy: 0.4957\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8827 - accuracy: 0.5593 - val_loss: 1.0384 - val_accuracy: 0.4957\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8812 - accuracy: 0.5593 - val_loss: 1.0363 - val_accuracy: 0.4957\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8829 - accuracy: 0.5593 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8825 - accuracy: 0.5593 - val_loss: 1.0370 - val_accuracy: 0.4957\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8815 - accuracy: 0.5593 - val_loss: 1.0392 - val_accuracy: 0.4957\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8816 - accuracy: 0.5593 - val_loss: 1.0425 - val_accuracy: 0.4957\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8820 - accuracy: 0.5593 - val_loss: 1.0413 - val_accuracy: 0.4957\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8814 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8846 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8817 - accuracy: 0.5593 - val_loss: 1.0404 - val_accuracy: 0.4957\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8819 - accuracy: 0.5593 - val_loss: 1.0412 - val_accuracy: 0.4957\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8830 - accuracy: 0.5593 - val_loss: 1.0407 - val_accuracy: 0.5043\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8820 - accuracy: 0.5593 - val_loss: 1.0367 - val_accuracy: 0.4957\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8818 - accuracy: 0.5593 - val_loss: 1.0383 - val_accuracy: 0.4957\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8810 - accuracy: 0.5593 - val_loss: 1.0393 - val_accuracy: 0.5043\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8817 - accuracy: 0.5630 - val_loss: 1.0402 - val_accuracy: 0.5043\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8815 - accuracy: 0.5630 - val_loss: 1.0394 - val_accuracy: 0.5043\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8813 - accuracy: 0.5630 - val_loss: 1.0370 - val_accuracy: 0.5043\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8814 - accuracy: 0.5630 - val_loss: 1.0380 - val_accuracy: 0.5043\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8812 - accuracy: 0.5630 - val_loss: 1.0370 - val_accuracy: 0.5043\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8822 - accuracy: 0.5630 - val_loss: 1.0404 - val_accuracy: 0.5043\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8814 - accuracy: 0.5630 - val_loss: 1.0396 - val_accuracy: 0.5043\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8815 - accuracy: 0.5593 - val_loss: 1.0392 - val_accuracy: 0.4957\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8803 - accuracy: 0.5593 - val_loss: 1.0384 - val_accuracy: 0.4957\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8798 - accuracy: 0.5593 - val_loss: 1.0409 - val_accuracy: 0.4957\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8820 - accuracy: 0.5593 - val_loss: 1.0416 - val_accuracy: 0.4957\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8824 - accuracy: 0.5593 - val_loss: 1.0401 - val_accuracy: 0.4957\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8858 - accuracy: 0.5593 - val_loss: 1.0421 - val_accuracy: 0.4957\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8815 - accuracy: 0.5593 - val_loss: 1.0429 - val_accuracy: 0.4957\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8808 - accuracy: 0.5630 - val_loss: 1.0421 - val_accuracy: 0.5043\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0412 - val_accuracy: 0.4957\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0385 - val_accuracy: 0.5043\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8814 - accuracy: 0.5630 - val_loss: 1.0400 - val_accuracy: 0.4957\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8797 - accuracy: 0.5593 - val_loss: 1.0421 - val_accuracy: 0.5043\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8812 - accuracy: 0.5630 - val_loss: 1.0432 - val_accuracy: 0.5043\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8809 - accuracy: 0.5630 - val_loss: 1.0422 - val_accuracy: 0.5043\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8797 - accuracy: 0.5593 - val_loss: 1.0414 - val_accuracy: 0.4957\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8813 - accuracy: 0.5593 - val_loss: 1.0428 - val_accuracy: 0.4957\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8820 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.5043\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8812 - accuracy: 0.5593 - val_loss: 1.0426 - val_accuracy: 0.4957\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8809 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8797 - accuracy: 0.5593 - val_loss: 1.0405 - val_accuracy: 0.5043\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8828 - accuracy: 0.5630 - val_loss: 1.0425 - val_accuracy: 0.5043\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8804 - accuracy: 0.5630 - val_loss: 1.0419 - val_accuracy: 0.5043\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8810 - accuracy: 0.5630 - val_loss: 1.0403 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8819 - accuracy: 0.5593 - val_loss: 1.0412 - val_accuracy: 0.4957\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8814 - accuracy: 0.5593 - val_loss: 1.0409 - val_accuracy: 0.5043\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8819 - accuracy: 0.5593 - val_loss: 1.0397 - val_accuracy: 0.5043\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8789 - accuracy: 0.5630 - val_loss: 1.0403 - val_accuracy: 0.5043\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8826 - accuracy: 0.5630 - val_loss: 1.0414 - val_accuracy: 0.5043\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8800 - accuracy: 0.5630 - val_loss: 1.0387 - val_accuracy: 0.5043\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8819 - accuracy: 0.5630 - val_loss: 1.0389 - val_accuracy: 0.5043\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0397 - val_accuracy: 0.5043\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8831 - accuracy: 0.5593 - val_loss: 1.0403 - val_accuracy: 0.4957\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8829 - accuracy: 0.5593 - val_loss: 1.0390 - val_accuracy: 0.5043\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8814 - accuracy: 0.5630 - val_loss: 1.0417 - val_accuracy: 0.5043\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8820 - accuracy: 0.5630 - val_loss: 1.0457 - val_accuracy: 0.5043\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8693 - accuracy: 0.59 - 0s 115us/step - loss: 0.8802 - accuracy: 0.5630 - val_loss: 1.0437 - val_accuracy: 0.5043\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8800 - accuracy: 0.5630 - val_loss: 1.0425 - val_accuracy: 0.5043\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8794 - accuracy: 0.5593 - val_loss: 1.0425 - val_accuracy: 0.5043\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8817 - accuracy: 0.5630 - val_loss: 1.0447 - val_accuracy: 0.5043\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0414 - val_accuracy: 0.5043\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8792 - accuracy: 0.5630 - val_loss: 1.0402 - val_accuracy: 0.5043\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0409 - val_accuracy: 0.5043\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8790 - accuracy: 0.5630 - val_loss: 1.0422 - val_accuracy: 0.5043\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8800 - accuracy: 0.5630 - val_loss: 1.0435 - val_accuracy: 0.5043\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8810 - accuracy: 0.5630 - val_loss: 1.0475 - val_accuracy: 0.5043\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8805 - accuracy: 0.5630 - val_loss: 1.0415 - val_accuracy: 0.5043\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8804 - accuracy: 0.5630 - val_loss: 1.0406 - val_accuracy: 0.5043\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8820 - accuracy: 0.5630 - val_loss: 1.0403 - val_accuracy: 0.5043\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0432 - val_accuracy: 0.5043\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8831 - accuracy: 0.5630 - val_loss: 1.0458 - val_accuracy: 0.5043\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8819 - accuracy: 0.5593 - val_loss: 1.0507 - val_accuracy: 0.4957\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8820 - accuracy: 0.5630 - val_loss: 1.0424 - val_accuracy: 0.5043\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8813 - accuracy: 0.5630 - val_loss: 1.0424 - val_accuracy: 0.5043\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8791 - accuracy: 0.5630 - val_loss: 1.0415 - val_accuracy: 0.5043\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8791 - accuracy: 0.5630 - val_loss: 1.0477 - val_accuracy: 0.5043\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8796 - accuracy: 0.5630 - val_loss: 1.0483 - val_accuracy: 0.5043\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8802 - accuracy: 0.5630 - val_loss: 1.0439 - val_accuracy: 0.5043\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8836 - accuracy: 0.5593 - val_loss: 1.0390 - val_accuracy: 0.5043\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8794 - accuracy: 0.5630 - val_loss: 1.0379 - val_accuracy: 0.5043\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8835 - accuracy: 0.5630 - val_loss: 1.0417 - val_accuracy: 0.5043\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0410 - val_accuracy: 0.5043\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8823 - accuracy: 0.5593 - val_loss: 1.0447 - val_accuracy: 0.4957\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8808 - accuracy: 0.5593 - val_loss: 1.0464 - val_accuracy: 0.5043\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8841 - accuracy: 0.5630 - val_loss: 1.0512 - val_accuracy: 0.5043\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8830 - accuracy: 0.5630 - val_loss: 1.0451 - val_accuracy: 0.4957\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8810 - accuracy: 0.5630 - val_loss: 1.0423 - val_accuracy: 0.5043\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8795 - accuracy: 0.5630 - val_loss: 1.0420 - val_accuracy: 0.5043\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8779 - accuracy: 0.5630 - val_loss: 1.0420 - val_accuracy: 0.5043\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.8787 - accuracy: 0.5630 - val_loss: 1.0403 - val_accuracy: 0.5043\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8790 - accuracy: 0.5630 - val_loss: 1.0425 - val_accuracy: 0.5043\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8786 - accuracy: 0.5630 - val_loss: 1.0433 - val_accuracy: 0.5043\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8804 - accuracy: 0.5630 - val_loss: 1.0409 - val_accuracy: 0.5043\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8790 - accuracy: 0.5630 - val_loss: 1.0454 - val_accuracy: 0.5043\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0462 - val_accuracy: 0.5043\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8800 - accuracy: 0.5630 - val_loss: 1.0451 - val_accuracy: 0.5043\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8786 - accuracy: 0.5630 - val_loss: 1.0437 - val_accuracy: 0.5043\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8803 - accuracy: 0.5630 - val_loss: 1.0452 - val_accuracy: 0.5043\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8781 - accuracy: 0.5630 - val_loss: 1.0487 - val_accuracy: 0.5043\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8810 - accuracy: 0.5630 - val_loss: 1.0445 - val_accuracy: 0.5043\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8814 - accuracy: 0.5630 - val_loss: 1.0443 - val_accuracy: 0.5043\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8824 - accuracy: 0.5593 - val_loss: 1.0521 - val_accuracy: 0.5043\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8820 - accuracy: 0.5630 - val_loss: 1.0493 - val_accuracy: 0.5043\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8782 - accuracy: 0.5630 - val_loss: 1.0446 - val_accuracy: 0.5043\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8794 - accuracy: 0.5630 - val_loss: 1.0455 - val_accuracy: 0.5043\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 289us/step - loss: 0.8821 - accuracy: 0.5630 - val_loss: 1.0441 - val_accuracy: 0.5043\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0474 - val_accuracy: 0.5043\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8775 - accuracy: 0.5630 - val_loss: 1.0457 - val_accuracy: 0.5043\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0445 - val_accuracy: 0.5043\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8808 - accuracy: 0.5630 - val_loss: 1.0442 - val_accuracy: 0.5043\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8780 - accuracy: 0.5630 - val_loss: 1.0432 - val_accuracy: 0.5043\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8817 - accuracy: 0.5630 - val_loss: 1.0448 - val_accuracy: 0.5043\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0445 - val_accuracy: 0.5043\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8758 - accuracy: 0.5630 - val_loss: 1.0462 - val_accuracy: 0.5043\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0495 - val_accuracy: 0.5043\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 602us/step - loss: 0.8796 - accuracy: 0.5630 - val_loss: 1.0446 - val_accuracy: 0.5043\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8792 - accuracy: 0.5630 - val_loss: 1.0455 - val_accuracy: 0.5043\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8833 - accuracy: 0.5630 - val_loss: 1.0445 - val_accuracy: 0.5043\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8807 - accuracy: 0.5630 - val_loss: 1.0470 - val_accuracy: 0.5043\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8771 - accuracy: 0.5630 - val_loss: 1.0447 - val_accuracy: 0.5043\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8790 - accuracy: 0.5630 - val_loss: 1.0473 - val_accuracy: 0.5043\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.8770 - accuracy: 0.5630 - val_loss: 1.0465 - val_accuracy: 0.5043\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8773 - accuracy: 0.5630 - val_loss: 1.0454 - val_accuracy: 0.5043\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8779 - accuracy: 0.5630 - val_loss: 1.0437 - val_accuracy: 0.5043\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8781 - accuracy: 0.5630 - val_loss: 1.0447 - val_accuracy: 0.5043\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8773 - accuracy: 0.5630 - val_loss: 1.0449 - val_accuracy: 0.5043\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8777 - accuracy: 0.5630 - val_loss: 1.0477 - val_accuracy: 0.5043\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 514us/step - loss: 0.8771 - accuracy: 0.5630 - val_loss: 1.0495 - val_accuracy: 0.5043\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8798 - accuracy: 0.5630 - val_loss: 1.0422 - val_accuracy: 0.5043\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0437 - val_accuracy: 0.5043\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8781 - accuracy: 0.5630 - val_loss: 1.0453 - val_accuracy: 0.5043\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.8788 - accuracy: 0.5630 - val_loss: 1.0463 - val_accuracy: 0.5043\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 358us/step - loss: 0.8755 - accuracy: 0.5630 - val_loss: 1.0497 - val_accuracy: 0.5043\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 341us/step - loss: 0.8782 - accuracy: 0.5630 - val_loss: 1.0497 - val_accuracy: 0.5043\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.8780 - accuracy: 0.5630 - val_loss: 1.0481 - val_accuracy: 0.5043\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.8870 - accuracy: 0.5630 - val_loss: 1.0489 - val_accuracy: 0.5043\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.8778 - accuracy: 0.5630 - val_loss: 1.0472 - val_accuracy: 0.5043\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 325us/step - loss: 0.8806 - accuracy: 0.5630 - val_loss: 1.0413 - val_accuracy: 0.5043\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0410 - val_accuracy: 0.5043\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8766 - accuracy: 0.5630 - val_loss: 1.0433 - val_accuracy: 0.5043\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 376us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0482 - val_accuracy: 0.5043\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8779 - accuracy: 0.5630 - val_loss: 1.0522 - val_accuracy: 0.5043\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8789 - accuracy: 0.5630 - val_loss: 1.0492 - val_accuracy: 0.5043\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8765 - accuracy: 0.5630 - val_loss: 1.0545 - val_accuracy: 0.5043\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8788 - accuracy: 0.5630 - val_loss: 1.0515 - val_accuracy: 0.5043\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0521 - val_accuracy: 0.5043\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0459 - val_accuracy: 0.5043\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8780 - accuracy: 0.5630 - val_loss: 1.0455 - val_accuracy: 0.5043\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8756 - accuracy: 0.5630 - val_loss: 1.0507 - val_accuracy: 0.5043\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0543 - val_accuracy: 0.5043\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8790 - accuracy: 0.5630 - val_loss: 1.0519 - val_accuracy: 0.5043\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8770 - accuracy: 0.5630 - val_loss: 1.0507 - val_accuracy: 0.5043\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8782 - accuracy: 0.5630 - val_loss: 1.0448 - val_accuracy: 0.5043\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8773 - accuracy: 0.5630 - val_loss: 1.0480 - val_accuracy: 0.5043\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 117us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0501 - val_accuracy: 0.5043\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8763 - accuracy: 0.5630 - val_loss: 1.0482 - val_accuracy: 0.5043\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8775 - accuracy: 0.5630 - val_loss: 1.0470 - val_accuracy: 0.5043\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8798 - accuracy: 0.5630 - val_loss: 1.0500 - val_accuracy: 0.5043\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0546 - val_accuracy: 0.5043\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8770 - accuracy: 0.5630 - val_loss: 1.0543 - val_accuracy: 0.5043\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8794 - accuracy: 0.5630 - val_loss: 1.0489 - val_accuracy: 0.5043\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8754 - accuracy: 0.5630 - val_loss: 1.0520 - val_accuracy: 0.5043\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8762 - accuracy: 0.5630 - val_loss: 1.0523 - val_accuracy: 0.5043\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8774 - accuracy: 0.5630 - val_loss: 1.0498 - val_accuracy: 0.5043\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8756 - accuracy: 0.5630 - val_loss: 1.0474 - val_accuracy: 0.5043\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8783 - accuracy: 0.5630 - val_loss: 1.0494 - val_accuracy: 0.5043\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8769 - accuracy: 0.5630 - val_loss: 1.0512 - val_accuracy: 0.5043\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.8759 - accuracy: 0.5630 - val_loss: 1.0492 - val_accuracy: 0.5043\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8778 - accuracy: 0.5630 - val_loss: 1.0472 - val_accuracy: 0.5043\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8766 - accuracy: 0.5630 - val_loss: 1.0501 - val_accuracy: 0.5043\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8763 - accuracy: 0.5630 - val_loss: 1.0499 - val_accuracy: 0.5043\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8760 - accuracy: 0.5630 - val_loss: 1.0543 - val_accuracy: 0.5043\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8764 - accuracy: 0.5630 - val_loss: 1.0504 - val_accuracy: 0.5043\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8775 - accuracy: 0.5630 - val_loss: 1.0485 - val_accuracy: 0.5043\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8790 - accuracy: 0.5667 - val_loss: 1.0517 - val_accuracy: 0.5043\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8773 - accuracy: 0.5630 - val_loss: 1.0491 - val_accuracy: 0.5043\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8776 - accuracy: 0.5630 - val_loss: 1.0525 - val_accuracy: 0.5043\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8775 - accuracy: 0.5630 - val_loss: 1.0506 - val_accuracy: 0.5043\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8758 - accuracy: 0.5630 - val_loss: 1.0508 - val_accuracy: 0.5043\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8789 - accuracy: 0.5630 - val_loss: 1.0562 - val_accuracy: 0.5043\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8779 - accuracy: 0.5630 - val_loss: 1.0531 - val_accuracy: 0.5043\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8775 - accuracy: 0.5630 - val_loss: 1.0548 - val_accuracy: 0.5043\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8787 - accuracy: 0.5630 - val_loss: 1.0524 - val_accuracy: 0.5043\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8797 - accuracy: 0.5630 - val_loss: 1.0553 - val_accuracy: 0.5043\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8770 - accuracy: 0.5630 - val_loss: 1.0492 - val_accuracy: 0.5043\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8760 - accuracy: 0.5667 - val_loss: 1.0496 - val_accuracy: 0.5043\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8757 - accuracy: 0.5630 - val_loss: 1.0496 - val_accuracy: 0.5043\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8759 - accuracy: 0.5630 - val_loss: 1.0518 - val_accuracy: 0.5043\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8766 - accuracy: 0.5630 - val_loss: 1.0524 - val_accuracy: 0.5043\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8764 - accuracy: 0.5630 - val_loss: 1.0536 - val_accuracy: 0.5043\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8754 - accuracy: 0.5630 - val_loss: 1.0538 - val_accuracy: 0.5043\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8763 - accuracy: 0.5630 - val_loss: 1.0505 - val_accuracy: 0.5043\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8735 - accuracy: 0.5630 - val_loss: 1.0521 - val_accuracy: 0.5043\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8749 - accuracy: 0.5630 - val_loss: 1.0521 - val_accuracy: 0.5043\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8762 - accuracy: 0.5630 - val_loss: 1.0540 - val_accuracy: 0.5043\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8748 - accuracy: 0.5630 - val_loss: 1.0538 - val_accuracy: 0.5043\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8767 - accuracy: 0.5630 - val_loss: 1.0565 - val_accuracy: 0.5043\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8753 - accuracy: 0.5630 - val_loss: 1.0526 - val_accuracy: 0.5043\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8755 - accuracy: 0.5667 - val_loss: 1.0516 - val_accuracy: 0.5043\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8755 - accuracy: 0.5667 - val_loss: 1.0526 - val_accuracy: 0.5043\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8741 - accuracy: 0.5630 - val_loss: 1.0534 - val_accuracy: 0.5043\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8756 - accuracy: 0.5630 - val_loss: 1.0558 - val_accuracy: 0.5043\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8753 - accuracy: 0.5630 - val_loss: 1.0546 - val_accuracy: 0.5043\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8756 - accuracy: 0.5630 - val_loss: 1.0519 - val_accuracy: 0.5043\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8803 - accuracy: 0.5556 - val_loss: 1.0508 - val_accuracy: 0.5043\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8742 - accuracy: 0.5667 - val_loss: 1.0541 - val_accuracy: 0.5043\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8764 - accuracy: 0.5667 - val_loss: 1.0522 - val_accuracy: 0.5043\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8757 - accuracy: 0.5630 - val_loss: 1.0522 - val_accuracy: 0.5043\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8738 - accuracy: 0.5630 - val_loss: 1.0550 - val_accuracy: 0.5043\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8744 - accuracy: 0.5630 - val_loss: 1.0542 - val_accuracy: 0.5043\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8747 - accuracy: 0.5630 - val_loss: 1.0590 - val_accuracy: 0.5043\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8771 - accuracy: 0.5630 - val_loss: 1.0535 - val_accuracy: 0.5043\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8742 - accuracy: 0.5630 - val_loss: 1.0512 - val_accuracy: 0.5043\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8748 - accuracy: 0.5630 - val_loss: 1.0546 - val_accuracy: 0.5043\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8766 - accuracy: 0.5630 - val_loss: 1.0556 - val_accuracy: 0.5043\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8770 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.5043\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8766 - accuracy: 0.5630 - val_loss: 1.0575 - val_accuracy: 0.5043\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8741 - accuracy: 0.5630 - val_loss: 1.0547 - val_accuracy: 0.5043\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8760 - accuracy: 0.5630 - val_loss: 1.0553 - val_accuracy: 0.5043\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8730 - accuracy: 0.5630 - val_loss: 1.0560 - val_accuracy: 0.5043\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8764 - accuracy: 0.5630 - val_loss: 1.0552 - val_accuracy: 0.5043\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8758 - accuracy: 0.5630 - val_loss: 1.0520 - val_accuracy: 0.5043\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8750 - accuracy: 0.5667 - val_loss: 1.0527 - val_accuracy: 0.5043\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8752 - accuracy: 0.5630 - val_loss: 1.0532 - val_accuracy: 0.5043\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8757 - accuracy: 0.5630 - val_loss: 1.0590 - val_accuracy: 0.5043\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8744 - accuracy: 0.5630 - val_loss: 1.0530 - val_accuracy: 0.5043\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8743 - accuracy: 0.5667 - val_loss: 1.0514 - val_accuracy: 0.5043\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8763 - accuracy: 0.5667 - val_loss: 1.0544 - val_accuracy: 0.5043\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8727 - accuracy: 0.5667 - val_loss: 1.0550 - val_accuracy: 0.5043\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8806 - accuracy: 0.5630 - val_loss: 1.0561 - val_accuracy: 0.5043\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8722 - accuracy: 0.5630 - val_loss: 1.0563 - val_accuracy: 0.5043\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8784 - accuracy: 0.5630 - val_loss: 1.0549 - val_accuracy: 0.5043\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8738 - accuracy: 0.5630 - val_loss: 1.0566 - val_accuracy: 0.5043\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8740 - accuracy: 0.5630 - val_loss: 1.0532 - val_accuracy: 0.5043\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8727 - accuracy: 0.5667 - val_loss: 1.0533 - val_accuracy: 0.5043\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8734 - accuracy: 0.5630 - val_loss: 1.0557 - val_accuracy: 0.5043\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8745 - accuracy: 0.5630 - val_loss: 1.0561 - val_accuracy: 0.5043\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8763 - accuracy: 0.5667 - val_loss: 1.0536 - val_accuracy: 0.5043\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8749 - accuracy: 0.5667 - val_loss: 1.0546 - val_accuracy: 0.5043\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8735 - accuracy: 0.5630 - val_loss: 1.0582 - val_accuracy: 0.5043\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8734 - accuracy: 0.5630 - val_loss: 1.0578 - val_accuracy: 0.5043\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8780 - accuracy: 0.5630 - val_loss: 1.0586 - val_accuracy: 0.5043\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8739 - accuracy: 0.5630 - val_loss: 1.0571 - val_accuracy: 0.5043\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8742 - accuracy: 0.5667 - val_loss: 1.0535 - val_accuracy: 0.5043\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8747 - accuracy: 0.5667 - val_loss: 1.0536 - val_accuracy: 0.5043\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8736 - accuracy: 0.5667 - val_loss: 1.0515 - val_accuracy: 0.5043\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8733 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.5043\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8748 - accuracy: 0.5630 - val_loss: 1.0608 - val_accuracy: 0.5043\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8742 - accuracy: 0.5630 - val_loss: 1.0611 - val_accuracy: 0.5043\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8742 - accuracy: 0.5630 - val_loss: 1.0612 - val_accuracy: 0.5043\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8747 - accuracy: 0.5630 - val_loss: 1.0603 - val_accuracy: 0.5043\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8727 - accuracy: 0.5667 - val_loss: 1.0561 - val_accuracy: 0.5043\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8750 - accuracy: 0.5667 - val_loss: 1.0555 - val_accuracy: 0.5043\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0615 - val_accuracy: 0.5043\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8741 - accuracy: 0.5630 - val_loss: 1.0575 - val_accuracy: 0.5043\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8729 - accuracy: 0.5630 - val_loss: 1.0554 - val_accuracy: 0.5043\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8735 - accuracy: 0.5667 - val_loss: 1.0536 - val_accuracy: 0.5043\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8730 - accuracy: 0.5667 - val_loss: 1.0559 - val_accuracy: 0.5043\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8738 - accuracy: 0.5667 - val_loss: 1.0587 - val_accuracy: 0.5043\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0592 - val_accuracy: 0.5043\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8735 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.5043\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8721 - accuracy: 0.5667 - val_loss: 1.0557 - val_accuracy: 0.5043\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8723 - accuracy: 0.5667 - val_loss: 1.0583 - val_accuracy: 0.5043\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8730 - accuracy: 0.5667 - val_loss: 1.0571 - val_accuracy: 0.5043\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 78us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0598 - val_accuracy: 0.5043\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8730 - accuracy: 0.5630 - val_loss: 1.0574 - val_accuracy: 0.5043\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8737 - accuracy: 0.5667 - val_loss: 1.0576 - val_accuracy: 0.5043\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8735 - accuracy: 0.5667 - val_loss: 1.0626 - val_accuracy: 0.5043\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8732 - accuracy: 0.5667 - val_loss: 1.0599 - val_accuracy: 0.5043\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8747 - accuracy: 0.5667 - val_loss: 1.0578 - val_accuracy: 0.5043\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8741 - accuracy: 0.5667 - val_loss: 1.0662 - val_accuracy: 0.5043\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8771 - accuracy: 0.5630 - val_loss: 1.0613 - val_accuracy: 0.5043\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8744 - accuracy: 0.5630 - val_loss: 1.0566 - val_accuracy: 0.5043\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8750 - accuracy: 0.5667 - val_loss: 1.0552 - val_accuracy: 0.5043\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0575 - val_accuracy: 0.5043\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8745 - accuracy: 0.5667 - val_loss: 1.0612 - val_accuracy: 0.5043\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8725 - accuracy: 0.5667 - val_loss: 1.0593 - val_accuracy: 0.5043\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8744 - accuracy: 0.5667 - val_loss: 1.0597 - val_accuracy: 0.5043\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8733 - accuracy: 0.5667 - val_loss: 1.0630 - val_accuracy: 0.5043\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8739 - accuracy: 0.5630 - val_loss: 1.0608 - val_accuracy: 0.5043\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8757 - accuracy: 0.5667 - val_loss: 1.0573 - val_accuracy: 0.5043\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8768 - accuracy: 0.5667 - val_loss: 1.0599 - val_accuracy: 0.5043\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8725 - accuracy: 0.5667 - val_loss: 1.0604 - val_accuracy: 0.5043\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8744 - accuracy: 0.5667 - val_loss: 1.0583 - val_accuracy: 0.5043\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8722 - accuracy: 0.5667 - val_loss: 1.0609 - val_accuracy: 0.5043\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8716 - accuracy: 0.5667 - val_loss: 1.0615 - val_accuracy: 0.5043\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8719 - accuracy: 0.5667 - val_loss: 1.0593 - val_accuracy: 0.5043\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8761 - accuracy: 0.5667 - val_loss: 1.0579 - val_accuracy: 0.5043\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0627 - val_accuracy: 0.5043\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8755 - accuracy: 0.5630 - val_loss: 1.0652 - val_accuracy: 0.5043\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8753 - accuracy: 0.5630 - val_loss: 1.0625 - val_accuracy: 0.5043\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8731 - accuracy: 0.5667 - val_loss: 1.0600 - val_accuracy: 0.5043\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8723 - accuracy: 0.5667 - val_loss: 1.0609 - val_accuracy: 0.5043\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0628 - val_accuracy: 0.5043\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8725 - accuracy: 0.5667 - val_loss: 1.0619 - val_accuracy: 0.5043\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8715 - accuracy: 0.5667 - val_loss: 1.0626 - val_accuracy: 0.5043\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8728 - accuracy: 0.5667 - val_loss: 1.0610 - val_accuracy: 0.5043\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8785 - accuracy: 0.5667 - val_loss: 1.0669 - val_accuracy: 0.5043\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0553 - val_accuracy: 0.5043\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8740 - accuracy: 0.5667 - val_loss: 1.0531 - val_accuracy: 0.5043\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8749 - accuracy: 0.5667 - val_loss: 1.0589 - val_accuracy: 0.5043\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8709 - accuracy: 0.5667 - val_loss: 1.0568 - val_accuracy: 0.5043\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0578 - val_accuracy: 0.5043\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0600 - val_accuracy: 0.5043\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8735 - accuracy: 0.5667 - val_loss: 1.0585 - val_accuracy: 0.5043\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8733 - accuracy: 0.5667 - val_loss: 1.0620 - val_accuracy: 0.5043\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8715 - accuracy: 0.5667 - val_loss: 1.0632 - val_accuracy: 0.5043\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8732 - accuracy: 0.5667 - val_loss: 1.0621 - val_accuracy: 0.5043\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8777 - accuracy: 0.5370 - val_loss: 1.0614 - val_accuracy: 0.5556\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8785 - accuracy: 0.5370 - val_loss: 1.0605 - val_accuracy: 0.5043\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8744 - accuracy: 0.5667 - val_loss: 1.0615 - val_accuracy: 0.5043\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8727 - accuracy: 0.5667 - val_loss: 1.0591 - val_accuracy: 0.5043\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8728 - accuracy: 0.5667 - val_loss: 1.0592 - val_accuracy: 0.5043\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8718 - accuracy: 0.5667 - val_loss: 1.0657 - val_accuracy: 0.5043\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8715 - accuracy: 0.5667 - val_loss: 1.0639 - val_accuracy: 0.5043\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8728 - accuracy: 0.5667 - val_loss: 1.0605 - val_accuracy: 0.5043\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0602 - val_accuracy: 0.5043\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8733 - accuracy: 0.5667 - val_loss: 1.0628 - val_accuracy: 0.5043\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8747 - accuracy: 0.5667 - val_loss: 1.0612 - val_accuracy: 0.5043\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8722 - accuracy: 0.5667 - val_loss: 1.0619 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0638 - val_accuracy: 0.5043\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0604 - val_accuracy: 0.5043\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8716 - accuracy: 0.5667 - val_loss: 1.0583 - val_accuracy: 0.5043\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8710 - accuracy: 0.5667 - val_loss: 1.0570 - val_accuracy: 0.5043\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8744 - accuracy: 0.5667 - val_loss: 1.0558 - val_accuracy: 0.5043\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8715 - accuracy: 0.5667 - val_loss: 1.0621 - val_accuracy: 0.5043\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8703 - accuracy: 0.5667 - val_loss: 1.0665 - val_accuracy: 0.5043\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8721 - accuracy: 0.5667 - val_loss: 1.0647 - val_accuracy: 0.5043\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0622 - val_accuracy: 0.5043\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8737 - accuracy: 0.5667 - val_loss: 1.0637 - val_accuracy: 0.5043\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.8721 - accuracy: 0.5667 - val_loss: 1.0640 - val_accuracy: 0.5043\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 442us/step - loss: 0.8708 - accuracy: 0.5667 - val_loss: 1.0601 - val_accuracy: 0.5043\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8725 - accuracy: 0.5667 - val_loss: 1.0655 - val_accuracy: 0.5043\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0613 - val_accuracy: 0.5043\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0613 - val_accuracy: 0.5043\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8781 - accuracy: 0.5667 - val_loss: 1.0649 - val_accuracy: 0.5043\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8691 - accuracy: 0.5667 - val_loss: 1.0655 - val_accuracy: 0.5043\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8748 - accuracy: 0.5407 - val_loss: 1.0632 - val_accuracy: 0.5043\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8724 - accuracy: 0.5667 - val_loss: 1.0624 - val_accuracy: 0.5043\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0643 - val_accuracy: 0.5043\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8748 - accuracy: 0.5667 - val_loss: 1.0686 - val_accuracy: 0.5043\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8703 - accuracy: 0.5667 - val_loss: 1.0630 - val_accuracy: 0.5043\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0644 - val_accuracy: 0.5043\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8705 - accuracy: 0.5667 - val_loss: 1.0624 - val_accuracy: 0.5043\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8725 - accuracy: 0.5667 - val_loss: 1.0647 - val_accuracy: 0.5043\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8704 - accuracy: 0.5667 - val_loss: 1.0665 - val_accuracy: 0.5043\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8707 - accuracy: 0.5667 - val_loss: 1.0652 - val_accuracy: 0.5043\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8795 - accuracy: 0.5074 - val_loss: 1.0618 - val_accuracy: 0.5043\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8737 - accuracy: 0.5667 - val_loss: 1.0683 - val_accuracy: 0.5043\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8743 - accuracy: 0.5630 - val_loss: 1.0703 - val_accuracy: 0.5043\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8687 - accuracy: 0.5667 - val_loss: 1.0604 - val_accuracy: 0.5043\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8740 - accuracy: 0.5481 - val_loss: 1.0600 - val_accuracy: 0.5556\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8717 - accuracy: 0.5889 - val_loss: 1.0657 - val_accuracy: 0.5043\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8717 - accuracy: 0.5667 - val_loss: 1.0657 - val_accuracy: 0.5043\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8695 - accuracy: 0.5667 - val_loss: 1.0590 - val_accuracy: 0.5043\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0590 - val_accuracy: 0.5043\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8716 - accuracy: 0.5667 - val_loss: 1.0623 - val_accuracy: 0.5043\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8707 - accuracy: 0.5667 - val_loss: 1.0649 - val_accuracy: 0.5043\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8748 - accuracy: 0.5667 - val_loss: 1.0646 - val_accuracy: 0.5043\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8701 - accuracy: 0.5667 - val_loss: 1.0661 - val_accuracy: 0.5043\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8739 - accuracy: 0.5667 - val_loss: 1.0618 - val_accuracy: 0.5043\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8734 - accuracy: 0.5296 - val_loss: 1.0667 - val_accuracy: 0.5043\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0714 - val_accuracy: 0.5043\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8710 - accuracy: 0.5667 - val_loss: 1.0682 - val_accuracy: 0.5043\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8727 - accuracy: 0.5667 - val_loss: 1.0646 - val_accuracy: 0.5043\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8751 - accuracy: 0.5667 - val_loss: 1.0654 - val_accuracy: 0.5043\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8695 - accuracy: 0.5667 - val_loss: 1.0607 - val_accuracy: 0.5043\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8729 - accuracy: 0.5519 - val_loss: 1.0607 - val_accuracy: 0.5043\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8712 - accuracy: 0.5704 - val_loss: 1.0603 - val_accuracy: 0.5043\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0715 - val_accuracy: 0.5043\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8744 - accuracy: 0.5630 - val_loss: 1.0698 - val_accuracy: 0.5043\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0671 - val_accuracy: 0.5043\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8706 - accuracy: 0.5667 - val_loss: 1.0642 - val_accuracy: 0.5043\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8704 - accuracy: 0.5667 - val_loss: 1.0637 - val_accuracy: 0.5043\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0630 - val_accuracy: 0.5043\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8691 - accuracy: 0.5704 - val_loss: 1.0647 - val_accuracy: 0.5043\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8759 - accuracy: 0.5667 - val_loss: 1.0685 - val_accuracy: 0.5043\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0682 - val_accuracy: 0.5043\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8709 - accuracy: 0.5704 - val_loss: 1.0690 - val_accuracy: 0.5043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a276f60>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 90us/step\n",
      "over-sampling test accuracy: 48.72%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 2, 2, 1, 0,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 1, 2,\n",
       "       2, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2,\n",
       "       0, 0, 1, 1, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 1, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 0, 0, 0,\n",
       "       1, 0, 2, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS236     1     2\n",
       "1      NRS113     2     2\n",
       "2    CFBRSa23     0     0\n",
       "3      NRS249     2     1\n",
       "4         107     1     0\n",
       "..        ...   ...   ...\n",
       "112     NY439     2     2\n",
       "113    NRS106     0     0\n",
       "114       221     0     0\n",
       "115    NRS386     2     2\n",
       "116  CFBRSa03     1     0\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.244626</td>\n",
       "      <td>0.742154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.280668</td>\n",
       "      <td>0.684549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.409025</td>\n",
       "      <td>0.340501</td>\n",
       "      <td>0.250474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198791</td>\n",
       "      <td>0.533104</td>\n",
       "      <td>0.268105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409025</td>\n",
       "      <td>0.340501</td>\n",
       "      <td>0.250474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.409025</td>\n",
       "      <td>0.340501</td>\n",
       "      <td>0.250474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.409025</td>\n",
       "      <td>0.340501</td>\n",
       "      <td>0.250474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.138160</td>\n",
       "      <td>0.309219</td>\n",
       "      <td>0.552621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.409025</td>\n",
       "      <td>0.340501</td>\n",
       "      <td>0.250474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.013220  0.244626  0.742154\n",
       "1    0.034782  0.280668  0.684549\n",
       "2    0.409025  0.340501  0.250474\n",
       "3    0.198791  0.533104  0.268105\n",
       "4    0.409025  0.340501  0.250474\n",
       "..        ...       ...       ...\n",
       "112  0.000021  0.000006  0.999972\n",
       "113  0.409025  0.340501  0.250474\n",
       "114  0.409025  0.340501  0.250474\n",
       "115  0.138160  0.309219  0.552621\n",
       "116  0.409025  0.340501  0.250474\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p006.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0262 - val_accuracy: 0.4872\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0278 - val_accuracy: 0.4872\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8710 - accuracy: 0.5667 - val_loss: 1.0307 - val_accuracy: 0.4872\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8737 - accuracy: 0.5667 - val_loss: 1.0280 - val_accuracy: 0.4872\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0285 - val_accuracy: 0.4872\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8812 - accuracy: 0.5667 - val_loss: 1.0328 - val_accuracy: 0.4872\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0285 - val_accuracy: 0.4872\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0299 - val_accuracy: 0.4872\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0291 - val_accuracy: 0.4872\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8733 - accuracy: 0.5667 - val_loss: 1.0269 - val_accuracy: 0.4872\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0304 - val_accuracy: 0.4872\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8719 - accuracy: 0.5667 - val_loss: 1.0311 - val_accuracy: 0.4872\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8723 - accuracy: 0.5667 - val_loss: 1.0289 - val_accuracy: 0.4872\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8730 - accuracy: 0.5667 - val_loss: 1.0268 - val_accuracy: 0.4872\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8726 - accuracy: 0.5704 - val_loss: 1.0311 - val_accuracy: 0.4872\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8739 - accuracy: 0.5704 - val_loss: 1.0289 - val_accuracy: 0.4872\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8715 - accuracy: 0.5704 - val_loss: 1.0288 - val_accuracy: 0.4872\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8744 - accuracy: 0.5704 - val_loss: 1.0290 - val_accuracy: 0.4872\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8723 - accuracy: 0.5667 - val_loss: 1.0293 - val_accuracy: 0.4872\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8689 - accuracy: 0.5667 - val_loss: 1.0308 - val_accuracy: 0.4872\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8784 - accuracy: 0.5704 - val_loss: 1.0287 - val_accuracy: 0.4872\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8773 - accuracy: 0.5667 - val_loss: 1.0351 - val_accuracy: 0.4872\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8818 - accuracy: 0.5704 - val_loss: 1.0322 - val_accuracy: 0.4872\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8719 - accuracy: 0.5704 - val_loss: 1.0276 - val_accuracy: 0.4872\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0307 - val_accuracy: 0.4872\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8721 - accuracy: 0.5667 - val_loss: 1.0315 - val_accuracy: 0.4872\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8734 - accuracy: 0.5667 - val_loss: 1.0335 - val_accuracy: 0.4872\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0346 - val_accuracy: 0.4872\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8755 - accuracy: 0.5667 - val_loss: 1.0331 - val_accuracy: 0.4872\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8758 - accuracy: 0.5667 - val_loss: 1.0322 - val_accuracy: 0.4872\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8755 - accuracy: 0.5667 - val_loss: 1.0365 - val_accuracy: 0.4872\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0322 - val_accuracy: 0.4872\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8722 - accuracy: 0.5667 - val_loss: 1.0288 - val_accuracy: 0.4872\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8717 - accuracy: 0.5667 - val_loss: 1.0295 - val_accuracy: 0.4872\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8736 - accuracy: 0.5704 - val_loss: 1.0363 - val_accuracy: 0.4872\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8730 - accuracy: 0.5704 - val_loss: 1.0304 - val_accuracy: 0.4872\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8709 - accuracy: 0.5667 - val_loss: 1.0285 - val_accuracy: 0.4872\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8711 - accuracy: 0.5667 - val_loss: 1.0301 - val_accuracy: 0.4872\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0275 - val_accuracy: 0.4872\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0318 - val_accuracy: 0.4872\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0319 - val_accuracy: 0.4872\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8720 - accuracy: 0.5667 - val_loss: 1.0303 - val_accuracy: 0.4872\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8731 - accuracy: 0.5667 - val_loss: 1.0373 - val_accuracy: 0.4872\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0335 - val_accuracy: 0.4872\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0308 - val_accuracy: 0.4872\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0362 - val_accuracy: 0.4872\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8721 - accuracy: 0.5667 - val_loss: 1.0390 - val_accuracy: 0.4872\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.8744 - accuracy: 0.5667 - val_loss: 1.0347 - val_accuracy: 0.4872\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 373us/step - loss: 0.8764 - accuracy: 0.5667 - val_loss: 1.0352 - val_accuracy: 0.4872\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 389us/step - loss: 0.8735 - accuracy: 0.5667 - val_loss: 1.0322 - val_accuracy: 0.4872\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8710 - accuracy: 0.5704 - val_loss: 1.0331 - val_accuracy: 0.4872\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 423us/step - loss: 0.8702 - accuracy: 0.5704 - val_loss: 1.0310 - val_accuracy: 0.4872\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8717 - accuracy: 0.5667 - val_loss: 1.0316 - val_accuracy: 0.4872\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0350 - val_accuracy: 0.4872\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8749 - accuracy: 0.5704 - val_loss: 1.0386 - val_accuracy: 0.4872\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.8741 - accuracy: 0.5704 - val_loss: 1.0352 - val_accuracy: 0.4872\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8721 - accuracy: 0.5704 - val_loss: 1.0307 - val_accuracy: 0.4872\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 779us/step - loss: 0.8719 - accuracy: 0.5667 - val_loss: 1.0287 - val_accuracy: 0.4872\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.8706 - accuracy: 0.5667 - val_loss: 1.0321 - val_accuracy: 0.4872\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8735 - accuracy: 0.5704 - val_loss: 1.0328 - val_accuracy: 0.4872\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8700 - accuracy: 0.5704 - val_loss: 1.0313 - val_accuracy: 0.4872\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8718 - accuracy: 0.5667 - val_loss: 1.0292 - val_accuracy: 0.4872\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8718 - accuracy: 0.5704 - val_loss: 1.0317 - val_accuracy: 0.4872\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8708 - accuracy: 0.5704 - val_loss: 1.0335 - val_accuracy: 0.4872\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0353 - val_accuracy: 0.4872\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0321 - val_accuracy: 0.4872\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8706 - accuracy: 0.5704 - val_loss: 1.0316 - val_accuracy: 0.4872\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0332 - val_accuracy: 0.4872\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8760 - accuracy: 0.5667 - val_loss: 1.0342 - val_accuracy: 0.4872\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.8770 - accuracy: 0.5667 - val_loss: 1.0352 - val_accuracy: 0.4872\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8695 - accuracy: 0.5667 - val_loss: 1.0314 - val_accuracy: 0.4872\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8729 - accuracy: 0.5667 - val_loss: 1.0326 - val_accuracy: 0.4872\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8690 - accuracy: 0.5667 - val_loss: 1.0428 - val_accuracy: 0.4872\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8739 - accuracy: 0.5667 - val_loss: 1.0386 - val_accuracy: 0.4872\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8713 - accuracy: 0.5667 - val_loss: 1.0396 - val_accuracy: 0.4872\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8708 - accuracy: 0.5667 - val_loss: 1.0365 - val_accuracy: 0.4872\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0341 - val_accuracy: 0.4872\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 340us/step - loss: 0.8724 - accuracy: 0.5704 - val_loss: 1.0339 - val_accuracy: 0.4872\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8681 - accuracy: 0.5667 - val_loss: 1.0329 - val_accuracy: 0.4872\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8731 - accuracy: 0.5630 - val_loss: 1.0321 - val_accuracy: 0.4872\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8748 - accuracy: 0.5704 - val_loss: 1.0332 - val_accuracy: 0.4872\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8716 - accuracy: 0.5704 - val_loss: 1.0393 - val_accuracy: 0.4872\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8743 - accuracy: 0.5704 - val_loss: 1.0394 - val_accuracy: 0.4872\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8690 - accuracy: 0.5704 - val_loss: 1.0378 - val_accuracy: 0.4872\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8728 - accuracy: 0.5704 - val_loss: 1.0362 - val_accuracy: 0.4872\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8691 - accuracy: 0.5704 - val_loss: 1.0395 - val_accuracy: 0.4872\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8703 - accuracy: 0.5704 - val_loss: 1.0361 - val_accuracy: 0.4872\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8701 - accuracy: 0.5704 - val_loss: 1.0338 - val_accuracy: 0.4872\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8697 - accuracy: 0.5704 - val_loss: 1.0315 - val_accuracy: 0.4872\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8700 - accuracy: 0.5704 - val_loss: 1.0346 - val_accuracy: 0.4872\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0354 - val_accuracy: 0.4872\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0362 - val_accuracy: 0.4872\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0358 - val_accuracy: 0.4872\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8771 - accuracy: 0.5704 - val_loss: 1.0319 - val_accuracy: 0.4872\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8725 - accuracy: 0.5704 - val_loss: 1.0403 - val_accuracy: 0.4872\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.8749 - accuracy: 0.5704 - val_loss: 1.0410 - val_accuracy: 0.4872\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8722 - accuracy: 0.5704 - val_loss: 1.0347 - val_accuracy: 0.4872\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8707 - accuracy: 0.5481 - val_loss: 1.0331 - val_accuracy: 0.5385\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8738 - accuracy: 0.5519 - val_loss: 1.0377 - val_accuracy: 0.4872\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8718 - accuracy: 0.5667 - val_loss: 1.0385 - val_accuracy: 0.4872\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8732 - accuracy: 0.5704 - val_loss: 1.0405 - val_accuracy: 0.4872\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8741 - accuracy: 0.5704 - val_loss: 1.0376 - val_accuracy: 0.4872\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.8710 - accuracy: 0.5667 - val_loss: 1.0325 - val_accuracy: 0.4872\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8743 - accuracy: 0.5630 - val_loss: 1.0306 - val_accuracy: 0.4786\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8718 - accuracy: 0.5667 - val_loss: 1.0347 - val_accuracy: 0.4872\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 265us/step - loss: 0.8726 - accuracy: 0.5704 - val_loss: 1.0376 - val_accuracy: 0.4872\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0321 - val_accuracy: 0.4872\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0306 - val_accuracy: 0.4872\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 417us/step - loss: 0.8732 - accuracy: 0.5704 - val_loss: 1.0331 - val_accuracy: 0.4872\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8709 - accuracy: 0.5704 - val_loss: 1.0343 - val_accuracy: 0.4872\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8697 - accuracy: 0.5704 - val_loss: 1.0391 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0377 - val_accuracy: 0.4872\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8687 - accuracy: 0.5667 - val_loss: 1.0367 - val_accuracy: 0.4872\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 332us/step - loss: 0.8715 - accuracy: 0.5667 - val_loss: 1.0371 - val_accuracy: 0.4872\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8701 - accuracy: 0.5704 - val_loss: 1.0384 - val_accuracy: 0.4872\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0368 - val_accuracy: 0.4872\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.8727 - accuracy: 0.5704 - val_loss: 1.0320 - val_accuracy: 0.4872\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8703 - accuracy: 0.5704 - val_loss: 1.0331 - val_accuracy: 0.4872\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8751 - accuracy: 0.5704 - val_loss: 1.0373 - val_accuracy: 0.4872\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8675 - accuracy: 0.5704 - val_loss: 1.0355 - val_accuracy: 0.5385\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8755 - accuracy: 0.5259 - val_loss: 1.0374 - val_accuracy: 0.4872\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 346us/step - loss: 0.8833 - accuracy: 0.5704 - val_loss: 1.0427 - val_accuracy: 0.4872\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0461 - val_accuracy: 0.4872\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 460us/step - loss: 0.8752 - accuracy: 0.5667 - val_loss: 1.0385 - val_accuracy: 0.4872\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8763 - accuracy: 0.5704 - val_loss: 1.0362 - val_accuracy: 0.4872\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8708 - accuracy: 0.5704 - val_loss: 1.0378 - val_accuracy: 0.4872\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0392 - val_accuracy: 0.4872\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0373 - val_accuracy: 0.4872\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 354us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0345 - val_accuracy: 0.4872\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.8708 - accuracy: 0.5704 - val_loss: 1.0363 - val_accuracy: 0.4872\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8710 - accuracy: 0.5704 - val_loss: 1.0375 - val_accuracy: 0.4872\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0363 - val_accuracy: 0.4872\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0364 - val_accuracy: 0.4872\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8720 - accuracy: 0.5704 - val_loss: 1.0374 - val_accuracy: 0.4872\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0391 - val_accuracy: 0.4872\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8704 - accuracy: 0.5704 - val_loss: 1.0447 - val_accuracy: 0.4872\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8713 - accuracy: 0.5704 - val_loss: 1.0374 - val_accuracy: 0.4872\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0398 - val_accuracy: 0.4872\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8721 - accuracy: 0.5704 - val_loss: 1.0412 - val_accuracy: 0.4872\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0399 - val_accuracy: 0.4872\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8712 - accuracy: 0.5704 - val_loss: 1.0384 - val_accuracy: 0.4872\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8716 - accuracy: 0.5704 - val_loss: 1.0356 - val_accuracy: 0.4872\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8710 - accuracy: 0.5704 - val_loss: 1.0387 - val_accuracy: 0.4872\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8687 - accuracy: 0.5704 - val_loss: 1.0377 - val_accuracy: 0.4872\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8715 - accuracy: 0.5704 - val_loss: 1.0396 - val_accuracy: 0.4872\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8702 - accuracy: 0.5704 - val_loss: 1.0439 - val_accuracy: 0.4872\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0363 - val_accuracy: 0.4872\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0386 - val_accuracy: 0.4872\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0409 - val_accuracy: 0.4872\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0383 - val_accuracy: 0.4872\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 298us/step - loss: 0.8706 - accuracy: 0.5704 - val_loss: 1.0365 - val_accuracy: 0.4872\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 355us/step - loss: 0.8716 - accuracy: 0.5481 - val_loss: 1.0381 - val_accuracy: 0.4872\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8806 - accuracy: 0.5704 - val_loss: 1.0416 - val_accuracy: 0.4872\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0460 - val_accuracy: 0.4872\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0379 - val_accuracy: 0.4872\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8681 - accuracy: 0.5704 - val_loss: 1.0403 - val_accuracy: 0.4872\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8705 - accuracy: 0.5704 - val_loss: 1.0402 - val_accuracy: 0.4872\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8680 - accuracy: 0.5704 - val_loss: 1.0421 - val_accuracy: 0.4872\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0432 - val_accuracy: 0.4872\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0377 - val_accuracy: 0.4872\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0379 - val_accuracy: 0.4872\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8794 - accuracy: 0.5704 - val_loss: 1.0474 - val_accuracy: 0.4872\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 278us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0371 - val_accuracy: 0.4872\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8697 - accuracy: 0.5704 - val_loss: 1.0369 - val_accuracy: 0.4872\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0380 - val_accuracy: 0.4872\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8691 - accuracy: 0.5704 - val_loss: 1.0422 - val_accuracy: 0.4872\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8720 - accuracy: 0.5704 - val_loss: 1.0430 - val_accuracy: 0.4872\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0392 - val_accuracy: 0.4872\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8727 - accuracy: 0.5704 - val_loss: 1.0394 - val_accuracy: 0.4872\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0339 - val_accuracy: 0.4872\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8693 - accuracy: 0.5704 - val_loss: 1.0364 - val_accuracy: 0.4872\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.8690 - accuracy: 0.5704 - val_loss: 1.0391 - val_accuracy: 0.4872\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8716 - accuracy: 0.5704 - val_loss: 1.0429 - val_accuracy: 0.4872\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8756 - accuracy: 0.5704 - val_loss: 1.0414 - val_accuracy: 0.4872\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8690 - accuracy: 0.5704 - val_loss: 1.0372 - val_accuracy: 0.4872\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0407 - val_accuracy: 0.4872\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8779 - accuracy: 0.5704 - val_loss: 1.0466 - val_accuracy: 0.4872\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8716 - accuracy: 0.5704 - val_loss: 1.0404 - val_accuracy: 0.4872\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0407 - val_accuracy: 0.4872\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8693 - accuracy: 0.5704 - val_loss: 1.0367 - val_accuracy: 0.4872\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8697 - accuracy: 0.5704 - val_loss: 1.0394 - val_accuracy: 0.4872\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8666 - accuracy: 0.5704 - val_loss: 1.0409 - val_accuracy: 0.4872\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0372 - val_accuracy: 0.4872\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.8674 - accuracy: 0.5704 - val_loss: 1.0372 - val_accuracy: 0.4872\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8722 - accuracy: 0.5704 - val_loss: 1.0408 - val_accuracy: 0.4872\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8672 - accuracy: 0.5704 - val_loss: 1.0437 - val_accuracy: 0.4872\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8709 - accuracy: 0.5704 - val_loss: 1.0419 - val_accuracy: 0.4872\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0454 - val_accuracy: 0.4872\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0410 - val_accuracy: 0.4872\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8703 - accuracy: 0.5704 - val_loss: 1.0437 - val_accuracy: 0.4872\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8685 - accuracy: 0.5704 - val_loss: 1.0475 - val_accuracy: 0.4872\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0439 - val_accuracy: 0.4872\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0437 - val_accuracy: 0.4872\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8711 - accuracy: 0.5704 - val_loss: 1.0390 - val_accuracy: 0.4872\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0415 - val_accuracy: 0.4872\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0397 - val_accuracy: 0.4872\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0406 - val_accuracy: 0.4872\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8687 - accuracy: 0.5704 - val_loss: 1.0407 - val_accuracy: 0.4872\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8685 - accuracy: 0.5704 - val_loss: 1.0405 - val_accuracy: 0.4872\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8736 - accuracy: 0.5704 - val_loss: 1.0410 - val_accuracy: 0.4872\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8681 - accuracy: 0.5704 - val_loss: 1.0435 - val_accuracy: 0.4872\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8727 - accuracy: 0.5185 - val_loss: 1.0433 - val_accuracy: 0.4872\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8724 - accuracy: 0.5704 - val_loss: 1.0470 - val_accuracy: 0.4872\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8675 - accuracy: 0.5704 - val_loss: 1.0408 - val_accuracy: 0.4872\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8694 - accuracy: 0.5704 - val_loss: 1.0392 - val_accuracy: 0.4872\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8723 - accuracy: 0.5704 - val_loss: 1.0433 - val_accuracy: 0.4872\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8713 - accuracy: 0.5704 - val_loss: 1.0461 - val_accuracy: 0.4872\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8699 - accuracy: 0.5667 - val_loss: 1.0395 - val_accuracy: 0.4872\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0384 - val_accuracy: 0.4872\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8694 - accuracy: 0.5704 - val_loss: 1.0375 - val_accuracy: 0.4872\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8706 - accuracy: 0.5407 - val_loss: 1.0405 - val_accuracy: 0.4872\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8730 - accuracy: 0.5704 - val_loss: 1.0483 - val_accuracy: 0.4872\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0418 - val_accuracy: 0.4872\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8675 - accuracy: 0.5704 - val_loss: 1.0399 - val_accuracy: 0.4872\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8702 - accuracy: 0.5704 - val_loss: 1.0425 - val_accuracy: 0.4872\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0385 - val_accuracy: 0.4872\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0404 - val_accuracy: 0.4872\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0418 - val_accuracy: 0.4872\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 85us/step - loss: 0.8684 - accuracy: 0.5704 - val_loss: 1.0466 - val_accuracy: 0.4872\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8720 - accuracy: 0.5704 - val_loss: 1.0438 - val_accuracy: 0.4872\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8705 - accuracy: 0.5704 - val_loss: 1.0469 - val_accuracy: 0.4872\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8685 - accuracy: 0.5704 - val_loss: 1.0423 - val_accuracy: 0.4872\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0467 - val_accuracy: 0.4872\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0413 - val_accuracy: 0.4872\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8684 - accuracy: 0.5704 - val_loss: 1.0461 - val_accuracy: 0.4872\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8710 - accuracy: 0.5704 - val_loss: 1.0399 - val_accuracy: 0.4872\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0409 - val_accuracy: 0.4872\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0385 - val_accuracy: 0.4872\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8710 - accuracy: 0.5704 - val_loss: 1.0379 - val_accuracy: 0.4872\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8743 - accuracy: 0.5259 - val_loss: 1.0473 - val_accuracy: 0.4872\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0433 - val_accuracy: 0.4872\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8767 - accuracy: 0.5704 - val_loss: 1.0449 - val_accuracy: 0.4872\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0471 - val_accuracy: 0.4872\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0463 - val_accuracy: 0.4872\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.8674 - accuracy: 0.5704 - val_loss: 1.0488 - val_accuracy: 0.4872\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8693 - accuracy: 0.5704 - val_loss: 1.0457 - val_accuracy: 0.4872\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0448 - val_accuracy: 0.4872\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8773 - accuracy: 0.5704 - val_loss: 1.0479 - val_accuracy: 0.4872\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8718 - accuracy: 0.5704 - val_loss: 1.0457 - val_accuracy: 0.4872\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 275us/step - loss: 0.8675 - accuracy: 0.5704 - val_loss: 1.0463 - val_accuracy: 0.4872\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8694 - accuracy: 0.5704 - val_loss: 1.0416 - val_accuracy: 0.4872\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0419 - val_accuracy: 0.4872\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.8729 - accuracy: 0.5148 - val_loss: 1.0414 - val_accuracy: 0.4872\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0454 - val_accuracy: 0.4872\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0429 - val_accuracy: 0.4872\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0456 - val_accuracy: 0.4872\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.8667 - accuracy: 0.5704 - val_loss: 1.0503 - val_accuracy: 0.4872\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0432 - val_accuracy: 0.4872\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0475 - val_accuracy: 0.4872\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0481 - val_accuracy: 0.4872\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.8705 - accuracy: 0.5333 - val_loss: 1.0465 - val_accuracy: 0.5385\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8729 - accuracy: 0.5593 - val_loss: 1.0498 - val_accuracy: 0.4872\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8699 - accuracy: 0.5704 - val_loss: 1.0483 - val_accuracy: 0.4872\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8680 - accuracy: 0.5704 - val_loss: 1.0437 - val_accuracy: 0.4872\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0478 - val_accuracy: 0.4872\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8694 - accuracy: 0.5704 - val_loss: 1.0524 - val_accuracy: 0.4872\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0481 - val_accuracy: 0.4872\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0452 - val_accuracy: 0.4872\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0453 - val_accuracy: 0.4872\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8689 - accuracy: 0.5704 - val_loss: 1.0495 - val_accuracy: 0.4872\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8693 - accuracy: 0.5704 - val_loss: 1.0511 - val_accuracy: 0.4872\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0480 - val_accuracy: 0.4872\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0476 - val_accuracy: 0.4872\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8672 - accuracy: 0.5704 - val_loss: 1.0449 - val_accuracy: 0.4872\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8717 - accuracy: 0.5704 - val_loss: 1.0492 - val_accuracy: 0.4872\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0455 - val_accuracy: 0.4872\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0451 - val_accuracy: 0.4872\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0479 - val_accuracy: 0.4872\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0455 - val_accuracy: 0.4872\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0458 - val_accuracy: 0.4872\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8673 - accuracy: 0.5704 - val_loss: 1.0472 - val_accuracy: 0.4872\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0472 - val_accuracy: 0.4872\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0450 - val_accuracy: 0.4872\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0465 - val_accuracy: 0.4872\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0482 - val_accuracy: 0.4872\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8701 - accuracy: 0.5704 - val_loss: 1.0463 - val_accuracy: 0.4872\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0488 - val_accuracy: 0.4872\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0535 - val_accuracy: 0.4872\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.8691 - accuracy: 0.5704 - val_loss: 1.0485 - val_accuracy: 0.4872\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.8685 - accuracy: 0.5704 - val_loss: 1.0474 - val_accuracy: 0.4872\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0451 - val_accuracy: 0.4872\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.8657 - accuracy: 0.5704 - val_loss: 1.0436 - val_accuracy: 0.4872\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8696 - accuracy: 0.5704 - val_loss: 1.0472 - val_accuracy: 0.4872\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8674 - accuracy: 0.5741 - val_loss: 1.0451 - val_accuracy: 0.5385\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8698 - accuracy: 0.5296 - val_loss: 1.0458 - val_accuracy: 0.4872\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0464 - val_accuracy: 0.4872\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0481 - val_accuracy: 0.4872\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8684 - accuracy: 0.5704 - val_loss: 1.0532 - val_accuracy: 0.4872\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8722 - accuracy: 0.5704 - val_loss: 1.0528 - val_accuracy: 0.4872\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0534 - val_accuracy: 0.4872\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8674 - accuracy: 0.5704 - val_loss: 1.0479 - val_accuracy: 0.4872\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8709 - accuracy: 0.5704 - val_loss: 1.0496 - val_accuracy: 0.4872\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0446 - val_accuracy: 0.4872\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8717 - accuracy: 0.5704 - val_loss: 1.0490 - val_accuracy: 0.4872\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8713 - accuracy: 0.5704 - val_loss: 1.0514 - val_accuracy: 0.4872\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8706 - accuracy: 0.5704 - val_loss: 1.0540 - val_accuracy: 0.4872\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8679 - accuracy: 0.5704 - val_loss: 1.0467 - val_accuracy: 0.4872\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8690 - accuracy: 0.5704 - val_loss: 1.0473 - val_accuracy: 0.4872\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0493 - val_accuracy: 0.4872\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8681 - accuracy: 0.5704 - val_loss: 1.0524 - val_accuracy: 0.4872\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8673 - accuracy: 0.5704 - val_loss: 1.0466 - val_accuracy: 0.4872\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0441 - val_accuracy: 0.4872\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0478 - val_accuracy: 0.4872\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0535 - val_accuracy: 0.4872\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8690 - accuracy: 0.5704 - val_loss: 1.0507 - val_accuracy: 0.4872\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0496 - val_accuracy: 0.4872\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8693 - accuracy: 0.5704 - val_loss: 1.0513 - val_accuracy: 0.4872\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0482 - val_accuracy: 0.4872\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0483 - val_accuracy: 0.4872\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0477 - val_accuracy: 0.4872\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0507 - val_accuracy: 0.4872\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0498 - val_accuracy: 0.4872\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.8658 - accuracy: 0.5667 - val_loss: 1.0463 - val_accuracy: 0.4786\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.8681 - accuracy: 0.5704 - val_loss: 1.0473 - val_accuracy: 0.4786\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.8667 - accuracy: 0.5704 - val_loss: 1.0489 - val_accuracy: 0.4872\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 331us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0483 - val_accuracy: 0.4872\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0482 - val_accuracy: 0.4872\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8694 - accuracy: 0.5704 - val_loss: 1.0482 - val_accuracy: 0.4872\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0508 - val_accuracy: 0.4872\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0539 - val_accuracy: 0.4872\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8676 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4872\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8673 - accuracy: 0.5704 - val_loss: 1.0455 - val_accuracy: 0.4872\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8699 - accuracy: 0.5667 - val_loss: 1.0505 - val_accuracy: 0.4872\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8667 - accuracy: 0.5704 - val_loss: 1.0500 - val_accuracy: 0.4872\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0485 - val_accuracy: 0.4872\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0454 - val_accuracy: 0.4872\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8754 - accuracy: 0.5704 - val_loss: 1.0532 - val_accuracy: 0.4872\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 148us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0467 - val_accuracy: 0.4872\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8676 - accuracy: 0.5667 - val_loss: 1.0453 - val_accuracy: 0.4786\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8677 - accuracy: 0.5667 - val_loss: 1.0508 - val_accuracy: 0.4872\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8676 - accuracy: 0.5704 - val_loss: 1.0533 - val_accuracy: 0.4872\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0525 - val_accuracy: 0.4872\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8661 - accuracy: 0.5704 - val_loss: 1.0515 - val_accuracy: 0.4872\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4872\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0509 - val_accuracy: 0.4872\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8656 - accuracy: 0.5704 - val_loss: 1.0519 - val_accuracy: 0.4872\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0538 - val_accuracy: 0.4872\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0577 - val_accuracy: 0.4872\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0502 - val_accuracy: 0.4872\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 381us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4872\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.8672 - accuracy: 0.5704 - val_loss: 1.0517 - val_accuracy: 0.4872\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.8712 - accuracy: 0.5704 - val_loss: 1.0556 - val_accuracy: 0.4872\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0566 - val_accuracy: 0.4872\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0525 - val_accuracy: 0.4872\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8687 - accuracy: 0.5704 - val_loss: 1.0531 - val_accuracy: 0.4872\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8716 - accuracy: 0.5667 - val_loss: 1.0506 - val_accuracy: 0.4786\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0525 - val_accuracy: 0.4872\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8701 - accuracy: 0.5704 - val_loss: 1.0575 - val_accuracy: 0.4872\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0531 - val_accuracy: 0.4872\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0513 - val_accuracy: 0.4872\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0513 - val_accuracy: 0.4872\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8673 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8682 - accuracy: 0.5704 - val_loss: 1.0557 - val_accuracy: 0.4872\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0547 - val_accuracy: 0.4872\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0486 - val_accuracy: 0.4872\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8639 - accuracy: 0.5704 - val_loss: 1.0509 - val_accuracy: 0.4872\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 308us/step - loss: 0.8745 - accuracy: 0.5704 - val_loss: 1.0535 - val_accuracy: 0.4872\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0533 - val_accuracy: 0.4872\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8692 - accuracy: 0.5704 - val_loss: 1.0501 - val_accuracy: 0.4872\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8648 - accuracy: 0.5704 - val_loss: 1.0533 - val_accuracy: 0.4872\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0530 - val_accuracy: 0.4872\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 386us/step - loss: 0.8715 - accuracy: 0.5704 - val_loss: 1.0538 - val_accuracy: 0.4872\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0565 - val_accuracy: 0.4872\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8657 - accuracy: 0.5704 - val_loss: 1.0551 - val_accuracy: 0.4872\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0547 - val_accuracy: 0.4872\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0500 - val_accuracy: 0.4872\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8684 - accuracy: 0.5704 - val_loss: 1.0498 - val_accuracy: 0.4872\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0532 - val_accuracy: 0.4872\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0540 - val_accuracy: 0.4872\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0528 - val_accuracy: 0.4872\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0512 - val_accuracy: 0.4872\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0521 - val_accuracy: 0.4872\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0545 - val_accuracy: 0.4872\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0544 - val_accuracy: 0.4872\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0519 - val_accuracy: 0.4872\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8656 - accuracy: 0.5704 - val_loss: 1.0541 - val_accuracy: 0.4872\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0517 - val_accuracy: 0.4872\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0543 - val_accuracy: 0.4872\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8695 - accuracy: 0.5704 - val_loss: 1.0550 - val_accuracy: 0.4872\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8684 - accuracy: 0.5704 - val_loss: 1.0571 - val_accuracy: 0.4872\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0510 - val_accuracy: 0.4872\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0490 - val_accuracy: 0.4872\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0503 - val_accuracy: 0.4872\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0491 - val_accuracy: 0.4872\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0521 - val_accuracy: 0.4872\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8657 - accuracy: 0.5704 - val_loss: 1.0498 - val_accuracy: 0.4872\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0544 - val_accuracy: 0.4872\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0504 - val_accuracy: 0.4872\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0499 - val_accuracy: 0.4872\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0574 - val_accuracy: 0.4872\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8648 - accuracy: 0.5704 - val_loss: 1.0552 - val_accuracy: 0.4872\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0505 - val_accuracy: 0.4872\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0490 - val_accuracy: 0.4872\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0509 - val_accuracy: 0.4872\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0534 - val_accuracy: 0.4872\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0536 - val_accuracy: 0.4872\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8659 - accuracy: 0.5667 - val_loss: 1.0544 - val_accuracy: 0.4786\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0601 - val_accuracy: 0.4872\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0532 - val_accuracy: 0.4872\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0486 - val_accuracy: 0.4872\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0474 - val_accuracy: 0.4872\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0490 - val_accuracy: 0.4872\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0501 - val_accuracy: 0.4872\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0554 - val_accuracy: 0.4872\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0549 - val_accuracy: 0.4872\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8728 - accuracy: 0.5704 - val_loss: 1.0472 - val_accuracy: 0.4872\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0500 - val_accuracy: 0.4872\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0555 - val_accuracy: 0.4872\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0549 - val_accuracy: 0.4872\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0504 - val_accuracy: 0.4872\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0517 - val_accuracy: 0.4872\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0554 - val_accuracy: 0.4872\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8655 - accuracy: 0.5704 - val_loss: 1.0504 - val_accuracy: 0.4872\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0499 - val_accuracy: 0.4872\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.8651 - accuracy: 0.5704 - val_loss: 1.0520 - val_accuracy: 0.4872\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0567 - val_accuracy: 0.4872\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8672 - accuracy: 0.5704 - val_loss: 1.0554 - val_accuracy: 0.4872\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0541 - val_accuracy: 0.4872\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0592 - val_accuracy: 0.4872\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0534 - val_accuracy: 0.4872\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0520 - val_accuracy: 0.4872\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0516 - val_accuracy: 0.4872\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8648 - accuracy: 0.5667 - val_loss: 1.0541 - val_accuracy: 0.4872\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0536 - val_accuracy: 0.4872\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8685 - accuracy: 0.5704 - val_loss: 1.0596 - val_accuracy: 0.4872\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8639 - accuracy: 0.5704 - val_loss: 1.0560 - val_accuracy: 0.4872\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0559 - val_accuracy: 0.4872\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8678 - accuracy: 0.5704 - val_loss: 1.0620 - val_accuracy: 0.4872\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0578 - val_accuracy: 0.4872\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8639 - accuracy: 0.5704 - val_loss: 1.0559 - val_accuracy: 0.4872\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0525 - val_accuracy: 0.4872\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0508 - val_accuracy: 0.4872\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8658 - accuracy: 0.5704 - val_loss: 1.0492 - val_accuracy: 0.4872\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8651 - accuracy: 0.5704 - val_loss: 1.0502 - val_accuracy: 0.4872\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 111us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0518 - val_accuracy: 0.4872\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0526 - val_accuracy: 0.4872\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0591 - val_accuracy: 0.4872\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.8645 - accuracy: 0.5704 - val_loss: 1.0575 - val_accuracy: 0.4872\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0573 - val_accuracy: 0.4872\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0587 - val_accuracy: 0.4872\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0541 - val_accuracy: 0.4872\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 387us/step - loss: 0.8661 - accuracy: 0.5704 - val_loss: 1.0537 - val_accuracy: 0.4872\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.8651 - accuracy: 0.5704 - val_loss: 1.0532 - val_accuracy: 0.4872\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0537 - val_accuracy: 0.4872\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0553 - val_accuracy: 0.4872\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0608 - val_accuracy: 0.4872\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 358us/step - loss: 0.8741 - accuracy: 0.5704 - val_loss: 1.0609 - val_accuracy: 0.4872\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 382us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0566 - val_accuracy: 0.4872\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8648 - accuracy: 0.5704 - val_loss: 1.0553 - val_accuracy: 0.4872\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8645 - accuracy: 0.5704 - val_loss: 1.0543 - val_accuracy: 0.4872\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0597 - val_accuracy: 0.4872\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0521 - val_accuracy: 0.4872\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0524 - val_accuracy: 0.4872\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 360us/step - loss: 0.8656 - accuracy: 0.5704 - val_loss: 1.0527 - val_accuracy: 0.4872\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0543 - val_accuracy: 0.4872\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0562 - val_accuracy: 0.4872\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8691 - accuracy: 0.5704 - val_loss: 1.0569 - val_accuracy: 0.4872\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0560 - val_accuracy: 0.4872\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8658 - accuracy: 0.5704 - val_loss: 1.0599 - val_accuracy: 0.4872\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0574 - val_accuracy: 0.4872\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0602 - val_accuracy: 0.4872\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8705 - accuracy: 0.5704 - val_loss: 1.0594 - val_accuracy: 0.4872\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0599 - val_accuracy: 0.4872\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8656 - accuracy: 0.5704 - val_loss: 1.0630 - val_accuracy: 0.4872\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8707 - accuracy: 0.5704 - val_loss: 1.0587 - val_accuracy: 0.4872\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 1.0526 - val_accuracy: 0.4786\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8670 - accuracy: 0.5333 - val_loss: 1.0546 - val_accuracy: 0.4872\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8730 - accuracy: 0.5704 - val_loss: 1.0641 - val_accuracy: 0.4872\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8648 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.4872\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0596 - val_accuracy: 0.4872\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0615 - val_accuracy: 0.4872\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.8653 - accuracy: 0.5667 - val_loss: 1.0594 - val_accuracy: 0.4786\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8644 - accuracy: 0.5667 - val_loss: 1.0566 - val_accuracy: 0.4872\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8671 - accuracy: 0.5704 - val_loss: 1.0594 - val_accuracy: 0.4872\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.8661 - accuracy: 0.5704 - val_loss: 1.0608 - val_accuracy: 0.4872\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0582 - val_accuracy: 0.4872\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8664 - accuracy: 0.5704 - val_loss: 1.0610 - val_accuracy: 0.4872\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0574 - val_accuracy: 0.4872\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8681 - accuracy: 0.5704 - val_loss: 1.0594 - val_accuracy: 0.4872\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 1.0575 - val_accuracy: 0.4872\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8739 - accuracy: 0.4963 - val_loss: 1.0573 - val_accuracy: 0.5385\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8714 - accuracy: 0.5667 - val_loss: 1.0658 - val_accuracy: 0.4872\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8628 - accuracy: 0.5704 - val_loss: 1.0597 - val_accuracy: 0.4872\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0611 - val_accuracy: 0.4872\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8651 - accuracy: 0.5704 - val_loss: 1.0638 - val_accuracy: 0.4872\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4872\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0586 - val_accuracy: 0.4872\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0576 - val_accuracy: 0.4872\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0550 - val_accuracy: 0.4872\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8663 - accuracy: 0.5704 - val_loss: 1.0591 - val_accuracy: 0.4872\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0589 - val_accuracy: 0.4872\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0574 - val_accuracy: 0.4872\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0611 - val_accuracy: 0.4872\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0658 - val_accuracy: 0.4872\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8648 - accuracy: 0.5704 - val_loss: 1.0613 - val_accuracy: 0.4872\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8635 - accuracy: 0.5667 - val_loss: 1.0597 - val_accuracy: 0.4786\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8648 - accuracy: 0.5667 - val_loss: 1.0596 - val_accuracy: 0.4872\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0548 - val_accuracy: 0.4786\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0539 - val_accuracy: 0.4786\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8646 - accuracy: 0.5667 - val_loss: 1.0581 - val_accuracy: 0.4872\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0649 - val_accuracy: 0.4872\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0642 - val_accuracy: 0.4872\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0589 - val_accuracy: 0.4872\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.4872\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.8669 - accuracy: 0.5704 - val_loss: 1.0592 - val_accuracy: 0.4872\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0611 - val_accuracy: 0.4872\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0578 - val_accuracy: 0.4786\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0624 - val_accuracy: 0.4872\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8631 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0654 - val_accuracy: 0.4872\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0615 - val_accuracy: 0.4872\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0620 - val_accuracy: 0.4872\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0695 - val_accuracy: 0.4872\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0627 - val_accuracy: 0.4872\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0580 - val_accuracy: 0.4872\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0606 - val_accuracy: 0.4872\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0624 - val_accuracy: 0.4872\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0620 - val_accuracy: 0.4872\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0586 - val_accuracy: 0.4872\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8624 - accuracy: 0.5667 - val_loss: 1.0550 - val_accuracy: 0.4786\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.8634 - accuracy: 0.5667 - val_loss: 1.0575 - val_accuracy: 0.4872\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.8621 - accuracy: 0.5704 - val_loss: 1.0600 - val_accuracy: 0.4872\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 278us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0583 - val_accuracy: 0.4872\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0595 - val_accuracy: 0.4872\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0562 - val_accuracy: 0.4872\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0640 - val_accuracy: 0.4872\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0595 - val_accuracy: 0.4872\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0589 - val_accuracy: 0.4872\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0612 - val_accuracy: 0.4872\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0578 - val_accuracy: 0.4872\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0572 - val_accuracy: 0.4872\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0624 - val_accuracy: 0.4872\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0600 - val_accuracy: 0.4872\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8631 - accuracy: 0.5704 - val_loss: 1.0561 - val_accuracy: 0.4872\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0610 - val_accuracy: 0.4872\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8628 - accuracy: 0.5704 - val_loss: 1.0670 - val_accuracy: 0.4872\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8657 - accuracy: 0.5704 - val_loss: 1.0628 - val_accuracy: 0.4872\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8712 - accuracy: 0.5704 - val_loss: 1.0635 - val_accuracy: 0.4872\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0602 - val_accuracy: 0.4872\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8643 - accuracy: 0.5481 - val_loss: 1.0612 - val_accuracy: 0.4872\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0643 - val_accuracy: 0.4872\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 97us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0642 - val_accuracy: 0.4872\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0650 - val_accuracy: 0.4872\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0580 - val_accuracy: 0.4872\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0571 - val_accuracy: 0.4872\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0642 - val_accuracy: 0.4872\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0598 - val_accuracy: 0.4872\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0614 - val_accuracy: 0.4872\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0618 - val_accuracy: 0.4872\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8683 - accuracy: 0.5407 - val_loss: 1.0585 - val_accuracy: 0.4872\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8619 - accuracy: 0.5704 - val_loss: 1.0619 - val_accuracy: 0.4872\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0651 - val_accuracy: 0.4872\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0606 - val_accuracy: 0.4872\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0588 - val_accuracy: 0.4872\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8646 - accuracy: 0.5407 - val_loss: 1.0572 - val_accuracy: 0.4872\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8609 - accuracy: 0.5704 - val_loss: 1.0617 - val_accuracy: 0.4872\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0702 - val_accuracy: 0.4872\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0614 - val_accuracy: 0.4872\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0625 - val_accuracy: 0.4872\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8630 - accuracy: 0.5704 - val_loss: 1.0621 - val_accuracy: 0.4872\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0638 - val_accuracy: 0.4872\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0662 - val_accuracy: 0.4872\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8660 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0644 - val_accuracy: 0.4872\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0654 - val_accuracy: 0.4872\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0596 - val_accuracy: 0.4872\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0596 - val_accuracy: 0.4872\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0626 - val_accuracy: 0.4872\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8620 - accuracy: 0.5704 - val_loss: 1.0625 - val_accuracy: 0.4872\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0613 - val_accuracy: 0.4872\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8653 - accuracy: 0.5148 - val_loss: 1.0601 - val_accuracy: 0.4872\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8666 - accuracy: 0.5704 - val_loss: 1.0652 - val_accuracy: 0.4872\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8633 - accuracy: 0.5704 - val_loss: 1.0605 - val_accuracy: 0.4872\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0614 - val_accuracy: 0.4872\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0640 - val_accuracy: 0.4872\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0626 - val_accuracy: 0.4872\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0630 - val_accuracy: 0.4872\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8630 - accuracy: 0.5704 - val_loss: 1.0582 - val_accuracy: 0.4872\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0659 - val_accuracy: 0.4872\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0609 - val_accuracy: 0.4872\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8661 - accuracy: 0.5704 - val_loss: 1.0665 - val_accuracy: 0.4872\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0635 - val_accuracy: 0.4872\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8619 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0693 - val_accuracy: 0.4872\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8627 - accuracy: 0.5370 - val_loss: 1.0597 - val_accuracy: 0.5299\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8666 - accuracy: 0.5704 - val_loss: 1.0617 - val_accuracy: 0.4872\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0620 - val_accuracy: 0.4872\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8619 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8608 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8636 - accuracy: 0.5667 - val_loss: 1.0638 - val_accuracy: 0.4872\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8658 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0602 - val_accuracy: 0.4872\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0665 - val_accuracy: 0.4872\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8630 - accuracy: 0.5704 - val_loss: 1.0597 - val_accuracy: 0.4872\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0609 - val_accuracy: 0.4872\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0608 - val_accuracy: 0.4872\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8652 - accuracy: 0.5407 - val_loss: 1.0592 - val_accuracy: 0.4872\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4872\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8638 - accuracy: 0.5704 - val_loss: 1.0636 - val_accuracy: 0.4872\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.4872\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8608 - accuracy: 0.5704 - val_loss: 1.0586 - val_accuracy: 0.4872\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0628 - val_accuracy: 0.4872\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8644 - accuracy: 0.5704 - val_loss: 1.0665 - val_accuracy: 0.4872\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0644 - val_accuracy: 0.4872\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8626 - accuracy: 0.5741 - val_loss: 1.0564 - val_accuracy: 0.4786\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8675 - accuracy: 0.5259 - val_loss: 1.0596 - val_accuracy: 0.4786\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0704 - val_accuracy: 0.4872\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8636 - accuracy: 0.5667 - val_loss: 1.0657 - val_accuracy: 0.4786\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0651 - val_accuracy: 0.4872\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8621 - accuracy: 0.5704 - val_loss: 1.0684 - val_accuracy: 0.4872\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0662 - val_accuracy: 0.4872\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0670 - val_accuracy: 0.4872\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8609 - accuracy: 0.5704 - val_loss: 1.0640 - val_accuracy: 0.4872\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0649 - val_accuracy: 0.4872\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8629 - accuracy: 0.5704 - val_loss: 1.0593 - val_accuracy: 0.4872\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0628 - val_accuracy: 0.4872\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0642 - val_accuracy: 0.4872\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0617 - val_accuracy: 0.4872\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8614 - accuracy: 0.5704 - val_loss: 1.0605 - val_accuracy: 0.4872\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0619 - val_accuracy: 0.4872\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0628 - val_accuracy: 0.4872\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0627 - val_accuracy: 0.4872\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8666 - accuracy: 0.5704 - val_loss: 1.0632 - val_accuracy: 0.4872\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8631 - accuracy: 0.5704 - val_loss: 1.0666 - val_accuracy: 0.4872\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0627 - val_accuracy: 0.4872\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0679 - val_accuracy: 0.4872\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0634 - val_accuracy: 0.4872\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8610 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0588 - val_accuracy: 0.4872\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0651 - val_accuracy: 0.4872\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0634 - val_accuracy: 0.4872\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0652 - val_accuracy: 0.4872\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0655 - val_accuracy: 0.4872\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8641 - accuracy: 0.5704 - val_loss: 1.0660 - val_accuracy: 0.4872\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8610 - accuracy: 0.5704 - val_loss: 1.0635 - val_accuracy: 0.4872\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0632 - val_accuracy: 0.4872\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0650 - val_accuracy: 0.4872\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0689 - val_accuracy: 0.4872\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8688 - accuracy: 0.5704 - val_loss: 1.0659 - val_accuracy: 0.4786\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8615 - accuracy: 0.5222 - val_loss: 1.0713 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0703 - val_accuracy: 0.4872\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0645 - val_accuracy: 0.4872\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0639 - val_accuracy: 0.4872\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8611 - accuracy: 0.5667 - val_loss: 1.0650 - val_accuracy: 0.4872\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0752 - val_accuracy: 0.4872\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8620 - accuracy: 0.5704 - val_loss: 1.0604 - val_accuracy: 0.4872\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0619 - val_accuracy: 0.4872\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8686 - accuracy: 0.5704 - val_loss: 1.0679 - val_accuracy: 0.4872\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8616 - accuracy: 0.5333 - val_loss: 1.0619 - val_accuracy: 0.5385\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8657 - accuracy: 0.5407 - val_loss: 1.0667 - val_accuracy: 0.4872\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0705 - val_accuracy: 0.4872\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0638 - val_accuracy: 0.4872\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0636 - val_accuracy: 0.4872\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0621 - val_accuracy: 0.4872\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.8624 - accuracy: 0.5704 - val_loss: 1.0704 - val_accuracy: 0.4872\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0652 - val_accuracy: 0.4872\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8625 - accuracy: 0.5444 - val_loss: 1.0651 - val_accuracy: 0.5299\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8610 - accuracy: 0.5481 - val_loss: 1.0663 - val_accuracy: 0.4872\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0665 - val_accuracy: 0.4786\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8622 - accuracy: 0.5444 - val_loss: 1.0572 - val_accuracy: 0.5299\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8659 - accuracy: 0.5370 - val_loss: 1.0602 - val_accuracy: 0.4872\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0710 - val_accuracy: 0.4872\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0673 - val_accuracy: 0.4872\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8620 - accuracy: 0.5704 - val_loss: 1.0678 - val_accuracy: 0.4872\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8609 - accuracy: 0.5704 - val_loss: 1.0667 - val_accuracy: 0.4872\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8668 - accuracy: 0.5704 - val_loss: 1.0702 - val_accuracy: 0.4872\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8632 - accuracy: 0.5519 - val_loss: 1.0605 - val_accuracy: 0.4872\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0664 - val_accuracy: 0.4872\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8608 - accuracy: 0.5704 - val_loss: 1.0650 - val_accuracy: 0.4872\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8614 - accuracy: 0.5704 - val_loss: 1.0693 - val_accuracy: 0.4872\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0668 - val_accuracy: 0.4872\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0647 - val_accuracy: 0.4872\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0640 - val_accuracy: 0.4872\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0709 - val_accuracy: 0.4872\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0681 - val_accuracy: 0.4872\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8610 - accuracy: 0.5704 - val_loss: 1.0612 - val_accuracy: 0.4872\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0673 - val_accuracy: 0.4872\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0694 - val_accuracy: 0.4872\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8656 - accuracy: 0.5222 - val_loss: 1.0678 - val_accuracy: 0.4872\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8638 - accuracy: 0.5704 - val_loss: 1.0752 - val_accuracy: 0.4872\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0660 - val_accuracy: 0.4872\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8626 - accuracy: 0.5370 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8592 - accuracy: 0.5704 - val_loss: 1.0716 - val_accuracy: 0.4872\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8673 - accuracy: 0.5704 - val_loss: 1.0716 - val_accuracy: 0.4872\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.8607 - accuracy: 0.5704 - val_loss: 1.0622 - val_accuracy: 0.4872\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8637 - accuracy: 0.5185 - val_loss: 1.0589 - val_accuracy: 0.4786\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0699 - val_accuracy: 0.4872\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0700 - val_accuracy: 0.4872\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0659 - val_accuracy: 0.4872\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8675 - accuracy: 0.5222 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0660 - val_accuracy: 0.4872\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0694 - val_accuracy: 0.4872\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0632 - val_accuracy: 0.4872\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0629 - val_accuracy: 0.4872\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8586 - accuracy: 0.5704 - val_loss: 1.0665 - val_accuracy: 0.4872\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0757 - val_accuracy: 0.4872\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8671 - accuracy: 0.5704 - val_loss: 1.0668 - val_accuracy: 0.4786\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.8698 - accuracy: 0.5704 - val_loss: 1.0771 - val_accuracy: 0.4872\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8639 - accuracy: 0.5704 - val_loss: 1.0635 - val_accuracy: 0.4786\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8629 - accuracy: 0.5741 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.8603 - accuracy: 0.5741 - val_loss: 1.0641 - val_accuracy: 0.4786\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0644 - val_accuracy: 0.4872\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0668 - val_accuracy: 0.4872\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.8652 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0666 - val_accuracy: 0.4872\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8598 - accuracy: 0.5704 - val_loss: 1.0679 - val_accuracy: 0.4872\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8650 - accuracy: 0.5704 - val_loss: 1.0700 - val_accuracy: 0.4872\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0612 - val_accuracy: 0.4872\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8619 - accuracy: 0.5370 - val_loss: 1.0644 - val_accuracy: 0.4872\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8633 - accuracy: 0.5704 - val_loss: 1.0767 - val_accuracy: 0.4872\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0607 - val_accuracy: 0.4872\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0673 - val_accuracy: 0.4872\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0701 - val_accuracy: 0.4872\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0760 - val_accuracy: 0.4872\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0633 - val_accuracy: 0.4872\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8631 - accuracy: 0.5704 - val_loss: 1.0634 - val_accuracy: 0.4872\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0675 - val_accuracy: 0.4872\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0666 - val_accuracy: 0.4872\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0721 - val_accuracy: 0.4872\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8648 - accuracy: 0.5593 - val_loss: 1.0630 - val_accuracy: 0.4786\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8651 - accuracy: 0.5667 - val_loss: 1.0692 - val_accuracy: 0.4872\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8665 - accuracy: 0.5704 - val_loss: 1.0726 - val_accuracy: 0.4872\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0705 - val_accuracy: 0.4872\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8607 - accuracy: 0.5704 - val_loss: 1.0691 - val_accuracy: 0.4872\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8656 - accuracy: 0.5704 - val_loss: 1.0698 - val_accuracy: 0.4872\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8605 - accuracy: 0.5704 - val_loss: 1.0620 - val_accuracy: 0.4872\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0635 - val_accuracy: 0.4872\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8719 - accuracy: 0.5704 - val_loss: 1.0749 - val_accuracy: 0.4872\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8585 - accuracy: 0.5704 - val_loss: 1.0624 - val_accuracy: 0.4872\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8646 - accuracy: 0.5704 - val_loss: 1.0679 - val_accuracy: 0.4786\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8653 - accuracy: 0.5704 - val_loss: 1.0743 - val_accuracy: 0.4872\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0737 - val_accuracy: 0.4872\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0695 - val_accuracy: 0.4872\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8647 - accuracy: 0.5704 - val_loss: 1.0738 - val_accuracy: 0.4872\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8671 - accuracy: 0.5333 - val_loss: 1.0677 - val_accuracy: 0.5385\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8596 - accuracy: 0.5444 - val_loss: 1.0709 - val_accuracy: 0.4872\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0726 - val_accuracy: 0.4872\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0656 - val_accuracy: 0.4872\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8584 - accuracy: 0.5704 - val_loss: 1.0670 - val_accuracy: 0.4872\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8659 - accuracy: 0.5704 - val_loss: 1.0681 - val_accuracy: 0.4872\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8637 - accuracy: 0.5704 - val_loss: 1.0753 - val_accuracy: 0.4872\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8639 - accuracy: 0.5259 - val_loss: 1.0718 - val_accuracy: 0.4872\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8649 - accuracy: 0.5704 - val_loss: 1.0720 - val_accuracy: 0.4872\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8677 - accuracy: 0.5704 - val_loss: 1.0804 - val_accuracy: 0.4872\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0671 - val_accuracy: 0.4872\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8691 - accuracy: 0.5148 - val_loss: 1.0606 - val_accuracy: 0.4872\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8662 - accuracy: 0.5704 - val_loss: 1.0768 - val_accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0727 - val_accuracy: 0.4872\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8667 - accuracy: 0.5222 - val_loss: 1.0634 - val_accuracy: 0.5385\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8667 - accuracy: 0.5593 - val_loss: 1.0745 - val_accuracy: 0.4872\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8591 - accuracy: 0.5704 - val_loss: 1.0735 - val_accuracy: 0.4872\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8638 - accuracy: 0.5296 - val_loss: 1.0648 - val_accuracy: 0.4872\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8598 - accuracy: 0.5704 - val_loss: 1.0630 - val_accuracy: 0.4872\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.8614 - accuracy: 0.5704 - val_loss: 1.0703 - val_accuracy: 0.4872\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8644 - accuracy: 0.5296 - val_loss: 1.0694 - val_accuracy: 0.4872\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8645 - accuracy: 0.5704 - val_loss: 1.0817 - val_accuracy: 0.4872\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8658 - accuracy: 0.5704 - val_loss: 1.0641 - val_accuracy: 0.4872\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0683 - val_accuracy: 0.4872\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0733 - val_accuracy: 0.4872\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8654 - accuracy: 0.5704 - val_loss: 1.0744 - val_accuracy: 0.4872\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8581 - accuracy: 0.5704 - val_loss: 1.0717 - val_accuracy: 0.4872\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0668 - val_accuracy: 0.4872\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8585 - accuracy: 0.5593 - val_loss: 1.0641 - val_accuracy: 0.5385\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8625 - accuracy: 0.5519 - val_loss: 1.0737 - val_accuracy: 0.4872\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0692 - val_accuracy: 0.4872\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0746 - val_accuracy: 0.4872\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8645 - accuracy: 0.5704 - val_loss: 1.0654 - val_accuracy: 0.4872\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8586 - accuracy: 0.5704 - val_loss: 1.0645 - val_accuracy: 0.4872\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0669 - val_accuracy: 0.4872\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8619 - accuracy: 0.5704 - val_loss: 1.0754 - val_accuracy: 0.4872\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8642 - accuracy: 0.5704 - val_loss: 1.0676 - val_accuracy: 0.4872\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0679 - val_accuracy: 0.4872\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8600 - accuracy: 0.5704 - val_loss: 1.0649 - val_accuracy: 0.4872\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0695 - val_accuracy: 0.4872\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0671 - val_accuracy: 0.4872\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0723 - val_accuracy: 0.4872\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8644 - accuracy: 0.5222 - val_loss: 1.0667 - val_accuracy: 0.4872\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8574 - accuracy: 0.5704 - val_loss: 1.0726 - val_accuracy: 0.4872\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0705 - val_accuracy: 0.4872\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8628 - accuracy: 0.5704 - val_loss: 1.0708 - val_accuracy: 0.4872\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0656 - val_accuracy: 0.4872\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0696 - val_accuracy: 0.4872\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.8627 - accuracy: 0.5704 - val_loss: 1.0730 - val_accuracy: 0.4872\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0721 - val_accuracy: 0.4872\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0681 - val_accuracy: 0.4872\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0658 - val_accuracy: 0.4872\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8616 - accuracy: 0.5704 - val_loss: 1.0672 - val_accuracy: 0.4872\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0764 - val_accuracy: 0.4872\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8577 - accuracy: 0.5667 - val_loss: 1.0711 - val_accuracy: 0.5385\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8652 - accuracy: 0.5259 - val_loss: 1.0688 - val_accuracy: 0.4872\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0832 - val_accuracy: 0.4872\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0728 - val_accuracy: 0.4872\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0654 - val_accuracy: 0.4872\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.8586 - accuracy: 0.5704 - val_loss: 1.0694 - val_accuracy: 0.4872\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8591 - accuracy: 0.5704 - val_loss: 1.0700 - val_accuracy: 0.4872\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8620 - accuracy: 0.5704 - val_loss: 1.0724 - val_accuracy: 0.4872\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8593 - accuracy: 0.5704 - val_loss: 1.0761 - val_accuracy: 0.4872\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0730 - val_accuracy: 0.4872\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8587 - accuracy: 0.5704 - val_loss: 1.0735 - val_accuracy: 0.4872\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0698 - val_accuracy: 0.4872\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0730 - val_accuracy: 0.4872\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0716 - val_accuracy: 0.4872\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0744 - val_accuracy: 0.4872\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8577 - accuracy: 0.5704 - val_loss: 1.0754 - val_accuracy: 0.4872\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0716 - val_accuracy: 0.4872\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8578 - accuracy: 0.5667 - val_loss: 1.0642 - val_accuracy: 0.5385\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8602 - accuracy: 0.5556 - val_loss: 1.0680 - val_accuracy: 0.4872\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0752 - val_accuracy: 0.4872\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0661 - val_accuracy: 0.4872\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0684 - val_accuracy: 0.4872\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 276us/step - loss: 0.8623 - accuracy: 0.5704 - val_loss: 1.0702 - val_accuracy: 0.4872\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8594 - accuracy: 0.5704 - val_loss: 1.0701 - val_accuracy: 0.4872\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0721 - val_accuracy: 0.4872\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8599 - accuracy: 0.5704 - val_loss: 1.0733 - val_accuracy: 0.4872\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 322us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0681 - val_accuracy: 0.4872\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.8587 - accuracy: 0.5704 - val_loss: 1.0691 - val_accuracy: 0.4872\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8587 - accuracy: 0.5704 - val_loss: 1.0654 - val_accuracy: 0.4872\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8609 - accuracy: 0.5704 - val_loss: 1.0637 - val_accuracy: 0.4872\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.9302 - accuracy: 0.59 - 0s 165us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0701 - val_accuracy: 0.4872\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8619 - accuracy: 0.5444 - val_loss: 1.0713 - val_accuracy: 0.4872\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0798 - val_accuracy: 0.4872\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0841 - val_accuracy: 0.4872\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8636 - accuracy: 0.5704 - val_loss: 1.0705 - val_accuracy: 0.4872\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.8577 - accuracy: 0.5704 - val_loss: 1.0762 - val_accuracy: 0.4872\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8592 - accuracy: 0.5704 - val_loss: 1.0770 - val_accuracy: 0.4872\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0734 - val_accuracy: 0.4872\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8574 - accuracy: 0.5704 - val_loss: 1.0723 - val_accuracy: 0.4872\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.8630 - accuracy: 0.59 - 0s 109us/step - loss: 0.8603 - accuracy: 0.5704 - val_loss: 1.0718 - val_accuracy: 0.4872\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8593 - accuracy: 0.5704 - val_loss: 1.0793 - val_accuracy: 0.4872\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8598 - accuracy: 0.5704 - val_loss: 1.0671 - val_accuracy: 0.4872\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8594 - accuracy: 0.5704 - val_loss: 1.0678 - val_accuracy: 0.4872\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.8634 - accuracy: 0.5111 - val_loss: 1.0661 - val_accuracy: 0.4872\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0795 - val_accuracy: 0.4872\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0736 - val_accuracy: 0.4872\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.8587 - accuracy: 0.5704 - val_loss: 1.0703 - val_accuracy: 0.4872\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.8616 - accuracy: 0.5444 - val_loss: 1.0688 - val_accuracy: 0.4872\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 445us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0814 - val_accuracy: 0.4872\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8764 - accuracy: 0.4926 - val_loss: 1.0709 - val_accuracy: 0.5299\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8599 - accuracy: 0.5778 - val_loss: 1.0751 - val_accuracy: 0.4872\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0718 - val_accuracy: 0.4872\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.8591 - accuracy: 0.5704 - val_loss: 1.0737 - val_accuracy: 0.4872\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8666 - accuracy: 0.5704 - val_loss: 1.0786 - val_accuracy: 0.4872\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0701 - val_accuracy: 0.4872\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8632 - accuracy: 0.5259 - val_loss: 1.0730 - val_accuracy: 0.4872\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0753 - val_accuracy: 0.4872\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.8675 - accuracy: 0.5704 - val_loss: 1.0837 - val_accuracy: 0.4872\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8694 - accuracy: 0.5741 - val_loss: 1.0692 - val_accuracy: 0.4786\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8628 - accuracy: 0.5741 - val_loss: 1.0765 - val_accuracy: 0.4872\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0735 - val_accuracy: 0.4872\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0689 - val_accuracy: 0.4872\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8582 - accuracy: 0.5704 - val_loss: 1.0736 - val_accuracy: 0.4872\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0771 - val_accuracy: 0.4872\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 324us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0684 - val_accuracy: 0.4872\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8602 - accuracy: 0.5741 - val_loss: 1.0714 - val_accuracy: 0.4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8579 - accuracy: 0.5704 - val_loss: 1.0766 - val_accuracy: 0.4786\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8632 - accuracy: 0.5704 - val_loss: 1.0770 - val_accuracy: 0.4872\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8579 - accuracy: 0.5667 - val_loss: 1.0691 - val_accuracy: 0.4872\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.8597 - accuracy: 0.5667 - val_loss: 1.0708 - val_accuracy: 0.4872\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0798 - val_accuracy: 0.4872\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0814 - val_accuracy: 0.4872\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0707 - val_accuracy: 0.4786\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.8683 - accuracy: 0.5704 - val_loss: 1.0736 - val_accuracy: 0.4872\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8607 - accuracy: 0.5519 - val_loss: 1.0689 - val_accuracy: 0.5385\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8653 - accuracy: 0.5556 - val_loss: 1.0705 - val_accuracy: 0.4872\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0757 - val_accuracy: 0.4872\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8600 - accuracy: 0.5704 - val_loss: 1.0717 - val_accuracy: 0.4872\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.8599 - accuracy: 0.5704 - val_loss: 1.0716 - val_accuracy: 0.4872\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8594 - accuracy: 0.5704 - val_loss: 1.0771 - val_accuracy: 0.4872\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.8579 - accuracy: 0.5704 - val_loss: 1.0744 - val_accuracy: 0.4872\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8618 - accuracy: 0.5704 - val_loss: 1.0725 - val_accuracy: 0.4872\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8635 - accuracy: 0.5704 - val_loss: 1.0773 - val_accuracy: 0.4872\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8633 - accuracy: 0.5704 - val_loss: 1.0715 - val_accuracy: 0.4872\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.8597 - accuracy: 0.5704 - val_loss: 1.0796 - val_accuracy: 0.4872\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0826 - val_accuracy: 0.4872\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8575 - accuracy: 0.5593 - val_loss: 1.0750 - val_accuracy: 0.5385\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8589 - accuracy: 0.5519 - val_loss: 1.0742 - val_accuracy: 0.4872\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8576 - accuracy: 0.5667 - val_loss: 1.0749 - val_accuracy: 0.4872\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8582 - accuracy: 0.5704 - val_loss: 1.0772 - val_accuracy: 0.4872\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0773 - val_accuracy: 0.4872\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.8593 - accuracy: 0.5704 - val_loss: 1.0779 - val_accuracy: 0.4872\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8687 - accuracy: 0.5704 - val_loss: 1.0758 - val_accuracy: 0.4872\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0742 - val_accuracy: 0.4872\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8634 - accuracy: 0.5704 - val_loss: 1.0803 - val_accuracy: 0.4872\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.8629 - accuracy: 0.5667 - val_loss: 1.0765 - val_accuracy: 0.4872\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.8639 - accuracy: 0.5667 - val_loss: 1.0814 - val_accuracy: 0.4872\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.8655 - accuracy: 0.5704 - val_loss: 1.0877 - val_accuracy: 0.4872\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.8617 - accuracy: 0.5704 - val_loss: 1.0812 - val_accuracy: 0.4872\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0720 - val_accuracy: 0.4872\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0765 - val_accuracy: 0.4872\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0784 - val_accuracy: 0.4872\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.8610 - accuracy: 0.5481 - val_loss: 1.0707 - val_accuracy: 0.4872\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0773 - val_accuracy: 0.4872\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.8580 - accuracy: 0.5704 - val_loss: 1.0744 - val_accuracy: 0.4872\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.8598 - accuracy: 0.5704 - val_loss: 1.0794 - val_accuracy: 0.4872\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.8655 - accuracy: 0.5704 - val_loss: 1.0740 - val_accuracy: 0.4872\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.8600 - accuracy: 0.5704 - val_loss: 1.0919 - val_accuracy: 0.4872\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8676 - accuracy: 0.5704 - val_loss: 1.0837 - val_accuracy: 0.4872\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.8573 - accuracy: 0.5704 - val_loss: 1.0786 - val_accuracy: 0.4872\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 352us/step - loss: 0.8670 - accuracy: 0.5704 - val_loss: 1.0771 - val_accuracy: 0.4872\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.8589 - accuracy: 0.5704 - val_loss: 1.0748 - val_accuracy: 0.4872\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0838 - val_accuracy: 0.4872\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0803 - val_accuracy: 0.4872\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0754 - val_accuracy: 0.4872\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.8601 - accuracy: 0.5704 - val_loss: 1.0816 - val_accuracy: 0.4872\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.8657 - accuracy: 0.5704 - val_loss: 1.0869 - val_accuracy: 0.4872\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.8682 - accuracy: 0.5222 - val_loss: 1.0788 - val_accuracy: 0.5385\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 440us/step - loss: 0.8573 - accuracy: 0.5519 - val_loss: 1.0826 - val_accuracy: 0.4872\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8625 - accuracy: 0.5704 - val_loss: 1.0804 - val_accuracy: 0.4872\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.8575 - accuracy: 0.5704 - val_loss: 1.0758 - val_accuracy: 0.4872\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.8604 - accuracy: 0.5704 - val_loss: 1.0792 - val_accuracy: 0.4872\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8594 - accuracy: 0.5704 - val_loss: 1.0739 - val_accuracy: 0.4872\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8611 - accuracy: 0.5704 - val_loss: 1.0726 - val_accuracy: 0.4872\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.8614 - accuracy: 0.5704 - val_loss: 1.0790 - val_accuracy: 0.4872\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.8596 - accuracy: 0.5704 - val_loss: 1.0819 - val_accuracy: 0.4872\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.8579 - accuracy: 0.5704 - val_loss: 1.0797 - val_accuracy: 0.4872\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8591 - accuracy: 0.5704 - val_loss: 1.0767 - val_accuracy: 0.4872\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8643 - accuracy: 0.5704 - val_loss: 1.0811 - val_accuracy: 0.4872\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8579 - accuracy: 0.5704 - val_loss: 1.0731 - val_accuracy: 0.4872\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8587 - accuracy: 0.5704 - val_loss: 1.0784 - val_accuracy: 0.4872\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.8573 - accuracy: 0.5704 - val_loss: 1.0819 - val_accuracy: 0.4872\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.8577 - accuracy: 0.5704 - val_loss: 1.0820 - val_accuracy: 0.4872\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8567 - accuracy: 0.5704 - val_loss: 1.0776 - val_accuracy: 0.4872\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.8576 - accuracy: 0.5704 - val_loss: 1.0743 - val_accuracy: 0.4872\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0775 - val_accuracy: 0.4872\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8575 - accuracy: 0.5704 - val_loss: 1.0789 - val_accuracy: 0.4872\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.8581 - accuracy: 0.5667 - val_loss: 1.0774 - val_accuracy: 0.4786\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.8606 - accuracy: 0.5704 - val_loss: 1.0782 - val_accuracy: 0.4786\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.8597 - accuracy: 0.5741 - val_loss: 1.0768 - val_accuracy: 0.4872\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.8628 - accuracy: 0.5704 - val_loss: 1.0713 - val_accuracy: 0.4872\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.8574 - accuracy: 0.5704 - val_loss: 1.0766 - val_accuracy: 0.4872\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.8574 - accuracy: 0.5704 - val_loss: 1.0837 - val_accuracy: 0.4872\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.8583 - accuracy: 0.5704 - val_loss: 1.0779 - val_accuracy: 0.4872\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8614 - accuracy: 0.5296 - val_loss: 1.0739 - val_accuracy: 0.5385\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8623 - accuracy: 0.5444 - val_loss: 1.0828 - val_accuracy: 0.4872\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.8584 - accuracy: 0.5704 - val_loss: 1.0762 - val_accuracy: 0.4872\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.8577 - accuracy: 0.5704 - val_loss: 1.0752 - val_accuracy: 0.4872\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.8572 - accuracy: 0.5704 - val_loss: 1.0759 - val_accuracy: 0.4872\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0742 - val_accuracy: 0.4872\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8594 - accuracy: 0.5704 - val_loss: 1.0795 - val_accuracy: 0.4872\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8612 - accuracy: 0.5704 - val_loss: 1.0724 - val_accuracy: 0.4872\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8640 - accuracy: 0.5704 - val_loss: 1.0830 - val_accuracy: 0.4872\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.8582 - accuracy: 0.5704 - val_loss: 1.0764 - val_accuracy: 0.4872\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8595 - accuracy: 0.5704 - val_loss: 1.0785 - val_accuracy: 0.4872\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8590 - accuracy: 0.5704 - val_loss: 1.0801 - val_accuracy: 0.4872\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8607 - accuracy: 0.5704 - val_loss: 1.0804 - val_accuracy: 0.4872\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8599 - accuracy: 0.5704 - val_loss: 1.0761 - val_accuracy: 0.4872\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8620 - accuracy: 0.5704 - val_loss: 1.0749 - val_accuracy: 0.4786\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.8580 - accuracy: 0.5667 - val_loss: 1.0809 - val_accuracy: 0.4872\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.8609 - accuracy: 0.5704 - val_loss: 1.0797 - val_accuracy: 0.4872\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8607 - accuracy: 0.5704 - val_loss: 1.0873 - val_accuracy: 0.4872\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.8613 - accuracy: 0.5704 - val_loss: 1.0823 - val_accuracy: 0.4872\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8609 - accuracy: 0.5667 - val_loss: 1.0779 - val_accuracy: 0.4786\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.8615 - accuracy: 0.5704 - val_loss: 1.0764 - val_accuracy: 0.4786\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8585 - accuracy: 0.5704 - val_loss: 1.0812 - val_accuracy: 0.4872\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8626 - accuracy: 0.5704 - val_loss: 1.0791 - val_accuracy: 0.4872\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8631 - accuracy: 0.5333 - val_loss: 1.0841 - val_accuracy: 0.4872\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8588 - accuracy: 0.5704 - val_loss: 1.0813 - val_accuracy: 0.4872\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8619 - accuracy: 0.5704 - val_loss: 1.0766 - val_accuracy: 0.4786\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8602 - accuracy: 0.5704 - val_loss: 1.0823 - val_accuracy: 0.4872\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8567 - accuracy: 0.5704 - val_loss: 1.0776 - val_accuracy: 0.4872\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8615 - accuracy: 0.5556 - val_loss: 1.0789 - val_accuracy: 0.4786\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8621 - accuracy: 0.5667 - val_loss: 1.0891 - val_accuracy: 0.4872\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8571 - accuracy: 0.5704 - val_loss: 1.0824 - val_accuracy: 0.4872\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8666 - accuracy: 0.5519 - val_loss: 1.0807 - val_accuracy: 0.4872\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 113us/step - loss: 0.8622 - accuracy: 0.5704 - val_loss: 1.0786 - val_accuracy: 0.4872\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8604 - accuracy: 0.5667 - val_loss: 1.0753 - val_accuracy: 0.4786\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.8584 - accuracy: 0.5704 - val_loss: 1.0807 - val_accuracy: 0.4872\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.8582 - accuracy: 0.5704 - val_loss: 1.0836 - val_accuracy: 0.4872\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.8615 - accuracy: 0.5704 - val_loss: 1.0834 - val_accuracy: 0.4872\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.8640 - accuracy: 0.5185 - val_loss: 1.0801 - val_accuracy: 0.5385\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.8627 - accuracy: 0.5519 - val_loss: 1.0880 - val_accuracy: 0.4872\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 56.78%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [3.4782300e-02, 2.8066847e-01, 6.8454915e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.3815957e-01, 3.0921945e-01, 5.5262100e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.8404920e-01, 1.0945539e-01, 2.0649539e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [2.1217002e-02, 1.9669692e-01, 7.8208610e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.0336818e-02, 1.0571358e-02, 9.7909180e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.5825848e-05, 1.8219705e-06, 9.9998236e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [2.1408030e-05, 6.4794817e-06, 9.9997210e-01],\n",
       "       [3.2965627e-01, 5.9332710e-01, 7.7016590e-02],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [8.9328974e-01, 4.8540752e-02, 5.8169533e-02],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [3.7781818e-05, 1.7679784e-05, 9.9994457e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [5.0539210e-01, 1.2961070e-01, 3.6499720e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.3815957e-01, 3.0921945e-01, 5.5262100e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.5116626e-07, 8.6246965e-09, 9.9999990e-01],\n",
       "       [9.3421350e-01, 2.8773345e-02, 3.7013100e-02],\n",
       "       [3.0883210e-01, 1.2329382e-01, 5.6787413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [2.1217002e-02, 1.9669692e-01, 7.8208610e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [5.4756176e-02, 3.9615236e-02, 9.0562860e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [3.1284610e-02, 6.2721570e-01, 3.4149972e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [9.6999120e-01, 1.6209135e-02, 1.3799639e-02],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [3.0883210e-01, 1.2329382e-01, 5.6787413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [2.1217002e-02, 1.9669692e-01, 7.8208610e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [1.9721220e-01, 6.3971970e-02, 7.3881584e-01],\n",
       "       [6.6708750e-01, 1.4172785e-01, 1.9118461e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [2.1217002e-02, 1.9669692e-01, 7.8208610e-01],\n",
       "       [2.1217002e-02, 1.9669692e-01, 7.8208610e-01],\n",
       "       [3.0883210e-01, 1.2329382e-01, 5.6787413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [5.4756176e-02, 3.9615236e-02, 9.0562860e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [9.3421350e-01, 2.8773345e-02, 3.7013100e-02],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [6.3482640e-01, 2.2028415e-01, 1.4488940e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [9.7884920e-01, 8.5665860e-03, 1.2584251e-02],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [2.1408030e-05, 6.4794817e-06, 9.9997210e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [1.5116626e-07, 8.6246965e-09, 9.9999990e-01],\n",
       "       [1.3219704e-02, 2.4462637e-01, 7.4215394e-01],\n",
       "       [3.0883210e-01, 1.2329382e-01, 5.6787413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.3680349e-04, 5.1535404e-04, 9.9934787e-01],\n",
       "       [8.2526890e-01, 3.4306657e-02, 1.4042431e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.9879068e-01, 5.3310440e-01, 2.6810485e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [2.1408030e-05, 6.4794817e-06, 9.9997210e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01],\n",
       "       [1.3815957e-01, 3.0921945e-01, 5.5262100e-01],\n",
       "       [4.0902510e-01, 3.4050083e-01, 2.5047413e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0006kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7145518299364454"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7145518299364454"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888286215209293"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029825730529423274"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888286215209293"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029825730529423274"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 51.07%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.03594574584774779\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 54.87%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.013600758\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
