{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks for p11presabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for four replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 953)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p11presabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      1\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    2\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_6449</th>\n",
       "      <th>group_8588</th>\n",
       "      <th>group_10026</th>\n",
       "      <th>group_10028</th>\n",
       "      <th>group_10211</th>\n",
       "      <th>group_2860</th>\n",
       "      <th>group_5746</th>\n",
       "      <th>group_7042</th>\n",
       "      <th>group_867</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  \\\n",
       "0     107               0                0                0   \n",
       "1     109               1                1                1   \n",
       "2     115               1                1                1   \n",
       "3  120335               1                1                1   \n",
       "4  120337               1                1                1   \n",
       "\n",
       "   TTTTTTATTTTGGATAA  TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  \\\n",
       "0                  0                        0                 0   \n",
       "1                  1                        1                 1   \n",
       "2                  1                        1                 1   \n",
       "3                  1                        1                 1   \n",
       "4                  1                        1                 1   \n",
       "\n",
       "   TTTTTATCGTTTACT  TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  ...  group_6449  \\\n",
       "0                0                0                 0  ...           0   \n",
       "1                1                1                 1  ...           0   \n",
       "2                1                1                 1  ...           0   \n",
       "3                1                1                 1  ...           0   \n",
       "4                1                1                 1  ...           0   \n",
       "\n",
       "   group_8588  group_10026  group_10028  group_10211  group_2860  group_5746  \\\n",
       "0           0            0            0            0           0           0   \n",
       "1           0            0            0            0           0           0   \n",
       "2           0            0            0            0           0           0   \n",
       "3           1            0            0            0           0           0   \n",
       "4           1            0            0            0           0           0   \n",
       "\n",
       "   group_7042  group_867  pheno  \n",
       "0           0          0      2  \n",
       "1           0          0      1  \n",
       "2           0          0      2  \n",
       "3           0          0      2  \n",
       "4           0          0      2  \n",
       "\n",
       "[5 rows x 953 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    181\n",
       "1     47\n",
       "0     25\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 952)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTGTAATTTT</th>\n",
       "      <th>TTTTTTGTAATTTTT</th>\n",
       "      <th>TTTTTTATTTTGGAT</th>\n",
       "      <th>TTTTTTATTTTGGATAA</th>\n",
       "      <th>TTTTTTATTTTGGATAAAAGGAG</th>\n",
       "      <th>TTTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTATCGTTTACT</th>\n",
       "      <th>TTTTTAGTCGTTTTT</th>\n",
       "      <th>TTTTTAGTCGTTTTTT</th>\n",
       "      <th>TTTTTAGGTAAGG</th>\n",
       "      <th>...</th>\n",
       "      <th>group_6449</th>\n",
       "      <th>group_8588</th>\n",
       "      <th>group_10026</th>\n",
       "      <th>group_10028</th>\n",
       "      <th>group_10211</th>\n",
       "      <th>group_2860</th>\n",
       "      <th>group_5746</th>\n",
       "      <th>group_7042</th>\n",
       "      <th>group_867</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTGTAATTTT  TTTTTTGTAATTTTT  TTTTTTATTTTGGAT  TTTTTTATTTTGGATAA  \\\n",
       "0               0                0                0                  0   \n",
       "1               1                1                1                  1   \n",
       "2               1                1                1                  1   \n",
       "3               1                1                1                  1   \n",
       "4               1                1                1                  1   \n",
       "\n",
       "   TTTTTTATTTTGGATAAAAGGAG  TTTTTTAGTCGTTTTT  TTTTTATCGTTTACT  \\\n",
       "0                        0                 0                0   \n",
       "1                        1                 1                1   \n",
       "2                        1                 1                1   \n",
       "3                        1                 1                1   \n",
       "4                        1                 1                1   \n",
       "\n",
       "   TTTTTAGTCGTTTTT  TTTTTAGTCGTTTTTT  TTTTTAGGTAAGG  ...  group_6449  \\\n",
       "0                0                 0              0  ...           0   \n",
       "1                1                 1              1  ...           0   \n",
       "2                1                 1              1  ...           0   \n",
       "3                1                 1              1  ...           0   \n",
       "4                1                 1              1  ...           0   \n",
       "\n",
       "   group_8588  group_10026  group_10028  group_10211  group_2860  group_5746  \\\n",
       "0           0            0            0            0           0           0   \n",
       "1           0            0            0            0           0           0   \n",
       "2           0            0            0            0           0           0   \n",
       "3           1            0            0            0           0           0   \n",
       "4           1            0            0            0           0           0   \n",
       "\n",
       "   group_7042  group_867  pheno  \n",
       "0           0          0      2  \n",
       "1           0          0      1  \n",
       "2           0          0      2  \n",
       "3           0          0      2  \n",
       "4           0          0      2  \n",
       "\n",
       "[5 rows x 952 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 952) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 181), (1, 181), (2, 181)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR1129     2\n",
       "1         NRS185     2\n",
       "2         NRS243     1\n",
       "3      BCH-SA-04     0\n",
       "4            504     1\n",
       "..           ...   ...\n",
       "158  CFBREBSa131     2\n",
       "159  CFBREBSa133     1\n",
       "160       NRS256     2\n",
       "161      GA48963     1\n",
       "162    BCH-SA-07     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 490us/step - loss: 1.2953 - accuracy: 0.3947 - val_loss: 1.1719 - val_accuracy: 0.4724\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 236us/step - loss: 0.9334 - accuracy: 0.5342 - val_loss: 0.9308 - val_accuracy: 0.6258\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.8581 - accuracy: 0.6158 - val_loss: 0.8329 - val_accuracy: 0.6196\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.7640 - accuracy: 0.6737 - val_loss: 0.7840 - val_accuracy: 0.6196\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.6978 - accuracy: 0.6895 - val_loss: 0.7918 - val_accuracy: 0.6503\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.6610 - accuracy: 0.7079 - val_loss: 0.8039 - val_accuracy: 0.6564\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 250us/step - loss: 0.6101 - accuracy: 0.7474 - val_loss: 0.7040 - val_accuracy: 0.6933\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.5531 - accuracy: 0.7868 - val_loss: 0.6390 - val_accuracy: 0.7301\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.5199 - accuracy: 0.8053 - val_loss: 0.6625 - val_accuracy: 0.7423\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.4878 - accuracy: 0.8263 - val_loss: 0.6303 - val_accuracy: 0.7239\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 371us/step - loss: 0.4576 - accuracy: 0.8368 - val_loss: 0.5832 - val_accuracy: 0.7730\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.4373 - accuracy: 0.8658 - val_loss: 0.5583 - val_accuracy: 0.7791\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 232us/step - loss: 0.4203 - accuracy: 0.8553 - val_loss: 0.5923 - val_accuracy: 0.7362\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 266us/step - loss: 0.4108 - accuracy: 0.8658 - val_loss: 0.6773 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 282us/step - loss: 0.4319 - accuracy: 0.8289 - val_loss: 0.5601 - val_accuracy: 0.7791\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 290us/step - loss: 0.3666 - accuracy: 0.8921 - val_loss: 0.5214 - val_accuracy: 0.8098\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3450 - accuracy: 0.9026 - val_loss: 0.4873 - val_accuracy: 0.8160\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.3420 - accuracy: 0.9026 - val_loss: 0.4882 - val_accuracy: 0.8098\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3542 - accuracy: 0.8605 - val_loss: 0.4659 - val_accuracy: 0.8344\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.3391 - accuracy: 0.8842 - val_loss: 0.4646 - val_accuracy: 0.8466\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.2994 - accuracy: 0.9132 - val_loss: 0.5182 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3052 - accuracy: 0.9026 - val_loss: 0.5491 - val_accuracy: 0.7730\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.3088 - accuracy: 0.9000 - val_loss: 0.4424 - val_accuracy: 0.8344\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.2856 - accuracy: 0.9105 - val_loss: 0.4812 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 308us/step - loss: 0.2870 - accuracy: 0.9053 - val_loss: 0.4874 - val_accuracy: 0.7853\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 232us/step - loss: 0.2716 - accuracy: 0.9184 - val_loss: 0.4263 - val_accuracy: 0.8528\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.2547 - accuracy: 0.9184 - val_loss: 0.4362 - val_accuracy: 0.8344\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.2598 - accuracy: 0.9184 - val_loss: 0.4808 - val_accuracy: 0.8160\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 237us/step - loss: 0.2645 - accuracy: 0.9184 - val_loss: 0.4381 - val_accuracy: 0.8589\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 282us/step - loss: 0.2631 - accuracy: 0.9237 - val_loss: 0.4232 - val_accuracy: 0.8712\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.2594 - accuracy: 0.9132 - val_loss: 0.4288 - val_accuracy: 0.8344\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 276us/step - loss: 0.2333 - accuracy: 0.9289 - val_loss: 0.4227 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 254us/step - loss: 0.2200 - accuracy: 0.9316 - val_loss: 0.4314 - val_accuracy: 0.8098\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 268us/step - loss: 0.2192 - accuracy: 0.9316 - val_loss: 0.4514 - val_accuracy: 0.8160\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.2106 - accuracy: 0.9263 - val_loss: 0.4382 - val_accuracy: 0.8344\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 235us/step - loss: 0.2017 - accuracy: 0.9289 - val_loss: 0.4965 - val_accuracy: 0.8037\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 264us/step - loss: 0.2132 - accuracy: 0.9316 - val_loss: 0.4314 - val_accuracy: 0.8221\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 194us/step - loss: 0.1986 - accuracy: 0.9263 - val_loss: 0.4392 - val_accuracy: 0.8528\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.2080 - accuracy: 0.9342 - val_loss: 0.4768 - val_accuracy: 0.8037\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.2083 - accuracy: 0.9237 - val_loss: 0.4555 - val_accuracy: 0.8221\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1964 - accuracy: 0.9579 - val_loss: 0.4202 - val_accuracy: 0.8466\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1832 - accuracy: 0.9447 - val_loss: 0.4137 - val_accuracy: 0.8589\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.2136 - accuracy: 0.9342 - val_loss: 0.4423 - val_accuracy: 0.8160\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2220 - accuracy: 0.9263 - val_loss: 0.4250 - val_accuracy: 0.8405\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1933 - accuracy: 0.9211 - val_loss: 0.4370 - val_accuracy: 0.8160\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1981 - accuracy: 0.9289 - val_loss: 0.4302 - val_accuracy: 0.8282\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.2051 - accuracy: 0.9289 - val_loss: 0.4082 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1999 - accuracy: 0.9316 - val_loss: 0.4102 - val_accuracy: 0.8834\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1632 - accuracy: 0.9474 - val_loss: 0.4348 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1721 - accuracy: 0.9526 - val_loss: 0.4236 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1663 - accuracy: 0.9447 - val_loss: 0.4005 - val_accuracy: 0.8834\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1623 - accuracy: 0.9526 - val_loss: 0.4327 - val_accuracy: 0.8466\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.1702 - accuracy: 0.9316 - val_loss: 0.4357 - val_accuracy: 0.8160\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2175 - accuracy: 0.9184 - val_loss: 0.4371 - val_accuracy: 0.8589\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1967 - accuracy: 0.9289 - val_loss: 0.4278 - val_accuracy: 0.8773\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1852 - accuracy: 0.9316 - val_loss: 0.3994 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 198us/step - loss: 0.1616 - accuracy: 0.9395 - val_loss: 0.3977 - val_accuracy: 0.8773\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 266us/step - loss: 0.1585 - accuracy: 0.9474 - val_loss: 0.3943 - val_accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.1472 - accuracy: 0.9526 - val_loss: 0.4080 - val_accuracy: 0.8896\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 291us/step - loss: 0.1628 - accuracy: 0.9553 - val_loss: 0.4446 - val_accuracy: 0.8282\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.1808 - accuracy: 0.9316 - val_loss: 0.4160 - val_accuracy: 0.8712\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 277us/step - loss: 0.1743 - accuracy: 0.9447 - val_loss: 0.4479 - val_accuracy: 0.8466\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 269us/step - loss: 0.2284 - accuracy: 0.9184 - val_loss: 0.4941 - val_accuracy: 0.8282\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 247us/step - loss: 0.1713 - accuracy: 0.9395 - val_loss: 0.7436 - val_accuracy: 0.7546\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.1887 - accuracy: 0.9211 - val_loss: 0.4947 - val_accuracy: 0.7914\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1431 - accuracy: 0.9395 - val_loss: 0.4121 - val_accuracy: 0.8896\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1445 - accuracy: 0.9526 - val_loss: 0.4067 - val_accuracy: 0.9018\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1719 - accuracy: 0.9368 - val_loss: 0.4330 - val_accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1962 - accuracy: 0.9132 - val_loss: 0.4104 - val_accuracy: 0.8896\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 213us/step - loss: 0.1828 - accuracy: 0.9421 - val_loss: 0.5317 - val_accuracy: 0.7853\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 318us/step - loss: 0.1862 - accuracy: 0.9368 - val_loss: 0.3997 - val_accuracy: 0.8712\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 250us/step - loss: 0.1483 - accuracy: 0.9500 - val_loss: 0.5359 - val_accuracy: 0.8098\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.93 - 0s 241us/step - loss: 0.1769 - accuracy: 0.9316 - val_loss: 0.4171 - val_accuracy: 0.8528\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.1429 - accuracy: 0.9553 - val_loss: 0.3973 - val_accuracy: 0.8773\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1413 - accuracy: 0.9526 - val_loss: 0.3908 - val_accuracy: 0.9080\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1402 - accuracy: 0.9526 - val_loss: 0.4810 - val_accuracy: 0.8344\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1567 - accuracy: 0.9447 - val_loss: 0.4701 - val_accuracy: 0.8221\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1647 - accuracy: 0.9342 - val_loss: 0.5223 - val_accuracy: 0.8037\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1501 - accuracy: 0.9421 - val_loss: 0.4499 - val_accuracy: 0.8160\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1319 - accuracy: 0.9500 - val_loss: 0.5202 - val_accuracy: 0.8037\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1462 - accuracy: 0.9447 - val_loss: 0.5778 - val_accuracy: 0.8344\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1741 - accuracy: 0.9316 - val_loss: 0.4450 - val_accuracy: 0.8466\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.1224 - accuracy: 0.9526 - val_loss: 0.4202 - val_accuracy: 0.8957\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 248us/step - loss: 0.1313 - accuracy: 0.9526 - val_loss: 0.3987 - val_accuracy: 0.9018\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 273us/step - loss: 0.1605 - accuracy: 0.9421 - val_loss: 0.4969 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1551 - accuracy: 0.9342 - val_loss: 0.4155 - val_accuracy: 0.9018\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1355 - accuracy: 0.9553 - val_loss: 0.4082 - val_accuracy: 0.8834\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.1222 - accuracy: 0.9474 - val_loss: 0.4294 - val_accuracy: 0.8957\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 267us/step - loss: 0.1167 - accuracy: 0.9684 - val_loss: 0.4657 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 216us/step - loss: 0.1192 - accuracy: 0.9658 - val_loss: 0.4506 - val_accuracy: 0.8712\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.1182 - accuracy: 0.9658 - val_loss: 0.4125 - val_accuracy: 0.8896\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.1057 - accuracy: 0.9658 - val_loss: 0.4287 - val_accuracy: 0.8712\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.1517 - accuracy: 0.9447 - val_loss: 0.5334 - val_accuracy: 0.8282\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.1368 - accuracy: 0.9474 - val_loss: 0.6148 - val_accuracy: 0.8344\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1584 - accuracy: 0.9395 - val_loss: 0.4841 - val_accuracy: 0.8773\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1476 - accuracy: 0.9368 - val_loss: 0.5824 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1463 - accuracy: 0.9395 - val_loss: 0.4396 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1345 - accuracy: 0.9421 - val_loss: 0.3977 - val_accuracy: 0.9018\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1106 - accuracy: 0.9684 - val_loss: 0.4593 - val_accuracy: 0.8528\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1134 - accuracy: 0.9579 - val_loss: 0.4410 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3faad208>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 111us/step\n",
      "over-sampling test accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0,\n",
       "       0, 2, 0, 0, 1, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2,\n",
       "       1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 2, 0, 1, 0, 1, 2, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 2, 0, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0,\n",
       "       2, 1, 1, 1, 2, 0, 0, 1, 1, 0, 0, 2, 1, 2, 0, 2, 1, 0, 2, 0, 0, 1,\n",
       "       2, 1, 2, 2, 0, 0, 2, 0, 1, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0,\n",
       "       1, 2, 0, 0, 2, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS185</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NRS256</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>BCH-SA-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR1129     2     0\n",
       "1         NRS185     2     2\n",
       "2         NRS243     1     1\n",
       "3      BCH-SA-04     0     0\n",
       "4            504     1     1\n",
       "..           ...   ...   ...\n",
       "158  CFBREBSa131     2     2\n",
       "159  CFBREBSa133     1     1\n",
       "160       NRS256     2     2\n",
       "161      GA48963     1     1\n",
       "162    BCH-SA-07     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.974422e-01</td>\n",
       "      <td>1.631184e-02</td>\n",
       "      <td>0.086246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.993144e-05</td>\n",
       "      <td>1.100095e-02</td>\n",
       "      <td>0.988969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.563049e-04</td>\n",
       "      <td>9.869603e-01</td>\n",
       "      <td>0.012383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.991750e-01</td>\n",
       "      <td>3.741669e-06</td>\n",
       "      <td>0.000821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.667562e-03</td>\n",
       "      <td>9.664202e-01</td>\n",
       "      <td>0.023912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3.620039e-07</td>\n",
       "      <td>7.913741e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.459399e-03</td>\n",
       "      <td>9.621805e-01</td>\n",
       "      <td>0.036360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>8.193681e-06</td>\n",
       "      <td>1.064882e-02</td>\n",
       "      <td>0.989343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2.966928e-06</td>\n",
       "      <td>9.835654e-01</td>\n",
       "      <td>0.016432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3.301910e-01</td>\n",
       "      <td>5.557241e-01</td>\n",
       "      <td>0.114085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    8.974422e-01  1.631184e-02  0.086246\n",
       "1    2.993144e-05  1.100095e-02  0.988969\n",
       "2    6.563049e-04  9.869603e-01  0.012383\n",
       "3    9.991750e-01  3.741669e-06  0.000821\n",
       "4    9.667562e-03  9.664202e-01  0.023912\n",
       "..            ...           ...       ...\n",
       "158  3.620039e-07  7.913741e-07  0.999999\n",
       "159  1.459399e-03  9.621805e-01  0.036360\n",
       "160  8.193681e-06  1.064882e-02  0.989343\n",
       "161  2.966928e-06  9.835654e-01  0.016432\n",
       "162  3.301910e-01  5.557241e-01  0.114085\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p11p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.1164 - accuracy: 0.9553 - val_loss: 0.4266 - val_accuracy: 0.8896\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1273 - accuracy: 0.9474 - val_loss: 0.4278 - val_accuracy: 0.8896\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1513 - accuracy: 0.9289 - val_loss: 0.4885 - val_accuracy: 0.8589\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1330 - accuracy: 0.9447 - val_loss: 0.5197 - val_accuracy: 0.8528\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1301 - accuracy: 0.9474 - val_loss: 0.5138 - val_accuracy: 0.8160\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1491 - accuracy: 0.9342 - val_loss: 0.4683 - val_accuracy: 0.8466\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.4165 - val_accuracy: 0.8957\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1405 - accuracy: 0.9605 - val_loss: 0.4195 - val_accuracy: 0.8896\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1208 - accuracy: 0.9605 - val_loss: 0.4403 - val_accuracy: 0.8896\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1898 - accuracy: 0.9316 - val_loss: 0.5754 - val_accuracy: 0.8160\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1434 - accuracy: 0.9421 - val_loss: 0.5354 - val_accuracy: 0.8528\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1329 - accuracy: 0.9500 - val_loss: 0.4230 - val_accuracy: 0.8957\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1022 - accuracy: 0.9658 - val_loss: 0.4343 - val_accuracy: 0.8650\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1217 - accuracy: 0.9579 - val_loss: 0.4191 - val_accuracy: 0.8896\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1174 - accuracy: 0.9632 - val_loss: 0.4238 - val_accuracy: 0.8957\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1071 - accuracy: 0.9632 - val_loss: 0.4497 - val_accuracy: 0.8773\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 244us/step - loss: 0.1081 - accuracy: 0.9579 - val_loss: 0.5828 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1304 - accuracy: 0.9632 - val_loss: 0.4782 - val_accuracy: 0.8712\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1072 - accuracy: 0.9658 - val_loss: 0.4341 - val_accuracy: 0.8957\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.1176 - accuracy: 0.9421 - val_loss: 0.4649 - val_accuracy: 0.8957\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1113 - accuracy: 0.9605 - val_loss: 0.4602 - val_accuracy: 0.8834\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1617 - accuracy: 0.9421 - val_loss: 0.4367 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1270 - accuracy: 0.9579 - val_loss: 0.4261 - val_accuracy: 0.8896\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1387 - accuracy: 0.9474 - val_loss: 0.4493 - val_accuracy: 0.8712\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1889 - accuracy: 0.9342 - val_loss: 0.6085 - val_accuracy: 0.8528\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1315 - accuracy: 0.9579 - val_loss: 0.5542 - val_accuracy: 0.8528\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1257 - accuracy: 0.9632 - val_loss: 0.4868 - val_accuracy: 0.8773\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1202 - accuracy: 0.9684 - val_loss: 0.4313 - val_accuracy: 0.8896\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 139us/step - loss: 0.1041 - accuracy: 0.9658 - val_loss: 0.4209 - val_accuracy: 0.8896\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1152 - accuracy: 0.9500 - val_loss: 0.4169 - val_accuracy: 0.8896\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.1144 - accuracy: 0.9474 - val_loss: 0.4268 - val_accuracy: 0.8773\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.1231 - accuracy: 0.9553 - val_loss: 0.4361 - val_accuracy: 0.8957\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.1187 - accuracy: 0.9553 - val_loss: 0.4667 - val_accuracy: 0.8834\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 325us/step - loss: 0.1170 - accuracy: 0.9500 - val_loss: 0.4318 - val_accuracy: 0.8896\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 290us/step - loss: 0.0950 - accuracy: 0.9632 - val_loss: 0.4488 - val_accuracy: 0.8957\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.0998 - accuracy: 0.9632 - val_loss: 0.4258 - val_accuracy: 0.8834\n",
      "Epoch 37/100\n",
      "256/380 [===================>..........] - ETA: 0s - loss: 0.0929 - accuracy: 0.9648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.112898). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9711 - val_loss: 0.4612 - val_accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1058 - accuracy: 0.9579 - val_loss: 0.4572 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.1003 - accuracy: 0.9632 - val_loss: 0.4499 - val_accuracy: 0.8834\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0981 - accuracy: 0.9763 - val_loss: 0.5676 - val_accuracy: 0.8528\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1318 - accuracy: 0.9553 - val_loss: 0.4464 - val_accuracy: 0.8834\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1309 - accuracy: 0.9553 - val_loss: 0.4567 - val_accuracy: 0.8773\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 297us/step - loss: 0.1054 - accuracy: 0.9605 - val_loss: 0.4406 - val_accuracy: 0.8773\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.1140 - accuracy: 0.9605 - val_loss: 0.5954 - val_accuracy: 0.8466\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.1460 - accuracy: 0.9421 - val_loss: 0.5612 - val_accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1387 - accuracy: 0.9421 - val_loss: 0.4341 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1235 - accuracy: 0.9421 - val_loss: 0.4318 - val_accuracy: 0.9018\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0992 - accuracy: 0.9632 - val_loss: 0.4327 - val_accuracy: 0.8957\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.0959 - accuracy: 0.9605 - val_loss: 0.4274 - val_accuracy: 0.8712\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0997 - accuracy: 0.9605 - val_loss: 0.4341 - val_accuracy: 0.9018\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1007 - accuracy: 0.9632 - val_loss: 0.4645 - val_accuracy: 0.8773\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0977 - accuracy: 0.9632 - val_loss: 0.5777 - val_accuracy: 0.8098\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1066 - accuracy: 0.9605 - val_loss: 0.4499 - val_accuracy: 0.8834\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1077 - accuracy: 0.9632 - val_loss: 0.4131 - val_accuracy: 0.8896\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1096 - accuracy: 0.9500 - val_loss: 0.4965 - val_accuracy: 0.8344\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1529 - accuracy: 0.9237 - val_loss: 0.4403 - val_accuracy: 0.8896\n",
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1072 - accuracy: 0.9553 - val_loss: 0.4933 - val_accuracy: 0.8282\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.0991 - accuracy: 0.9579 - val_loss: 0.4660 - val_accuracy: 0.8589\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1011 - accuracy: 0.9579 - val_loss: 0.4622 - val_accuracy: 0.9018\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0999 - accuracy: 0.9658 - val_loss: 0.5006 - val_accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.0900 - accuracy: 0.9684 - val_loss: 0.4297 - val_accuracy: 0.8957\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0809 - accuracy: 0.9737 - val_loss: 0.4584 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1008 - accuracy: 0.9579 - val_loss: 0.5523 - val_accuracy: 0.8160\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 227us/step - loss: 0.1065 - accuracy: 0.9579 - val_loss: 0.4397 - val_accuracy: 0.8957\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1145 - accuracy: 0.9553 - val_loss: 0.4740 - val_accuracy: 0.8773\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 291us/step - loss: 0.1016 - accuracy: 0.9684 - val_loss: 0.5223 - val_accuracy: 0.8834\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 436us/step - loss: 0.0876 - accuracy: 0.9737 - val_loss: 0.4982 - val_accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 245us/step - loss: 0.0909 - accuracy: 0.9658 - val_loss: 0.4833 - val_accuracy: 0.8773\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.0959 - accuracy: 0.9632 - val_loss: 0.5137 - val_accuracy: 0.8834\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.0886 - accuracy: 0.9684 - val_loss: 0.4289 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.0999 - accuracy: 0.9605 - val_loss: 0.4319 - val_accuracy: 0.9018\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.1071 - accuracy: 0.9500 - val_loss: 0.4275 - val_accuracy: 0.8834\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.1157 - accuracy: 0.9526 - val_loss: 0.4308 - val_accuracy: 0.8834\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 259us/step - loss: 0.0929 - accuracy: 0.9605 - val_loss: 0.4928 - val_accuracy: 0.8528\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.0969 - accuracy: 0.9579 - val_loss: 0.5389 - val_accuracy: 0.8344\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.1036 - accuracy: 0.9526 - val_loss: 0.4645 - val_accuracy: 0.8773\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.9684 - val_loss: 0.4437 - val_accuracy: 0.8773\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 188us/step - loss: 0.0963 - accuracy: 0.9605 - val_loss: 0.4217 - val_accuracy: 0.9018\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1206 - accuracy: 0.9579 - val_loss: 0.4027 - val_accuracy: 0.8896\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.0910 - accuracy: 0.9684 - val_loss: 0.4116 - val_accuracy: 0.8957\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.0904 - accuracy: 0.9658 - val_loss: 0.4239 - val_accuracy: 0.8834\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.4071 - val_accuracy: 0.8957\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.0872 - accuracy: 0.9684 - val_loss: 0.5240 - val_accuracy: 0.8589\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.1080 - accuracy: 0.9526 - val_loss: 0.5348 - val_accuracy: 0.8589\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 269us/step - loss: 0.0798 - accuracy: 0.9632 - val_loss: 0.4323 - val_accuracy: 0.8957\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.0767 - accuracy: 0.9763 - val_loss: 0.4151 - val_accuracy: 0.9080\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 256us/step - loss: 0.0808 - accuracy: 0.9658 - val_loss: 0.4437 - val_accuracy: 0.8957\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 429us/step - loss: 0.0750 - accuracy: 0.9789 - val_loss: 0.4514 - val_accuracy: 0.8834\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 245us/step - loss: 0.0817 - accuracy: 0.9737 - val_loss: 0.4755 - val_accuracy: 0.8773\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 252us/step - loss: 0.0817 - accuracy: 0.9684 - val_loss: 0.4370 - val_accuracy: 0.9018\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.0966 - accuracy: 0.9684 - val_loss: 0.4279 - val_accuracy: 0.8957\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.4487 - val_accuracy: 0.8957\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 259us/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.4505 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.4364 - val_accuracy: 0.8957\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 216us/step - loss: 0.0780 - accuracy: 0.9816 - val_loss: 0.4368 - val_accuracy: 0.9018\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0801 - accuracy: 0.9658 - val_loss: 0.4176 - val_accuracy: 0.8957\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.0876 - accuracy: 0.9605 - val_loss: 0.4627 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.0832 - accuracy: 0.9737 - val_loss: 0.5056 - val_accuracy: 0.8344\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.0946 - accuracy: 0.9579 - val_loss: 0.4300 - val_accuracy: 0.9018\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.0809 - accuracy: 0.9763 - val_loss: 0.4452 - val_accuracy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 95.91%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.97442200e-01, 1.63118400e-02, 8.62458350e-02],\n",
       "       [2.99314380e-05, 1.10009540e-02, 9.88969100e-01],\n",
       "       [6.56304900e-04, 9.86960300e-01, 1.23833580e-02],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [9.66756200e-03, 9.66420230e-01, 2.39122250e-02],\n",
       "       [8.64572600e-01, 8.71616300e-02, 4.82658300e-02],\n",
       "       [9.93526000e-01, 3.33350450e-03, 3.14053820e-03],\n",
       "       [8.65304700e-01, 5.64754120e-05, 1.34638950e-01],\n",
       "       [1.83631820e-02, 7.75294000e-01, 2.06342790e-01],\n",
       "       [5.09233630e-03, 9.89207500e-01, 5.70020170e-03],\n",
       "       [5.66357340e-05, 9.59045700e-03, 9.90352900e-01],\n",
       "       [9.90899440e-01, 8.96445600e-03, 1.36130740e-04],\n",
       "       [8.72450050e-01, 9.89174900e-02, 2.86324640e-02],\n",
       "       [7.33481100e-04, 1.03320780e-02, 9.88934460e-01],\n",
       "       [9.90899440e-01, 8.96445600e-03, 1.36130740e-04],\n",
       "       [9.95040240e-01, 4.47050170e-04, 4.51269650e-03],\n",
       "       [1.48833220e-04, 2.67485730e-02, 9.73102600e-01],\n",
       "       [1.06803660e-02, 8.55337900e-03, 9.80766300e-01],\n",
       "       [7.01661170e-01, 1.78269540e-01, 1.20069170e-01],\n",
       "       [1.00448680e-01, 7.92603250e-01, 1.06948030e-01],\n",
       "       [7.88663400e-03, 9.72648860e-01, 1.94644980e-02],\n",
       "       [9.97336450e-01, 3.98002560e-04, 2.26552800e-03],\n",
       "       [9.87032400e-01, 2.79329020e-04, 1.26882880e-02],\n",
       "       [8.71443400e-08, 8.08925600e-03, 9.91910640e-01],\n",
       "       [9.99391440e-01, 5.34570500e-04, 7.40035400e-05],\n",
       "       [9.98547400e-01, 6.89910900e-04, 7.62694500e-04],\n",
       "       [3.30190960e-01, 5.55724100e-01, 1.14084974e-01],\n",
       "       [9.66756200e-03, 9.66420230e-01, 2.39122250e-02],\n",
       "       [9.98051300e-01, 1.69697420e-03, 2.51814500e-04],\n",
       "       [9.99391440e-01, 5.34570500e-04, 7.40035400e-05],\n",
       "       [3.31504360e-03, 9.09567300e-01, 8.71177700e-02],\n",
       "       [1.02420680e-03, 2.34298570e-01, 7.64677170e-01],\n",
       "       [2.09890420e-03, 9.92122500e-01, 5.77856650e-03],\n",
       "       [6.58785400e-01, 3.06949020e-01, 3.42656080e-02],\n",
       "       [2.09890420e-03, 9.92122500e-01, 5.77856650e-03],\n",
       "       [9.93973800e-01, 2.63414760e-03, 3.39208870e-03],\n",
       "       [5.20243080e-03, 9.89558340e-01, 5.23921060e-03],\n",
       "       [8.30847800e-04, 9.98040600e-01, 1.12865410e-03],\n",
       "       [2.96692770e-06, 9.83565400e-01, 1.64316820e-02],\n",
       "       [6.01605470e-03, 9.52332700e-01, 4.16513700e-02],\n",
       "       [9.99411000e-01, 1.04636220e-06, 5.87969550e-04],\n",
       "       [9.96651100e-03, 3.52244230e-01, 6.37789200e-01],\n",
       "       [9.95514800e-01, 8.82384340e-05, 4.39685700e-03],\n",
       "       [4.93725100e-03, 4.54844150e-01, 5.40218600e-01],\n",
       "       [2.96692770e-06, 9.83565400e-01, 1.64316820e-02],\n",
       "       [1.07322330e-02, 7.77010140e-01, 2.12257600e-01],\n",
       "       [1.52417900e-04, 4.29078000e-03, 9.95556800e-01],\n",
       "       [3.30160900e-06, 9.80980750e-01, 1.90159420e-02],\n",
       "       [9.97611760e-01, 8.30857600e-04, 1.55744520e-03],\n",
       "       [7.01661170e-01, 1.78269540e-01, 1.20069170e-01],\n",
       "       [9.94247800e-01, 5.39021100e-03, 3.62028660e-04],\n",
       "       [5.76144320e-08, 5.13965570e-05, 9.99948500e-01],\n",
       "       [3.32477520e-06, 9.98609200e-01, 1.38742730e-03],\n",
       "       [2.33569260e-04, 9.87382100e-01, 1.23843440e-02],\n",
       "       [3.68019330e-03, 9.91786800e-01, 4.53302030e-03],\n",
       "       [1.43339250e-01, 2.48290160e-05, 8.56635900e-01],\n",
       "       [8.45363500e-03, 5.08082500e-01, 4.83463820e-01],\n",
       "       [1.32921950e-08, 5.28306400e-06, 9.99994750e-01],\n",
       "       [9.95514800e-01, 8.82384340e-05, 4.39685700e-03],\n",
       "       [5.25173900e-02, 4.24722730e-02, 9.05010340e-01],\n",
       "       [9.96230200e-01, 2.41916130e-05, 3.74551820e-03],\n",
       "       [4.68515930e-03, 9.84898600e-01, 1.04162125e-02],\n",
       "       [9.98547400e-01, 6.89910900e-04, 7.62694500e-04],\n",
       "       [1.39077590e-01, 8.13244340e-01, 4.76780600e-02],\n",
       "       [5.20243080e-03, 9.89558340e-01, 5.23921060e-03],\n",
       "       [6.13774800e-01, 1.69382580e-05, 3.86208300e-01],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [9.87032400e-01, 2.79329020e-04, 1.26882880e-02],\n",
       "       [1.45939870e-03, 9.62180500e-01, 3.63600330e-02],\n",
       "       [1.45877050e-02, 3.45858800e-01, 6.39553500e-01],\n",
       "       [8.72450050e-01, 9.89174900e-02, 2.86324640e-02],\n",
       "       [5.20243080e-03, 9.89558340e-01, 5.23921060e-03],\n",
       "       [9.98547400e-01, 6.89910900e-04, 7.62694500e-04],\n",
       "       [3.22139430e-03, 9.94122450e-01, 2.65609850e-03],\n",
       "       [1.11116420e-01, 1.22002460e-01, 7.66881100e-01],\n",
       "       [6.62166100e-05, 9.49209750e-01, 5.07240600e-02],\n",
       "       [5.20243080e-03, 9.89558340e-01, 5.23921060e-03],\n",
       "       [5.13319900e-07, 1.27438030e-04, 9.99872100e-01],\n",
       "       [9.93526000e-01, 3.33350450e-03, 3.14053820e-03],\n",
       "       [1.66810450e-02, 8.29154730e-01, 1.54164270e-01],\n",
       "       [1.45939870e-03, 9.62180500e-01, 3.63600330e-02],\n",
       "       [9.73446000e-05, 9.94743700e-01, 5.15889560e-03],\n",
       "       [6.13774800e-01, 1.69382580e-05, 3.86208300e-01],\n",
       "       [3.90133720e-05, 9.75838240e-01, 2.41228030e-02],\n",
       "       [2.96692770e-06, 9.83565400e-01, 1.64316820e-02],\n",
       "       [9.97611760e-01, 8.30857600e-04, 1.55744520e-03],\n",
       "       [9.93526000e-01, 3.33350450e-03, 3.14053820e-03],\n",
       "       [6.56304900e-04, 9.86960300e-01, 1.23833580e-02],\n",
       "       [6.07705270e-04, 9.98657460e-01, 7.34814500e-04],\n",
       "       [3.30936450e-05, 3.05349600e-03, 9.96913430e-01],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [1.00448680e-01, 7.92603250e-01, 1.06948030e-01],\n",
       "       [2.30681150e-01, 4.29702600e-01, 3.39616300e-01],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [3.18838500e-03, 9.94729340e-01, 2.08226680e-03],\n",
       "       [9.54810500e-09, 3.66878600e-07, 9.99999640e-01],\n",
       "       [1.36546310e-08, 3.61314920e-04, 9.99638700e-01],\n",
       "       [9.87032400e-01, 2.79329020e-04, 1.26882880e-02],\n",
       "       [1.33529520e-05, 8.55146600e-04, 9.99131500e-01],\n",
       "       [8.72450050e-01, 9.89174900e-02, 2.86324640e-02],\n",
       "       [9.96962960e-01, 2.78777770e-03, 2.49180700e-04],\n",
       "       [9.96962960e-01, 2.78777770e-03, 2.49180700e-04],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [6.01605470e-03, 9.52332700e-01, 4.16513700e-02],\n",
       "       [5.50663400e-09, 6.90096430e-06, 9.99993100e-01],\n",
       "       [3.30190960e-01, 5.55724100e-01, 1.14084974e-01],\n",
       "       [1.24922400e-04, 9.95729000e-01, 4.14603670e-03],\n",
       "       [8.54278800e-01, 6.84011730e-03, 1.38881010e-01],\n",
       "       [8.72450050e-01, 9.89174900e-02, 2.86324640e-02],\n",
       "       [5.77208900e-01, 6.91167540e-04, 4.22099920e-01],\n",
       "       [1.98564790e-02, 1.35642140e-02, 9.66579260e-01],\n",
       "       [2.09890420e-03, 9.92122500e-01, 5.77856650e-03],\n",
       "       [2.19423880e-01, 6.40942400e-01, 1.39633720e-01],\n",
       "       [4.68515930e-03, 9.84898600e-01, 1.04162125e-02],\n",
       "       [6.61872500e-02, 2.19846330e-05, 9.33790700e-01],\n",
       "       [9.96962960e-01, 2.78777770e-03, 2.49180700e-04],\n",
       "       [9.95533940e-01, 1.01461150e-04, 4.36462650e-03],\n",
       "       [6.01605470e-03, 9.52332700e-01, 4.16513700e-02],\n",
       "       [5.05116680e-03, 9.87120800e-01, 7.82803800e-03],\n",
       "       [9.93149200e-01, 3.00981400e-03, 3.84095260e-03],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [3.66430240e-03, 6.06014430e-02, 9.35734300e-01],\n",
       "       [2.53713910e-02, 9.50039570e-01, 2.45890540e-02],\n",
       "       [6.42050640e-04, 4.95974540e-01, 5.03383400e-01],\n",
       "       [9.99391440e-01, 5.34570500e-04, 7.40035400e-05],\n",
       "       [4.29079380e-10, 1.30953470e-06, 9.99998700e-01],\n",
       "       [1.10839170e-03, 6.03142740e-01, 3.95748850e-01],\n",
       "       [9.96962960e-01, 2.78777770e-03, 2.49180700e-04],\n",
       "       [8.56646400e-07, 1.35892370e-02, 9.86409840e-01],\n",
       "       [9.87032400e-01, 2.79329020e-04, 1.26882880e-02],\n",
       "       [9.94247800e-01, 5.39021100e-03, 3.62028660e-04],\n",
       "       [4.68515930e-03, 9.84898600e-01, 1.04162125e-02],\n",
       "       [1.06626960e-04, 4.79630100e-03, 9.95097100e-01],\n",
       "       [8.30847800e-04, 9.98040600e-01, 1.12865410e-03],\n",
       "       [2.03792770e-06, 2.81365100e-02, 9.71861500e-01],\n",
       "       [1.47800970e-03, 2.70657780e-01, 7.27864200e-01],\n",
       "       [9.75571330e-01, 1.38441000e-02, 1.05845420e-02],\n",
       "       [9.94247800e-01, 5.39021100e-03, 3.62028660e-04],\n",
       "       [6.00569230e-03, 9.71443200e-02, 8.96849930e-01],\n",
       "       [9.97674400e-01, 1.56650610e-03, 7.59092300e-04],\n",
       "       [1.20660104e-01, 6.67358640e-01, 2.11981270e-01],\n",
       "       [4.70417000e-03, 1.88375880e-02, 9.76458200e-01],\n",
       "       [9.99391440e-01, 5.34570500e-04, 7.40035400e-05],\n",
       "       [1.25177200e-09, 2.93718680e-05, 9.99970700e-01],\n",
       "       [2.81732370e-03, 4.08467800e-01, 5.88714840e-01],\n",
       "       [2.52914470e-02, 3.36909560e-01, 6.37799000e-01],\n",
       "       [7.01661170e-01, 1.78269540e-01, 1.20069170e-01],\n",
       "       [3.32477520e-06, 9.98609200e-01, 1.38742730e-03],\n",
       "       [9.95040240e-01, 4.47050170e-04, 4.51269650e-03],\n",
       "       [5.31160700e-03, 4.69705340e-01, 5.24983050e-01],\n",
       "       [9.99175000e-01, 3.74166920e-06, 8.21327700e-04],\n",
       "       [9.96962960e-01, 2.78777770e-03, 2.49180700e-04],\n",
       "       [2.19423880e-01, 6.40942400e-01, 1.39633720e-01],\n",
       "       [9.95514800e-01, 8.82384340e-05, 4.39685700e-03],\n",
       "       [3.09928800e-03, 7.78901000e-01, 2.17999640e-01],\n",
       "       [1.19243405e-05, 2.00278650e-04, 9.99787870e-01],\n",
       "       [9.97336450e-01, 3.98002560e-04, 2.26552800e-03],\n",
       "       [6.08780200e-01, 2.18972940e-01, 1.72246930e-01],\n",
       "       [3.62003870e-07, 7.91374130e-07, 9.99998800e-01],\n",
       "       [1.45939870e-03, 9.62180500e-01, 3.63600330e-02],\n",
       "       [8.19368100e-06, 1.06488170e-02, 9.89343050e-01],\n",
       "       [2.96692770e-06, 9.83565400e-01, 1.64316820e-02],\n",
       "       [3.30190960e-01, 5.55724100e-01, 1.14084974e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p11presabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676716193535766"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676716193535766"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS027     0\n",
       "1       CFBRSa07     0\n",
       "2       CFBRSa27     1\n",
       "3            504     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       SR3569     2\n",
       "159       NRS243     1\n",
       "160      GA48963     1\n",
       "161          504     1\n",
       "162  CFBREBSa123     0\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 372us/step - loss: 1.1094 - accuracy: 0.4237 - val_loss: 1.0615 - val_accuracy: 0.5153\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.9539 - accuracy: 0.5368 - val_loss: 0.9731 - val_accuracy: 0.4601\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.8438 - accuracy: 0.5947 - val_loss: 0.9613 - val_accuracy: 0.5828\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.8118 - accuracy: 0.6263 - val_loss: 0.8207 - val_accuracy: 0.5828\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 279us/step - loss: 0.7041 - accuracy: 0.6842 - val_loss: 0.7843 - val_accuracy: 0.5767\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.6801 - accuracy: 0.6868 - val_loss: 0.8201 - val_accuracy: 0.6258\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.6499 - accuracy: 0.7211 - val_loss: 0.7232 - val_accuracy: 0.6748\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.5927 - accuracy: 0.7816 - val_loss: 0.6578 - val_accuracy: 0.7546\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.5406 - accuracy: 0.7868 - val_loss: 0.6267 - val_accuracy: 0.7117\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.5129 - accuracy: 0.8211 - val_loss: 0.6035 - val_accuracy: 0.7730\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.5071 - accuracy: 0.8263 - val_loss: 0.6778 - val_accuracy: 0.7178\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.5145 - accuracy: 0.8000 - val_loss: 0.6157 - val_accuracy: 0.7362\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.4450 - accuracy: 0.8421 - val_loss: 0.5475 - val_accuracy: 0.7730\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.4288 - accuracy: 0.8684 - val_loss: 0.5340 - val_accuracy: 0.7362\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 274us/step - loss: 0.4113 - accuracy: 0.8658 - val_loss: 0.4981 - val_accuracy: 0.8098\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.4062 - accuracy: 0.8737 - val_loss: 0.4824 - val_accuracy: 0.8221\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.4004 - accuracy: 0.8579 - val_loss: 0.5634 - val_accuracy: 0.7423\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 271us/step - loss: 0.4275 - accuracy: 0.8632 - val_loss: 0.4686 - val_accuracy: 0.7914\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 217us/step - loss: 0.4196 - accuracy: 0.8368 - val_loss: 0.4501 - val_accuracy: 0.8528\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 223us/step - loss: 0.4470 - accuracy: 0.8421 - val_loss: 0.5003 - val_accuracy: 0.7730\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 210us/step - loss: 0.3634 - accuracy: 0.8763 - val_loss: 0.4831 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 176us/step - loss: 0.3346 - accuracy: 0.8868 - val_loss: 0.4712 - val_accuracy: 0.7914\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.3257 - accuracy: 0.8974 - val_loss: 0.4159 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.3029 - accuracy: 0.9105 - val_loss: 0.4126 - val_accuracy: 0.8344\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.3074 - accuracy: 0.9105 - val_loss: 0.4136 - val_accuracy: 0.8405\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2962 - accuracy: 0.9000 - val_loss: 0.3775 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.3089 - accuracy: 0.9158 - val_loss: 0.4007 - val_accuracy: 0.8528\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 453us/step - loss: 0.2892 - accuracy: 0.9184 - val_loss: 0.3933 - val_accuracy: 0.8834\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 218us/step - loss: 0.2764 - accuracy: 0.9289 - val_loss: 0.4098 - val_accuracy: 0.8773\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 276us/step - loss: 0.2919 - accuracy: 0.9053 - val_loss: 0.4462 - val_accuracy: 0.8221\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 321us/step - loss: 0.3121 - accuracy: 0.9026 - val_loss: 0.4108 - val_accuracy: 0.8589\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 371us/step - loss: 0.3561 - accuracy: 0.8579 - val_loss: 0.3827 - val_accuracy: 0.8221\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 276us/step - loss: 0.3547 - accuracy: 0.8763 - val_loss: 0.3997 - val_accuracy: 0.8160\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 255us/step - loss: 0.2730 - accuracy: 0.9132 - val_loss: 0.3395 - val_accuracy: 0.8712\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 311us/step - loss: 0.2388 - accuracy: 0.9342 - val_loss: 0.3382 - val_accuracy: 0.8957\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 346us/step - loss: 0.2390 - accuracy: 0.9263 - val_loss: 0.3261 - val_accuracy: 0.9202\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 317us/step - loss: 0.2240 - accuracy: 0.9368 - val_loss: 0.3603 - val_accuracy: 0.8650\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 425us/step - loss: 0.2268 - accuracy: 0.9289 - val_loss: 0.3280 - val_accuracy: 0.8957\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 392us/step - loss: 0.2208 - accuracy: 0.9474 - val_loss: 0.3488 - val_accuracy: 0.8834\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 299us/step - loss: 0.2244 - accuracy: 0.9395 - val_loss: 0.3649 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 379us/step - loss: 0.2242 - accuracy: 0.9316 - val_loss: 0.3130 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 372us/step - loss: 0.2328 - accuracy: 0.9237 - val_loss: 0.3406 - val_accuracy: 0.8896\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 252us/step - loss: 0.2062 - accuracy: 0.9421 - val_loss: 0.3208 - val_accuracy: 0.8834\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.2254 - accuracy: 0.9184 - val_loss: 0.3529 - val_accuracy: 0.8650\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.2214 - accuracy: 0.9395 - val_loss: 0.3466 - val_accuracy: 0.8773\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.2080 - accuracy: 0.9421 - val_loss: 0.3483 - val_accuracy: 0.9018\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.2209 - accuracy: 0.9342 - val_loss: 0.3318 - val_accuracy: 0.8957\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.1944 - accuracy: 0.9526 - val_loss: 0.2908 - val_accuracy: 0.9141\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.2058 - accuracy: 0.9395 - val_loss: 0.3609 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.2195 - accuracy: 0.9263 - val_loss: 0.2908 - val_accuracy: 0.9080\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1741 - accuracy: 0.9474 - val_loss: 0.3420 - val_accuracy: 0.8712\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.1958 - accuracy: 0.9395 - val_loss: 0.2933 - val_accuracy: 0.8834\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.1821 - accuracy: 0.9526 - val_loss: 0.2871 - val_accuracy: 0.9202\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.1809 - accuracy: 0.9368 - val_loss: 0.2916 - val_accuracy: 0.9018\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1663 - accuracy: 0.9474 - val_loss: 0.2939 - val_accuracy: 0.9264\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1665 - accuracy: 0.9500 - val_loss: 0.3497 - val_accuracy: 0.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1772 - accuracy: 0.9474 - val_loss: 0.3161 - val_accuracy: 0.9141\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1791 - accuracy: 0.9316 - val_loss: 0.3075 - val_accuracy: 0.8896\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1916 - accuracy: 0.9368 - val_loss: 0.2902 - val_accuracy: 0.8957\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1857 - accuracy: 0.9316 - val_loss: 0.3364 - val_accuracy: 0.9018\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1769 - accuracy: 0.9316 - val_loss: 0.3201 - val_accuracy: 0.9141\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1654 - accuracy: 0.9526 - val_loss: 0.3470 - val_accuracy: 0.8712\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.1876 - accuracy: 0.9395 - val_loss: 0.3068 - val_accuracy: 0.9018\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1985 - accuracy: 0.9158 - val_loss: 0.2859 - val_accuracy: 0.9080\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1496 - accuracy: 0.9605 - val_loss: 0.3003 - val_accuracy: 0.9080\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1527 - accuracy: 0.9500 - val_loss: 0.2927 - val_accuracy: 0.9141\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1569 - accuracy: 0.9421 - val_loss: 0.2735 - val_accuracy: 0.9202\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1481 - accuracy: 0.9579 - val_loss: 0.3723 - val_accuracy: 0.8834\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1865 - accuracy: 0.9368 - val_loss: 0.3035 - val_accuracy: 0.9141\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1594 - accuracy: 0.9553 - val_loss: 0.2846 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1460 - accuracy: 0.9579 - val_loss: 0.3055 - val_accuracy: 0.9141\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1366 - accuracy: 0.9605 - val_loss: 0.3007 - val_accuracy: 0.9018\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1459 - accuracy: 0.9500 - val_loss: 0.3010 - val_accuracy: 0.9080\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1631 - accuracy: 0.9526 - val_loss: 0.2686 - val_accuracy: 0.9141\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1383 - accuracy: 0.9553 - val_loss: 0.3012 - val_accuracy: 0.9018\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1656 - accuracy: 0.9421 - val_loss: 0.2924 - val_accuracy: 0.8834\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1375 - accuracy: 0.9605 - val_loss: 0.2720 - val_accuracy: 0.9264\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1465 - accuracy: 0.9500 - val_loss: 0.3337 - val_accuracy: 0.8834\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1769 - accuracy: 0.9263 - val_loss: 0.3247 - val_accuracy: 0.8834\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1796 - accuracy: 0.9316 - val_loss: 0.2649 - val_accuracy: 0.9202\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1328 - accuracy: 0.9605 - val_loss: 0.2934 - val_accuracy: 0.8589\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1540 - accuracy: 0.9447 - val_loss: 0.2646 - val_accuracy: 0.9202\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1291 - accuracy: 0.9605 - val_loss: 0.2778 - val_accuracy: 0.9080\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1264 - accuracy: 0.9605 - val_loss: 0.2570 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1541 - accuracy: 0.9526 - val_loss: 0.2973 - val_accuracy: 0.8773\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1589 - accuracy: 0.9316 - val_loss: 0.2599 - val_accuracy: 0.9387\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1765 - accuracy: 0.9368 - val_loss: 0.2523 - val_accuracy: 0.9325\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.2469 - accuracy: 0.9000 - val_loss: 0.4891 - val_accuracy: 0.8589\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 371us/step - loss: 0.1812 - accuracy: 0.9289 - val_loss: 0.4260 - val_accuracy: 0.8344\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1905 - accuracy: 0.9211 - val_loss: 0.3787 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.1589 - accuracy: 0.9447 - val_loss: 0.4148 - val_accuracy: 0.8650\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1636 - accuracy: 0.9316 - val_loss: 0.5138 - val_accuracy: 0.8344\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.1573 - accuracy: 0.9447 - val_loss: 0.2646 - val_accuracy: 0.9264\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 138us/step - loss: 0.1250 - accuracy: 0.9500 - val_loss: 0.2721 - val_accuracy: 0.9080\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.1255 - accuracy: 0.9579 - val_loss: 0.2715 - val_accuracy: 0.9080\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.1254 - accuracy: 0.9605 - val_loss: 0.3524 - val_accuracy: 0.8712\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.1228 - accuracy: 0.9579 - val_loss: 0.3383 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1395 - accuracy: 0.9474 - val_loss: 0.3036 - val_accuracy: 0.9018\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.2452 - val_accuracy: 0.9202\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 293us/step - loss: 0.1593 - accuracy: 0.9421 - val_loss: 0.3823 - val_accuracy: 0.8344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63c078358>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 106us/step\n",
      "over-sampling test accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0,\n",
       "       1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 0, 2, 1, 2, 0,\n",
       "       2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0,\n",
       "       1, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 1, 0, 0, 2, 0, 0,\n",
       "       2, 0, 2, 2, 1, 0, 0, 2, 1, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 0, 2,\n",
       "       1, 1, 0, 2, 2, 1, 1, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NRS243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>GA48963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS027     0     0\n",
       "1       CFBRSa07     0     0\n",
       "2       CFBRSa27     1     0\n",
       "3            504     1     2\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       SR3569     2     2\n",
       "159       NRS243     1     1\n",
       "160      GA48963     1     1\n",
       "161          504     1     2\n",
       "162  CFBREBSa123     0     0\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999576</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998123</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786800</td>\n",
       "      <td>0.097460</td>\n",
       "      <td>0.115741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.311864</td>\n",
       "      <td>0.307633</td>\n",
       "      <td>0.380503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.043488</td>\n",
       "      <td>0.115955</td>\n",
       "      <td>0.840557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.988498</td>\n",
       "      <td>0.011483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>0.212369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.311864</td>\n",
       "      <td>0.307633</td>\n",
       "      <td>0.380503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.999576  0.000147  0.000277\n",
       "1    0.998123  0.000037  0.001840\n",
       "2    0.786800  0.097460  0.115741\n",
       "3    0.311864  0.307633  0.380503\n",
       "4    0.999031  0.000525  0.000444\n",
       "..        ...       ...       ...\n",
       "158  0.043488  0.115955  0.840557\n",
       "159  0.000020  0.988498  0.011483\n",
       "160  0.000330  0.787300  0.212369\n",
       "161  0.311864  0.307633  0.380503\n",
       "162  0.999745  0.000233  0.000022\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p11p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.1152 - accuracy: 0.9658 - val_loss: 0.3429 - val_accuracy: 0.8957\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.1111 - accuracy: 0.9684 - val_loss: 0.3723 - val_accuracy: 0.8896\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1146 - accuracy: 0.9579 - val_loss: 0.2945 - val_accuracy: 0.9141\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1142 - accuracy: 0.9605 - val_loss: 0.3076 - val_accuracy: 0.8957\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1091 - accuracy: 0.9632 - val_loss: 0.2894 - val_accuracy: 0.9141\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1100 - accuracy: 0.9632 - val_loss: 0.3068 - val_accuracy: 0.9018\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1036 - accuracy: 0.9684 - val_loss: 0.3211 - val_accuracy: 0.9018\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1238 - accuracy: 0.9500 - val_loss: 0.2793 - val_accuracy: 0.9141\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1240 - accuracy: 0.9632 - val_loss: 0.2791 - val_accuracy: 0.9080\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.1246 - accuracy: 0.9474 - val_loss: 0.2840 - val_accuracy: 0.9202\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1291 - accuracy: 0.9500 - val_loss: 0.3436 - val_accuracy: 0.8957\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1186 - accuracy: 0.9605 - val_loss: 0.5053 - val_accuracy: 0.8405\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1330 - accuracy: 0.9395 - val_loss: 0.3401 - val_accuracy: 0.9018\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.1640 - accuracy: 0.9316 - val_loss: 0.4437 - val_accuracy: 0.8528\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1499 - accuracy: 0.9447 - val_loss: 0.3189 - val_accuracy: 0.9018\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1376 - accuracy: 0.9368 - val_loss: 0.3936 - val_accuracy: 0.8896\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 196us/step - loss: 0.1162 - accuracy: 0.9658 - val_loss: 0.2983 - val_accuracy: 0.9018\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 180us/step - loss: 0.1104 - accuracy: 0.9553 - val_loss: 0.2910 - val_accuracy: 0.9264\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.1186 - accuracy: 0.9684 - val_loss: 0.2911 - val_accuracy: 0.9018\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.1202 - accuracy: 0.9605 - val_loss: 0.2879 - val_accuracy: 0.9141\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.1027 - accuracy: 0.9711 - val_loss: 0.3031 - val_accuracy: 0.9141\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.0932 - accuracy: 0.9711 - val_loss: 0.3125 - val_accuracy: 0.9080\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.0982 - accuracy: 0.9579 - val_loss: 0.3658 - val_accuracy: 0.9018\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 172us/step - loss: 0.1256 - accuracy: 0.9632 - val_loss: 0.3688 - val_accuracy: 0.9018\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0929 - accuracy: 0.9763 - val_loss: 0.3931 - val_accuracy: 0.8896\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 192us/step - loss: 0.1161 - accuracy: 0.9605 - val_loss: 0.3150 - val_accuracy: 0.9141\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.1120 - accuracy: 0.9605 - val_loss: 0.2795 - val_accuracy: 0.9080\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 202us/step - loss: 0.0988 - accuracy: 0.9684 - val_loss: 0.3168 - val_accuracy: 0.9080\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.1036 - accuracy: 0.9684 - val_loss: 0.3052 - val_accuracy: 0.9141\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.1073 - accuracy: 0.9526 - val_loss: 0.4217 - val_accuracy: 0.8650\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.1360 - accuracy: 0.9605 - val_loss: 0.5324 - val_accuracy: 0.8773\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.1252 - accuracy: 0.9395 - val_loss: 0.4030 - val_accuracy: 0.8834\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 286us/step - loss: 0.0989 - accuracy: 0.9684 - val_loss: 0.3810 - val_accuracy: 0.8896\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 327us/step - loss: 0.1052 - accuracy: 0.9658 - val_loss: 0.3859 - val_accuracy: 0.9018\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.4278 - val_accuracy: 0.8589\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 181us/step - loss: 0.1233 - accuracy: 0.9579 - val_loss: 0.3522 - val_accuracy: 0.9018\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 147us/step - loss: 0.0921 - accuracy: 0.9711 - val_loss: 0.3412 - val_accuracy: 0.8896\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.1090 - accuracy: 0.9553 - val_loss: 0.3065 - val_accuracy: 0.9080\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.3279 - val_accuracy: 0.9018\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 375us/step - loss: 0.0861 - accuracy: 0.9684 - val_loss: 0.2885 - val_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.1040 - accuracy: 0.9632 - val_loss: 0.3171 - val_accuracy: 0.9018\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 214us/step - loss: 0.1192 - accuracy: 0.9579 - val_loss: 0.2909 - val_accuracy: 0.9202\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 203us/step - loss: 0.0941 - accuracy: 0.9684 - val_loss: 0.3566 - val_accuracy: 0.9018\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 151us/step - loss: 0.0890 - accuracy: 0.9789 - val_loss: 0.4353 - val_accuracy: 0.8773\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1001 - accuracy: 0.9684 - val_loss: 0.4330 - val_accuracy: 0.8834\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0935 - accuracy: 0.9737 - val_loss: 0.2986 - val_accuracy: 0.9202\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.3281 - val_accuracy: 0.9018\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0831 - accuracy: 0.9789 - val_loss: 0.4031 - val_accuracy: 0.8712\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0950 - accuracy: 0.9711 - val_loss: 0.2964 - val_accuracy: 0.9141\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0952 - accuracy: 0.9737 - val_loss: 0.3812 - val_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1207 - accuracy: 0.9553 - val_loss: 0.2921 - val_accuracy: 0.9202\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1844 - accuracy: 0.9263 - val_loss: 0.2819 - val_accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1041 - accuracy: 0.9605 - val_loss: 0.2991 - val_accuracy: 0.9080\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0828 - accuracy: 0.9658 - val_loss: 0.3396 - val_accuracy: 0.9018\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0912 - accuracy: 0.9684 - val_loss: 0.5232 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1371 - accuracy: 0.9342 - val_loss: 0.5781 - val_accuracy: 0.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1212 - accuracy: 0.9579 - val_loss: 0.3645 - val_accuracy: 0.8896\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0853 - accuracy: 0.9763 - val_loss: 0.4644 - val_accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1146 - accuracy: 0.9605 - val_loss: 0.3138 - val_accuracy: 0.9018\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1224 - accuracy: 0.9474 - val_loss: 0.3808 - val_accuracy: 0.8957\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1208 - accuracy: 0.9605 - val_loss: 0.3385 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1038 - accuracy: 0.9553 - val_loss: 0.3072 - val_accuracy: 0.9202\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1041 - accuracy: 0.9632 - val_loss: 0.3233 - val_accuracy: 0.9080\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1013 - accuracy: 0.9684 - val_loss: 0.4929 - val_accuracy: 0.8773\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1040 - accuracy: 0.9684 - val_loss: 0.3347 - val_accuracy: 0.8957\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.0811 - accuracy: 0.9711 - val_loss: 0.2755 - val_accuracy: 0.9202\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0857 - accuracy: 0.9789 - val_loss: 0.4528 - val_accuracy: 0.8773\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.0954 - accuracy: 0.9579 - val_loss: 0.4204 - val_accuracy: 0.8896\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.1217 - accuracy: 0.9579 - val_loss: 0.5425 - val_accuracy: 0.8528\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.1110 - accuracy: 0.9526 - val_loss: 0.3362 - val_accuracy: 0.8957\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1218 - accuracy: 0.9500 - val_loss: 0.3590 - val_accuracy: 0.8528\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1096 - accuracy: 0.9526 - val_loss: 0.2897 - val_accuracy: 0.9202\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 0.2783 - val_accuracy: 0.9264\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0834 - accuracy: 0.9763 - val_loss: 0.3120 - val_accuracy: 0.9080\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0790 - accuracy: 0.9684 - val_loss: 0.2971 - val_accuracy: 0.9264\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0895 - accuracy: 0.9711 - val_loss: 0.2924 - val_accuracy: 0.9264\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0947 - accuracy: 0.9605 - val_loss: 0.3769 - val_accuracy: 0.8773\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1095 - accuracy: 0.9605 - val_loss: 0.4057 - val_accuracy: 0.8896\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0801 - accuracy: 0.9711 - val_loss: 0.3350 - val_accuracy: 0.9080\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0875 - accuracy: 0.9711 - val_loss: 0.3129 - val_accuracy: 0.9080\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 341us/step - loss: 0.0762 - accuracy: 0.9658 - val_loss: 0.3032 - val_accuracy: 0.9202\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0886 - accuracy: 0.9711 - val_loss: 0.3610 - val_accuracy: 0.9018\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1098 - accuracy: 0.9553 - val_loss: 0.4507 - val_accuracy: 0.8834\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0870 - accuracy: 0.9632 - val_loss: 0.3810 - val_accuracy: 0.8896\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.4988 - val_accuracy: 0.8773\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.0896 - accuracy: 0.9684 - val_loss: 0.3335 - val_accuracy: 0.8896\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0905 - accuracy: 0.9658 - val_loss: 0.3578 - val_accuracy: 0.8957\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0701 - accuracy: 0.9711 - val_loss: 0.3007 - val_accuracy: 0.9202\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0792 - accuracy: 0.9711 - val_loss: 0.3608 - val_accuracy: 0.8896\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.0943 - accuracy: 0.9658 - val_loss: 0.2745 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1431 - accuracy: 0.9447 - val_loss: 0.3335 - val_accuracy: 0.8773\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0909 - accuracy: 0.9684 - val_loss: 0.3384 - val_accuracy: 0.9080\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 132us/step - loss: 0.0696 - accuracy: 0.9737 - val_loss: 0.4518 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0948 - accuracy: 0.9684 - val_loss: 0.4153 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 0.3916 - val_accuracy: 0.8896\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0821 - accuracy: 0.9789 - val_loss: 0.2932 - val_accuracy: 0.9264\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0827 - accuracy: 0.9632 - val_loss: 0.3689 - val_accuracy: 0.9018\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0872 - accuracy: 0.9658 - val_loss: 0.2949 - val_accuracy: 0.9264\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0783 - accuracy: 0.9737 - val_loss: 0.3272 - val_accuracy: 0.9202\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 133us/step - loss: 0.0690 - accuracy: 0.9763 - val_loss: 0.3098 - val_accuracy: 0.9202\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.27%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [9.98123200e-01, 3.70915080e-05, 1.83963000e-03],\n",
       "       [7.86799600e-01, 9.74595900e-02, 1.15740790e-01],\n",
       "       [3.11864170e-01, 3.07633220e-01, 3.80502670e-01],\n",
       "       [9.99031200e-01, 5.24683600e-04, 4.44119880e-04],\n",
       "       [9.86831070e-01, 3.20975900e-05, 1.31367890e-02],\n",
       "       [9.99031200e-01, 5.24683600e-04, 4.44119880e-04],\n",
       "       [2.43028400e-02, 6.10687900e-01, 3.65009250e-01],\n",
       "       [7.86799600e-01, 9.74595900e-02, 1.15740790e-01],\n",
       "       [8.78673050e-03, 9.86969950e-01, 4.24322900e-03],\n",
       "       [1.06192560e-08, 3.17531560e-05, 9.99968300e-01],\n",
       "       [9.98318850e-01, 1.28406790e-03, 3.96977470e-04],\n",
       "       [1.45408140e-02, 7.86452200e-01, 1.99007030e-01],\n",
       "       [9.76358900e-02, 6.30768500e-01, 2.71595600e-01],\n",
       "       [1.50144810e-05, 9.86956950e-01, 1.30279360e-02],\n",
       "       [6.05480560e-14, 1.36032190e-09, 1.00000000e+00],\n",
       "       [4.85778400e-06, 8.92515400e-01, 1.07479620e-01],\n",
       "       [2.10603400e-02, 9.01900900e-01, 7.70387600e-02],\n",
       "       [4.67377630e-01, 1.13849270e-01, 4.18773140e-01],\n",
       "       [3.18165200e-05, 1.74191810e-04, 9.99794070e-01],\n",
       "       [3.30300240e-04, 7.87300300e-01, 2.12369470e-01],\n",
       "       [9.99432600e-01, 6.13217070e-06, 5.61278430e-04],\n",
       "       [5.67682550e-04, 9.98887000e-01, 5.45392740e-04],\n",
       "       [9.99432600e-01, 6.13217070e-06, 5.61278430e-04],\n",
       "       [1.77227760e-03, 1.11578265e-02, 9.87069960e-01],\n",
       "       [9.87508000e-01, 1.03030110e-03, 1.14616530e-02],\n",
       "       [8.78673050e-03, 9.86969950e-01, 4.24322900e-03],\n",
       "       [9.99432600e-01, 6.13217070e-06, 5.61278430e-04],\n",
       "       [4.89272300e-04, 8.90072300e-01, 1.09438530e-01],\n",
       "       [6.36381860e-01, 1.18964190e-03, 3.62428500e-01],\n",
       "       [9.95948140e-01, 2.93443030e-03, 1.11749090e-03],\n",
       "       [9.94873600e-01, 1.54535500e-04, 4.97188700e-03],\n",
       "       [9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [5.53425740e-05, 1.00507816e-04, 9.99844100e-01],\n",
       "       [1.70469200e-06, 9.90098060e-01, 9.90026600e-03],\n",
       "       [9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [7.40063100e-09, 4.75412130e-05, 9.99952440e-01],\n",
       "       [1.39516720e-03, 9.94026300e-01, 4.57854480e-03],\n",
       "       [9.94873600e-01, 1.54535500e-04, 4.97188700e-03],\n",
       "       [9.94346700e-01, 2.07353900e-03, 3.57974000e-03],\n",
       "       [9.94873600e-01, 1.54535500e-04, 4.97188700e-03],\n",
       "       [9.98121800e-01, 3.64545600e-04, 1.51356810e-03],\n",
       "       [1.38832080e-07, 2.49385080e-04, 9.99750440e-01],\n",
       "       [1.31369950e-06, 9.87712860e-01, 1.22857860e-02],\n",
       "       [1.01062990e-02, 9.85099850e-01, 4.79385100e-03],\n",
       "       [9.99140400e-01, 4.58476600e-04, 4.01155640e-04],\n",
       "       [9.89673260e-01, 3.27422000e-03, 7.05249370e-03],\n",
       "       [3.11864170e-01, 3.07633220e-01, 3.80502670e-01],\n",
       "       [3.97567400e-02, 9.53236000e-01, 7.00732040e-03],\n",
       "       [9.97389850e-01, 2.05371370e-04, 2.40489240e-03],\n",
       "       [9.33855350e-01, 1.44788770e-02, 5.16658100e-02],\n",
       "       [7.86799600e-01, 9.74595900e-02, 1.15740790e-01],\n",
       "       [9.94346700e-01, 2.07353900e-03, 3.57974000e-03],\n",
       "       [2.10603400e-02, 9.01900900e-01, 7.70387600e-02],\n",
       "       [9.99140400e-01, 4.58476600e-04, 4.01155640e-04],\n",
       "       [5.44462900e-01, 1.71538330e-02, 4.38383250e-01],\n",
       "       [2.97910870e-02, 2.15969180e-02, 9.48612000e-01],\n",
       "       [9.89673260e-01, 3.27422000e-03, 7.05249370e-03],\n",
       "       [9.95948140e-01, 2.93443030e-03, 1.11749090e-03],\n",
       "       [9.95948140e-01, 2.93443030e-03, 1.11749090e-03],\n",
       "       [1.16182220e-08, 2.65289830e-07, 9.99999760e-01],\n",
       "       [4.89272300e-04, 8.90072300e-01, 1.09438530e-01],\n",
       "       [1.17641140e-05, 3.36715820e-05, 9.99954600e-01],\n",
       "       [9.99940900e-01, 8.53258650e-07, 5.82573160e-05],\n",
       "       [9.19766650e-10, 1.07264360e-06, 9.99998900e-01],\n",
       "       [1.74077200e-01, 6.75638800e-01, 1.50283930e-01],\n",
       "       [9.99493100e-01, 4.05990650e-05, 4.66182070e-04],\n",
       "       [1.26041470e-01, 1.44885060e-01, 7.29073460e-01],\n",
       "       [7.61800840e-09, 9.99712050e-01, 2.87982520e-04],\n",
       "       [4.67439970e-03, 2.97978670e-01, 6.97346900e-01],\n",
       "       [2.98352030e-08, 2.97826850e-05, 9.99970200e-01],\n",
       "       [9.99031200e-01, 5.24683600e-04, 4.44119880e-04],\n",
       "       [1.31369950e-06, 9.87712860e-01, 1.22857860e-02],\n",
       "       [3.00079900e-08, 1.96835100e-06, 9.99998000e-01],\n",
       "       [3.39808430e-02, 6.86400200e-02, 8.97379160e-01],\n",
       "       [3.11864170e-01, 3.07633220e-01, 3.80502670e-01],\n",
       "       [1.24647130e-10, 4.71183800e-10, 1.00000000e+00],\n",
       "       [9.98059100e-01, 4.06252700e-04, 1.53462830e-03],\n",
       "       [9.90121600e-01, 1.31977800e-03, 8.55854600e-03],\n",
       "       [4.07500980e-01, 6.43273440e-02, 5.28171660e-01],\n",
       "       [2.87358280e-01, 6.18817450e-01, 9.38243300e-02],\n",
       "       [8.92932500e-05, 2.24470800e-04, 9.99686240e-01],\n",
       "       [4.85778400e-06, 8.92515400e-01, 1.07479620e-01],\n",
       "       [9.90121600e-01, 1.31977800e-03, 8.55854600e-03],\n",
       "       [3.11864170e-01, 3.07633220e-01, 3.80502670e-01],\n",
       "       [4.85778400e-06, 8.92515400e-01, 1.07479620e-01],\n",
       "       [6.75216200e-05, 1.20832150e-02, 9.87849200e-01],\n",
       "       [6.64100600e-01, 1.07294020e-01, 2.28605340e-01],\n",
       "       [2.17160020e-04, 7.55650400e-06, 9.99775350e-01],\n",
       "       [3.03167050e-02, 3.22420880e-04, 9.69360900e-01],\n",
       "       [2.93284280e-02, 8.17609800e-03, 9.62495450e-01],\n",
       "       [9.99031200e-01, 5.24683600e-04, 4.44119880e-04],\n",
       "       [2.17561070e-02, 9.44739200e-01, 3.35046280e-02],\n",
       "       [9.98629330e-01, 1.15214180e-03, 2.18546280e-04],\n",
       "       [9.99940900e-01, 8.53258650e-07, 5.82573160e-05],\n",
       "       [3.71515100e-02, 9.47731800e-01, 1.51167220e-02],\n",
       "       [9.96693730e-01, 4.04121020e-05, 3.26585630e-03],\n",
       "       [3.68472600e-07, 4.85829600e-06, 9.99994750e-01],\n",
       "       [4.19976200e-05, 3.13022970e-03, 9.96827800e-01],\n",
       "       [9.98629330e-01, 1.15214180e-03, 2.18546280e-04],\n",
       "       [9.97389850e-01, 2.05371370e-04, 2.40489240e-03],\n",
       "       [9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [5.67682550e-04, 9.98887000e-01, 5.45392740e-04],\n",
       "       [9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [5.67682550e-04, 9.98887000e-01, 5.45392740e-04],\n",
       "       [6.05736280e-05, 9.32518900e-03, 9.90614300e-01],\n",
       "       [2.85388800e-02, 8.72398260e-01, 9.90628200e-02],\n",
       "       [3.83326150e-07, 4.33413370e-05, 9.99956250e-01],\n",
       "       [4.89272300e-04, 8.90072300e-01, 1.09438530e-01],\n",
       "       [9.96693730e-01, 4.04121020e-05, 3.26585630e-03],\n",
       "       [9.08861400e-05, 9.97719000e-01, 2.19005320e-03],\n",
       "       [2.87358280e-01, 6.18817450e-01, 9.38243300e-02],\n",
       "       [9.98123200e-01, 3.70915080e-05, 1.83963000e-03],\n",
       "       [9.97389850e-01, 2.05371370e-04, 2.40489240e-03],\n",
       "       [3.48381640e-01, 5.86151200e-01, 6.54671500e-02],\n",
       "       [3.57701120e-10, 3.47761150e-06, 9.99996540e-01],\n",
       "       [1.19533620e-05, 1.66717500e-08, 9.99988100e-01],\n",
       "       [8.71055600e-02, 8.09446040e-01, 1.03448450e-01],\n",
       "       [2.28424630e-05, 9.79169850e-01, 2.08073100e-02],\n",
       "       [9.99432600e-01, 6.13217070e-06, 5.61278430e-04],\n",
       "       [4.22113700e-01, 1.55778570e-01, 4.22107800e-01],\n",
       "       [1.01062990e-02, 9.85099850e-01, 4.79385100e-03],\n",
       "       [9.95442350e-02, 7.02261550e-02, 8.30229600e-01],\n",
       "       [3.51186170e-02, 3.32129540e-01, 6.32751900e-01],\n",
       "       [3.30300240e-04, 7.87300300e-01, 2.12369470e-01],\n",
       "       [9.99576300e-01, 1.47134720e-04, 2.76561740e-04],\n",
       "       [2.74073000e-02, 7.57575630e-01, 2.15017080e-01],\n",
       "       [9.96514260e-01, 1.77968690e-04, 3.30777630e-03],\n",
       "       [9.94873600e-01, 1.54535500e-04, 4.97188700e-03],\n",
       "       [5.74463860e-04, 5.35129700e-03, 9.94074300e-01],\n",
       "       [9.98121800e-01, 3.64545600e-04, 1.51356810e-03],\n",
       "       [8.14016340e-01, 1.27154800e-01, 5.88288000e-02],\n",
       "       [1.46019250e-12, 5.42902900e-09, 1.00000000e+00],\n",
       "       [9.94346700e-01, 2.07353900e-03, 3.57974000e-03],\n",
       "       [6.92558900e-08, 2.93303900e-02, 9.70669570e-01],\n",
       "       [1.25800770e-04, 7.57887100e-04, 9.99116360e-01],\n",
       "       [1.25955930e-02, 9.78396100e-01, 9.00819500e-03],\n",
       "       [7.01192700e-01, 6.58032400e-02, 2.33004080e-01],\n",
       "       [8.34829800e-01, 8.71168100e-02, 7.80534500e-02],\n",
       "       [1.24273480e-01, 4.30855600e-03, 8.71417940e-01],\n",
       "       [1.25955930e-02, 9.78396100e-01, 9.00819500e-03],\n",
       "       [6.02593460e-08, 1.04623310e-06, 9.99998900e-01],\n",
       "       [9.33855350e-01, 1.44788770e-02, 5.16658100e-02],\n",
       "       [1.22752700e-06, 5.50462200e-06, 9.99993300e-01],\n",
       "       [9.98121800e-01, 3.64545600e-04, 1.51356810e-03],\n",
       "       [5.22299200e-01, 2.56559370e-01, 2.21141490e-01],\n",
       "       [9.98629330e-01, 1.15214180e-03, 2.18546280e-04],\n",
       "       [1.24273480e-01, 4.30855600e-03, 8.71417940e-01],\n",
       "       [6.45022200e-02, 2.76123120e-02, 9.07885500e-01],\n",
       "       [1.26145390e-04, 1.03427320e-03, 9.98839560e-01],\n",
       "       [4.89272300e-04, 8.90072300e-01, 1.09438530e-01],\n",
       "       [9.93682400e-01, 1.86000140e-04, 6.13162200e-03],\n",
       "       [9.99140400e-01, 4.58476600e-04, 4.01155640e-04],\n",
       "       [5.29416300e-02, 5.41459860e-03, 9.41643800e-01],\n",
       "       [4.92967940e-03, 6.48211700e-01, 3.46858530e-01],\n",
       "       [3.24175000e-02, 9.44351800e-01, 2.32307780e-02],\n",
       "       [7.01192700e-01, 6.58032400e-02, 2.33004080e-01],\n",
       "       [2.14136650e-02, 3.06709260e-02, 9.47915430e-01],\n",
       "       [4.34882980e-02, 1.15955130e-01, 8.40556560e-01],\n",
       "       [1.95843790e-05, 9.88497730e-01, 1.14827175e-02],\n",
       "       [3.30300240e-04, 7.87300300e-01, 2.12369470e-01],\n",
       "       [3.11864170e-01, 3.07633220e-01, 3.80502670e-01],\n",
       "       [9.99744950e-01, 2.33342730e-04, 2.17402180e-05]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p11presabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735566675933649"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735566675933649"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS149     0\n",
       "1          EUH13     0\n",
       "2         NRS106     2\n",
       "3         NRS214     1\n",
       "4    CFBREBSa129     0\n",
       "..           ...   ...\n",
       "158       NRS027     0\n",
       "159     CFBRSa70     2\n",
       "160  CFBREBSa130     0\n",
       "161       NRS214     1\n",
       "162       NRS073     1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 376us/step - loss: 1.0742 - accuracy: 0.4368 - val_loss: 0.9354 - val_accuracy: 0.5583\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.8840 - accuracy: 0.5921 - val_loss: 0.8311 - val_accuracy: 0.6871\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.8074 - accuracy: 0.6421 - val_loss: 0.7803 - val_accuracy: 0.6074\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.7470 - accuracy: 0.6526 - val_loss: 0.7290 - val_accuracy: 0.6564\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.6966 - accuracy: 0.6605 - val_loss: 0.7041 - val_accuracy: 0.6994\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.6481 - accuracy: 0.7263 - val_loss: 0.6580 - val_accuracy: 0.7301\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.5962 - accuracy: 0.7553 - val_loss: 0.6277 - val_accuracy: 0.7546\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 179us/step - loss: 0.5655 - accuracy: 0.7816 - val_loss: 0.6415 - val_accuracy: 0.7423\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.5619 - accuracy: 0.7711 - val_loss: 0.5788 - val_accuracy: 0.7607\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.4821 - accuracy: 0.8474 - val_loss: 0.5333 - val_accuracy: 0.8221\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.4927 - accuracy: 0.8105 - val_loss: 0.5086 - val_accuracy: 0.8098\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.4577 - accuracy: 0.8289 - val_loss: 0.5458 - val_accuracy: 0.7791\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 343us/step - loss: 0.4324 - accuracy: 0.8421 - val_loss: 0.5043 - val_accuracy: 0.8344\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.3968 - accuracy: 0.8684 - val_loss: 0.5458 - val_accuracy: 0.7975\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.3938 - accuracy: 0.8526 - val_loss: 0.5241 - val_accuracy: 0.8160\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 264us/step - loss: 0.4011 - accuracy: 0.8211 - val_loss: 0.4757 - val_accuracy: 0.8221\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 263us/step - loss: 0.3578 - accuracy: 0.8974 - val_loss: 0.4524 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.3377 - accuracy: 0.9079 - val_loss: 0.4536 - val_accuracy: 0.8466\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 241us/step - loss: 0.3284 - accuracy: 0.8868 - val_loss: 0.4382 - val_accuracy: 0.8098\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.3103 - accuracy: 0.9158 - val_loss: 0.5181 - val_accuracy: 0.8037\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.3601 - accuracy: 0.8737 - val_loss: 0.4076 - val_accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.3778 - accuracy: 0.8605 - val_loss: 0.4572 - val_accuracy: 0.8344\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.3053 - accuracy: 0.9079 - val_loss: 0.3958 - val_accuracy: 0.8773\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.2694 - accuracy: 0.9316 - val_loss: 0.4544 - val_accuracy: 0.8282\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.2883 - accuracy: 0.9079 - val_loss: 0.4936 - val_accuracy: 0.7975\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 297us/step - loss: 0.2866 - accuracy: 0.8947 - val_loss: 0.4190 - val_accuracy: 0.8405\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 500us/step - loss: 0.2547 - accuracy: 0.9395 - val_loss: 0.4320 - val_accuracy: 0.8466\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 338us/step - loss: 0.2485 - accuracy: 0.9368 - val_loss: 0.5784 - val_accuracy: 0.8037\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 251us/step - loss: 0.2709 - accuracy: 0.9184 - val_loss: 0.3946 - val_accuracy: 0.8650\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.2513 - accuracy: 0.9211 - val_loss: 0.3691 - val_accuracy: 0.8957\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 318us/step - loss: 0.2357 - accuracy: 0.9289 - val_loss: 0.4021 - val_accuracy: 0.8528\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.2405 - accuracy: 0.9289 - val_loss: 0.3678 - val_accuracy: 0.8896\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.2253 - accuracy: 0.9211 - val_loss: 0.3741 - val_accuracy: 0.8834\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 324us/step - loss: 0.2117 - accuracy: 0.9342 - val_loss: 0.4007 - val_accuracy: 0.8405\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.1974 - accuracy: 0.9605 - val_loss: 0.3823 - val_accuracy: 0.8896\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 465us/step - loss: 0.1930 - accuracy: 0.9632 - val_loss: 0.4406 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 386us/step - loss: 0.1996 - accuracy: 0.9526 - val_loss: 0.4838 - val_accuracy: 0.8405\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 291us/step - loss: 0.2136 - accuracy: 0.9105 - val_loss: 0.3598 - val_accuracy: 0.8773\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 215us/step - loss: 0.2210 - accuracy: 0.9263 - val_loss: 0.4493 - val_accuracy: 0.8712\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.2429 - accuracy: 0.9105 - val_loss: 0.4668 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 226us/step - loss: 0.2063 - accuracy: 0.9316 - val_loss: 0.3843 - val_accuracy: 0.8773\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 212us/step - loss: 0.2138 - accuracy: 0.9316 - val_loss: 0.3681 - val_accuracy: 0.8712\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 322us/step - loss: 0.1972 - accuracy: 0.9553 - val_loss: 0.3689 - val_accuracy: 0.8773\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 221us/step - loss: 0.1819 - accuracy: 0.9395 - val_loss: 0.3586 - val_accuracy: 0.8957\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 419us/step - loss: 0.1933 - accuracy: 0.9447 - val_loss: 0.3872 - val_accuracy: 0.8712\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 590us/step - loss: 0.1655 - accuracy: 0.9579 - val_loss: 0.4190 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 222us/step - loss: 0.1926 - accuracy: 0.9395 - val_loss: 0.3631 - val_accuracy: 0.8896\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.1853 - accuracy: 0.9421 - val_loss: 0.4012 - val_accuracy: 0.8773\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.1612 - accuracy: 0.9605 - val_loss: 0.3793 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 302us/step - loss: 0.1504 - accuracy: 0.9711 - val_loss: 0.4001 - val_accuracy: 0.8650\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.1742 - accuracy: 0.9526 - val_loss: 0.4183 - val_accuracy: 0.8712\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.1652 - accuracy: 0.9421 - val_loss: 0.4266 - val_accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1534 - accuracy: 0.9579 - val_loss: 0.5090 - val_accuracy: 0.8589\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.1473 - accuracy: 0.9711 - val_loss: 0.5082 - val_accuracy: 0.8405\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.1343 - accuracy: 0.9658 - val_loss: 0.3779 - val_accuracy: 0.8773\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 465us/step - loss: 0.1387 - accuracy: 0.9711 - val_loss: 0.4137 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.1402 - accuracy: 0.9711 - val_loss: 0.4537 - val_accuracy: 0.8650\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 204us/step - loss: 0.1281 - accuracy: 0.9737 - val_loss: 0.3668 - val_accuracy: 0.8834\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.1369 - accuracy: 0.9632 - val_loss: 0.3803 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 270us/step - loss: 0.1294 - accuracy: 0.9711 - val_loss: 0.3667 - val_accuracy: 0.8712\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.1286 - accuracy: 0.9658 - val_loss: 0.3577 - val_accuracy: 0.9018\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1220 - accuracy: 0.9763 - val_loss: 0.3518 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1451 - accuracy: 0.9632 - val_loss: 0.3487 - val_accuracy: 0.8957\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1379 - accuracy: 0.9632 - val_loss: 0.3857 - val_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 197us/step - loss: 0.1277 - accuracy: 0.9684 - val_loss: 0.4058 - val_accuracy: 0.8773\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 325us/step - loss: 0.1240 - accuracy: 0.9737 - val_loss: 0.4086 - val_accuracy: 0.8589\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.1385 - accuracy: 0.9605 - val_loss: 0.3807 - val_accuracy: 0.8896\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.1426 - accuracy: 0.9474 - val_loss: 0.3953 - val_accuracy: 0.8896\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.1276 - accuracy: 0.9658 - val_loss: 0.4627 - val_accuracy: 0.8589\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1218 - accuracy: 0.9684 - val_loss: 0.4581 - val_accuracy: 0.8650\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.1257 - accuracy: 0.9711 - val_loss: 0.4363 - val_accuracy: 0.8650\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 166us/step - loss: 0.1158 - accuracy: 0.9711 - val_loss: 0.4387 - val_accuracy: 0.8650\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1050 - accuracy: 0.9789 - val_loss: 0.3674 - val_accuracy: 0.8896\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 178us/step - loss: 0.1220 - accuracy: 0.9632 - val_loss: 0.3692 - val_accuracy: 0.8773\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 193us/step - loss: 0.1319 - accuracy: 0.9474 - val_loss: 0.4074 - val_accuracy: 0.8773\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 350us/step - loss: 0.1119 - accuracy: 0.9711 - val_loss: 0.4943 - val_accuracy: 0.8589\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1053 - accuracy: 0.9737 - val_loss: 0.4267 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 735us/step - loss: 0.1032 - accuracy: 0.9842 - val_loss: 0.3756 - val_accuracy: 0.8712\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 274us/step - loss: 0.1090 - accuracy: 0.9816 - val_loss: 0.3918 - val_accuracy: 0.8834\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.1080 - accuracy: 0.9789 - val_loss: 0.4894 - val_accuracy: 0.8712\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 162us/step - loss: 0.1306 - accuracy: 0.9579 - val_loss: 0.4837 - val_accuracy: 0.8650\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.1180 - accuracy: 0.9658 - val_loss: 0.6618 - val_accuracy: 0.8282\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 247us/step - loss: 0.1349 - accuracy: 0.9553 - val_loss: 0.6361 - val_accuracy: 0.8344\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 207us/step - loss: 0.1135 - accuracy: 0.9737 - val_loss: 0.5283 - val_accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.0989 - accuracy: 0.9763 - val_loss: 0.4650 - val_accuracy: 0.8650\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 267us/step - loss: 0.1092 - accuracy: 0.9711 - val_loss: 0.4362 - val_accuracy: 0.8712\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 184us/step - loss: 0.0873 - accuracy: 0.9789 - val_loss: 0.3938 - val_accuracy: 0.8773\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0886 - accuracy: 0.9842 - val_loss: 0.5254 - val_accuracy: 0.8589\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 161us/step - loss: 0.1096 - accuracy: 0.9684 - val_loss: 0.5656 - val_accuracy: 0.8466\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.0972 - accuracy: 0.9658 - val_loss: 0.5468 - val_accuracy: 0.8528\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.0857 - accuracy: 0.9816 - val_loss: 0.4496 - val_accuracy: 0.8712\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 159us/step - loss: 0.0867 - accuracy: 0.9789 - val_loss: 0.4749 - val_accuracy: 0.8589\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0941 - accuracy: 0.9789 - val_loss: 0.4042 - val_accuracy: 0.8834\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0932 - accuracy: 0.9816 - val_loss: 0.4341 - val_accuracy: 0.8773\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0840 - accuracy: 0.9842 - val_loss: 0.4125 - val_accuracy: 0.8834\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1102 - accuracy: 0.9658 - val_loss: 0.3795 - val_accuracy: 0.8650\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1075 - accuracy: 0.9632 - val_loss: 0.4387 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 289us/step - loss: 0.0960 - accuracy: 0.9684 - val_loss: 0.4436 - val_accuracy: 0.8712\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0942 - accuracy: 0.9737 - val_loss: 0.3929 - val_accuracy: 0.9018\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.1018 - accuracy: 0.9658 - val_loss: 0.3906 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a401b2f98>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 96us/step\n",
      "over-sampling test accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 2, 1, 2,\n",
       "       0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 0, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1,\n",
       "       2, 0, 2, 1, 0, 2, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1,\n",
       "       0, 1, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 0,\n",
       "       1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBREBSa130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS149     0     0\n",
       "1          EUH13     0     0\n",
       "2         NRS106     2     0\n",
       "3         NRS214     1     1\n",
       "4    CFBREBSa129     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS027     0     0\n",
       "159     CFBRSa70     2     1\n",
       "160  CFBREBSa130     0     0\n",
       "161       NRS214     1     1\n",
       "162       NRS073     1     1\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.930519e-01</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.874885e-01</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.017478e-01</td>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.024334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.036675e-02</td>\n",
       "      <td>0.939113</td>\n",
       "      <td>0.040520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.980913e-01</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>9.989587e-01</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2.886204e-01</td>\n",
       "      <td>0.697115</td>\n",
       "      <td>0.014265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>9.944845e-01</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2.036675e-02</td>\n",
       "      <td>0.939113</td>\n",
       "      <td>0.040520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.647558e-09</td>\n",
       "      <td>0.995643</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2\n",
       "0    9.930519e-01  0.003753  0.003196\n",
       "1    9.874885e-01  0.011873  0.000639\n",
       "2    9.017478e-01  0.073918  0.024334\n",
       "3    2.036675e-02  0.939113  0.040520\n",
       "4    9.980913e-01  0.001881  0.000028\n",
       "..            ...       ...       ...\n",
       "158  9.989587e-01  0.001020  0.000021\n",
       "159  2.886204e-01  0.697115  0.014265\n",
       "160  9.944845e-01  0.000317  0.005198\n",
       "161  2.036675e-02  0.939113  0.040520\n",
       "162  1.647558e-09  0.995643  0.004357\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p11p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.3017 - val_accuracy: 0.9080\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1138 - accuracy: 0.9632 - val_loss: 0.3227 - val_accuracy: 0.8834\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1030 - accuracy: 0.9711 - val_loss: 0.3063 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1039 - accuracy: 0.9737 - val_loss: 0.3373 - val_accuracy: 0.8896\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0858 - accuracy: 0.9816 - val_loss: 0.3640 - val_accuracy: 0.8896\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0963 - accuracy: 0.9763 - val_loss: 0.5135 - val_accuracy: 0.8466\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1192 - accuracy: 0.9632 - val_loss: 0.6584 - val_accuracy: 0.8221\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 149us/step - loss: 0.1202 - accuracy: 0.9500 - val_loss: 0.4336 - val_accuracy: 0.8773\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 146us/step - loss: 0.0999 - accuracy: 0.9711 - val_loss: 0.3949 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 154us/step - loss: 0.0768 - accuracy: 0.9789 - val_loss: 0.3937 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0855 - accuracy: 0.9763 - val_loss: 0.4584 - val_accuracy: 0.8589\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.3527 - val_accuracy: 0.8834\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.0721 - accuracy: 0.9816 - val_loss: 0.4039 - val_accuracy: 0.8712\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0697 - accuracy: 0.9816 - val_loss: 0.4077 - val_accuracy: 0.8650\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0726 - accuracy: 0.9842 - val_loss: 0.4105 - val_accuracy: 0.8712\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 143us/step - loss: 0.0702 - accuracy: 0.9763 - val_loss: 0.3729 - val_accuracy: 0.8773\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.0732 - accuracy: 0.9816 - val_loss: 0.5737 - val_accuracy: 0.8466\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 140us/step - loss: 0.1409 - accuracy: 0.9421 - val_loss: 0.4255 - val_accuracy: 0.8589\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1066 - accuracy: 0.9500 - val_loss: 0.3535 - val_accuracy: 0.8957\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.0905 - accuracy: 0.9763 - val_loss: 0.3317 - val_accuracy: 0.9018\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 0.3663 - val_accuracy: 0.8712\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 0.4258 - val_accuracy: 0.8650\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1476 - accuracy: 0.9368 - val_loss: 0.3463 - val_accuracy: 0.8957\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1186 - accuracy: 0.9632 - val_loss: 0.3972 - val_accuracy: 0.8773\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0662 - accuracy: 0.9816 - val_loss: 0.4267 - val_accuracy: 0.8650\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0905 - accuracy: 0.9658 - val_loss: 0.5155 - val_accuracy: 0.8589\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 128us/step - loss: 0.0842 - accuracy: 0.9711 - val_loss: 0.6764 - val_accuracy: 0.8466\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0943 - accuracy: 0.9737 - val_loss: 0.4420 - val_accuracy: 0.8712\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0661 - accuracy: 0.9842 - val_loss: 0.4958 - val_accuracy: 0.8589\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0637 - accuracy: 0.9816 - val_loss: 0.4373 - val_accuracy: 0.8650\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.0858 - accuracy: 0.9658 - val_loss: 0.3935 - val_accuracy: 0.8834\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 177us/step - loss: 0.0816 - accuracy: 0.9763 - val_loss: 0.3872 - val_accuracy: 0.8834\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 0.0915 - accuracy: 0.9711 - val_loss: 0.5113 - val_accuracy: 0.8528\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 338us/step - loss: 0.0825 - accuracy: 0.9711 - val_loss: 0.4083 - val_accuracy: 0.8712\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 287us/step - loss: 0.1079 - accuracy: 0.9632 - val_loss: 0.3057 - val_accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.1030 - accuracy: 0.9658 - val_loss: 0.3479 - val_accuracy: 0.8896\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.0657 - accuracy: 0.9737 - val_loss: 0.3554 - val_accuracy: 0.8834\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 182us/step - loss: 0.0725 - accuracy: 0.9737 - val_loss: 0.4483 - val_accuracy: 0.8773\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.0748 - accuracy: 0.9737 - val_loss: 0.5022 - val_accuracy: 0.8589\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 426us/step - loss: 0.0746 - accuracy: 0.9658 - val_loss: 0.4347 - val_accuracy: 0.8650\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 306us/step - loss: 0.0717 - accuracy: 0.9763 - val_loss: 0.4690 - val_accuracy: 0.8773\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.0620 - accuracy: 0.9842 - val_loss: 0.5306 - val_accuracy: 0.8589\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 286us/step - loss: 0.0652 - accuracy: 0.9868 - val_loss: 0.3736 - val_accuracy: 0.9018\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.3484 - val_accuracy: 0.8957\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.0636 - accuracy: 0.9816 - val_loss: 0.6121 - val_accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.0650 - accuracy: 0.9895 - val_loss: 0.3863 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0626 - accuracy: 0.9842 - val_loss: 0.4234 - val_accuracy: 0.8773\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.3857 - val_accuracy: 0.8773\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0667 - accuracy: 0.9763 - val_loss: 0.3752 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.4964 - val_accuracy: 0.8773\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0683 - accuracy: 0.9737 - val_loss: 0.4182 - val_accuracy: 0.8896\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.4012 - val_accuracy: 0.8896\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0488 - accuracy: 0.9895 - val_loss: 0.6476 - val_accuracy: 0.8528\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0817 - accuracy: 0.9711 - val_loss: 0.4133 - val_accuracy: 0.8773\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.0705 - accuracy: 0.9789 - val_loss: 0.3050 - val_accuracy: 0.9141\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0835 - accuracy: 0.9763 - val_loss: 0.4049 - val_accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0807 - accuracy: 0.9684 - val_loss: 0.4047 - val_accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 0.4913 - val_accuracy: 0.8589\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.4745 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.5148 - val_accuracy: 0.8650\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.5186 - val_accuracy: 0.8650\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 111us/step - loss: 0.1091 - accuracy: 0.9553 - val_loss: 0.7576 - val_accuracy: 0.8528\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.1060 - accuracy: 0.9579 - val_loss: 0.4444 - val_accuracy: 0.8773\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 386us/step - loss: 0.1065 - accuracy: 0.9605 - val_loss: 0.6242 - val_accuracy: 0.8528\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 157us/step - loss: 0.0596 - accuracy: 0.9816 - val_loss: 0.4749 - val_accuracy: 0.8650\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 135us/step - loss: 0.0654 - accuracy: 0.9816 - val_loss: 0.3913 - val_accuracy: 0.9018\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0771 - accuracy: 0.9842 - val_loss: 0.4049 - val_accuracy: 0.8834\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0964 - accuracy: 0.9632 - val_loss: 0.5583 - val_accuracy: 0.8528\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.3797 - val_accuracy: 0.8957\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 134us/step - loss: 0.0659 - accuracy: 0.9816 - val_loss: 0.4007 - val_accuracy: 0.8773\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.0507 - accuracy: 0.9842 - val_loss: 0.3552 - val_accuracy: 0.9018\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.0565 - accuracy: 0.9763 - val_loss: 0.5484 - val_accuracy: 0.8650\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0622 - accuracy: 0.9763 - val_loss: 0.3506 - val_accuracy: 0.9018\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.4007 - val_accuracy: 0.8834\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.5864 - val_accuracy: 0.8712\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0561 - accuracy: 0.9868 - val_loss: 0.3469 - val_accuracy: 0.9141\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.0542 - accuracy: 0.9868 - val_loss: 0.5121 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.0708 - accuracy: 0.9711 - val_loss: 0.4125 - val_accuracy: 0.8834\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0678 - accuracy: 0.9816 - val_loss: 0.5600 - val_accuracy: 0.8650\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0493 - accuracy: 0.9868 - val_loss: 0.3930 - val_accuracy: 0.8896\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.0483 - accuracy: 0.9842 - val_loss: 0.3375 - val_accuracy: 0.9018\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.6362 - val_accuracy: 0.8528\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.0749 - accuracy: 0.9763 - val_loss: 0.5094 - val_accuracy: 0.8773\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 224us/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.4296 - val_accuracy: 0.8834\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 431us/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.4367 - val_accuracy: 0.8773\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 233us/step - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.4500 - val_accuracy: 0.8773\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 245us/step - loss: 0.0465 - accuracy: 0.9868 - val_loss: 0.4718 - val_accuracy: 0.8834\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.0515 - accuracy: 0.9789 - val_loss: 0.4082 - val_accuracy: 0.8834\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 187us/step - loss: 0.0655 - accuracy: 0.9763 - val_loss: 0.5937 - val_accuracy: 0.8528\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 171us/step - loss: 0.0662 - accuracy: 0.9842 - val_loss: 0.5485 - val_accuracy: 0.8589\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.0834 - accuracy: 0.9737 - val_loss: 0.6381 - val_accuracy: 0.8589\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.0834 - accuracy: 0.9632 - val_loss: 0.5766 - val_accuracy: 0.8589\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.5249 - val_accuracy: 0.8650\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.1125 - accuracy: 0.9553 - val_loss: 0.5109 - val_accuracy: 0.8650\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 191us/step - loss: 0.0674 - accuracy: 0.9737 - val_loss: 0.5884 - val_accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 251us/step - loss: 0.0776 - accuracy: 0.9711 - val_loss: 0.5087 - val_accuracy: 0.8589\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.0505 - accuracy: 0.9789 - val_loss: 0.3374 - val_accuracy: 0.9080\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.3429 - val_accuracy: 0.9080\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.0538 - accuracy: 0.9816 - val_loss: 0.3835 - val_accuracy: 0.8957\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 163us/step - loss: 0.0596 - accuracy: 0.9789 - val_loss: 0.4025 - val_accuracy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 97.51%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9305190e-01, 3.7526863e-03, 3.1955044e-03],\n",
       "       [9.8748850e-01, 1.1872638e-02, 6.3884980e-04],\n",
       "       [9.0174776e-01, 7.3917750e-02, 2.4334421e-02],\n",
       "       [2.0366747e-02, 9.3911320e-01, 4.0519953e-02],\n",
       "       [9.9809130e-01, 1.8808233e-03, 2.7855504e-05],\n",
       "       [1.0060513e-03, 2.3835833e-01, 7.6063570e-01],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [7.8345780e-01, 1.5822506e-01, 5.8317162e-02],\n",
       "       [1.6870590e-03, 2.4654175e-04, 9.9806637e-01],\n",
       "       [9.5704810e-01, 4.2899497e-02, 5.2420000e-05],\n",
       "       [4.5415204e-02, 9.0583116e-01, 4.8753670e-02],\n",
       "       [9.2836140e-07, 2.9438186e-05, 9.9996960e-01],\n",
       "       [1.4491033e-06, 9.6917510e-01, 3.0823348e-02],\n",
       "       [1.3627746e-11, 4.5725750e-08, 1.0000000e+00],\n",
       "       [9.9317825e-01, 6.4289668e-03, 3.9270805e-04],\n",
       "       [1.1150439e-04, 9.7580760e-01, 2.4080833e-02],\n",
       "       [3.6498480e-02, 7.9646000e-01, 1.6704161e-01],\n",
       "       [7.8345780e-01, 1.5822506e-01, 5.8317162e-02],\n",
       "       [9.9268370e-01, 3.8432586e-04, 6.9319094e-03],\n",
       "       [4.2608907e-03, 1.6919430e-02, 9.7881967e-01],\n",
       "       [4.2717500e-04, 6.1775374e-01, 3.8181907e-01],\n",
       "       [2.6375630e-09, 8.4464220e-08, 9.9999990e-01],\n",
       "       [9.9448450e-01, 3.1744808e-04, 5.1980615e-03],\n",
       "       [5.4358870e-16, 4.8666084e-07, 9.9999950e-01],\n",
       "       [2.5153266e-05, 8.5287760e-03, 9.9144600e-01],\n",
       "       [9.8811040e-04, 9.9777170e-01, 1.2402338e-03],\n",
       "       [1.1154905e-04, 2.3603482e-02, 9.7628504e-01],\n",
       "       [3.4117138e-03, 3.1260785e-01, 6.8398040e-01],\n",
       "       [9.9776080e-01, 1.1659093e-03, 1.0733497e-03],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [7.1770046e-03, 9.2706160e-01, 6.5761350e-02],\n",
       "       [2.1145064e-04, 9.7246110e-01, 2.7327394e-02],\n",
       "       [2.7940577e-11, 9.9911577e-01, 8.8426674e-04],\n",
       "       [7.1144720e-01, 2.8424990e-01, 4.3030116e-03],\n",
       "       [4.1282090e-04, 8.1031740e-05, 9.9950610e-01],\n",
       "       [2.6502930e-06, 9.9710030e-01, 2.8970377e-03],\n",
       "       [9.4370790e-03, 6.2578046e-01, 3.6478248e-01],\n",
       "       [5.5222420e-10, 7.8250830e-07, 9.9999917e-01],\n",
       "       [7.1770046e-03, 9.2706160e-01, 6.5761350e-02],\n",
       "       [1.3194525e-10, 5.4832990e-06, 9.9999450e-01],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [2.1198888e-07, 9.8323030e-01, 1.6769439e-02],\n",
       "       [2.1145064e-04, 9.7246110e-01, 2.7327394e-02],\n",
       "       [1.6475583e-09, 9.9564254e-01, 4.3574270e-03],\n",
       "       [1.9088329e-03, 4.6338528e-01, 5.3470590e-01],\n",
       "       [9.9976856e-01, 1.6529580e-04, 6.6099565e-05],\n",
       "       [2.2143708e-03, 6.0060430e-02, 9.3772520e-01],\n",
       "       [2.4476817e-01, 7.3272760e-01, 2.2504350e-02],\n",
       "       [9.9279810e-01, 7.1645420e-03, 3.7307480e-05],\n",
       "       [5.6455936e-03, 4.1821107e-02, 9.5253325e-01],\n",
       "       [3.3346960e-05, 2.5152300e-01, 7.4844366e-01],\n",
       "       [9.9443170e-01, 1.8969033e-05, 5.5493110e-03],\n",
       "       [9.9776080e-01, 1.1659093e-03, 1.0733497e-03],\n",
       "       [9.9776080e-01, 1.1659093e-03, 1.0733497e-03],\n",
       "       [4.7792844e-05, 5.4097235e-01, 4.5897993e-01],\n",
       "       [8.5932090e-02, 7.6935995e-01, 1.4470800e-01],\n",
       "       [4.8238040e-08, 5.4758773e-05, 9.9994516e-01],\n",
       "       [6.6776816e-03, 8.8918190e-01, 1.0414036e-01],\n",
       "       [4.7894962e-05, 6.2459840e-03, 9.9370617e-01],\n",
       "       [2.6502930e-06, 9.9710030e-01, 2.8970377e-03],\n",
       "       [2.1624466e-07, 7.6624850e-08, 9.9999976e-01],\n",
       "       [3.1417012e-03, 9.7574025e-01, 2.1117974e-02],\n",
       "       [8.5335255e-01, 1.4139374e-01, 5.2536787e-03],\n",
       "       [5.5613970e-05, 9.9951290e-01, 4.3139787e-04],\n",
       "       [2.1145064e-04, 9.7246110e-01, 2.7327394e-02],\n",
       "       [9.9772830e-01, 1.6499303e-03, 6.2185850e-04],\n",
       "       [9.9772830e-01, 1.6499303e-03, 6.2185850e-04],\n",
       "       [7.1946144e-01, 1.1831754e-01, 1.6222104e-01],\n",
       "       [9.9443170e-01, 1.8969033e-05, 5.5493110e-03],\n",
       "       [8.1212055e-14, 4.5024350e-07, 9.9999950e-01],\n",
       "       [9.9553230e-01, 2.6442828e-03, 1.8235166e-03],\n",
       "       [8.5932090e-02, 7.6935995e-01, 1.4470800e-01],\n",
       "       [3.1278316e-06, 6.7342490e-04, 9.9932350e-01],\n",
       "       [9.9772830e-01, 1.6499303e-03, 6.2185850e-04],\n",
       "       [9.9971120e-01, 9.2518394e-07, 2.8784995e-04],\n",
       "       [1.0466231e-05, 9.9889356e-01, 1.0959420e-03],\n",
       "       [9.9922290e-01, 4.1917570e-04, 3.5798800e-04],\n",
       "       [1.3461690e-06, 7.8871460e-05, 9.9991980e-01],\n",
       "       [9.9268370e-01, 3.8432586e-04, 6.9319094e-03],\n",
       "       [9.9443170e-01, 1.8969033e-05, 5.5493110e-03],\n",
       "       [9.8836530e-01, 1.0961944e-02, 6.7273020e-04],\n",
       "       [2.6354531e-03, 6.6362983e-01, 3.3373478e-01],\n",
       "       [1.1064219e-14, 7.1043900e-07, 9.9999930e-01],\n",
       "       [1.2828775e-13, 8.2794190e-07, 9.9999917e-01],\n",
       "       [2.7121810e-02, 6.2433640e-02, 9.1044460e-01],\n",
       "       [9.5704810e-01, 4.2899497e-02, 5.2420000e-05],\n",
       "       [9.5704810e-01, 4.2899497e-02, 5.2420000e-05],\n",
       "       [1.4866851e-02, 9.5559060e-01, 2.9542510e-02],\n",
       "       [2.3145554e-16, 6.5427535e-09, 1.0000000e+00],\n",
       "       [9.9971120e-01, 9.2518394e-07, 2.8784995e-04],\n",
       "       [8.5335255e-01, 1.4139374e-01, 5.2536787e-03],\n",
       "       [9.9305190e-01, 3.7526863e-03, 3.1955044e-03],\n",
       "       [9.9292460e-01, 1.9774277e-05, 7.0556900e-03],\n",
       "       [9.9776080e-01, 1.1659093e-03, 1.0733497e-03],\n",
       "       [4.3751940e-03, 8.9531280e-01, 1.0031209e-01],\n",
       "       [6.3529330e-04, 1.7631772e-01, 8.2304704e-01],\n",
       "       [3.4209131e-03, 9.8701084e-01, 9.5682890e-03],\n",
       "       [5.6331330e-01, 3.9273800e-01, 4.3948594e-02],\n",
       "       [9.7636455e-01, 2.3850895e-04, 2.3396965e-02],\n",
       "       [1.0242294e-01, 8.0264830e-01, 9.4928760e-02],\n",
       "       [9.1717240e-11, 6.0944776e-06, 9.9999390e-01],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [4.5415204e-02, 9.0583116e-01, 4.8753670e-02],\n",
       "       [1.3090548e-03, 9.3671197e-01, 6.1978970e-02],\n",
       "       [6.5987254e-03, 5.7096810e-01, 4.2243323e-01],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [2.4256310e-05, 2.5181195e-01, 7.4816380e-01],\n",
       "       [9.8811040e-04, 9.9777170e-01, 1.2402338e-03],\n",
       "       [1.0466231e-05, 9.9889356e-01, 1.0959420e-03],\n",
       "       [9.6107044e-08, 9.8742956e-01, 1.2570391e-02],\n",
       "       [6.5878010e-01, 2.8112134e-01, 6.0098560e-02],\n",
       "       [4.6897920e-04, 6.0764180e-01, 3.9188927e-01],\n",
       "       [7.1144720e-01, 2.8424990e-01, 4.3030116e-03],\n",
       "       [9.4549050e-01, 4.4833764e-02, 9.6758260e-03],\n",
       "       [1.6836068e-16, 6.9244708e-09, 1.0000000e+00],\n",
       "       [8.4076004e-07, 8.5372250e-03, 9.9146200e-01],\n",
       "       [1.0242294e-01, 8.0264830e-01, 9.4928760e-02],\n",
       "       [1.4171569e-07, 9.7259210e-01, 2.7407743e-02],\n",
       "       [5.1521253e-02, 7.5886330e-01, 1.8961549e-01],\n",
       "       [5.1077720e-05, 7.5964120e-02, 9.2398480e-01],\n",
       "       [2.5044676e-07, 1.4803872e-03, 9.9851936e-01],\n",
       "       [2.6134466e-16, 1.2449440e-07, 9.9999990e-01],\n",
       "       [9.9317825e-01, 6.4289668e-03, 3.9270805e-04],\n",
       "       [6.3788730e-11, 4.3455153e-04, 9.9956540e-01],\n",
       "       [7.1770046e-03, 9.2706160e-01, 6.5761350e-02],\n",
       "       [1.6475583e-09, 9.9564254e-01, 4.3574270e-03],\n",
       "       [1.7786537e-05, 1.1449765e-03, 9.9883730e-01],\n",
       "       [7.9559380e-02, 8.9805660e-01, 2.2383995e-02],\n",
       "       [2.7940577e-11, 9.9911577e-01, 8.8426674e-04],\n",
       "       [2.6502930e-06, 9.9710030e-01, 2.8970377e-03],\n",
       "       [2.1198888e-07, 9.8323030e-01, 1.6769439e-02],\n",
       "       [9.5704810e-01, 4.2899497e-02, 5.2420000e-05],\n",
       "       [1.4866851e-02, 9.5559060e-01, 2.9542510e-02],\n",
       "       [8.0722256e-04, 9.4944190e-02, 9.0424865e-01],\n",
       "       [9.8748850e-01, 1.1872638e-02, 6.3884980e-04],\n",
       "       [1.0976053e-09, 1.5461773e-03, 9.9845386e-01],\n",
       "       [9.8748850e-01, 1.1872638e-02, 6.3884980e-04],\n",
       "       [9.9305190e-01, 3.7526863e-03, 3.1955044e-03],\n",
       "       [9.9562424e-01, 1.7245156e-04, 4.2032730e-03],\n",
       "       [6.3933500e-10, 1.4577068e-05, 9.9998546e-01],\n",
       "       [3.4209131e-03, 9.8701084e-01, 9.5682890e-03],\n",
       "       [9.9562424e-01, 1.7245156e-04, 4.2032730e-03],\n",
       "       [6.6776816e-03, 8.8918190e-01, 1.0414036e-01],\n",
       "       [9.9317825e-01, 6.4289668e-03, 3.9270805e-04],\n",
       "       [2.0342046e-01, 7.1645280e-01, 8.0126820e-02],\n",
       "       [2.6502930e-06, 9.9710030e-01, 2.8970377e-03],\n",
       "       [9.9971120e-01, 9.2518394e-07, 2.8784995e-04],\n",
       "       [9.9443170e-01, 1.8969033e-05, 5.5493110e-03],\n",
       "       [9.9853430e-01, 7.7090720e-04, 6.9480970e-04],\n",
       "       [1.3803449e-04, 1.0058642e-01, 8.9927560e-01],\n",
       "       [9.9305190e-01, 3.7526863e-03, 3.1955044e-03],\n",
       "       [5.6474465e-03, 3.8953910e-02, 9.5539860e-01],\n",
       "       [1.9526212e-04, 9.7733680e-01, 2.2467890e-02],\n",
       "       [9.9553230e-01, 2.6442828e-03, 1.8235166e-03],\n",
       "       [4.5415204e-02, 9.0583116e-01, 4.8753670e-02],\n",
       "       [9.9268370e-01, 3.8432586e-04, 6.9319094e-03],\n",
       "       [2.0366747e-02, 9.3911320e-01, 4.0519953e-02],\n",
       "       [1.3252106e-02, 9.6251094e-01, 2.4236938e-02],\n",
       "       [9.9895870e-01, 1.0201789e-03, 2.1116744e-05],\n",
       "       [2.8862038e-01, 6.9711500e-01, 1.4264562e-02],\n",
       "       [9.9448450e-01, 3.1744808e-04, 5.1980615e-03],\n",
       "       [2.0366747e-02, 9.3911320e-01, 4.0519953e-02],\n",
       "       [1.6475583e-09, 9.9564254e-01, 4.3574270e-03]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p11presabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647581832597124"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647581832597124"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR2852     2\n",
       "1    CFBREBSa138     0\n",
       "2      BCH-SA-12     0\n",
       "3          EUH13     0\n",
       "4          EUH13     0\n",
       "..           ...   ...\n",
       "158       NRS036     1\n",
       "159        CA105     1\n",
       "160     CFBRSa51     1\n",
       "161       NRS102     1\n",
       "162       NRS189     2\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 597us/step - loss: 1.1719 - accuracy: 0.3763 - val_loss: 1.0926 - val_accuracy: 0.3804\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 169us/step - loss: 1.0448 - accuracy: 0.4579 - val_loss: 1.0213 - val_accuracy: 0.5890\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 173us/step - loss: 0.9944 - accuracy: 0.5474 - val_loss: 0.9780 - val_accuracy: 0.5644\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.9439 - accuracy: 0.5737 - val_loss: 0.9402 - val_accuracy: 0.5521\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.8850 - accuracy: 0.5895 - val_loss: 0.9192 - val_accuracy: 0.5706\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.8323 - accuracy: 0.6342 - val_loss: 0.8688 - val_accuracy: 0.5951\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.7825 - accuracy: 0.6553 - val_loss: 0.8209 - val_accuracy: 0.5951\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.7506 - accuracy: 0.6474 - val_loss: 0.8170 - val_accuracy: 0.6319\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 301us/step - loss: 0.7244 - accuracy: 0.6842 - val_loss: 0.8127 - val_accuracy: 0.5951\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 167us/step - loss: 0.6818 - accuracy: 0.7211 - val_loss: 0.7463 - val_accuracy: 0.7055\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.6517 - accuracy: 0.7158 - val_loss: 0.7000 - val_accuracy: 0.6748\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.6256 - accuracy: 0.7158 - val_loss: 0.6946 - val_accuracy: 0.7178\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 239us/step - loss: 0.5792 - accuracy: 0.7921 - val_loss: 0.6754 - val_accuracy: 0.7239\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 156us/step - loss: 0.5684 - accuracy: 0.7711 - val_loss: 0.6987 - val_accuracy: 0.6810\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 150us/step - loss: 0.5495 - accuracy: 0.7868 - val_loss: 0.7264 - val_accuracy: 0.6687\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 170us/step - loss: 0.5724 - accuracy: 0.7474 - val_loss: 0.6044 - val_accuracy: 0.7301\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.4854 - accuracy: 0.8237 - val_loss: 0.5732 - val_accuracy: 0.7423\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 164us/step - loss: 0.4605 - accuracy: 0.8263 - val_loss: 0.5560 - val_accuracy: 0.8160\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.4393 - accuracy: 0.8579 - val_loss: 0.5591 - val_accuracy: 0.7423\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.4492 - accuracy: 0.8105 - val_loss: 0.5252 - val_accuracy: 0.7853\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.4086 - accuracy: 0.8368 - val_loss: 0.5560 - val_accuracy: 0.7730\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.4073 - accuracy: 0.8553 - val_loss: 0.5575 - val_accuracy: 0.7301\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.3821 - accuracy: 0.8632 - val_loss: 0.5086 - val_accuracy: 0.8098\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.3756 - accuracy: 0.8763 - val_loss: 0.5050 - val_accuracy: 0.7730\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 370us/step - loss: 0.3640 - accuracy: 0.8763 - val_loss: 0.4637 - val_accuracy: 0.7546\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 183us/step - loss: 0.3448 - accuracy: 0.8658 - val_loss: 0.4646 - val_accuracy: 0.8344\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 208us/step - loss: 0.3179 - accuracy: 0.8816 - val_loss: 0.4367 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 190us/step - loss: 0.2957 - accuracy: 0.9184 - val_loss: 0.4565 - val_accuracy: 0.7975\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 152us/step - loss: 0.3002 - accuracy: 0.8895 - val_loss: 0.4793 - val_accuracy: 0.8344\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2892 - accuracy: 0.9000 - val_loss: 0.4226 - val_accuracy: 0.8466\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.2650 - accuracy: 0.9132 - val_loss: 0.4395 - val_accuracy: 0.8282\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 212us/step - loss: 0.2867 - accuracy: 0.8921 - val_loss: 0.4126 - val_accuracy: 0.8344\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 316us/step - loss: 0.2605 - accuracy: 0.8974 - val_loss: 0.4612 - val_accuracy: 0.8405\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 209us/step - loss: 0.2780 - accuracy: 0.9079 - val_loss: 0.4771 - val_accuracy: 0.8098\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.2786 - accuracy: 0.9184 - val_loss: 0.4181 - val_accuracy: 0.8528\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 232us/step - loss: 0.2656 - accuracy: 0.8974 - val_loss: 0.4625 - val_accuracy: 0.7791\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 246us/step - loss: 0.2514 - accuracy: 0.8974 - val_loss: 0.4053 - val_accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 288us/step - loss: 0.2297 - accuracy: 0.9342 - val_loss: 0.3789 - val_accuracy: 0.9018\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 185us/step - loss: 0.2408 - accuracy: 0.9053 - val_loss: 0.4111 - val_accuracy: 0.8098\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 155us/step - loss: 0.2746 - accuracy: 0.8895 - val_loss: 0.4537 - val_accuracy: 0.7914\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 199us/step - loss: 0.2505 - accuracy: 0.9158 - val_loss: 0.3705 - val_accuracy: 0.8834\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 322us/step - loss: 0.2171 - accuracy: 0.9368 - val_loss: 0.4028 - val_accuracy: 0.8773\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 243us/step - loss: 0.2010 - accuracy: 0.9553 - val_loss: 0.3810 - val_accuracy: 0.8344\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 242us/step - loss: 0.2191 - accuracy: 0.9289 - val_loss: 0.3798 - val_accuracy: 0.8344\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 144us/step - loss: 0.2416 - accuracy: 0.9184 - val_loss: 0.4920 - val_accuracy: 0.8712\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.2395 - accuracy: 0.8974 - val_loss: 0.3630 - val_accuracy: 0.8834\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.2177 - accuracy: 0.9211 - val_loss: 0.3941 - val_accuracy: 0.8282\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2090 - accuracy: 0.9447 - val_loss: 0.3641 - val_accuracy: 0.8773\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1934 - accuracy: 0.9421 - val_loss: 0.4217 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.2274 - accuracy: 0.9026 - val_loss: 0.3782 - val_accuracy: 0.8282\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.2274 - accuracy: 0.9211 - val_loss: 0.3426 - val_accuracy: 0.8957\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.2199 - accuracy: 0.9105 - val_loss: 0.4341 - val_accuracy: 0.8712\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 117us/step - loss: 0.2374 - accuracy: 0.9053 - val_loss: 0.3921 - val_accuracy: 0.8160\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 294us/step - loss: 0.1962 - accuracy: 0.9316 - val_loss: 0.3884 - val_accuracy: 0.8589\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 229us/step - loss: 0.1812 - accuracy: 0.9316 - val_loss: 0.3835 - val_accuracy: 0.8589\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 240us/step - loss: 0.1685 - accuracy: 0.9395 - val_loss: 0.3750 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.1648 - accuracy: 0.9474 - val_loss: 0.3580 - val_accuracy: 0.9080\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 205us/step - loss: 0.1630 - accuracy: 0.9421 - val_loss: 0.3366 - val_accuracy: 0.9018\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 230us/step - loss: 0.1525 - accuracy: 0.9526 - val_loss: 0.3427 - val_accuracy: 0.9018\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.1524 - accuracy: 0.9605 - val_loss: 0.3843 - val_accuracy: 0.8834\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1537 - accuracy: 0.9500 - val_loss: 0.3457 - val_accuracy: 0.8834\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1485 - accuracy: 0.9553 - val_loss: 0.4171 - val_accuracy: 0.8589\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.1782 - accuracy: 0.9316 - val_loss: 0.3320 - val_accuracy: 0.9141\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 82us/step - loss: 0.1423 - accuracy: 0.9526 - val_loss: 0.3327 - val_accuracy: 0.9018\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1456 - accuracy: 0.9500 - val_loss: 0.3725 - val_accuracy: 0.9018\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.1576 - accuracy: 0.9421 - val_loss: 0.3469 - val_accuracy: 0.8896\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1381 - accuracy: 0.9526 - val_loss: 0.3349 - val_accuracy: 0.8957\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 225us/step - loss: 0.1279 - accuracy: 0.9684 - val_loss: 0.3738 - val_accuracy: 0.8712\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 234us/step - loss: 0.1335 - accuracy: 0.9579 - val_loss: 0.3668 - val_accuracy: 0.8405\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1653 - accuracy: 0.9447 - val_loss: 0.3955 - val_accuracy: 0.8773\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1451 - accuracy: 0.9500 - val_loss: 0.3285 - val_accuracy: 0.9141\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 83us/step - loss: 0.1344 - accuracy: 0.9605 - val_loss: 0.3347 - val_accuracy: 0.8957\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.1257 - accuracy: 0.9632 - val_loss: 0.3506 - val_accuracy: 0.9018\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.1210 - accuracy: 0.9658 - val_loss: 0.3169 - val_accuracy: 0.9141\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.95 - 0s 223us/step - loss: 0.1270 - accuracy: 0.9605 - val_loss: 0.3759 - val_accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 244us/step - loss: 0.1299 - accuracy: 0.9500 - val_loss: 0.3246 - val_accuracy: 0.9018\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.1261 - accuracy: 0.9632 - val_loss: 0.3571 - val_accuracy: 0.8773\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1277 - accuracy: 0.9579 - val_loss: 0.3647 - val_accuracy: 0.8896\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 121us/step - loss: 0.1182 - accuracy: 0.9632 - val_loss: 0.3313 - val_accuracy: 0.9018\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.1278 - accuracy: 0.9579 - val_loss: 0.3245 - val_accuracy: 0.9018\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 160us/step - loss: 0.1235 - accuracy: 0.9553 - val_loss: 0.3891 - val_accuracy: 0.8834\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 165us/step - loss: 0.1246 - accuracy: 0.9605 - val_loss: 0.3883 - val_accuracy: 0.8834\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1124 - accuracy: 0.9684 - val_loss: 0.3187 - val_accuracy: 0.8957\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1185 - accuracy: 0.9632 - val_loss: 0.4148 - val_accuracy: 0.8712\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.1096 - accuracy: 0.9684 - val_loss: 0.3374 - val_accuracy: 0.9018\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1118 - accuracy: 0.9658 - val_loss: 0.4135 - val_accuracy: 0.8834\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1250 - accuracy: 0.9579 - val_loss: 0.3266 - val_accuracy: 0.9080\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.1215 - accuracy: 0.9632 - val_loss: 0.3358 - val_accuracy: 0.9018\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1214 - accuracy: 0.9632 - val_loss: 0.3711 - val_accuracy: 0.8957\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.1074 - accuracy: 0.9632 - val_loss: 0.3461 - val_accuracy: 0.8834\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.1156 - accuracy: 0.9526 - val_loss: 0.3425 - val_accuracy: 0.9018\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.96 - 0s 177us/step - loss: 0.0999 - accuracy: 0.9605 - val_loss: 0.3283 - val_accuracy: 0.9141\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 158us/step - loss: 0.1095 - accuracy: 0.9658 - val_loss: 0.4302 - val_accuracy: 0.8773\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1113 - accuracy: 0.9684 - val_loss: 0.3419 - val_accuracy: 0.9018\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0975 - accuracy: 0.9737 - val_loss: 0.3217 - val_accuracy: 0.9202\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1009 - accuracy: 0.9684 - val_loss: 0.3225 - val_accuracy: 0.9018\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 136us/step - loss: 0.0937 - accuracy: 0.9711 - val_loss: 0.4380 - val_accuracy: 0.8834\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 95us/step - loss: 0.1066 - accuracy: 0.9737 - val_loss: 0.3228 - val_accuracy: 0.9141\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.1174 - accuracy: 0.9632 - val_loss: 0.3168 - val_accuracy: 0.9018\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.1116 - accuracy: 0.9553 - val_loss: 0.3936 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a40af7438>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 106us/step\n",
      "over-sampling test accuracy: 91.41%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2,\n",
       "       0, 1, 1, 1, 2, 0, 1, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 0, 2, 1, 1,\n",
       "       1, 0, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 2, 0, 2, 1, 0,\n",
       "       2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 0, 1, 0,\n",
       "       1, 1, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS036</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS189</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR2852     2     2\n",
       "1    CFBREBSa138     0     0\n",
       "2      BCH-SA-12     0     0\n",
       "3          EUH13     0     0\n",
       "4          EUH13     0     0\n",
       "..           ...   ...   ...\n",
       "158       NRS036     1     1\n",
       "159        CA105     1     1\n",
       "160     CFBRSa51     1     1\n",
       "161       NRS102     1     1\n",
       "162       NRS189     2     2\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.802514e-06</td>\n",
       "      <td>1.108062e-03</td>\n",
       "      <td>0.998890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.996647e-01</td>\n",
       "      <td>1.931857e-04</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.992285e-01</td>\n",
       "      <td>6.816303e-04</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.884464e-01</td>\n",
       "      <td>1.041394e-02</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.884464e-01</td>\n",
       "      <td>1.041394e-02</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.051734e-02</td>\n",
       "      <td>9.504162e-01</td>\n",
       "      <td>0.039066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2.425348e-05</td>\n",
       "      <td>9.996481e-01</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.810323e-04</td>\n",
       "      <td>9.889921e-01</td>\n",
       "      <td>0.010827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>6.294157e-05</td>\n",
       "      <td>9.933652e-01</td>\n",
       "      <td>0.006572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>6.171983e-12</td>\n",
       "      <td>5.730723e-08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    1.802514e-06  1.108062e-03  0.998890\n",
       "1    9.996647e-01  1.931857e-04  0.000142\n",
       "2    9.992285e-01  6.816303e-04  0.000090\n",
       "3    9.884464e-01  1.041394e-02  0.001140\n",
       "4    9.884464e-01  1.041394e-02  0.001140\n",
       "..            ...           ...       ...\n",
       "158  1.051734e-02  9.504162e-01  0.039066\n",
       "159  2.425348e-05  9.996481e-01  0.000328\n",
       "160  1.810323e-04  9.889921e-01  0.010827\n",
       "161  6.294157e-05  9.933652e-01  0.006572\n",
       "162  6.171983e-12  5.730723e-08  1.000000\n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p11p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 163 samples\n",
      "Epoch 1/100\n",
      "380/380 [==============================] - 0s 148us/step - loss: 0.0896 - accuracy: 0.9605 - val_loss: 0.4265 - val_accuracy: 0.8773\n",
      "Epoch 2/100\n",
      "380/380 [==============================] - 0s 120us/step - loss: 0.0904 - accuracy: 0.9658 - val_loss: 0.3583 - val_accuracy: 0.8957\n",
      "Epoch 3/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.0880 - accuracy: 0.9737 - val_loss: 0.3198 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.0841 - accuracy: 0.9737 - val_loss: 0.3173 - val_accuracy: 0.9080\n",
      "Epoch 5/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.1026 - accuracy: 0.9605 - val_loss: 0.3054 - val_accuracy: 0.9141\n",
      "Epoch 6/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1024 - accuracy: 0.9658 - val_loss: 0.2995 - val_accuracy: 0.9141\n",
      "Epoch 7/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.0765 - accuracy: 0.9789 - val_loss: 0.4058 - val_accuracy: 0.8957\n",
      "Epoch 8/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.0786 - accuracy: 0.9658 - val_loss: 0.3186 - val_accuracy: 0.9080\n",
      "Epoch 9/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.0827 - accuracy: 0.9684 - val_loss: 0.3109 - val_accuracy: 0.9018\n",
      "Epoch 10/100\n",
      "380/380 [==============================] - 0s 114us/step - loss: 0.0683 - accuracy: 0.9789 - val_loss: 0.3716 - val_accuracy: 0.8896\n",
      "Epoch 11/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.0964 - accuracy: 0.9737 - val_loss: 0.5615 - val_accuracy: 0.8650\n",
      "Epoch 12/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1094 - accuracy: 0.9605 - val_loss: 0.3043 - val_accuracy: 0.9202\n",
      "Epoch 13/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.1066 - accuracy: 0.9684 - val_loss: 0.2970 - val_accuracy: 0.8773\n",
      "Epoch 14/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.0900 - accuracy: 0.9684 - val_loss: 0.3896 - val_accuracy: 0.8957\n",
      "Epoch 15/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0873 - accuracy: 0.9684 - val_loss: 0.4581 - val_accuracy: 0.8834\n",
      "Epoch 16/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.0962 - accuracy: 0.9605 - val_loss: 0.3303 - val_accuracy: 0.9080\n",
      "Epoch 17/100\n",
      "380/380 [==============================] - 0s 113us/step - loss: 0.0784 - accuracy: 0.9605 - val_loss: 0.3053 - val_accuracy: 0.8773\n",
      "Epoch 18/100\n",
      "380/380 [==============================] - 0s 131us/step - loss: 0.0902 - accuracy: 0.9711 - val_loss: 0.3051 - val_accuracy: 0.9202\n",
      "Epoch 19/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.0752 - accuracy: 0.9789 - val_loss: 0.4341 - val_accuracy: 0.8896\n",
      "Epoch 20/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.1148 - accuracy: 0.9553 - val_loss: 0.5926 - val_accuracy: 0.8589\n",
      "Epoch 21/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.1751 - accuracy: 0.9263 - val_loss: 0.3873 - val_accuracy: 0.8282\n",
      "Epoch 22/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.1299 - accuracy: 0.9579 - val_loss: 0.3611 - val_accuracy: 0.8957\n",
      "Epoch 23/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.1067 - accuracy: 0.9632 - val_loss: 0.6106 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1329 - accuracy: 0.9500 - val_loss: 0.3433 - val_accuracy: 0.8405\n",
      "Epoch 25/100\n",
      "380/380 [==============================] - 0s 106us/step - loss: 0.0989 - accuracy: 0.9684 - val_loss: 0.3312 - val_accuracy: 0.9080\n",
      "Epoch 26/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.0868 - accuracy: 0.9711 - val_loss: 0.5567 - val_accuracy: 0.8712\n",
      "Epoch 27/100\n",
      "380/380 [==============================] - 0s 115us/step - loss: 0.1014 - accuracy: 0.9605 - val_loss: 0.3441 - val_accuracy: 0.8405\n",
      "Epoch 28/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0940 - accuracy: 0.9684 - val_loss: 0.4396 - val_accuracy: 0.8896\n",
      "Epoch 29/100\n",
      "380/380 [==============================] - 0s 186us/step - loss: 0.0731 - accuracy: 0.9763 - val_loss: 0.3557 - val_accuracy: 0.9018\n",
      "Epoch 30/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0673 - accuracy: 0.9789 - val_loss: 0.3285 - val_accuracy: 0.9080\n",
      "Epoch 31/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.0794 - accuracy: 0.9737 - val_loss: 0.4510 - val_accuracy: 0.8834\n",
      "Epoch 32/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0880 - accuracy: 0.9684 - val_loss: 0.3857 - val_accuracy: 0.8896\n",
      "Epoch 33/100\n",
      "380/380 [==============================] - 0s 112us/step - loss: 0.1085 - accuracy: 0.9579 - val_loss: 0.4037 - val_accuracy: 0.8773\n",
      "Epoch 34/100\n",
      "380/380 [==============================] - 0s 124us/step - loss: 0.1038 - accuracy: 0.9711 - val_loss: 0.3456 - val_accuracy: 0.8528\n",
      "Epoch 35/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.1130 - accuracy: 0.9500 - val_loss: 0.4912 - val_accuracy: 0.8834\n",
      "Epoch 36/100\n",
      "380/380 [==============================] - 0s 142us/step - loss: 0.0734 - accuracy: 0.9816 - val_loss: 0.3382 - val_accuracy: 0.9080\n",
      "Epoch 37/100\n",
      "380/380 [==============================] - 0s 127us/step - loss: 0.0589 - accuracy: 0.9763 - val_loss: 0.3618 - val_accuracy: 0.9080\n",
      "Epoch 38/100\n",
      "380/380 [==============================] - 0s 174us/step - loss: 0.0729 - accuracy: 0.9763 - val_loss: 0.4636 - val_accuracy: 0.8896\n",
      "Epoch 39/100\n",
      "380/380 [==============================] - 0s 122us/step - loss: 0.0601 - accuracy: 0.9763 - val_loss: 0.3273 - val_accuracy: 0.9141\n",
      "Epoch 40/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0654 - accuracy: 0.9711 - val_loss: 0.3609 - val_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0627 - accuracy: 0.9816 - val_loss: 0.3464 - val_accuracy: 0.9080\n",
      "Epoch 42/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0787 - accuracy: 0.9605 - val_loss: 0.3681 - val_accuracy: 0.9018\n",
      "Epoch 43/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.0615 - accuracy: 0.9763 - val_loss: 0.3919 - val_accuracy: 0.8957\n",
      "Epoch 44/100\n",
      "380/380 [==============================] - 0s 100us/step - loss: 0.0721 - accuracy: 0.9737 - val_loss: 0.4614 - val_accuracy: 0.8896\n",
      "Epoch 45/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0690 - accuracy: 0.9684 - val_loss: 0.3855 - val_accuracy: 0.8957\n",
      "Epoch 46/100\n",
      "380/380 [==============================] - 0s 118us/step - loss: 0.0621 - accuracy: 0.9789 - val_loss: 0.4280 - val_accuracy: 0.9018\n",
      "Epoch 47/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0780 - accuracy: 0.9684 - val_loss: 0.3488 - val_accuracy: 0.9080\n",
      "Epoch 48/100\n",
      "380/380 [==============================] - 0s 141us/step - loss: 0.0674 - accuracy: 0.9737 - val_loss: 0.3436 - val_accuracy: 0.9080\n",
      "Epoch 49/100\n",
      "380/380 [==============================] - 0s 119us/step - loss: 0.0673 - accuracy: 0.9763 - val_loss: 0.3175 - val_accuracy: 0.8712\n",
      "Epoch 50/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0764 - accuracy: 0.9763 - val_loss: 0.5133 - val_accuracy: 0.8834\n",
      "Epoch 51/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0832 - accuracy: 0.9711 - val_loss: 0.4260 - val_accuracy: 0.8957\n",
      "Epoch 52/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.0769 - accuracy: 0.9763 - val_loss: 0.3623 - val_accuracy: 0.9080\n",
      "Epoch 53/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.3369 - val_accuracy: 0.9141\n",
      "Epoch 54/100\n",
      "380/380 [==============================] - 0s 85us/step - loss: 0.0651 - accuracy: 0.9737 - val_loss: 0.5175 - val_accuracy: 0.8773\n",
      "Epoch 55/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.0874 - accuracy: 0.9658 - val_loss: 0.4848 - val_accuracy: 0.8896\n",
      "Epoch 56/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.0762 - accuracy: 0.9763 - val_loss: 0.3343 - val_accuracy: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "380/380 [==============================] - 0s 102us/step - loss: 0.0614 - accuracy: 0.9842 - val_loss: 0.3637 - val_accuracy: 0.9080\n",
      "Epoch 58/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.0614 - accuracy: 0.9789 - val_loss: 0.5003 - val_accuracy: 0.8712\n",
      "Epoch 59/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.0997 - accuracy: 0.9553 - val_loss: 0.3494 - val_accuracy: 0.9080\n",
      "Epoch 60/100\n",
      "380/380 [==============================] - 0s 96us/step - loss: 0.0796 - accuracy: 0.9632 - val_loss: 0.3576 - val_accuracy: 0.9080\n",
      "Epoch 61/100\n",
      "380/380 [==============================] - 0s 93us/step - loss: 0.0750 - accuracy: 0.9632 - val_loss: 0.3585 - val_accuracy: 0.9080\n",
      "Epoch 62/100\n",
      "380/380 [==============================] - 0s 98us/step - loss: 0.0929 - accuracy: 0.9605 - val_loss: 0.3785 - val_accuracy: 0.9018\n",
      "Epoch 63/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1233 - accuracy: 0.9553 - val_loss: 0.7003 - val_accuracy: 0.8344\n",
      "Epoch 64/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.1335 - accuracy: 0.9605 - val_loss: 0.3493 - val_accuracy: 0.9202\n",
      "Epoch 65/100\n",
      "380/380 [==============================] - 0s 108us/step - loss: 0.0825 - accuracy: 0.9711 - val_loss: 0.3806 - val_accuracy: 0.8957\n",
      "Epoch 66/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.0950 - accuracy: 0.9711 - val_loss: 0.3715 - val_accuracy: 0.9018\n",
      "Epoch 67/100\n",
      "380/380 [==============================] - 0s 116us/step - loss: 0.1274 - accuracy: 0.9526 - val_loss: 0.6133 - val_accuracy: 0.8466\n",
      "Epoch 68/100\n",
      "380/380 [==============================] - 0s 126us/step - loss: 0.1349 - accuracy: 0.9474 - val_loss: 0.3872 - val_accuracy: 0.9080\n",
      "Epoch 69/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.0990 - accuracy: 0.9605 - val_loss: 0.4276 - val_accuracy: 0.9018\n",
      "Epoch 70/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0800 - accuracy: 0.9684 - val_loss: 0.4342 - val_accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "380/380 [==============================] - 0s 88us/step - loss: 0.0819 - accuracy: 0.9737 - val_loss: 0.4239 - val_accuracy: 0.9018\n",
      "Epoch 72/100\n",
      "380/380 [==============================] - 0s 123us/step - loss: 0.0625 - accuracy: 0.9816 - val_loss: 0.3310 - val_accuracy: 0.8834\n",
      "Epoch 73/100\n",
      "380/380 [==============================] - 0s 107us/step - loss: 0.0682 - accuracy: 0.9737 - val_loss: 0.6047 - val_accuracy: 0.8650\n",
      "Epoch 74/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.1222 - accuracy: 0.9447 - val_loss: 0.4935 - val_accuracy: 0.8957\n",
      "Epoch 75/100\n",
      "380/380 [==============================] - 0s 99us/step - loss: 0.1864 - accuracy: 0.9395 - val_loss: 0.3391 - val_accuracy: 0.8712\n",
      "Epoch 76/100\n",
      "380/380 [==============================] - 0s 97us/step - loss: 0.0794 - accuracy: 0.9711 - val_loss: 0.3621 - val_accuracy: 0.9141\n",
      "Epoch 77/100\n",
      "380/380 [==============================] - 0s 110us/step - loss: 0.0608 - accuracy: 0.9763 - val_loss: 0.4563 - val_accuracy: 0.8957\n",
      "Epoch 78/100\n",
      "380/380 [==============================] - 0s 103us/step - loss: 0.0565 - accuracy: 0.9816 - val_loss: 0.4026 - val_accuracy: 0.9018\n",
      "Epoch 79/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.0543 - accuracy: 0.9763 - val_loss: 0.3639 - val_accuracy: 0.9141\n",
      "Epoch 80/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.0635 - accuracy: 0.9789 - val_loss: 0.3644 - val_accuracy: 0.9080\n",
      "Epoch 81/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.0621 - accuracy: 0.9658 - val_loss: 0.4004 - val_accuracy: 0.9018\n",
      "Epoch 82/100\n",
      "380/380 [==============================] - 0s 87us/step - loss: 0.0596 - accuracy: 0.9789 - val_loss: 0.4823 - val_accuracy: 0.8896\n",
      "Epoch 83/100\n",
      "380/380 [==============================] - 0s 86us/step - loss: 0.0919 - accuracy: 0.9605 - val_loss: 0.3623 - val_accuracy: 0.9141\n",
      "Epoch 84/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.0787 - accuracy: 0.9632 - val_loss: 0.3694 - val_accuracy: 0.9080\n",
      "Epoch 85/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.0598 - accuracy: 0.9763 - val_loss: 0.4959 - val_accuracy: 0.8957\n",
      "Epoch 86/100\n",
      "380/380 [==============================] - 0s 101us/step - loss: 0.0707 - accuracy: 0.9711 - val_loss: 0.3537 - val_accuracy: 0.9202\n",
      "Epoch 87/100\n",
      "380/380 [==============================] - 0s 94us/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.4636 - val_accuracy: 0.8957\n",
      "Epoch 88/100\n",
      "380/380 [==============================] - 0s 89us/step - loss: 0.0462 - accuracy: 0.9868 - val_loss: 0.3620 - val_accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "380/380 [==============================] - 0s 90us/step - loss: 0.0537 - accuracy: 0.9789 - val_loss: 0.4015 - val_accuracy: 0.8957\n",
      "Epoch 90/100\n",
      "380/380 [==============================] - 0s 91us/step - loss: 0.0466 - accuracy: 0.9789 - val_loss: 0.3872 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "380/380 [==============================] - 0s 104us/step - loss: 0.0541 - accuracy: 0.9816 - val_loss: 0.4668 - val_accuracy: 0.8957\n",
      "Epoch 92/100\n",
      "380/380 [==============================] - 0s 109us/step - loss: 0.0490 - accuracy: 0.9763 - val_loss: 0.3581 - val_accuracy: 0.9080\n",
      "Epoch 93/100\n",
      "380/380 [==============================] - 0s 105us/step - loss: 0.0595 - accuracy: 0.9816 - val_loss: 0.3750 - val_accuracy: 0.9141\n",
      "Epoch 94/100\n",
      "380/380 [==============================] - 0s 260us/step - loss: 0.0615 - accuracy: 0.9711 - val_loss: 0.5918 - val_accuracy: 0.8834\n",
      "Epoch 95/100\n",
      "380/380 [==============================] - 0s 145us/step - loss: 0.0912 - accuracy: 0.9711 - val_loss: 0.3466 - val_accuracy: 0.8712\n",
      "Epoch 96/100\n",
      "380/380 [==============================] - 0s 130us/step - loss: 0.0752 - accuracy: 0.9763 - val_loss: 0.5866 - val_accuracy: 0.8773\n",
      "Epoch 97/100\n",
      "380/380 [==============================] - 0s 125us/step - loss: 0.0867 - accuracy: 0.9579 - val_loss: 0.3864 - val_accuracy: 0.9018\n",
      "Epoch 98/100\n",
      "380/380 [==============================] - 0s 137us/step - loss: 0.0758 - accuracy: 0.9632 - val_loss: 0.3330 - val_accuracy: 0.8773\n",
      "Epoch 99/100\n",
      "380/380 [==============================] - 0s 129us/step - loss: 0.1105 - accuracy: 0.9500 - val_loss: 0.5198 - val_accuracy: 0.8834\n",
      "Epoch 100/100\n",
      "380/380 [==============================] - 0s 168us/step - loss: 0.0882 - accuracy: 0.9579 - val_loss: 0.4034 - val_accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.88%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80251380e-06, 1.10806190e-03, 9.98890100e-01],\n",
       "       [9.99664660e-01, 1.93185710e-04, 1.42152130e-04],\n",
       "       [9.99228500e-01, 6.81630340e-04, 8.99736550e-05],\n",
       "       [9.88446350e-01, 1.04139400e-02, 1.13964500e-03],\n",
       "       [9.88446350e-01, 1.04139400e-02, 1.13964500e-03],\n",
       "       [2.02436730e-02, 9.68955340e-01, 1.08009910e-02],\n",
       "       [9.46789600e-01, 3.96002680e-02, 1.36100550e-02],\n",
       "       [4.51099740e-04, 1.28171980e-02, 9.86731700e-01],\n",
       "       [9.55403400e-01, 4.41104320e-02, 4.86224000e-04],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [2.05551370e-02, 9.35666200e-01, 4.37785950e-02],\n",
       "       [8.00717950e-01, 1.35962900e-01, 6.33191400e-02],\n",
       "       [5.90009150e-04, 1.11505700e-02, 9.88259430e-01],\n",
       "       [9.55403400e-01, 4.41104320e-02, 4.86224000e-04],\n",
       "       [2.31649680e-05, 2.37071170e-01, 7.62905600e-01],\n",
       "       [9.95546460e-01, 1.34978780e-04, 4.31862660e-03],\n",
       "       [9.55403400e-01, 4.41104320e-02, 4.86224000e-04],\n",
       "       [9.98963500e-01, 8.76140430e-04, 1.60466210e-04],\n",
       "       [4.22294680e-14, 1.22217240e-08, 1.00000000e+00],\n",
       "       [9.88446350e-01, 1.04139400e-02, 1.13964500e-03],\n",
       "       [1.88789960e-11, 9.21733400e-07, 9.99999050e-01],\n",
       "       [8.22214900e-05, 5.71853200e-03, 9.94199300e-01],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [2.59373260e-05, 9.96919040e-01, 3.05512550e-03],\n",
       "       [4.54186280e-03, 9.83052250e-01, 1.24058435e-02],\n",
       "       [2.65588740e-02, 8.71249800e-01, 1.02191380e-01],\n",
       "       [1.84416980e-07, 2.85051830e-05, 9.99971300e-01],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [2.63708060e-01, 7.15884030e-01, 2.04079470e-02],\n",
       "       [9.46789600e-01, 3.96002680e-02, 1.36100550e-02],\n",
       "       [9.99931450e-01, 1.23682400e-05, 5.61284140e-05],\n",
       "       [2.52382800e-02, 9.72112700e-02, 8.77550400e-01],\n",
       "       [6.15604750e-04, 9.15493200e-01, 8.38912200e-02],\n",
       "       [3.46889950e-03, 9.92192100e-01, 4.33910300e-03],\n",
       "       [6.67573700e-01, 2.40189730e-01, 9.22366100e-02],\n",
       "       [8.00717950e-01, 1.35962900e-01, 6.33191400e-02],\n",
       "       [9.93253200e-01, 5.71985800e-05, 6.68968600e-03],\n",
       "       [6.98181250e-05, 3.54203730e-02, 9.64509800e-01],\n",
       "       [9.99664660e-01, 1.93185710e-04, 1.42152130e-04],\n",
       "       [9.98484700e-01, 9.32426700e-05, 1.42218310e-03],\n",
       "       [9.95546460e-01, 1.34978780e-04, 4.31862660e-03],\n",
       "       [1.81032290e-04, 9.88992100e-01, 1.08268205e-02],\n",
       "       [5.86271900e-05, 9.99632240e-01, 3.09165970e-04],\n",
       "       [3.04800810e-05, 9.99736250e-01, 2.33241460e-04],\n",
       "       [7.83741350e-01, 1.90572650e-01, 2.56859440e-02],\n",
       "       [7.01319660e-03, 9.53389600e-01, 3.95972130e-02],\n",
       "       [1.18106860e-01, 8.06896870e-01, 7.49962700e-02],\n",
       "       [9.99228500e-01, 6.81630340e-04, 8.99736550e-05],\n",
       "       [9.98484700e-01, 9.32426700e-05, 1.42218310e-03],\n",
       "       [9.93253200e-01, 5.71985800e-05, 6.68968600e-03],\n",
       "       [6.29415660e-05, 9.93365200e-01, 6.57169430e-03],\n",
       "       [1.11617670e-06, 9.99486450e-01, 5.12452160e-04],\n",
       "       [7.01319660e-03, 9.53389600e-01, 3.95972130e-02],\n",
       "       [1.97854440e-01, 7.35582700e-01, 6.65628800e-02],\n",
       "       [5.70188400e-11, 4.20354470e-07, 9.99999500e-01],\n",
       "       [2.82744410e-02, 8.36843300e-01, 1.34882260e-01],\n",
       "       [2.87823200e-05, 7.00739900e-02, 9.29897300e-01],\n",
       "       [1.81778540e-05, 9.85410900e-01, 1.45709235e-02],\n",
       "       [1.69933600e-03, 9.92951040e-01, 5.34965420e-03],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [1.19386930e-02, 8.83869200e-01, 1.04192080e-01],\n",
       "       [2.08715570e-02, 9.72758230e-01, 6.37020200e-03],\n",
       "       [9.98484700e-01, 9.32426700e-05, 1.42218310e-03],\n",
       "       [2.61633540e-04, 2.12317680e-01, 7.87420630e-01],\n",
       "       [1.00761130e-02, 7.99060900e-01, 1.90863010e-01],\n",
       "       [7.16756470e-03, 9.63066100e-01, 2.97662730e-02],\n",
       "       [1.19386930e-02, 8.83869200e-01, 1.04192080e-01],\n",
       "       [9.98963500e-01, 8.76140430e-04, 1.60466210e-04],\n",
       "       [1.51269180e-03, 3.89206800e-02, 9.59566600e-01],\n",
       "       [6.69952200e-01, 8.22846440e-02, 2.47763100e-01],\n",
       "       [9.88446350e-01, 1.04139400e-02, 1.13964500e-03],\n",
       "       [1.81032290e-04, 9.88992100e-01, 1.08268205e-02],\n",
       "       [9.94030800e-01, 2.07908090e-04, 5.76118660e-03],\n",
       "       [9.99737900e-01, 2.40068800e-04, 2.20073430e-05],\n",
       "       [4.99620600e-04, 7.73583770e-01, 2.25916600e-01],\n",
       "       [4.12642800e-03, 1.54834430e-01, 8.41039060e-01],\n",
       "       [2.36785000e-01, 6.98317770e-01, 6.48972200e-02],\n",
       "       [7.16756470e-03, 9.63066100e-01, 2.97662730e-02],\n",
       "       [2.94609760e-02, 5.33951640e-01, 4.36587360e-01],\n",
       "       [4.47088200e-09, 2.94190180e-05, 9.99970560e-01],\n",
       "       [9.99737900e-01, 2.40068800e-04, 2.20073430e-05],\n",
       "       [9.94030800e-01, 2.07908090e-04, 5.76118660e-03],\n",
       "       [2.96634600e-13, 2.36143020e-09, 1.00000000e+00],\n",
       "       [6.29415660e-05, 9.93365200e-01, 6.57169430e-03],\n",
       "       [5.07647030e-03, 5.91044950e-06, 9.94917630e-01],\n",
       "       [1.97854440e-01, 7.35582700e-01, 6.65628800e-02],\n",
       "       [8.00717950e-01, 1.35962900e-01, 6.33191400e-02],\n",
       "       [2.25103270e-01, 7.54148600e-01, 2.07481630e-02],\n",
       "       [9.96644400e-01, 2.64793100e-03, 7.07780900e-04],\n",
       "       [8.00717950e-01, 1.35962900e-01, 6.33191400e-02],\n",
       "       [9.95461760e-01, 4.40491400e-03, 1.33216630e-04],\n",
       "       [1.81778540e-05, 9.85410900e-01, 1.45709235e-02],\n",
       "       [8.64939330e-01, 1.24515840e-01, 1.05448775e-02],\n",
       "       [4.26614800e-09, 1.21490870e-07, 9.99999900e-01],\n",
       "       [2.05551370e-02, 9.35666200e-01, 4.37785950e-02],\n",
       "       [1.81032290e-04, 9.88992100e-01, 1.08268205e-02],\n",
       "       [9.96644400e-01, 2.64793100e-03, 7.07780900e-04],\n",
       "       [3.46889950e-03, 9.92192100e-01, 4.33910300e-03],\n",
       "       [4.02188300e-02, 9.30012640e-01, 2.97685470e-02],\n",
       "       [1.97854440e-01, 7.35582700e-01, 6.65628800e-02],\n",
       "       [9.82657250e-01, 1.61714390e-02, 1.17126850e-03],\n",
       "       [8.00717950e-01, 1.35962900e-01, 6.33191400e-02],\n",
       "       [2.61604960e-04, 3.13741500e-02, 9.68364240e-01],\n",
       "       [2.05551370e-02, 9.35666200e-01, 4.37785950e-02],\n",
       "       [6.87520900e-07, 1.21115960e-03, 9.98788200e-01],\n",
       "       [2.48395140e-04, 4.62887460e-06, 9.99747000e-01],\n",
       "       [8.64939330e-01, 1.24515840e-01, 1.05448775e-02],\n",
       "       [3.43084050e-07, 3.23407330e-05, 9.99967340e-01],\n",
       "       [2.05551370e-02, 9.35666200e-01, 4.37785950e-02],\n",
       "       [9.94694400e-01, 1.46985050e-03, 3.83572230e-03],\n",
       "       [3.24205600e-09, 3.82921460e-06, 9.99996200e-01],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [3.04800810e-05, 9.99736250e-01, 2.33241460e-04],\n",
       "       [4.02188300e-02, 9.30012640e-01, 2.97685470e-02],\n",
       "       [9.95546460e-01, 1.34978780e-04, 4.31862660e-03],\n",
       "       [1.03168090e-02, 2.67357250e-02, 9.62947500e-01],\n",
       "       [9.98484700e-01, 9.32426700e-05, 1.42218310e-03],\n",
       "       [5.26279900e-03, 9.81315430e-01, 1.34218580e-02],\n",
       "       [3.83123000e-09, 2.35289670e-04, 9.99764740e-01],\n",
       "       [6.59576300e-07, 9.99687550e-01, 3.11718580e-04],\n",
       "       [3.31977400e-03, 9.89992440e-01, 6.68771150e-03],\n",
       "       [8.17433000e-04, 6.97691200e-01, 3.01491350e-01],\n",
       "       [7.55788300e-12, 4.73133560e-06, 9.99995230e-01],\n",
       "       [3.75859830e-13, 8.75839850e-08, 9.99999900e-01],\n",
       "       [2.05551370e-02, 9.35666200e-01, 4.37785950e-02],\n",
       "       [8.63966800e-08, 9.99557550e-01, 4.42310320e-04],\n",
       "       [1.19571080e-04, 2.09596140e-02, 9.78920760e-01],\n",
       "       [3.04800810e-05, 9.99736250e-01, 2.33241460e-04],\n",
       "       [4.34411100e-08, 4.77520380e-03, 9.95224700e-01],\n",
       "       [9.98487600e-01, 1.37558350e-03, 1.36718050e-04],\n",
       "       [1.52621450e-01, 8.28151050e-01, 1.92274710e-02],\n",
       "       [7.01217700e-01, 2.53261570e-01, 4.55207820e-02],\n",
       "       [4.49821940e-04, 5.94771860e-01, 4.04778330e-01],\n",
       "       [3.04800810e-05, 9.99736250e-01, 2.33241460e-04],\n",
       "       [1.70827220e-04, 4.48641050e-04, 9.99380470e-01],\n",
       "       [1.81778540e-05, 9.85410900e-01, 1.45709235e-02],\n",
       "       [9.82657250e-01, 1.61714390e-02, 1.17126850e-03],\n",
       "       [3.74171440e-03, 1.32520745e-05, 9.96244970e-01],\n",
       "       [6.77942160e-03, 9.86812650e-01, 6.40799430e-03],\n",
       "       [1.03122660e-05, 9.96449350e-01, 3.54024020e-03],\n",
       "       [9.96631560e-01, 2.33815300e-03, 1.03034850e-03],\n",
       "       [9.84357700e-01, 5.01925170e-05, 1.55920480e-02],\n",
       "       [7.79958250e-11, 1.35551500e-06, 9.99998700e-01],\n",
       "       [9.94694400e-01, 1.46985050e-03, 3.83572230e-03],\n",
       "       [6.67809100e-03, 6.82602470e-01, 3.10719500e-01],\n",
       "       [4.35889160e-06, 6.69672100e-08, 9.99995600e-01],\n",
       "       [4.99620600e-04, 7.73583770e-01, 2.25916600e-01],\n",
       "       [3.06849580e-05, 9.98487600e-01, 1.48168880e-03],\n",
       "       [2.36785000e-01, 6.98317770e-01, 6.48972200e-02],\n",
       "       [9.91215800e-01, 8.46053700e-03, 3.23604820e-04],\n",
       "       [9.98484700e-01, 9.32426700e-05, 1.42218310e-03],\n",
       "       [1.96875050e-03, 9.85949040e-01, 1.20822660e-02],\n",
       "       [3.64303290e-03, 9.02103600e-01, 9.42534100e-02],\n",
       "       [8.05950240e-02, 8.66602100e-01, 5.28028830e-02],\n",
       "       [4.93520870e-04, 9.55378200e-01, 4.41284030e-02],\n",
       "       [2.46790610e-06, 9.99761040e-01, 2.36415920e-04],\n",
       "       [2.36785000e-01, 6.98317770e-01, 6.48972200e-02],\n",
       "       [1.11617670e-06, 9.99486450e-01, 5.12452160e-04],\n",
       "       [1.05173440e-02, 9.50416200e-01, 3.90664260e-02],\n",
       "       [2.42534820e-05, 9.99648100e-01, 3.27543820e-04],\n",
       "       [1.81032290e-04, 9.88992100e-01, 1.08268205e-02],\n",
       "       [6.29415660e-05, 9.93365200e-01, 6.57169430e-03],\n",
       "       [6.17198350e-12, 5.73072330e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p11presabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646724636785798"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646724636785798"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676647334713084"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036095930435103354"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676647334713084"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036095930435103354"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 89.72%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.015865159093204316\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 96.64%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0060931975\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
