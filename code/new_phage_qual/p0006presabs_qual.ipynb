{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0006presabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 96)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0006presabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "248    1\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>...</th>\n",
       "      <th>group_7824</th>\n",
       "      <th>group_7845</th>\n",
       "      <th>group_10140</th>\n",
       "      <th>group_10143</th>\n",
       "      <th>group_3985</th>\n",
       "      <th>group_4427</th>\n",
       "      <th>group_7172</th>\n",
       "      <th>group_8210</th>\n",
       "      <th>group_9586</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  \\\n",
       "0     107            1              1              1               1   \n",
       "1     109            1              1              1               1   \n",
       "2     115            1              1              1               1   \n",
       "3  120335            1              1              1               1   \n",
       "4  120337            1              1              1               1   \n",
       "\n",
       "   TATTATGTTAATG  TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  ...  \\\n",
       "0              1            1             1               1            1  ...   \n",
       "1              1            1             1               1            1  ...   \n",
       "2              1            1             1               1            1  ...   \n",
       "3              1            1             1               1            1  ...   \n",
       "4              1            1             1               1            1  ...   \n",
       "\n",
       "   group_7824  group_7845  group_10140  group_10143  group_3985  group_4427  \\\n",
       "0           0           0            0            0           0           0   \n",
       "1           0           0            0            0           0           0   \n",
       "2           0           0            0            0           0           0   \n",
       "3           0           0            0            0           0           0   \n",
       "4           0           0            0            0           0           0   \n",
       "\n",
       "   group_7172  group_8210  group_9586  pheno  \n",
       "0           0           0           0      1  \n",
       "1           0           0           0      0  \n",
       "2           0           0           0      1  \n",
       "3           0           0           0      1  \n",
       "4           0           0           0      1  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 95)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTGTTATAGTC</th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GCAAACATGCG</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_7824</th>\n",
       "      <th>group_7845</th>\n",
       "      <th>group_10140</th>\n",
       "      <th>group_10143</th>\n",
       "      <th>group_3985</th>\n",
       "      <th>group_4427</th>\n",
       "      <th>group_7172</th>\n",
       "      <th>group_8210</th>\n",
       "      <th>group_9586</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTGTTATAGTC  TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  TATTATGTTAATG  \\\n",
       "0            1              1              1               1              1   \n",
       "1            1              1              1               1              1   \n",
       "2            1              1              1               1              1   \n",
       "3            1              1              1               1              1   \n",
       "4            1              1              1               1              1   \n",
       "\n",
       "   TACATACCGAT  GTGTATCATAAT  GCTGTTGAAATGGC  GCAAACATGCG  GAGTCCTGTT  ...  \\\n",
       "0            1             1               1            1           1  ...   \n",
       "1            1             1               1            1           1  ...   \n",
       "2            1             1               1            1           1  ...   \n",
       "3            1             1               1            1           1  ...   \n",
       "4            1             1               1            1           1  ...   \n",
       "\n",
       "   group_7824  group_7845  group_10140  group_10143  group_3985  group_4427  \\\n",
       "0           0           0            0            0           0           0   \n",
       "1           0           0            0            0           0           0   \n",
       "2           0           0            0            0           0           0   \n",
       "3           0           0            0            0           0           0   \n",
       "4           0           0            0            0           0           0   \n",
       "\n",
       "   group_7172  group_8210  group_9586  pheno  \n",
       "0           0           0           0      1  \n",
       "1           0           0           0      0  \n",
       "2           0           0           0      1  \n",
       "3           0           0           0      1  \n",
       "4           0           0           0      1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 95) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS383     1\n",
       "1       NRS254     1\n",
       "2       NRS218     1\n",
       "3       NRS215     0\n",
       "4    BCH-SA-14     2\n",
       "..         ...   ...\n",
       "112     NRS227     1\n",
       "113     NRS272     1\n",
       "114   CFBRSa24     0\n",
       "115   CFBRSa74     0\n",
       "116     NRS271     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 451us/step - loss: 1.0906 - accuracy: 0.3259 - val_loss: 1.0419 - val_accuracy: 0.4188\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9993 - accuracy: 0.5593 - val_loss: 1.0124 - val_accuracy: 0.5385\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.9526 - accuracy: 0.6000 - val_loss: 0.9882 - val_accuracy: 0.5299\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.9198 - accuracy: 0.5889 - val_loss: 0.9709 - val_accuracy: 0.5385\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8919 - accuracy: 0.5926 - val_loss: 0.9572 - val_accuracy: 0.5470\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.8736 - accuracy: 0.5963 - val_loss: 0.9511 - val_accuracy: 0.5556\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.8534 - accuracy: 0.6185 - val_loss: 0.9348 - val_accuracy: 0.5641\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8384 - accuracy: 0.6037 - val_loss: 0.9236 - val_accuracy: 0.6154\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.8226 - accuracy: 0.6259 - val_loss: 0.9148 - val_accuracy: 0.6068\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 466us/step - loss: 0.8088 - accuracy: 0.6370 - val_loss: 0.9045 - val_accuracy: 0.6154\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.7966 - accuracy: 0.6667 - val_loss: 0.8961 - val_accuracy: 0.6239\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 259us/step - loss: 0.7847 - accuracy: 0.6667 - val_loss: 0.8894 - val_accuracy: 0.6325\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.7760 - accuracy: 0.6704 - val_loss: 0.8863 - val_accuracy: 0.6325\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.7633 - accuracy: 0.6741 - val_loss: 0.8807 - val_accuracy: 0.6325\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7538 - accuracy: 0.6778 - val_loss: 0.8725 - val_accuracy: 0.6325\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.7459 - accuracy: 0.6926 - val_loss: 0.8663 - val_accuracy: 0.6325\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.7371 - accuracy: 0.6926 - val_loss: 0.8647 - val_accuracy: 0.6239\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.7271 - accuracy: 0.6963 - val_loss: 0.8581 - val_accuracy: 0.6239\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 338us/step - loss: 0.7181 - accuracy: 0.7000 - val_loss: 0.8536 - val_accuracy: 0.6239\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7088 - accuracy: 0.6963 - val_loss: 0.8495 - val_accuracy: 0.6239\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.7018 - accuracy: 0.6926 - val_loss: 0.8478 - val_accuracy: 0.6325\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6960 - accuracy: 0.7037 - val_loss: 0.8447 - val_accuracy: 0.6410\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6880 - accuracy: 0.7111 - val_loss: 0.8412 - val_accuracy: 0.6410\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.6802 - accuracy: 0.7074 - val_loss: 0.8390 - val_accuracy: 0.6410\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6722 - accuracy: 0.7111 - val_loss: 0.8369 - val_accuracy: 0.6410\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6643 - accuracy: 0.7148 - val_loss: 0.8310 - val_accuracy: 0.6410\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.6563 - accuracy: 0.7148 - val_loss: 0.8296 - val_accuracy: 0.6410\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.6505 - accuracy: 0.7222 - val_loss: 0.8287 - val_accuracy: 0.6496\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6424 - accuracy: 0.7333 - val_loss: 0.8307 - val_accuracy: 0.6496\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.6383 - accuracy: 0.7370 - val_loss: 0.8304 - val_accuracy: 0.6154\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6292 - accuracy: 0.7407 - val_loss: 0.8287 - val_accuracy: 0.6496\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6242 - accuracy: 0.7222 - val_loss: 0.8250 - val_accuracy: 0.6496\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.6159 - accuracy: 0.7296 - val_loss: 0.8279 - val_accuracy: 0.6154\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.6114 - accuracy: 0.7444 - val_loss: 0.8246 - val_accuracy: 0.6068\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.6021 - accuracy: 0.7407 - val_loss: 0.8199 - val_accuracy: 0.6496\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.6008 - accuracy: 0.7630 - val_loss: 0.8177 - val_accuracy: 0.7009\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.5917 - accuracy: 0.7444 - val_loss: 0.8165 - val_accuracy: 0.5983\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5862 - accuracy: 0.7556 - val_loss: 0.8180 - val_accuracy: 0.5983\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.5792 - accuracy: 0.7593 - val_loss: 0.8141 - val_accuracy: 0.6068\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.5741 - accuracy: 0.7852 - val_loss: 0.8132 - val_accuracy: 0.6410\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5678 - accuracy: 0.7667 - val_loss: 0.8148 - val_accuracy: 0.5983\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5632 - accuracy: 0.7667 - val_loss: 0.8094 - val_accuracy: 0.6410\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.5588 - accuracy: 0.7630 - val_loss: 0.8128 - val_accuracy: 0.6154\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.5521 - accuracy: 0.8111 - val_loss: 0.8029 - val_accuracy: 0.7009\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5462 - accuracy: 0.8185 - val_loss: 0.8042 - val_accuracy: 0.6410\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.5402 - accuracy: 0.8074 - val_loss: 0.8061 - val_accuracy: 0.6410\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.5383 - accuracy: 0.7963 - val_loss: 0.8038 - val_accuracy: 0.6581\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5315 - accuracy: 0.8037 - val_loss: 0.8042 - val_accuracy: 0.6410\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5276 - accuracy: 0.8111 - val_loss: 0.8045 - val_accuracy: 0.6325\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 352us/step - loss: 0.5230 - accuracy: 0.8185 - val_loss: 0.8051 - val_accuracy: 0.6410\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 487us/step - loss: 0.5166 - accuracy: 0.8111 - val_loss: 0.8042 - val_accuracy: 0.6581\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.5143 - accuracy: 0.8037 - val_loss: 0.8070 - val_accuracy: 0.6496\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 453us/step - loss: 0.5096 - accuracy: 0.8000 - val_loss: 0.8055 - val_accuracy: 0.6239\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.5048 - accuracy: 0.8037 - val_loss: 0.8015 - val_accuracy: 0.6496\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.5022 - accuracy: 0.8074 - val_loss: 0.7984 - val_accuracy: 0.6410\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 545us/step - loss: 0.4991 - accuracy: 0.8148 - val_loss: 0.8012 - val_accuracy: 0.6239\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 307us/step - loss: 0.4921 - accuracy: 0.8185 - val_loss: 0.7984 - val_accuracy: 0.6410\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4927 - accuracy: 0.8111 - val_loss: 0.8022 - val_accuracy: 0.6581\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.4878 - accuracy: 0.7963 - val_loss: 0.8104 - val_accuracy: 0.6239\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.4806 - accuracy: 0.8111 - val_loss: 0.8031 - val_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4795 - accuracy: 0.8185 - val_loss: 0.8025 - val_accuracy: 0.6667\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4755 - accuracy: 0.8296 - val_loss: 0.8019 - val_accuracy: 0.6410\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 377us/step - loss: 0.4705 - accuracy: 0.8259 - val_loss: 0.7935 - val_accuracy: 0.6923\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4667 - accuracy: 0.8185 - val_loss: 0.7957 - val_accuracy: 0.6838\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4616 - accuracy: 0.8407 - val_loss: 0.7979 - val_accuracy: 0.6581\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.4614 - accuracy: 0.8296 - val_loss: 0.7966 - val_accuracy: 0.6496\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.4555 - accuracy: 0.8222 - val_loss: 0.8052 - val_accuracy: 0.6581\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4540 - accuracy: 0.8296 - val_loss: 0.8074 - val_accuracy: 0.6496\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 338us/step - loss: 0.4554 - accuracy: 0.8148 - val_loss: 0.8064 - val_accuracy: 0.6752\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.4490 - accuracy: 0.8259 - val_loss: 0.8066 - val_accuracy: 0.6325\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.4448 - accuracy: 0.8370 - val_loss: 0.8019 - val_accuracy: 0.6496\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4444 - accuracy: 0.8296 - val_loss: 0.8219 - val_accuracy: 0.6496\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.4409 - accuracy: 0.8333 - val_loss: 0.8150 - val_accuracy: 0.6325\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.4384 - accuracy: 0.8259 - val_loss: 0.8039 - val_accuracy: 0.6667\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.4331 - accuracy: 0.8296 - val_loss: 0.8096 - val_accuracy: 0.6410\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.4292 - accuracy: 0.8370 - val_loss: 0.8043 - val_accuracy: 0.6325\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4255 - accuracy: 0.8185 - val_loss: 0.8041 - val_accuracy: 0.6325\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 332us/step - loss: 0.4228 - accuracy: 0.8407 - val_loss: 0.8068 - val_accuracy: 0.6325\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.4215 - accuracy: 0.8481 - val_loss: 0.8082 - val_accuracy: 0.6496\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 431us/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.8117 - val_accuracy: 0.6496\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 527us/step - loss: 0.4164 - accuracy: 0.8333 - val_loss: 0.8075 - val_accuracy: 0.6496\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4133 - accuracy: 0.8407 - val_loss: 0.8170 - val_accuracy: 0.6496\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.4146 - accuracy: 0.8370 - val_loss: 0.8126 - val_accuracy: 0.6239\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4082 - accuracy: 0.8444 - val_loss: 0.8175 - val_accuracy: 0.6496\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.4058 - accuracy: 0.8519 - val_loss: 0.8153 - val_accuracy: 0.6496\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 476us/step - loss: 0.4052 - accuracy: 0.8519 - val_loss: 0.8157 - val_accuracy: 0.6496\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.4027 - accuracy: 0.8296 - val_loss: 0.8177 - val_accuracy: 0.6496\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3990 - accuracy: 0.8444 - val_loss: 0.8270 - val_accuracy: 0.6068\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3984 - accuracy: 0.8556 - val_loss: 0.8218 - val_accuracy: 0.6581\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3963 - accuracy: 0.8519 - val_loss: 0.8273 - val_accuracy: 0.6154\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.3956 - accuracy: 0.8444 - val_loss: 0.8239 - val_accuracy: 0.6752\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3922 - accuracy: 0.8519 - val_loss: 0.8206 - val_accuracy: 0.6154\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3915 - accuracy: 0.8519 - val_loss: 0.8171 - val_accuracy: 0.6581\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.3875 - accuracy: 0.8444 - val_loss: 0.8176 - val_accuracy: 0.6410\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.3876 - accuracy: 0.8556 - val_loss: 0.8243 - val_accuracy: 0.6325\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3839 - accuracy: 0.8593 - val_loss: 0.8304 - val_accuracy: 0.6325\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 336us/step - loss: 0.3817 - accuracy: 0.8556 - val_loss: 0.8269 - val_accuracy: 0.6325\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3810 - accuracy: 0.8519 - val_loss: 0.8191 - val_accuracy: 0.6581\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 264us/step - loss: 0.3848 - accuracy: 0.8407 - val_loss: 0.8211 - val_accuracy: 0.6752\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.3773 - accuracy: 0.8481 - val_loss: 0.8324 - val_accuracy: 0.6410\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.3755 - accuracy: 0.8519 - val_loss: 0.8233 - val_accuracy: 0.6581\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.3778 - accuracy: 0.8407 - val_loss: 0.8267 - val_accuracy: 0.6325\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3696 - accuracy: 0.8519 - val_loss: 0.8338 - val_accuracy: 0.6154\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.3729 - accuracy: 0.8556 - val_loss: 0.8373 - val_accuracy: 0.6154\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.3679 - accuracy: 0.8519 - val_loss: 0.8329 - val_accuracy: 0.6325\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3675 - accuracy: 0.8556 - val_loss: 0.8355 - val_accuracy: 0.6154\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 320us/step - loss: 0.3658 - accuracy: 0.8593 - val_loss: 0.8335 - val_accuracy: 0.6325\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 247us/step - loss: 0.3650 - accuracy: 0.8593 - val_loss: 0.8299 - val_accuracy: 0.6325\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.3689 - accuracy: 0.8519 - val_loss: 0.8430 - val_accuracy: 0.6154\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.3649 - accuracy: 0.8444 - val_loss: 0.8330 - val_accuracy: 0.6325\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.3589 - accuracy: 0.8593 - val_loss: 0.8497 - val_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.3641 - accuracy: 0.8519 - val_loss: 0.8336 - val_accuracy: 0.6496\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.3584 - accuracy: 0.8667 - val_loss: 0.8406 - val_accuracy: 0.6410\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.3546 - accuracy: 0.8667 - val_loss: 0.8367 - val_accuracy: 0.6410\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3589 - accuracy: 0.8556 - val_loss: 0.8401 - val_accuracy: 0.6325\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3510 - accuracy: 0.8593 - val_loss: 0.8596 - val_accuracy: 0.6239\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3535 - accuracy: 0.8593 - val_loss: 0.8473 - val_accuracy: 0.6239\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.3543 - accuracy: 0.8519 - val_loss: 0.8399 - val_accuracy: 0.6325\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.3487 - accuracy: 0.8519 - val_loss: 0.8527 - val_accuracy: 0.6325\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3493 - accuracy: 0.8667 - val_loss: 0.8441 - val_accuracy: 0.6410\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.3443 - accuracy: 0.8667 - val_loss: 0.8413 - val_accuracy: 0.6410\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 359us/step - loss: 0.3459 - accuracy: 0.8704 - val_loss: 0.8511 - val_accuracy: 0.6239\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.3424 - accuracy: 0.8556 - val_loss: 0.8448 - val_accuracy: 0.6410\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.3413 - accuracy: 0.8630 - val_loss: 0.8474 - val_accuracy: 0.6239\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3398 - accuracy: 0.8704 - val_loss: 0.8419 - val_accuracy: 0.6410\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.3389 - accuracy: 0.8741 - val_loss: 0.8391 - val_accuracy: 0.6410\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 368us/step - loss: 0.3382 - accuracy: 0.8741 - val_loss: 0.8456 - val_accuracy: 0.6410\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3417 - accuracy: 0.8630 - val_loss: 0.8533 - val_accuracy: 0.6410\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3366 - accuracy: 0.8593 - val_loss: 0.8445 - val_accuracy: 0.6581\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3359 - accuracy: 0.8630 - val_loss: 0.8512 - val_accuracy: 0.6410\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3339 - accuracy: 0.8741 - val_loss: 0.8485 - val_accuracy: 0.6410\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.3329 - accuracy: 0.8741 - val_loss: 0.8529 - val_accuracy: 0.6410\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.3314 - accuracy: 0.8630 - val_loss: 0.8612 - val_accuracy: 0.6239\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.3310 - accuracy: 0.8630 - val_loss: 0.8613 - val_accuracy: 0.6325\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3308 - accuracy: 0.8704 - val_loss: 0.8525 - val_accuracy: 0.6410\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3268 - accuracy: 0.8704 - val_loss: 0.8597 - val_accuracy: 0.6410\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 289us/step - loss: 0.3273 - accuracy: 0.8704 - val_loss: 0.8608 - val_accuracy: 0.6410\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.3242 - accuracy: 0.8704 - val_loss: 0.8627 - val_accuracy: 0.6410\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3255 - accuracy: 0.8704 - val_loss: 0.8675 - val_accuracy: 0.6410\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3234 - accuracy: 0.8741 - val_loss: 0.8474 - val_accuracy: 0.6838\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3252 - accuracy: 0.8778 - val_loss: 0.8592 - val_accuracy: 0.6581\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.3234 - accuracy: 0.8704 - val_loss: 0.8631 - val_accuracy: 0.6496\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 313us/step - loss: 0.3226 - accuracy: 0.8704 - val_loss: 0.8802 - val_accuracy: 0.6496\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.3191 - accuracy: 0.8704 - val_loss: 0.8720 - val_accuracy: 0.6410\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.3203 - accuracy: 0.8704 - val_loss: 0.8667 - val_accuracy: 0.6496\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3188 - accuracy: 0.8704 - val_loss: 0.8762 - val_accuracy: 0.6410\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.3172 - accuracy: 0.8704 - val_loss: 0.8727 - val_accuracy: 0.6496\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 366us/step - loss: 0.3178 - accuracy: 0.8704 - val_loss: 0.8689 - val_accuracy: 0.6496\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.3138 - accuracy: 0.8704 - val_loss: 0.8740 - val_accuracy: 0.6496\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.3157 - accuracy: 0.8593 - val_loss: 0.8710 - val_accuracy: 0.6496\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.3130 - accuracy: 0.8741 - val_loss: 0.8796 - val_accuracy: 0.6496\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3133 - accuracy: 0.8667 - val_loss: 0.8639 - val_accuracy: 0.6496\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3119 - accuracy: 0.8741 - val_loss: 0.8622 - val_accuracy: 0.6496\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3118 - accuracy: 0.8741 - val_loss: 0.8669 - val_accuracy: 0.6496\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.3103 - accuracy: 0.8741 - val_loss: 0.8693 - val_accuracy: 0.6581\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3118 - accuracy: 0.8667 - val_loss: 0.8760 - val_accuracy: 0.6496\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.8760 - val_accuracy: 0.6496\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.3068 - accuracy: 0.8704 - val_loss: 0.8745 - val_accuracy: 0.6496\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.3100 - accuracy: 0.8630 - val_loss: 0.8737 - val_accuracy: 0.6496\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.3137 - accuracy: 0.8667 - val_loss: 0.8835 - val_accuracy: 0.6325\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.3091 - accuracy: 0.8630 - val_loss: 0.8679 - val_accuracy: 0.6667\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.3060 - accuracy: 0.8667 - val_loss: 0.8890 - val_accuracy: 0.6496\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.3027 - accuracy: 0.8704 - val_loss: 0.8892 - val_accuracy: 0.6496\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3037 - accuracy: 0.8704 - val_loss: 0.8839 - val_accuracy: 0.6496\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3013 - accuracy: 0.8704 - val_loss: 0.8793 - val_accuracy: 0.6496\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.3065 - accuracy: 0.8667 - val_loss: 0.8880 - val_accuracy: 0.6496\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3043 - accuracy: 0.8741 - val_loss: 0.8777 - val_accuracy: 0.6496\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 348us/step - loss: 0.3025 - accuracy: 0.8667 - val_loss: 0.8973 - val_accuracy: 0.6496\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 392us/step - loss: 0.2975 - accuracy: 0.8704 - val_loss: 0.8955 - val_accuracy: 0.6496\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2970 - accuracy: 0.8704 - val_loss: 0.8889 - val_accuracy: 0.6496\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2978 - accuracy: 0.8778 - val_loss: 0.8931 - val_accuracy: 0.6496\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2973 - accuracy: 0.8741 - val_loss: 0.8967 - val_accuracy: 0.6496\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2962 - accuracy: 0.8704 - val_loss: 0.8922 - val_accuracy: 0.6496\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.3083 - accuracy: 0.8593 - val_loss: 0.8802 - val_accuracy: 0.6667\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2960 - accuracy: 0.8741 - val_loss: 0.9069 - val_accuracy: 0.6496\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2974 - accuracy: 0.8704 - val_loss: 0.9103 - val_accuracy: 0.6581\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2927 - accuracy: 0.8741 - val_loss: 0.9121 - val_accuracy: 0.6496\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2910 - accuracy: 0.8741 - val_loss: 0.9082 - val_accuracy: 0.6581\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2919 - accuracy: 0.8741 - val_loss: 0.9041 - val_accuracy: 0.6496\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2947 - accuracy: 0.8778 - val_loss: 0.9010 - val_accuracy: 0.6496\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2912 - accuracy: 0.8778 - val_loss: 0.9107 - val_accuracy: 0.6496\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2904 - accuracy: 0.8741 - val_loss: 0.9041 - val_accuracy: 0.6496\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.2925 - accuracy: 0.8741 - val_loss: 0.9012 - val_accuracy: 0.6496\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2892 - accuracy: 0.8778 - val_loss: 0.9149 - val_accuracy: 0.6496\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2912 - accuracy: 0.8741 - val_loss: 0.9017 - val_accuracy: 0.6496\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2883 - accuracy: 0.8778 - val_loss: 0.9126 - val_accuracy: 0.6581\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2876 - accuracy: 0.8704 - val_loss: 0.9021 - val_accuracy: 0.6496\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2851 - accuracy: 0.8704 - val_loss: 0.9153 - val_accuracy: 0.6496\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2886 - accuracy: 0.8741 - val_loss: 0.9177 - val_accuracy: 0.6496\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2833 - accuracy: 0.8741 - val_loss: 0.9170 - val_accuracy: 0.6496\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2869 - accuracy: 0.8704 - val_loss: 0.9194 - val_accuracy: 0.6581\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2830 - accuracy: 0.8741 - val_loss: 0.9040 - val_accuracy: 0.6496\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2839 - accuracy: 0.8741 - val_loss: 0.9158 - val_accuracy: 0.6496\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2857 - accuracy: 0.8778 - val_loss: 0.9233 - val_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2850 - accuracy: 0.8741 - val_loss: 0.9229 - val_accuracy: 0.6667\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2810 - accuracy: 0.8815 - val_loss: 0.9149 - val_accuracy: 0.6581\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2856 - accuracy: 0.8741 - val_loss: 0.9236 - val_accuracy: 0.6496\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2810 - accuracy: 0.8741 - val_loss: 0.9164 - val_accuracy: 0.6667\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 406us/step - loss: 0.2819 - accuracy: 0.8741 - val_loss: 0.9112 - val_accuracy: 0.6581\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2789 - accuracy: 0.8815 - val_loss: 0.9150 - val_accuracy: 0.6581\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2779 - accuracy: 0.8852 - val_loss: 0.9180 - val_accuracy: 0.6496\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2776 - accuracy: 0.8741 - val_loss: 0.9217 - val_accuracy: 0.6667\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2759 - accuracy: 0.8815 - val_loss: 0.9209 - val_accuracy: 0.6496\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2754 - accuracy: 0.8815 - val_loss: 0.9140 - val_accuracy: 0.6496\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2768 - accuracy: 0.8815 - val_loss: 0.9222 - val_accuracy: 0.6581\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2763 - accuracy: 0.8852 - val_loss: 0.9182 - val_accuracy: 0.6496\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2735 - accuracy: 0.8852 - val_loss: 0.9303 - val_accuracy: 0.6581\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.2769 - accuracy: 0.8741 - val_loss: 0.9350 - val_accuracy: 0.6581\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2735 - accuracy: 0.8815 - val_loss: 0.9234 - val_accuracy: 0.6496\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2735 - accuracy: 0.8852 - val_loss: 0.9244 - val_accuracy: 0.6581\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2778 - accuracy: 0.8852 - val_loss: 0.9193 - val_accuracy: 0.6496\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2716 - accuracy: 0.8778 - val_loss: 0.9362 - val_accuracy: 0.6581\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2726 - accuracy: 0.8815 - val_loss: 0.9278 - val_accuracy: 0.6581\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2739 - accuracy: 0.8741 - val_loss: 0.9229 - val_accuracy: 0.6581\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2723 - accuracy: 0.8815 - val_loss: 0.9484 - val_accuracy: 0.6581\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2750 - accuracy: 0.8667 - val_loss: 0.9255 - val_accuracy: 0.6752\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2705 - accuracy: 0.8778 - val_loss: 0.9420 - val_accuracy: 0.6496\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2704 - accuracy: 0.8815 - val_loss: 0.9367 - val_accuracy: 0.6581\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2705 - accuracy: 0.8852 - val_loss: 0.9316 - val_accuracy: 0.6581\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2683 - accuracy: 0.8852 - val_loss: 0.9369 - val_accuracy: 0.6581\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2691 - accuracy: 0.8778 - val_loss: 0.9372 - val_accuracy: 0.6581\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 103us/step - loss: 0.2679 - accuracy: 0.8741 - val_loss: 0.9257 - val_accuracy: 0.6581\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2690 - accuracy: 0.8815 - val_loss: 0.9518 - val_accuracy: 0.6581\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.78 - 0s 98us/step - loss: 0.2646 - accuracy: 0.8926 - val_loss: 0.9242 - val_accuracy: 0.6923\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2750 - accuracy: 0.8852 - val_loss: 0.9252 - val_accuracy: 0.6923\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2656 - accuracy: 0.8852 - val_loss: 0.9460 - val_accuracy: 0.6667\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2695 - accuracy: 0.8815 - val_loss: 0.9334 - val_accuracy: 0.6667\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2663 - accuracy: 0.8815 - val_loss: 0.9376 - val_accuracy: 0.6496\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2650 - accuracy: 0.8889 - val_loss: 0.9441 - val_accuracy: 0.6581\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2648 - accuracy: 0.8852 - val_loss: 0.9363 - val_accuracy: 0.6581\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2666 - accuracy: 0.8889 - val_loss: 0.9337 - val_accuracy: 0.6581\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2634 - accuracy: 0.8815 - val_loss: 0.9516 - val_accuracy: 0.6581\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2659 - accuracy: 0.8815 - val_loss: 0.9421 - val_accuracy: 0.6581\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2630 - accuracy: 0.8889 - val_loss: 0.9507 - val_accuracy: 0.6581\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2619 - accuracy: 0.8926 - val_loss: 0.9432 - val_accuracy: 0.6581\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2627 - accuracy: 0.8852 - val_loss: 0.9376 - val_accuracy: 0.6667\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2673 - accuracy: 0.8704 - val_loss: 0.9260 - val_accuracy: 0.7009\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2627 - accuracy: 0.8815 - val_loss: 0.9565 - val_accuracy: 0.6581\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2609 - accuracy: 0.8889 - val_loss: 0.9375 - val_accuracy: 0.6581\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2601 - accuracy: 0.8926 - val_loss: 0.9437 - val_accuracy: 0.6581\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2598 - accuracy: 0.8889 - val_loss: 0.9459 - val_accuracy: 0.6581\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2604 - accuracy: 0.8889 - val_loss: 0.9433 - val_accuracy: 0.6581\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2585 - accuracy: 0.8926 - val_loss: 0.9429 - val_accuracy: 0.6923\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2581 - accuracy: 0.8926 - val_loss: 0.9535 - val_accuracy: 0.6667\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2591 - accuracy: 0.8926 - val_loss: 0.9413 - val_accuracy: 0.6923\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2577 - accuracy: 0.8889 - val_loss: 0.9560 - val_accuracy: 0.6581\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.9486 - val_accuracy: 0.6581\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2559 - accuracy: 0.8852 - val_loss: 0.9500 - val_accuracy: 0.6667\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2564 - accuracy: 0.8889 - val_loss: 0.9546 - val_accuracy: 0.6923\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2559 - accuracy: 0.8926 - val_loss: 0.9427 - val_accuracy: 0.6581\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2590 - accuracy: 0.8815 - val_loss: 0.9569 - val_accuracy: 0.6581\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2598 - accuracy: 0.8963 - val_loss: 0.9545 - val_accuracy: 0.6667\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2567 - accuracy: 0.8815 - val_loss: 0.9394 - val_accuracy: 0.6838\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2614 - accuracy: 0.8815 - val_loss: 0.9627 - val_accuracy: 0.6581\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2536 - accuracy: 0.8926 - val_loss: 0.9440 - val_accuracy: 0.7009\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2554 - accuracy: 0.8852 - val_loss: 0.9407 - val_accuracy: 0.7009\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2521 - accuracy: 0.8889 - val_loss: 0.9679 - val_accuracy: 0.6667\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2543 - accuracy: 0.8926 - val_loss: 0.9637 - val_accuracy: 0.6581\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2546 - accuracy: 0.8926 - val_loss: 0.9446 - val_accuracy: 0.6752\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2594 - accuracy: 0.8815 - val_loss: 0.9648 - val_accuracy: 0.6581\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2570 - accuracy: 0.8852 - val_loss: 0.9568 - val_accuracy: 0.6752\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2541 - accuracy: 0.8889 - val_loss: 0.9522 - val_accuracy: 0.6667\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2513 - accuracy: 0.8926 - val_loss: 0.9656 - val_accuracy: 0.7009\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2548 - accuracy: 0.8852 - val_loss: 0.9646 - val_accuracy: 0.6923\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2473 - accuracy: 0.8926 - val_loss: 0.9418 - val_accuracy: 0.7009\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2520 - accuracy: 0.8926 - val_loss: 0.9508 - val_accuracy: 0.7009\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 0.9497 - val_accuracy: 0.7009\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2512 - accuracy: 0.8926 - val_loss: 0.9544 - val_accuracy: 0.6923\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2531 - accuracy: 0.8963 - val_loss: 0.9687 - val_accuracy: 0.7009\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2497 - accuracy: 0.8926 - val_loss: 0.9452 - val_accuracy: 0.7094\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2525 - accuracy: 0.9037 - val_loss: 0.9684 - val_accuracy: 0.7009\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2473 - accuracy: 0.8926 - val_loss: 0.9577 - val_accuracy: 0.7179\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2494 - accuracy: 0.8815 - val_loss: 0.9680 - val_accuracy: 0.6923\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2487 - accuracy: 0.8926 - val_loss: 0.9651 - val_accuracy: 0.7009\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2467 - accuracy: 0.8926 - val_loss: 0.9652 - val_accuracy: 0.7009\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2456 - accuracy: 0.8926 - val_loss: 0.9678 - val_accuracy: 0.6923\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2469 - accuracy: 0.8926 - val_loss: 0.9684 - val_accuracy: 0.7009\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 0.9610 - val_accuracy: 0.6923\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2449 - accuracy: 0.8889 - val_loss: 0.9789 - val_accuracy: 0.6923\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2482 - accuracy: 0.8963 - val_loss: 0.9718 - val_accuracy: 0.7009\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2449 - accuracy: 0.8963 - val_loss: 0.9608 - val_accuracy: 0.7094\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2480 - accuracy: 0.8889 - val_loss: 0.9584 - val_accuracy: 0.7094\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.9926 - val_accuracy: 0.7009\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2473 - accuracy: 0.8926 - val_loss: 0.9662 - val_accuracy: 0.6923\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2425 - accuracy: 0.8963 - val_loss: 0.9739 - val_accuracy: 0.7009\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2552 - accuracy: 0.8889 - val_loss: 0.9997 - val_accuracy: 0.6752\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2442 - accuracy: 0.8963 - val_loss: 0.9724 - val_accuracy: 0.7009\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2437 - accuracy: 0.8926 - val_loss: 0.9737 - val_accuracy: 0.6923\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 0.9880 - val_accuracy: 0.6752\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2422 - accuracy: 0.8963 - val_loss: 0.9878 - val_accuracy: 0.7094\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2439 - accuracy: 0.8926 - val_loss: 0.9746 - val_accuracy: 0.7009\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2429 - accuracy: 0.8926 - val_loss: 0.9646 - val_accuracy: 0.7009\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2417 - accuracy: 0.8889 - val_loss: 0.9776 - val_accuracy: 0.7009\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2419 - accuracy: 0.8926 - val_loss: 0.9781 - val_accuracy: 0.6923\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2441 - accuracy: 0.8852 - val_loss: 0.9723 - val_accuracy: 0.7179\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9748 - val_accuracy: 0.7094\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2423 - accuracy: 0.8963 - val_loss: 0.9744 - val_accuracy: 0.7094\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2416 - accuracy: 0.8963 - val_loss: 0.9699 - val_accuracy: 0.7094\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2429 - accuracy: 0.8926 - val_loss: 0.9854 - val_accuracy: 0.7009\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2399 - accuracy: 0.8926 - val_loss: 0.9835 - val_accuracy: 0.7179\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2427 - accuracy: 0.8889 - val_loss: 0.9670 - val_accuracy: 0.7009\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2366 - accuracy: 0.8963 - val_loss: 0.9886 - val_accuracy: 0.6923\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2538 - accuracy: 0.8963 - val_loss: 1.0045 - val_accuracy: 0.7009\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2417 - accuracy: 0.8889 - val_loss: 0.9702 - val_accuracy: 0.7179\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 0.9801 - val_accuracy: 0.7009\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2403 - accuracy: 0.8889 - val_loss: 0.9878 - val_accuracy: 0.7009\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2377 - accuracy: 0.9000 - val_loss: 0.9878 - val_accuracy: 0.7009\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 0.9797 - val_accuracy: 0.7179\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2419 - accuracy: 0.8926 - val_loss: 1.0018 - val_accuracy: 0.7094\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2413 - accuracy: 0.8963 - val_loss: 1.0011 - val_accuracy: 0.7009\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2395 - accuracy: 0.8963 - val_loss: 0.9751 - val_accuracy: 0.7265\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2398 - accuracy: 0.8926 - val_loss: 0.9821 - val_accuracy: 0.7009\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2367 - accuracy: 0.9000 - val_loss: 0.9896 - val_accuracy: 0.7009\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2396 - accuracy: 0.9000 - val_loss: 0.9914 - val_accuracy: 0.7094\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2363 - accuracy: 0.8963 - val_loss: 0.9804 - val_accuracy: 0.7094\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2363 - accuracy: 0.8963 - val_loss: 0.9849 - val_accuracy: 0.7094\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2346 - accuracy: 0.9000 - val_loss: 0.9966 - val_accuracy: 0.7009\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2350 - accuracy: 0.8963 - val_loss: 0.9921 - val_accuracy: 0.7094\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2338 - accuracy: 0.8963 - val_loss: 0.9850 - val_accuracy: 0.7179\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 0.9901 - val_accuracy: 0.7094\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2379 - accuracy: 0.8963 - val_loss: 1.0003 - val_accuracy: 0.7009\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2382 - accuracy: 0.8963 - val_loss: 0.9883 - val_accuracy: 0.7094\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2363 - accuracy: 0.9000 - val_loss: 0.9934 - val_accuracy: 0.7094\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2343 - accuracy: 0.9000 - val_loss: 1.0022 - val_accuracy: 0.7009\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2380 - accuracy: 0.8963 - val_loss: 1.0057 - val_accuracy: 0.7094\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2333 - accuracy: 0.8926 - val_loss: 0.9913 - val_accuracy: 0.7009\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2364 - accuracy: 0.9000 - val_loss: 1.0008 - val_accuracy: 0.7094\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2330 - accuracy: 0.8963 - val_loss: 0.9948 - val_accuracy: 0.7009\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2339 - accuracy: 0.9000 - val_loss: 0.9949 - val_accuracy: 0.7094\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2340 - accuracy: 0.8963 - val_loss: 0.9974 - val_accuracy: 0.7009\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2364 - accuracy: 0.8963 - val_loss: 1.0033 - val_accuracy: 0.6923\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 129us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.0029 - val_accuracy: 0.7009\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2315 - accuracy: 0.9000 - val_loss: 0.9962 - val_accuracy: 0.7094\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2335 - accuracy: 0.8963 - val_loss: 1.0035 - val_accuracy: 0.7094\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2376 - accuracy: 0.9000 - val_loss: 1.0154 - val_accuracy: 0.7179\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2359 - accuracy: 0.8815 - val_loss: 0.9969 - val_accuracy: 0.7094\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2371 - accuracy: 0.8889 - val_loss: 0.9996 - val_accuracy: 0.7094\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2351 - accuracy: 0.8963 - val_loss: 0.9938 - val_accuracy: 0.7265\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2284 - accuracy: 0.9037 - val_loss: 1.0168 - val_accuracy: 0.7094\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2356 - accuracy: 0.8963 - val_loss: 1.0170 - val_accuracy: 0.7094\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2320 - accuracy: 0.8963 - val_loss: 1.0050 - val_accuracy: 0.7094\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2316 - accuracy: 0.8889 - val_loss: 1.0090 - val_accuracy: 0.7094\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2310 - accuracy: 0.8926 - val_loss: 1.0143 - val_accuracy: 0.7009\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2302 - accuracy: 0.9000 - val_loss: 1.0094 - val_accuracy: 0.7094\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2296 - accuracy: 0.8963 - val_loss: 1.0120 - val_accuracy: 0.7009\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2304 - accuracy: 0.8963 - val_loss: 1.0112 - val_accuracy: 0.7094\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2301 - accuracy: 0.9000 - val_loss: 1.0093 - val_accuracy: 0.7009\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2291 - accuracy: 0.9000 - val_loss: 1.0071 - val_accuracy: 0.7094\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2298 - accuracy: 0.9000 - val_loss: 1.0098 - val_accuracy: 0.7094\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2295 - accuracy: 0.8926 - val_loss: 1.0063 - val_accuracy: 0.7094\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2345 - accuracy: 0.8926 - val_loss: 1.0228 - val_accuracy: 0.7094\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.0096 - val_accuracy: 0.7179\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2336 - accuracy: 0.9000 - val_loss: 1.0327 - val_accuracy: 0.7094\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2312 - accuracy: 0.9000 - val_loss: 1.0049 - val_accuracy: 0.7094\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2278 - accuracy: 0.9000 - val_loss: 1.0051 - val_accuracy: 0.7094\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2311 - accuracy: 0.8926 - val_loss: 1.0158 - val_accuracy: 0.7094\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2279 - accuracy: 0.8852 - val_loss: 1.0049 - val_accuracy: 0.7265\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2321 - accuracy: 0.8963 - val_loss: 1.0277 - val_accuracy: 0.7094\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2299 - accuracy: 0.8926 - val_loss: 1.0130 - val_accuracy: 0.7094\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2318 - accuracy: 0.8815 - val_loss: 1.0049 - val_accuracy: 0.7094\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2272 - accuracy: 0.8926 - val_loss: 1.0221 - val_accuracy: 0.7094\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2282 - accuracy: 0.8963 - val_loss: 1.0276 - val_accuracy: 0.7094\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.8963 - val_loss: 1.0152 - val_accuracy: 0.7094\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2299 - accuracy: 0.8815 - val_loss: 1.0018 - val_accuracy: 0.7094\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2358 - accuracy: 0.8926 - val_loss: 1.0314 - val_accuracy: 0.7094\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2305 - accuracy: 0.9000 - val_loss: 1.0216 - val_accuracy: 0.7094\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2277 - accuracy: 0.9000 - val_loss: 1.0375 - val_accuracy: 0.7009\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2303 - accuracy: 0.8889 - val_loss: 1.0285 - val_accuracy: 0.6752\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2273 - accuracy: 0.9000 - val_loss: 1.0410 - val_accuracy: 0.7094\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2274 - accuracy: 0.9000 - val_loss: 1.0334 - val_accuracy: 0.7094\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2268 - accuracy: 0.8926 - val_loss: 1.0407 - val_accuracy: 0.6752\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2253 - accuracy: 0.8963 - val_loss: 1.0345 - val_accuracy: 0.7094\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2307 - accuracy: 0.8889 - val_loss: 1.0180 - val_accuracy: 0.7265\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2278 - accuracy: 0.8963 - val_loss: 1.0370 - val_accuracy: 0.7009\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2260 - accuracy: 0.9000 - val_loss: 1.0385 - val_accuracy: 0.7009\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2265 - accuracy: 0.8741 - val_loss: 1.0235 - val_accuracy: 0.7179\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2251 - accuracy: 0.9000 - val_loss: 1.0320 - val_accuracy: 0.7179\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2257 - accuracy: 0.8889 - val_loss: 1.0410 - val_accuracy: 0.7179\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2234 - accuracy: 0.9037 - val_loss: 1.0306 - val_accuracy: 0.7094\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2255 - accuracy: 0.9000 - val_loss: 1.0238 - val_accuracy: 0.7094\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2287 - accuracy: 0.9000 - val_loss: 1.0339 - val_accuracy: 0.7094\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2252 - accuracy: 0.8889 - val_loss: 1.0260 - val_accuracy: 0.7094\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2254 - accuracy: 0.8926 - val_loss: 1.0368 - val_accuracy: 0.7094\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2244 - accuracy: 0.8963 - val_loss: 1.0375 - val_accuracy: 0.7094\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2251 - accuracy: 0.9000 - val_loss: 1.0358 - val_accuracy: 0.7094\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2232 - accuracy: 0.9000 - val_loss: 1.0365 - val_accuracy: 0.7094\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2235 - accuracy: 0.9000 - val_loss: 1.0375 - val_accuracy: 0.7094\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2240 - accuracy: 0.9000 - val_loss: 1.0414 - val_accuracy: 0.7094\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2249 - accuracy: 0.8963 - val_loss: 1.0441 - val_accuracy: 0.7094\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2241 - accuracy: 0.8963 - val_loss: 1.0329 - val_accuracy: 0.7094\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2253 - accuracy: 0.9000 - val_loss: 1.0429 - val_accuracy: 0.7094\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2234 - accuracy: 0.8963 - val_loss: 1.0477 - val_accuracy: 0.7179\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2281 - accuracy: 0.9000 - val_loss: 1.0532 - val_accuracy: 0.7179\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2279 - accuracy: 0.8815 - val_loss: 1.0256 - val_accuracy: 0.7094\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2239 - accuracy: 0.9000 - val_loss: 1.0484 - val_accuracy: 0.7094\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2232 - accuracy: 0.8926 - val_loss: 1.0514 - val_accuracy: 0.7094\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2220 - accuracy: 0.9000 - val_loss: 1.0425 - val_accuracy: 0.7094\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2299 - accuracy: 0.8815 - val_loss: 1.0479 - val_accuracy: 0.7179\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2211 - accuracy: 0.8963 - val_loss: 1.0424 - val_accuracy: 0.7094\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2236 - accuracy: 0.9000 - val_loss: 1.0511 - val_accuracy: 0.7009\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2238 - accuracy: 0.8926 - val_loss: 1.0499 - val_accuracy: 0.7094\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2248 - accuracy: 0.8926 - val_loss: 1.0445 - val_accuracy: 0.7094\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2255 - accuracy: 0.8926 - val_loss: 1.0490 - val_accuracy: 0.7094\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2226 - accuracy: 0.8963 - val_loss: 1.0528 - val_accuracy: 0.7179\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2200 - accuracy: 0.8926 - val_loss: 1.0435 - val_accuracy: 0.7094\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2226 - accuracy: 0.8889 - val_loss: 1.0469 - val_accuracy: 0.7179\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2199 - accuracy: 0.9000 - val_loss: 1.0580 - val_accuracy: 0.7094\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2239 - accuracy: 0.9000 - val_loss: 1.0666 - val_accuracy: 0.7094\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2216 - accuracy: 0.9000 - val_loss: 1.0524 - val_accuracy: 0.7094\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2204 - accuracy: 0.8926 - val_loss: 1.0461 - val_accuracy: 0.7094\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2226 - accuracy: 0.8778 - val_loss: 1.0499 - val_accuracy: 0.7094\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2206 - accuracy: 0.8963 - val_loss: 1.0681 - val_accuracy: 0.7094\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2248 - accuracy: 0.9037 - val_loss: 1.0461 - val_accuracy: 0.7094\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2237 - accuracy: 0.9000 - val_loss: 1.0521 - val_accuracy: 0.7094\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2202 - accuracy: 0.9000 - val_loss: 1.0718 - val_accuracy: 0.7009\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2232 - accuracy: 0.9000 - val_loss: 1.0649 - val_accuracy: 0.7094\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2208 - accuracy: 0.9000 - val_loss: 1.0587 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2188 - accuracy: 0.8963 - val_loss: 1.0639 - val_accuracy: 0.7094\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2191 - accuracy: 0.9000 - val_loss: 1.0684 - val_accuracy: 0.7009\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2190 - accuracy: 0.8963 - val_loss: 1.0611 - val_accuracy: 0.7094\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2199 - accuracy: 0.9000 - val_loss: 1.0539 - val_accuracy: 0.7094\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2205 - accuracy: 0.9000 - val_loss: 1.0597 - val_accuracy: 0.7094\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2215 - accuracy: 0.8963 - val_loss: 1.0631 - val_accuracy: 0.7179\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2239 - accuracy: 0.8963 - val_loss: 1.0706 - val_accuracy: 0.7009\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2247 - accuracy: 0.8963 - val_loss: 1.0659 - val_accuracy: 0.7094\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2264 - accuracy: 0.8889 - val_loss: 1.0858 - val_accuracy: 0.7094\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2234 - accuracy: 0.8926 - val_loss: 1.0717 - val_accuracy: 0.7094\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2239 - accuracy: 0.8630 - val_loss: 1.0565 - val_accuracy: 0.7265\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2206 - accuracy: 0.9000 - val_loss: 1.0744 - val_accuracy: 0.7009\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2310 - accuracy: 0.9000 - val_loss: 1.0804 - val_accuracy: 0.7094\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2209 - accuracy: 0.8963 - val_loss: 1.0619 - val_accuracy: 0.7094\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2179 - accuracy: 0.9000 - val_loss: 1.0604 - val_accuracy: 0.7094\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2167 - accuracy: 0.9000 - val_loss: 1.0680 - val_accuracy: 0.7009\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2198 - accuracy: 0.8852 - val_loss: 1.0845 - val_accuracy: 0.7094\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2196 - accuracy: 0.8963 - val_loss: 1.0622 - val_accuracy: 0.7094\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2221 - accuracy: 0.9000 - val_loss: 1.0721 - val_accuracy: 0.7094\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2194 - accuracy: 0.8815 - val_loss: 1.0598 - val_accuracy: 0.7094\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2184 - accuracy: 0.9000 - val_loss: 1.0571 - val_accuracy: 0.7094\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2176 - accuracy: 0.9000 - val_loss: 1.0685 - val_accuracy: 0.7094\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2198 - accuracy: 0.9000 - val_loss: 1.0745 - val_accuracy: 0.7009\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2189 - accuracy: 0.8963 - val_loss: 1.0772 - val_accuracy: 0.7094\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 108us/step - loss: 0.2207 - accuracy: 0.8926 - val_loss: 1.0631 - val_accuracy: 0.7094\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2153 - accuracy: 0.9000 - val_loss: 1.0747 - val_accuracy: 0.7009\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2210 - accuracy: 0.8963 - val_loss: 1.0804 - val_accuracy: 0.7094\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2218 - accuracy: 0.8852 - val_loss: 1.0714 - val_accuracy: 0.7265\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2193 - accuracy: 0.8778 - val_loss: 1.0904 - val_accuracy: 0.7009\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2184 - accuracy: 0.8889 - val_loss: 1.0789 - val_accuracy: 0.7179\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2207 - accuracy: 0.8889 - val_loss: 1.0666 - val_accuracy: 0.7265\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2207 - accuracy: 0.9074 - val_loss: 1.0876 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2177 - accuracy: 0.9000 - val_loss: 1.0744 - val_accuracy: 0.7094\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2191 - accuracy: 0.8889 - val_loss: 1.0755 - val_accuracy: 0.7094\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2156 - accuracy: 0.8889 - val_loss: 1.0741 - val_accuracy: 0.7009\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2197 - accuracy: 0.9000 - val_loss: 1.0700 - val_accuracy: 0.7094\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2189 - accuracy: 0.9000 - val_loss: 1.0758 - val_accuracy: 0.7094\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.8852 - val_loss: 1.0710 - val_accuracy: 0.7094\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2190 - accuracy: 0.9000 - val_loss: 1.1014 - val_accuracy: 0.7094\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2167 - accuracy: 0.8926 - val_loss: 1.0789 - val_accuracy: 0.7094\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2215 - accuracy: 0.8889 - val_loss: 1.0812 - val_accuracy: 0.7179\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2162 - accuracy: 0.8963 - val_loss: 1.1078 - val_accuracy: 0.7094\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2213 - accuracy: 0.9000 - val_loss: 1.0866 - val_accuracy: 0.7094\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2166 - accuracy: 0.8963 - val_loss: 1.0834 - val_accuracy: 0.7094\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2167 - accuracy: 0.8852 - val_loss: 1.0890 - val_accuracy: 0.7094\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2183 - accuracy: 0.8926 - val_loss: 1.1010 - val_accuracy: 0.7094\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2168 - accuracy: 0.9000 - val_loss: 1.0934 - val_accuracy: 0.7094\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2153 - accuracy: 0.9000 - val_loss: 1.0904 - val_accuracy: 0.7094\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2162 - accuracy: 0.8926 - val_loss: 1.0982 - val_accuracy: 0.7009\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2145 - accuracy: 0.9000 - val_loss: 1.0921 - val_accuracy: 0.7094\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2152 - accuracy: 0.8926 - val_loss: 1.0853 - val_accuracy: 0.7094\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2142 - accuracy: 0.9000 - val_loss: 1.0971 - val_accuracy: 0.7009\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2143 - accuracy: 0.9000 - val_loss: 1.0971 - val_accuracy: 0.7094\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2182 - accuracy: 0.8852 - val_loss: 1.0792 - val_accuracy: 0.7094\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2180 - accuracy: 0.8926 - val_loss: 1.1036 - val_accuracy: 0.7094\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2150 - accuracy: 0.8963 - val_loss: 1.0958 - val_accuracy: 0.7009\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2229 - accuracy: 0.8815 - val_loss: 1.0779 - val_accuracy: 0.7265\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2162 - accuracy: 0.8815 - val_loss: 1.1138 - val_accuracy: 0.7094\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2165 - accuracy: 0.8926 - val_loss: 1.1044 - val_accuracy: 0.7009\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2154 - accuracy: 0.9000 - val_loss: 1.1086 - val_accuracy: 0.7009\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2157 - accuracy: 0.8926 - val_loss: 1.1035 - val_accuracy: 0.7009\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2166 - accuracy: 0.9037 - val_loss: 1.0988 - val_accuracy: 0.7009\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2162 - accuracy: 0.9000 - val_loss: 1.0857 - val_accuracy: 0.7094\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2168 - accuracy: 0.9000 - val_loss: 1.0917 - val_accuracy: 0.7009\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2148 - accuracy: 0.8963 - val_loss: 1.1081 - val_accuracy: 0.7009\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2166 - accuracy: 0.8889 - val_loss: 1.1098 - val_accuracy: 0.7009\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2133 - accuracy: 0.9000 - val_loss: 1.0933 - val_accuracy: 0.7094\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2151 - accuracy: 0.8926 - val_loss: 1.0882 - val_accuracy: 0.7094\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2203 - accuracy: 0.8815 - val_loss: 1.1149 - val_accuracy: 0.7009\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2116 - accuracy: 0.8963 - val_loss: 1.1075 - val_accuracy: 0.6923\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2170 - accuracy: 0.8963 - val_loss: 1.1026 - val_accuracy: 0.7094\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2166 - accuracy: 0.9000 - val_loss: 1.1005 - val_accuracy: 0.7009\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2197 - accuracy: 0.8889 - val_loss: 1.0970 - val_accuracy: 0.7265\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2188 - accuracy: 0.8963 - val_loss: 1.1210 - val_accuracy: 0.7009\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2149 - accuracy: 0.8926 - val_loss: 1.0941 - val_accuracy: 0.7094\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2127 - accuracy: 0.8852 - val_loss: 1.1051 - val_accuracy: 0.7265\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2167 - accuracy: 0.8963 - val_loss: 1.1083 - val_accuracy: 0.7009\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2157 - accuracy: 0.9000 - val_loss: 1.1041 - val_accuracy: 0.7094\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2115 - accuracy: 0.8963 - val_loss: 1.1043 - val_accuracy: 0.7094\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2172 - accuracy: 0.8926 - val_loss: 1.1137 - val_accuracy: 0.7179\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2153 - accuracy: 0.9000 - val_loss: 1.0941 - val_accuracy: 0.7094\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2141 - accuracy: 0.9000 - val_loss: 1.1120 - val_accuracy: 0.7009\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2152 - accuracy: 0.8852 - val_loss: 1.0966 - val_accuracy: 0.7265\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2123 - accuracy: 0.8926 - val_loss: 1.1117 - val_accuracy: 0.7094\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2173 - accuracy: 0.8963 - val_loss: 1.0980 - val_accuracy: 0.7009\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2153 - accuracy: 0.9000 - val_loss: 1.1099 - val_accuracy: 0.7009\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2152 - accuracy: 0.9000 - val_loss: 1.1044 - val_accuracy: 0.7094\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2139 - accuracy: 0.8926 - val_loss: 1.1212 - val_accuracy: 0.7179\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2139 - accuracy: 0.9000 - val_loss: 1.1115 - val_accuracy: 0.6923\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2126 - accuracy: 0.9000 - val_loss: 1.1090 - val_accuracy: 0.7009\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2148 - accuracy: 0.8926 - val_loss: 1.1032 - val_accuracy: 0.7094\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2150 - accuracy: 0.8963 - val_loss: 1.1285 - val_accuracy: 0.7009\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2135 - accuracy: 0.9000 - val_loss: 1.1051 - val_accuracy: 0.7094\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2109 - accuracy: 0.9000 - val_loss: 1.1171 - val_accuracy: 0.7094\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2118 - accuracy: 0.9000 - val_loss: 1.1189 - val_accuracy: 0.7009\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2101 - accuracy: 0.9000 - val_loss: 1.1081 - val_accuracy: 0.7009\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2139 - accuracy: 0.9000 - val_loss: 1.1138 - val_accuracy: 0.7009\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2123 - accuracy: 0.8926 - val_loss: 1.1165 - val_accuracy: 0.7094\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2181 - accuracy: 0.8852 - val_loss: 1.1029 - val_accuracy: 0.7009\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2117 - accuracy: 0.9000 - val_loss: 1.1361 - val_accuracy: 0.7009\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2127 - accuracy: 0.9000 - val_loss: 1.1204 - val_accuracy: 0.7094\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2176 - accuracy: 0.8852 - val_loss: 1.1055 - val_accuracy: 0.7094\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2116 - accuracy: 0.8963 - val_loss: 1.1314 - val_accuracy: 0.7179\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2139 - accuracy: 0.9000 - val_loss: 1.1144 - val_accuracy: 0.7179\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2108 - accuracy: 0.8963 - val_loss: 1.1161 - val_accuracy: 0.7009\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2180 - accuracy: 0.8926 - val_loss: 1.1311 - val_accuracy: 0.7009\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2172 - accuracy: 0.8815 - val_loss: 1.1166 - val_accuracy: 0.6923\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2140 - accuracy: 0.9037 - val_loss: 1.1415 - val_accuracy: 0.7009\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2128 - accuracy: 0.9000 - val_loss: 1.1205 - val_accuracy: 0.7094\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2129 - accuracy: 0.9000 - val_loss: 1.1184 - val_accuracy: 0.7094\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2143 - accuracy: 0.8741 - val_loss: 1.1136 - val_accuracy: 0.7009\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2091 - accuracy: 0.9000 - val_loss: 1.1338 - val_accuracy: 0.7009\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2129 - accuracy: 0.8963 - val_loss: 1.1405 - val_accuracy: 0.7094\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2149 - accuracy: 0.8815 - val_loss: 1.1225 - val_accuracy: 0.7179\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2116 - accuracy: 0.8926 - val_loss: 1.1347 - val_accuracy: 0.7009\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2109 - accuracy: 0.8963 - val_loss: 1.1274 - val_accuracy: 0.7094\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2093 - accuracy: 0.8963 - val_loss: 1.1357 - val_accuracy: 0.7094\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2123 - accuracy: 0.8963 - val_loss: 1.1316 - val_accuracy: 0.7094\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2122 - accuracy: 0.8963 - val_loss: 1.1114 - val_accuracy: 0.7179\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2128 - accuracy: 0.8963 - val_loss: 1.1268 - val_accuracy: 0.7094\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2127 - accuracy: 0.8963 - val_loss: 1.1317 - val_accuracy: 0.7094\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2105 - accuracy: 0.9000 - val_loss: 1.1200 - val_accuracy: 0.7094\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2125 - accuracy: 0.8889 - val_loss: 1.1276 - val_accuracy: 0.7094\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2117 - accuracy: 0.8963 - val_loss: 1.1459 - val_accuracy: 0.7094\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2144 - accuracy: 0.9000 - val_loss: 1.1354 - val_accuracy: 0.7009\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2130 - accuracy: 0.9000 - val_loss: 1.1153 - val_accuracy: 0.7265\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2114 - accuracy: 0.8963 - val_loss: 1.1359 - val_accuracy: 0.7179\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2131 - accuracy: 0.9000 - val_loss: 1.1312 - val_accuracy: 0.7179\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2113 - accuracy: 0.8852 - val_loss: 1.1312 - val_accuracy: 0.6923\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2093 - accuracy: 0.8926 - val_loss: 1.1429 - val_accuracy: 0.7179\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2121 - accuracy: 0.8889 - val_loss: 1.1453 - val_accuracy: 0.7265\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2182 - accuracy: 0.8889 - val_loss: 1.1291 - val_accuracy: 0.7094\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2121 - accuracy: 0.8963 - val_loss: 1.1234 - val_accuracy: 0.7094\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2115 - accuracy: 0.8963 - val_loss: 1.1328 - val_accuracy: 0.7094\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 118us/step - loss: 0.2213 - accuracy: 0.8852 - val_loss: 1.1286 - val_accuracy: 0.7094\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2084 - accuracy: 0.8963 - val_loss: 1.1363 - val_accuracy: 0.7179\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 278us/step - loss: 0.2094 - accuracy: 0.8926 - val_loss: 1.1386 - val_accuracy: 0.7179\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 370us/step - loss: 0.2097 - accuracy: 0.9000 - val_loss: 1.1353 - val_accuracy: 0.7179\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2085 - accuracy: 0.8963 - val_loss: 1.1299 - val_accuracy: 0.7009\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2114 - accuracy: 0.8926 - val_loss: 1.1353 - val_accuracy: 0.7094\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2109 - accuracy: 0.8778 - val_loss: 1.1248 - val_accuracy: 0.7265\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2140 - accuracy: 0.8963 - val_loss: 1.1482 - val_accuracy: 0.7265\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2125 - accuracy: 0.8963 - val_loss: 1.1377 - val_accuracy: 0.7009\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2112 - accuracy: 0.8926 - val_loss: 1.1481 - val_accuracy: 0.7094\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2124 - accuracy: 0.8889 - val_loss: 1.1325 - val_accuracy: 0.7094\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2088 - accuracy: 0.9000 - val_loss: 1.1340 - val_accuracy: 0.7094\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2091 - accuracy: 0.8889 - val_loss: 1.1392 - val_accuracy: 0.7094\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2084 - accuracy: 0.9000 - val_loss: 1.1503 - val_accuracy: 0.7094\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2099 - accuracy: 0.9000 - val_loss: 1.1398 - val_accuracy: 0.7094\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2108 - accuracy: 0.8963 - val_loss: 1.1379 - val_accuracy: 0.7094\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2122 - accuracy: 0.8778 - val_loss: 1.1382 - val_accuracy: 0.7094\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2097 - accuracy: 0.9000 - val_loss: 1.1424 - val_accuracy: 0.7179\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2150 - accuracy: 0.8852 - val_loss: 1.1334 - val_accuracy: 0.7179\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2062 - accuracy: 0.9000 - val_loss: 1.1382 - val_accuracy: 0.7094\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2134 - accuracy: 0.8963 - val_loss: 1.1377 - val_accuracy: 0.6923\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2064 - accuracy: 0.8963 - val_loss: 1.1590 - val_accuracy: 0.7179\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2097 - accuracy: 0.8963 - val_loss: 1.1478 - val_accuracy: 0.7179\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2143 - accuracy: 0.8778 - val_loss: 1.1289 - val_accuracy: 0.7265\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2094 - accuracy: 0.8963 - val_loss: 1.1607 - val_accuracy: 0.7094\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2121 - accuracy: 0.9000 - val_loss: 1.1532 - val_accuracy: 0.7094\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2097 - accuracy: 0.8852 - val_loss: 1.1243 - val_accuracy: 0.7265\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2099 - accuracy: 0.8889 - val_loss: 1.1406 - val_accuracy: 0.7179\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2080 - accuracy: 0.9000 - val_loss: 1.1592 - val_accuracy: 0.7179\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2093 - accuracy: 0.9000 - val_loss: 1.1454 - val_accuracy: 0.7179\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2161 - accuracy: 0.8963 - val_loss: 1.1497 - val_accuracy: 0.7009\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2099 - accuracy: 0.9000 - val_loss: 1.1509 - val_accuracy: 0.7179\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2127 - accuracy: 0.8926 - val_loss: 1.1446 - val_accuracy: 0.7009\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2105 - accuracy: 0.8926 - val_loss: 1.1567 - val_accuracy: 0.6923\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2067 - accuracy: 0.9037 - val_loss: 1.1597 - val_accuracy: 0.7179\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2097 - accuracy: 0.8889 - val_loss: 1.1331 - val_accuracy: 0.7350\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2102 - accuracy: 0.8926 - val_loss: 1.1488 - val_accuracy: 0.7179\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2066 - accuracy: 0.9000 - val_loss: 1.1461 - val_accuracy: 0.7094\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2122 - accuracy: 0.8852 - val_loss: 1.1425 - val_accuracy: 0.7265\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2061 - accuracy: 0.8926 - val_loss: 1.1661 - val_accuracy: 0.7179\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2119 - accuracy: 0.8889 - val_loss: 1.1540 - val_accuracy: 0.7094\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2134 - accuracy: 0.8889 - val_loss: 1.1543 - val_accuracy: 0.7094\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2079 - accuracy: 0.9000 - val_loss: 1.1509 - val_accuracy: 0.7094\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2073 - accuracy: 0.9000 - val_loss: 1.1633 - val_accuracy: 0.7094\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2084 - accuracy: 0.8963 - val_loss: 1.1555 - val_accuracy: 0.7179\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2106 - accuracy: 0.8852 - val_loss: 1.1479 - val_accuracy: 0.7265\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2106 - accuracy: 0.8852 - val_loss: 1.1771 - val_accuracy: 0.7265\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2108 - accuracy: 0.8889 - val_loss: 1.1618 - val_accuracy: 0.7179\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2139 - accuracy: 0.8778 - val_loss: 1.1454 - val_accuracy: 0.7265\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2075 - accuracy: 0.8926 - val_loss: 1.1572 - val_accuracy: 0.7094\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2076 - accuracy: 0.8963 - val_loss: 1.1588 - val_accuracy: 0.7179\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2075 - accuracy: 0.9000 - val_loss: 1.1603 - val_accuracy: 0.7179\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2124 - accuracy: 0.9000 - val_loss: 1.1667 - val_accuracy: 0.7179\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2078 - accuracy: 0.8963 - val_loss: 1.1543 - val_accuracy: 0.7094\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2118 - accuracy: 0.8667 - val_loss: 1.1553 - val_accuracy: 0.7094\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2080 - accuracy: 0.8889 - val_loss: 1.1625 - val_accuracy: 0.7094\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2083 - accuracy: 0.8926 - val_loss: 1.1501 - val_accuracy: 0.7179\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2072 - accuracy: 0.8889 - val_loss: 1.1447 - val_accuracy: 0.7179\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2081 - accuracy: 0.9000 - val_loss: 1.1610 - val_accuracy: 0.7179\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2094 - accuracy: 0.8889 - val_loss: 1.1611 - val_accuracy: 0.7009\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2114 - accuracy: 0.9000 - val_loss: 1.1518 - val_accuracy: 0.7009\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2084 - accuracy: 0.9000 - val_loss: 1.1782 - val_accuracy: 0.7179\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2065 - accuracy: 0.9000 - val_loss: 1.1556 - val_accuracy: 0.7094\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2074 - accuracy: 0.9000 - val_loss: 1.1534 - val_accuracy: 0.7009\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2059 - accuracy: 0.9000 - val_loss: 1.1687 - val_accuracy: 0.7179\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2075 - accuracy: 0.9000 - val_loss: 1.1661 - val_accuracy: 0.7179\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2058 - accuracy: 0.8926 - val_loss: 1.1600 - val_accuracy: 0.7094\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2057 - accuracy: 0.8963 - val_loss: 1.1750 - val_accuracy: 0.7094\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.1694 - val_accuracy: 0.7094\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.1634 - val_accuracy: 0.7094\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2086 - accuracy: 0.8963 - val_loss: 1.1754 - val_accuracy: 0.7179\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2088 - accuracy: 0.8963 - val_loss: 1.1517 - val_accuracy: 0.7179\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2074 - accuracy: 0.8889 - val_loss: 1.1686 - val_accuracy: 0.7179\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2077 - accuracy: 0.8963 - val_loss: 1.1637 - val_accuracy: 0.7094\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2062 - accuracy: 0.8926 - val_loss: 1.1589 - val_accuracy: 0.7094\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2070 - accuracy: 0.8963 - val_loss: 1.1697 - val_accuracy: 0.7094\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2082 - accuracy: 0.9000 - val_loss: 1.1672 - val_accuracy: 0.7094\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2049 - accuracy: 0.8963 - val_loss: 1.1681 - val_accuracy: 0.7094\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2055 - accuracy: 0.9000 - val_loss: 1.1744 - val_accuracy: 0.7094\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2105 - accuracy: 0.9000 - val_loss: 1.1742 - val_accuracy: 0.7094\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2061 - accuracy: 0.9000 - val_loss: 1.1598 - val_accuracy: 0.7094\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2057 - accuracy: 0.9000 - val_loss: 1.1650 - val_accuracy: 0.7009\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2073 - accuracy: 0.9000 - val_loss: 1.1673 - val_accuracy: 0.7009\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2057 - accuracy: 0.9000 - val_loss: 1.1787 - val_accuracy: 0.7009\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2054 - accuracy: 0.8926 - val_loss: 1.1767 - val_accuracy: 0.7009\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2074 - accuracy: 0.9074 - val_loss: 1.1763 - val_accuracy: 0.6923\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2065 - accuracy: 0.8963 - val_loss: 1.1735 - val_accuracy: 0.7179\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2063 - accuracy: 0.8963 - val_loss: 1.1728 - val_accuracy: 0.7009\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2074 - accuracy: 0.8889 - val_loss: 1.1672 - val_accuracy: 0.7094\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2064 - accuracy: 0.9000 - val_loss: 1.1765 - val_accuracy: 0.7009\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2060 - accuracy: 0.9000 - val_loss: 1.1709 - val_accuracy: 0.7009\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2059 - accuracy: 0.9000 - val_loss: 1.1725 - val_accuracy: 0.7009\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2041 - accuracy: 0.9000 - val_loss: 1.1833 - val_accuracy: 0.7009\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2067 - accuracy: 0.8926 - val_loss: 1.1766 - val_accuracy: 0.7094\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2078 - accuracy: 0.9037 - val_loss: 1.1670 - val_accuracy: 0.7009\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2063 - accuracy: 0.8963 - val_loss: 1.1776 - val_accuracy: 0.7179\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2053 - accuracy: 0.8963 - val_loss: 1.1737 - val_accuracy: 0.7179\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2045 - accuracy: 0.8926 - val_loss: 1.1760 - val_accuracy: 0.7094\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2069 - accuracy: 0.8963 - val_loss: 1.1771 - val_accuracy: 0.7094\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.1854 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2085 - accuracy: 0.9000 - val_loss: 1.1810 - val_accuracy: 0.7094\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2070 - accuracy: 0.9000 - val_loss: 1.1807 - val_accuracy: 0.7094\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2070 - accuracy: 0.9000 - val_loss: 1.1901 - val_accuracy: 0.7094\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2042 - accuracy: 0.9000 - val_loss: 1.1832 - val_accuracy: 0.7094\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2065 - accuracy: 0.8963 - val_loss: 1.1663 - val_accuracy: 0.7350\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2106 - accuracy: 0.8926 - val_loss: 1.1882 - val_accuracy: 0.7179\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2062 - accuracy: 0.9000 - val_loss: 1.1818 - val_accuracy: 0.7179\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2048 - accuracy: 0.9000 - val_loss: 1.1725 - val_accuracy: 0.7179\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2072 - accuracy: 0.9000 - val_loss: 1.1721 - val_accuracy: 0.7179\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2075 - accuracy: 0.8889 - val_loss: 1.1794 - val_accuracy: 0.7179\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2068 - accuracy: 0.9037 - val_loss: 1.2084 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2062 - accuracy: 0.9000 - val_loss: 1.1903 - val_accuracy: 0.7179\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2044 - accuracy: 0.9000 - val_loss: 1.1845 - val_accuracy: 0.7179\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2065 - accuracy: 0.9000 - val_loss: 1.1917 - val_accuracy: 0.7179\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.1816 - val_accuracy: 0.7179\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2035 - accuracy: 0.9000 - val_loss: 1.1842 - val_accuracy: 0.7179\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2060 - accuracy: 0.8963 - val_loss: 1.1892 - val_accuracy: 0.7179\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2078 - accuracy: 0.9000 - val_loss: 1.1914 - val_accuracy: 0.7179\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2040 - accuracy: 0.8963 - val_loss: 1.1795 - val_accuracy: 0.7094\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2045 - accuracy: 0.8926 - val_loss: 1.1763 - val_accuracy: 0.7094\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2063 - accuracy: 0.8963 - val_loss: 1.1790 - val_accuracy: 0.7179\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2114 - accuracy: 0.8926 - val_loss: 1.1937 - val_accuracy: 0.7179\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2048 - accuracy: 0.9000 - val_loss: 1.1937 - val_accuracy: 0.7179\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2021 - accuracy: 0.9037 - val_loss: 1.1698 - val_accuracy: 0.7179\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2062 - accuracy: 0.8889 - val_loss: 1.1770 - val_accuracy: 0.7265\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2037 - accuracy: 0.8926 - val_loss: 1.1944 - val_accuracy: 0.7179\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.1948 - val_accuracy: 0.7179\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2061 - accuracy: 0.8852 - val_loss: 1.1866 - val_accuracy: 0.7094\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.1982 - val_accuracy: 0.7094\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2057 - accuracy: 0.9000 - val_loss: 1.1963 - val_accuracy: 0.7094\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2037 - accuracy: 0.8963 - val_loss: 1.1883 - val_accuracy: 0.7094\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2051 - accuracy: 0.8926 - val_loss: 1.1867 - val_accuracy: 0.7179\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2065 - accuracy: 0.8778 - val_loss: 1.1805 - val_accuracy: 0.7094\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.1977 - val_accuracy: 0.7094\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2094 - accuracy: 0.9000 - val_loss: 1.2131 - val_accuracy: 0.7094\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2083 - accuracy: 0.8889 - val_loss: 1.1889 - val_accuracy: 0.7350\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2084 - accuracy: 0.8852 - val_loss: 1.2043 - val_accuracy: 0.7179\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2056 - accuracy: 0.9000 - val_loss: 1.1918 - val_accuracy: 0.7179\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2047 - accuracy: 0.8852 - val_loss: 1.1970 - val_accuracy: 0.7094\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2040 - accuracy: 0.8963 - val_loss: 1.2007 - val_accuracy: 0.7179\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2042 - accuracy: 0.9000 - val_loss: 1.2006 - val_accuracy: 0.7179\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.1997 - val_accuracy: 0.7179\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.2025 - val_accuracy: 0.7179\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.1868 - val_accuracy: 0.7179\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2120 - accuracy: 0.8926 - val_loss: 1.1870 - val_accuracy: 0.7265\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2218 - accuracy: 0.8852 - val_loss: 1.2463 - val_accuracy: 0.7265\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2136 - accuracy: 0.8889 - val_loss: 1.1869 - val_accuracy: 0.7179\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2100 - accuracy: 0.8852 - val_loss: 1.2052 - val_accuracy: 0.7179\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.2038 - val_accuracy: 0.7179\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2048 - accuracy: 0.8815 - val_loss: 1.1912 - val_accuracy: 0.7350\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2033 - accuracy: 0.9000 - val_loss: 1.2004 - val_accuracy: 0.7179\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2050 - accuracy: 0.9000 - val_loss: 1.1983 - val_accuracy: 0.7094\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2044 - accuracy: 0.9000 - val_loss: 1.1927 - val_accuracy: 0.7179\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2039 - accuracy: 0.9000 - val_loss: 1.2052 - val_accuracy: 0.7179\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2080 - accuracy: 0.9037 - val_loss: 1.2069 - val_accuracy: 0.7094\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2052 - accuracy: 0.9000 - val_loss: 1.2174 - val_accuracy: 0.7094\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2052 - accuracy: 0.8889 - val_loss: 1.2025 - val_accuracy: 0.7094\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2045 - accuracy: 0.8963 - val_loss: 1.1941 - val_accuracy: 0.7265\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2101 - accuracy: 0.8926 - val_loss: 1.2094 - val_accuracy: 0.7094\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2021 - accuracy: 0.9000 - val_loss: 1.2074 - val_accuracy: 0.7265\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2063 - accuracy: 0.8963 - val_loss: 1.2042 - val_accuracy: 0.7179\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2015 - accuracy: 0.9000 - val_loss: 1.2109 - val_accuracy: 0.7179\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2042 - accuracy: 0.8963 - val_loss: 1.2091 - val_accuracy: 0.7009\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2056 - accuracy: 0.9000 - val_loss: 1.2097 - val_accuracy: 0.7094\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2052 - accuracy: 0.8963 - val_loss: 1.2019 - val_accuracy: 0.7265\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2051 - accuracy: 0.8963 - val_loss: 1.2104 - val_accuracy: 0.7094\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2039 - accuracy: 0.9000 - val_loss: 1.2019 - val_accuracy: 0.7179\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.2123 - val_accuracy: 0.7094\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.2232 - val_accuracy: 0.7179\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2072 - accuracy: 0.8963 - val_loss: 1.2091 - val_accuracy: 0.7094\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2091 - accuracy: 0.8889 - val_loss: 1.1936 - val_accuracy: 0.7179\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2047 - accuracy: 0.8926 - val_loss: 1.2196 - val_accuracy: 0.7094\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.2168 - val_accuracy: 0.7094\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2042 - accuracy: 0.9000 - val_loss: 1.2191 - val_accuracy: 0.7094\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.2066 - val_accuracy: 0.7094\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.2160 - val_accuracy: 0.7179\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2047 - accuracy: 0.8963 - val_loss: 1.2104 - val_accuracy: 0.7179\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.2290 - val_accuracy: 0.7179\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2059 - accuracy: 0.9000 - val_loss: 1.2166 - val_accuracy: 0.7179\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2033 - accuracy: 0.9000 - val_loss: 1.2105 - val_accuracy: 0.7179\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2078 - accuracy: 0.8926 - val_loss: 1.2331 - val_accuracy: 0.7265\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2031 - accuracy: 0.9037 - val_loss: 1.2178 - val_accuracy: 0.6923\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2063 - accuracy: 0.8963 - val_loss: 1.2176 - val_accuracy: 0.7094\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2040 - accuracy: 0.9000 - val_loss: 1.2105 - val_accuracy: 0.7094\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2075 - accuracy: 0.8926 - val_loss: 1.2076 - val_accuracy: 0.7094\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2079 - accuracy: 0.8963 - val_loss: 1.2234 - val_accuracy: 0.7179\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2052 - accuracy: 0.8963 - val_loss: 1.2140 - val_accuracy: 0.7094\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2050 - accuracy: 0.9000 - val_loss: 1.2222 - val_accuracy: 0.7094\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2038 - accuracy: 0.9000 - val_loss: 1.2200 - val_accuracy: 0.7094\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2047 - accuracy: 0.8926 - val_loss: 1.1976 - val_accuracy: 0.7265\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2062 - accuracy: 0.8926 - val_loss: 1.2198 - val_accuracy: 0.7094\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2055 - accuracy: 0.8963 - val_loss: 1.2216 - val_accuracy: 0.7094\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.2085 - val_accuracy: 0.7094\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2041 - accuracy: 0.8963 - val_loss: 1.2194 - val_accuracy: 0.7179\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2073 - accuracy: 0.8963 - val_loss: 1.2180 - val_accuracy: 0.7094\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2060 - accuracy: 0.8926 - val_loss: 1.2307 - val_accuracy: 0.7179\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2011 - accuracy: 0.8963 - val_loss: 1.2203 - val_accuracy: 0.7094\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2040 - accuracy: 0.8926 - val_loss: 1.2061 - val_accuracy: 0.7179\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.2146 - val_accuracy: 0.7094\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2048 - accuracy: 0.9000 - val_loss: 1.2117 - val_accuracy: 0.7179\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2031 - accuracy: 0.9000 - val_loss: 1.2233 - val_accuracy: 0.7094\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2061 - accuracy: 0.8926 - val_loss: 1.2182 - val_accuracy: 0.7179\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2031 - accuracy: 0.8963 - val_loss: 1.2112 - val_accuracy: 0.7265\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2053 - accuracy: 0.8852 - val_loss: 1.2222 - val_accuracy: 0.7179\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2066 - accuracy: 0.8926 - val_loss: 1.2563 - val_accuracy: 0.7265\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2077 - accuracy: 0.8963 - val_loss: 1.2142 - val_accuracy: 0.7094\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2098 - accuracy: 0.8852 - val_loss: 1.2069 - val_accuracy: 0.7350\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2028 - accuracy: 0.8963 - val_loss: 1.2330 - val_accuracy: 0.7179\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2064 - accuracy: 0.9000 - val_loss: 1.2312 - val_accuracy: 0.7179\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2054 - accuracy: 0.9000 - val_loss: 1.2076 - val_accuracy: 0.7094\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2054 - accuracy: 0.9000 - val_loss: 1.2173 - val_accuracy: 0.7179\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2057 - accuracy: 0.9037 - val_loss: 1.2394 - val_accuracy: 0.7179\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2073 - accuracy: 0.8963 - val_loss: 1.2044 - val_accuracy: 0.7265\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2051 - accuracy: 0.8852 - val_loss: 1.2329 - val_accuracy: 0.7179\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2055 - accuracy: 0.9000 - val_loss: 1.2270 - val_accuracy: 0.7179\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2030 - accuracy: 0.8963 - val_loss: 1.2189 - val_accuracy: 0.7094\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2057 - accuracy: 0.9000 - val_loss: 1.2240 - val_accuracy: 0.7094\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2019 - accuracy: 0.9000 - val_loss: 1.2226 - val_accuracy: 0.7094\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2023 - accuracy: 0.8963 - val_loss: 1.2287 - val_accuracy: 0.7179\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2048 - accuracy: 0.8889 - val_loss: 1.2210 - val_accuracy: 0.7094\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2032 - accuracy: 0.8852 - val_loss: 1.2413 - val_accuracy: 0.7179\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 104us/step - loss: 0.2024 - accuracy: 0.9000 - val_loss: 1.2295 - val_accuracy: 0.7094\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2035 - accuracy: 0.8889 - val_loss: 1.2154 - val_accuracy: 0.7350\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2059 - accuracy: 0.8963 - val_loss: 1.2211 - val_accuracy: 0.7094\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2013 - accuracy: 0.8963 - val_loss: 1.2317 - val_accuracy: 0.7179\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.2244 - val_accuracy: 0.7094\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2032 - accuracy: 0.9000 - val_loss: 1.2161 - val_accuracy: 0.7179\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2053 - accuracy: 0.8815 - val_loss: 1.2119 - val_accuracy: 0.7094\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2060 - accuracy: 0.8926 - val_loss: 1.2443 - val_accuracy: 0.7179\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2010 - accuracy: 0.8926 - val_loss: 1.2192 - val_accuracy: 0.7265\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2038 - accuracy: 0.8889 - val_loss: 1.2294 - val_accuracy: 0.7094\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2013 - accuracy: 0.8963 - val_loss: 1.2203 - val_accuracy: 0.7179\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2117 - accuracy: 0.8926 - val_loss: 1.2416 - val_accuracy: 0.7094\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2037 - accuracy: 0.8889 - val_loss: 1.2081 - val_accuracy: 0.7350\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2064 - accuracy: 0.8889 - val_loss: 1.2280 - val_accuracy: 0.7179\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2027 - accuracy: 0.9000 - val_loss: 1.2348 - val_accuracy: 0.7094\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2036 - accuracy: 0.9000 - val_loss: 1.2270 - val_accuracy: 0.7094\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2053 - accuracy: 0.8889 - val_loss: 1.2304 - val_accuracy: 0.7179\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2064 - accuracy: 0.9000 - val_loss: 1.2230 - val_accuracy: 0.7094\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.2194 - val_accuracy: 0.7094\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2017 - accuracy: 0.8926 - val_loss: 1.2300 - val_accuracy: 0.7094\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2048 - accuracy: 0.8926 - val_loss: 1.2512 - val_accuracy: 0.7179\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2043 - accuracy: 0.9000 - val_loss: 1.2321 - val_accuracy: 0.7094\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2083 - accuracy: 0.8963 - val_loss: 1.2414 - val_accuracy: 0.7094\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.2040 - accuracy: 0.9000 - val_loss: 1.2318 - val_accuracy: 0.7094\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.2038 - accuracy: 0.8963 - val_loss: 1.2267 - val_accuracy: 0.7094\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2046 - accuracy: 0.8852 - val_loss: 1.2142 - val_accuracy: 0.7350\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2053 - accuracy: 0.8889 - val_loss: 1.2432 - val_accuracy: 0.7094\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2024 - accuracy: 0.9000 - val_loss: 1.2345 - val_accuracy: 0.7094\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2035 - accuracy: 0.8889 - val_loss: 1.2272 - val_accuracy: 0.7179\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2036 - accuracy: 0.9000 - val_loss: 1.2278 - val_accuracy: 0.7179\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2028 - accuracy: 0.9000 - val_loss: 1.2352 - val_accuracy: 0.7179\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2031 - accuracy: 0.9000 - val_loss: 1.2421 - val_accuracy: 0.7179\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2034 - accuracy: 0.8815 - val_loss: 1.2256 - val_accuracy: 0.7179\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2024 - accuracy: 0.8963 - val_loss: 1.2401 - val_accuracy: 0.7179\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.2466 - val_accuracy: 0.7179\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2032 - accuracy: 0.9000 - val_loss: 1.2339 - val_accuracy: 0.7179\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.2434 - val_accuracy: 0.7179\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2034 - accuracy: 0.8963 - val_loss: 1.2388 - val_accuracy: 0.7094\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.2375 - val_accuracy: 0.7094\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2024 - accuracy: 0.8926 - val_loss: 1.2367 - val_accuracy: 0.7179\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.2403 - val_accuracy: 0.7179\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2019 - accuracy: 0.9000 - val_loss: 1.2331 - val_accuracy: 0.7094\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2041 - accuracy: 0.9000 - val_loss: 1.2338 - val_accuracy: 0.7179\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2006 - accuracy: 0.8963 - val_loss: 1.2397 - val_accuracy: 0.7094\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.2033 - accuracy: 0.8889 - val_loss: 1.2294 - val_accuracy: 0.7094\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.2406 - val_accuracy: 0.7009\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2073 - accuracy: 0.8889 - val_loss: 1.2355 - val_accuracy: 0.7009\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2089 - accuracy: 0.8889 - val_loss: 1.2523 - val_accuracy: 0.7265\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.2494 - val_accuracy: 0.7179\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 299us/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.2400 - val_accuracy: 0.7179\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.2037 - accuracy: 0.8778 - val_loss: 1.2517 - val_accuracy: 0.7179\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2022 - accuracy: 0.9000 - val_loss: 1.2533 - val_accuracy: 0.7179\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2050 - accuracy: 0.8852 - val_loss: 1.2443 - val_accuracy: 0.7179\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2079 - accuracy: 0.8852 - val_loss: 1.2350 - val_accuracy: 0.7179\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2045 - accuracy: 0.8926 - val_loss: 1.2378 - val_accuracy: 0.7265\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2011 - accuracy: 0.8963 - val_loss: 1.2481 - val_accuracy: 0.7179\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2124 - accuracy: 0.8741 - val_loss: 1.2540 - val_accuracy: 0.7009\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2072 - accuracy: 0.8963 - val_loss: 1.2488 - val_accuracy: 0.7265\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2103 - accuracy: 0.8815 - val_loss: 1.2264 - val_accuracy: 0.7350\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2090 - accuracy: 0.8889 - val_loss: 1.2591 - val_accuracy: 0.7179\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2018 - accuracy: 0.9000 - val_loss: 1.2500 - val_accuracy: 0.7179\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 636us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.2398 - val_accuracy: 0.7179\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.2374 - val_accuracy: 0.7350\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2048 - accuracy: 0.8852 - val_loss: 1.2616 - val_accuracy: 0.7265\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2028 - accuracy: 0.8889 - val_loss: 1.2467 - val_accuracy: 0.7094\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.2458 - val_accuracy: 0.7094\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.2483 - val_accuracy: 0.7094\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2020 - accuracy: 0.9000 - val_loss: 1.2386 - val_accuracy: 0.7179\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.2513 - val_accuracy: 0.7094\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.2497 - val_accuracy: 0.7179\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 641us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.2513 - val_accuracy: 0.7179\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2024 - accuracy: 0.8963 - val_loss: 1.2502 - val_accuracy: 0.7094\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2049 - accuracy: 0.8815 - val_loss: 1.2392 - val_accuracy: 0.7179\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 484us/step - loss: 0.2015 - accuracy: 0.9037 - val_loss: 1.2627 - val_accuracy: 0.7179\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.2610 - val_accuracy: 0.7179\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.2570 - val_accuracy: 0.7094\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2005 - accuracy: 0.8926 - val_loss: 1.2443 - val_accuracy: 0.7179\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2034 - accuracy: 0.8852 - val_loss: 1.2440 - val_accuracy: 0.7179\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2018 - accuracy: 0.9000 - val_loss: 1.2788 - val_accuracy: 0.7179\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2038 - accuracy: 0.9000 - val_loss: 1.2584 - val_accuracy: 0.7094\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.2590 - val_accuracy: 0.7179\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.2478 - val_accuracy: 0.7094\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2021 - accuracy: 0.8889 - val_loss: 1.2366 - val_accuracy: 0.7094\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.2511 - val_accuracy: 0.7179\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.2577 - val_accuracy: 0.7179\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.2569 - val_accuracy: 0.7179\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2007 - accuracy: 0.8926 - val_loss: 1.2388 - val_accuracy: 0.7265\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2005 - accuracy: 0.8963 - val_loss: 1.2562 - val_accuracy: 0.7094\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2052 - accuracy: 0.9000 - val_loss: 1.2689 - val_accuracy: 0.7179\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2053 - accuracy: 0.8815 - val_loss: 1.2408 - val_accuracy: 0.7350\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2010 - accuracy: 0.9000 - val_loss: 1.2608 - val_accuracy: 0.7179\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2037 - accuracy: 0.8926 - val_loss: 1.2561 - val_accuracy: 0.7179\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2019 - accuracy: 0.9000 - val_loss: 1.2476 - val_accuracy: 0.7009\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2042 - accuracy: 0.8889 - val_loss: 1.2416 - val_accuracy: 0.7265\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.2547 - val_accuracy: 0.7094\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2028 - accuracy: 0.9000 - val_loss: 1.2520 - val_accuracy: 0.7094\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.2712 - val_accuracy: 0.7179\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2079 - accuracy: 0.8852 - val_loss: 1.2578 - val_accuracy: 0.7094\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.2646 - val_accuracy: 0.7094\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2018 - accuracy: 0.9000 - val_loss: 1.2526 - val_accuracy: 0.7094\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2025 - accuracy: 0.8963 - val_loss: 1.2724 - val_accuracy: 0.7179\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2073 - accuracy: 0.8852 - val_loss: 1.2571 - val_accuracy: 0.7094\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2034 - accuracy: 0.8926 - val_loss: 1.2559 - val_accuracy: 0.7094\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.2641 - val_accuracy: 0.7179\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2031 - accuracy: 0.8852 - val_loss: 1.2706 - val_accuracy: 0.7179\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2065 - accuracy: 0.8889 - val_loss: 1.2636 - val_accuracy: 0.7009\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2045 - accuracy: 0.8963 - val_loss: 1.2735 - val_accuracy: 0.7179\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2016 - accuracy: 0.8926 - val_loss: 1.2654 - val_accuracy: 0.7179\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2012 - accuracy: 0.8815 - val_loss: 1.2672 - val_accuracy: 0.7179\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.2776 - val_accuracy: 0.7179\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 116us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.2733 - val_accuracy: 0.7179\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.2639 - val_accuracy: 0.7094\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2047 - accuracy: 0.8963 - val_loss: 1.2500 - val_accuracy: 0.7179\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2020 - accuracy: 0.8963 - val_loss: 1.2648 - val_accuracy: 0.7094\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.2643 - val_accuracy: 0.7179\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2022 - accuracy: 0.8963 - val_loss: 1.2662 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1998 - accuracy: 0.9074 - val_loss: 1.2539 - val_accuracy: 0.7350\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2034 - accuracy: 0.8852 - val_loss: 1.2792 - val_accuracy: 0.7094\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2015 - accuracy: 0.8926 - val_loss: 1.2726 - val_accuracy: 0.7179\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2037 - accuracy: 0.8889 - val_loss: 1.2573 - val_accuracy: 0.7350\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2030 - accuracy: 0.8889 - val_loss: 1.2745 - val_accuracy: 0.7094\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2012 - accuracy: 0.8926 - val_loss: 1.2655 - val_accuracy: 0.7265\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.2673 - val_accuracy: 0.7179\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2052 - accuracy: 0.8889 - val_loss: 1.2771 - val_accuracy: 0.7179\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2034 - accuracy: 0.8963 - val_loss: 1.2529 - val_accuracy: 0.7350\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2032 - accuracy: 0.8963 - val_loss: 1.2585 - val_accuracy: 0.7179\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2022 - accuracy: 0.9000 - val_loss: 1.2674 - val_accuracy: 0.7179\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.2551 - val_accuracy: 0.7179\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2049 - accuracy: 0.8778 - val_loss: 1.2644 - val_accuracy: 0.7179\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2065 - accuracy: 0.8852 - val_loss: 1.2737 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2020 - accuracy: 0.9000 - val_loss: 1.2592 - val_accuracy: 0.7179\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2046 - accuracy: 0.8889 - val_loss: 1.2574 - val_accuracy: 0.7179\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2127 - accuracy: 0.8926 - val_loss: 1.2868 - val_accuracy: 0.7179\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.2638 - val_accuracy: 0.7179\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2011 - accuracy: 0.8815 - val_loss: 1.2665 - val_accuracy: 0.7179\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2015 - accuracy: 0.8963 - val_loss: 1.2772 - val_accuracy: 0.7265\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1982 - accuracy: 0.9037 - val_loss: 1.2720 - val_accuracy: 0.7094\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2074 - accuracy: 0.8926 - val_loss: 1.2591 - val_accuracy: 0.7179\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.2767 - val_accuracy: 0.7179\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.2726 - val_accuracy: 0.7179\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.2907 - val_accuracy: 0.7179\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2035 - accuracy: 0.9000 - val_loss: 1.2720 - val_accuracy: 0.7179\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2033 - accuracy: 0.8889 - val_loss: 1.2707 - val_accuracy: 0.7179\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2073 - accuracy: 0.9000 - val_loss: 1.2878 - val_accuracy: 0.7094\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.2661 - val_accuracy: 0.7094\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.2846 - val_accuracy: 0.7179\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.2668 - val_accuracy: 0.7179\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.2818 - val_accuracy: 0.7094\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.2725 - val_accuracy: 0.7094\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.2675 - val_accuracy: 0.7179\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.2657 - val_accuracy: 0.7179\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.2754 - val_accuracy: 0.7179\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2034 - accuracy: 0.8926 - val_loss: 1.3039 - val_accuracy: 0.7179\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.2807 - val_accuracy: 0.7179\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.2804 - val_accuracy: 0.7094\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.1999 - accuracy: 0.8963 - val_loss: 1.2862 - val_accuracy: 0.7179\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2051 - accuracy: 0.8741 - val_loss: 1.2797 - val_accuracy: 0.7094\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.3034 - val_accuracy: 0.7094\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.2888 - val_accuracy: 0.7094\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2043 - accuracy: 0.8926 - val_loss: 1.2636 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.2788 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.2950 - val_accuracy: 0.7179\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2046 - accuracy: 0.9000 - val_loss: 1.2935 - val_accuracy: 0.7179\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2121 - accuracy: 0.8556 - val_loss: 1.2786 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.1979 - accuracy: 0.8926 - val_loss: 1.2773 - val_accuracy: 0.7179\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2069 - accuracy: 0.8889 - val_loss: 1.2867 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2029 - accuracy: 0.8815 - val_loss: 1.2696 - val_accuracy: 0.7350\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.2941 - val_accuracy: 0.7179\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2010 - accuracy: 0.9037 - val_loss: 1.2790 - val_accuracy: 0.7179\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2007 - accuracy: 0.8852 - val_loss: 1.2770 - val_accuracy: 0.7179\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.3042 - val_accuracy: 0.7094\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.2881 - val_accuracy: 0.7179\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2102 - accuracy: 0.8889 - val_loss: 1.2667 - val_accuracy: 0.7350\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.1995 - accuracy: 0.8852 - val_loss: 1.3047 - val_accuracy: 0.7265\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2059 - accuracy: 0.8926 - val_loss: 1.2972 - val_accuracy: 0.7265\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.2872 - val_accuracy: 0.7094\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.2872 - val_accuracy: 0.7094\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2020 - accuracy: 0.9000 - val_loss: 1.2813 - val_accuracy: 0.7179\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.2770 - val_accuracy: 0.7179\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.2681 - val_accuracy: 0.7094\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.1993 - accuracy: 0.8963 - val_loss: 1.2920 - val_accuracy: 0.7179\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2017 - accuracy: 0.8889 - val_loss: 1.2803 - val_accuracy: 0.6923\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.2788 - val_accuracy: 0.7179\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2001 - accuracy: 0.8926 - val_loss: 1.2750 - val_accuracy: 0.7350\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.1991 - accuracy: 0.8926 - val_loss: 1.2927 - val_accuracy: 0.7179\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.3055 - val_accuracy: 0.7179\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2021 - accuracy: 0.9000 - val_loss: 1.2931 - val_accuracy: 0.7094\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.2779 - val_accuracy: 0.7350\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2010 - accuracy: 0.8926 - val_loss: 1.2806 - val_accuracy: 0.7265\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1988 - accuracy: 0.9037 - val_loss: 1.2998 - val_accuracy: 0.7179\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2134 - accuracy: 0.8963 - val_loss: 1.3140 - val_accuracy: 0.7179\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.2683 - val_accuracy: 0.7350\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2033 - accuracy: 0.8889 - val_loss: 1.2758 - val_accuracy: 0.7265\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2004 - accuracy: 0.8963 - val_loss: 1.2922 - val_accuracy: 0.7094\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2031 - accuracy: 0.9000 - val_loss: 1.2873 - val_accuracy: 0.7179\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.2959 - val_accuracy: 0.7094\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2042 - accuracy: 0.8852 - val_loss: 1.2854 - val_accuracy: 0.7094\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1982 - accuracy: 0.8963 - val_loss: 1.3098 - val_accuracy: 0.7179\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2015 - accuracy: 0.8963 - val_loss: 1.2809 - val_accuracy: 0.7179\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.2798 - val_accuracy: 0.7094\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.2709 - val_accuracy: 0.7265\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.2972 - val_accuracy: 0.7094\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2077 - accuracy: 0.9000 - val_loss: 1.3090 - val_accuracy: 0.7094\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2065 - accuracy: 0.8815 - val_loss: 1.2811 - val_accuracy: 0.7265\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.1999 - accuracy: 0.8889 - val_loss: 1.3026 - val_accuracy: 0.7094\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2014 - accuracy: 0.8926 - val_loss: 1.2981 - val_accuracy: 0.7094\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.3069 - val_accuracy: 0.7094\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2035 - accuracy: 0.8889 - val_loss: 1.2785 - val_accuracy: 0.7350\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2008 - accuracy: 0.8926 - val_loss: 1.2903 - val_accuracy: 0.7094\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2010 - accuracy: 0.8963 - val_loss: 1.3141 - val_accuracy: 0.7179\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2046 - accuracy: 0.9000 - val_loss: 1.2869 - val_accuracy: 0.7179\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.2890 - val_accuracy: 0.7179\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.3009 - val_accuracy: 0.7179\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2082 - accuracy: 0.8667 - val_loss: 1.2783 - val_accuracy: 0.7350\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1984 - accuracy: 0.8852 - val_loss: 1.2866 - val_accuracy: 0.7179\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.2882 - val_accuracy: 0.7179\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2038 - accuracy: 0.9000 - val_loss: 1.3093 - val_accuracy: 0.7179\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.2849 - val_accuracy: 0.7094\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2024 - accuracy: 0.8852 - val_loss: 1.2957 - val_accuracy: 0.7179\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2001 - accuracy: 0.8926 - val_loss: 1.2974 - val_accuracy: 0.7179\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.3038 - val_accuracy: 0.7179\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2040 - accuracy: 0.8926 - val_loss: 1.2896 - val_accuracy: 0.7179\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.2998 - val_accuracy: 0.7179\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2036 - accuracy: 0.9000 - val_loss: 1.3040 - val_accuracy: 0.7179\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1976 - accuracy: 0.8963 - val_loss: 1.2943 - val_accuracy: 0.7094\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2060 - accuracy: 0.8889 - val_loss: 1.3036 - val_accuracy: 0.7179\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.2993 - val_accuracy: 0.7179\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.2914 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3197b080>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 92us/step\n",
      "over-sampling test accuracy: 68.38%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 0, 2, 2, 2, 0, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1,\n",
       "       0, 1, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1,\n",
       "       1, 1, 1, 2, 0, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2,\n",
       "       1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 2, 1,\n",
       "       0, 0, 1, 1, 1, 0, 2, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 0, 2, 0, 1, 2,\n",
       "       2, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CFBRSa24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS383     1     0\n",
       "1       NRS254     1     1\n",
       "2       NRS218     1     1\n",
       "3       NRS215     0     0\n",
       "4    BCH-SA-14     2     2\n",
       "..         ...   ...   ...\n",
       "112     NRS227     1     0\n",
       "113     NRS272     1     1\n",
       "114   CFBRSa24     0     1\n",
       "115   CFBRSa74     0     0\n",
       "116     NRS271     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966261</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>1.181456e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>5.229296e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>2.717784e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.848142e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>9.390469e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.953246</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>3.748031e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.987253</td>\n",
       "      <td>2.679535e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.478381</td>\n",
       "      <td>0.521614</td>\n",
       "      <td>4.744370e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>7.578712e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.973466</td>\n",
       "      <td>2.536758e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.966261  0.032558  1.181456e-03\n",
       "1    0.003082  0.996395  5.229296e-04\n",
       "2    0.013079  0.986894  2.717784e-05\n",
       "3    0.999998  0.000002  1.848142e-09\n",
       "4    0.000005  0.060949  9.390469e-01\n",
       "..        ...       ...           ...\n",
       "112  0.953246  0.009274  3.748031e-02\n",
       "113  0.010068  0.987253  2.679535e-03\n",
       "114  0.478381  0.521614  4.744370e-06\n",
       "115  0.999965  0.000035  7.578712e-09\n",
       "116  0.001166  0.973466  2.536758e-02\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2069 - accuracy: 0.8889 - val_loss: 1.4136 - val_accuracy: 0.7094\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2023 - accuracy: 0.8926 - val_loss: 1.4354 - val_accuracy: 0.6838\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.4402 - val_accuracy: 0.6667\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2036 - accuracy: 0.8889 - val_loss: 1.4350 - val_accuracy: 0.6838\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2064 - accuracy: 0.8963 - val_loss: 1.4157 - val_accuracy: 0.6838\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2121 - accuracy: 0.9037 - val_loss: 1.4330 - val_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2069 - accuracy: 0.8963 - val_loss: 1.4137 - val_accuracy: 0.6923\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2036 - accuracy: 0.8926 - val_loss: 1.4215 - val_accuracy: 0.7009\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2048 - accuracy: 0.8926 - val_loss: 1.4308 - val_accuracy: 0.6752\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2060 - accuracy: 0.9000 - val_loss: 1.4261 - val_accuracy: 0.6838\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.4312 - val_accuracy: 0.6838\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2027 - accuracy: 0.9000 - val_loss: 1.4230 - val_accuracy: 0.6923\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.1994 - accuracy: 0.8963 - val_loss: 1.4319 - val_accuracy: 0.6923\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2051 - accuracy: 0.8926 - val_loss: 1.4312 - val_accuracy: 0.7009\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.84 - 0s 111us/step - loss: 0.2012 - accuracy: 0.8963 - val_loss: 1.4302 - val_accuracy: 0.6838\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.4253 - val_accuracy: 0.6838\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.4271 - val_accuracy: 0.6923\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2052 - accuracy: 0.8963 - val_loss: 1.4217 - val_accuracy: 0.6838\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2002 - accuracy: 0.8963 - val_loss: 1.4237 - val_accuracy: 0.6923\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.4293 - val_accuracy: 0.6923\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2014 - accuracy: 0.8963 - val_loss: 1.4242 - val_accuracy: 0.6923\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4328 - val_accuracy: 0.6923\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.4411 - val_accuracy: 0.6923\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2025 - accuracy: 0.8963 - val_loss: 1.4444 - val_accuracy: 0.6838\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2028 - accuracy: 0.9000 - val_loss: 1.4224 - val_accuracy: 0.6923\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2064 - accuracy: 0.8926 - val_loss: 1.4387 - val_accuracy: 0.6923\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2041 - accuracy: 0.8889 - val_loss: 1.4223 - val_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2042 - accuracy: 0.8852 - val_loss: 1.4248 - val_accuracy: 0.6923\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2030 - accuracy: 0.8963 - val_loss: 1.4393 - val_accuracy: 0.6838\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2036 - accuracy: 0.8926 - val_loss: 1.4327 - val_accuracy: 0.6838\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2046 - accuracy: 0.8889 - val_loss: 1.4338 - val_accuracy: 0.6752\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.4420 - val_accuracy: 0.6923\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2021 - accuracy: 0.8963 - val_loss: 1.4347 - val_accuracy: 0.6923\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2129 - accuracy: 0.9000 - val_loss: 1.4563 - val_accuracy: 0.6838\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1992 - accuracy: 0.9037 - val_loss: 1.4196 - val_accuracy: 0.7009\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2043 - accuracy: 0.8926 - val_loss: 1.4228 - val_accuracy: 0.7009\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.1987 - accuracy: 0.8926 - val_loss: 1.4409 - val_accuracy: 0.6838\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.4415 - val_accuracy: 0.6923\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2002 - accuracy: 0.9037 - val_loss: 1.4280 - val_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2041 - accuracy: 0.9000 - val_loss: 1.4429 - val_accuracy: 0.6923\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2060 - accuracy: 0.9000 - val_loss: 1.4243 - val_accuracy: 0.6838\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.4399 - val_accuracy: 0.6923\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2023 - accuracy: 0.8963 - val_loss: 1.4457 - val_accuracy: 0.6923\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.4256 - val_accuracy: 0.6838\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 317us/step - loss: 0.2027 - accuracy: 0.9000 - val_loss: 1.4370 - val_accuracy: 0.6923\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.4362 - val_accuracy: 0.6923\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2026 - accuracy: 0.8852 - val_loss: 1.4372 - val_accuracy: 0.6838\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.4405 - val_accuracy: 0.6838\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.4368 - val_accuracy: 0.7009\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2042 - accuracy: 0.8926 - val_loss: 1.4386 - val_accuracy: 0.6838\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2011 - accuracy: 0.8852 - val_loss: 1.4353 - val_accuracy: 0.6752\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2028 - accuracy: 0.8852 - val_loss: 1.4349 - val_accuracy: 0.6923\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2046 - accuracy: 0.9000 - val_loss: 1.4413 - val_accuracy: 0.6838\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2008 - accuracy: 0.9000 - val_loss: 1.4235 - val_accuracy: 0.7009\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2044 - accuracy: 0.8889 - val_loss: 1.4304 - val_accuracy: 0.7009\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2041 - accuracy: 0.9000 - val_loss: 1.4569 - val_accuracy: 0.6838\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2052 - accuracy: 0.8963 - val_loss: 1.4321 - val_accuracy: 0.7009\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2033 - accuracy: 0.8926 - val_loss: 1.4274 - val_accuracy: 0.7094\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2118 - accuracy: 0.8889 - val_loss: 1.4479 - val_accuracy: 0.7094\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2001 - accuracy: 0.8889 - val_loss: 1.4318 - val_accuracy: 0.6838\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2030 - accuracy: 0.8741 - val_loss: 1.4408 - val_accuracy: 0.7009\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2034 - accuracy: 0.8963 - val_loss: 1.4608 - val_accuracy: 0.7009\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2066 - accuracy: 0.8852 - val_loss: 1.4458 - val_accuracy: 0.6667\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2050 - accuracy: 0.8926 - val_loss: 1.4520 - val_accuracy: 0.7009\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2025 - accuracy: 0.8963 - val_loss: 1.4476 - val_accuracy: 0.6923\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2010 - accuracy: 0.9000 - val_loss: 1.4403 - val_accuracy: 0.6667\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.4423 - val_accuracy: 0.6838\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2032 - accuracy: 0.9000 - val_loss: 1.4529 - val_accuracy: 0.7009\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.4290 - val_accuracy: 0.7009\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2030 - accuracy: 0.8852 - val_loss: 1.4452 - val_accuracy: 0.6838\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.4416 - val_accuracy: 0.6838\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2004 - accuracy: 0.8852 - val_loss: 1.4386 - val_accuracy: 0.6923\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4359 - val_accuracy: 0.6923\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2022 - accuracy: 0.9000 - val_loss: 1.4468 - val_accuracy: 0.6838\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.4448 - val_accuracy: 0.6838\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2010 - accuracy: 0.9000 - val_loss: 1.4448 - val_accuracy: 0.6838\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2016 - accuracy: 0.8926 - val_loss: 1.4494 - val_accuracy: 0.6838\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.90 - 0s 184us/step - loss: 0.2000 - accuracy: 0.9000 - val_loss: 1.4553 - val_accuracy: 0.6923\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.4457 - val_accuracy: 0.6838\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.4373 - val_accuracy: 0.6838\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2028 - accuracy: 0.8778 - val_loss: 1.4414 - val_accuracy: 0.6923\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2038 - accuracy: 0.8926 - val_loss: 1.4710 - val_accuracy: 0.6838\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.4623 - val_accuracy: 0.6838\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2054 - accuracy: 0.9000 - val_loss: 1.4666 - val_accuracy: 0.6838\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.4445 - val_accuracy: 0.6838\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2018 - accuracy: 0.8926 - val_loss: 1.4497 - val_accuracy: 0.6838\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.4744 - val_accuracy: 0.6923\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2015 - accuracy: 0.9000 - val_loss: 1.4512 - val_accuracy: 0.6923\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2008 - accuracy: 0.8889 - val_loss: 1.4493 - val_accuracy: 0.6923\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2018 - accuracy: 0.8926 - val_loss: 1.4559 - val_accuracy: 0.7094\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2015 - accuracy: 0.8926 - val_loss: 1.4623 - val_accuracy: 0.6752\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.1991 - accuracy: 0.9037 - val_loss: 1.4535 - val_accuracy: 0.6923\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.4515 - val_accuracy: 0.6838\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.4526 - val_accuracy: 0.6838\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.4612 - val_accuracy: 0.6838\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.4612 - val_accuracy: 0.6838\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.4609 - val_accuracy: 0.6838\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.4532 - val_accuracy: 0.6838\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2038 - accuracy: 0.8963 - val_loss: 1.4418 - val_accuracy: 0.7009\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2009 - accuracy: 0.8963 - val_loss: 1.4650 - val_accuracy: 0.6838\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.4742 - val_accuracy: 0.6923\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2038 - accuracy: 0.9000 - val_loss: 1.4696 - val_accuracy: 0.6923\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.1997 - accuracy: 0.8889 - val_loss: 1.4405 - val_accuracy: 0.7009\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2013 - accuracy: 0.9037 - val_loss: 1.4605 - val_accuracy: 0.6838\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.4616 - val_accuracy: 0.6923\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2053 - accuracy: 0.8815 - val_loss: 1.4393 - val_accuracy: 0.7009\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2035 - accuracy: 0.8815 - val_loss: 1.4637 - val_accuracy: 0.6923\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2041 - accuracy: 0.8926 - val_loss: 1.4624 - val_accuracy: 0.7009\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.1969 - accuracy: 0.8963 - val_loss: 1.4530 - val_accuracy: 0.6667\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2043 - accuracy: 0.8963 - val_loss: 1.4684 - val_accuracy: 0.6667\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 171us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.4669 - val_accuracy: 0.6838\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4639 - val_accuracy: 0.6923\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.4658 - val_accuracy: 0.6923\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.4712 - val_accuracy: 0.6923\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2015 - accuracy: 0.8963 - val_loss: 1.4773 - val_accuracy: 0.6838\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.4657 - val_accuracy: 0.6923\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2013 - accuracy: 0.8963 - val_loss: 1.4798 - val_accuracy: 0.6838\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.4766 - val_accuracy: 0.6838\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2020 - accuracy: 0.8778 - val_loss: 1.4646 - val_accuracy: 0.7179\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.4871 - val_accuracy: 0.6838\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4875 - val_accuracy: 0.6923\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.4697 - val_accuracy: 0.6838\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.4704 - val_accuracy: 0.6923\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2039 - accuracy: 0.8889 - val_loss: 1.4636 - val_accuracy: 0.6923\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2032 - accuracy: 0.8741 - val_loss: 1.4821 - val_accuracy: 0.6667\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2041 - accuracy: 0.8852 - val_loss: 1.4829 - val_accuracy: 0.6838\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.4830 - val_accuracy: 0.7094\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2024 - accuracy: 0.8963 - val_loss: 1.4675 - val_accuracy: 0.6923\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4734 - val_accuracy: 0.6838\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2009 - accuracy: 0.8926 - val_loss: 1.4723 - val_accuracy: 0.7094\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2125 - accuracy: 0.8963 - val_loss: 1.4991 - val_accuracy: 0.7009\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.1993 - accuracy: 0.9037 - val_loss: 1.4634 - val_accuracy: 0.7094\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2081 - accuracy: 0.8926 - val_loss: 1.4693 - val_accuracy: 0.7094\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2048 - accuracy: 0.8926 - val_loss: 1.5028 - val_accuracy: 0.6923\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.4709 - val_accuracy: 0.6838\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2043 - accuracy: 0.8852 - val_loss: 1.4687 - val_accuracy: 0.6838\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.4752 - val_accuracy: 0.6923\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.4725 - val_accuracy: 0.6923\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.4809 - val_accuracy: 0.6838\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.4792 - val_accuracy: 0.6923\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2009 - accuracy: 0.8963 - val_loss: 1.4853 - val_accuracy: 0.7009\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.4666 - val_accuracy: 0.7179\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2033 - accuracy: 0.8852 - val_loss: 1.4864 - val_accuracy: 0.7009\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2028 - accuracy: 0.9000 - val_loss: 1.4715 - val_accuracy: 0.6923\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.4894 - val_accuracy: 0.7009\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.4821 - val_accuracy: 0.6838\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.4756 - val_accuracy: 0.6923\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2022 - accuracy: 0.9000 - val_loss: 1.4823 - val_accuracy: 0.6923\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2010 - accuracy: 0.8963 - val_loss: 1.4823 - val_accuracy: 0.7009\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.4824 - val_accuracy: 0.7009\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2031 - accuracy: 0.8815 - val_loss: 1.4879 - val_accuracy: 0.6752\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.4811 - val_accuracy: 0.7009\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 273us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.4805 - val_accuracy: 0.7009\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 285us/step - loss: 0.2032 - accuracy: 0.8926 - val_loss: 1.4900 - val_accuracy: 0.7009\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2095 - accuracy: 0.8778 - val_loss: 1.4776 - val_accuracy: 0.6838\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.1985 - accuracy: 0.9037 - val_loss: 1.5020 - val_accuracy: 0.7094\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2020 - accuracy: 0.8963 - val_loss: 1.4931 - val_accuracy: 0.7094\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.4921 - val_accuracy: 0.6923\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 1.4778 - val_accuracy: 0.7094\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2023 - accuracy: 0.8926 - val_loss: 1.4775 - val_accuracy: 0.6923\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2035 - accuracy: 0.9000 - val_loss: 1.5083 - val_accuracy: 0.7009\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.4835 - val_accuracy: 0.6838\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.4934 - val_accuracy: 0.7009\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 485us/step - loss: 0.2026 - accuracy: 0.9000 - val_loss: 1.4837 - val_accuracy: 0.6923\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.1994 - accuracy: 0.8963 - val_loss: 1.5032 - val_accuracy: 0.6838\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.4904 - val_accuracy: 0.6838\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2046 - accuracy: 0.9000 - val_loss: 1.5033 - val_accuracy: 0.7009\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2029 - accuracy: 0.8963 - val_loss: 1.4790 - val_accuracy: 0.7009\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 350us/step - loss: 0.2037 - accuracy: 0.8889 - val_loss: 1.4968 - val_accuracy: 0.6923\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.4971 - val_accuracy: 0.6838\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.4897 - val_accuracy: 0.6923\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2092 - accuracy: 0.8556 - val_loss: 1.4905 - val_accuracy: 0.6667\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2068 - accuracy: 0.9037 - val_loss: 1.5245 - val_accuracy: 0.7009\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2020 - accuracy: 0.9000 - val_loss: 1.4944 - val_accuracy: 0.6923\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1999 - accuracy: 0.8889 - val_loss: 1.4873 - val_accuracy: 0.7179\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2009 - accuracy: 0.8926 - val_loss: 1.5050 - val_accuracy: 0.7009\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.5002 - val_accuracy: 0.7009\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.5100 - val_accuracy: 0.7009\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.4926 - val_accuracy: 0.6923\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2075 - accuracy: 0.9000 - val_loss: 1.5247 - val_accuracy: 0.7009\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.4918 - val_accuracy: 0.6923\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2005 - accuracy: 0.8926 - val_loss: 1.4881 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2011 - accuracy: 0.8963 - val_loss: 1.5026 - val_accuracy: 0.7009\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2042 - accuracy: 0.9037 - val_loss: 1.5262 - val_accuracy: 0.6752\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2038 - accuracy: 0.9000 - val_loss: 1.5042 - val_accuracy: 0.6923\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2017 - accuracy: 0.8889 - val_loss: 1.4856 - val_accuracy: 0.7094\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2026 - accuracy: 0.8889 - val_loss: 1.5115 - val_accuracy: 0.6923\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2018 - accuracy: 0.8926 - val_loss: 1.5142 - val_accuracy: 0.6923\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.5090 - val_accuracy: 0.6923\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.5125 - val_accuracy: 0.6923\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.5140 - val_accuracy: 0.6923\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.5187 - val_accuracy: 0.7009\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2006 - accuracy: 0.8778 - val_loss: 1.5085 - val_accuracy: 0.7009\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2031 - accuracy: 0.8926 - val_loss: 1.5282 - val_accuracy: 0.7009\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 421us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.5205 - val_accuracy: 0.7009\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.5222 - val_accuracy: 0.7009\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2000 - accuracy: 0.9000 - val_loss: 1.5225 - val_accuracy: 0.7009\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 300us/step - loss: 0.2013 - accuracy: 0.8926 - val_loss: 1.5088 - val_accuracy: 0.6667\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.5157 - val_accuracy: 0.7009\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.5175 - val_accuracy: 0.7009\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2021 - accuracy: 0.8963 - val_loss: 1.4998 - val_accuracy: 0.7179\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 327us/step - loss: 0.2067 - accuracy: 0.8778 - val_loss: 1.5202 - val_accuracy: 0.6752\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.1949 - accuracy: 0.8963 - val_loss: 1.5307 - val_accuracy: 0.7094\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2094 - accuracy: 0.8963 - val_loss: 1.5371 - val_accuracy: 0.7094\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2107 - accuracy: 0.8926 - val_loss: 1.5329 - val_accuracy: 0.6838\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2095 - accuracy: 0.8889 - val_loss: 1.5108 - val_accuracy: 0.6923\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.5247 - val_accuracy: 0.6838\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2026 - accuracy: 0.8963 - val_loss: 1.5172 - val_accuracy: 0.7009\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.5355 - val_accuracy: 0.6838\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.5328 - val_accuracy: 0.6838\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.5321 - val_accuracy: 0.6923\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2029 - accuracy: 0.8963 - val_loss: 1.5424 - val_accuracy: 0.6923\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2023 - accuracy: 0.9074 - val_loss: 1.5169 - val_accuracy: 0.7094\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2029 - accuracy: 0.8926 - val_loss: 1.5187 - val_accuracy: 0.7179\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2092 - accuracy: 0.8963 - val_loss: 1.5438 - val_accuracy: 0.7009\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 280us/step - loss: 0.2050 - accuracy: 0.8963 - val_loss: 1.5457 - val_accuracy: 0.6667\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.2032 - accuracy: 0.8889 - val_loss: 1.5180 - val_accuracy: 0.6923\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.5391 - val_accuracy: 0.7009\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.5314 - val_accuracy: 0.7094\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.1985 - accuracy: 0.8926 - val_loss: 1.5268 - val_accuracy: 0.6923\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 163us/step - loss: 0.2026 - accuracy: 0.8889 - val_loss: 1.5314 - val_accuracy: 0.6923\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2033 - accuracy: 0.9037 - val_loss: 1.5469 - val_accuracy: 0.6667\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2024 - accuracy: 0.9037 - val_loss: 1.5261 - val_accuracy: 0.6923\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.1966 - accuracy: 0.8963 - val_loss: 1.5353 - val_accuracy: 0.7009\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.5274 - val_accuracy: 0.7009\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.5277 - val_accuracy: 0.6923\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2010 - accuracy: 0.8926 - val_loss: 1.5182 - val_accuracy: 0.7179\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2017 - accuracy: 0.8926 - val_loss: 1.5292 - val_accuracy: 0.7009\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2104 - accuracy: 0.8667 - val_loss: 1.5525 - val_accuracy: 0.6752\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2080 - accuracy: 0.8963 - val_loss: 1.5295 - val_accuracy: 0.7009\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.5423 - val_accuracy: 0.7009\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.5373 - val_accuracy: 0.7009\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.5372 - val_accuracy: 0.7009\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2013 - accuracy: 0.8815 - val_loss: 1.5295 - val_accuracy: 0.6923\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.5528 - val_accuracy: 0.7009\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2011 - accuracy: 0.8963 - val_loss: 1.5501 - val_accuracy: 0.6923\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 1.5358 - val_accuracy: 0.6923\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 300us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.5319 - val_accuracy: 0.6923\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.1984 - accuracy: 0.8852 - val_loss: 1.5337 - val_accuracy: 0.6923\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.5446 - val_accuracy: 0.6923\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.1978 - accuracy: 0.9000 - val_loss: 1.5485 - val_accuracy: 0.6923\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2016 - accuracy: 0.9000 - val_loss: 1.5392 - val_accuracy: 0.6667\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2006 - accuracy: 0.8963 - val_loss: 1.5540 - val_accuracy: 0.7094\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2036 - accuracy: 0.8963 - val_loss: 1.5432 - val_accuracy: 0.7094\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1994 - accuracy: 0.8963 - val_loss: 1.5405 - val_accuracy: 0.7094\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.1985 - accuracy: 0.9037 - val_loss: 1.5546 - val_accuracy: 0.6923\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2055 - accuracy: 0.8963 - val_loss: 1.5624 - val_accuracy: 0.7009\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2007 - accuracy: 0.8926 - val_loss: 1.5317 - val_accuracy: 0.6923\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2024 - accuracy: 0.8926 - val_loss: 1.5412 - val_accuracy: 0.6752\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.5587 - val_accuracy: 0.7094\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.5316 - val_accuracy: 0.6923\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2083 - accuracy: 0.8926 - val_loss: 1.5270 - val_accuracy: 0.7094\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2031 - accuracy: 0.8852 - val_loss: 1.5628 - val_accuracy: 0.7094\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.2009 - accuracy: 0.8963 - val_loss: 1.5270 - val_accuracy: 0.7094\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.1999 - accuracy: 0.8889 - val_loss: 1.5339 - val_accuracy: 0.6838\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.1984 - accuracy: 0.8889 - val_loss: 1.5396 - val_accuracy: 0.6923\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.5476 - val_accuracy: 0.6923\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2029 - accuracy: 0.9000 - val_loss: 1.5398 - val_accuracy: 0.6923\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.5580 - val_accuracy: 0.7009\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.5399 - val_accuracy: 0.6923\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.5493 - val_accuracy: 0.6923\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.5431 - val_accuracy: 0.6923\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.5556 - val_accuracy: 0.6667\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2000 - accuracy: 0.8852 - val_loss: 1.5558 - val_accuracy: 0.7009\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2071 - accuracy: 0.8926 - val_loss: 1.5603 - val_accuracy: 0.7094\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2062 - accuracy: 0.8926 - val_loss: 1.5491 - val_accuracy: 0.6923\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2035 - accuracy: 0.8704 - val_loss: 1.5649 - val_accuracy: 0.6667\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2035 - accuracy: 0.8926 - val_loss: 1.5790 - val_accuracy: 0.7009\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2049 - accuracy: 0.8889 - val_loss: 1.5512 - val_accuracy: 0.6923\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2049 - accuracy: 0.9074 - val_loss: 1.5489 - val_accuracy: 0.6667\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2033 - accuracy: 0.9037 - val_loss: 1.5515 - val_accuracy: 0.6923\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2012 - accuracy: 0.8963 - val_loss: 1.5606 - val_accuracy: 0.6923\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.5532 - val_accuracy: 0.6667\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.5485 - val_accuracy: 0.6923\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2075 - accuracy: 0.8963 - val_loss: 1.5490 - val_accuracy: 0.7009\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2111 - accuracy: 0.8852 - val_loss: 1.5377 - val_accuracy: 0.6838\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2067 - accuracy: 0.8704 - val_loss: 1.5754 - val_accuracy: 0.7009\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.5574 - val_accuracy: 0.6923\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.5436 - val_accuracy: 0.6923\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.5446 - val_accuracy: 0.6923\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.5567 - val_accuracy: 0.6923\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2039 - accuracy: 0.8926 - val_loss: 1.5674 - val_accuracy: 0.7094\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.5401 - val_accuracy: 0.6923\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2060 - accuracy: 0.8852 - val_loss: 1.5411 - val_accuracy: 0.7094\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2013 - accuracy: 0.8889 - val_loss: 1.5664 - val_accuracy: 0.7009\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2023 - accuracy: 0.8926 - val_loss: 1.5461 - val_accuracy: 0.6923\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2000 - accuracy: 0.8778 - val_loss: 1.5607 - val_accuracy: 0.7009\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2015 - accuracy: 0.9000 - val_loss: 1.5630 - val_accuracy: 0.7009\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2009 - accuracy: 0.8963 - val_loss: 1.5540 - val_accuracy: 0.6923\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.5596 - val_accuracy: 0.7009\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.5520 - val_accuracy: 0.7009\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.5522 - val_accuracy: 0.7009\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.5545 - val_accuracy: 0.7009\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.5482 - val_accuracy: 0.7179\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2001 - accuracy: 0.8852 - val_loss: 1.5587 - val_accuracy: 0.7009\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.5766 - val_accuracy: 0.7009\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.5597 - val_accuracy: 0.7009\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2047 - accuracy: 0.8963 - val_loss: 1.5554 - val_accuracy: 0.6752\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.1971 - accuracy: 0.8963 - val_loss: 1.5624 - val_accuracy: 0.6923\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2061 - accuracy: 0.8963 - val_loss: 1.5618 - val_accuracy: 0.7009\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2062 - accuracy: 0.8852 - val_loss: 1.5449 - val_accuracy: 0.7094\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2013 - accuracy: 0.8889 - val_loss: 1.5689 - val_accuracy: 0.7009\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.5720 - val_accuracy: 0.7009\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.5612 - val_accuracy: 0.7009\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.1981 - accuracy: 0.8963 - val_loss: 1.5588 - val_accuracy: 0.6923\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2038 - accuracy: 0.8852 - val_loss: 1.5458 - val_accuracy: 0.6923\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.5684 - val_accuracy: 0.6923\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.5731 - val_accuracy: 0.6923\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.5748 - val_accuracy: 0.6923\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.5596 - val_accuracy: 0.6923\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.1978 - accuracy: 0.9000 - val_loss: 1.5591 - val_accuracy: 0.7009\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.5719 - val_accuracy: 0.6923\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1998 - accuracy: 0.8926 - val_loss: 1.5627 - val_accuracy: 0.7009\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 1.5771 - val_accuracy: 0.6923\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.5598 - val_accuracy: 0.6923\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.1985 - accuracy: 0.8963 - val_loss: 1.5606 - val_accuracy: 0.6923\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2022 - accuracy: 0.8963 - val_loss: 1.5838 - val_accuracy: 0.7009\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.2072 - accuracy: 0.8741 - val_loss: 1.5574 - val_accuracy: 0.6923\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 434us/step - loss: 0.1992 - accuracy: 0.8926 - val_loss: 1.5786 - val_accuracy: 0.6923\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2017 - accuracy: 0.9000 - val_loss: 1.5844 - val_accuracy: 0.6923\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.5582 - val_accuracy: 0.6923\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.5495 - val_accuracy: 0.6923\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.1988 - accuracy: 0.8963 - val_loss: 1.5644 - val_accuracy: 0.7009\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.5824 - val_accuracy: 0.7009\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.5796 - val_accuracy: 0.6923\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.5745 - val_accuracy: 0.7009\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.5598 - val_accuracy: 0.6923\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.1980 - accuracy: 0.8963 - val_loss: 1.5740 - val_accuracy: 0.7009\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 584us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.5761 - val_accuracy: 0.7009\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.5718 - val_accuracy: 0.6923\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 115us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.5667 - val_accuracy: 0.6923\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 1.5833 - val_accuracy: 0.6923\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.5701 - val_accuracy: 0.6923\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2009 - accuracy: 0.9037 - val_loss: 1.5716 - val_accuracy: 0.6923\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2051 - accuracy: 0.8815 - val_loss: 1.5693 - val_accuracy: 0.6923\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.5827 - val_accuracy: 0.7009\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.5718 - val_accuracy: 0.7009\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2011 - accuracy: 0.8926 - val_loss: 1.5731 - val_accuracy: 0.6923\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2095 - accuracy: 0.8926 - val_loss: 1.5980 - val_accuracy: 0.7009\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1991 - accuracy: 0.8926 - val_loss: 1.5640 - val_accuracy: 0.7094\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.1985 - accuracy: 0.8926 - val_loss: 1.5671 - val_accuracy: 0.6923\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2014 - accuracy: 0.8926 - val_loss: 1.5695 - val_accuracy: 0.6752\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2040 - accuracy: 0.9000 - val_loss: 1.5820 - val_accuracy: 0.7009\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2065 - accuracy: 0.8852 - val_loss: 1.5535 - val_accuracy: 0.7094\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2011 - accuracy: 0.8889 - val_loss: 1.5721 - val_accuracy: 0.7009\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2029 - accuracy: 0.8963 - val_loss: 1.5927 - val_accuracy: 0.6923\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.5719 - val_accuracy: 0.6923\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.5655 - val_accuracy: 0.6923\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.5687 - val_accuracy: 0.6923\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.5757 - val_accuracy: 0.6752\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 255us/step - loss: 0.1987 - accuracy: 0.8926 - val_loss: 1.5879 - val_accuracy: 0.7094\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2012 - accuracy: 0.8926 - val_loss: 1.5791 - val_accuracy: 0.6923\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.5853 - val_accuracy: 0.6923\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.5805 - val_accuracy: 0.6923\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2012 - accuracy: 0.9000 - val_loss: 1.5746 - val_accuracy: 0.6752\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.1966 - accuracy: 0.8963 - val_loss: 1.5729 - val_accuracy: 0.7009\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2033 - accuracy: 0.8926 - val_loss: 1.5701 - val_accuracy: 0.6923\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.5915 - val_accuracy: 0.7009\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2057 - accuracy: 0.8926 - val_loss: 1.5777 - val_accuracy: 0.7094\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.5741 - val_accuracy: 0.6923\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.5688 - val_accuracy: 0.6923\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.5870 - val_accuracy: 0.7009\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.5799 - val_accuracy: 0.7009\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.5806 - val_accuracy: 0.7009\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2005 - accuracy: 0.8815 - val_loss: 1.5619 - val_accuracy: 0.7094\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2029 - accuracy: 0.8926 - val_loss: 1.6003 - val_accuracy: 0.7009\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.5848 - val_accuracy: 0.6923\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.1965 - accuracy: 0.9000 - val_loss: 1.5779 - val_accuracy: 0.6923\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.5708 - val_accuracy: 0.7009\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2004 - accuracy: 0.8963 - val_loss: 1.5932 - val_accuracy: 0.7009\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.5904 - val_accuracy: 0.6923\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 637us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.5847 - val_accuracy: 0.6923\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 369us/step - loss: 0.2005 - accuracy: 0.8889 - val_loss: 1.5706 - val_accuracy: 0.7094\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2040 - accuracy: 0.8889 - val_loss: 1.5964 - val_accuracy: 0.6923\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.5944 - val_accuracy: 0.6923\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.1980 - accuracy: 0.8926 - val_loss: 1.5871 - val_accuracy: 0.6923\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.6001 - val_accuracy: 0.6923\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.1991 - accuracy: 0.8926 - val_loss: 1.5944 - val_accuracy: 0.6923\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2006 - accuracy: 0.8889 - val_loss: 1.5836 - val_accuracy: 0.6923\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.6128 - val_accuracy: 0.6923\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.5972 - val_accuracy: 0.6923\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.5969 - val_accuracy: 0.6923\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.6050 - val_accuracy: 0.6923\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2003 - accuracy: 0.8926 - val_loss: 1.5816 - val_accuracy: 0.7179\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2048 - accuracy: 0.8889 - val_loss: 1.5966 - val_accuracy: 0.6923\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.5982 - val_accuracy: 0.6923\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.6040 - val_accuracy: 0.6923\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.5868 - val_accuracy: 0.6923\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.5962 - val_accuracy: 0.6923\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.5949 - val_accuracy: 0.6923\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.5890 - val_accuracy: 0.6923\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.1975 - accuracy: 0.8963 - val_loss: 1.5963 - val_accuracy: 0.6923\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.6003 - val_accuracy: 0.6752\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.5960 - val_accuracy: 0.6923\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.1985 - accuracy: 0.8963 - val_loss: 1.6063 - val_accuracy: 0.6923\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.6009 - val_accuracy: 0.6923\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.1996 - accuracy: 0.8963 - val_loss: 1.5950 - val_accuracy: 0.7009\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.1989 - accuracy: 0.8852 - val_loss: 1.6009 - val_accuracy: 0.6923\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2057 - accuracy: 0.8963 - val_loss: 1.6372 - val_accuracy: 0.6752\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2037 - accuracy: 0.9000 - val_loss: 1.5988 - val_accuracy: 0.6923\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.5877 - val_accuracy: 0.6923\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.1993 - accuracy: 0.8889 - val_loss: 1.5923 - val_accuracy: 0.6923\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2024 - accuracy: 0.8963 - val_loss: 1.6132 - val_accuracy: 0.6752\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 1.5969 - val_accuracy: 0.7009\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.6047 - val_accuracy: 0.6923\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2024 - accuracy: 0.8926 - val_loss: 1.6118 - val_accuracy: 0.6923\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.5970 - val_accuracy: 0.6923\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2069 - accuracy: 0.8889 - val_loss: 1.5897 - val_accuracy: 0.7094\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2030 - accuracy: 0.8889 - val_loss: 1.6075 - val_accuracy: 0.7094\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2015 - accuracy: 0.8963 - val_loss: 1.6029 - val_accuracy: 0.7009\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2011 - accuracy: 0.8815 - val_loss: 1.5879 - val_accuracy: 0.7094\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 606us/step - loss: 0.1973 - accuracy: 0.8963 - val_loss: 1.6105 - val_accuracy: 0.7009\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2004 - accuracy: 0.8963 - val_loss: 1.6163 - val_accuracy: 0.7009\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.5978 - val_accuracy: 0.7094\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.1977 - accuracy: 0.9074 - val_loss: 1.6137 - val_accuracy: 0.7009\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2014 - accuracy: 0.8926 - val_loss: 1.6202 - val_accuracy: 0.7009\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.1993 - accuracy: 0.8926 - val_loss: 1.6170 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2069 - accuracy: 0.8778 - val_loss: 1.5868 - val_accuracy: 0.7094\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2024 - accuracy: 0.8926 - val_loss: 1.6209 - val_accuracy: 0.6923\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.6154 - val_accuracy: 0.6923\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.6157 - val_accuracy: 0.6923\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2012 - accuracy: 0.8852 - val_loss: 1.6143 - val_accuracy: 0.7009\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1993 - accuracy: 0.8889 - val_loss: 1.6172 - val_accuracy: 0.7009\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2054 - accuracy: 0.8778 - val_loss: 1.6206 - val_accuracy: 0.6752\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1980 - accuracy: 0.9037 - val_loss: 1.6067 - val_accuracy: 0.6923\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.5981 - val_accuracy: 0.6923\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.1996 - accuracy: 0.8889 - val_loss: 1.5978 - val_accuracy: 0.7094\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2002 - accuracy: 0.8926 - val_loss: 1.6220 - val_accuracy: 0.6838\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2023 - accuracy: 0.8889 - val_loss: 1.6014 - val_accuracy: 0.6923\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2067 - accuracy: 0.8889 - val_loss: 1.6226 - val_accuracy: 0.7094\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.6207 - val_accuracy: 0.6923\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2009 - accuracy: 0.8889 - val_loss: 1.6131 - val_accuracy: 0.6923\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1952 - accuracy: 0.9000 - val_loss: 1.6142 - val_accuracy: 0.7009\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.6096 - val_accuracy: 0.7009\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.6151 - val_accuracy: 0.6923\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2043 - accuracy: 0.8889 - val_loss: 1.6103 - val_accuracy: 0.7009\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.1999 - accuracy: 0.8815 - val_loss: 1.6073 - val_accuracy: 0.7009\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.6241 - val_accuracy: 0.7009\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2024 - accuracy: 0.9000 - val_loss: 1.6260 - val_accuracy: 0.7009\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1976 - accuracy: 0.8963 - val_loss: 1.6045 - val_accuracy: 0.6923\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 106us/step - loss: 0.1992 - accuracy: 0.8926 - val_loss: 1.6091 - val_accuracy: 0.6923\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.6254 - val_accuracy: 0.7009\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1998 - accuracy: 0.8926 - val_loss: 1.6126 - val_accuracy: 0.6923\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1985 - accuracy: 0.8926 - val_loss: 1.6264 - val_accuracy: 0.6752\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1978 - accuracy: 0.8963 - val_loss: 1.6151 - val_accuracy: 0.6923\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.6228 - val_accuracy: 0.7009\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.6253 - val_accuracy: 0.7009\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.1997 - accuracy: 0.8963 - val_loss: 1.6089 - val_accuracy: 0.7009\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.6275 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6284 - val_accuracy: 0.7009\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 1.6225 - val_accuracy: 0.7009\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.6207 - val_accuracy: 0.7009\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2028 - accuracy: 0.8630 - val_loss: 1.6195 - val_accuracy: 0.7009\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.6336 - val_accuracy: 0.7094\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.6313 - val_accuracy: 0.7009\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.6374 - val_accuracy: 0.7009\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 1.6273 - val_accuracy: 0.7009\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1992 - accuracy: 0.8852 - val_loss: 1.6054 - val_accuracy: 0.7094\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2023 - accuracy: 0.8815 - val_loss: 1.6289 - val_accuracy: 0.6923\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6127 - val_accuracy: 0.6923\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1984 - accuracy: 0.8852 - val_loss: 1.6152 - val_accuracy: 0.7009\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.6314 - val_accuracy: 0.7009\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.6382 - val_accuracy: 0.6923\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.6275 - val_accuracy: 0.6923\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.6198 - val_accuracy: 0.6923\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.6221 - val_accuracy: 0.6923\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2017 - accuracy: 0.8963 - val_loss: 1.6475 - val_accuracy: 0.6923\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.6205 - val_accuracy: 0.7094\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2028 - accuracy: 0.8926 - val_loss: 1.6306 - val_accuracy: 0.6923\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2016 - accuracy: 0.8963 - val_loss: 1.6482 - val_accuracy: 0.7009\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.6277 - val_accuracy: 0.6923\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.6322 - val_accuracy: 0.6923\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.6431 - val_accuracy: 0.7009\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.1987 - accuracy: 0.8963 - val_loss: 1.6333 - val_accuracy: 0.6923\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.6314 - val_accuracy: 0.7009\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.6258 - val_accuracy: 0.7009\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2030 - accuracy: 0.8963 - val_loss: 1.6363 - val_accuracy: 0.6923\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2048 - accuracy: 0.8889 - val_loss: 1.6200 - val_accuracy: 0.6923\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2004 - accuracy: 0.8889 - val_loss: 1.6298 - val_accuracy: 0.6923\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.1959 - accuracy: 0.9000 - val_loss: 1.6479 - val_accuracy: 0.6923\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.6458 - val_accuracy: 0.6923\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2032 - accuracy: 0.8852 - val_loss: 1.6478 - val_accuracy: 0.7009\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.6393 - val_accuracy: 0.6923\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.1985 - accuracy: 0.8963 - val_loss: 1.6258 - val_accuracy: 0.7094\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.6409 - val_accuracy: 0.6923\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.6397 - val_accuracy: 0.6923\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.6473 - val_accuracy: 0.6923\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1956 - accuracy: 0.9000 - val_loss: 1.6293 - val_accuracy: 0.7094\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1984 - accuracy: 0.8852 - val_loss: 1.6353 - val_accuracy: 0.7094\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1983 - accuracy: 0.8926 - val_loss: 1.6429 - val_accuracy: 0.7009\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1964 - accuracy: 0.8815 - val_loss: 1.6268 - val_accuracy: 0.7094\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2035 - accuracy: 0.8926 - val_loss: 1.6412 - val_accuracy: 0.7009\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2026 - accuracy: 0.8815 - val_loss: 1.6281 - val_accuracy: 0.7094\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.1979 - accuracy: 0.8926 - val_loss: 1.6518 - val_accuracy: 0.6923\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2045 - accuracy: 0.9000 - val_loss: 1.6608 - val_accuracy: 0.7009\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2022 - accuracy: 0.8852 - val_loss: 1.6193 - val_accuracy: 0.7179\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2008 - accuracy: 0.8889 - val_loss: 1.6368 - val_accuracy: 0.6923\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 1.6478 - val_accuracy: 0.6923\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.6413 - val_accuracy: 0.6923\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1959 - accuracy: 0.9000 - val_loss: 1.6517 - val_accuracy: 0.7009\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2028 - accuracy: 0.8926 - val_loss: 1.6373 - val_accuracy: 0.6923\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.6477 - val_accuracy: 0.7009\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2023 - accuracy: 0.8926 - val_loss: 1.6527 - val_accuracy: 0.7009\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2013 - accuracy: 0.8815 - val_loss: 1.6369 - val_accuracy: 0.7094\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2022 - accuracy: 0.8889 - val_loss: 1.6434 - val_accuracy: 0.7009\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.6372 - val_accuracy: 0.7009\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 351us/step - loss: 0.1970 - accuracy: 0.8963 - val_loss: 1.6322 - val_accuracy: 0.7094\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.1979 - accuracy: 0.8926 - val_loss: 1.6434 - val_accuracy: 0.7009\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.1990 - accuracy: 0.8889 - val_loss: 1.6381 - val_accuracy: 0.6923\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 360us/step - loss: 0.2009 - accuracy: 0.8963 - val_loss: 1.6631 - val_accuracy: 0.7009\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.6491 - val_accuracy: 0.7094\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2083 - accuracy: 0.8778 - val_loss: 1.6235 - val_accuracy: 0.6923\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2002 - accuracy: 0.8778 - val_loss: 1.6480 - val_accuracy: 0.6923\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.6532 - val_accuracy: 0.7009\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.1983 - accuracy: 0.8926 - val_loss: 1.6309 - val_accuracy: 0.7094\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2008 - accuracy: 0.8889 - val_loss: 1.6514 - val_accuracy: 0.6923\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2028 - accuracy: 0.8852 - val_loss: 1.6367 - val_accuracy: 0.6923\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.6472 - val_accuracy: 0.7009\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1995 - accuracy: 0.8926 - val_loss: 1.6604 - val_accuracy: 0.7094\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2050 - accuracy: 0.8889 - val_loss: 1.6361 - val_accuracy: 0.6752\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2012 - accuracy: 0.8889 - val_loss: 1.6389 - val_accuracy: 0.7009\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.6333 - val_accuracy: 0.7094\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2000 - accuracy: 0.9000 - val_loss: 1.6683 - val_accuracy: 0.6923\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2033 - accuracy: 0.8926 - val_loss: 1.6527 - val_accuracy: 0.6923\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2047 - accuracy: 0.8926 - val_loss: 1.6537 - val_accuracy: 0.7009\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.6454 - val_accuracy: 0.6752\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2000 - accuracy: 0.8926 - val_loss: 1.6440 - val_accuracy: 0.6923\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2027 - accuracy: 0.8926 - val_loss: 1.6459 - val_accuracy: 0.6923\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.6471 - val_accuracy: 0.6923\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2014 - accuracy: 0.8815 - val_loss: 1.6379 - val_accuracy: 0.6923\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.6505 - val_accuracy: 0.6923\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2037 - accuracy: 0.8926 - val_loss: 1.6634 - val_accuracy: 0.6923\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2004 - accuracy: 0.8926 - val_loss: 1.6374 - val_accuracy: 0.6923\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2054 - accuracy: 0.8852 - val_loss: 1.6485 - val_accuracy: 0.6923\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2005 - accuracy: 0.8889 - val_loss: 1.6515 - val_accuracy: 0.6923\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.6649 - val_accuracy: 0.6923\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2002 - accuracy: 0.9000 - val_loss: 1.6479 - val_accuracy: 0.6923\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6634 - val_accuracy: 0.6923\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1994 - accuracy: 0.8926 - val_loss: 1.6598 - val_accuracy: 0.6923\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.1986 - accuracy: 0.8963 - val_loss: 1.6573 - val_accuracy: 0.6752\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.6577 - val_accuracy: 0.6923\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.1976 - accuracy: 0.8963 - val_loss: 1.6508 - val_accuracy: 0.6923\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.6668 - val_accuracy: 0.7009\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2050 - accuracy: 0.8963 - val_loss: 1.6815 - val_accuracy: 0.7009\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.6511 - val_accuracy: 0.6923\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2068 - accuracy: 0.8926 - val_loss: 1.6384 - val_accuracy: 0.7094\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2005 - accuracy: 0.9000 - val_loss: 1.6805 - val_accuracy: 0.6923\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.6597 - val_accuracy: 0.6923\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.2039 - accuracy: 0.9000 - val_loss: 1.6593 - val_accuracy: 0.6923\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2007 - accuracy: 0.8852 - val_loss: 1.6498 - val_accuracy: 0.6923\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 109us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.6602 - val_accuracy: 0.6923\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.1984 - accuracy: 0.8926 - val_loss: 1.6640 - val_accuracy: 0.6923\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2010 - accuracy: 0.8926 - val_loss: 1.6530 - val_accuracy: 0.6752\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2017 - accuracy: 0.8741 - val_loss: 1.6575 - val_accuracy: 0.6923\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.6552 - val_accuracy: 0.6923\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1988 - accuracy: 0.8963 - val_loss: 1.6645 - val_accuracy: 0.7009\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2063 - accuracy: 0.8778 - val_loss: 1.6396 - val_accuracy: 0.7094\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2014 - accuracy: 0.8889 - val_loss: 1.6626 - val_accuracy: 0.7009\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6665 - val_accuracy: 0.7009\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.6552 - val_accuracy: 0.7009\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.6517 - val_accuracy: 0.7009\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 1.6562 - val_accuracy: 0.7094\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.6778 - val_accuracy: 0.7009\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.6590 - val_accuracy: 0.6923\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1966 - accuracy: 0.9000 - val_loss: 1.6568 - val_accuracy: 0.6923\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.6627 - val_accuracy: 0.6923\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.6647 - val_accuracy: 0.6923\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.1967 - accuracy: 0.9000 - val_loss: 1.6656 - val_accuracy: 0.6923\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.6711 - val_accuracy: 0.6923\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 310us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.6666 - val_accuracy: 0.6923\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.6718 - val_accuracy: 0.7009\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.6616 - val_accuracy: 0.6923\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1991 - accuracy: 0.8926 - val_loss: 1.6577 - val_accuracy: 0.7094\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2084 - accuracy: 0.8778 - val_loss: 1.6835 - val_accuracy: 0.6752\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.6685 - val_accuracy: 0.6923\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2037 - accuracy: 0.8963 - val_loss: 1.6491 - val_accuracy: 0.7094\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2047 - accuracy: 0.8889 - val_loss: 1.6880 - val_accuracy: 0.7009\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6700 - val_accuracy: 0.6923\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2090 - accuracy: 0.8630 - val_loss: 1.6739 - val_accuracy: 0.6752\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2024 - accuracy: 0.9111 - val_loss: 1.6854 - val_accuracy: 0.7094\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2081 - accuracy: 0.8852 - val_loss: 1.6489 - val_accuracy: 0.7179\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2040 - accuracy: 0.8889 - val_loss: 1.6627 - val_accuracy: 0.7179\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1988 - accuracy: 0.8963 - val_loss: 1.6784 - val_accuracy: 0.6838\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2012 - accuracy: 0.8963 - val_loss: 1.6758 - val_accuracy: 0.7009\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.6698 - val_accuracy: 0.6923\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.6588 - val_accuracy: 0.6923\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.6555 - val_accuracy: 0.6923\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2020 - accuracy: 0.8963 - val_loss: 1.6681 - val_accuracy: 0.7009\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2057 - accuracy: 0.8778 - val_loss: 1.6512 - val_accuracy: 0.6923\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.6732 - val_accuracy: 0.6923\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1960 - accuracy: 0.9000 - val_loss: 1.6658 - val_accuracy: 0.6923\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2038 - accuracy: 0.8963 - val_loss: 1.6584 - val_accuracy: 0.6923\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.6617 - val_accuracy: 0.6923\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6710 - val_accuracy: 0.6923\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 1.6649 - val_accuracy: 0.6923\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1957 - accuracy: 0.8889 - val_loss: 1.6597 - val_accuracy: 0.7094\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2023 - accuracy: 0.8889 - val_loss: 1.6716 - val_accuracy: 0.6752\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 340us/step - loss: 0.2036 - accuracy: 0.8963 - val_loss: 1.6788 - val_accuracy: 0.7009\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.1989 - accuracy: 0.8926 - val_loss: 1.6672 - val_accuracy: 0.6923\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2002 - accuracy: 0.8852 - val_loss: 1.6668 - val_accuracy: 0.6923\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.6790 - val_accuracy: 0.6923\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1991 - accuracy: 0.8963 - val_loss: 1.6915 - val_accuracy: 0.7094\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1986 - accuracy: 0.8963 - val_loss: 1.6581 - val_accuracy: 0.7094\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.1999 - accuracy: 0.8815 - val_loss: 1.6658 - val_accuracy: 0.7009\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.6662 - val_accuracy: 0.7009\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.1991 - accuracy: 0.8852 - val_loss: 1.6656 - val_accuracy: 0.7009\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.6815 - val_accuracy: 0.7009\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.6697 - val_accuracy: 0.7009\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.6876 - val_accuracy: 0.7009\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.6723 - val_accuracy: 0.6923\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.1983 - accuracy: 0.8926 - val_loss: 1.6648 - val_accuracy: 0.7094\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 368us/step - loss: 0.1967 - accuracy: 0.8963 - val_loss: 1.6826 - val_accuracy: 0.7009\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.1982 - accuracy: 0.8963 - val_loss: 1.6844 - val_accuracy: 0.6923\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.6719 - val_accuracy: 0.6923\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.6795 - val_accuracy: 0.7009\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.1983 - accuracy: 0.8926 - val_loss: 1.6696 - val_accuracy: 0.6923\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.6876 - val_accuracy: 0.7009\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2041 - accuracy: 0.8926 - val_loss: 1.6790 - val_accuracy: 0.7009\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1955 - accuracy: 0.9000 - val_loss: 1.6750 - val_accuracy: 0.7009\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.6813 - val_accuracy: 0.7009\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.1984 - accuracy: 0.8889 - val_loss: 1.6689 - val_accuracy: 0.7009\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.6743 - val_accuracy: 0.6923\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 474us/step - loss: 0.2003 - accuracy: 0.8889 - val_loss: 1.6701 - val_accuracy: 0.7094\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.6871 - val_accuracy: 0.6923\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.6916 - val_accuracy: 0.6923\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1982 - accuracy: 0.8963 - val_loss: 1.6825 - val_accuracy: 0.6923\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2007 - accuracy: 0.8926 - val_loss: 1.6753 - val_accuracy: 0.6923\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 1.6874 - val_accuracy: 0.7009\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.1986 - accuracy: 0.8963 - val_loss: 1.6892 - val_accuracy: 0.7009\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2005 - accuracy: 0.8926 - val_loss: 1.6797 - val_accuracy: 0.6923\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.1992 - accuracy: 0.8815 - val_loss: 1.6848 - val_accuracy: 0.7009\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1984 - accuracy: 0.8963 - val_loss: 1.7043 - val_accuracy: 0.7009\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.6899 - val_accuracy: 0.6923\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.6909 - val_accuracy: 0.6923\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1978 - accuracy: 0.9000 - val_loss: 1.6949 - val_accuracy: 0.6923\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2010 - accuracy: 0.8963 - val_loss: 1.6909 - val_accuracy: 0.6923\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.6834 - val_accuracy: 0.7009\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1985 - accuracy: 0.8926 - val_loss: 1.6791 - val_accuracy: 0.6923\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1985 - accuracy: 0.8963 - val_loss: 1.6937 - val_accuracy: 0.7009\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.6876 - val_accuracy: 0.7009\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1983 - accuracy: 0.8815 - val_loss: 1.6731 - val_accuracy: 0.7094\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1973 - accuracy: 0.8963 - val_loss: 1.6855 - val_accuracy: 0.7009\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.6936 - val_accuracy: 0.7009\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1994 - accuracy: 0.8889 - val_loss: 1.6854 - val_accuracy: 0.6752\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1963 - accuracy: 0.8926 - val_loss: 1.6940 - val_accuracy: 0.6923\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1968 - accuracy: 0.9000 - val_loss: 1.6884 - val_accuracy: 0.7009\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.6884 - val_accuracy: 0.7009\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1974 - accuracy: 0.8926 - val_loss: 1.6794 - val_accuracy: 0.7009\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.7016 - val_accuracy: 0.7009\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.7004 - val_accuracy: 0.7009\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.6933 - val_accuracy: 0.6923\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.1959 - accuracy: 0.9000 - val_loss: 1.7067 - val_accuracy: 0.7009\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2017 - accuracy: 0.8963 - val_loss: 1.7106 - val_accuracy: 0.7009\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2018 - accuracy: 0.8926 - val_loss: 1.6779 - val_accuracy: 0.7094\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2012 - accuracy: 0.8815 - val_loss: 1.6952 - val_accuracy: 0.7009\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.7085 - val_accuracy: 0.7009\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1974 - accuracy: 0.8963 - val_loss: 1.6861 - val_accuracy: 0.6923\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.1976 - accuracy: 0.8963 - val_loss: 1.6984 - val_accuracy: 0.7094\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.1978 - accuracy: 0.8963 - val_loss: 1.7027 - val_accuracy: 0.6923\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1968 - accuracy: 0.8889 - val_loss: 1.7012 - val_accuracy: 0.6923\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 100us/step - loss: 0.2010 - accuracy: 0.8963 - val_loss: 1.7148 - val_accuracy: 0.7094\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1990 - accuracy: 0.9000 - val_loss: 1.7014 - val_accuracy: 0.6923\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2015 - accuracy: 0.9000 - val_loss: 1.7034 - val_accuracy: 0.6923\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1967 - accuracy: 0.9000 - val_loss: 1.6962 - val_accuracy: 0.7009\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1999 - accuracy: 0.8963 - val_loss: 1.7036 - val_accuracy: 0.7009\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2008 - accuracy: 0.8963 - val_loss: 1.7005 - val_accuracy: 0.7009\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1960 - accuracy: 0.9000 - val_loss: 1.7109 - val_accuracy: 0.7009\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.7040 - val_accuracy: 0.6923\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.6988 - val_accuracy: 0.7009\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2028 - accuracy: 0.9000 - val_loss: 1.7195 - val_accuracy: 0.7009\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2002 - accuracy: 0.8963 - val_loss: 1.6901 - val_accuracy: 0.7094\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1985 - accuracy: 0.8926 - val_loss: 1.7037 - val_accuracy: 0.7009\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1974 - accuracy: 0.8963 - val_loss: 1.7111 - val_accuracy: 0.7009\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.7203 - val_accuracy: 0.6923\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1993 - accuracy: 0.8926 - val_loss: 1.6990 - val_accuracy: 0.6923\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.7213 - val_accuracy: 0.7009\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.7005 - val_accuracy: 0.7094\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2027 - accuracy: 0.8815 - val_loss: 1.7161 - val_accuracy: 0.6752\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2076 - accuracy: 0.8889 - val_loss: 1.7164 - val_accuracy: 0.7009\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1998 - accuracy: 0.8889 - val_loss: 1.6958 - val_accuracy: 0.7009\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2046 - accuracy: 0.8852 - val_loss: 1.6954 - val_accuracy: 0.6923\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1955 - accuracy: 0.8963 - val_loss: 1.7133 - val_accuracy: 0.7009\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2040 - accuracy: 0.9000 - val_loss: 1.7181 - val_accuracy: 0.7009\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.7031 - val_accuracy: 0.6923\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1965 - accuracy: 0.9000 - val_loss: 1.6957 - val_accuracy: 0.7009\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1976 - accuracy: 0.8889 - val_loss: 1.7010 - val_accuracy: 0.7009\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.7079 - val_accuracy: 0.7009\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1961 - accuracy: 0.9000 - val_loss: 1.7121 - val_accuracy: 0.7009\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.7033 - val_accuracy: 0.7009\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1954 - accuracy: 0.8963 - val_loss: 1.7023 - val_accuracy: 0.6923\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2052 - accuracy: 0.8963 - val_loss: 1.7196 - val_accuracy: 0.7009\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1976 - accuracy: 0.9037 - val_loss: 1.6911 - val_accuracy: 0.7179\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2010 - accuracy: 0.8926 - val_loss: 1.7000 - val_accuracy: 0.7179\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1966 - accuracy: 0.8963 - val_loss: 1.7222 - val_accuracy: 0.7094\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.7160 - val_accuracy: 0.6923\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1984 - accuracy: 0.8889 - val_loss: 1.7085 - val_accuracy: 0.6923\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.7107 - val_accuracy: 0.6923\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2029 - accuracy: 0.9000 - val_loss: 1.7288 - val_accuracy: 0.7009\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.7186 - val_accuracy: 0.7009\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2065 - accuracy: 0.8852 - val_loss: 1.6847 - val_accuracy: 0.7009\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2077 - accuracy: 0.8778 - val_loss: 1.7219 - val_accuracy: 0.7094\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.93 - 0s 107us/step - loss: 0.2007 - accuracy: 0.8963 - val_loss: 1.7268 - val_accuracy: 0.6838\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.1979 - accuracy: 0.9037 - val_loss: 1.7051 - val_accuracy: 0.7009\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1978 - accuracy: 0.8926 - val_loss: 1.7070 - val_accuracy: 0.7009\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.7185 - val_accuracy: 0.7009\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2000 - accuracy: 0.8963 - val_loss: 1.7179 - val_accuracy: 0.6838\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2015 - accuracy: 0.8852 - val_loss: 1.7004 - val_accuracy: 0.7094\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2033 - accuracy: 0.8926 - val_loss: 1.7138 - val_accuracy: 0.6923\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1980 - accuracy: 0.8963 - val_loss: 1.7099 - val_accuracy: 0.6923\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2009 - accuracy: 0.8926 - val_loss: 1.7117 - val_accuracy: 0.6923\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.7108 - val_accuracy: 0.6752\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2026 - accuracy: 0.8704 - val_loss: 1.7094 - val_accuracy: 0.6923\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2002 - accuracy: 0.8778 - val_loss: 1.7047 - val_accuracy: 0.6923\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2024 - accuracy: 0.8963 - val_loss: 1.7286 - val_accuracy: 0.6923\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.7060 - val_accuracy: 0.6923\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.7102 - val_accuracy: 0.6923\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.7041 - val_accuracy: 0.6923\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.7128 - val_accuracy: 0.6923\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.1965 - accuracy: 0.9000 - val_loss: 1.7174 - val_accuracy: 0.6923\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.7212 - val_accuracy: 0.6923\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2021 - accuracy: 0.8926 - val_loss: 1.7148 - val_accuracy: 0.6752\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.7045 - val_accuracy: 0.6923\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.7051 - val_accuracy: 0.7009\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.7203 - val_accuracy: 0.7009\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2004 - accuracy: 0.9000 - val_loss: 1.7095 - val_accuracy: 0.7009\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2015 - accuracy: 0.8741 - val_loss: 1.7029 - val_accuracy: 0.6923\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1974 - accuracy: 0.9000 - val_loss: 1.7282 - val_accuracy: 0.6923\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.1978 - accuracy: 0.8963 - val_loss: 1.7163 - val_accuracy: 0.7009\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2071 - accuracy: 0.9000 - val_loss: 1.7289 - val_accuracy: 0.7009\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 1.6956 - val_accuracy: 0.7094\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2015 - accuracy: 0.8926 - val_loss: 1.7021 - val_accuracy: 0.6923\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2007 - accuracy: 0.9000 - val_loss: 1.7430 - val_accuracy: 0.6923\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.7220 - val_accuracy: 0.6923\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1971 - accuracy: 0.8963 - val_loss: 1.7157 - val_accuracy: 0.6923\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.7099 - val_accuracy: 0.7009\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.7132 - val_accuracy: 0.6923\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2036 - accuracy: 0.8926 - val_loss: 1.7192 - val_accuracy: 0.6923\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1955 - accuracy: 0.8963 - val_loss: 1.7050 - val_accuracy: 0.7094\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1987 - accuracy: 0.8963 - val_loss: 1.7309 - val_accuracy: 0.6923\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.7405 - val_accuracy: 0.7009\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2019 - accuracy: 0.8963 - val_loss: 1.7380 - val_accuracy: 0.6838\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.7120 - val_accuracy: 0.7009\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1990 - accuracy: 0.8889 - val_loss: 1.7108 - val_accuracy: 0.6923\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.1997 - accuracy: 0.9000 - val_loss: 1.7267 - val_accuracy: 0.6923\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.7189 - val_accuracy: 0.6923\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.7189 - val_accuracy: 0.6923\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2006 - accuracy: 0.8963 - val_loss: 1.7120 - val_accuracy: 0.6923\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 1.7162 - val_accuracy: 0.7009\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1988 - accuracy: 0.8926 - val_loss: 1.7314 - val_accuracy: 0.7009\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.7184 - val_accuracy: 0.7009\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.7177 - val_accuracy: 0.7009\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1981 - accuracy: 0.8963 - val_loss: 1.7172 - val_accuracy: 0.7094\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1980 - accuracy: 0.8963 - val_loss: 1.7247 - val_accuracy: 0.7009\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.7173 - val_accuracy: 0.7009\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.1994 - accuracy: 0.8852 - val_loss: 1.7124 - val_accuracy: 0.6923\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1986 - accuracy: 0.8852 - val_loss: 1.7191 - val_accuracy: 0.6923\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.7195 - val_accuracy: 0.6923\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.7264 - val_accuracy: 0.6752\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2006 - accuracy: 0.8889 - val_loss: 1.7269 - val_accuracy: 0.6923\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.7240 - val_accuracy: 0.6923\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1994 - accuracy: 0.9000 - val_loss: 1.7247 - val_accuracy: 0.6752\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1967 - accuracy: 0.8963 - val_loss: 1.7130 - val_accuracy: 0.6923\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2000 - accuracy: 0.9000 - val_loss: 1.7136 - val_accuracy: 0.6923\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.7290 - val_accuracy: 0.6923\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2061 - accuracy: 0.8926 - val_loss: 1.7294 - val_accuracy: 0.6752\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2027 - accuracy: 0.8926 - val_loss: 1.7330 - val_accuracy: 0.7009\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1963 - accuracy: 0.8963 - val_loss: 1.7106 - val_accuracy: 0.7094\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.7239 - val_accuracy: 0.7094\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1956 - accuracy: 0.8963 - val_loss: 1.7284 - val_accuracy: 0.7009\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.7204 - val_accuracy: 0.6923\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.7289 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2025 - accuracy: 0.8889 - val_loss: 1.7037 - val_accuracy: 0.7094\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1954 - accuracy: 0.8889 - val_loss: 1.7267 - val_accuracy: 0.7009\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1977 - accuracy: 0.8926 - val_loss: 1.7366 - val_accuracy: 0.7009\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.7189 - val_accuracy: 0.7094\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.1956 - accuracy: 0.8963 - val_loss: 1.7253 - val_accuracy: 0.7009\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1999 - accuracy: 0.8889 - val_loss: 1.7210 - val_accuracy: 0.6752\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2034 - accuracy: 0.8963 - val_loss: 1.7294 - val_accuracy: 0.7009\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.7122 - val_accuracy: 0.7009\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2045 - accuracy: 0.8889 - val_loss: 1.7090 - val_accuracy: 0.7094\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1969 - accuracy: 0.8963 - val_loss: 1.7315 - val_accuracy: 0.7009\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1988 - accuracy: 0.8926 - val_loss: 1.7270 - val_accuracy: 0.7094\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2006 - accuracy: 0.9000 - val_loss: 1.7468 - val_accuracy: 0.7009\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.7147 - val_accuracy: 0.7179\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2008 - accuracy: 0.8926 - val_loss: 1.7078 - val_accuracy: 0.7094\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.7190 - val_accuracy: 0.7009\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1986 - accuracy: 0.8963 - val_loss: 1.7205 - val_accuracy: 0.7009\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2052 - accuracy: 0.8926 - val_loss: 1.7152 - val_accuracy: 0.6838\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2053 - accuracy: 0.9000 - val_loss: 1.7242 - val_accuracy: 0.7094\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.1999 - accuracy: 0.8963 - val_loss: 1.7155 - val_accuracy: 0.7094\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2015 - accuracy: 0.8704 - val_loss: 1.7079 - val_accuracy: 0.6752\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2004 - accuracy: 0.9037 - val_loss: 1.7306 - val_accuracy: 0.7094\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1991 - accuracy: 0.8963 - val_loss: 1.7114 - val_accuracy: 0.6923\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2000 - accuracy: 0.8852 - val_loss: 1.7118 - val_accuracy: 0.7009\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1952 - accuracy: 0.8963 - val_loss: 1.7006 - val_accuracy: 0.7094\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1988 - accuracy: 0.8815 - val_loss: 1.7091 - val_accuracy: 0.6923\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1965 - accuracy: 0.8963 - val_loss: 1.7243 - val_accuracy: 0.6838\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2002 - accuracy: 0.8889 - val_loss: 1.7228 - val_accuracy: 0.7009\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.7242 - val_accuracy: 0.7009\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1987 - accuracy: 0.8926 - val_loss: 1.6950 - val_accuracy: 0.7094\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2001 - accuracy: 0.8926 - val_loss: 1.7221 - val_accuracy: 0.6923\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.7109 - val_accuracy: 0.6923\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1977 - accuracy: 0.8963 - val_loss: 1.7169 - val_accuracy: 0.6923\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.7213 - val_accuracy: 0.6923\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1968 - accuracy: 0.9000 - val_loss: 1.7148 - val_accuracy: 0.6923\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 1.7121 - val_accuracy: 0.6923\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2009 - accuracy: 0.9000 - val_loss: 1.7254 - val_accuracy: 0.6923\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.7233 - val_accuracy: 0.6923\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1998 - accuracy: 0.8926 - val_loss: 1.7111 - val_accuracy: 0.6923\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1951 - accuracy: 0.9000 - val_loss: 1.7386 - val_accuracy: 0.6923\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2008 - accuracy: 0.9000 - val_loss: 1.7220 - val_accuracy: 0.7009\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.7335 - val_accuracy: 0.7009\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2018 - accuracy: 0.8926 - val_loss: 1.7229 - val_accuracy: 0.7009\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1982 - accuracy: 0.8963 - val_loss: 1.7188 - val_accuracy: 0.7009\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1966 - accuracy: 0.9000 - val_loss: 1.7295 - val_accuracy: 0.7009\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.7173 - val_accuracy: 0.7009\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.1995 - accuracy: 0.8963 - val_loss: 1.7037 - val_accuracy: 0.7179\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1990 - accuracy: 0.9037 - val_loss: 1.7180 - val_accuracy: 0.7009\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.7365 - val_accuracy: 0.7009\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1967 - accuracy: 0.9000 - val_loss: 1.7254 - val_accuracy: 0.7009\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2032 - accuracy: 0.8815 - val_loss: 1.7201 - val_accuracy: 0.7009\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.1968 - accuracy: 0.8963 - val_loss: 1.7461 - val_accuracy: 0.6923\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2026 - accuracy: 0.9000 - val_loss: 1.7164 - val_accuracy: 0.7094\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2013 - accuracy: 0.8926 - val_loss: 1.7199 - val_accuracy: 0.6923\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1960 - accuracy: 0.9037 - val_loss: 1.7410 - val_accuracy: 0.6838\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1993 - accuracy: 0.8963 - val_loss: 1.7389 - val_accuracy: 0.7009\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1978 - accuracy: 0.9000 - val_loss: 1.7254 - val_accuracy: 0.7009\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1963 - accuracy: 0.8963 - val_loss: 1.7203 - val_accuracy: 0.6923\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.7187 - val_accuracy: 0.6923\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1993 - accuracy: 0.8889 - val_loss: 1.7317 - val_accuracy: 0.7094\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2001 - accuracy: 0.8963 - val_loss: 1.7169 - val_accuracy: 0.6923\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.7402 - val_accuracy: 0.6923\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1974 - accuracy: 0.9000 - val_loss: 1.7273 - val_accuracy: 0.6923\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2002 - accuracy: 0.8889 - val_loss: 1.7133 - val_accuracy: 0.7094\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2004 - accuracy: 0.8852 - val_loss: 1.7293 - val_accuracy: 0.6923\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.1999 - accuracy: 0.9000 - val_loss: 1.7372 - val_accuracy: 0.6923\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2030 - accuracy: 0.8889 - val_loss: 1.7218 - val_accuracy: 0.6752\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1988 - accuracy: 0.8963 - val_loss: 1.7359 - val_accuracy: 0.7009\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.96 - 0s 104us/step - loss: 0.1997 - accuracy: 0.8852 - val_loss: 1.7219 - val_accuracy: 0.7009\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1982 - accuracy: 0.9000 - val_loss: 1.7336 - val_accuracy: 0.7009\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.7271 - val_accuracy: 0.7009\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.7221 - val_accuracy: 0.7009\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1949 - accuracy: 0.8963 - val_loss: 1.7105 - val_accuracy: 0.6923\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2007 - accuracy: 0.8889 - val_loss: 1.7109 - val_accuracy: 0.7009\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.7394 - val_accuracy: 0.7009\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2023 - accuracy: 0.9000 - val_loss: 1.7242 - val_accuracy: 0.7009\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2019 - accuracy: 0.8926 - val_loss: 1.7354 - val_accuracy: 0.7094\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1983 - accuracy: 0.8926 - val_loss: 1.7325 - val_accuracy: 0.6923\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.1963 - accuracy: 0.8963 - val_loss: 1.7268 - val_accuracy: 0.7009\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.7251 - val_accuracy: 0.7009\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1971 - accuracy: 0.9037 - val_loss: 1.7288 - val_accuracy: 0.6923\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.7297 - val_accuracy: 0.6923\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2040 - accuracy: 0.8963 - val_loss: 1.7341 - val_accuracy: 0.6923\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 1.7241 - val_accuracy: 0.6923\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2013 - accuracy: 0.8963 - val_loss: 1.7407 - val_accuracy: 0.7009\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1999 - accuracy: 0.8963 - val_loss: 1.7353 - val_accuracy: 0.6923\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1986 - accuracy: 0.8852 - val_loss: 1.7307 - val_accuracy: 0.6923\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.7512 - val_accuracy: 0.7009\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1998 - accuracy: 0.8926 - val_loss: 1.7552 - val_accuracy: 0.6923\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.7368 - val_accuracy: 0.6923\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.7285 - val_accuracy: 0.7094\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.7447 - val_accuracy: 0.7009\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.1961 - accuracy: 0.9000 - val_loss: 1.7470 - val_accuracy: 0.6923\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.7496 - val_accuracy: 0.6923\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1972 - accuracy: 0.8963 - val_loss: 1.7329 - val_accuracy: 0.7009\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1988 - accuracy: 0.9000 - val_loss: 1.7279 - val_accuracy: 0.6923\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2058 - accuracy: 0.9000 - val_loss: 1.7630 - val_accuracy: 0.6923\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2004 - accuracy: 0.8926 - val_loss: 1.7323 - val_accuracy: 0.6752\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1967 - accuracy: 0.8889 - val_loss: 1.7357 - val_accuracy: 0.6923\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.7356 - val_accuracy: 0.6923\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1976 - accuracy: 0.9000 - val_loss: 1.7436 - val_accuracy: 0.6923\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1962 - accuracy: 0.9000 - val_loss: 1.7483 - val_accuracy: 0.6923\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2040 - accuracy: 0.8852 - val_loss: 1.7284 - val_accuracy: 0.6923\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2011 - accuracy: 0.8889 - val_loss: 1.7709 - val_accuracy: 0.7094\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2025 - accuracy: 0.9000 - val_loss: 1.7458 - val_accuracy: 0.7009\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2024 - accuracy: 0.8889 - val_loss: 1.7286 - val_accuracy: 0.6923\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1994 - accuracy: 0.8963 - val_loss: 1.7539 - val_accuracy: 0.7009\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2004 - accuracy: 0.8926 - val_loss: 1.7457 - val_accuracy: 0.6923\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1957 - accuracy: 0.8963 - val_loss: 1.7477 - val_accuracy: 0.7009\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1990 - accuracy: 0.8926 - val_loss: 1.7466 - val_accuracy: 0.7009\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.7397 - val_accuracy: 0.6838\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 89us/step - loss: 0.1951 - accuracy: 0.9000 - val_loss: 1.7490 - val_accuracy: 0.6923\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.7594 - val_accuracy: 0.7009\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2005 - accuracy: 0.9037 - val_loss: 1.7722 - val_accuracy: 0.6923\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2003 - accuracy: 0.8963 - val_loss: 1.7415 - val_accuracy: 0.7094\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 1.7464 - val_accuracy: 0.6923\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2026 - accuracy: 0.9000 - val_loss: 1.7376 - val_accuracy: 0.6923\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.7526 - val_accuracy: 0.6923\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1984 - accuracy: 0.9000 - val_loss: 1.7431 - val_accuracy: 0.6923\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1965 - accuracy: 0.8963 - val_loss: 1.7385 - val_accuracy: 0.6923\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.1970 - accuracy: 0.9037 - val_loss: 1.7544 - val_accuracy: 0.7009\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.7525 - val_accuracy: 0.6923\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1996 - accuracy: 0.8963 - val_loss: 1.7601 - val_accuracy: 0.7009\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1976 - accuracy: 0.8852 - val_loss: 1.7289 - val_accuracy: 0.7094\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1999 - accuracy: 0.8852 - val_loss: 1.7416 - val_accuracy: 0.6923\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2102 - accuracy: 0.9074 - val_loss: 1.7885 - val_accuracy: 0.6838\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2084 - accuracy: 0.8926 - val_loss: 1.7393 - val_accuracy: 0.7009\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1976 - accuracy: 0.8815 - val_loss: 1.7433 - val_accuracy: 0.6752\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1984 - accuracy: 0.8926 - val_loss: 1.7503 - val_accuracy: 0.6923\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1989 - accuracy: 0.8963 - val_loss: 1.7711 - val_accuracy: 0.7009\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2008 - accuracy: 0.9000 - val_loss: 1.7480 - val_accuracy: 0.7009\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2037 - accuracy: 0.8889 - val_loss: 1.7369 - val_accuracy: 0.7009\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1965 - accuracy: 0.9074 - val_loss: 1.7679 - val_accuracy: 0.7009\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1972 - accuracy: 0.9000 - val_loss: 1.7693 - val_accuracy: 0.7009\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.1981 - accuracy: 0.9000 - val_loss: 1.7530 - val_accuracy: 0.7009\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.1996 - accuracy: 0.9037 - val_loss: 1.7541 - val_accuracy: 0.6752\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1985 - accuracy: 0.9037 - val_loss: 1.7511 - val_accuracy: 0.6923\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1989 - accuracy: 0.9000 - val_loss: 1.7483 - val_accuracy: 0.6923\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1991 - accuracy: 0.8963 - val_loss: 1.7460 - val_accuracy: 0.7009\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.7579 - val_accuracy: 0.7009\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.7516 - val_accuracy: 0.7009\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1968 - accuracy: 0.9000 - val_loss: 1.7607 - val_accuracy: 0.7009\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.7565 - val_accuracy: 0.7009\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.7499 - val_accuracy: 0.7009\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1967 - accuracy: 0.9000 - val_loss: 1.7537 - val_accuracy: 0.7009\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1972 - accuracy: 0.8963 - val_loss: 1.7564 - val_accuracy: 0.7009\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1957 - accuracy: 0.8926 - val_loss: 1.7373 - val_accuracy: 0.7094\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1998 - accuracy: 0.8778 - val_loss: 1.7505 - val_accuracy: 0.7009\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.7497 - val_accuracy: 0.6923\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1975 - accuracy: 0.9000 - val_loss: 1.7581 - val_accuracy: 0.6923\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2009 - accuracy: 0.8889 - val_loss: 1.7433 - val_accuracy: 0.6923\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.7487 - val_accuracy: 0.6923\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.1980 - accuracy: 0.8963 - val_loss: 1.7538 - val_accuracy: 0.7009\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1968 - accuracy: 0.8963 - val_loss: 1.7577 - val_accuracy: 0.7009\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1980 - accuracy: 0.9000 - val_loss: 1.7565 - val_accuracy: 0.7009\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1974 - accuracy: 0.9000 - val_loss: 1.7618 - val_accuracy: 0.7009\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1968 - accuracy: 0.9000 - val_loss: 1.7555 - val_accuracy: 0.7009\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2009 - accuracy: 0.8815 - val_loss: 1.7428 - val_accuracy: 0.6923\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2001 - accuracy: 0.8815 - val_loss: 1.7520 - val_accuracy: 0.6923\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1949 - accuracy: 0.9000 - val_loss: 1.7633 - val_accuracy: 0.6923\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2021 - accuracy: 0.8889 - val_loss: 1.7613 - val_accuracy: 0.7009\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.7674 - val_accuracy: 0.7009\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1960 - accuracy: 0.8926 - val_loss: 1.7513 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1992 - accuracy: 0.8926 - val_loss: 1.7679 - val_accuracy: 0.6923\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.7514 - val_accuracy: 0.6923\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.1979 - accuracy: 0.8852 - val_loss: 1.7503 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2010 - accuracy: 0.8889 - val_loss: 1.7504 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1964 - accuracy: 0.8963 - val_loss: 1.7708 - val_accuracy: 0.7094\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.1995 - accuracy: 0.9000 - val_loss: 1.7719 - val_accuracy: 0.7009\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.1996 - accuracy: 0.9000 - val_loss: 1.7495 - val_accuracy: 0.6923\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.7539 - val_accuracy: 0.6923\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1987 - accuracy: 0.9000 - val_loss: 1.7643 - val_accuracy: 0.6923\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1970 - accuracy: 0.9000 - val_loss: 1.7565 - val_accuracy: 0.6923\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1988 - accuracy: 0.8963 - val_loss: 1.7639 - val_accuracy: 0.7009\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1982 - accuracy: 0.8963 - val_loss: 1.7571 - val_accuracy: 0.6923\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.7648 - val_accuracy: 0.7009\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.1962 - accuracy: 0.9000 - val_loss: 1.7674 - val_accuracy: 0.7009\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.1959 - accuracy: 0.9074 - val_loss: 1.7511 - val_accuracy: 0.7094\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.1991 - accuracy: 0.8889 - val_loss: 1.7530 - val_accuracy: 0.7009\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1964 - accuracy: 0.8963 - val_loss: 1.7705 - val_accuracy: 0.6923\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1969 - accuracy: 0.9000 - val_loss: 1.7739 - val_accuracy: 0.6923\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1991 - accuracy: 0.9000 - val_loss: 1.7813 - val_accuracy: 0.6923\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.7500 - val_accuracy: 0.7094\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.1992 - accuracy: 0.8926 - val_loss: 1.7934 - val_accuracy: 0.6838\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.1992 - accuracy: 0.8926 - val_loss: 1.7724 - val_accuracy: 0.6923\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1979 - accuracy: 0.8889 - val_loss: 1.7641 - val_accuracy: 0.7179\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2004 - accuracy: 0.9037 - val_loss: 1.7916 - val_accuracy: 0.7009\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1964 - accuracy: 0.9000 - val_loss: 1.7659 - val_accuracy: 0.6923\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2005 - accuracy: 0.8926 - val_loss: 1.7504 - val_accuracy: 0.6923\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.1985 - accuracy: 0.9000 - val_loss: 1.7664 - val_accuracy: 0.7009\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.7726 - val_accuracy: 0.7009\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1973 - accuracy: 0.8963 - val_loss: 1.7525 - val_accuracy: 0.7094\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1993 - accuracy: 0.8926 - val_loss: 1.7593 - val_accuracy: 0.6923\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.7837 - val_accuracy: 0.6923\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 1.7722 - val_accuracy: 0.6923\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.1973 - accuracy: 0.9000 - val_loss: 1.7667 - val_accuracy: 0.6923\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2011 - accuracy: 0.8963 - val_loss: 1.7561 - val_accuracy: 0.7179\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2014 - accuracy: 0.8889 - val_loss: 1.7755 - val_accuracy: 0.6752\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2010 - accuracy: 0.8963 - val_loss: 1.7936 - val_accuracy: 0.7009\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.1998 - accuracy: 0.9000 - val_loss: 1.7746 - val_accuracy: 0.7009\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1972 - accuracy: 0.8926 - val_loss: 1.7625 - val_accuracy: 0.7179\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1962 - accuracy: 0.9000 - val_loss: 1.7800 - val_accuracy: 0.7009\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.1998 - accuracy: 0.8963 - val_loss: 1.7856 - val_accuracy: 0.7009\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1965 - accuracy: 0.9000 - val_loss: 1.7588 - val_accuracy: 0.7094\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.1961 - accuracy: 0.8963 - val_loss: 1.7705 - val_accuracy: 0.6923\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.7834 - val_accuracy: 0.7009\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1979 - accuracy: 0.9000 - val_loss: 1.7617 - val_accuracy: 0.6923\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2013 - accuracy: 0.8852 - val_loss: 1.7723 - val_accuracy: 0.6923\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2011 - accuracy: 0.9000 - val_loss: 1.7872 - val_accuracy: 0.7009\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 1.7867 - val_accuracy: 0.7009\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.1968 - accuracy: 0.8963 - val_loss: 1.7689 - val_accuracy: 0.6923\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1967 - accuracy: 0.8815 - val_loss: 1.7597 - val_accuracy: 0.7094\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1978 - accuracy: 0.9000 - val_loss: 1.7801 - val_accuracy: 0.7009\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1960 - accuracy: 0.8963 - val_loss: 1.7706 - val_accuracy: 0.6923\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.1992 - accuracy: 0.8963 - val_loss: 1.7698 - val_accuracy: 0.6923\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.1971 - accuracy: 0.9000 - val_loss: 1.7819 - val_accuracy: 0.6923\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.1993 - accuracy: 0.9000 - val_loss: 1.7816 - val_accuracy: 0.6752\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.1991 - accuracy: 0.8963 - val_loss: 1.7929 - val_accuracy: 0.6923\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.1990 - accuracy: 0.8852 - val_loss: 1.7674 - val_accuracy: 0.7094\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.1997 - accuracy: 0.8852 - val_loss: 1.7880 - val_accuracy: 0.6923\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2006 - accuracy: 0.8963 - val_loss: 1.7865 - val_accuracy: 0.7094\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.1973 - accuracy: 0.8963 - val_loss: 1.7696 - val_accuracy: 0.6923\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.1987 - accuracy: 0.8926 - val_loss: 1.7697 - val_accuracy: 0.6923\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 1.7737 - val_accuracy: 0.6923\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.1978 - accuracy: 0.8926 - val_loss: 1.7975 - val_accuracy: 0.7094\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.1984 - accuracy: 0.8926 - val_loss: 1.7766 - val_accuracy: 0.6923\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.1975 - accuracy: 0.8926 - val_loss: 1.7633 - val_accuracy: 0.7094\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.1990 - accuracy: 0.8963 - val_loss: 1.7896 - val_accuracy: 0.7009\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.1994 - accuracy: 0.8926 - val_loss: 1.8100 - val_accuracy: 0.7094\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2084 - accuracy: 0.8815 - val_loss: 1.7694 - val_accuracy: 0.7094\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 89.54%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.66260970e-01, 3.25575960e-02, 1.18145640e-03],\n",
       "       [3.08213550e-03, 9.96394930e-01, 5.22929600e-04],\n",
       "       [1.30788350e-02, 9.86894000e-01, 2.71778390e-05],\n",
       "       [9.99998200e-01, 1.79803540e-06, 1.84814210e-09],\n",
       "       [4.63356300e-06, 6.09485320e-02, 9.39046860e-01],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [9.99708830e-01, 1.52814060e-04, 1.38412880e-04],\n",
       "       [1.30061850e-01, 9.73072800e-02, 7.72630900e-01],\n",
       "       [3.44520700e-08, 1.09946450e-20, 1.00000000e+00],\n",
       "       [8.17404000e-03, 5.94106900e-06, 9.91820000e-01],\n",
       "       [9.99510650e-01, 2.20254270e-04, 2.69011940e-04],\n",
       "       [5.46364400e-10, 8.41722650e-04, 9.99158260e-01],\n",
       "       [1.54542230e-02, 9.84524900e-01, 2.09116440e-05],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [1.46845470e-01, 8.51896170e-01, 1.25834920e-03],\n",
       "       [4.63356300e-06, 6.09485320e-02, 9.39046860e-01],\n",
       "       [8.46771200e-05, 4.93230300e-03, 9.94982960e-01],\n",
       "       [1.78620400e-04, 5.72109100e-03, 9.94100300e-01],\n",
       "       [1.46845470e-01, 8.51896170e-01, 1.25834920e-03],\n",
       "       [7.36139670e-07, 1.23429490e-19, 9.99999300e-01],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [9.99867700e-01, 1.32281920e-04, 2.10032600e-09],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [8.73491500e-01, 1.37752500e-04, 1.26370770e-01],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [9.99985100e-01, 1.29631430e-05, 1.90295870e-06],\n",
       "       [6.44770000e-05, 1.18190680e-09, 9.99935500e-01],\n",
       "       [1.46845470e-01, 8.51896170e-01, 1.25834920e-03],\n",
       "       [8.17404000e-03, 5.94106900e-06, 9.91820000e-01],\n",
       "       [1.30061850e-01, 9.73072800e-02, 7.72630900e-01],\n",
       "       [1.07914815e-08, 5.61051200e-03, 9.94389500e-01],\n",
       "       [4.28918400e-03, 3.34006150e-03, 9.92370700e-01],\n",
       "       [6.17819900e-08, 2.09083360e-03, 9.97909100e-01],\n",
       "       [3.70978530e-02, 5.47729600e-01, 4.15172550e-01],\n",
       "       [8.42748200e-01, 1.57251550e-01, 1.82316510e-07],\n",
       "       [2.11424630e-05, 9.99758540e-01, 2.20352170e-04],\n",
       "       [9.99900000e-01, 2.11099700e-05, 7.88749460e-05],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [1.46845470e-01, 8.51896170e-01, 1.25834920e-03],\n",
       "       [4.63356300e-06, 6.09485320e-02, 9.39046860e-01],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [9.95754840e-01, 7.19403900e-07, 4.24451150e-03],\n",
       "       [1.46845470e-01, 8.51896170e-01, 1.25834920e-03],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [7.11004000e-03, 5.78915240e-01, 4.13974730e-01],\n",
       "       [1.46333030e-02, 9.81924000e-01, 3.44271500e-03],\n",
       "       [1.14295806e-04, 2.53102440e-03, 9.97354750e-01],\n",
       "       [9.66260970e-01, 3.25575960e-02, 1.18145640e-03],\n",
       "       [6.36269700e-02, 9.36373000e-01, 2.70555660e-14],\n",
       "       [1.00000000e+00, 4.92813850e-11, 6.76870150e-12],\n",
       "       [5.46364400e-10, 8.41722650e-04, 9.99158260e-01],\n",
       "       [6.00795900e-03, 9.93981060e-01, 1.08588310e-05],\n",
       "       [9.66260970e-01, 3.25575960e-02, 1.18145640e-03],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [9.66260970e-01, 3.25575960e-02, 1.18145640e-03],\n",
       "       [4.11762200e-03, 1.92327350e-04, 9.95690050e-01],\n",
       "       [4.60523500e-13, 2.33661350e-06, 9.99997600e-01],\n",
       "       [1.48222110e-04, 9.99735400e-01, 1.16296270e-04],\n",
       "       [1.16620740e-03, 9.73466160e-01, 2.53675800e-02],\n",
       "       [7.11004000e-03, 5.78915240e-01, 4.13974730e-01],\n",
       "       [4.08620570e-01, 5.91379460e-01, 6.76012900e-17],\n",
       "       [9.99999640e-01, 3.09672830e-07, 1.52666700e-09],\n",
       "       [8.18300300e-04, 6.36071460e-08, 9.99181570e-01],\n",
       "       [1.60927280e-06, 7.04514900e-02, 9.29546950e-01],\n",
       "       [6.17819900e-08, 2.09083360e-03, 9.97909100e-01],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [8.10857700e-03, 9.91670970e-01, 2.20419230e-04],\n",
       "       [1.52917400e-03, 3.81672380e-01, 6.16798460e-01],\n",
       "       [6.46707200e-12, 1.77821890e-07, 9.99999900e-01],\n",
       "       [9.82216100e-01, 1.77838540e-02, 3.67240130e-09],\n",
       "       [7.05927400e-04, 1.08706300e-09, 9.99294040e-01],\n",
       "       [9.51496240e-04, 9.81474000e-01, 1.75745770e-02],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [8.17404000e-03, 5.94106900e-06, 9.91820000e-01],\n",
       "       [1.27299080e-03, 2.76899750e-04, 9.98450040e-01],\n",
       "       [9.96309100e-01, 3.69090800e-03, 3.64842650e-13],\n",
       "       [1.23534305e-02, 9.78091800e-01, 9.55478500e-03],\n",
       "       [9.99806100e-01, 1.93972960e-04, 5.22613500e-11],\n",
       "       [7.40751150e-01, 1.32007150e-01, 1.27241700e-01],\n",
       "       [5.02238300e-01, 4.97731750e-01, 3.00050320e-05],\n",
       "       [2.11424630e-05, 9.99758540e-01, 2.20352170e-04],\n",
       "       [1.31291645e-05, 9.95346000e-01, 4.64081100e-03],\n",
       "       [7.36139670e-07, 1.23429490e-19, 9.99999300e-01],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [8.01784200e-01, 1.97857500e-01, 3.58294300e-04],\n",
       "       [1.52917400e-03, 3.81672380e-01, 6.16798460e-01],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [9.98601730e-01, 1.39827000e-03, 2.45337060e-09],\n",
       "       [9.99342400e-01, 6.51080200e-04, 6.49418870e-06],\n",
       "       [1.16620740e-03, 9.73466160e-01, 2.53675800e-02],\n",
       "       [2.97920170e-01, 7.02078800e-01, 1.10365300e-06],\n",
       "       [2.66900370e-04, 9.98170400e-01, 1.56268950e-03],\n",
       "       [5.24287460e-01, 4.75127900e-01, 5.84645100e-04],\n",
       "       [5.46364400e-10, 8.41722650e-04, 9.99158260e-01],\n",
       "       [4.63356300e-06, 6.09485320e-02, 9.39046860e-01],\n",
       "       [2.80427730e-06, 9.99742570e-01, 2.54584200e-04],\n",
       "       [1.52917400e-03, 3.81672380e-01, 6.16798460e-01],\n",
       "       [7.56385850e-05, 9.99809200e-01, 1.15108494e-04],\n",
       "       [9.99991660e-01, 2.44000060e-06, 5.95036770e-06],\n",
       "       [6.98862540e-04, 5.68120300e-03, 9.93619860e-01],\n",
       "       [9.99777140e-01, 2.22892530e-04, 3.63129830e-13],\n",
       "       [5.16118370e-02, 6.10886700e-01, 3.37501530e-01],\n",
       "       [3.44520700e-08, 1.09946450e-20, 1.00000000e+00],\n",
       "       [1.46333030e-02, 9.81924000e-01, 3.44271500e-03],\n",
       "       [1.00000000e+00, 4.68743180e-09, 1.82906100e-13],\n",
       "       [5.46364400e-10, 8.41722650e-04, 9.99158260e-01],\n",
       "       [9.53245800e-01, 9.27393900e-03, 3.74803060e-02],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [8.46771200e-05, 4.93230300e-03, 9.94982960e-01],\n",
       "       [2.50139410e-03, 5.70362600e-04, 9.96928300e-01],\n",
       "       [2.64227060e-03, 9.91499600e-01, 5.85815780e-03],\n",
       "       [9.53245800e-01, 9.27393900e-03, 3.74803060e-02],\n",
       "       [1.00678820e-02, 9.87252530e-01, 2.67953470e-03],\n",
       "       [4.78380920e-01, 5.21614400e-01, 4.74437000e-06],\n",
       "       [9.99964830e-01, 3.52133800e-05, 7.57871200e-09],\n",
       "       [1.16620740e-03, 9.73466160e-01, 2.53675800e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645627876397107"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645627876397107"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0    BCH-SA-11     2\n",
       "1       NRS161     1\n",
       "2    BCH-SA-14     2\n",
       "3    BCH-SA-11     2\n",
       "4     CFBRSa49     1\n",
       "..         ...   ...\n",
       "112     NRS064     2\n",
       "113     NRS266     2\n",
       "114     NRS222     0\n",
       "115       GA27     2\n",
       "116      GA984     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 577us/step - loss: 1.1979 - accuracy: 0.3444 - val_loss: 1.0965 - val_accuracy: 0.3419\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 1.0690 - accuracy: 0.4259 - val_loss: 1.0104 - val_accuracy: 0.5214\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.9959 - accuracy: 0.5296 - val_loss: 0.9627 - val_accuracy: 0.5983\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.9607 - accuracy: 0.5852 - val_loss: 0.9298 - val_accuracy: 0.6239\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.9278 - accuracy: 0.5852 - val_loss: 0.9057 - val_accuracy: 0.6068\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.9040 - accuracy: 0.5815 - val_loss: 0.8895 - val_accuracy: 0.6068\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.8876 - accuracy: 0.5815 - val_loss: 0.8728 - val_accuracy: 0.6068\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8711 - accuracy: 0.5926 - val_loss: 0.8585 - val_accuracy: 0.6154\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.8581 - accuracy: 0.5926 - val_loss: 0.8482 - val_accuracy: 0.6325\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8471 - accuracy: 0.6111 - val_loss: 0.8387 - val_accuracy: 0.6581\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.8353 - accuracy: 0.6111 - val_loss: 0.8282 - val_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.8243 - accuracy: 0.6296 - val_loss: 0.8201 - val_accuracy: 0.6838\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.8138 - accuracy: 0.6556 - val_loss: 0.8099 - val_accuracy: 0.6838\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.8067 - accuracy: 0.6519 - val_loss: 0.8027 - val_accuracy: 0.6752\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7974 - accuracy: 0.6630 - val_loss: 0.7984 - val_accuracy: 0.7265\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.7866 - accuracy: 0.6593 - val_loss: 0.7912 - val_accuracy: 0.6923\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7800 - accuracy: 0.6630 - val_loss: 0.7837 - val_accuracy: 0.6923\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7703 - accuracy: 0.6889 - val_loss: 0.7809 - val_accuracy: 0.7179\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7628 - accuracy: 0.6815 - val_loss: 0.7760 - val_accuracy: 0.7350\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7536 - accuracy: 0.6852 - val_loss: 0.7685 - val_accuracy: 0.7265\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.7476 - accuracy: 0.7037 - val_loss: 0.7624 - val_accuracy: 0.6923\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.7410 - accuracy: 0.7111 - val_loss: 0.7599 - val_accuracy: 0.7265\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7328 - accuracy: 0.7074 - val_loss: 0.7565 - val_accuracy: 0.7265\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7229 - accuracy: 0.7000 - val_loss: 0.7474 - val_accuracy: 0.7179\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7175 - accuracy: 0.6963 - val_loss: 0.7411 - val_accuracy: 0.7094\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7103 - accuracy: 0.7259 - val_loss: 0.7382 - val_accuracy: 0.7179\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7008 - accuracy: 0.7259 - val_loss: 0.7360 - val_accuracy: 0.7350\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.6976 - accuracy: 0.7074 - val_loss: 0.7289 - val_accuracy: 0.7265\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6856 - accuracy: 0.7333 - val_loss: 0.7344 - val_accuracy: 0.7265\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.6815 - accuracy: 0.7148 - val_loss: 0.7289 - val_accuracy: 0.7265\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6759 - accuracy: 0.7407 - val_loss: 0.7231 - val_accuracy: 0.7179\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.6693 - accuracy: 0.7444 - val_loss: 0.7207 - val_accuracy: 0.7179\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.6619 - accuracy: 0.7519 - val_loss: 0.7221 - val_accuracy: 0.7265\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.6550 - accuracy: 0.7556 - val_loss: 0.7215 - val_accuracy: 0.7350\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.6532 - accuracy: 0.7630 - val_loss: 0.7235 - val_accuracy: 0.7436\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.6455 - accuracy: 0.7667 - val_loss: 0.7155 - val_accuracy: 0.7350\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6387 - accuracy: 0.7667 - val_loss: 0.7067 - val_accuracy: 0.7350\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6346 - accuracy: 0.7630 - val_loss: 0.7050 - val_accuracy: 0.7350\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.6279 - accuracy: 0.7667 - val_loss: 0.7084 - val_accuracy: 0.7265\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6244 - accuracy: 0.7630 - val_loss: 0.7076 - val_accuracy: 0.7265\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.6194 - accuracy: 0.7667 - val_loss: 0.7023 - val_accuracy: 0.7350\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6146 - accuracy: 0.7667 - val_loss: 0.7045 - val_accuracy: 0.7350\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 315us/step - loss: 0.6070 - accuracy: 0.7667 - val_loss: 0.7023 - val_accuracy: 0.7350\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.6074 - accuracy: 0.7741 - val_loss: 0.6956 - val_accuracy: 0.7265\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5975 - accuracy: 0.7667 - val_loss: 0.6990 - val_accuracy: 0.7350\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.5935 - accuracy: 0.7741 - val_loss: 0.6943 - val_accuracy: 0.7265\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.5892 - accuracy: 0.7852 - val_loss: 0.6970 - val_accuracy: 0.7350\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.5852 - accuracy: 0.7889 - val_loss: 0.6919 - val_accuracy: 0.7350\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5821 - accuracy: 0.7815 - val_loss: 0.7036 - val_accuracy: 0.7350\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.5753 - accuracy: 0.7889 - val_loss: 0.6833 - val_accuracy: 0.7265\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.5727 - accuracy: 0.7926 - val_loss: 0.6818 - val_accuracy: 0.7179\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5691 - accuracy: 0.7889 - val_loss: 0.6922 - val_accuracy: 0.7436\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.5619 - accuracy: 0.7815 - val_loss: 0.6872 - val_accuracy: 0.7265\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5583 - accuracy: 0.7778 - val_loss: 0.6855 - val_accuracy: 0.7436\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.5565 - accuracy: 0.7889 - val_loss: 0.6773 - val_accuracy: 0.7094\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5509 - accuracy: 0.7963 - val_loss: 0.6751 - val_accuracy: 0.7350\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.5473 - accuracy: 0.7963 - val_loss: 0.6809 - val_accuracy: 0.7436\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.5490 - accuracy: 0.7852 - val_loss: 0.6789 - val_accuracy: 0.7009\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.5386 - accuracy: 0.7889 - val_loss: 0.6885 - val_accuracy: 0.7265\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.5366 - accuracy: 0.7815 - val_loss: 0.6830 - val_accuracy: 0.7009\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.5315 - accuracy: 0.7963 - val_loss: 0.6779 - val_accuracy: 0.7350\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.5300 - accuracy: 0.8111 - val_loss: 0.6803 - val_accuracy: 0.7350\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.5279 - accuracy: 0.8111 - val_loss: 0.6787 - val_accuracy: 0.7265\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.5285 - accuracy: 0.7963 - val_loss: 0.6775 - val_accuracy: 0.6923\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5226 - accuracy: 0.8111 - val_loss: 0.6817 - val_accuracy: 0.7436\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5186 - accuracy: 0.8074 - val_loss: 0.6748 - val_accuracy: 0.7350\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.5160 - accuracy: 0.8000 - val_loss: 0.6692 - val_accuracy: 0.7265\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5165 - accuracy: 0.8185 - val_loss: 0.6721 - val_accuracy: 0.7094\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.5080 - accuracy: 0.8111 - val_loss: 0.6813 - val_accuracy: 0.7350\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.5061 - accuracy: 0.8074 - val_loss: 0.6748 - val_accuracy: 0.7094\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.5022 - accuracy: 0.8074 - val_loss: 0.6711 - val_accuracy: 0.7094\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.5015 - accuracy: 0.8037 - val_loss: 0.6721 - val_accuracy: 0.7094\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.4971 - accuracy: 0.8074 - val_loss: 0.6786 - val_accuracy: 0.7521\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.4967 - accuracy: 0.8111 - val_loss: 0.6701 - val_accuracy: 0.7350\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.4967 - accuracy: 0.8111 - val_loss: 0.6675 - val_accuracy: 0.7094\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.4947 - accuracy: 0.8074 - val_loss: 0.6793 - val_accuracy: 0.7179\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4857 - accuracy: 0.8074 - val_loss: 0.6679 - val_accuracy: 0.7094\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.4881 - accuracy: 0.8148 - val_loss: 0.6699 - val_accuracy: 0.7179\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4848 - accuracy: 0.8148 - val_loss: 0.6724 - val_accuracy: 0.7094\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4813 - accuracy: 0.8111 - val_loss: 0.6657 - val_accuracy: 0.7094\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4758 - accuracy: 0.8111 - val_loss: 0.6691 - val_accuracy: 0.7094\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4774 - accuracy: 0.8111 - val_loss: 0.6705 - val_accuracy: 0.7094\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4766 - accuracy: 0.8037 - val_loss: 0.6711 - val_accuracy: 0.7094\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4726 - accuracy: 0.8074 - val_loss: 0.6704 - val_accuracy: 0.7094\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4725 - accuracy: 0.8111 - val_loss: 0.6699 - val_accuracy: 0.7094\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4657 - accuracy: 0.8185 - val_loss: 0.6750 - val_accuracy: 0.7094\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4666 - accuracy: 0.8074 - val_loss: 0.6762 - val_accuracy: 0.7179\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.4671 - accuracy: 0.8111 - val_loss: 0.6646 - val_accuracy: 0.7009\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4643 - accuracy: 0.8074 - val_loss: 0.6758 - val_accuracy: 0.7179\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.4604 - accuracy: 0.8111 - val_loss: 0.6730 - val_accuracy: 0.7094\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4593 - accuracy: 0.8222 - val_loss: 0.6695 - val_accuracy: 0.7094\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.4567 - accuracy: 0.8222 - val_loss: 0.6806 - val_accuracy: 0.7179\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4543 - accuracy: 0.8074 - val_loss: 0.6733 - val_accuracy: 0.7179\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.4515 - accuracy: 0.8222 - val_loss: 0.6652 - val_accuracy: 0.7009\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.4521 - accuracy: 0.8259 - val_loss: 0.6692 - val_accuracy: 0.7179\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.4507 - accuracy: 0.8074 - val_loss: 0.6687 - val_accuracy: 0.7094\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.4454 - accuracy: 0.8111 - val_loss: 0.6695 - val_accuracy: 0.7179\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.4445 - accuracy: 0.8222 - val_loss: 0.6677 - val_accuracy: 0.7179\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.4446 - accuracy: 0.8222 - val_loss: 0.6625 - val_accuracy: 0.7179\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.4395 - accuracy: 0.8333 - val_loss: 0.6714 - val_accuracy: 0.7094\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 287us/step - loss: 0.4445 - accuracy: 0.8037 - val_loss: 0.6865 - val_accuracy: 0.7265\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.4431 - accuracy: 0.8296 - val_loss: 0.6585 - val_accuracy: 0.7265\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.4374 - accuracy: 0.8333 - val_loss: 0.6714 - val_accuracy: 0.7179\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4343 - accuracy: 0.8296 - val_loss: 0.6661 - val_accuracy: 0.7179\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4337 - accuracy: 0.8259 - val_loss: 0.6730 - val_accuracy: 0.7179\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4302 - accuracy: 0.8333 - val_loss: 0.6685 - val_accuracy: 0.7179\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.4284 - accuracy: 0.8370 - val_loss: 0.6686 - val_accuracy: 0.7094\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.4298 - accuracy: 0.8333 - val_loss: 0.6721 - val_accuracy: 0.7179\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.4252 - accuracy: 0.8333 - val_loss: 0.6727 - val_accuracy: 0.7179\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.4248 - accuracy: 0.8407 - val_loss: 0.6669 - val_accuracy: 0.7179\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.6754 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.4206 - accuracy: 0.8333 - val_loss: 0.6684 - val_accuracy: 0.7179\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.4206 - accuracy: 0.8370 - val_loss: 0.6700 - val_accuracy: 0.7179\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.4226 - accuracy: 0.8407 - val_loss: 0.6626 - val_accuracy: 0.7265\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.4227 - accuracy: 0.8148 - val_loss: 0.6855 - val_accuracy: 0.6838\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.4176 - accuracy: 0.8333 - val_loss: 0.6629 - val_accuracy: 0.7179\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.4169 - accuracy: 0.8444 - val_loss: 0.6715 - val_accuracy: 0.7179\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4152 - accuracy: 0.8370 - val_loss: 0.6752 - val_accuracy: 0.7265\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4102 - accuracy: 0.8407 - val_loss: 0.6730 - val_accuracy: 0.7179\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.4145 - accuracy: 0.8296 - val_loss: 0.6720 - val_accuracy: 0.7179\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4090 - accuracy: 0.8370 - val_loss: 0.6836 - val_accuracy: 0.7265\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.4062 - accuracy: 0.8407 - val_loss: 0.6691 - val_accuracy: 0.7179\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4070 - accuracy: 0.8407 - val_loss: 0.6698 - val_accuracy: 0.7179\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.4046 - accuracy: 0.8296 - val_loss: 0.6708 - val_accuracy: 0.7179\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4045 - accuracy: 0.8333 - val_loss: 0.6774 - val_accuracy: 0.7265\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4071 - accuracy: 0.8407 - val_loss: 0.6650 - val_accuracy: 0.7179\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4011 - accuracy: 0.8444 - val_loss: 0.6922 - val_accuracy: 0.7265\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4049 - accuracy: 0.8222 - val_loss: 0.6861 - val_accuracy: 0.7265\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4003 - accuracy: 0.8370 - val_loss: 0.6723 - val_accuracy: 0.7179\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.4003 - accuracy: 0.8407 - val_loss: 0.6747 - val_accuracy: 0.7350\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3988 - accuracy: 0.8444 - val_loss: 0.6734 - val_accuracy: 0.7265\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3945 - accuracy: 0.8407 - val_loss: 0.6851 - val_accuracy: 0.7179\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.6754 - val_accuracy: 0.7265\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3914 - accuracy: 0.8407 - val_loss: 0.6793 - val_accuracy: 0.7350\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3916 - accuracy: 0.8444 - val_loss: 0.6783 - val_accuracy: 0.7265\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3933 - accuracy: 0.8407 - val_loss: 0.6801 - val_accuracy: 0.7265\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.3903 - accuracy: 0.8407 - val_loss: 0.6827 - val_accuracy: 0.7265\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.3890 - accuracy: 0.8259 - val_loss: 0.6857 - val_accuracy: 0.7265\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.3872 - accuracy: 0.8407 - val_loss: 0.6822 - val_accuracy: 0.7265\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.3888 - accuracy: 0.8444 - val_loss: 0.6769 - val_accuracy: 0.7265\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.3849 - accuracy: 0.8444 - val_loss: 0.6859 - val_accuracy: 0.7265\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.3829 - accuracy: 0.8407 - val_loss: 0.6745 - val_accuracy: 0.7265\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3863 - accuracy: 0.8481 - val_loss: 0.6733 - val_accuracy: 0.7265\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3826 - accuracy: 0.8444 - val_loss: 0.6864 - val_accuracy: 0.7265\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3812 - accuracy: 0.8481 - val_loss: 0.6886 - val_accuracy: 0.7265\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3791 - accuracy: 0.8370 - val_loss: 0.6941 - val_accuracy: 0.7265\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3774 - accuracy: 0.8444 - val_loss: 0.6839 - val_accuracy: 0.7350\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3840 - accuracy: 0.8444 - val_loss: 0.6788 - val_accuracy: 0.7265\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3755 - accuracy: 0.8519 - val_loss: 0.6932 - val_accuracy: 0.6838\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3848 - accuracy: 0.8407 - val_loss: 0.6899 - val_accuracy: 0.7350\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3745 - accuracy: 0.8481 - val_loss: 0.6730 - val_accuracy: 0.7265\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3777 - accuracy: 0.8481 - val_loss: 0.6794 - val_accuracy: 0.7350\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3747 - accuracy: 0.8407 - val_loss: 0.6929 - val_accuracy: 0.6923\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.3753 - accuracy: 0.8370 - val_loss: 0.6885 - val_accuracy: 0.6923\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.3730 - accuracy: 0.8370 - val_loss: 0.6745 - val_accuracy: 0.7265\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.3720 - accuracy: 0.8481 - val_loss: 0.6831 - val_accuracy: 0.7265\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.3713 - accuracy: 0.8519 - val_loss: 0.6870 - val_accuracy: 0.7265\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3703 - accuracy: 0.8481 - val_loss: 0.6848 - val_accuracy: 0.7265\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3681 - accuracy: 0.8481 - val_loss: 0.6821 - val_accuracy: 0.7265\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.3662 - accuracy: 0.8519 - val_loss: 0.6893 - val_accuracy: 0.7350\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.3653 - accuracy: 0.8556 - val_loss: 0.6878 - val_accuracy: 0.7350\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3659 - accuracy: 0.8519 - val_loss: 0.6950 - val_accuracy: 0.7350\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3654 - accuracy: 0.8556 - val_loss: 0.6872 - val_accuracy: 0.7350\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3623 - accuracy: 0.8481 - val_loss: 0.6864 - val_accuracy: 0.7350\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.3623 - accuracy: 0.8519 - val_loss: 0.6918 - val_accuracy: 0.7350\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3614 - accuracy: 0.8593 - val_loss: 0.6884 - val_accuracy: 0.7265\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3598 - accuracy: 0.8593 - val_loss: 0.6951 - val_accuracy: 0.7350\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3617 - accuracy: 0.8481 - val_loss: 0.6853 - val_accuracy: 0.7436\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.3600 - accuracy: 0.8370 - val_loss: 0.7008 - val_accuracy: 0.7350\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3585 - accuracy: 0.8556 - val_loss: 0.6901 - val_accuracy: 0.7350\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3551 - accuracy: 0.8519 - val_loss: 0.6938 - val_accuracy: 0.7350\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3557 - accuracy: 0.8556 - val_loss: 0.7035 - val_accuracy: 0.7350\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.3586 - accuracy: 0.8519 - val_loss: 0.6956 - val_accuracy: 0.7350\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3548 - accuracy: 0.8519 - val_loss: 0.6839 - val_accuracy: 0.7265\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.3552 - accuracy: 0.8556 - val_loss: 0.6934 - val_accuracy: 0.7350\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3501 - accuracy: 0.8593 - val_loss: 0.6906 - val_accuracy: 0.7350\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3527 - accuracy: 0.8556 - val_loss: 0.6973 - val_accuracy: 0.7350\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.3498 - accuracy: 0.8593 - val_loss: 0.6854 - val_accuracy: 0.7350\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3517 - accuracy: 0.8593 - val_loss: 0.6883 - val_accuracy: 0.7350\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3534 - accuracy: 0.8444 - val_loss: 0.7060 - val_accuracy: 0.6923\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3498 - accuracy: 0.8556 - val_loss: 0.6879 - val_accuracy: 0.7265\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3482 - accuracy: 0.8593 - val_loss: 0.7032 - val_accuracy: 0.7350\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3490 - accuracy: 0.8556 - val_loss: 0.7031 - val_accuracy: 0.7350\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.3455 - accuracy: 0.8593 - val_loss: 0.6984 - val_accuracy: 0.7350\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.3480 - accuracy: 0.8556 - val_loss: 0.7087 - val_accuracy: 0.7350\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3454 - accuracy: 0.8556 - val_loss: 0.7065 - val_accuracy: 0.7350\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3472 - accuracy: 0.8593 - val_loss: 0.6956 - val_accuracy: 0.7350\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.3440 - accuracy: 0.8519 - val_loss: 0.7045 - val_accuracy: 0.7350\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.3444 - accuracy: 0.8481 - val_loss: 0.6974 - val_accuracy: 0.7350\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.3430 - accuracy: 0.8519 - val_loss: 0.6943 - val_accuracy: 0.7350\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3415 - accuracy: 0.8556 - val_loss: 0.7047 - val_accuracy: 0.7350\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3434 - accuracy: 0.8556 - val_loss: 0.7044 - val_accuracy: 0.7350\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.3411 - accuracy: 0.8593 - val_loss: 0.6964 - val_accuracy: 0.7436\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.3420 - accuracy: 0.8519 - val_loss: 0.6991 - val_accuracy: 0.7350\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.3393 - accuracy: 0.8593 - val_loss: 0.6926 - val_accuracy: 0.7350\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.3388 - accuracy: 0.8593 - val_loss: 0.7068 - val_accuracy: 0.7350\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.3422 - accuracy: 0.8556 - val_loss: 0.7170 - val_accuracy: 0.7009\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.3379 - accuracy: 0.8667 - val_loss: 0.7041 - val_accuracy: 0.7350\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3397 - accuracy: 0.8630 - val_loss: 0.7064 - val_accuracy: 0.7350\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3371 - accuracy: 0.8556 - val_loss: 0.7141 - val_accuracy: 0.7009\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3365 - accuracy: 0.8556 - val_loss: 0.7018 - val_accuracy: 0.7350\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3370 - accuracy: 0.8556 - val_loss: 0.7095 - val_accuracy: 0.7350\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3358 - accuracy: 0.8519 - val_loss: 0.7131 - val_accuracy: 0.7009\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3336 - accuracy: 0.8593 - val_loss: 0.7041 - val_accuracy: 0.7350\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3348 - accuracy: 0.8593 - val_loss: 0.7089 - val_accuracy: 0.7350\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.3365 - accuracy: 0.8630 - val_loss: 0.7071 - val_accuracy: 0.7607\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3323 - accuracy: 0.8667 - val_loss: 0.7038 - val_accuracy: 0.7350\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3311 - accuracy: 0.8556 - val_loss: 0.7032 - val_accuracy: 0.7350\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.3287 - accuracy: 0.8630 - val_loss: 0.7109 - val_accuracy: 0.7350\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.3302 - accuracy: 0.8704 - val_loss: 0.7187 - val_accuracy: 0.7436\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.3284 - accuracy: 0.8667 - val_loss: 0.7008 - val_accuracy: 0.7350\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.3306 - accuracy: 0.8593 - val_loss: 0.7056 - val_accuracy: 0.7350\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3287 - accuracy: 0.8630 - val_loss: 0.7077 - val_accuracy: 0.7350\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.3317 - accuracy: 0.8556 - val_loss: 0.7177 - val_accuracy: 0.7179\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.3314 - accuracy: 0.8556 - val_loss: 0.7074 - val_accuracy: 0.7436\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.3263 - accuracy: 0.8593 - val_loss: 0.7206 - val_accuracy: 0.7607\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.3352 - accuracy: 0.8519 - val_loss: 0.7207 - val_accuracy: 0.7692\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.3237 - accuracy: 0.8630 - val_loss: 0.7061 - val_accuracy: 0.7350\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.3320 - accuracy: 0.8519 - val_loss: 0.7177 - val_accuracy: 0.7436\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.3287 - accuracy: 0.8556 - val_loss: 0.7318 - val_accuracy: 0.7436\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.3248 - accuracy: 0.8593 - val_loss: 0.7153 - val_accuracy: 0.7350\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 104us/step - loss: 0.3238 - accuracy: 0.8630 - val_loss: 0.7074 - val_accuracy: 0.7350\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3262 - accuracy: 0.8556 - val_loss: 0.7252 - val_accuracy: 0.7436\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3214 - accuracy: 0.8630 - val_loss: 0.7120 - val_accuracy: 0.7350\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3234 - accuracy: 0.8593 - val_loss: 0.7127 - val_accuracy: 0.7350\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3239 - accuracy: 0.8630 - val_loss: 0.7218 - val_accuracy: 0.7436\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3225 - accuracy: 0.8667 - val_loss: 0.7114 - val_accuracy: 0.7350\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3225 - accuracy: 0.8630 - val_loss: 0.7134 - val_accuracy: 0.7350\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3224 - accuracy: 0.8630 - val_loss: 0.7159 - val_accuracy: 0.7350\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.3221 - accuracy: 0.8704 - val_loss: 0.7351 - val_accuracy: 0.7265\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3201 - accuracy: 0.8593 - val_loss: 0.7119 - val_accuracy: 0.7350\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3180 - accuracy: 0.8667 - val_loss: 0.7232 - val_accuracy: 0.7350\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3196 - accuracy: 0.8630 - val_loss: 0.7272 - val_accuracy: 0.7436\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3194 - accuracy: 0.8667 - val_loss: 0.7158 - val_accuracy: 0.7436\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3182 - accuracy: 0.8667 - val_loss: 0.7252 - val_accuracy: 0.7436\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.3186 - accuracy: 0.8630 - val_loss: 0.7196 - val_accuracy: 0.7436\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3177 - accuracy: 0.8667 - val_loss: 0.7118 - val_accuracy: 0.7265\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3182 - accuracy: 0.8630 - val_loss: 0.7154 - val_accuracy: 0.7692\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3151 - accuracy: 0.8667 - val_loss: 0.7287 - val_accuracy: 0.7692\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3148 - accuracy: 0.8704 - val_loss: 0.7256 - val_accuracy: 0.7692\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3130 - accuracy: 0.8704 - val_loss: 0.7290 - val_accuracy: 0.7692\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3130 - accuracy: 0.8630 - val_loss: 0.7227 - val_accuracy: 0.7350\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3134 - accuracy: 0.8630 - val_loss: 0.7301 - val_accuracy: 0.7436\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3131 - accuracy: 0.8667 - val_loss: 0.7260 - val_accuracy: 0.7436\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3120 - accuracy: 0.8667 - val_loss: 0.7274 - val_accuracy: 0.7436\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3147 - accuracy: 0.8704 - val_loss: 0.7351 - val_accuracy: 0.7692\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3111 - accuracy: 0.8630 - val_loss: 0.7206 - val_accuracy: 0.7778\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.3154 - accuracy: 0.8704 - val_loss: 0.7198 - val_accuracy: 0.7692\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 400us/step - loss: 0.3119 - accuracy: 0.8704 - val_loss: 0.7244 - val_accuracy: 0.7692\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3119 - accuracy: 0.8704 - val_loss: 0.7215 - val_accuracy: 0.7692\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3125 - accuracy: 0.8704 - val_loss: 0.7262 - val_accuracy: 0.7778\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3155 - accuracy: 0.8630 - val_loss: 0.7404 - val_accuracy: 0.7692\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3136 - accuracy: 0.8704 - val_loss: 0.7286 - val_accuracy: 0.7265\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3173 - accuracy: 0.8556 - val_loss: 0.7204 - val_accuracy: 0.7436\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3139 - accuracy: 0.8593 - val_loss: 0.7335 - val_accuracy: 0.7692\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3081 - accuracy: 0.8667 - val_loss: 0.7270 - val_accuracy: 0.7863\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3127 - accuracy: 0.8667 - val_loss: 0.7226 - val_accuracy: 0.7607\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3214 - accuracy: 0.8519 - val_loss: 0.7418 - val_accuracy: 0.7350\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3101 - accuracy: 0.8704 - val_loss: 0.7198 - val_accuracy: 0.7350\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3137 - accuracy: 0.8667 - val_loss: 0.7375 - val_accuracy: 0.7692\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3065 - accuracy: 0.8704 - val_loss: 0.7225 - val_accuracy: 0.7692\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3070 - accuracy: 0.8667 - val_loss: 0.7296 - val_accuracy: 0.7521\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3057 - accuracy: 0.8630 - val_loss: 0.7482 - val_accuracy: 0.7692\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3060 - accuracy: 0.8630 - val_loss: 0.7408 - val_accuracy: 0.7436\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3045 - accuracy: 0.8741 - val_loss: 0.7300 - val_accuracy: 0.7692\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3058 - accuracy: 0.8741 - val_loss: 0.7439 - val_accuracy: 0.7778\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3028 - accuracy: 0.8667 - val_loss: 0.7324 - val_accuracy: 0.7436\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3053 - accuracy: 0.8667 - val_loss: 0.7328 - val_accuracy: 0.7692\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3041 - accuracy: 0.8704 - val_loss: 0.7354 - val_accuracy: 0.7692\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3078 - accuracy: 0.8704 - val_loss: 0.7292 - val_accuracy: 0.7778\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3006 - accuracy: 0.8741 - val_loss: 0.7299 - val_accuracy: 0.7692\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3042 - accuracy: 0.8741 - val_loss: 0.7366 - val_accuracy: 0.7692\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3030 - accuracy: 0.8704 - val_loss: 0.7409 - val_accuracy: 0.7692\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3039 - accuracy: 0.8704 - val_loss: 0.7357 - val_accuracy: 0.7863\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3069 - accuracy: 0.8667 - val_loss: 0.7429 - val_accuracy: 0.7778\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3028 - accuracy: 0.8704 - val_loss: 0.7361 - val_accuracy: 0.7436\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3027 - accuracy: 0.8704 - val_loss: 0.7393 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3006 - accuracy: 0.8667 - val_loss: 0.7434 - val_accuracy: 0.7778\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2997 - accuracy: 0.8667 - val_loss: 0.7456 - val_accuracy: 0.7521\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3006 - accuracy: 0.8704 - val_loss: 0.7374 - val_accuracy: 0.7692\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3008 - accuracy: 0.8667 - val_loss: 0.7380 - val_accuracy: 0.7778\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2987 - accuracy: 0.8704 - val_loss: 0.7538 - val_accuracy: 0.7692\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3003 - accuracy: 0.8741 - val_loss: 0.7469 - val_accuracy: 0.7692\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2974 - accuracy: 0.8667 - val_loss: 0.7564 - val_accuracy: 0.7863\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3007 - accuracy: 0.8519 - val_loss: 0.7438 - val_accuracy: 0.7521\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2948 - accuracy: 0.8667 - val_loss: 0.7531 - val_accuracy: 0.7521\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2987 - accuracy: 0.8778 - val_loss: 0.7455 - val_accuracy: 0.7692\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2964 - accuracy: 0.8704 - val_loss: 0.7484 - val_accuracy: 0.7778\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2971 - accuracy: 0.8667 - val_loss: 0.7433 - val_accuracy: 0.7778\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2963 - accuracy: 0.8741 - val_loss: 0.7395 - val_accuracy: 0.7692\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2981 - accuracy: 0.8778 - val_loss: 0.7489 - val_accuracy: 0.7692\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3028 - accuracy: 0.8630 - val_loss: 0.7408 - val_accuracy: 0.7692\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2957 - accuracy: 0.8667 - val_loss: 0.7604 - val_accuracy: 0.7778\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2949 - accuracy: 0.8704 - val_loss: 0.7483 - val_accuracy: 0.7778\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2956 - accuracy: 0.8741 - val_loss: 0.7463 - val_accuracy: 0.7778\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2938 - accuracy: 0.8741 - val_loss: 0.7513 - val_accuracy: 0.7521\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2955 - accuracy: 0.8667 - val_loss: 0.7551 - val_accuracy: 0.7863\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2995 - accuracy: 0.8704 - val_loss: 0.7571 - val_accuracy: 0.7436\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2924 - accuracy: 0.8704 - val_loss: 0.7455 - val_accuracy: 0.7778\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2952 - accuracy: 0.8630 - val_loss: 0.7378 - val_accuracy: 0.7607\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2923 - accuracy: 0.8593 - val_loss: 0.7645 - val_accuracy: 0.7436\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2986 - accuracy: 0.8667 - val_loss: 0.7603 - val_accuracy: 0.7778\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2971 - accuracy: 0.8630 - val_loss: 0.7373 - val_accuracy: 0.7436\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2973 - accuracy: 0.8667 - val_loss: 0.7626 - val_accuracy: 0.7265\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2954 - accuracy: 0.8481 - val_loss: 0.7632 - val_accuracy: 0.7778\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2931 - accuracy: 0.8630 - val_loss: 0.7590 - val_accuracy: 0.7521\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.2908 - accuracy: 0.8704 - val_loss: 0.7646 - val_accuracy: 0.7778\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2915 - accuracy: 0.8741 - val_loss: 0.7605 - val_accuracy: 0.7778\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2892 - accuracy: 0.8741 - val_loss: 0.7465 - val_accuracy: 0.7778\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2893 - accuracy: 0.8741 - val_loss: 0.7518 - val_accuracy: 0.7863\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2893 - accuracy: 0.8667 - val_loss: 0.7573 - val_accuracy: 0.7778\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2884 - accuracy: 0.8704 - val_loss: 0.7625 - val_accuracy: 0.7778\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2928 - accuracy: 0.8667 - val_loss: 0.7568 - val_accuracy: 0.7778\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2922 - accuracy: 0.8704 - val_loss: 0.7801 - val_accuracy: 0.7179\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2900 - accuracy: 0.8778 - val_loss: 0.7597 - val_accuracy: 0.7778\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2877 - accuracy: 0.8741 - val_loss: 0.7630 - val_accuracy: 0.7778\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2883 - accuracy: 0.8741 - val_loss: 0.7654 - val_accuracy: 0.7778\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2944 - accuracy: 0.8741 - val_loss: 0.7519 - val_accuracy: 0.7778\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2877 - accuracy: 0.8704 - val_loss: 0.7641 - val_accuracy: 0.7607\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2891 - accuracy: 0.8704 - val_loss: 0.7656 - val_accuracy: 0.7521\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2888 - accuracy: 0.8667 - val_loss: 0.7692 - val_accuracy: 0.7863\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2858 - accuracy: 0.8741 - val_loss: 0.7572 - val_accuracy: 0.7778\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2851 - accuracy: 0.8741 - val_loss: 0.7710 - val_accuracy: 0.7521\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2859 - accuracy: 0.8778 - val_loss: 0.7759 - val_accuracy: 0.7863\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2851 - accuracy: 0.8815 - val_loss: 0.7608 - val_accuracy: 0.7778\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2853 - accuracy: 0.8741 - val_loss: 0.7578 - val_accuracy: 0.7778\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2843 - accuracy: 0.8778 - val_loss: 0.7620 - val_accuracy: 0.7778\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2852 - accuracy: 0.8741 - val_loss: 0.7688 - val_accuracy: 0.7607\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2917 - accuracy: 0.8667 - val_loss: 0.7612 - val_accuracy: 0.7778\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2860 - accuracy: 0.8704 - val_loss: 0.7764 - val_accuracy: 0.7863\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2894 - accuracy: 0.8667 - val_loss: 0.7797 - val_accuracy: 0.7521\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2831 - accuracy: 0.8778 - val_loss: 0.7605 - val_accuracy: 0.7778\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2866 - accuracy: 0.8741 - val_loss: 0.7601 - val_accuracy: 0.7863\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2836 - accuracy: 0.8704 - val_loss: 0.7632 - val_accuracy: 0.7778\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2865 - accuracy: 0.8741 - val_loss: 0.7600 - val_accuracy: 0.7778\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2892 - accuracy: 0.8741 - val_loss: 0.7962 - val_accuracy: 0.7179\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2851 - accuracy: 0.8815 - val_loss: 0.7617 - val_accuracy: 0.7778\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2883 - accuracy: 0.8704 - val_loss: 0.7721 - val_accuracy: 0.7778\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2820 - accuracy: 0.8778 - val_loss: 0.7816 - val_accuracy: 0.7521\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2893 - accuracy: 0.8630 - val_loss: 0.7631 - val_accuracy: 0.7778\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2835 - accuracy: 0.8741 - val_loss: 0.7805 - val_accuracy: 0.7778\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2815 - accuracy: 0.8778 - val_loss: 0.7716 - val_accuracy: 0.7778\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2841 - accuracy: 0.8741 - val_loss: 0.7803 - val_accuracy: 0.7778\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2890 - accuracy: 0.8593 - val_loss: 0.7680 - val_accuracy: 0.7692\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2851 - accuracy: 0.8741 - val_loss: 0.7909 - val_accuracy: 0.7863\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2814 - accuracy: 0.8778 - val_loss: 0.7793 - val_accuracy: 0.7778\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2805 - accuracy: 0.8778 - val_loss: 0.7781 - val_accuracy: 0.7778\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2803 - accuracy: 0.8741 - val_loss: 0.7733 - val_accuracy: 0.7778\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2833 - accuracy: 0.8704 - val_loss: 0.7853 - val_accuracy: 0.7863\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2811 - accuracy: 0.8741 - val_loss: 0.7695 - val_accuracy: 0.7692\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2836 - accuracy: 0.8741 - val_loss: 0.7863 - val_accuracy: 0.7778\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2808 - accuracy: 0.8778 - val_loss: 0.7786 - val_accuracy: 0.7778\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2861 - accuracy: 0.8778 - val_loss: 0.7909 - val_accuracy: 0.7778\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2802 - accuracy: 0.8778 - val_loss: 0.7748 - val_accuracy: 0.7692\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2819 - accuracy: 0.8741 - val_loss: 0.7882 - val_accuracy: 0.7778\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2801 - accuracy: 0.8741 - val_loss: 0.7918 - val_accuracy: 0.7521\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2826 - accuracy: 0.8778 - val_loss: 0.7783 - val_accuracy: 0.7692\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2768 - accuracy: 0.8778 - val_loss: 0.7894 - val_accuracy: 0.7778\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2811 - accuracy: 0.8667 - val_loss: 0.7929 - val_accuracy: 0.7863\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2772 - accuracy: 0.8630 - val_loss: 0.7705 - val_accuracy: 0.8034\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2817 - accuracy: 0.8630 - val_loss: 0.7866 - val_accuracy: 0.7521\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2775 - accuracy: 0.8704 - val_loss: 0.7865 - val_accuracy: 0.7778\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2788 - accuracy: 0.8704 - val_loss: 0.7853 - val_accuracy: 0.7778\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2793 - accuracy: 0.8704 - val_loss: 0.7749 - val_accuracy: 0.7692\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2828 - accuracy: 0.8741 - val_loss: 0.8019 - val_accuracy: 0.7521\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2824 - accuracy: 0.8741 - val_loss: 0.7812 - val_accuracy: 0.7778\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2796 - accuracy: 0.8667 - val_loss: 0.7767 - val_accuracy: 0.7692\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2810 - accuracy: 0.8667 - val_loss: 0.8131 - val_accuracy: 0.7436\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2776 - accuracy: 0.8778 - val_loss: 0.7851 - val_accuracy: 0.7778\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2839 - accuracy: 0.8667 - val_loss: 0.7801 - val_accuracy: 0.7778\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2821 - accuracy: 0.8667 - val_loss: 0.8100 - val_accuracy: 0.7607\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2780 - accuracy: 0.8778 - val_loss: 0.7831 - val_accuracy: 0.7692\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2740 - accuracy: 0.8778 - val_loss: 0.7850 - val_accuracy: 0.7778\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2745 - accuracy: 0.8778 - val_loss: 0.7989 - val_accuracy: 0.7778\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2752 - accuracy: 0.8778 - val_loss: 0.7859 - val_accuracy: 0.7778\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2771 - accuracy: 0.8741 - val_loss: 0.7873 - val_accuracy: 0.7778\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2723 - accuracy: 0.8778 - val_loss: 0.7959 - val_accuracy: 0.7778\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2762 - accuracy: 0.8778 - val_loss: 0.8006 - val_accuracy: 0.7778\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2723 - accuracy: 0.8778 - val_loss: 0.7944 - val_accuracy: 0.7692\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2774 - accuracy: 0.8741 - val_loss: 0.7909 - val_accuracy: 0.7692\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2743 - accuracy: 0.8778 - val_loss: 0.8052 - val_accuracy: 0.7521\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2723 - accuracy: 0.8778 - val_loss: 0.7997 - val_accuracy: 0.7778\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2748 - accuracy: 0.8741 - val_loss: 0.7923 - val_accuracy: 0.7436\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2762 - accuracy: 0.8704 - val_loss: 0.7963 - val_accuracy: 0.7778\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2719 - accuracy: 0.8778 - val_loss: 0.8034 - val_accuracy: 0.7778\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2754 - accuracy: 0.8704 - val_loss: 0.7901 - val_accuracy: 0.7692\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2734 - accuracy: 0.8741 - val_loss: 0.7963 - val_accuracy: 0.7778\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2720 - accuracy: 0.8704 - val_loss: 0.8002 - val_accuracy: 0.7521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2729 - accuracy: 0.8741 - val_loss: 0.7961 - val_accuracy: 0.7778\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2726 - accuracy: 0.8778 - val_loss: 0.7987 - val_accuracy: 0.7778\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2795 - accuracy: 0.8741 - val_loss: 0.7865 - val_accuracy: 0.7778\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2737 - accuracy: 0.8667 - val_loss: 0.8113 - val_accuracy: 0.7521\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2765 - accuracy: 0.8741 - val_loss: 0.7921 - val_accuracy: 0.7778\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2734 - accuracy: 0.8778 - val_loss: 0.7904 - val_accuracy: 0.7692\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2743 - accuracy: 0.8741 - val_loss: 0.7965 - val_accuracy: 0.7778\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2723 - accuracy: 0.8778 - val_loss: 0.8026 - val_accuracy: 0.7778\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2754 - accuracy: 0.8778 - val_loss: 0.7956 - val_accuracy: 0.7778\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2730 - accuracy: 0.8778 - val_loss: 0.7917 - val_accuracy: 0.7692\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2718 - accuracy: 0.8704 - val_loss: 0.7996 - val_accuracy: 0.7778\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2851 - accuracy: 0.8667 - val_loss: 0.8259 - val_accuracy: 0.7521\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2701 - accuracy: 0.8741 - val_loss: 0.7966 - val_accuracy: 0.7692\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2800 - accuracy: 0.8741 - val_loss: 0.7975 - val_accuracy: 0.7692\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2679 - accuracy: 0.8778 - val_loss: 0.8128 - val_accuracy: 0.7521\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2783 - accuracy: 0.8630 - val_loss: 0.8091 - val_accuracy: 0.7436\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2765 - accuracy: 0.8667 - val_loss: 0.7984 - val_accuracy: 0.7778\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2737 - accuracy: 0.8704 - val_loss: 0.8086 - val_accuracy: 0.7521\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2712 - accuracy: 0.8741 - val_loss: 0.8101 - val_accuracy: 0.7778\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2731 - accuracy: 0.8593 - val_loss: 0.7966 - val_accuracy: 0.7692\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2705 - accuracy: 0.8778 - val_loss: 0.8223 - val_accuracy: 0.7778\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.8004 - val_accuracy: 0.7692\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2713 - accuracy: 0.8778 - val_loss: 0.7993 - val_accuracy: 0.7692\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2738 - accuracy: 0.8741 - val_loss: 0.8106 - val_accuracy: 0.7778\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2772 - accuracy: 0.8704 - val_loss: 0.8256 - val_accuracy: 0.7521\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2743 - accuracy: 0.8704 - val_loss: 0.8089 - val_accuracy: 0.7778\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2704 - accuracy: 0.8741 - val_loss: 0.7987 - val_accuracy: 0.7692\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2732 - accuracy: 0.8778 - val_loss: 0.8143 - val_accuracy: 0.7521\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.8026 - val_accuracy: 0.7778\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2690 - accuracy: 0.8778 - val_loss: 0.8061 - val_accuracy: 0.7692\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2678 - accuracy: 0.8704 - val_loss: 0.8089 - val_accuracy: 0.7778\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2702 - accuracy: 0.8778 - val_loss: 0.8150 - val_accuracy: 0.7521\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2702 - accuracy: 0.8667 - val_loss: 0.7996 - val_accuracy: 0.7692\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 848us/step - loss: 0.2667 - accuracy: 0.8778 - val_loss: 0.8198 - val_accuracy: 0.7692\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2718 - accuracy: 0.8704 - val_loss: 0.8307 - val_accuracy: 0.7521\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2700 - accuracy: 0.8741 - val_loss: 0.8188 - val_accuracy: 0.7778\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2679 - accuracy: 0.8778 - val_loss: 0.8099 - val_accuracy: 0.7692\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 800us/step - loss: 0.2708 - accuracy: 0.8741 - val_loss: 0.8160 - val_accuracy: 0.7436\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2687 - accuracy: 0.8778 - val_loss: 0.8277 - val_accuracy: 0.7778\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2697 - accuracy: 0.8778 - val_loss: 0.8148 - val_accuracy: 0.7692\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2675 - accuracy: 0.8778 - val_loss: 0.8148 - val_accuracy: 0.7778\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2666 - accuracy: 0.8778 - val_loss: 0.8171 - val_accuracy: 0.7778\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.2714 - accuracy: 0.8704 - val_loss: 0.8065 - val_accuracy: 0.7692\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2657 - accuracy: 0.8815 - val_loss: 0.8207 - val_accuracy: 0.7521\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2675 - accuracy: 0.8778 - val_loss: 0.8180 - val_accuracy: 0.7778\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2685 - accuracy: 0.8778 - val_loss: 0.8293 - val_accuracy: 0.7778\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2715 - accuracy: 0.8630 - val_loss: 0.8284 - val_accuracy: 0.7778\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2687 - accuracy: 0.8741 - val_loss: 0.8173 - val_accuracy: 0.7692\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2659 - accuracy: 0.8778 - val_loss: 0.8224 - val_accuracy: 0.7692\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2674 - accuracy: 0.8778 - val_loss: 0.8123 - val_accuracy: 0.7692\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2691 - accuracy: 0.8778 - val_loss: 0.8307 - val_accuracy: 0.7778\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2676 - accuracy: 0.8778 - val_loss: 0.8194 - val_accuracy: 0.7692\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2662 - accuracy: 0.8778 - val_loss: 0.8197 - val_accuracy: 0.7436\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2673 - accuracy: 0.8704 - val_loss: 0.8225 - val_accuracy: 0.7692\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2717 - accuracy: 0.8778 - val_loss: 0.8188 - val_accuracy: 0.7692\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2691 - accuracy: 0.8778 - val_loss: 0.8277 - val_accuracy: 0.7692\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2678 - accuracy: 0.8778 - val_loss: 0.8260 - val_accuracy: 0.7436\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 241us/step - loss: 0.2691 - accuracy: 0.8593 - val_loss: 0.8264 - val_accuracy: 0.7692\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2617 - accuracy: 0.8778 - val_loss: 0.8217 - val_accuracy: 0.7692\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2670 - accuracy: 0.8741 - val_loss: 0.8317 - val_accuracy: 0.7436\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2697 - accuracy: 0.8778 - val_loss: 0.8279 - val_accuracy: 0.7778\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2648 - accuracy: 0.8778 - val_loss: 0.8208 - val_accuracy: 0.7692\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2654 - accuracy: 0.8778 - val_loss: 0.8182 - val_accuracy: 0.7692\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2662 - accuracy: 0.8778 - val_loss: 0.8317 - val_accuracy: 0.7692\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2625 - accuracy: 0.8778 - val_loss: 0.8241 - val_accuracy: 0.7436\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2652 - accuracy: 0.8741 - val_loss: 0.8236 - val_accuracy: 0.7692\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2640 - accuracy: 0.8741 - val_loss: 0.8437 - val_accuracy: 0.7350\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2700 - accuracy: 0.8667 - val_loss: 0.8481 - val_accuracy: 0.7094\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2648 - accuracy: 0.8778 - val_loss: 0.8225 - val_accuracy: 0.7692\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2657 - accuracy: 0.8741 - val_loss: 0.8307 - val_accuracy: 0.7692\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2616 - accuracy: 0.8778 - val_loss: 0.8420 - val_accuracy: 0.7692\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2649 - accuracy: 0.8741 - val_loss: 0.8325 - val_accuracy: 0.7436\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2647 - accuracy: 0.8778 - val_loss: 0.8277 - val_accuracy: 0.7692\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 0.8439 - val_accuracy: 0.7692\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 0.8371 - val_accuracy: 0.7692\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2644 - accuracy: 0.8741 - val_loss: 0.8396 - val_accuracy: 0.7436\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2646 - accuracy: 0.8704 - val_loss: 0.8425 - val_accuracy: 0.7436\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2676 - accuracy: 0.8778 - val_loss: 0.8274 - val_accuracy: 0.7692\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2635 - accuracy: 0.8778 - val_loss: 0.8479 - val_accuracy: 0.7436\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2653 - accuracy: 0.8815 - val_loss: 0.8493 - val_accuracy: 0.7692\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 0.8387 - val_accuracy: 0.7692\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2708 - accuracy: 0.8704 - val_loss: 0.8273 - val_accuracy: 0.7692\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2662 - accuracy: 0.8778 - val_loss: 0.8604 - val_accuracy: 0.7521\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2626 - accuracy: 0.8778 - val_loss: 0.8354 - val_accuracy: 0.7692\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2614 - accuracy: 0.8741 - val_loss: 0.8460 - val_accuracy: 0.7692\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2621 - accuracy: 0.8778 - val_loss: 0.8424 - val_accuracy: 0.7692\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2613 - accuracy: 0.8778 - val_loss: 0.8505 - val_accuracy: 0.7692\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2603 - accuracy: 0.8778 - val_loss: 0.8369 - val_accuracy: 0.7692\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2635 - accuracy: 0.8778 - val_loss: 0.8422 - val_accuracy: 0.7436\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2610 - accuracy: 0.8778 - val_loss: 0.8332 - val_accuracy: 0.7692\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2754 - accuracy: 0.8630 - val_loss: 0.8291 - val_accuracy: 0.7778\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2680 - accuracy: 0.8407 - val_loss: 0.8823 - val_accuracy: 0.6923\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2688 - accuracy: 0.8556 - val_loss: 0.8398 - val_accuracy: 0.7692\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2646 - accuracy: 0.8778 - val_loss: 0.8362 - val_accuracy: 0.7692\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2661 - accuracy: 0.8778 - val_loss: 0.8579 - val_accuracy: 0.7436\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2689 - accuracy: 0.8704 - val_loss: 0.8409 - val_accuracy: 0.7692\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2595 - accuracy: 0.8667 - val_loss: 0.8516 - val_accuracy: 0.7692\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2655 - accuracy: 0.8704 - val_loss: 0.8541 - val_accuracy: 0.7436\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2690 - accuracy: 0.8593 - val_loss: 0.8463 - val_accuracy: 0.7692\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2649 - accuracy: 0.8704 - val_loss: 0.8524 - val_accuracy: 0.7436\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2632 - accuracy: 0.8778 - val_loss: 0.8364 - val_accuracy: 0.7692\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2601 - accuracy: 0.8778 - val_loss: 0.8581 - val_accuracy: 0.7692\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 0.8582 - val_accuracy: 0.7692\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2604 - accuracy: 0.8778 - val_loss: 0.8559 - val_accuracy: 0.7692\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2607 - accuracy: 0.8778 - val_loss: 0.8538 - val_accuracy: 0.7692\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2589 - accuracy: 0.8741 - val_loss: 0.8505 - val_accuracy: 0.7692\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 0.8443 - val_accuracy: 0.7692\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2610 - accuracy: 0.8778 - val_loss: 0.8509 - val_accuracy: 0.7436\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2610 - accuracy: 0.8778 - val_loss: 0.8457 - val_accuracy: 0.7692\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2595 - accuracy: 0.8778 - val_loss: 0.8499 - val_accuracy: 0.7692\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 105us/step - loss: 0.2598 - accuracy: 0.8778 - val_loss: 0.8454 - val_accuracy: 0.7692\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2604 - accuracy: 0.8778 - val_loss: 0.8594 - val_accuracy: 0.7692\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2596 - accuracy: 0.8778 - val_loss: 0.8560 - val_accuracy: 0.7692\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2582 - accuracy: 0.8778 - val_loss: 0.8606 - val_accuracy: 0.7692\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2603 - accuracy: 0.8778 - val_loss: 0.8550 - val_accuracy: 0.7692\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2591 - accuracy: 0.8741 - val_loss: 0.8550 - val_accuracy: 0.7692\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2697 - accuracy: 0.8630 - val_loss: 0.8701 - val_accuracy: 0.7692\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2587 - accuracy: 0.8778 - val_loss: 0.8399 - val_accuracy: 0.7692\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2643 - accuracy: 0.8741 - val_loss: 0.8413 - val_accuracy: 0.7692\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 0.8613 - val_accuracy: 0.7436\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 0.8400 - val_accuracy: 0.7692\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2600 - accuracy: 0.8704 - val_loss: 0.8437 - val_accuracy: 0.7692\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2589 - accuracy: 0.8778 - val_loss: 0.8492 - val_accuracy: 0.7692\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2578 - accuracy: 0.8778 - val_loss: 0.8556 - val_accuracy: 0.7692\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2590 - accuracy: 0.8778 - val_loss: 0.8548 - val_accuracy: 0.7436\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2590 - accuracy: 0.8741 - val_loss: 0.8569 - val_accuracy: 0.7692\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2587 - accuracy: 0.8778 - val_loss: 0.8472 - val_accuracy: 0.7692\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2594 - accuracy: 0.8778 - val_loss: 0.8513 - val_accuracy: 0.7692\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2571 - accuracy: 0.8778 - val_loss: 0.8578 - val_accuracy: 0.7692\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 0.8562 - val_accuracy: 0.7692\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.8490 - val_accuracy: 0.7692\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2592 - accuracy: 0.8778 - val_loss: 0.8475 - val_accuracy: 0.7692\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2616 - accuracy: 0.8778 - val_loss: 0.8665 - val_accuracy: 0.7692\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2647 - accuracy: 0.8778 - val_loss: 0.8597 - val_accuracy: 0.7436\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2611 - accuracy: 0.8741 - val_loss: 0.8540 - val_accuracy: 0.7692\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2582 - accuracy: 0.8778 - val_loss: 0.8540 - val_accuracy: 0.7692\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2582 - accuracy: 0.8667 - val_loss: 0.8581 - val_accuracy: 0.7692\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2596 - accuracy: 0.8741 - val_loss: 0.8630 - val_accuracy: 0.7692\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2590 - accuracy: 0.8741 - val_loss: 0.8617 - val_accuracy: 0.7436\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2603 - accuracy: 0.8741 - val_loss: 0.8658 - val_accuracy: 0.7436\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2573 - accuracy: 0.8778 - val_loss: 0.8517 - val_accuracy: 0.7692\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2599 - accuracy: 0.8778 - val_loss: 0.8680 - val_accuracy: 0.7692\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2582 - accuracy: 0.8778 - val_loss: 0.8572 - val_accuracy: 0.7692\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2590 - accuracy: 0.8778 - val_loss: 0.8730 - val_accuracy: 0.7436\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2580 - accuracy: 0.8778 - val_loss: 0.8605 - val_accuracy: 0.7692\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.8674 - val_accuracy: 0.7692\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2599 - accuracy: 0.8741 - val_loss: 0.8797 - val_accuracy: 0.7692\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2567 - accuracy: 0.8778 - val_loss: 0.8662 - val_accuracy: 0.7436\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2632 - accuracy: 0.8593 - val_loss: 0.8607 - val_accuracy: 0.7692\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2555 - accuracy: 0.8778 - val_loss: 0.8800 - val_accuracy: 0.7436\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2588 - accuracy: 0.8778 - val_loss: 0.8718 - val_accuracy: 0.7692\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 0.8657 - val_accuracy: 0.7436\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2577 - accuracy: 0.8778 - val_loss: 0.8648 - val_accuracy: 0.7692\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2561 - accuracy: 0.8778 - val_loss: 0.8638 - val_accuracy: 0.7436\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2569 - accuracy: 0.8778 - val_loss: 0.8665 - val_accuracy: 0.7692\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2557 - accuracy: 0.8778 - val_loss: 0.8685 - val_accuracy: 0.7692\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2558 - accuracy: 0.8778 - val_loss: 0.8641 - val_accuracy: 0.7692\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 0.8723 - val_accuracy: 0.7436\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 0.8617 - val_accuracy: 0.7692\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2543 - accuracy: 0.8778 - val_loss: 0.8732 - val_accuracy: 0.7692\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2620 - accuracy: 0.8778 - val_loss: 0.8789 - val_accuracy: 0.7436\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2597 - accuracy: 0.8815 - val_loss: 0.8584 - val_accuracy: 0.7692\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2536 - accuracy: 0.8778 - val_loss: 0.8770 - val_accuracy: 0.7692\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2618 - accuracy: 0.8778 - val_loss: 0.8868 - val_accuracy: 0.7436\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2592 - accuracy: 0.8778 - val_loss: 0.8707 - val_accuracy: 0.7692\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2540 - accuracy: 0.8778 - val_loss: 0.8938 - val_accuracy: 0.7692\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2624 - accuracy: 0.8741 - val_loss: 0.8997 - val_accuracy: 0.7436\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2573 - accuracy: 0.8741 - val_loss: 0.8709 - val_accuracy: 0.7692\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 0.8766 - val_accuracy: 0.7436\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2540 - accuracy: 0.8778 - val_loss: 0.8728 - val_accuracy: 0.7692\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2548 - accuracy: 0.8778 - val_loss: 0.8732 - val_accuracy: 0.7692\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2559 - accuracy: 0.8778 - val_loss: 0.8770 - val_accuracy: 0.7692\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 0.8741 - val_accuracy: 0.7692\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 0.8723 - val_accuracy: 0.7692\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2567 - accuracy: 0.8778 - val_loss: 0.8844 - val_accuracy: 0.7692\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2564 - accuracy: 0.8778 - val_loss: 0.8761 - val_accuracy: 0.7692\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2562 - accuracy: 0.8778 - val_loss: 0.8827 - val_accuracy: 0.7692\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2554 - accuracy: 0.8778 - val_loss: 0.8805 - val_accuracy: 0.7692\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2582 - accuracy: 0.8741 - val_loss: 0.8922 - val_accuracy: 0.7436\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2538 - accuracy: 0.8815 - val_loss: 0.8823 - val_accuracy: 0.7436\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2557 - accuracy: 0.8815 - val_loss: 0.8751 - val_accuracy: 0.7692\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2554 - accuracy: 0.8778 - val_loss: 0.8826 - val_accuracy: 0.7692\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2565 - accuracy: 0.8778 - val_loss: 0.8966 - val_accuracy: 0.7692\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2649 - accuracy: 0.8741 - val_loss: 0.8853 - val_accuracy: 0.7436\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2562 - accuracy: 0.8704 - val_loss: 0.8782 - val_accuracy: 0.7692\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2620 - accuracy: 0.8741 - val_loss: 0.9061 - val_accuracy: 0.7692\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2605 - accuracy: 0.8741 - val_loss: 0.8932 - val_accuracy: 0.7436\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2562 - accuracy: 0.8778 - val_loss: 0.8818 - val_accuracy: 0.7692\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2540 - accuracy: 0.8778 - val_loss: 0.8867 - val_accuracy: 0.7692\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.8880 - val_accuracy: 0.7692\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2568 - accuracy: 0.8741 - val_loss: 0.8801 - val_accuracy: 0.7436\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2567 - accuracy: 0.8778 - val_loss: 0.8827 - val_accuracy: 0.7436\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2640 - accuracy: 0.8667 - val_loss: 0.8801 - val_accuracy: 0.7692\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2592 - accuracy: 0.8741 - val_loss: 0.8974 - val_accuracy: 0.7692\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2562 - accuracy: 0.8778 - val_loss: 0.8942 - val_accuracy: 0.7436\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.8766 - val_accuracy: 0.7778\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 0.8986 - val_accuracy: 0.7692\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2637 - accuracy: 0.8704 - val_loss: 0.8930 - val_accuracy: 0.7265\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 0.8874 - val_accuracy: 0.7692\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2551 - accuracy: 0.8741 - val_loss: 0.8869 - val_accuracy: 0.7778\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2589 - accuracy: 0.8741 - val_loss: 0.8841 - val_accuracy: 0.7692\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2584 - accuracy: 0.8630 - val_loss: 0.9059 - val_accuracy: 0.7265\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2580 - accuracy: 0.8815 - val_loss: 0.8868 - val_accuracy: 0.7692\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2537 - accuracy: 0.8704 - val_loss: 0.8958 - val_accuracy: 0.7692\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 0.8963 - val_accuracy: 0.7692\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 0.8836 - val_accuracy: 0.7692\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2531 - accuracy: 0.8667 - val_loss: 0.8894 - val_accuracy: 0.7692\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2529 - accuracy: 0.8741 - val_loss: 0.8938 - val_accuracy: 0.7692\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2604 - accuracy: 0.8778 - val_loss: 0.8896 - val_accuracy: 0.7692\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2548 - accuracy: 0.8778 - val_loss: 0.8935 - val_accuracy: 0.7436\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2554 - accuracy: 0.8778 - val_loss: 0.8991 - val_accuracy: 0.7436\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2531 - accuracy: 0.8815 - val_loss: 0.8840 - val_accuracy: 0.7778\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2564 - accuracy: 0.8741 - val_loss: 0.8930 - val_accuracy: 0.7436\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2555 - accuracy: 0.8778 - val_loss: 0.8908 - val_accuracy: 0.7436\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2624 - accuracy: 0.8519 - val_loss: 0.8798 - val_accuracy: 0.7436\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2576 - accuracy: 0.8741 - val_loss: 0.8929 - val_accuracy: 0.7692\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2531 - accuracy: 0.8778 - val_loss: 0.8950 - val_accuracy: 0.7692\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2595 - accuracy: 0.8741 - val_loss: 0.8936 - val_accuracy: 0.7692\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2565 - accuracy: 0.8741 - val_loss: 0.9111 - val_accuracy: 0.7436\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2513 - accuracy: 0.8778 - val_loss: 0.8960 - val_accuracy: 0.7692\n",
      "Epoch 609/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 113us/step - loss: 0.2535 - accuracy: 0.8778 - val_loss: 0.8904 - val_accuracy: 0.7692\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 0.9016 - val_accuracy: 0.7692\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2566 - accuracy: 0.8778 - val_loss: 0.9099 - val_accuracy: 0.7436\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2527 - accuracy: 0.8741 - val_loss: 0.8995 - val_accuracy: 0.7692\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2550 - accuracy: 0.8741 - val_loss: 0.8967 - val_accuracy: 0.7692\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2516 - accuracy: 0.8815 - val_loss: 0.9199 - val_accuracy: 0.7265\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2564 - accuracy: 0.8630 - val_loss: 0.9002 - val_accuracy: 0.7436\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2525 - accuracy: 0.8778 - val_loss: 0.8890 - val_accuracy: 0.7692\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2515 - accuracy: 0.8778 - val_loss: 0.9042 - val_accuracy: 0.7692\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2519 - accuracy: 0.8778 - val_loss: 0.9109 - val_accuracy: 0.7692\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2524 - accuracy: 0.8815 - val_loss: 0.9105 - val_accuracy: 0.7692\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2540 - accuracy: 0.8778 - val_loss: 0.9046 - val_accuracy: 0.7692\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 0.9086 - val_accuracy: 0.7692\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2528 - accuracy: 0.8778 - val_loss: 0.9178 - val_accuracy: 0.7692\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2546 - accuracy: 0.8778 - val_loss: 0.8941 - val_accuracy: 0.7692\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 0.9077 - val_accuracy: 0.7692\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2604 - accuracy: 0.8741 - val_loss: 0.9252 - val_accuracy: 0.7436\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2527 - accuracy: 0.8778 - val_loss: 0.8887 - val_accuracy: 0.7778\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 344us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 0.9072 - val_accuracy: 0.7692\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2568 - accuracy: 0.8778 - val_loss: 0.9173 - val_accuracy: 0.7436\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2577 - accuracy: 0.8741 - val_loss: 0.8947 - val_accuracy: 0.7778\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.9224 - val_accuracy: 0.7692\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2581 - accuracy: 0.8778 - val_loss: 0.9057 - val_accuracy: 0.7692\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 0.8965 - val_accuracy: 0.7778\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2562 - accuracy: 0.8704 - val_loss: 0.9049 - val_accuracy: 0.7778\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2521 - accuracy: 0.8778 - val_loss: 0.9188 - val_accuracy: 0.7692\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2573 - accuracy: 0.8778 - val_loss: 0.9140 - val_accuracy: 0.7692\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2520 - accuracy: 0.8741 - val_loss: 0.9177 - val_accuracy: 0.7436\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2524 - accuracy: 0.8741 - val_loss: 0.9161 - val_accuracy: 0.7436\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2517 - accuracy: 0.8741 - val_loss: 0.9149 - val_accuracy: 0.7692\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2511 - accuracy: 0.8741 - val_loss: 0.9196 - val_accuracy: 0.7692\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2504 - accuracy: 0.8778 - val_loss: 0.9128 - val_accuracy: 0.7436\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2564 - accuracy: 0.8778 - val_loss: 0.9206 - val_accuracy: 0.7436\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2510 - accuracy: 0.8778 - val_loss: 0.9141 - val_accuracy: 0.7692\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2526 - accuracy: 0.8778 - val_loss: 0.9167 - val_accuracy: 0.7436\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 0.9135 - val_accuracy: 0.7436\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2532 - accuracy: 0.8741 - val_loss: 0.9139 - val_accuracy: 0.7436\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2517 - accuracy: 0.8704 - val_loss: 0.9133 - val_accuracy: 0.7692\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 0.9318 - val_accuracy: 0.7692\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.9065 - val_accuracy: 0.7692\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 0.9266 - val_accuracy: 0.7436\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2542 - accuracy: 0.8741 - val_loss: 0.9083 - val_accuracy: 0.7778\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2528 - accuracy: 0.8741 - val_loss: 0.9330 - val_accuracy: 0.7692\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2604 - accuracy: 0.8556 - val_loss: 0.9422 - val_accuracy: 0.7265\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2514 - accuracy: 0.8815 - val_loss: 0.9132 - val_accuracy: 0.7692\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2648 - accuracy: 0.8778 - val_loss: 0.9262 - val_accuracy: 0.7778\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2536 - accuracy: 0.8741 - val_loss: 0.9103 - val_accuracy: 0.7692\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2513 - accuracy: 0.8741 - val_loss: 0.9185 - val_accuracy: 0.7436\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2579 - accuracy: 0.8630 - val_loss: 0.9333 - val_accuracy: 0.7436\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2531 - accuracy: 0.8667 - val_loss: 0.9133 - val_accuracy: 0.7692\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2541 - accuracy: 0.8741 - val_loss: 0.9263 - val_accuracy: 0.7692\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2536 - accuracy: 0.8778 - val_loss: 0.9185 - val_accuracy: 0.7692\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2539 - accuracy: 0.8778 - val_loss: 0.9222 - val_accuracy: 0.7692\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.9253 - val_accuracy: 0.7436\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 0.9134 - val_accuracy: 0.7692\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 0.9129 - val_accuracy: 0.7778\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2527 - accuracy: 0.8704 - val_loss: 0.9297 - val_accuracy: 0.7692\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 0.9372 - val_accuracy: 0.7692\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 0.9352 - val_accuracy: 0.7692\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 0.9266 - val_accuracy: 0.7692\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2507 - accuracy: 0.8704 - val_loss: 0.9309 - val_accuracy: 0.7436\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2611 - accuracy: 0.8556 - val_loss: 0.9204 - val_accuracy: 0.8034\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2508 - accuracy: 0.8704 - val_loss: 0.9373 - val_accuracy: 0.7692\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 0.9227 - val_accuracy: 0.7692\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2537 - accuracy: 0.8741 - val_loss: 0.9278 - val_accuracy: 0.7436\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2527 - accuracy: 0.8704 - val_loss: 0.9494 - val_accuracy: 0.7436\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2560 - accuracy: 0.8630 - val_loss: 0.9216 - val_accuracy: 0.7692\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.87 - 0s 87us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 0.9280 - val_accuracy: 0.7692\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2517 - accuracy: 0.8741 - val_loss: 0.9346 - val_accuracy: 0.7436\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2536 - accuracy: 0.8556 - val_loss: 0.9325 - val_accuracy: 0.7692\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2508 - accuracy: 0.8778 - val_loss: 0.9277 - val_accuracy: 0.7692\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 0.9290 - val_accuracy: 0.7692\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2622 - accuracy: 0.8556 - val_loss: 0.9389 - val_accuracy: 0.7265\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2534 - accuracy: 0.8815 - val_loss: 0.9383 - val_accuracy: 0.7692\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2520 - accuracy: 0.8667 - val_loss: 0.9352 - val_accuracy: 0.7778\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 0.9409 - val_accuracy: 0.7436\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2533 - accuracy: 0.8778 - val_loss: 0.9338 - val_accuracy: 0.7692\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 0.9268 - val_accuracy: 0.7778\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2499 - accuracy: 0.8741 - val_loss: 0.9279 - val_accuracy: 0.7778\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2493 - accuracy: 0.8741 - val_loss: 0.9290 - val_accuracy: 0.7436\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2510 - accuracy: 0.8778 - val_loss: 0.9317 - val_accuracy: 0.7692\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2545 - accuracy: 0.8630 - val_loss: 0.9212 - val_accuracy: 0.7692\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2498 - accuracy: 0.8778 - val_loss: 0.9495 - val_accuracy: 0.7436\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 0.9320 - val_accuracy: 0.7692\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 0.9271 - val_accuracy: 0.7692\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 0.9269 - val_accuracy: 0.7692\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 0.9202 - val_accuracy: 0.7692\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 0.9246 - val_accuracy: 0.7436\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2529 - accuracy: 0.8778 - val_loss: 0.9284 - val_accuracy: 0.7692\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 0.9310 - val_accuracy: 0.7692\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 0.9262 - val_accuracy: 0.7692\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 0.9400 - val_accuracy: 0.7692\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2558 - accuracy: 0.8667 - val_loss: 0.9311 - val_accuracy: 0.7436\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2545 - accuracy: 0.8741 - val_loss: 0.9324 - val_accuracy: 0.7692\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 0.9339 - val_accuracy: 0.7692\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2497 - accuracy: 0.8704 - val_loss: 0.9489 - val_accuracy: 0.7436\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 0.9363 - val_accuracy: 0.7436\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 0.9297 - val_accuracy: 0.7692\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2524 - accuracy: 0.8778 - val_loss: 0.9260 - val_accuracy: 0.7692\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2500 - accuracy: 0.8778 - val_loss: 0.9440 - val_accuracy: 0.7692\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 0.9373 - val_accuracy: 0.7436\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2506 - accuracy: 0.8667 - val_loss: 0.9274 - val_accuracy: 0.7692\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 0.9405 - val_accuracy: 0.7692\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 0.9305 - val_accuracy: 0.7436\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2514 - accuracy: 0.8667 - val_loss: 0.9342 - val_accuracy: 0.7692\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2514 - accuracy: 0.8778 - val_loss: 0.9410 - val_accuracy: 0.7436\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2508 - accuracy: 0.8741 - val_loss: 0.9353 - val_accuracy: 0.7692\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2561 - accuracy: 0.8667 - val_loss: 0.9417 - val_accuracy: 0.7436\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 0.9322 - val_accuracy: 0.7692\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2527 - accuracy: 0.8778 - val_loss: 0.9403 - val_accuracy: 0.7692\n",
      "Epoch 719/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 79us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 0.9333 - val_accuracy: 0.7436\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2558 - accuracy: 0.8815 - val_loss: 0.9421 - val_accuracy: 0.7265\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2519 - accuracy: 0.8704 - val_loss: 0.9454 - val_accuracy: 0.7692\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2493 - accuracy: 0.8741 - val_loss: 0.9406 - val_accuracy: 0.7692\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2545 - accuracy: 0.8704 - val_loss: 0.9487 - val_accuracy: 0.7436\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2497 - accuracy: 0.8667 - val_loss: 0.9350 - val_accuracy: 0.7692\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2538 - accuracy: 0.8704 - val_loss: 0.9363 - val_accuracy: 0.7778\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 0.9526 - val_accuracy: 0.7436\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2516 - accuracy: 0.8741 - val_loss: 0.9398 - val_accuracy: 0.7436\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2479 - accuracy: 0.8667 - val_loss: 0.9445 - val_accuracy: 0.7692\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 0.9406 - val_accuracy: 0.7692\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2515 - accuracy: 0.8778 - val_loss: 0.9531 - val_accuracy: 0.7436\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 0.9400 - val_accuracy: 0.7692\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2521 - accuracy: 0.8704 - val_loss: 0.9458 - val_accuracy: 0.7436\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2476 - accuracy: 0.8741 - val_loss: 0.9484 - val_accuracy: 0.7692\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2466 - accuracy: 0.8778 - val_loss: 0.9397 - val_accuracy: 0.7692\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2568 - accuracy: 0.8667 - val_loss: 0.9428 - val_accuracy: 0.7692\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 0.9500 - val_accuracy: 0.7436\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 0.9452 - val_accuracy: 0.7692\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2533 - accuracy: 0.8778 - val_loss: 0.9507 - val_accuracy: 0.7692\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 0.9523 - val_accuracy: 0.7436\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 0.9571 - val_accuracy: 0.7436\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2520 - accuracy: 0.8704 - val_loss: 0.9430 - val_accuracy: 0.7692\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 0.9600 - val_accuracy: 0.7436\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 0.9428 - val_accuracy: 0.7692\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2561 - accuracy: 0.8630 - val_loss: 0.9499 - val_accuracy: 0.7778\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2522 - accuracy: 0.8630 - val_loss: 0.9662 - val_accuracy: 0.7265\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2508 - accuracy: 0.8704 - val_loss: 0.9532 - val_accuracy: 0.7692\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 0.9419 - val_accuracy: 0.7778\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2503 - accuracy: 0.8778 - val_loss: 0.9532 - val_accuracy: 0.7692\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2550 - accuracy: 0.8741 - val_loss: 0.9480 - val_accuracy: 0.7692\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 0.9545 - val_accuracy: 0.7692\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2519 - accuracy: 0.8704 - val_loss: 0.9512 - val_accuracy: 0.7778\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 0.9532 - val_accuracy: 0.7692\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 0.9490 - val_accuracy: 0.7692\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 0.9531 - val_accuracy: 0.7436\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 0.9558 - val_accuracy: 0.7692\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2512 - accuracy: 0.8741 - val_loss: 0.9624 - val_accuracy: 0.7436\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2491 - accuracy: 0.8704 - val_loss: 0.9549 - val_accuracy: 0.7692\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 0.9631 - val_accuracy: 0.7692\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2479 - accuracy: 0.8741 - val_loss: 0.9430 - val_accuracy: 0.7778\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2492 - accuracy: 0.8704 - val_loss: 0.9441 - val_accuracy: 0.7778\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2538 - accuracy: 0.8741 - val_loss: 0.9688 - val_accuracy: 0.7436\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 0.9475 - val_accuracy: 0.7436\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2510 - accuracy: 0.8556 - val_loss: 0.9487 - val_accuracy: 0.7692\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.9737 - val_accuracy: 0.7692\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 0.9525 - val_accuracy: 0.7692\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 0.9613 - val_accuracy: 0.7436\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 0.9674 - val_accuracy: 0.7692\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 0.9574 - val_accuracy: 0.7692\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2498 - accuracy: 0.8778 - val_loss: 0.9531 - val_accuracy: 0.7692\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2508 - accuracy: 0.8778 - val_loss: 0.9657 - val_accuracy: 0.7692\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2495 - accuracy: 0.8741 - val_loss: 0.9609 - val_accuracy: 0.7692\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 0.9666 - val_accuracy: 0.7436\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 0.9544 - val_accuracy: 0.7692\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 0.9631 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2523 - accuracy: 0.8778 - val_loss: 0.9684 - val_accuracy: 0.7436\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2515 - accuracy: 0.8741 - val_loss: 0.9545 - val_accuracy: 0.7778\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2522 - accuracy: 0.8815 - val_loss: 0.9758 - val_accuracy: 0.7436\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 0.9611 - val_accuracy: 0.7692\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 0.9653 - val_accuracy: 0.7436\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2535 - accuracy: 0.8741 - val_loss: 0.9834 - val_accuracy: 0.7350\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.9554 - val_accuracy: 0.7692\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 0.9588 - val_accuracy: 0.7692\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 0.9612 - val_accuracy: 0.7436\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2543 - accuracy: 0.8593 - val_loss: 0.9701 - val_accuracy: 0.7436\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 0.9660 - val_accuracy: 0.7692\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 0.9618 - val_accuracy: 0.7692\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2501 - accuracy: 0.8741 - val_loss: 0.9634 - val_accuracy: 0.7692\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2500 - accuracy: 0.8778 - val_loss: 0.9632 - val_accuracy: 0.7436\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2511 - accuracy: 0.8593 - val_loss: 0.9611 - val_accuracy: 0.7692\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 0.9665 - val_accuracy: 0.7436\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 0.9663 - val_accuracy: 0.7436\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 0.9681 - val_accuracy: 0.7692\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2532 - accuracy: 0.8741 - val_loss: 0.9606 - val_accuracy: 0.7692\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2613 - accuracy: 0.8444 - val_loss: 0.9895 - val_accuracy: 0.7265\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2499 - accuracy: 0.8667 - val_loss: 0.9480 - val_accuracy: 0.7778\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2511 - accuracy: 0.8667 - val_loss: 0.9606 - val_accuracy: 0.7778\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2501 - accuracy: 0.8519 - val_loss: 0.9800 - val_accuracy: 0.7265\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 0.9627 - val_accuracy: 0.7692\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 0.9567 - val_accuracy: 0.7692\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 0.9682 - val_accuracy: 0.7692\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2514 - accuracy: 0.8704 - val_loss: 0.9785 - val_accuracy: 0.7436\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 0.9578 - val_accuracy: 0.7436\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2501 - accuracy: 0.8778 - val_loss: 0.9654 - val_accuracy: 0.7692\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 0.9746 - val_accuracy: 0.7692\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 0.9877 - val_accuracy: 0.7436\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2496 - accuracy: 0.8741 - val_loss: 0.9644 - val_accuracy: 0.7436\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2519 - accuracy: 0.8778 - val_loss: 0.9632 - val_accuracy: 0.7692\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 0.9734 - val_accuracy: 0.7436\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2526 - accuracy: 0.8704 - val_loss: 0.9667 - val_accuracy: 0.7692\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 0.9585 - val_accuracy: 0.7692\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2580 - accuracy: 0.8630 - val_loss: 0.9652 - val_accuracy: 0.7692\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 0.9932 - val_accuracy: 0.7436\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2525 - accuracy: 0.8778 - val_loss: 0.9611 - val_accuracy: 0.7436\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2492 - accuracy: 0.8630 - val_loss: 0.9658 - val_accuracy: 0.7778\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2562 - accuracy: 0.8519 - val_loss: 0.9794 - val_accuracy: 0.7436\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 0.9718 - val_accuracy: 0.7436\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2515 - accuracy: 0.8704 - val_loss: 0.9625 - val_accuracy: 0.7692\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 0.9728 - val_accuracy: 0.7436\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 0.9720 - val_accuracy: 0.7436\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2514 - accuracy: 0.8704 - val_loss: 0.9631 - val_accuracy: 0.7778\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 0.9833 - val_accuracy: 0.7436\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2505 - accuracy: 0.8778 - val_loss: 0.9813 - val_accuracy: 0.7436\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 0.9677 - val_accuracy: 0.7778\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 0.9823 - val_accuracy: 0.7436\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 0.9727 - val_accuracy: 0.7436\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2500 - accuracy: 0.8741 - val_loss: 0.9737 - val_accuracy: 0.7436\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 0.9701 - val_accuracy: 0.7692\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 0.9807 - val_accuracy: 0.7436\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 0.9779 - val_accuracy: 0.7436\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 0.9714 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 0.9750 - val_accuracy: 0.7692\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 0.9930 - val_accuracy: 0.7436\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 0.9752 - val_accuracy: 0.7436\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 0.9744 - val_accuracy: 0.7692\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2484 - accuracy: 0.8741 - val_loss: 0.9874 - val_accuracy: 0.7436\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 0.9776 - val_accuracy: 0.7778\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 0.9804 - val_accuracy: 0.7436\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 0.9739 - val_accuracy: 0.7436\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2463 - accuracy: 0.8704 - val_loss: 0.9808 - val_accuracy: 0.7436\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 0.9787 - val_accuracy: 0.7692\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 0.9963 - val_accuracy: 0.7436\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 0.9806 - val_accuracy: 0.7436\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 0.9904 - val_accuracy: 0.7692\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 0.9878 - val_accuracy: 0.7692\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2493 - accuracy: 0.8667 - val_loss: 0.9780 - val_accuracy: 0.7778\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 0.9787 - val_accuracy: 0.7436\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 0.9802 - val_accuracy: 0.7692\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 0.9921 - val_accuracy: 0.7692\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2516 - accuracy: 0.8667 - val_loss: 0.9955 - val_accuracy: 0.7265\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2494 - accuracy: 0.8667 - val_loss: 0.9801 - val_accuracy: 0.7692\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 0.9866 - val_accuracy: 0.7436\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 0.9934 - val_accuracy: 0.7692\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 0.9946 - val_accuracy: 0.7692\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2484 - accuracy: 0.8704 - val_loss: 0.9795 - val_accuracy: 0.7692\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2484 - accuracy: 0.8778 - val_loss: 0.9982 - val_accuracy: 0.7436\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 0.9803 - val_accuracy: 0.7692\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 0.9886 - val_accuracy: 0.7692\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 0.9832 - val_accuracy: 0.7436\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 0.9907 - val_accuracy: 0.7436\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 0.9832 - val_accuracy: 0.7692\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2512 - accuracy: 0.8704 - val_loss: 0.9837 - val_accuracy: 0.7692\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 0.9932 - val_accuracy: 0.7692\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2524 - accuracy: 0.8630 - val_loss: 1.0011 - val_accuracy: 0.7436\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2482 - accuracy: 0.8704 - val_loss: 0.9771 - val_accuracy: 0.7778\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2477 - accuracy: 0.8630 - val_loss: 0.9858 - val_accuracy: 0.7436\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 0.9926 - val_accuracy: 0.7692\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 0.9952 - val_accuracy: 0.7692\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 0.9853 - val_accuracy: 0.7692\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2519 - accuracy: 0.8667 - val_loss: 0.9879 - val_accuracy: 0.7436\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2494 - accuracy: 0.8667 - val_loss: 0.9800 - val_accuracy: 0.7692\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2503 - accuracy: 0.8593 - val_loss: 0.9991 - val_accuracy: 0.7436\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 0.9849 - val_accuracy: 0.7692\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 0.9833 - val_accuracy: 0.7692\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 0.9958 - val_accuracy: 0.7436\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2467 - accuracy: 0.8704 - val_loss: 0.9879 - val_accuracy: 0.7436\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2478 - accuracy: 0.8704 - val_loss: 0.9875 - val_accuracy: 0.7692\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 0.9828 - val_accuracy: 0.7692\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 0.9899 - val_accuracy: 0.7692\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2484 - accuracy: 0.8704 - val_loss: 1.0215 - val_accuracy: 0.7094\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2484 - accuracy: 0.8741 - val_loss: 0.9853 - val_accuracy: 0.7692\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 0.9841 - val_accuracy: 0.7692\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.0008 - val_accuracy: 0.7692\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 0.9906 - val_accuracy: 0.7436\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 0.9915 - val_accuracy: 0.7692\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 0.9907 - val_accuracy: 0.7692\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 0.9839 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 0.9924 - val_accuracy: 0.7436\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2497 - accuracy: 0.8704 - val_loss: 0.9947 - val_accuracy: 0.7436\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 0.9785 - val_accuracy: 0.7692\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 0.9963 - val_accuracy: 0.7692\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 0.9944 - val_accuracy: 0.7436\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 0.9765 - val_accuracy: 0.7607\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 0.9823 - val_accuracy: 0.7692\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 0.9934 - val_accuracy: 0.7692\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 0.9991 - val_accuracy: 0.7436\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 0.9924 - val_accuracy: 0.7436\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 0.9863 - val_accuracy: 0.7778\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2551 - accuracy: 0.8741 - val_loss: 0.9766 - val_accuracy: 0.7692\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2523 - accuracy: 0.8704 - val_loss: 1.0104 - val_accuracy: 0.7436\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 0.9916 - val_accuracy: 0.7692\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2490 - accuracy: 0.8741 - val_loss: 0.9882 - val_accuracy: 0.7778\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.0184 - val_accuracy: 0.7436\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 1.0007 - val_accuracy: 0.7692\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 0.9900 - val_accuracy: 0.7692\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2501 - accuracy: 0.8741 - val_loss: 0.9808 - val_accuracy: 0.7778\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 0.9995 - val_accuracy: 0.7436\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2450 - accuracy: 0.8630 - val_loss: 0.9960 - val_accuracy: 0.7350\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 0.9938 - val_accuracy: 0.7692\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2494 - accuracy: 0.8741 - val_loss: 0.9908 - val_accuracy: 0.7692\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.0101 - val_accuracy: 0.7436\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.0020 - val_accuracy: 0.7436\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2547 - accuracy: 0.8741 - val_loss: 1.0048 - val_accuracy: 0.7692\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.0194 - val_accuracy: 0.7436\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2509 - accuracy: 0.8741 - val_loss: 0.9951 - val_accuracy: 0.7436\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 0.9972 - val_accuracy: 0.7692\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.0000 - val_accuracy: 0.7436\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.0068 - val_accuracy: 0.7436\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 0.9940 - val_accuracy: 0.7778\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 0.9943 - val_accuracy: 0.7692\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.0030 - val_accuracy: 0.7692\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2495 - accuracy: 0.8704 - val_loss: 1.0087 - val_accuracy: 0.7436\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 0.9914 - val_accuracy: 0.7692\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2488 - accuracy: 0.8741 - val_loss: 1.0026 - val_accuracy: 0.7692\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.0016 - val_accuracy: 0.7436\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2483 - accuracy: 0.8630 - val_loss: 1.0012 - val_accuracy: 0.7692\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2488 - accuracy: 0.8667 - val_loss: 1.0016 - val_accuracy: 0.7692\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 0.9936 - val_accuracy: 0.7692\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2483 - accuracy: 0.8667 - val_loss: 0.9834 - val_accuracy: 0.7778\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 0.9999 - val_accuracy: 0.7436\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 0.9975 - val_accuracy: 0.7692\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 0.9918 - val_accuracy: 0.7607\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.0040 - val_accuracy: 0.7692\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.0068 - val_accuracy: 0.7692\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.0094 - val_accuracy: 0.7692\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.0055 - val_accuracy: 0.7436\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.0006 - val_accuracy: 0.7692\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 0.9987 - val_accuracy: 0.7436\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 1.0080 - val_accuracy: 0.7436\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.0079 - val_accuracy: 0.7436\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.0021 - val_accuracy: 0.7436\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2527 - accuracy: 0.8667 - val_loss: 0.9958 - val_accuracy: 0.7778\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.0285 - val_accuracy: 0.7009\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2506 - accuracy: 0.8704 - val_loss: 1.0244 - val_accuracy: 0.7009\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2471 - accuracy: 0.8704 - val_loss: 0.9993 - val_accuracy: 0.7350\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.0041 - val_accuracy: 0.7436\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.0323 - val_accuracy: 0.7094\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2486 - accuracy: 0.8667 - val_loss: 0.9997 - val_accuracy: 0.7436\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2493 - accuracy: 0.8667 - val_loss: 1.0010 - val_accuracy: 0.7692\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2556 - accuracy: 0.8667 - val_loss: 1.0345 - val_accuracy: 0.7692\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.0150 - val_accuracy: 0.7350\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2507 - accuracy: 0.8556 - val_loss: 1.0040 - val_accuracy: 0.7607\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.0184 - val_accuracy: 0.7692\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2457 - accuracy: 0.8704 - val_loss: 1.0212 - val_accuracy: 0.7436\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.0154 - val_accuracy: 0.7692\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.0214 - val_accuracy: 0.7436\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2456 - accuracy: 0.8704 - val_loss: 1.0059 - val_accuracy: 0.7778\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.0063 - val_accuracy: 0.7692\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.0214 - val_accuracy: 0.7692\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2505 - accuracy: 0.8704 - val_loss: 1.0246 - val_accuracy: 0.7436\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.0026 - val_accuracy: 0.7607\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2490 - accuracy: 0.8704 - val_loss: 1.0152 - val_accuracy: 0.7692\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.0250 - val_accuracy: 0.7692\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.0141 - val_accuracy: 0.7436\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2520 - accuracy: 0.8667 - val_loss: 1.0032 - val_accuracy: 0.7692\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.0147 - val_accuracy: 0.7436\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.0190 - val_accuracy: 0.7436\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.0140 - val_accuracy: 0.7692\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2458 - accuracy: 0.8704 - val_loss: 1.0122 - val_accuracy: 0.7692\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2465 - accuracy: 0.8667 - val_loss: 1.0121 - val_accuracy: 0.7350\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.0337 - val_accuracy: 0.7094\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2495 - accuracy: 0.8741 - val_loss: 1.0064 - val_accuracy: 0.7436\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.0162 - val_accuracy: 0.7436\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.0069 - val_accuracy: 0.7692\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2448 - accuracy: 0.8704 - val_loss: 1.0225 - val_accuracy: 0.7692\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.0271 - val_accuracy: 0.7692\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2454 - accuracy: 0.8852 - val_loss: 1.0268 - val_accuracy: 0.7436\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2498 - accuracy: 0.8778 - val_loss: 1.0178 - val_accuracy: 0.7350\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2517 - accuracy: 0.8704 - val_loss: 1.0454 - val_accuracy: 0.7094\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.0156 - val_accuracy: 0.7350\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2506 - accuracy: 0.8593 - val_loss: 1.0169 - val_accuracy: 0.7436\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.0350 - val_accuracy: 0.7692\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2487 - accuracy: 0.8704 - val_loss: 1.0263 - val_accuracy: 0.7692\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.0153 - val_accuracy: 0.7350\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.0125 - val_accuracy: 0.7436\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.0263 - val_accuracy: 0.7692\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.0178 - val_accuracy: 0.7692\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 1.0143 - val_accuracy: 0.7692\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.0294 - val_accuracy: 0.7436\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.0183 - val_accuracy: 0.7692\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.0254 - val_accuracy: 0.7692\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2479 - accuracy: 0.8778 - val_loss: 1.0178 - val_accuracy: 0.7692\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2508 - accuracy: 0.8778 - val_loss: 1.0316 - val_accuracy: 0.7692\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.0105 - val_accuracy: 0.7692\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2515 - accuracy: 0.8704 - val_loss: 1.0148 - val_accuracy: 0.7778\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2397 - accuracy: 0.8667 - val_loss: 1.0343 - val_accuracy: 0.7436\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2536 - accuracy: 0.8630 - val_loss: 1.0358 - val_accuracy: 0.7436\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 91us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.0142 - val_accuracy: 0.7607\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2516 - accuracy: 0.8704 - val_loss: 1.0112 - val_accuracy: 0.7692\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2606 - accuracy: 0.8481 - val_loss: 1.0379 - val_accuracy: 0.7436\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2516 - accuracy: 0.8704 - val_loss: 1.0123 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a31e210b8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 58us/step\n",
      "over-sampling test accuracy: 76.07%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 2, 1,\n",
       "       0, 0, 0, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 0, 0,\n",
       "       2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 0, 1, 0, 1, 1, 2, 2, 2, 1, 1, 0,\n",
       "       1, 2, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 2, 0, 0, 1, 0,\n",
       "       0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2,\n",
       "       0, 1, 2, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCH-SA-14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBRSa49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GA984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0    BCH-SA-11     2     2\n",
       "1       NRS161     1     1\n",
       "2    BCH-SA-14     2     2\n",
       "3    BCH-SA-11     2     2\n",
       "4     CFBRSa49     1     1\n",
       "..         ...   ...   ...\n",
       "112     NRS064     2     2\n",
       "113     NRS266     2     2\n",
       "114     NRS222     0     0\n",
       "115       GA27     2     2\n",
       "116      GA984     1     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.401598e-01</td>\n",
       "      <td>0.221760</td>\n",
       "      <td>6.380803e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.279516e-03</td>\n",
       "      <td>0.611688</td>\n",
       "      <td>3.870320e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.149810e-06</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>9.993679e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.401598e-01</td>\n",
       "      <td>0.221760</td>\n",
       "      <td>6.380803e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.517423e-02</td>\n",
       "      <td>0.984826</td>\n",
       "      <td>8.666426e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5.866610e-10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.139936e-02</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>9.882096e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>9.997405e-01</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>5.487098e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.858575e-04</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>9.972298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2.580785e-03</td>\n",
       "      <td>0.996810</td>\n",
       "      <td>6.089573e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    1.401598e-01  0.221760  6.380803e-01\n",
       "1    1.279516e-03  0.611688  3.870320e-01\n",
       "2    1.149810e-06  0.000631  9.993679e-01\n",
       "3    1.401598e-01  0.221760  6.380803e-01\n",
       "4    1.517423e-02  0.984826  8.666426e-16\n",
       "..            ...       ...           ...\n",
       "112  5.866610e-10  0.000001  9.999988e-01\n",
       "113  1.139936e-02  0.000391  9.882096e-01\n",
       "114  9.997405e-01  0.000205  5.487098e-05\n",
       "115  1.858575e-04  0.002584  9.972298e-01\n",
       "116  2.580785e-03  0.996810  6.089573e-04\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.0701 - val_accuracy: 0.7350\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2485 - accuracy: 0.8667 - val_loss: 1.0554 - val_accuracy: 0.7607\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.0761 - val_accuracy: 0.7350\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.0695 - val_accuracy: 0.7350\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.0789 - val_accuracy: 0.7350\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.0704 - val_accuracy: 0.7350\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.0720 - val_accuracy: 0.7607\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.0749 - val_accuracy: 0.7350\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2468 - accuracy: 0.8556 - val_loss: 1.0749 - val_accuracy: 0.7350\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2441 - accuracy: 0.8704 - val_loss: 1.0650 - val_accuracy: 0.7692\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2445 - accuracy: 0.8704 - val_loss: 1.0767 - val_accuracy: 0.7350\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.0691 - val_accuracy: 0.7350\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.0663 - val_accuracy: 0.7692\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2430 - accuracy: 0.8704 - val_loss: 1.0665 - val_accuracy: 0.7607\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.0732 - val_accuracy: 0.7607\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.0742 - val_accuracy: 0.7607\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.0696 - val_accuracy: 0.7607\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2429 - accuracy: 0.8667 - val_loss: 1.0606 - val_accuracy: 0.7607\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2466 - accuracy: 0.8778 - val_loss: 1.0742 - val_accuracy: 0.7607\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2525 - accuracy: 0.8667 - val_loss: 1.0630 - val_accuracy: 0.7692\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 1.0811 - val_accuracy: 0.7350\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.0704 - val_accuracy: 0.7607\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2442 - accuracy: 0.8741 - val_loss: 1.0641 - val_accuracy: 0.7607\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.0743 - val_accuracy: 0.7607\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.0779 - val_accuracy: 0.7350\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.0741 - val_accuracy: 0.7350\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.0830 - val_accuracy: 0.7350\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 1.0744 - val_accuracy: 0.7607\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.0727 - val_accuracy: 0.7607\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.0885 - val_accuracy: 0.7350\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.0802 - val_accuracy: 0.7607\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.0723 - val_accuracy: 0.7607\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.0691 - val_accuracy: 0.7607\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2476 - accuracy: 0.8741 - val_loss: 1.0921 - val_accuracy: 0.7350\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.0743 - val_accuracy: 0.7692\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2443 - accuracy: 0.8704 - val_loss: 1.0800 - val_accuracy: 0.7607\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.0918 - val_accuracy: 0.7350\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2393 - accuracy: 0.8741 - val_loss: 1.0946 - val_accuracy: 0.7607\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.0863 - val_accuracy: 0.7607\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.0815 - val_accuracy: 0.7350\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.0918 - val_accuracy: 0.7350\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.0834 - val_accuracy: 0.7607\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.0763 - val_accuracy: 0.7607\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.0944 - val_accuracy: 0.7350\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.0838 - val_accuracy: 0.7350\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.0853 - val_accuracy: 0.7607\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.0830 - val_accuracy: 0.7607\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2407 - accuracy: 0.8741 - val_loss: 1.0997 - val_accuracy: 0.7350\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.0907 - val_accuracy: 0.7350\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.0858 - val_accuracy: 0.7350\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.0830 - val_accuracy: 0.7607\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.0832 - val_accuracy: 0.7607\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.0687 - val_accuracy: 0.7607\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.0905 - val_accuracy: 0.7350\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2455 - accuracy: 0.8593 - val_loss: 1.0866 - val_accuracy: 0.7350\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.0857 - val_accuracy: 0.7607\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.0831 - val_accuracy: 0.7607\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2455 - accuracy: 0.8667 - val_loss: 1.0862 - val_accuracy: 0.7692\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2458 - accuracy: 0.8704 - val_loss: 1.0948 - val_accuracy: 0.7350\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2489 - accuracy: 0.8704 - val_loss: 1.0773 - val_accuracy: 0.7607\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.0970 - val_accuracy: 0.7350\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2484 - accuracy: 0.8630 - val_loss: 1.0850 - val_accuracy: 0.7607\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.0960 - val_accuracy: 0.7350\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.0997 - val_accuracy: 0.7607\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.1016 - val_accuracy: 0.7350\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.0916 - val_accuracy: 0.7607\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.1008 - val_accuracy: 0.7350\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.0968 - val_accuracy: 0.7350\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2440 - accuracy: 0.8667 - val_loss: 1.0802 - val_accuracy: 0.7692\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.0984 - val_accuracy: 0.7350\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2442 - accuracy: 0.8704 - val_loss: 1.0960 - val_accuracy: 0.7350\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2491 - accuracy: 0.8704 - val_loss: 1.0838 - val_accuracy: 0.7692\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.90 - 0s 96us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.0858 - val_accuracy: 0.7350\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.0880 - val_accuracy: 0.7350\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.0899 - val_accuracy: 0.7350\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2425 - accuracy: 0.8704 - val_loss: 1.0931 - val_accuracy: 0.7607\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 330us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.1007 - val_accuracy: 0.7350\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.0994 - val_accuracy: 0.7350\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.1075 - val_accuracy: 0.7350\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 1.0907 - val_accuracy: 0.7607\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.0955 - val_accuracy: 0.7607\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.0979 - val_accuracy: 0.7607\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1013 - val_accuracy: 0.7607\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2418 - accuracy: 0.8852 - val_loss: 1.1076 - val_accuracy: 0.7350\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2441 - accuracy: 0.8704 - val_loss: 1.0939 - val_accuracy: 0.7607\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.0916 - val_accuracy: 0.7350\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 417us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.0961 - val_accuracy: 0.7350\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.0953 - val_accuracy: 0.7350\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.0977 - val_accuracy: 0.7350\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.1001 - val_accuracy: 0.7350\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.1055 - val_accuracy: 0.7350\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.1014 - val_accuracy: 0.7350\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.1024 - val_accuracy: 0.7350\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.0866 - val_accuracy: 0.7607\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.0915 - val_accuracy: 0.7607\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.0921 - val_accuracy: 0.7607\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.1017 - val_accuracy: 0.7350\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.1106 - val_accuracy: 0.7350\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.1063 - val_accuracy: 0.7692\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.0970 - val_accuracy: 0.7607\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2532 - accuracy: 0.8519 - val_loss: 1.1119 - val_accuracy: 0.7179\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2420 - accuracy: 0.8889 - val_loss: 1.0795 - val_accuracy: 0.7692\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2438 - accuracy: 0.8667 - val_loss: 1.1026 - val_accuracy: 0.7350\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 1.1038 - val_accuracy: 0.7350\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2513 - accuracy: 0.8741 - val_loss: 1.0936 - val_accuracy: 0.7607\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2412 - accuracy: 0.8704 - val_loss: 1.1079 - val_accuracy: 0.7350\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2464 - accuracy: 0.8630 - val_loss: 1.1107 - val_accuracy: 0.7607\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.0978 - val_accuracy: 0.7607\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.1073 - val_accuracy: 0.7350\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1006 - val_accuracy: 0.7607\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 88us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1067 - val_accuracy: 0.7350\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2471 - accuracy: 0.8593 - val_loss: 1.1269 - val_accuracy: 0.7179\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 1.1060 - val_accuracy: 0.7607\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.1115 - val_accuracy: 0.7607\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.1049 - val_accuracy: 0.7607\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.1030 - val_accuracy: 0.7607\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2453 - accuracy: 0.8667 - val_loss: 1.0939 - val_accuracy: 0.7607\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.1149 - val_accuracy: 0.7350\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.1000 - val_accuracy: 0.7607\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.1095 - val_accuracy: 0.7607\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2405 - accuracy: 0.8741 - val_loss: 1.1210 - val_accuracy: 0.7350\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.1072 - val_accuracy: 0.7607\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.1168 - val_accuracy: 0.7350\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.0964 - val_accuracy: 0.7607\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.1001 - val_accuracy: 0.7350\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.1031 - val_accuracy: 0.7607\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 1.1271 - val_accuracy: 0.6923\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.1026 - val_accuracy: 0.7607\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2438 - accuracy: 0.8704 - val_loss: 1.1090 - val_accuracy: 0.7350\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2479 - accuracy: 0.8778 - val_loss: 1.1090 - val_accuracy: 0.7607\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2414 - accuracy: 0.8667 - val_loss: 1.1068 - val_accuracy: 0.7607\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1065 - val_accuracy: 0.7607\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.1085 - val_accuracy: 0.7607\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.1187 - val_accuracy: 0.7350\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.1053 - val_accuracy: 0.7607\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1151 - val_accuracy: 0.7350\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.1066 - val_accuracy: 0.7350\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 916us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.1210 - val_accuracy: 0.7350\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.1022 - val_accuracy: 0.7607\n",
      "Epoch 140/1000\n",
      " 32/270 [==>...........................] - ETA: 0s - loss: 0.3727 - accuracy: 0.7812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.142766). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 213us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.0816 - val_accuracy: 0.7607\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.0932 - val_accuracy: 0.7350\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.0966 - val_accuracy: 0.7350\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2460 - accuracy: 0.8667 - val_loss: 1.0916 - val_accuracy: 0.7692\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2659 - accuracy: 0.8556 - val_loss: 1.1049 - val_accuracy: 0.7350\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2449 - accuracy: 0.8593 - val_loss: 1.1355 - val_accuracy: 0.6752\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2513 - accuracy: 0.8519 - val_loss: 1.1057 - val_accuracy: 0.7692\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2464 - accuracy: 0.8741 - val_loss: 1.1084 - val_accuracy: 0.7350\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.1194 - val_accuracy: 0.7350\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.1146 - val_accuracy: 0.7350\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.1035 - val_accuracy: 0.7350\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.1053 - val_accuracy: 0.7350\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.1028 - val_accuracy: 0.7607\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.1097 - val_accuracy: 0.7607\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2442 - accuracy: 0.8741 - val_loss: 1.1126 - val_accuracy: 0.7350\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.1100 - val_accuracy: 0.7607\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.1178 - val_accuracy: 0.7350\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.1144 - val_accuracy: 0.7350\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 1.1272 - val_accuracy: 0.7350\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.1118 - val_accuracy: 0.7692\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2407 - accuracy: 0.8741 - val_loss: 1.1122 - val_accuracy: 0.7350\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2415 - accuracy: 0.8593 - val_loss: 1.1154 - val_accuracy: 0.7179\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2512 - accuracy: 0.8593 - val_loss: 1.1051 - val_accuracy: 0.7607\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.1300 - val_accuracy: 0.7350\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2452 - accuracy: 0.8667 - val_loss: 1.1109 - val_accuracy: 0.7692\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.1211 - val_accuracy: 0.7350\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.1142 - val_accuracy: 0.7436\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.1218 - val_accuracy: 0.7350\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.2472 - accuracy: 0.8667 - val_loss: 1.1293 - val_accuracy: 0.7350\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.1090 - val_accuracy: 0.7607\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1198 - val_accuracy: 0.7350\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2463 - accuracy: 0.8593 - val_loss: 1.1179 - val_accuracy: 0.7350\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.1132 - val_accuracy: 0.7692\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.1142 - val_accuracy: 0.7607\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.1380 - val_accuracy: 0.7350\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.1172 - val_accuracy: 0.7607\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.1146 - val_accuracy: 0.7607\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1339 - val_accuracy: 0.7607\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2426 - accuracy: 0.8630 - val_loss: 1.1338 - val_accuracy: 0.7350\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.1160 - val_accuracy: 0.7350\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.1131 - val_accuracy: 0.7350\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.1394 - val_accuracy: 0.7350\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.1216 - val_accuracy: 0.7607\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.1264 - val_accuracy: 0.7607\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1258 - val_accuracy: 0.7350\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.1192 - val_accuracy: 0.7607\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.1158 - val_accuracy: 0.7607\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.1352 - val_accuracy: 0.7350\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.1296 - val_accuracy: 0.7350\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.1178 - val_accuracy: 0.7607\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.1402 - val_accuracy: 0.6923\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.1221 - val_accuracy: 0.7607\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.1094 - val_accuracy: 0.7692\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 534us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.1237 - val_accuracy: 0.7350\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.1157 - val_accuracy: 0.7607\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.1190 - val_accuracy: 0.7607\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.1360 - val_accuracy: 0.7350\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1251 - val_accuracy: 0.7350\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.1269 - val_accuracy: 0.7607\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1250 - val_accuracy: 0.7350\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.1234 - val_accuracy: 0.7607\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.1214 - val_accuracy: 0.7350\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.1242 - val_accuracy: 0.7350\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.1160 - val_accuracy: 0.7607\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2500 - accuracy: 0.8667 - val_loss: 1.1469 - val_accuracy: 0.7179\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2531 - accuracy: 0.8593 - val_loss: 1.1403 - val_accuracy: 0.7607\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2520 - accuracy: 0.8630 - val_loss: 1.1198 - val_accuracy: 0.7350\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2483 - accuracy: 0.8704 - val_loss: 1.1509 - val_accuracy: 0.7179\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2517 - accuracy: 0.8667 - val_loss: 1.1375 - val_accuracy: 0.7350\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2419 - accuracy: 0.8704 - val_loss: 1.1143 - val_accuracy: 0.7607\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.1297 - val_accuracy: 0.7350\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.1290 - val_accuracy: 0.7350\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.1355 - val_accuracy: 0.7350\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.1239 - val_accuracy: 0.7607\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.1321 - val_accuracy: 0.7350\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.1391 - val_accuracy: 0.7350\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.1275 - val_accuracy: 0.7607\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.1318 - val_accuracy: 0.7607\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1302 - val_accuracy: 0.7350\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.1300 - val_accuracy: 0.7607\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2456 - accuracy: 0.8667 - val_loss: 1.1364 - val_accuracy: 0.7350\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 332us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.1378 - val_accuracy: 0.7350\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.1372 - val_accuracy: 0.7607\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.1429 - val_accuracy: 0.7607\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.1265 - val_accuracy: 0.7607\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 1.1331 - val_accuracy: 0.7350\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.1447 - val_accuracy: 0.7350\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.1360 - val_accuracy: 0.7607\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.1384 - val_accuracy: 0.7607\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2419 - accuracy: 0.8704 - val_loss: 1.1370 - val_accuracy: 0.7692\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.1284 - val_accuracy: 0.7607\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2422 - accuracy: 0.8667 - val_loss: 1.1252 - val_accuracy: 0.7607\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.1341 - val_accuracy: 0.7350\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.1418 - val_accuracy: 0.7350\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.1439 - val_accuracy: 0.7607\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1362 - val_accuracy: 0.7607\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2388 - accuracy: 0.8778 - val_loss: 1.1374 - val_accuracy: 0.7350\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.1372 - val_accuracy: 0.7350\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 1.1385 - val_accuracy: 0.7607\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.1367 - val_accuracy: 0.7607\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2458 - accuracy: 0.8667 - val_loss: 1.1375 - val_accuracy: 0.7692\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2435 - accuracy: 0.8593 - val_loss: 1.1553 - val_accuracy: 0.7350\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 279us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.1350 - val_accuracy: 0.7607\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1376 - val_accuracy: 0.7607\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1500 - val_accuracy: 0.7350\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.1391 - val_accuracy: 0.7607\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1289 - val_accuracy: 0.7607\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 278us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.1389 - val_accuracy: 0.7607\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2465 - accuracy: 0.8704 - val_loss: 1.1477 - val_accuracy: 0.7607\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 1.1404 - val_accuracy: 0.7607\n",
      "Epoch 250/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 148us/step - loss: 0.2416 - accuracy: 0.8852 - val_loss: 1.1503 - val_accuracy: 0.7350\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2462 - accuracy: 0.8630 - val_loss: 1.1571 - val_accuracy: 0.7350\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2447 - accuracy: 0.8704 - val_loss: 1.1312 - val_accuracy: 0.7607\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.1435 - val_accuracy: 0.7607\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.1601 - val_accuracy: 0.7350\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.1455 - val_accuracy: 0.7607\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1464 - val_accuracy: 0.7607\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2460 - accuracy: 0.8667 - val_loss: 1.1604 - val_accuracy: 0.7179\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2451 - accuracy: 0.8704 - val_loss: 1.1385 - val_accuracy: 0.7607\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.1390 - val_accuracy: 0.7607\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 1.1348 - val_accuracy: 0.7607\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.1414 - val_accuracy: 0.7350\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.1404 - val_accuracy: 0.7607\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.1425 - val_accuracy: 0.7607\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.1554 - val_accuracy: 0.7350\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 452us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.1447 - val_accuracy: 0.7607\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1457 - val_accuracy: 0.7607\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.1643 - val_accuracy: 0.7350\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.1462 - val_accuracy: 0.7607\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2464 - accuracy: 0.8704 - val_loss: 1.1344 - val_accuracy: 0.7692\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2494 - accuracy: 0.8519 - val_loss: 1.1549 - val_accuracy: 0.7179\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 445us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.1485 - val_accuracy: 0.7607\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2537 - accuracy: 0.8778 - val_loss: 1.1376 - val_accuracy: 0.7607\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2473 - accuracy: 0.8741 - val_loss: 1.1675 - val_accuracy: 0.7350\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 377us/step - loss: 0.2500 - accuracy: 0.8667 - val_loss: 1.1583 - val_accuracy: 0.7607\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.1351 - val_accuracy: 0.7607\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.1355 - val_accuracy: 0.7607\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.1458 - val_accuracy: 0.7607\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.1602 - val_accuracy: 0.7607\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.1489 - val_accuracy: 0.7607\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2446 - accuracy: 0.8852 - val_loss: 1.1573 - val_accuracy: 0.7350\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 255us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.1549 - val_accuracy: 0.7607\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.1485 - val_accuracy: 0.7350\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.1503 - val_accuracy: 0.7350\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 1.1394 - val_accuracy: 0.7692\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1562 - val_accuracy: 0.7350\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 1.1613 - val_accuracy: 0.7350\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.1511 - val_accuracy: 0.7607\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 373us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.1553 - val_accuracy: 0.7350\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1533 - val_accuracy: 0.7350\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2460 - accuracy: 0.8556 - val_loss: 1.1671 - val_accuracy: 0.7350\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.1515 - val_accuracy: 0.7607\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1619 - val_accuracy: 0.7350\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 474us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.1801 - val_accuracy: 0.7350\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2483 - accuracy: 0.8815 - val_loss: 1.1544 - val_accuracy: 0.7607\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.1584 - val_accuracy: 0.7350\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.1634 - val_accuracy: 0.7607\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1637 - val_accuracy: 0.7350\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1582 - val_accuracy: 0.7350\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2444 - accuracy: 0.8481 - val_loss: 1.1637 - val_accuracy: 0.7350\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.1578 - val_accuracy: 0.7607\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.1533 - val_accuracy: 0.7607\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.1678 - val_accuracy: 0.7607\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2413 - accuracy: 0.8741 - val_loss: 1.1533 - val_accuracy: 0.7350\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.1478 - val_accuracy: 0.7607\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.1467 - val_accuracy: 0.7607\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.1416 - val_accuracy: 0.7607\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 1.1510 - val_accuracy: 0.7607\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2464 - accuracy: 0.8444 - val_loss: 1.1670 - val_accuracy: 0.7179\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2404 - accuracy: 0.8704 - val_loss: 1.1442 - val_accuracy: 0.7607\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.1453 - val_accuracy: 0.7607\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.1511 - val_accuracy: 0.7607\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.1493 - val_accuracy: 0.7350\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.1676 - val_accuracy: 0.7179\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 268us/step - loss: 0.2440 - accuracy: 0.8667 - val_loss: 1.1549 - val_accuracy: 0.7607\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.84 - 0s 167us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.1457 - val_accuracy: 0.7607\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.1390 - val_accuracy: 0.7607\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.1712 - val_accuracy: 0.7179\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2467 - accuracy: 0.8667 - val_loss: 1.1449 - val_accuracy: 0.7607\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.1405 - val_accuracy: 0.7607\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1652 - val_accuracy: 0.7350\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1591 - val_accuracy: 0.7350\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2409 - accuracy: 0.8741 - val_loss: 1.1518 - val_accuracy: 0.7692\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 1.1508 - val_accuracy: 0.7607\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1500 - val_accuracy: 0.7607\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.1537 - val_accuracy: 0.7350\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.1771 - val_accuracy: 0.7350\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2459 - accuracy: 0.8481 - val_loss: 1.1644 - val_accuracy: 0.7350\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.1408 - val_accuracy: 0.7607\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 318us/step - loss: 0.2440 - accuracy: 0.8741 - val_loss: 1.1628 - val_accuracy: 0.7350\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 328us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1562 - val_accuracy: 0.7350\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1477 - val_accuracy: 0.7607\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2400 - accuracy: 0.8741 - val_loss: 1.1612 - val_accuracy: 0.7350\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2452 - accuracy: 0.8519 - val_loss: 1.1620 - val_accuracy: 0.7179\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1564 - val_accuracy: 0.7607\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.1550 - val_accuracy: 0.7692\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.1577 - val_accuracy: 0.7607\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.1720 - val_accuracy: 0.7350\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1484 - val_accuracy: 0.7692\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.1444 - val_accuracy: 0.7692\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.1694 - val_accuracy: 0.7350\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2457 - accuracy: 0.8630 - val_loss: 1.1660 - val_accuracy: 0.7350\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2393 - accuracy: 0.8815 - val_loss: 1.1599 - val_accuracy: 0.7607\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.1510 - val_accuracy: 0.7607\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2528 - accuracy: 0.8741 - val_loss: 1.1668 - val_accuracy: 0.7350\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.1388 - val_accuracy: 0.7607\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.1422 - val_accuracy: 0.7350\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.1566 - val_accuracy: 0.7350\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2504 - accuracy: 0.8444 - val_loss: 1.1463 - val_accuracy: 0.7350\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.1364 - val_accuracy: 0.7607\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.1530 - val_accuracy: 0.7350\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 1.1631 - val_accuracy: 0.7607\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.1521 - val_accuracy: 0.7350\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 1.1884 - val_accuracy: 0.7179\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 1.1520 - val_accuracy: 0.7607\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1597 - val_accuracy: 0.7607\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2478 - accuracy: 0.8667 - val_loss: 1.1818 - val_accuracy: 0.6923\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.1595 - val_accuracy: 0.7350\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.1621 - val_accuracy: 0.7607\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2417 - accuracy: 0.8704 - val_loss: 1.1667 - val_accuracy: 0.7350\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 121us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1780 - val_accuracy: 0.7350\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.1645 - val_accuracy: 0.7607\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2399 - accuracy: 0.8704 - val_loss: 1.1639 - val_accuracy: 0.7350\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2405 - accuracy: 0.8741 - val_loss: 1.1666 - val_accuracy: 0.7607\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1690 - val_accuracy: 0.7607\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.1695 - val_accuracy: 0.7607\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1676 - val_accuracy: 0.7350\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1689 - val_accuracy: 0.7350\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.1763 - val_accuracy: 0.7350\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 347us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.1687 - val_accuracy: 0.7607\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2401 - accuracy: 0.8667 - val_loss: 1.1726 - val_accuracy: 0.7350\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.1656 - val_accuracy: 0.7692\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.1639 - val_accuracy: 0.7607\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 459us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.1725 - val_accuracy: 0.7350\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.1762 - val_accuracy: 0.7350\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.1717 - val_accuracy: 0.7350\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.1659 - val_accuracy: 0.7607\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.1750 - val_accuracy: 0.7607\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2493 - accuracy: 0.8556 - val_loss: 1.1899 - val_accuracy: 0.7350\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2492 - accuracy: 0.8593 - val_loss: 1.1727 - val_accuracy: 0.7607\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.1811 - val_accuracy: 0.7350\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.1700 - val_accuracy: 0.7350\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.1633 - val_accuracy: 0.7350\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1641 - val_accuracy: 0.7350\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.1737 - val_accuracy: 0.7350\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1721 - val_accuracy: 0.7607\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2417 - accuracy: 0.8741 - val_loss: 1.1674 - val_accuracy: 0.7607\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.1776 - val_accuracy: 0.7350\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.1756 - val_accuracy: 0.7607\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.1600 - val_accuracy: 0.7607\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.1645 - val_accuracy: 0.7607\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.1762 - val_accuracy: 0.7350\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.1613 - val_accuracy: 0.7607\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1687 - val_accuracy: 0.7607\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2481 - accuracy: 0.8667 - val_loss: 1.1906 - val_accuracy: 0.7179\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2433 - accuracy: 0.8667 - val_loss: 1.1684 - val_accuracy: 0.7350\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2449 - accuracy: 0.8704 - val_loss: 1.1673 - val_accuracy: 0.7607\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.1701 - val_accuracy: 0.7607\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2461 - accuracy: 0.8630 - val_loss: 1.1807 - val_accuracy: 0.7350\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2478 - accuracy: 0.8704 - val_loss: 1.1754 - val_accuracy: 0.7350\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.1661 - val_accuracy: 0.7607\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.1765 - val_accuracy: 0.7350\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.1735 - val_accuracy: 0.7607\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.1785 - val_accuracy: 0.7350\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.1718 - val_accuracy: 0.7607\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.1829 - val_accuracy: 0.7350\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.1675 - val_accuracy: 0.7607\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.1814 - val_accuracy: 0.7350\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2433 - accuracy: 0.8481 - val_loss: 1.1795 - val_accuracy: 0.7350\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2397 - accuracy: 0.8741 - val_loss: 1.1651 - val_accuracy: 0.7607\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.1701 - val_accuracy: 0.7607\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.1862 - val_accuracy: 0.7350\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.1714 - val_accuracy: 0.7607\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.1727 - val_accuracy: 0.7607\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1931 - val_accuracy: 0.7179\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2391 - accuracy: 0.8741 - val_loss: 1.1750 - val_accuracy: 0.7607\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.1794 - val_accuracy: 0.7607\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.1932 - val_accuracy: 0.7607\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2409 - accuracy: 0.8704 - val_loss: 1.1780 - val_accuracy: 0.7607\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.1828 - val_accuracy: 0.7607\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.1813 - val_accuracy: 0.7607\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.1860 - val_accuracy: 0.7607\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2404 - accuracy: 0.8667 - val_loss: 1.1792 - val_accuracy: 0.7692\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2460 - accuracy: 0.8630 - val_loss: 1.1904 - val_accuracy: 0.7350\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.1771 - val_accuracy: 0.7607\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.1793 - val_accuracy: 0.7607\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.1741 - val_accuracy: 0.7607\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2424 - accuracy: 0.8667 - val_loss: 1.1931 - val_accuracy: 0.7179\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2446 - accuracy: 0.8667 - val_loss: 1.1671 - val_accuracy: 0.7692\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2451 - accuracy: 0.8889 - val_loss: 1.1822 - val_accuracy: 0.7350\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.1712 - val_accuracy: 0.7607\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.1847 - val_accuracy: 0.7350\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.1821 - val_accuracy: 0.7350\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.1806 - val_accuracy: 0.7350\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.1860 - val_accuracy: 0.7350\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.1842 - val_accuracy: 0.7350\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.1772 - val_accuracy: 0.7607\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.1930 - val_accuracy: 0.7350\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.1856 - val_accuracy: 0.7607\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.1813 - val_accuracy: 0.7607\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 303us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 1.1813 - val_accuracy: 0.7265\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.1949 - val_accuracy: 0.7350\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2449 - accuracy: 0.8519 - val_loss: 1.1885 - val_accuracy: 0.7350\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.1890 - val_accuracy: 0.7607\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.1881 - val_accuracy: 0.7607\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2396 - accuracy: 0.8704 - val_loss: 1.1748 - val_accuracy: 0.7607\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.1931 - val_accuracy: 0.7350\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.1871 - val_accuracy: 0.7350\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.1689 - val_accuracy: 0.7607\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.1755 - val_accuracy: 0.7607\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2497 - accuracy: 0.8556 - val_loss: 1.2145 - val_accuracy: 0.6752\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2588 - accuracy: 0.8630 - val_loss: 1.1838 - val_accuracy: 0.7607\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 1.1964 - val_accuracy: 0.7350\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2521 - accuracy: 0.8741 - val_loss: 1.1822 - val_accuracy: 0.7607\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.1834 - val_accuracy: 0.7350\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2426 - accuracy: 0.8704 - val_loss: 1.1854 - val_accuracy: 0.7692\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2419 - accuracy: 0.8667 - val_loss: 1.1836 - val_accuracy: 0.7436\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.1874 - val_accuracy: 0.7350\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.1946 - val_accuracy: 0.7350\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2449 - accuracy: 0.8704 - val_loss: 1.1922 - val_accuracy: 0.7607\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2443 - accuracy: 0.8704 - val_loss: 1.1806 - val_accuracy: 0.7607\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.1968 - val_accuracy: 0.7350\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.1887 - val_accuracy: 0.7350\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.1838 - val_accuracy: 0.7607\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.1955 - val_accuracy: 0.7350\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.1899 - val_accuracy: 0.7607\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.1889 - val_accuracy: 0.7607\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.1937 - val_accuracy: 0.7350\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.1894 - val_accuracy: 0.7607\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.2062 - val_accuracy: 0.7350\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 244us/step - loss: 0.2486 - accuracy: 0.8704 - val_loss: 1.1840 - val_accuracy: 0.7607\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.2044 - val_accuracy: 0.7350\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2472 - accuracy: 0.8519 - val_loss: 1.2162 - val_accuracy: 0.7350\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2381 - accuracy: 0.8778 - val_loss: 1.1922 - val_accuracy: 0.7607\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.2515 - accuracy: 0.8630 - val_loss: 1.1856 - val_accuracy: 0.7692\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.2143 - val_accuracy: 0.6923\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 1.1863 - val_accuracy: 0.7607\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 1.1973 - val_accuracy: 0.7436\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2489 - accuracy: 0.8630 - val_loss: 1.1778 - val_accuracy: 0.7692\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.1671 - val_accuracy: 0.7607\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.1882 - val_accuracy: 0.7350\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2478 - accuracy: 0.8667 - val_loss: 1.1717 - val_accuracy: 0.7350\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2420 - accuracy: 0.8704 - val_loss: 1.1607 - val_accuracy: 0.7607\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.1686 - val_accuracy: 0.7350\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.1743 - val_accuracy: 0.7350\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2396 - accuracy: 0.8741 - val_loss: 1.1671 - val_accuracy: 0.7692\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.1749 - val_accuracy: 0.7607\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.1931 - val_accuracy: 0.7607\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.1930 - val_accuracy: 0.7350\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.1784 - val_accuracy: 0.7607\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.2013 - val_accuracy: 0.7350\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.1897 - val_accuracy: 0.7607\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2413 - accuracy: 0.8704 - val_loss: 1.1853 - val_accuracy: 0.7607\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.1913 - val_accuracy: 0.7350\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2395 - accuracy: 0.8741 - val_loss: 1.1893 - val_accuracy: 0.7350\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 1.1858 - val_accuracy: 0.7607\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2450 - accuracy: 0.8630 - val_loss: 1.1957 - val_accuracy: 0.7350\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.1841 - val_accuracy: 0.7607\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.2037 - val_accuracy: 0.7607\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.2000 - val_accuracy: 0.7350\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.1929 - val_accuracy: 0.7607\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.1905 - val_accuracy: 0.7607\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.1971 - val_accuracy: 0.7607\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.2015 - val_accuracy: 0.7350\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.1941 - val_accuracy: 0.7607\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.1944 - val_accuracy: 0.7607\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.1871 - val_accuracy: 0.7692\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 1.1933 - val_accuracy: 0.7350\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.2032 - val_accuracy: 0.7350\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.2017 - val_accuracy: 0.7350\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.1986 - val_accuracy: 0.7350\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.1978 - val_accuracy: 0.7607\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.2096 - val_accuracy: 0.7607\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 276us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2020 - val_accuracy: 0.7607\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2052 - val_accuracy: 0.7607\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.2153 - val_accuracy: 0.7350\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.2127 - val_accuracy: 0.7350\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.2179 - val_accuracy: 0.7350\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2504 - accuracy: 0.8741 - val_loss: 1.1971 - val_accuracy: 0.7692\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.2259 - val_accuracy: 0.7179\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2434 - accuracy: 0.8593 - val_loss: 1.2094 - val_accuracy: 0.7692\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.2082 - val_accuracy: 0.7607\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2171 - val_accuracy: 0.7350\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.2210 - val_accuracy: 0.7350\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2025 - val_accuracy: 0.7350\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.1970 - val_accuracy: 0.7607\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.2192 - val_accuracy: 0.7350\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.2091 - val_accuracy: 0.7350\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.2149 - val_accuracy: 0.7350\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.2069 - val_accuracy: 0.7692\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2468 - accuracy: 0.8704 - val_loss: 1.2154 - val_accuracy: 0.7607\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.2212 - val_accuracy: 0.7350\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.2235 - val_accuracy: 0.7350\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 341us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.2041 - val_accuracy: 0.7607\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.2160 - val_accuracy: 0.7350\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 338us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2122 - val_accuracy: 0.7350\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2028 - val_accuracy: 0.7692\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2467 - accuracy: 0.8704 - val_loss: 1.2238 - val_accuracy: 0.7350\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.2263 - val_accuracy: 0.7350\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.2196 - val_accuracy: 0.7350\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.2220 - val_accuracy: 0.7607\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.2197 - val_accuracy: 0.7350\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.2076 - val_accuracy: 0.7607\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.2158 - val_accuracy: 0.7350\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.2097 - val_accuracy: 0.7350\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2418 - accuracy: 0.8630 - val_loss: 1.2151 - val_accuracy: 0.7350\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2448 - accuracy: 0.8667 - val_loss: 1.2116 - val_accuracy: 0.7607\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.2107 - val_accuracy: 0.7350\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.2116 - val_accuracy: 0.7607\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.2079 - val_accuracy: 0.7607\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2403 - accuracy: 0.8704 - val_loss: 1.2265 - val_accuracy: 0.7179\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2436 - accuracy: 0.8667 - val_loss: 1.2180 - val_accuracy: 0.7350\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.2040 - val_accuracy: 0.7607\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.2099 - val_accuracy: 0.7436\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2444 - accuracy: 0.8630 - val_loss: 1.2196 - val_accuracy: 0.7350\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.2049 - val_accuracy: 0.7607\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2233 - val_accuracy: 0.7350\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2387 - accuracy: 0.8778 - val_loss: 1.2177 - val_accuracy: 0.7350\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.2128 - val_accuracy: 0.7350\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.2083 - val_accuracy: 0.7607\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.84 - 0s 108us/step - loss: 0.2470 - accuracy: 0.8519 - val_loss: 1.2193 - val_accuracy: 0.7350\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.2019 - val_accuracy: 0.7607\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2149 - val_accuracy: 0.7350\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.2212 - val_accuracy: 0.7350\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.2060 - val_accuracy: 0.7607\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.2229 - val_accuracy: 0.7179\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.2119 - val_accuracy: 0.7607\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.2143 - val_accuracy: 0.7607\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.2250 - val_accuracy: 0.7607\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.2222 - val_accuracy: 0.7350\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2407 - accuracy: 0.8741 - val_loss: 1.2205 - val_accuracy: 0.7692\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.2284 - val_accuracy: 0.7350\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.2284 - val_accuracy: 0.7350\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2205 - val_accuracy: 0.7607\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.2305 - val_accuracy: 0.7350\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2401 - accuracy: 0.8741 - val_loss: 1.2157 - val_accuracy: 0.7607\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.2108 - val_accuracy: 0.7350\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.2125 - val_accuracy: 0.7607\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2472 - accuracy: 0.8519 - val_loss: 1.2252 - val_accuracy: 0.7179\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2535 - accuracy: 0.8741 - val_loss: 1.2049 - val_accuracy: 0.7607\n",
      "Epoch 580/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 84us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.2314 - val_accuracy: 0.7350\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2439 - accuracy: 0.8667 - val_loss: 1.2122 - val_accuracy: 0.7350\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 1.1966 - val_accuracy: 0.7692\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 320us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.2170 - val_accuracy: 0.7350\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.2200 - val_accuracy: 0.7350\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.93 - 0s 129us/step - loss: 0.2436 - accuracy: 0.8852 - val_loss: 1.2069 - val_accuracy: 0.7607\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.2230 - val_accuracy: 0.7350\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.1997 - val_accuracy: 0.7692\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 444us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.2140 - val_accuracy: 0.7607\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.2228 - val_accuracy: 0.7350\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 271us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.2191 - val_accuracy: 0.7607\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.2275 - val_accuracy: 0.7607\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.2317 - val_accuracy: 0.7607\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.2179 - val_accuracy: 0.7607\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.2225 - val_accuracy: 0.7350\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.2195 - val_accuracy: 0.7607\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2367 - accuracy: 0.8778 - val_loss: 1.2269 - val_accuracy: 0.7607\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.2227 - val_accuracy: 0.7607\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 1.2209 - val_accuracy: 0.7350\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.2275 - val_accuracy: 0.7350\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.2217 - val_accuracy: 0.7692\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2275 - val_accuracy: 0.7350\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.2307 - val_accuracy: 0.7350\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.2289 - val_accuracy: 0.7350\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2388 - accuracy: 0.8778 - val_loss: 1.2351 - val_accuracy: 0.7350\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2401 - accuracy: 0.8815 - val_loss: 1.2239 - val_accuracy: 0.7607\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.2156 - val_accuracy: 0.7607\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2416 - accuracy: 0.8704 - val_loss: 1.2141 - val_accuracy: 0.7436\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2413 - accuracy: 0.8741 - val_loss: 1.2205 - val_accuracy: 0.7350\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2462 - accuracy: 0.8630 - val_loss: 1.2341 - val_accuracy: 0.7350\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.2153 - val_accuracy: 0.7607\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2464 - accuracy: 0.8704 - val_loss: 1.2107 - val_accuracy: 0.7692\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2419 - accuracy: 0.8704 - val_loss: 1.2332 - val_accuracy: 0.7350\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.2266 - val_accuracy: 0.7350\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.2194 - val_accuracy: 0.7607\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2473 - accuracy: 0.8704 - val_loss: 1.2426 - val_accuracy: 0.6923\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.2289 - val_accuracy: 0.7607\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.2238 - val_accuracy: 0.7350\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.2145 - val_accuracy: 0.7607\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.2374 - val_accuracy: 0.7350\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.2245 - val_accuracy: 0.7607\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.87 - 0s 102us/step - loss: 0.2404 - accuracy: 0.8741 - val_loss: 1.2204 - val_accuracy: 0.7607\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.2303 - val_accuracy: 0.7350\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 1.2353 - val_accuracy: 0.7350\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2446 - accuracy: 0.8593 - val_loss: 1.2472 - val_accuracy: 0.6923\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.2203 - val_accuracy: 0.7607\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2407 - accuracy: 0.8741 - val_loss: 1.2248 - val_accuracy: 0.7350\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.2383 - val_accuracy: 0.7350\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.2306 - val_accuracy: 0.7350\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.2249 - val_accuracy: 0.7607\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 319us/step - loss: 0.2380 - accuracy: 0.8778 - val_loss: 1.2312 - val_accuracy: 0.7607\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2403 - accuracy: 0.8741 - val_loss: 1.2465 - val_accuracy: 0.7350\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2430 - accuracy: 0.8704 - val_loss: 1.2224 - val_accuracy: 0.7692\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2413 - accuracy: 0.8704 - val_loss: 1.2231 - val_accuracy: 0.7350\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.2363 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.2224 - val_accuracy: 0.7607\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.2201 - val_accuracy: 0.7350\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.2116 - val_accuracy: 0.7607\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2481 - accuracy: 0.8741 - val_loss: 1.2260 - val_accuracy: 0.7350\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.2258 - val_accuracy: 0.7350\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2452 - accuracy: 0.8593 - val_loss: 1.2332 - val_accuracy: 0.7350\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2394 - accuracy: 0.8815 - val_loss: 1.2289 - val_accuracy: 0.7607\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.2320 - val_accuracy: 0.7607\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.2357 - val_accuracy: 0.7350\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2334 - val_accuracy: 0.7607\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2392 - val_accuracy: 0.7607\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2457 - accuracy: 0.8741 - val_loss: 1.2276 - val_accuracy: 0.7607\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2423 - val_accuracy: 0.7607\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2438 - val_accuracy: 0.7607\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.2387 - val_accuracy: 0.7607\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.2430 - val_accuracy: 0.7350\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.2357 - val_accuracy: 0.7350\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2431 - val_accuracy: 0.7350\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2481 - accuracy: 0.8481 - val_loss: 1.2443 - val_accuracy: 0.7350\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.2230 - val_accuracy: 0.7692\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.2193 - val_accuracy: 0.7607\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2449 - accuracy: 0.8630 - val_loss: 1.2274 - val_accuracy: 0.7350\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.2477 - val_accuracy: 0.7350\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2347 - val_accuracy: 0.7350\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2463 - accuracy: 0.8704 - val_loss: 1.2275 - val_accuracy: 0.7692\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2424 - accuracy: 0.8704 - val_loss: 1.2404 - val_accuracy: 0.7350\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 571us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.2480 - val_accuracy: 0.7350\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.2455 - accuracy: 0.8741 - val_loss: 1.2429 - val_accuracy: 0.7607\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2493 - val_accuracy: 0.7350\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2346 - val_accuracy: 0.7607\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.2369 - val_accuracy: 0.7607\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.2347 - val_accuracy: 0.7607\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.2285 - val_accuracy: 0.7607\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2468 - accuracy: 0.8556 - val_loss: 1.2539 - val_accuracy: 0.7179\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2447 - accuracy: 0.8852 - val_loss: 1.2410 - val_accuracy: 0.7607\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.2329 - val_accuracy: 0.7607\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.2529 - val_accuracy: 0.7607\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.2496 - val_accuracy: 0.7350\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.84 - 0s 134us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.2529 - val_accuracy: 0.7350\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2397 - accuracy: 0.8815 - val_loss: 1.2385 - val_accuracy: 0.7607\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2454 - accuracy: 0.8704 - val_loss: 1.2281 - val_accuracy: 0.7607\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2516 - accuracy: 0.8593 - val_loss: 1.2540 - val_accuracy: 0.6923\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2332 - val_accuracy: 0.7607\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.2447 - val_accuracy: 0.7607\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.2563 - val_accuracy: 0.7350\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2409 - val_accuracy: 0.7607\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.2368 - val_accuracy: 0.7607\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.2360 - val_accuracy: 0.7350\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.2495 - val_accuracy: 0.7607\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.2493 - val_accuracy: 0.7607\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.2544 - val_accuracy: 0.7350\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2391 - accuracy: 0.8778 - val_loss: 1.2381 - val_accuracy: 0.7350\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.2398 - val_accuracy: 0.7607\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.2423 - val_accuracy: 0.7607\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.2413 - val_accuracy: 0.7607\n",
      "Epoch 690/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 100us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.2416 - val_accuracy: 0.7350\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.2475 - val_accuracy: 0.7350\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2385 - accuracy: 0.8778 - val_loss: 1.2389 - val_accuracy: 0.7692\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2471 - accuracy: 0.8667 - val_loss: 1.2434 - val_accuracy: 0.7436\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.2480 - val_accuracy: 0.7607\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2454 - accuracy: 0.8667 - val_loss: 1.2587 - val_accuracy: 0.7350\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.2439 - val_accuracy: 0.7350\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2377 - val_accuracy: 0.7607\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2435 - accuracy: 0.8741 - val_loss: 1.2581 - val_accuracy: 0.7607\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.2403 - val_accuracy: 0.7607\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.2426 - val_accuracy: 0.7607\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.2459 - val_accuracy: 0.7607\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.2440 - val_accuracy: 0.7607\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.2405 - val_accuracy: 0.7607\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2439 - accuracy: 0.8741 - val_loss: 1.2635 - val_accuracy: 0.7350\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.2491 - val_accuracy: 0.7607\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.2515 - val_accuracy: 0.7350\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2480 - val_accuracy: 0.7607\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.2562 - val_accuracy: 0.7350\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.2661 - val_accuracy: 0.7350\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2417 - accuracy: 0.8704 - val_loss: 1.2626 - val_accuracy: 0.7094\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.2503 - val_accuracy: 0.7350\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2384 - accuracy: 0.8778 - val_loss: 1.2569 - val_accuracy: 0.7350\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.2582 - val_accuracy: 0.7350\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.2420 - val_accuracy: 0.7607\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.2534 - val_accuracy: 0.7350\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2624 - val_accuracy: 0.7607\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.2557 - val_accuracy: 0.7607\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.2688 - val_accuracy: 0.7350\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2518 - val_accuracy: 0.7607\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.2537 - val_accuracy: 0.7607\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.2723 - val_accuracy: 0.7350\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.2521 - val_accuracy: 0.7350\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2422 - accuracy: 0.8704 - val_loss: 1.2545 - val_accuracy: 0.7350\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.2490 - val_accuracy: 0.7607\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2573 - val_accuracy: 0.7607\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.2647 - val_accuracy: 0.7350\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.2513 - val_accuracy: 0.7607\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.2576 - val_accuracy: 0.7607\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.2766 - val_accuracy: 0.7607\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.2680 - val_accuracy: 0.7607\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2524 - val_accuracy: 0.7607\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.2579 - val_accuracy: 0.7350\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2600 - val_accuracy: 0.7350\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2568 - val_accuracy: 0.7607\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2452 - accuracy: 0.8704 - val_loss: 1.2524 - val_accuracy: 0.7692\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.2853 - val_accuracy: 0.7179\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2443 - accuracy: 0.8704 - val_loss: 1.2546 - val_accuracy: 0.7607\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.2566 - val_accuracy: 0.7607\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.2586 - val_accuracy: 0.7350\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2449 - accuracy: 0.8556 - val_loss: 1.2779 - val_accuracy: 0.7179\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2390 - accuracy: 0.8815 - val_loss: 1.2592 - val_accuracy: 0.7692\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2442 - accuracy: 0.8741 - val_loss: 1.2683 - val_accuracy: 0.7607\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.2768 - val_accuracy: 0.7607\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.2753 - val_accuracy: 0.7607\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.2618 - val_accuracy: 0.7607\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.2646 - val_accuracy: 0.7607\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2386 - accuracy: 0.8778 - val_loss: 1.2898 - val_accuracy: 0.7607\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.2649 - val_accuracy: 0.7607\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.2671 - val_accuracy: 0.7607\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.2789 - val_accuracy: 0.7607\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.2893 - val_accuracy: 0.7350\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2414 - accuracy: 0.8704 - val_loss: 1.2767 - val_accuracy: 0.7350\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.2756 - val_accuracy: 0.7607\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.2802 - val_accuracy: 0.7607\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2909 - val_accuracy: 0.7350\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2901 - val_accuracy: 0.7350\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.2725 - val_accuracy: 0.7607\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.2727 - val_accuracy: 0.7607\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.2597 - val_accuracy: 0.7607\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2667 - val_accuracy: 0.7607\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.2803 - val_accuracy: 0.7350\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.2782 - val_accuracy: 0.7350\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.2869 - val_accuracy: 0.7607\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 1.2835 - val_accuracy: 0.7350\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2398 - accuracy: 0.8741 - val_loss: 1.2965 - val_accuracy: 0.7350\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2474 - accuracy: 0.8630 - val_loss: 1.2943 - val_accuracy: 0.7350\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.2697 - val_accuracy: 0.7607\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.2789 - val_accuracy: 0.7350\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2428 - accuracy: 0.8704 - val_loss: 1.2943 - val_accuracy: 0.7094\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.3026 - val_accuracy: 0.7350\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2417 - accuracy: 0.8741 - val_loss: 1.2848 - val_accuracy: 0.7607\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.2732 - val_accuracy: 0.7607\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.2889 - val_accuracy: 0.7350\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2541 - accuracy: 0.8741 - val_loss: 1.2713 - val_accuracy: 0.7350\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2479 - accuracy: 0.8741 - val_loss: 1.2901 - val_accuracy: 0.7350\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2401 - accuracy: 0.8704 - val_loss: 1.2688 - val_accuracy: 0.7350\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.2717 - val_accuracy: 0.7607\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.2819 - val_accuracy: 0.7607\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 1.2920 - val_accuracy: 0.7607\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2776 - val_accuracy: 0.7607\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.2834 - val_accuracy: 0.7607\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2916 - val_accuracy: 0.7607\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.2921 - val_accuracy: 0.7607\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2852 - val_accuracy: 0.7607\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.2882 - val_accuracy: 0.7607\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.2765 - val_accuracy: 0.7607\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.2806 - val_accuracy: 0.7607\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.2881 - val_accuracy: 0.7350\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.2834 - val_accuracy: 0.7607\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2401 - accuracy: 0.8741 - val_loss: 1.2899 - val_accuracy: 0.7607\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.90 - 0s 128us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.2842 - val_accuracy: 0.7607\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2429 - accuracy: 0.8741 - val_loss: 1.2941 - val_accuracy: 0.7350\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.2835 - val_accuracy: 0.7350\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.2822 - val_accuracy: 0.7607\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2945 - val_accuracy: 0.7350\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.2855 - val_accuracy: 0.7607\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.3034 - val_accuracy: 0.7607\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.2943 - val_accuracy: 0.7607\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.2907 - val_accuracy: 0.7607\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 100us/step - loss: 0.2452 - accuracy: 0.8481 - val_loss: 1.2998 - val_accuracy: 0.7350\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2413 - accuracy: 0.8704 - val_loss: 1.2855 - val_accuracy: 0.7607\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.2889 - val_accuracy: 0.7607\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.2931 - val_accuracy: 0.7350\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2401 - accuracy: 0.8741 - val_loss: 1.2872 - val_accuracy: 0.7607\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.2870 - val_accuracy: 0.7607\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.2888 - val_accuracy: 0.7350\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.2832 - val_accuracy: 0.7607\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 1.2853 - val_accuracy: 0.7607\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2400 - accuracy: 0.8741 - val_loss: 1.3004 - val_accuracy: 0.7607\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.2941 - val_accuracy: 0.7607\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.2835 - val_accuracy: 0.7350\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.2883 - val_accuracy: 0.7607\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.2921 - val_accuracy: 0.7607\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.2866 - val_accuracy: 0.7607\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.2489 - val_accuracy: 0.7607\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2357 - val_accuracy: 0.7607\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.2396 - val_accuracy: 0.7607\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2394 - accuracy: 0.8741 - val_loss: 1.2490 - val_accuracy: 0.7350\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.2508 - val_accuracy: 0.7607\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.2558 - val_accuracy: 0.7607\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.2691 - val_accuracy: 0.7607\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.2703 - val_accuracy: 0.7350\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2454 - accuracy: 0.8630 - val_loss: 1.2765 - val_accuracy: 0.7350\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2392 - accuracy: 0.8741 - val_loss: 1.2697 - val_accuracy: 0.7607\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.2811 - val_accuracy: 0.7607\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.2895 - val_accuracy: 0.7607\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2387 - accuracy: 0.8741 - val_loss: 1.2885 - val_accuracy: 0.7350\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.2770 - val_accuracy: 0.7350\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.2770 - val_accuracy: 0.7607\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.2761 - val_accuracy: 0.7607\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.2847 - val_accuracy: 0.7607\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2381 - accuracy: 0.8778 - val_loss: 1.2923 - val_accuracy: 0.7350\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2433 - accuracy: 0.8630 - val_loss: 1.2920 - val_accuracy: 0.7179\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.2985 - val_accuracy: 0.7607\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.2826 - val_accuracy: 0.7607\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.2917 - val_accuracy: 0.7607\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.3182 - val_accuracy: 0.7350\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2445 - accuracy: 0.8593 - val_loss: 1.2955 - val_accuracy: 0.7350\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2441 - accuracy: 0.8667 - val_loss: 1.2964 - val_accuracy: 0.7607\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.3001 - val_accuracy: 0.7607\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.3082 - val_accuracy: 0.7350\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2387 - accuracy: 0.8778 - val_loss: 1.3036 - val_accuracy: 0.7350\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.2952 - val_accuracy: 0.7607\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.3187 - val_accuracy: 0.7350\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.3080 - val_accuracy: 0.7350\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.3016 - val_accuracy: 0.7350\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2431 - accuracy: 0.8556 - val_loss: 1.3131 - val_accuracy: 0.7350\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.2986 - val_accuracy: 0.7692\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.3120 - val_accuracy: 0.7607\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.3106 - val_accuracy: 0.7607\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.3097 - val_accuracy: 0.7350\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2483 - accuracy: 0.8519 - val_loss: 1.3093 - val_accuracy: 0.7350\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2391 - accuracy: 0.8778 - val_loss: 1.2997 - val_accuracy: 0.7607\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.3067 - val_accuracy: 0.7607\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.3215 - val_accuracy: 0.7350\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.3202 - val_accuracy: 0.7350\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.3277 - val_accuracy: 0.7350\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.3103 - val_accuracy: 0.7607\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3110 - val_accuracy: 0.7607\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.3013 - val_accuracy: 0.7607\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.3057 - val_accuracy: 0.7350\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.3154 - val_accuracy: 0.7350\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2443 - accuracy: 0.8704 - val_loss: 1.3204 - val_accuracy: 0.7607\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2423 - accuracy: 0.8667 - val_loss: 1.3162 - val_accuracy: 0.7607\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.3347 - val_accuracy: 0.7350\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3198 - val_accuracy: 0.7350\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2441 - accuracy: 0.8741 - val_loss: 1.3110 - val_accuracy: 0.7607\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2400 - accuracy: 0.8778 - val_loss: 1.3215 - val_accuracy: 0.7350\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.3167 - val_accuracy: 0.7350\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.3062 - val_accuracy: 0.7350\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.3072 - val_accuracy: 0.7692\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3200 - val_accuracy: 0.7350\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.3115 - val_accuracy: 0.7350\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.3072 - val_accuracy: 0.7607\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2405 - accuracy: 0.8741 - val_loss: 1.3156 - val_accuracy: 0.7350\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2434 - accuracy: 0.8630 - val_loss: 1.3136 - val_accuracy: 0.7350\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2413 - accuracy: 0.8741 - val_loss: 1.3177 - val_accuracy: 0.7350\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 1.3122 - val_accuracy: 0.7607\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.3256 - val_accuracy: 0.7350\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.3160 - val_accuracy: 0.7607\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2436 - accuracy: 0.8667 - val_loss: 1.3109 - val_accuracy: 0.7607\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.3297 - val_accuracy: 0.7179\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2438 - accuracy: 0.8593 - val_loss: 1.3159 - val_accuracy: 0.7350\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.3134 - val_accuracy: 0.7350\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.3066 - val_accuracy: 0.7607\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2390 - accuracy: 0.8778 - val_loss: 1.3123 - val_accuracy: 0.7607\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.3139 - val_accuracy: 0.7607\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 1.3182 - val_accuracy: 0.7607\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2447 - accuracy: 0.8704 - val_loss: 1.3206 - val_accuracy: 0.7607\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.3141 - val_accuracy: 0.7607\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3175 - val_accuracy: 0.7607\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.3281 - val_accuracy: 0.7350\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2389 - accuracy: 0.8815 - val_loss: 1.3124 - val_accuracy: 0.7607\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.3161 - val_accuracy: 0.7607\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 1.3198 - val_accuracy: 0.7607\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.3245 - val_accuracy: 0.7607\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2441 - accuracy: 0.8704 - val_loss: 1.3297 - val_accuracy: 0.7350\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.3126 - val_accuracy: 0.7607\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.3288 - val_accuracy: 0.7350\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3325 - val_accuracy: 0.7350\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2404 - accuracy: 0.8741 - val_loss: 1.3186 - val_accuracy: 0.7607\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2385 - accuracy: 0.8778 - val_loss: 1.3151 - val_accuracy: 0.7607\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.3236 - val_accuracy: 0.7350\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.3210 - val_accuracy: 0.7607\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.3089 - val_accuracy: 0.7692\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2393 - accuracy: 0.8704 - val_loss: 1.3213 - val_accuracy: 0.7607\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2476 - accuracy: 0.8667 - val_loss: 1.3384 - val_accuracy: 0.7350\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.3200 - val_accuracy: 0.7607\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.3138 - val_accuracy: 0.7692\n",
      "Epoch 910/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 112us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.3304 - val_accuracy: 0.7607\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2388 - accuracy: 0.8778 - val_loss: 1.3280 - val_accuracy: 0.7607\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.3256 - val_accuracy: 0.7607\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.3242 - val_accuracy: 0.7350\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.3329 - val_accuracy: 0.7350\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.3311 - val_accuracy: 0.7350\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2475 - accuracy: 0.8556 - val_loss: 1.3246 - val_accuracy: 0.7692\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.3471 - val_accuracy: 0.7350\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2483 - accuracy: 0.8556 - val_loss: 1.3468 - val_accuracy: 0.7350\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.3267 - val_accuracy: 0.7607\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.3243 - val_accuracy: 0.7607\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.3321 - val_accuracy: 0.7350\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2409 - accuracy: 0.8741 - val_loss: 1.3215 - val_accuracy: 0.7350\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.3308 - val_accuracy: 0.7350\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2417 - accuracy: 0.8741 - val_loss: 1.3409 - val_accuracy: 0.7607\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.3277 - val_accuracy: 0.7607\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.3401 - val_accuracy: 0.7350\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.3344 - val_accuracy: 0.7350\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.3418 - val_accuracy: 0.7350\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.3273 - val_accuracy: 0.7607\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.3406 - val_accuracy: 0.7350\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2524 - accuracy: 0.8778 - val_loss: 1.3301 - val_accuracy: 0.7350\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.3304 - val_accuracy: 0.7607\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2389 - accuracy: 0.8778 - val_loss: 1.3255 - val_accuracy: 0.7692\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2412 - accuracy: 0.8704 - val_loss: 1.3331 - val_accuracy: 0.7350\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2419 - accuracy: 0.8741 - val_loss: 1.3336 - val_accuracy: 0.7350\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2410 - accuracy: 0.8556 - val_loss: 1.3338 - val_accuracy: 0.7350\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.3308 - val_accuracy: 0.7607\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.3198 - val_accuracy: 0.7607\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.3348 - val_accuracy: 0.7350\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2445 - accuracy: 0.8667 - val_loss: 1.3526 - val_accuracy: 0.7265\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2423 - accuracy: 0.8667 - val_loss: 1.3259 - val_accuracy: 0.7607\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2419 - accuracy: 0.8704 - val_loss: 1.3389 - val_accuracy: 0.7607\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2495 - accuracy: 0.8667 - val_loss: 1.3763 - val_accuracy: 0.7265\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.3371 - val_accuracy: 0.7607\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.3326 - val_accuracy: 0.7607\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2390 - accuracy: 0.8778 - val_loss: 1.3413 - val_accuracy: 0.7350\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.3423 - val_accuracy: 0.7350\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2395 - accuracy: 0.8778 - val_loss: 1.3303 - val_accuracy: 0.7607\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.3362 - val_accuracy: 0.7607\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2399 - accuracy: 0.8741 - val_loss: 1.3378 - val_accuracy: 0.7692\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2449 - accuracy: 0.8667 - val_loss: 1.3283 - val_accuracy: 0.7607\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2391 - accuracy: 0.8741 - val_loss: 1.3317 - val_accuracy: 0.7607\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2404 - accuracy: 0.8741 - val_loss: 1.3324 - val_accuracy: 0.7350\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.3287 - val_accuracy: 0.7607\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.3353 - val_accuracy: 0.7607\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.3264 - val_accuracy: 0.7607\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.3224 - val_accuracy: 0.7436\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3314 - val_accuracy: 0.7350\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.3384 - val_accuracy: 0.7350\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.3325 - val_accuracy: 0.7350\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.3354 - val_accuracy: 0.7350\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2392 - accuracy: 0.8741 - val_loss: 1.3344 - val_accuracy: 0.7607\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3362 - val_accuracy: 0.7607\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.3388 - val_accuracy: 0.7607\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.3401 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2452 - accuracy: 0.8519 - val_loss: 1.3512 - val_accuracy: 0.7350\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2457 - accuracy: 0.8741 - val_loss: 1.3396 - val_accuracy: 0.7350\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.3538 - val_accuracy: 0.7350\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 1.3357 - val_accuracy: 0.7607\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2462 - accuracy: 0.8556 - val_loss: 1.3461 - val_accuracy: 0.7179\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.3437 - val_accuracy: 0.7350\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3427 - val_accuracy: 0.7350\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3409 - val_accuracy: 0.7436\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2418 - accuracy: 0.8667 - val_loss: 1.3403 - val_accuracy: 0.7350\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2383 - accuracy: 0.8778 - val_loss: 1.3444 - val_accuracy: 0.7607\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.3455 - val_accuracy: 0.7607\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2405 - accuracy: 0.8741 - val_loss: 1.3537 - val_accuracy: 0.7350\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.3514 - val_accuracy: 0.7350\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.3396 - val_accuracy: 0.7350\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.3349 - val_accuracy: 0.7607\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.3391 - val_accuracy: 0.7607\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2396 - accuracy: 0.8741 - val_loss: 1.3486 - val_accuracy: 0.7350\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.3462 - val_accuracy: 0.7350\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2388 - accuracy: 0.8778 - val_loss: 1.3398 - val_accuracy: 0.7607\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2400 - accuracy: 0.8741 - val_loss: 1.3286 - val_accuracy: 0.7692\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.3439 - val_accuracy: 0.7607\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2388 - accuracy: 0.8815 - val_loss: 1.3592 - val_accuracy: 0.7350\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2456 - accuracy: 0.8630 - val_loss: 1.3506 - val_accuracy: 0.7350\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3476 - val_accuracy: 0.7350\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.3398 - val_accuracy: 0.7350\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2483 - accuracy: 0.8630 - val_loss: 1.3334 - val_accuracy: 0.7692\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2372 - accuracy: 0.8778 - val_loss: 1.3546 - val_accuracy: 0.7179\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2457 - accuracy: 0.8667 - val_loss: 1.3495 - val_accuracy: 0.7350\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2385 - accuracy: 0.8778 - val_loss: 1.3306 - val_accuracy: 0.7607\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.3330 - val_accuracy: 0.7607\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.3546 - val_accuracy: 0.7350\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.3456 - val_accuracy: 0.7350\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.3552 - val_accuracy: 0.7350\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.3511 - val_accuracy: 0.7350\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.3502 - val_accuracy: 0.7607\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 87.47%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40159790e-01, 2.21759930e-01, 6.38080300e-01],\n",
       "       [1.27951560e-03, 6.11688500e-01, 3.87032000e-01],\n",
       "       [1.14981000e-06, 6.30983500e-04, 9.99367900e-01],\n",
       "       [1.40159790e-01, 2.21759930e-01, 6.38080300e-01],\n",
       "       [1.51742340e-02, 9.84825800e-01, 8.66642550e-16],\n",
       "       [2.08744730e-05, 1.13796390e-04, 9.99865300e-01],\n",
       "       [2.66073170e-05, 6.04231000e-04, 9.99369200e-01],\n",
       "       [1.14000120e-02, 9.88586100e-01, 1.39110100e-05],\n",
       "       [9.95590000e-01, 4.16077400e-03, 2.49183070e-04],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [7.53085200e-07, 9.24056500e-12, 9.99999300e-01],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [9.31678650e-01, 2.58136280e-04, 6.80632900e-02],\n",
       "       [6.23062600e-01, 3.74073740e-01, 2.86369300e-03],\n",
       "       [9.99999900e-01, 9.80837950e-08, 1.29155950e-10],\n",
       "       [1.20944480e-10, 3.64184950e-08, 1.00000000e+00],\n",
       "       [1.73290820e-02, 7.19616700e-04, 9.81951360e-01],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [1.37134830e-04, 1.75191830e-02, 9.82343700e-01],\n",
       "       [2.82713850e-04, 9.98772900e-01, 9.44362300e-04],\n",
       "       [1.54629500e-03, 5.44091100e-03, 9.93012850e-01],\n",
       "       [1.32540540e-01, 5.78658000e-01, 2.88801520e-01],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [1.48173510e-02, 9.84982000e-01, 2.00671260e-04],\n",
       "       [4.11354330e-04, 3.07877050e-05, 9.99557800e-01],\n",
       "       [3.15704200e-01, 6.83492700e-01, 8.03133500e-04],\n",
       "       [7.53085200e-07, 9.24056500e-12, 9.99999300e-01],\n",
       "       [2.58078540e-03, 9.96810260e-01, 6.08957300e-04],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [1.35112740e-03, 6.19190340e-01, 3.79458520e-01],\n",
       "       [6.30496700e-08, 4.40959570e-01, 5.59040370e-01],\n",
       "       [1.32540540e-01, 5.78658000e-01, 2.88801520e-01],\n",
       "       [1.26345960e-03, 9.98733340e-01, 3.17890820e-06],\n",
       "       [5.59010800e-01, 4.19459370e-01, 2.15299130e-02],\n",
       "       [1.32540540e-01, 5.78658000e-01, 2.88801520e-01],\n",
       "       [3.15704200e-01, 6.83492700e-01, 8.03133500e-04],\n",
       "       [1.74639760e-06, 1.19371295e-08, 9.99998200e-01],\n",
       "       [6.17002400e-05, 2.49792060e-02, 9.74959000e-01],\n",
       "       [8.58708600e-01, 1.41291370e-01, 6.52401600e-17],\n",
       "       [9.93531300e-01, 6.46862340e-03, 6.92378140e-08],\n",
       "       [9.99999900e-01, 9.80837950e-08, 1.29155950e-10],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [4.60534410e-04, 4.14503260e-06, 9.99535300e-01],\n",
       "       [6.23062600e-01, 3.74073740e-01, 2.86369300e-03],\n",
       "       [1.40159790e-01, 2.21759930e-01, 6.38080300e-01],\n",
       "       [1.54629500e-03, 5.44091100e-03, 9.93012850e-01],\n",
       "       [6.17002400e-05, 2.49792060e-02, 9.74959000e-01],\n",
       "       [1.93056070e-02, 9.61676500e-01, 1.90178380e-02],\n",
       "       [9.99992130e-01, 6.75852930e-06, 1.08535370e-06],\n",
       "       [9.99800260e-01, 1.99697320e-04, 6.24199500e-14],\n",
       "       [1.40159790e-01, 2.21759930e-01, 6.38080300e-01],\n",
       "       [6.17002400e-05, 2.49792060e-02, 9.74959000e-01],\n",
       "       [1.00000000e+00, 1.63550900e-09, 9.79794600e-12],\n",
       "       [9.99995600e-01, 4.38343600e-06, 1.58899170e-08],\n",
       "       [1.09280770e-04, 9.99751600e-01, 1.39110130e-04],\n",
       "       [1.00000000e+00, 1.66855380e-11, 2.35659660e-10],\n",
       "       [1.09280770e-04, 9.99751600e-01, 1.39110130e-04],\n",
       "       [3.15704200e-01, 6.83492700e-01, 8.03133500e-04],\n",
       "       [1.04394620e-06, 1.00713560e-05, 9.99988900e-01],\n",
       "       [5.59127060e-06, 7.84619240e-11, 9.99994400e-01],\n",
       "       [6.30496700e-08, 4.40959570e-01, 5.59040370e-01],\n",
       "       [1.27951560e-03, 6.11688500e-01, 3.87032000e-01],\n",
       "       [1.35112740e-03, 6.19190340e-01, 3.79458520e-01],\n",
       "       [9.57178600e-01, 4.26853150e-02, 1.36105560e-04],\n",
       "       [1.32540540e-01, 5.78658000e-01, 2.88801520e-01],\n",
       "       [9.31645600e-04, 2.71565020e-03, 9.96352700e-01],\n",
       "       [1.35112740e-03, 6.19190340e-01, 3.79458520e-01],\n",
       "       [9.57178600e-01, 4.26853150e-02, 1.36105560e-04],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [6.23062600e-01, 3.74073740e-01, 2.86369300e-03],\n",
       "       [1.27951560e-03, 6.11688500e-01, 3.87032000e-01],\n",
       "       [8.71519400e-08, 2.42202800e-05, 9.99975700e-01],\n",
       "       [9.16728000e-01, 8.32719500e-02, 5.32853040e-10],\n",
       "       [3.15704200e-01, 6.83492700e-01, 8.03133500e-04],\n",
       "       [5.04179950e-01, 4.95820000e-01, 2.06556440e-10],\n",
       "       [3.16265240e-09, 1.17238600e-06, 9.99998800e-01],\n",
       "       [9.82166650e-01, 1.78330430e-02, 1.97578030e-07],\n",
       "       [9.99694700e-01, 3.05267430e-04, 7.74122700e-11],\n",
       "       [2.58078540e-03, 9.96810260e-01, 6.08957300e-04],\n",
       "       [1.33597430e-09, 3.43657660e-03, 9.96563400e-01],\n",
       "       [3.16722480e-01, 6.82809500e-01, 4.68022500e-04],\n",
       "       [1.33597430e-09, 3.43657660e-03, 9.96563400e-01],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [1.35112740e-03, 6.19190340e-01, 3.79458520e-01],\n",
       "       [9.99960540e-01, 3.93319240e-05, 9.23133000e-08],\n",
       "       [6.00208340e-01, 3.99788350e-01, 3.31982280e-06],\n",
       "       [9.97895840e-01, 1.82971210e-03, 2.74382470e-04],\n",
       "       [2.05407320e-08, 2.18796000e-03, 9.97812030e-01],\n",
       "       [9.96998550e-01, 3.00058350e-03, 9.74091600e-07],\n",
       "       [7.06675140e-03, 9.90585600e-01, 2.34751470e-03],\n",
       "       [9.99961850e-01, 3.81488100e-05, 3.78367820e-14],\n",
       "       [5.78414650e-02, 9.42156600e-01, 1.90155740e-06],\n",
       "       [8.59940500e-01, 1.39910820e-01, 1.48611450e-04],\n",
       "       [5.86661000e-10, 1.23844700e-06, 9.99998800e-01],\n",
       "       [6.30496700e-08, 4.40959570e-01, 5.59040370e-01],\n",
       "       [9.07537200e-03, 9.90873200e-01, 5.13427150e-05],\n",
       "       [6.30496700e-08, 4.40959570e-01, 5.59040370e-01],\n",
       "       [1.00000000e+00, 5.80195500e-13, 2.35617950e-13],\n",
       "       [1.41537700e-01, 8.58434300e-01, 2.80891450e-05],\n",
       "       [1.35112740e-03, 6.19190340e-01, 3.79458520e-01],\n",
       "       [9.68778900e-01, 3.12187650e-02, 2.31185900e-06],\n",
       "       [3.15704200e-01, 6.83492700e-01, 8.03133500e-04],\n",
       "       [9.99960540e-01, 3.93319240e-05, 9.23133000e-08],\n",
       "       [1.09002784e-01, 8.90997230e-01, 9.33638800e-10],\n",
       "       [4.11354330e-04, 3.07877050e-05, 9.99557800e-01],\n",
       "       [3.39259280e-03, 9.95863200e-01, 7.44267540e-04],\n",
       "       [1.74639760e-06, 1.19371295e-08, 9.99998200e-01],\n",
       "       [9.62847350e-01, 6.04142600e-03, 3.11111850e-02],\n",
       "       [1.48173510e-02, 9.84982000e-01, 2.00671260e-04],\n",
       "       [5.86661000e-10, 1.23844700e-06, 9.99998800e-01],\n",
       "       [1.13993610e-02, 3.90971000e-04, 9.88209600e-01],\n",
       "       [9.99740540e-01, 2.04682400e-04, 5.48709800e-05],\n",
       "       [1.85857510e-04, 2.58434240e-03, 9.97229750e-01],\n",
       "       [2.58078540e-03, 9.96810260e-01, 6.08957300e-04]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908612754766602"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908612754766602"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         SR4187     0\n",
       "1         NRS177     0\n",
       "2         NRS109     2\n",
       "3    CFBREBSa131     2\n",
       "4         SR4152     1\n",
       "..           ...   ...\n",
       "112       NRS110     2\n",
       "113     CFBRSa25     1\n",
       "114         834N     0\n",
       "115  CFBREBSa114     1\n",
       "116       NRS387     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 667us/step - loss: 1.1835 - accuracy: 0.3667 - val_loss: 1.0829 - val_accuracy: 0.3761\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 1.0273 - accuracy: 0.4630 - val_loss: 1.0095 - val_accuracy: 0.4786\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.9828 - accuracy: 0.5407 - val_loss: 0.9744 - val_accuracy: 0.5470\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.9499 - accuracy: 0.5667 - val_loss: 0.9436 - val_accuracy: 0.5897\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.9216 - accuracy: 0.5852 - val_loss: 0.9224 - val_accuracy: 0.6154\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.8981 - accuracy: 0.6148 - val_loss: 0.9089 - val_accuracy: 0.6154\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.8789 - accuracy: 0.6593 - val_loss: 0.8971 - val_accuracy: 0.6239\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8617 - accuracy: 0.6741 - val_loss: 0.8859 - val_accuracy: 0.6325\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.8448 - accuracy: 0.6926 - val_loss: 0.8784 - val_accuracy: 0.6325\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8310 - accuracy: 0.6852 - val_loss: 0.8686 - val_accuracy: 0.6325\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.8175 - accuracy: 0.6852 - val_loss: 0.8635 - val_accuracy: 0.6325\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.8041 - accuracy: 0.7296 - val_loss: 0.8543 - val_accuracy: 0.6410\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.7915 - accuracy: 0.7296 - val_loss: 0.8444 - val_accuracy: 0.6410\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.7805 - accuracy: 0.7185 - val_loss: 0.8352 - val_accuracy: 0.6581\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.7700 - accuracy: 0.6963 - val_loss: 0.8291 - val_accuracy: 0.6581\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7591 - accuracy: 0.7037 - val_loss: 0.8250 - val_accuracy: 0.6581\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.7504 - accuracy: 0.7148 - val_loss: 0.8219 - val_accuracy: 0.6581\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7424 - accuracy: 0.7185 - val_loss: 0.8136 - val_accuracy: 0.6581\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7311 - accuracy: 0.7111 - val_loss: 0.8067 - val_accuracy: 0.6496\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.7223 - accuracy: 0.7111 - val_loss: 0.7982 - val_accuracy: 0.6410\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.7151 - accuracy: 0.7074 - val_loss: 0.7958 - val_accuracy: 0.6410\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.7086 - accuracy: 0.7296 - val_loss: 0.7881 - val_accuracy: 0.6581\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.6988 - accuracy: 0.7259 - val_loss: 0.7837 - val_accuracy: 0.6410\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6911 - accuracy: 0.7296 - val_loss: 0.7763 - val_accuracy: 0.6410\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6861 - accuracy: 0.7259 - val_loss: 0.7751 - val_accuracy: 0.6410\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6840 - accuracy: 0.7259 - val_loss: 0.7715 - val_accuracy: 0.6496\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6699 - accuracy: 0.7333 - val_loss: 0.7636 - val_accuracy: 0.6410\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.6651 - accuracy: 0.7444 - val_loss: 0.7615 - val_accuracy: 0.6410\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6598 - accuracy: 0.7481 - val_loss: 0.7663 - val_accuracy: 0.6410\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.6523 - accuracy: 0.7556 - val_loss: 0.7516 - val_accuracy: 0.6410\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.6453 - accuracy: 0.7630 - val_loss: 0.7492 - val_accuracy: 0.6410\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.6415 - accuracy: 0.7667 - val_loss: 0.7490 - val_accuracy: 0.6410\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6367 - accuracy: 0.7556 - val_loss: 0.7382 - val_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.6283 - accuracy: 0.7593 - val_loss: 0.7358 - val_accuracy: 0.6410\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.6243 - accuracy: 0.7630 - val_loss: 0.7399 - val_accuracy: 0.6410\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6195 - accuracy: 0.7593 - val_loss: 0.7326 - val_accuracy: 0.6410\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6129 - accuracy: 0.7630 - val_loss: 0.7277 - val_accuracy: 0.6581\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.6070 - accuracy: 0.7593 - val_loss: 0.7266 - val_accuracy: 0.6496\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6053 - accuracy: 0.7593 - val_loss: 0.7219 - val_accuracy: 0.6581\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5993 - accuracy: 0.7704 - val_loss: 0.7154 - val_accuracy: 0.6581\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5929 - accuracy: 0.7778 - val_loss: 0.7171 - val_accuracy: 0.6496\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.5892 - accuracy: 0.7852 - val_loss: 0.7127 - val_accuracy: 0.6581\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.5850 - accuracy: 0.7778 - val_loss: 0.7166 - val_accuracy: 0.6410\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.5814 - accuracy: 0.7704 - val_loss: 0.7066 - val_accuracy: 0.6838\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5747 - accuracy: 0.7852 - val_loss: 0.7051 - val_accuracy: 0.6752\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5753 - accuracy: 0.7852 - val_loss: 0.7099 - val_accuracy: 0.6581\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 352us/step - loss: 0.5688 - accuracy: 0.7852 - val_loss: 0.7060 - val_accuracy: 0.6752\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 347us/step - loss: 0.5658 - accuracy: 0.7815 - val_loss: 0.6915 - val_accuracy: 0.6667\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 479us/step - loss: 0.5644 - accuracy: 0.7926 - val_loss: 0.6959 - val_accuracy: 0.6496\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 347us/step - loss: 0.5618 - accuracy: 0.7815 - val_loss: 0.7001 - val_accuracy: 0.6752\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5530 - accuracy: 0.7889 - val_loss: 0.6914 - val_accuracy: 0.6838\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.5482 - accuracy: 0.7852 - val_loss: 0.6872 - val_accuracy: 0.6496\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5443 - accuracy: 0.7778 - val_loss: 0.6863 - val_accuracy: 0.6667\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5415 - accuracy: 0.8000 - val_loss: 0.6883 - val_accuracy: 0.6752\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5382 - accuracy: 0.8000 - val_loss: 0.6811 - val_accuracy: 0.6838\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5339 - accuracy: 0.7926 - val_loss: 0.6827 - val_accuracy: 0.6667\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.5317 - accuracy: 0.7889 - val_loss: 0.6821 - val_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.5285 - accuracy: 0.8000 - val_loss: 0.6906 - val_accuracy: 0.6923\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.5251 - accuracy: 0.8074 - val_loss: 0.6839 - val_accuracy: 0.6923\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.5221 - accuracy: 0.7926 - val_loss: 0.6765 - val_accuracy: 0.6667\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.5239 - accuracy: 0.7963 - val_loss: 0.6686 - val_accuracy: 0.6752\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.5186 - accuracy: 0.8037 - val_loss: 0.6960 - val_accuracy: 0.7094\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5189 - accuracy: 0.8000 - val_loss: 0.6733 - val_accuracy: 0.6752\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.5112 - accuracy: 0.7889 - val_loss: 0.6725 - val_accuracy: 0.7009\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5093 - accuracy: 0.8000 - val_loss: 0.6675 - val_accuracy: 0.7265\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5085 - accuracy: 0.8074 - val_loss: 0.6835 - val_accuracy: 0.7094\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5031 - accuracy: 0.8148 - val_loss: 0.6687 - val_accuracy: 0.7350\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5021 - accuracy: 0.8037 - val_loss: 0.6662 - val_accuracy: 0.7436\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.4978 - accuracy: 0.8185 - val_loss: 0.6765 - val_accuracy: 0.7009\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.4967 - accuracy: 0.8074 - val_loss: 0.6727 - val_accuracy: 0.7009\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.4930 - accuracy: 0.8111 - val_loss: 0.6634 - val_accuracy: 0.7179\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.4891 - accuracy: 0.8111 - val_loss: 0.6742 - val_accuracy: 0.6923\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.4900 - accuracy: 0.8074 - val_loss: 0.6695 - val_accuracy: 0.7094\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.4845 - accuracy: 0.8037 - val_loss: 0.6749 - val_accuracy: 0.7094\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.4814 - accuracy: 0.8111 - val_loss: 0.6729 - val_accuracy: 0.7265\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.4781 - accuracy: 0.8148 - val_loss: 0.6568 - val_accuracy: 0.7094\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.4768 - accuracy: 0.8074 - val_loss: 0.6613 - val_accuracy: 0.7265\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.4737 - accuracy: 0.7963 - val_loss: 0.6664 - val_accuracy: 0.7350\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.4717 - accuracy: 0.8222 - val_loss: 0.6595 - val_accuracy: 0.7094\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.4696 - accuracy: 0.8259 - val_loss: 0.6640 - val_accuracy: 0.7179\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4658 - accuracy: 0.8222 - val_loss: 0.6662 - val_accuracy: 0.7350\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.4635 - accuracy: 0.8333 - val_loss: 0.6673 - val_accuracy: 0.7265\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.4629 - accuracy: 0.8148 - val_loss: 0.6589 - val_accuracy: 0.7265\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.4603 - accuracy: 0.8185 - val_loss: 0.6605 - val_accuracy: 0.7179\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.4589 - accuracy: 0.8185 - val_loss: 0.6562 - val_accuracy: 0.7350\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4571 - accuracy: 0.8259 - val_loss: 0.6642 - val_accuracy: 0.7265\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4568 - accuracy: 0.8333 - val_loss: 0.6599 - val_accuracy: 0.7179\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4546 - accuracy: 0.8333 - val_loss: 0.6666 - val_accuracy: 0.7265\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4514 - accuracy: 0.8259 - val_loss: 0.6552 - val_accuracy: 0.7265\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4507 - accuracy: 0.8407 - val_loss: 0.6631 - val_accuracy: 0.7350\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.4479 - accuracy: 0.8407 - val_loss: 0.6593 - val_accuracy: 0.7350\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.4462 - accuracy: 0.8333 - val_loss: 0.6540 - val_accuracy: 0.7350\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.4425 - accuracy: 0.8407 - val_loss: 0.6615 - val_accuracy: 0.7265\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.4420 - accuracy: 0.8370 - val_loss: 0.6721 - val_accuracy: 0.7265\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4400 - accuracy: 0.8333 - val_loss: 0.6595 - val_accuracy: 0.7265\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4370 - accuracy: 0.8370 - val_loss: 0.6517 - val_accuracy: 0.7265\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.4358 - accuracy: 0.8333 - val_loss: 0.6568 - val_accuracy: 0.7265\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4338 - accuracy: 0.8407 - val_loss: 0.6634 - val_accuracy: 0.7179\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4341 - accuracy: 0.8370 - val_loss: 0.6561 - val_accuracy: 0.7265\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4282 - accuracy: 0.8370 - val_loss: 0.6593 - val_accuracy: 0.7179\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.4304 - accuracy: 0.8370 - val_loss: 0.6598 - val_accuracy: 0.7179\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4275 - accuracy: 0.8407 - val_loss: 0.6602 - val_accuracy: 0.7436\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.4278 - accuracy: 0.8407 - val_loss: 0.6631 - val_accuracy: 0.7265\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.4255 - accuracy: 0.8333 - val_loss: 0.6580 - val_accuracy: 0.7265\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4255 - accuracy: 0.8519 - val_loss: 0.6596 - val_accuracy: 0.7350\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.4224 - accuracy: 0.8222 - val_loss: 0.6531 - val_accuracy: 0.7009\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.4219 - accuracy: 0.8370 - val_loss: 0.6570 - val_accuracy: 0.7179\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.4216 - accuracy: 0.8444 - val_loss: 0.6487 - val_accuracy: 0.7265\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.4172 - accuracy: 0.8296 - val_loss: 0.6554 - val_accuracy: 0.7265\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.4157 - accuracy: 0.8370 - val_loss: 0.6613 - val_accuracy: 0.7350\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4137 - accuracy: 0.8444 - val_loss: 0.6536 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.4132 - accuracy: 0.8444 - val_loss: 0.6592 - val_accuracy: 0.7179\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4117 - accuracy: 0.8407 - val_loss: 0.6639 - val_accuracy: 0.7265\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.4112 - accuracy: 0.8444 - val_loss: 0.6481 - val_accuracy: 0.7179\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4081 - accuracy: 0.8407 - val_loss: 0.6580 - val_accuracy: 0.7265\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.4101 - accuracy: 0.8481 - val_loss: 0.6671 - val_accuracy: 0.7009\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4070 - accuracy: 0.8481 - val_loss: 0.6515 - val_accuracy: 0.7179\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.4079 - accuracy: 0.8481 - val_loss: 0.6586 - val_accuracy: 0.7179\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4083 - accuracy: 0.8296 - val_loss: 0.6634 - val_accuracy: 0.7265\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.4025 - accuracy: 0.8481 - val_loss: 0.6535 - val_accuracy: 0.7350\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.4017 - accuracy: 0.8481 - val_loss: 0.6533 - val_accuracy: 0.7265\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.4017 - accuracy: 0.8556 - val_loss: 0.6529 - val_accuracy: 0.7350\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.3981 - accuracy: 0.8481 - val_loss: 0.6582 - val_accuracy: 0.7265\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3981 - accuracy: 0.8519 - val_loss: 0.6594 - val_accuracy: 0.7179\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.3959 - accuracy: 0.8444 - val_loss: 0.6505 - val_accuracy: 0.7179\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.3954 - accuracy: 0.8481 - val_loss: 0.6563 - val_accuracy: 0.7350\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3956 - accuracy: 0.8481 - val_loss: 0.6649 - val_accuracy: 0.7350\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3924 - accuracy: 0.8481 - val_loss: 0.6530 - val_accuracy: 0.7265\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3922 - accuracy: 0.8593 - val_loss: 0.6586 - val_accuracy: 0.7265\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3941 - accuracy: 0.8519 - val_loss: 0.6714 - val_accuracy: 0.7179\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3906 - accuracy: 0.8556 - val_loss: 0.6559 - val_accuracy: 0.7094\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3864 - accuracy: 0.8593 - val_loss: 0.6531 - val_accuracy: 0.7179\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.3859 - accuracy: 0.8519 - val_loss: 0.6604 - val_accuracy: 0.7179\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3855 - accuracy: 0.8519 - val_loss: 0.6536 - val_accuracy: 0.7179\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3850 - accuracy: 0.8519 - val_loss: 0.6627 - val_accuracy: 0.7350\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.3858 - accuracy: 0.8556 - val_loss: 0.6543 - val_accuracy: 0.7179\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3838 - accuracy: 0.8481 - val_loss: 0.6639 - val_accuracy: 0.7094\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3842 - accuracy: 0.8556 - val_loss: 0.6791 - val_accuracy: 0.7179\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3815 - accuracy: 0.8593 - val_loss: 0.6576 - val_accuracy: 0.7350\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3803 - accuracy: 0.8593 - val_loss: 0.6511 - val_accuracy: 0.7179\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3797 - accuracy: 0.8556 - val_loss: 0.6620 - val_accuracy: 0.7350\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3779 - accuracy: 0.8481 - val_loss: 0.6557 - val_accuracy: 0.7094\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3763 - accuracy: 0.8481 - val_loss: 0.6521 - val_accuracy: 0.7179\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3825 - accuracy: 0.8630 - val_loss: 0.6695 - val_accuracy: 0.7350\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3813 - accuracy: 0.8481 - val_loss: 0.6624 - val_accuracy: 0.7094\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3732 - accuracy: 0.8556 - val_loss: 0.6718 - val_accuracy: 0.7179\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3742 - accuracy: 0.8593 - val_loss: 0.6610 - val_accuracy: 0.7094\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3725 - accuracy: 0.8519 - val_loss: 0.6571 - val_accuracy: 0.7094\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3707 - accuracy: 0.8519 - val_loss: 0.6667 - val_accuracy: 0.7094\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3705 - accuracy: 0.8556 - val_loss: 0.6644 - val_accuracy: 0.7179\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3742 - accuracy: 0.8630 - val_loss: 0.6691 - val_accuracy: 0.7350\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3690 - accuracy: 0.8481 - val_loss: 0.6662 - val_accuracy: 0.7094\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3732 - accuracy: 0.8444 - val_loss: 0.6615 - val_accuracy: 0.7179\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3666 - accuracy: 0.8593 - val_loss: 0.6667 - val_accuracy: 0.7094\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3697 - accuracy: 0.8630 - val_loss: 0.6692 - val_accuracy: 0.7094\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3649 - accuracy: 0.8519 - val_loss: 0.6683 - val_accuracy: 0.7094\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3632 - accuracy: 0.8593 - val_loss: 0.6680 - val_accuracy: 0.7094\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3620 - accuracy: 0.8630 - val_loss: 0.6693 - val_accuracy: 0.7094\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3642 - accuracy: 0.8593 - val_loss: 0.6623 - val_accuracy: 0.7179\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3668 - accuracy: 0.8593 - val_loss: 0.6778 - val_accuracy: 0.7094\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.3672 - accuracy: 0.8593 - val_loss: 0.6832 - val_accuracy: 0.7436\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3612 - accuracy: 0.8667 - val_loss: 0.6629 - val_accuracy: 0.7094\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3605 - accuracy: 0.8630 - val_loss: 0.6674 - val_accuracy: 0.7094\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3583 - accuracy: 0.8667 - val_loss: 0.6659 - val_accuracy: 0.7094\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3574 - accuracy: 0.8667 - val_loss: 0.6712 - val_accuracy: 0.7094\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3560 - accuracy: 0.8630 - val_loss: 0.6562 - val_accuracy: 0.7094\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3551 - accuracy: 0.8667 - val_loss: 0.6629 - val_accuracy: 0.7094\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3565 - accuracy: 0.8667 - val_loss: 0.6718 - val_accuracy: 0.7094\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3549 - accuracy: 0.8593 - val_loss: 0.6614 - val_accuracy: 0.7094\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.3528 - accuracy: 0.8667 - val_loss: 0.6654 - val_accuracy: 0.7094\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3569 - accuracy: 0.8704 - val_loss: 0.6636 - val_accuracy: 0.7265\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3583 - accuracy: 0.8630 - val_loss: 0.6780 - val_accuracy: 0.7094\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3486 - accuracy: 0.8704 - val_loss: 0.6553 - val_accuracy: 0.7094\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3511 - accuracy: 0.8704 - val_loss: 0.6565 - val_accuracy: 0.7179\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3513 - accuracy: 0.8704 - val_loss: 0.6686 - val_accuracy: 0.7094\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3491 - accuracy: 0.8667 - val_loss: 0.6642 - val_accuracy: 0.7094\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3502 - accuracy: 0.8667 - val_loss: 0.6737 - val_accuracy: 0.7094\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3470 - accuracy: 0.8667 - val_loss: 0.6681 - val_accuracy: 0.7094\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3481 - accuracy: 0.8704 - val_loss: 0.6693 - val_accuracy: 0.7094\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3476 - accuracy: 0.8704 - val_loss: 0.6688 - val_accuracy: 0.7094\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3475 - accuracy: 0.8704 - val_loss: 0.6836 - val_accuracy: 0.7094\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3448 - accuracy: 0.8667 - val_loss: 0.6827 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3465 - accuracy: 0.8704 - val_loss: 0.6795 - val_accuracy: 0.7094\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3436 - accuracy: 0.8667 - val_loss: 0.6769 - val_accuracy: 0.7094\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3450 - accuracy: 0.8667 - val_loss: 0.6815 - val_accuracy: 0.7094\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3429 - accuracy: 0.8704 - val_loss: 0.6790 - val_accuracy: 0.7094\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3415 - accuracy: 0.8741 - val_loss: 0.6674 - val_accuracy: 0.7094\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3426 - accuracy: 0.8704 - val_loss: 0.6632 - val_accuracy: 0.7094\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3413 - accuracy: 0.8704 - val_loss: 0.6748 - val_accuracy: 0.7094\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3397 - accuracy: 0.8704 - val_loss: 0.6783 - val_accuracy: 0.7094\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3393 - accuracy: 0.8704 - val_loss: 0.6716 - val_accuracy: 0.7094\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3425 - accuracy: 0.8667 - val_loss: 0.6741 - val_accuracy: 0.7094\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3465 - accuracy: 0.8741 - val_loss: 0.6776 - val_accuracy: 0.7179\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3411 - accuracy: 0.8704 - val_loss: 0.6781 - val_accuracy: 0.7094\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.3370 - accuracy: 0.8741 - val_loss: 0.6820 - val_accuracy: 0.7094\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3416 - accuracy: 0.8704 - val_loss: 0.6734 - val_accuracy: 0.7094\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3433 - accuracy: 0.8704 - val_loss: 0.6925 - val_accuracy: 0.7094\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3350 - accuracy: 0.8704 - val_loss: 0.6737 - val_accuracy: 0.7094\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3350 - accuracy: 0.8704 - val_loss: 0.6742 - val_accuracy: 0.7094\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3368 - accuracy: 0.8704 - val_loss: 0.6741 - val_accuracy: 0.7094\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3379 - accuracy: 0.8704 - val_loss: 0.6760 - val_accuracy: 0.7179\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3360 - accuracy: 0.8741 - val_loss: 0.6855 - val_accuracy: 0.7094\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3354 - accuracy: 0.8704 - val_loss: 0.6706 - val_accuracy: 0.7094\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3322 - accuracy: 0.8704 - val_loss: 0.6705 - val_accuracy: 0.7094\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3328 - accuracy: 0.8704 - val_loss: 0.6841 - val_accuracy: 0.7094\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3305 - accuracy: 0.8704 - val_loss: 0.6761 - val_accuracy: 0.7094\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3343 - accuracy: 0.8519 - val_loss: 0.6691 - val_accuracy: 0.7094\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3389 - accuracy: 0.8704 - val_loss: 0.6983 - val_accuracy: 0.7094\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3277 - accuracy: 0.8741 - val_loss: 0.6767 - val_accuracy: 0.7094\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.3341 - accuracy: 0.8556 - val_loss: 0.6745 - val_accuracy: 0.7094\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.3288 - accuracy: 0.8741 - val_loss: 0.6875 - val_accuracy: 0.7094\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.3313 - accuracy: 0.8704 - val_loss: 0.6899 - val_accuracy: 0.7094\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3305 - accuracy: 0.8667 - val_loss: 0.6773 - val_accuracy: 0.7094\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3261 - accuracy: 0.8741 - val_loss: 0.6911 - val_accuracy: 0.7094\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3278 - accuracy: 0.8741 - val_loss: 0.6992 - val_accuracy: 0.7094\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3248 - accuracy: 0.8741 - val_loss: 0.6795 - val_accuracy: 0.7094\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3250 - accuracy: 0.8741 - val_loss: 0.6919 - val_accuracy: 0.7094\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3279 - accuracy: 0.8704 - val_loss: 0.6959 - val_accuracy: 0.7094\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3324 - accuracy: 0.8630 - val_loss: 0.6863 - val_accuracy: 0.7094\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3282 - accuracy: 0.8778 - val_loss: 0.6771 - val_accuracy: 0.7179\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3253 - accuracy: 0.8741 - val_loss: 0.6904 - val_accuracy: 0.7094\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3235 - accuracy: 0.8704 - val_loss: 0.6960 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3241 - accuracy: 0.8741 - val_loss: 0.6830 - val_accuracy: 0.7094\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3356 - accuracy: 0.8741 - val_loss: 0.6771 - val_accuracy: 0.7094\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3278 - accuracy: 0.8593 - val_loss: 0.6974 - val_accuracy: 0.7179\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.3241 - accuracy: 0.8741 - val_loss: 0.6817 - val_accuracy: 0.7094\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.3218 - accuracy: 0.8704 - val_loss: 0.6901 - val_accuracy: 0.7094\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3291 - accuracy: 0.8593 - val_loss: 0.6760 - val_accuracy: 0.7094\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3237 - accuracy: 0.8741 - val_loss: 0.7078 - val_accuracy: 0.7094\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.3204 - accuracy: 0.8704 - val_loss: 0.6970 - val_accuracy: 0.7094\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3202 - accuracy: 0.8704 - val_loss: 0.7002 - val_accuracy: 0.7265\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3189 - accuracy: 0.8741 - val_loss: 0.6844 - val_accuracy: 0.7094\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3179 - accuracy: 0.8778 - val_loss: 0.6908 - val_accuracy: 0.7094\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3198 - accuracy: 0.8741 - val_loss: 0.7042 - val_accuracy: 0.7094\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3196 - accuracy: 0.8741 - val_loss: 0.6881 - val_accuracy: 0.7094\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3208 - accuracy: 0.8741 - val_loss: 0.6925 - val_accuracy: 0.7094\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3189 - accuracy: 0.8778 - val_loss: 0.6998 - val_accuracy: 0.7179\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.3182 - accuracy: 0.8778 - val_loss: 0.6900 - val_accuracy: 0.7094\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.3161 - accuracy: 0.8741 - val_loss: 0.6969 - val_accuracy: 0.7094\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3162 - accuracy: 0.8741 - val_loss: 0.7038 - val_accuracy: 0.7094\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 270us/step - loss: 0.3166 - accuracy: 0.8778 - val_loss: 0.6973 - val_accuracy: 0.7094\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 416us/step - loss: 0.3159 - accuracy: 0.8778 - val_loss: 0.6881 - val_accuracy: 0.7094\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.3148 - accuracy: 0.8741 - val_loss: 0.6884 - val_accuracy: 0.7094\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.3140 - accuracy: 0.8778 - val_loss: 0.6978 - val_accuracy: 0.7094\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 428us/step - loss: 0.3162 - accuracy: 0.8778 - val_loss: 0.7008 - val_accuracy: 0.7094\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.3130 - accuracy: 0.8667 - val_loss: 0.6882 - val_accuracy: 0.7179\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.3205 - accuracy: 0.8741 - val_loss: 0.6876 - val_accuracy: 0.7179\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.3210 - accuracy: 0.8778 - val_loss: 0.7305 - val_accuracy: 0.7094\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3145 - accuracy: 0.8741 - val_loss: 0.6959 - val_accuracy: 0.7094\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.3130 - accuracy: 0.8778 - val_loss: 0.6903 - val_accuracy: 0.7094\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.3127 - accuracy: 0.8778 - val_loss: 0.6990 - val_accuracy: 0.7094\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.3109 - accuracy: 0.8778 - val_loss: 0.6896 - val_accuracy: 0.7094\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.3103 - accuracy: 0.8778 - val_loss: 0.7065 - val_accuracy: 0.7094\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.3116 - accuracy: 0.8741 - val_loss: 0.6970 - val_accuracy: 0.7094\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.3107 - accuracy: 0.8778 - val_loss: 0.7170 - val_accuracy: 0.7094\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 366us/step - loss: 0.3107 - accuracy: 0.8741 - val_loss: 0.6985 - val_accuracy: 0.7094\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.3100 - accuracy: 0.8778 - val_loss: 0.7070 - val_accuracy: 0.7094\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.3102 - accuracy: 0.8778 - val_loss: 0.6854 - val_accuracy: 0.7094\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.3131 - accuracy: 0.8704 - val_loss: 0.6793 - val_accuracy: 0.7094\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.3081 - accuracy: 0.8778 - val_loss: 0.7012 - val_accuracy: 0.7094\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.3084 - accuracy: 0.8741 - val_loss: 0.7208 - val_accuracy: 0.7094\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.3103 - accuracy: 0.8778 - val_loss: 0.6983 - val_accuracy: 0.7094\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.3067 - accuracy: 0.8778 - val_loss: 0.7089 - val_accuracy: 0.7094\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.3068 - accuracy: 0.8778 - val_loss: 0.7017 - val_accuracy: 0.7094\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.3063 - accuracy: 0.8778 - val_loss: 0.6938 - val_accuracy: 0.7094\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.3091 - accuracy: 0.8704 - val_loss: 0.7005 - val_accuracy: 0.7094\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.3071 - accuracy: 0.8778 - val_loss: 0.7075 - val_accuracy: 0.7094\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.3063 - accuracy: 0.8778 - val_loss: 0.6980 - val_accuracy: 0.7094\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.3049 - accuracy: 0.8778 - val_loss: 0.7175 - val_accuracy: 0.7094\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.3057 - accuracy: 0.8778 - val_loss: 0.6940 - val_accuracy: 0.7094\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.3038 - accuracy: 0.8741 - val_loss: 0.6983 - val_accuracy: 0.7094\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.3029 - accuracy: 0.8778 - val_loss: 0.7116 - val_accuracy: 0.7094\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.7122 - val_accuracy: 0.7265\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.3069 - accuracy: 0.8778 - val_loss: 0.7243 - val_accuracy: 0.7265\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3027 - accuracy: 0.8778 - val_loss: 0.7095 - val_accuracy: 0.7094\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.3029 - accuracy: 0.8667 - val_loss: 0.7054 - val_accuracy: 0.7094\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.3061 - accuracy: 0.8741 - val_loss: 0.7185 - val_accuracy: 0.7094\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.2998 - accuracy: 0.8778 - val_loss: 0.6994 - val_accuracy: 0.7094\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.3032 - accuracy: 0.8778 - val_loss: 0.6963 - val_accuracy: 0.7094\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3039 - accuracy: 0.8778 - val_loss: 0.7175 - val_accuracy: 0.7094\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3047 - accuracy: 0.8630 - val_loss: 0.7126 - val_accuracy: 0.7094\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3031 - accuracy: 0.8778 - val_loss: 0.7247 - val_accuracy: 0.7094\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3028 - accuracy: 0.8741 - val_loss: 0.7088 - val_accuracy: 0.7094\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3009 - accuracy: 0.8741 - val_loss: 0.7084 - val_accuracy: 0.7094\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2995 - accuracy: 0.8778 - val_loss: 0.7167 - val_accuracy: 0.7094\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3024 - accuracy: 0.8778 - val_loss: 0.7119 - val_accuracy: 0.7094\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3009 - accuracy: 0.8778 - val_loss: 0.6996 - val_accuracy: 0.7094\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2983 - accuracy: 0.8778 - val_loss: 0.7123 - val_accuracy: 0.7265\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2999 - accuracy: 0.8778 - val_loss: 0.7238 - val_accuracy: 0.7265\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2990 - accuracy: 0.8778 - val_loss: 0.7135 - val_accuracy: 0.7094\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2985 - accuracy: 0.8778 - val_loss: 0.7081 - val_accuracy: 0.7094\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2971 - accuracy: 0.8778 - val_loss: 0.7302 - val_accuracy: 0.7094\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2985 - accuracy: 0.8778 - val_loss: 0.7213 - val_accuracy: 0.7094\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2978 - accuracy: 0.8778 - val_loss: 0.7146 - val_accuracy: 0.7094\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2974 - accuracy: 0.8778 - val_loss: 0.7147 - val_accuracy: 0.7094\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2990 - accuracy: 0.8593 - val_loss: 0.7095 - val_accuracy: 0.7094\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2980 - accuracy: 0.8778 - val_loss: 0.7319 - val_accuracy: 0.7094\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2965 - accuracy: 0.8778 - val_loss: 0.7202 - val_accuracy: 0.7094\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2991 - accuracy: 0.8778 - val_loss: 0.7088 - val_accuracy: 0.7094\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2966 - accuracy: 0.8667 - val_loss: 0.7229 - val_accuracy: 0.7094\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2973 - accuracy: 0.8778 - val_loss: 0.7306 - val_accuracy: 0.7094\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2959 - accuracy: 0.8778 - val_loss: 0.7185 - val_accuracy: 0.7094\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2951 - accuracy: 0.8778 - val_loss: 0.7165 - val_accuracy: 0.7094\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2942 - accuracy: 0.8778 - val_loss: 0.7134 - val_accuracy: 0.7094\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2980 - accuracy: 0.8778 - val_loss: 0.7312 - val_accuracy: 0.7094\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2997 - accuracy: 0.8556 - val_loss: 0.7225 - val_accuracy: 0.7094\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2924 - accuracy: 0.8778 - val_loss: 0.7282 - val_accuracy: 0.7094\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2960 - accuracy: 0.8778 - val_loss: 0.7198 - val_accuracy: 0.7094\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2956 - accuracy: 0.8704 - val_loss: 0.7261 - val_accuracy: 0.7094\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2922 - accuracy: 0.8778 - val_loss: 0.7329 - val_accuracy: 0.7094\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2917 - accuracy: 0.8778 - val_loss: 0.7262 - val_accuracy: 0.7094\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2931 - accuracy: 0.8741 - val_loss: 0.7251 - val_accuracy: 0.7094\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2930 - accuracy: 0.8778 - val_loss: 0.7330 - val_accuracy: 0.7094\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2925 - accuracy: 0.8778 - val_loss: 0.7343 - val_accuracy: 0.7094\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2922 - accuracy: 0.8778 - val_loss: 0.7240 - val_accuracy: 0.7094\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2934 - accuracy: 0.8778 - val_loss: 0.7280 - val_accuracy: 0.7094\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2935 - accuracy: 0.8778 - val_loss: 0.7260 - val_accuracy: 0.7094\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3060 - accuracy: 0.8519 - val_loss: 0.7375 - val_accuracy: 0.7179\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2931 - accuracy: 0.8741 - val_loss: 0.7274 - val_accuracy: 0.7179\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2942 - accuracy: 0.8778 - val_loss: 0.7253 - val_accuracy: 0.7094\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2932 - accuracy: 0.8630 - val_loss: 0.7300 - val_accuracy: 0.7094\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2909 - accuracy: 0.8778 - val_loss: 0.7264 - val_accuracy: 0.7094\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2926 - accuracy: 0.8778 - val_loss: 0.7180 - val_accuracy: 0.7094\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2934 - accuracy: 0.8778 - val_loss: 0.7447 - val_accuracy: 0.7094\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2907 - accuracy: 0.8778 - val_loss: 0.7326 - val_accuracy: 0.7094\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2885 - accuracy: 0.8778 - val_loss: 0.7293 - val_accuracy: 0.7094\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2911 - accuracy: 0.8778 - val_loss: 0.7424 - val_accuracy: 0.7094\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2894 - accuracy: 0.8778 - val_loss: 0.7185 - val_accuracy: 0.7094\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2894 - accuracy: 0.8778 - val_loss: 0.7304 - val_accuracy: 0.7094\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2894 - accuracy: 0.8778 - val_loss: 0.7250 - val_accuracy: 0.7094\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2890 - accuracy: 0.8778 - val_loss: 0.7389 - val_accuracy: 0.7094\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2902 - accuracy: 0.8778 - val_loss: 0.7521 - val_accuracy: 0.7094\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 91us/step - loss: 0.2907 - accuracy: 0.8778 - val_loss: 0.7389 - val_accuracy: 0.7094\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2895 - accuracy: 0.8778 - val_loss: 0.7241 - val_accuracy: 0.7094\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2880 - accuracy: 0.8593 - val_loss: 0.7372 - val_accuracy: 0.7094\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2891 - accuracy: 0.8741 - val_loss: 0.7423 - val_accuracy: 0.7094\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2944 - accuracy: 0.8704 - val_loss: 0.7293 - val_accuracy: 0.7179\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2879 - accuracy: 0.8778 - val_loss: 0.7434 - val_accuracy: 0.7094\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2885 - accuracy: 0.8778 - val_loss: 0.7425 - val_accuracy: 0.7094\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2905 - accuracy: 0.8667 - val_loss: 0.7307 - val_accuracy: 0.7179\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2864 - accuracy: 0.8778 - val_loss: 0.7470 - val_accuracy: 0.7094\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2885 - accuracy: 0.8778 - val_loss: 0.7394 - val_accuracy: 0.7094\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2890 - accuracy: 0.8778 - val_loss: 0.7460 - val_accuracy: 0.7094\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2898 - accuracy: 0.8778 - val_loss: 0.7345 - val_accuracy: 0.7009\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2877 - accuracy: 0.8778 - val_loss: 0.7456 - val_accuracy: 0.7265\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2859 - accuracy: 0.8778 - val_loss: 0.7403 - val_accuracy: 0.7094\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2919 - accuracy: 0.8778 - val_loss: 0.7610 - val_accuracy: 0.7094\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2840 - accuracy: 0.8778 - val_loss: 0.7385 - val_accuracy: 0.7179\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2908 - accuracy: 0.8667 - val_loss: 0.7424 - val_accuracy: 0.7094\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2873 - accuracy: 0.8778 - val_loss: 0.7523 - val_accuracy: 0.7009\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2860 - accuracy: 0.8704 - val_loss: 0.7380 - val_accuracy: 0.7094\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2855 - accuracy: 0.8778 - val_loss: 0.7353 - val_accuracy: 0.7094\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2838 - accuracy: 0.8778 - val_loss: 0.7487 - val_accuracy: 0.7094\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2824 - accuracy: 0.8778 - val_loss: 0.7489 - val_accuracy: 0.7094\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2833 - accuracy: 0.8778 - val_loss: 0.7468 - val_accuracy: 0.7094\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2822 - accuracy: 0.8778 - val_loss: 0.7458 - val_accuracy: 0.7009\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2846 - accuracy: 0.8778 - val_loss: 0.7514 - val_accuracy: 0.7009\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2826 - accuracy: 0.8778 - val_loss: 0.7465 - val_accuracy: 0.7094\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2840 - accuracy: 0.8778 - val_loss: 0.7356 - val_accuracy: 0.7094\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2829 - accuracy: 0.8778 - val_loss: 0.7516 - val_accuracy: 0.7094\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2833 - accuracy: 0.8778 - val_loss: 0.7511 - val_accuracy: 0.7094\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2846 - accuracy: 0.8778 - val_loss: 0.7387 - val_accuracy: 0.7094\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2812 - accuracy: 0.8778 - val_loss: 0.7571 - val_accuracy: 0.7009\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2817 - accuracy: 0.8778 - val_loss: 0.7604 - val_accuracy: 0.7094\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2805 - accuracy: 0.8778 - val_loss: 0.7516 - val_accuracy: 0.7094\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2808 - accuracy: 0.8778 - val_loss: 0.7470 - val_accuracy: 0.7009\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2820 - accuracy: 0.8778 - val_loss: 0.7642 - val_accuracy: 0.7009\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2804 - accuracy: 0.8778 - val_loss: 0.7506 - val_accuracy: 0.7009\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2807 - accuracy: 0.8741 - val_loss: 0.7521 - val_accuracy: 0.7009\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2826 - accuracy: 0.8778 - val_loss: 0.7600 - val_accuracy: 0.7179\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2807 - accuracy: 0.8778 - val_loss: 0.7534 - val_accuracy: 0.7094\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2817 - accuracy: 0.8778 - val_loss: 0.7548 - val_accuracy: 0.7094\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2817 - accuracy: 0.8778 - val_loss: 0.7668 - val_accuracy: 0.7009\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2796 - accuracy: 0.8778 - val_loss: 0.7592 - val_accuracy: 0.7094\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2795 - accuracy: 0.8778 - val_loss: 0.7534 - val_accuracy: 0.7094\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2795 - accuracy: 0.8778 - val_loss: 0.7533 - val_accuracy: 0.7094\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2807 - accuracy: 0.8667 - val_loss: 0.7454 - val_accuracy: 0.7094\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2783 - accuracy: 0.8778 - val_loss: 0.7748 - val_accuracy: 0.7179\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2874 - accuracy: 0.8778 - val_loss: 0.7668 - val_accuracy: 0.7094\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2787 - accuracy: 0.8741 - val_loss: 0.7487 - val_accuracy: 0.7094\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2813 - accuracy: 0.8741 - val_loss: 0.7614 - val_accuracy: 0.7009\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2815 - accuracy: 0.8667 - val_loss: 0.7579 - val_accuracy: 0.6923\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2800 - accuracy: 0.8778 - val_loss: 0.7641 - val_accuracy: 0.7179\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2765 - accuracy: 0.8778 - val_loss: 0.7536 - val_accuracy: 0.7094\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2890 - accuracy: 0.8630 - val_loss: 0.7700 - val_accuracy: 0.7094\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2745 - accuracy: 0.8778 - val_loss: 0.7650 - val_accuracy: 0.7009\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2796 - accuracy: 0.8778 - val_loss: 0.7661 - val_accuracy: 0.7094\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2800 - accuracy: 0.8741 - val_loss: 0.7582 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2779 - accuracy: 0.8778 - val_loss: 0.7721 - val_accuracy: 0.7094\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2754 - accuracy: 0.8778 - val_loss: 0.7593 - val_accuracy: 0.7094\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2748 - accuracy: 0.8778 - val_loss: 0.7573 - val_accuracy: 0.7094\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2803 - accuracy: 0.8667 - val_loss: 0.7534 - val_accuracy: 0.7094\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2797 - accuracy: 0.8778 - val_loss: 0.7963 - val_accuracy: 0.7179\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2794 - accuracy: 0.8778 - val_loss: 0.7730 - val_accuracy: 0.7265\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2762 - accuracy: 0.8778 - val_loss: 0.7525 - val_accuracy: 0.7094\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2783 - accuracy: 0.8741 - val_loss: 0.7518 - val_accuracy: 0.7009\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2757 - accuracy: 0.8704 - val_loss: 0.7557 - val_accuracy: 0.7094\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2752 - accuracy: 0.8778 - val_loss: 0.7638 - val_accuracy: 0.7094\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2824 - accuracy: 0.8741 - val_loss: 0.7857 - val_accuracy: 0.7009\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2790 - accuracy: 0.8778 - val_loss: 0.7679 - val_accuracy: 0.7009\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2821 - accuracy: 0.8593 - val_loss: 0.7592 - val_accuracy: 0.7179\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2787 - accuracy: 0.8704 - val_loss: 0.7492 - val_accuracy: 0.7179\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2754 - accuracy: 0.8778 - val_loss: 0.7817 - val_accuracy: 0.7094\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2831 - accuracy: 0.8778 - val_loss: 0.8220 - val_accuracy: 0.7009\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2742 - accuracy: 0.8778 - val_loss: 0.7628 - val_accuracy: 0.6923\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2750 - accuracy: 0.8741 - val_loss: 0.7633 - val_accuracy: 0.7009\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2742 - accuracy: 0.8778 - val_loss: 0.7760 - val_accuracy: 0.7009\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2774 - accuracy: 0.8778 - val_loss: 0.7730 - val_accuracy: 0.6923\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2722 - accuracy: 0.8778 - val_loss: 0.7796 - val_accuracy: 0.7009\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2742 - accuracy: 0.8778 - val_loss: 0.7688 - val_accuracy: 0.7094\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2731 - accuracy: 0.8778 - val_loss: 0.7645 - val_accuracy: 0.7094\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2721 - accuracy: 0.8778 - val_loss: 0.7768 - val_accuracy: 0.7009\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2768 - accuracy: 0.8778 - val_loss: 0.7700 - val_accuracy: 0.7009\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.7889 - val_accuracy: 0.7009\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2736 - accuracy: 0.8778 - val_loss: 0.7718 - val_accuracy: 0.7009\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2718 - accuracy: 0.8778 - val_loss: 0.7728 - val_accuracy: 0.7094\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2733 - accuracy: 0.8778 - val_loss: 0.7587 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2731 - accuracy: 0.8667 - val_loss: 0.7689 - val_accuracy: 0.7094\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2740 - accuracy: 0.8778 - val_loss: 0.7921 - val_accuracy: 0.7009\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.7718 - val_accuracy: 0.7009\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2726 - accuracy: 0.8778 - val_loss: 0.7765 - val_accuracy: 0.7009\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2767 - accuracy: 0.8667 - val_loss: 0.7744 - val_accuracy: 0.6923\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2707 - accuracy: 0.8704 - val_loss: 0.7984 - val_accuracy: 0.7009\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2717 - accuracy: 0.8778 - val_loss: 0.7750 - val_accuracy: 0.7009\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2705 - accuracy: 0.8778 - val_loss: 0.7647 - val_accuracy: 0.7009\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2705 - accuracy: 0.8778 - val_loss: 0.7754 - val_accuracy: 0.7009\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2711 - accuracy: 0.8778 - val_loss: 0.7763 - val_accuracy: 0.7009\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2688 - accuracy: 0.8778 - val_loss: 0.7828 - val_accuracy: 0.7094\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2775 - accuracy: 0.8593 - val_loss: 0.7813 - val_accuracy: 0.7094\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2690 - accuracy: 0.8778 - val_loss: 0.7828 - val_accuracy: 0.7009\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2727 - accuracy: 0.8778 - val_loss: 0.7831 - val_accuracy: 0.7009\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2696 - accuracy: 0.8778 - val_loss: 0.7764 - val_accuracy: 0.7009\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2720 - accuracy: 0.8778 - val_loss: 0.7876 - val_accuracy: 0.7009\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2694 - accuracy: 0.8704 - val_loss: 0.7786 - val_accuracy: 0.7094\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2710 - accuracy: 0.8778 - val_loss: 0.7958 - val_accuracy: 0.7009\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2699 - accuracy: 0.8778 - val_loss: 0.7749 - val_accuracy: 0.7009\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2703 - accuracy: 0.8778 - val_loss: 0.7803 - val_accuracy: 0.7009\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.7850 - val_accuracy: 0.7009\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2704 - accuracy: 0.8778 - val_loss: 0.8213 - val_accuracy: 0.7009\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2717 - accuracy: 0.8778 - val_loss: 0.7870 - val_accuracy: 0.7009\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2703 - accuracy: 0.8815 - val_loss: 0.7707 - val_accuracy: 0.7094\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2740 - accuracy: 0.8704 - val_loss: 0.7860 - val_accuracy: 0.7009\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2694 - accuracy: 0.8778 - val_loss: 0.7930 - val_accuracy: 0.7179\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2774 - accuracy: 0.8741 - val_loss: 0.7992 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2688 - accuracy: 0.8778 - val_loss: 0.7832 - val_accuracy: 0.7265\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2712 - accuracy: 0.8741 - val_loss: 0.7770 - val_accuracy: 0.7009\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2707 - accuracy: 0.8778 - val_loss: 0.8263 - val_accuracy: 0.7009\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2725 - accuracy: 0.8778 - val_loss: 0.7973 - val_accuracy: 0.7009\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2659 - accuracy: 0.8852 - val_loss: 0.7781 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2681 - accuracy: 0.8815 - val_loss: 0.7874 - val_accuracy: 0.7009\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2665 - accuracy: 0.8778 - val_loss: 0.7988 - val_accuracy: 0.7009\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2689 - accuracy: 0.8778 - val_loss: 0.7876 - val_accuracy: 0.7009\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2663 - accuracy: 0.8778 - val_loss: 0.7888 - val_accuracy: 0.7179\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2731 - accuracy: 0.8778 - val_loss: 0.7996 - val_accuracy: 0.7179\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2831 - accuracy: 0.8556 - val_loss: 0.8143 - val_accuracy: 0.6923\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2684 - accuracy: 0.8852 - val_loss: 0.7747 - val_accuracy: 0.7094\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2734 - accuracy: 0.8667 - val_loss: 0.7849 - val_accuracy: 0.6923\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2669 - accuracy: 0.8778 - val_loss: 0.8247 - val_accuracy: 0.7009\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2693 - accuracy: 0.8778 - val_loss: 0.8208 - val_accuracy: 0.7009\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2734 - accuracy: 0.8778 - val_loss: 0.7912 - val_accuracy: 0.7009\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2677 - accuracy: 0.8778 - val_loss: 0.7941 - val_accuracy: 0.7009\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2634 - accuracy: 0.8741 - val_loss: 0.8049 - val_accuracy: 0.6923\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2699 - accuracy: 0.8741 - val_loss: 0.8049 - val_accuracy: 0.7009\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2667 - accuracy: 0.8778 - val_loss: 0.7926 - val_accuracy: 0.7009\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2657 - accuracy: 0.8778 - val_loss: 0.8033 - val_accuracy: 0.7009\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2662 - accuracy: 0.8778 - val_loss: 0.7994 - val_accuracy: 0.7179\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2680 - accuracy: 0.8815 - val_loss: 0.7921 - val_accuracy: 0.6923\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2646 - accuracy: 0.8852 - val_loss: 0.8052 - val_accuracy: 0.7009\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2725 - accuracy: 0.8741 - val_loss: 0.8193 - val_accuracy: 0.7009\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2780 - accuracy: 0.8778 - val_loss: 0.8094 - val_accuracy: 0.7009\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2670 - accuracy: 0.8815 - val_loss: 0.7798 - val_accuracy: 0.7094\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2693 - accuracy: 0.8778 - val_loss: 0.7983 - val_accuracy: 0.7009\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2758 - accuracy: 0.8778 - val_loss: 0.8329 - val_accuracy: 0.7179\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2667 - accuracy: 0.8778 - val_loss: 0.7868 - val_accuracy: 0.7094\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2698 - accuracy: 0.8667 - val_loss: 0.7917 - val_accuracy: 0.7009\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2671 - accuracy: 0.8778 - val_loss: 0.8247 - val_accuracy: 0.7009\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2707 - accuracy: 0.8741 - val_loss: 0.8063 - val_accuracy: 0.7179\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2751 - accuracy: 0.8333 - val_loss: 0.8117 - val_accuracy: 0.7009\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2674 - accuracy: 0.8815 - val_loss: 0.7976 - val_accuracy: 0.7009\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2653 - accuracy: 0.8778 - val_loss: 0.7961 - val_accuracy: 0.7009\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2648 - accuracy: 0.8778 - val_loss: 0.8046 - val_accuracy: 0.7009\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2625 - accuracy: 0.8815 - val_loss: 0.8020 - val_accuracy: 0.7009\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2652 - accuracy: 0.8815 - val_loss: 0.8029 - val_accuracy: 0.7009\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2624 - accuracy: 0.8815 - val_loss: 0.8064 - val_accuracy: 0.6923\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2643 - accuracy: 0.8889 - val_loss: 0.8305 - val_accuracy: 0.7094\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2647 - accuracy: 0.8778 - val_loss: 0.8150 - val_accuracy: 0.7179\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.87 - 0s 64us/step - loss: 0.2638 - accuracy: 0.8815 - val_loss: 0.7976 - val_accuracy: 0.7265\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2627 - accuracy: 0.8815 - val_loss: 0.8135 - val_accuracy: 0.7179\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2623 - accuracy: 0.8889 - val_loss: 0.8206 - val_accuracy: 0.7179\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2655 - accuracy: 0.8815 - val_loss: 0.7938 - val_accuracy: 0.7009\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2630 - accuracy: 0.8815 - val_loss: 0.8021 - val_accuracy: 0.7009\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2626 - accuracy: 0.8852 - val_loss: 0.8208 - val_accuracy: 0.7009\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2633 - accuracy: 0.8778 - val_loss: 0.8139 - val_accuracy: 0.7179\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2677 - accuracy: 0.8778 - val_loss: 0.8033 - val_accuracy: 0.7179\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2616 - accuracy: 0.8778 - val_loss: 0.8282 - val_accuracy: 0.7009\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2681 - accuracy: 0.8704 - val_loss: 0.8275 - val_accuracy: 0.7009\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2644 - accuracy: 0.8815 - val_loss: 0.8115 - val_accuracy: 0.7009\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2691 - accuracy: 0.8667 - val_loss: 0.8063 - val_accuracy: 0.7009\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2642 - accuracy: 0.8778 - val_loss: 0.8269 - val_accuracy: 0.7179\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2627 - accuracy: 0.8815 - val_loss: 0.8046 - val_accuracy: 0.7009\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2687 - accuracy: 0.8704 - val_loss: 0.8154 - val_accuracy: 0.6838\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2682 - accuracy: 0.8815 - val_loss: 0.8378 - val_accuracy: 0.7009\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2624 - accuracy: 0.8815 - val_loss: 0.8098 - val_accuracy: 0.7009\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.8089 - val_accuracy: 0.7009\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2597 - accuracy: 0.8778 - val_loss: 0.8291 - val_accuracy: 0.7009\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2640 - accuracy: 0.8778 - val_loss: 0.8450 - val_accuracy: 0.7009\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2627 - accuracy: 0.8778 - val_loss: 0.8105 - val_accuracy: 0.7009\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 0.8030 - val_accuracy: 0.7009\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2625 - accuracy: 0.8815 - val_loss: 0.8197 - val_accuracy: 0.7009\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2625 - accuracy: 0.8852 - val_loss: 0.8034 - val_accuracy: 0.7009\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2618 - accuracy: 0.8815 - val_loss: 0.8371 - val_accuracy: 0.6923\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2612 - accuracy: 0.8815 - val_loss: 0.8316 - val_accuracy: 0.7179\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2610 - accuracy: 0.8815 - val_loss: 0.8105 - val_accuracy: 0.7009\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2626 - accuracy: 0.8852 - val_loss: 0.8237 - val_accuracy: 0.7009\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2608 - accuracy: 0.8889 - val_loss: 0.8144 - val_accuracy: 0.6923\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2587 - accuracy: 0.8852 - val_loss: 0.8308 - val_accuracy: 0.7009\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2608 - accuracy: 0.8815 - val_loss: 0.8286 - val_accuracy: 0.7009\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2596 - accuracy: 0.8815 - val_loss: 0.8228 - val_accuracy: 0.7009\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2595 - accuracy: 0.8852 - val_loss: 0.8191 - val_accuracy: 0.7009\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 0.8135 - val_accuracy: 0.7009\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2609 - accuracy: 0.8852 - val_loss: 0.8210 - val_accuracy: 0.7009\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2604 - accuracy: 0.8778 - val_loss: 0.8155 - val_accuracy: 0.7094\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2631 - accuracy: 0.8741 - val_loss: 0.8377 - val_accuracy: 0.7009\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2597 - accuracy: 0.8778 - val_loss: 0.8246 - val_accuracy: 0.7009\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2619 - accuracy: 0.8852 - val_loss: 0.8202 - val_accuracy: 0.7009\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2601 - accuracy: 0.8815 - val_loss: 0.8451 - val_accuracy: 0.7009\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2618 - accuracy: 0.8815 - val_loss: 0.8322 - val_accuracy: 0.7179\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2607 - accuracy: 0.8778 - val_loss: 0.8425 - val_accuracy: 0.7009\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2641 - accuracy: 0.8778 - val_loss: 0.8413 - val_accuracy: 0.7179\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2597 - accuracy: 0.8852 - val_loss: 0.8320 - val_accuracy: 0.7179\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2610 - accuracy: 0.8852 - val_loss: 0.8377 - val_accuracy: 0.7009\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2626 - accuracy: 0.8852 - val_loss: 0.8255 - val_accuracy: 0.7009\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2583 - accuracy: 0.8852 - val_loss: 0.8345 - val_accuracy: 0.7179\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2611 - accuracy: 0.8852 - val_loss: 0.8368 - val_accuracy: 0.7179\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2598 - accuracy: 0.8815 - val_loss: 0.8330 - val_accuracy: 0.7009\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2608 - accuracy: 0.8815 - val_loss: 0.8444 - val_accuracy: 0.7009\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2638 - accuracy: 0.8778 - val_loss: 0.8547 - val_accuracy: 0.7009\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.8223 - val_accuracy: 0.7009\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2585 - accuracy: 0.8778 - val_loss: 0.8166 - val_accuracy: 0.7094\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2639 - accuracy: 0.8815 - val_loss: 0.8510 - val_accuracy: 0.7179\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2581 - accuracy: 0.8852 - val_loss: 0.8380 - val_accuracy: 0.7094\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2616 - accuracy: 0.8778 - val_loss: 0.8386 - val_accuracy: 0.6923\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2606 - accuracy: 0.8852 - val_loss: 0.8352 - val_accuracy: 0.7179\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2586 - accuracy: 0.8852 - val_loss: 0.8251 - val_accuracy: 0.7009\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2655 - accuracy: 0.8741 - val_loss: 0.8330 - val_accuracy: 0.7009\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2674 - accuracy: 0.8852 - val_loss: 0.8407 - val_accuracy: 0.7009\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2567 - accuracy: 0.8852 - val_loss: 0.8411 - val_accuracy: 0.6923\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2751 - accuracy: 0.8593 - val_loss: 0.8436 - val_accuracy: 0.7009\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2593 - accuracy: 0.8815 - val_loss: 0.8527 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2575 - accuracy: 0.8815 - val_loss: 0.8353 - val_accuracy: 0.7179\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2576 - accuracy: 0.8815 - val_loss: 0.8268 - val_accuracy: 0.7094\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2566 - accuracy: 0.8926 - val_loss: 0.8363 - val_accuracy: 0.7009\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2592 - accuracy: 0.8852 - val_loss: 0.8414 - val_accuracy: 0.7009\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2553 - accuracy: 0.8852 - val_loss: 0.8559 - val_accuracy: 0.7009\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 0.8389 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2556 - accuracy: 0.8852 - val_loss: 0.8469 - val_accuracy: 0.7179\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2573 - accuracy: 0.8852 - val_loss: 0.8424 - val_accuracy: 0.7009\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2611 - accuracy: 0.8778 - val_loss: 0.8253 - val_accuracy: 0.7094\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2562 - accuracy: 0.8815 - val_loss: 0.8517 - val_accuracy: 0.7009\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2587 - accuracy: 0.8852 - val_loss: 0.8551 - val_accuracy: 0.7009\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2582 - accuracy: 0.8852 - val_loss: 0.8356 - val_accuracy: 0.7179\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2598 - accuracy: 0.8815 - val_loss: 0.8546 - val_accuracy: 0.7009\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.8313 - val_accuracy: 0.7009\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2601 - accuracy: 0.8741 - val_loss: 0.8445 - val_accuracy: 0.7179\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2588 - accuracy: 0.8778 - val_loss: 0.8680 - val_accuracy: 0.7009\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2580 - accuracy: 0.8815 - val_loss: 0.8545 - val_accuracy: 0.7009\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2555 - accuracy: 0.8778 - val_loss: 0.8384 - val_accuracy: 0.7179\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2549 - accuracy: 0.8852 - val_loss: 0.8381 - val_accuracy: 0.7179\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 0.8457 - val_accuracy: 0.7009\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2546 - accuracy: 0.8963 - val_loss: 0.8660 - val_accuracy: 0.7009\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2567 - accuracy: 0.8852 - val_loss: 0.8516 - val_accuracy: 0.7009\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.8336 - val_accuracy: 0.7009\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2577 - accuracy: 0.8852 - val_loss: 0.8427 - val_accuracy: 0.7009\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2586 - accuracy: 0.8667 - val_loss: 0.8512 - val_accuracy: 0.6923\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2559 - accuracy: 0.8667 - val_loss: 0.8545 - val_accuracy: 0.7179\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2551 - accuracy: 0.8852 - val_loss: 0.8491 - val_accuracy: 0.7179\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2555 - accuracy: 0.8852 - val_loss: 0.8605 - val_accuracy: 0.7009\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2553 - accuracy: 0.8852 - val_loss: 0.8480 - val_accuracy: 0.7009\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2557 - accuracy: 0.8852 - val_loss: 0.8372 - val_accuracy: 0.7094\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2571 - accuracy: 0.8778 - val_loss: 0.8628 - val_accuracy: 0.7009\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2585 - accuracy: 0.8815 - val_loss: 0.8775 - val_accuracy: 0.7009\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2549 - accuracy: 0.8815 - val_loss: 0.8388 - val_accuracy: 0.7009\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2567 - accuracy: 0.8815 - val_loss: 0.8580 - val_accuracy: 0.7009\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2598 - accuracy: 0.8852 - val_loss: 0.8636 - val_accuracy: 0.7094\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.8593 - val_accuracy: 0.7179\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2550 - accuracy: 0.8815 - val_loss: 0.8443 - val_accuracy: 0.7179\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2625 - accuracy: 0.8778 - val_loss: 0.8741 - val_accuracy: 0.7094\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2627 - accuracy: 0.8852 - val_loss: 0.8621 - val_accuracy: 0.7179\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2552 - accuracy: 0.8852 - val_loss: 0.8530 - val_accuracy: 0.7265\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 0.8516 - val_accuracy: 0.7179\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2594 - accuracy: 0.8778 - val_loss: 0.8585 - val_accuracy: 0.7009\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2576 - accuracy: 0.8852 - val_loss: 0.8614 - val_accuracy: 0.7009\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 0.8320 - val_accuracy: 0.6923\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.8561 - val_accuracy: 0.7179\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2533 - accuracy: 0.8852 - val_loss: 0.8599 - val_accuracy: 0.7009\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2565 - accuracy: 0.8741 - val_loss: 0.8572 - val_accuracy: 0.7009\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2536 - accuracy: 0.8815 - val_loss: 0.8724 - val_accuracy: 0.7179\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2575 - accuracy: 0.8852 - val_loss: 0.8623 - val_accuracy: 0.7179\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2554 - accuracy: 0.8852 - val_loss: 0.8641 - val_accuracy: 0.7179\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2537 - accuracy: 0.8852 - val_loss: 0.8437 - val_accuracy: 0.6923\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2562 - accuracy: 0.8852 - val_loss: 0.8633 - val_accuracy: 0.7009\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2537 - accuracy: 0.8778 - val_loss: 0.8484 - val_accuracy: 0.7265\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2553 - accuracy: 0.8852 - val_loss: 0.8523 - val_accuracy: 0.6923\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2546 - accuracy: 0.8852 - val_loss: 0.8751 - val_accuracy: 0.7009\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.8661 - val_accuracy: 0.7009\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.8648 - val_accuracy: 0.7009\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2520 - accuracy: 0.8852 - val_loss: 0.8692 - val_accuracy: 0.7009\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2538 - accuracy: 0.8741 - val_loss: 0.8697 - val_accuracy: 0.7179\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.8661 - val_accuracy: 0.7179\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2555 - accuracy: 0.8852 - val_loss: 0.8722 - val_accuracy: 0.7009\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 0.8578 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2538 - accuracy: 0.8778 - val_loss: 0.8497 - val_accuracy: 0.7094\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 0.8698 - val_accuracy: 0.7179\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2535 - accuracy: 0.8852 - val_loss: 0.8742 - val_accuracy: 0.7009\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2526 - accuracy: 0.8667 - val_loss: 0.8679 - val_accuracy: 0.7009\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2546 - accuracy: 0.8852 - val_loss: 0.8690 - val_accuracy: 0.7009\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2537 - accuracy: 0.8852 - val_loss: 0.8804 - val_accuracy: 0.7009\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2539 - accuracy: 0.8815 - val_loss: 0.8722 - val_accuracy: 0.6923\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2548 - accuracy: 0.8815 - val_loss: 0.8887 - val_accuracy: 0.7094\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2594 - accuracy: 0.8741 - val_loss: 0.8818 - val_accuracy: 0.7094\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2524 - accuracy: 0.8852 - val_loss: 0.8627 - val_accuracy: 0.7179\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2548 - accuracy: 0.8815 - val_loss: 0.8693 - val_accuracy: 0.7009\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2586 - accuracy: 0.8852 - val_loss: 0.8832 - val_accuracy: 0.7009\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2561 - accuracy: 0.8852 - val_loss: 0.8578 - val_accuracy: 0.6923\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2540 - accuracy: 0.8852 - val_loss: 0.8731 - val_accuracy: 0.7179\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2506 - accuracy: 0.8852 - val_loss: 0.8675 - val_accuracy: 0.7179\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2535 - accuracy: 0.8815 - val_loss: 0.8878 - val_accuracy: 0.7265\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2527 - accuracy: 0.8852 - val_loss: 0.8788 - val_accuracy: 0.7009\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.8849 - val_accuracy: 0.6923\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2504 - accuracy: 0.8852 - val_loss: 0.8628 - val_accuracy: 0.7094\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2529 - accuracy: 0.8815 - val_loss: 0.8663 - val_accuracy: 0.7094\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 0.8808 - val_accuracy: 0.7009\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2510 - accuracy: 0.8889 - val_loss: 0.8895 - val_accuracy: 0.6923\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2526 - accuracy: 0.8815 - val_loss: 0.8898 - val_accuracy: 0.7179\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 0.8621 - val_accuracy: 0.7094\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2518 - accuracy: 0.8815 - val_loss: 0.8891 - val_accuracy: 0.7179\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2522 - accuracy: 0.8852 - val_loss: 0.8821 - val_accuracy: 0.7009\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2538 - accuracy: 0.8815 - val_loss: 0.8971 - val_accuracy: 0.6923\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2520 - accuracy: 0.8815 - val_loss: 0.8824 - val_accuracy: 0.7009\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2524 - accuracy: 0.8778 - val_loss: 0.8674 - val_accuracy: 0.7265\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 0.8830 - val_accuracy: 0.7179\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.8861 - val_accuracy: 0.7009\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2521 - accuracy: 0.8852 - val_loss: 0.8711 - val_accuracy: 0.7009\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2509 - accuracy: 0.8852 - val_loss: 0.8747 - val_accuracy: 0.7009\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2540 - accuracy: 0.8852 - val_loss: 0.8915 - val_accuracy: 0.7179\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.8766 - val_accuracy: 0.7179\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.8735 - val_accuracy: 0.7009\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2529 - accuracy: 0.8852 - val_loss: 0.8853 - val_accuracy: 0.7179\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2528 - accuracy: 0.8741 - val_loss: 0.8862 - val_accuracy: 0.7179\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2543 - accuracy: 0.8630 - val_loss: 0.9049 - val_accuracy: 0.7179\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 0.8862 - val_accuracy: 0.7265\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 0.8724 - val_accuracy: 0.7009\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2529 - accuracy: 0.8778 - val_loss: 0.8976 - val_accuracy: 0.7009\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 0.8787 - val_accuracy: 0.7009\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2540 - accuracy: 0.8741 - val_loss: 0.8667 - val_accuracy: 0.7009\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2515 - accuracy: 0.8741 - val_loss: 0.9113 - val_accuracy: 0.7179\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2526 - accuracy: 0.8852 - val_loss: 0.9098 - val_accuracy: 0.7179\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 0.8861 - val_accuracy: 0.7009\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.8823 - val_accuracy: 0.7009\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2507 - accuracy: 0.8852 - val_loss: 0.8874 - val_accuracy: 0.7009\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2525 - accuracy: 0.8704 - val_loss: 0.8913 - val_accuracy: 0.7009\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2582 - accuracy: 0.8815 - val_loss: 0.8894 - val_accuracy: 0.7179\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2557 - accuracy: 0.8852 - val_loss: 0.9273 - val_accuracy: 0.7009\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2522 - accuracy: 0.8704 - val_loss: 0.8911 - val_accuracy: 0.7009\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2531 - accuracy: 0.8852 - val_loss: 0.8737 - val_accuracy: 0.7009\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2501 - accuracy: 0.8852 - val_loss: 0.8940 - val_accuracy: 0.7009\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2497 - accuracy: 0.8852 - val_loss: 0.8898 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 0.8828 - val_accuracy: 0.7009\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2489 - accuracy: 0.8852 - val_loss: 0.8932 - val_accuracy: 0.7009\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2556 - accuracy: 0.8778 - val_loss: 0.9023 - val_accuracy: 0.6923\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.8824 - val_accuracy: 0.7179\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 0.8822 - val_accuracy: 0.7009\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 0.9017 - val_accuracy: 0.7009\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 0.9057 - val_accuracy: 0.7179\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.8868 - val_accuracy: 0.7009\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2503 - accuracy: 0.8741 - val_loss: 0.8893 - val_accuracy: 0.7009\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2500 - accuracy: 0.8704 - val_loss: 0.9044 - val_accuracy: 0.7009\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2581 - accuracy: 0.8852 - val_loss: 0.8764 - val_accuracy: 0.7094\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.8994 - val_accuracy: 0.7009\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2512 - accuracy: 0.8556 - val_loss: 0.9089 - val_accuracy: 0.7009\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2500 - accuracy: 0.8852 - val_loss: 0.9055 - val_accuracy: 0.7179\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2500 - accuracy: 0.8852 - val_loss: 0.9002 - val_accuracy: 0.7009\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2481 - accuracy: 0.8852 - val_loss: 0.9042 - val_accuracy: 0.7009\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2483 - accuracy: 0.8852 - val_loss: 0.9027 - val_accuracy: 0.7094\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2517 - accuracy: 0.8741 - val_loss: 0.8817 - val_accuracy: 0.7009\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2501 - accuracy: 0.8889 - val_loss: 0.9207 - val_accuracy: 0.7179\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.93 - 0s 89us/step - loss: 0.2553 - accuracy: 0.8852 - val_loss: 0.9087 - val_accuracy: 0.7009\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 0.8894 - val_accuracy: 0.6838\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2534 - accuracy: 0.8926 - val_loss: 0.9093 - val_accuracy: 0.7179\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 0.9182 - val_accuracy: 0.7179\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2519 - accuracy: 0.8852 - val_loss: 0.9031 - val_accuracy: 0.7009\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2541 - accuracy: 0.8852 - val_loss: 0.9095 - val_accuracy: 0.7094\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2593 - accuracy: 0.8852 - val_loss: 0.9119 - val_accuracy: 0.7179\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 0.8999 - val_accuracy: 0.7094\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2553 - accuracy: 0.8852 - val_loss: 0.9144 - val_accuracy: 0.7179\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 0.9016 - val_accuracy: 0.7179\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 0.8945 - val_accuracy: 0.7009\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2484 - accuracy: 0.8778 - val_loss: 0.9078 - val_accuracy: 0.7179\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2489 - accuracy: 0.8852 - val_loss: 0.9270 - val_accuracy: 0.7179\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2481 - accuracy: 0.8852 - val_loss: 0.9085 - val_accuracy: 0.7179\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 0.9127 - val_accuracy: 0.6923\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 0.9024 - val_accuracy: 0.7009\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 0.9015 - val_accuracy: 0.7179\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2508 - accuracy: 0.8852 - val_loss: 0.9111 - val_accuracy: 0.7094\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2524 - accuracy: 0.8852 - val_loss: 0.9120 - val_accuracy: 0.7179\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2489 - accuracy: 0.8815 - val_loss: 0.9010 - val_accuracy: 0.7009\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2478 - accuracy: 0.8852 - val_loss: 0.9130 - val_accuracy: 0.6923\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 0.9086 - val_accuracy: 0.6923\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 0.8951 - val_accuracy: 0.6923\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2478 - accuracy: 0.8852 - val_loss: 0.9124 - val_accuracy: 0.7094\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 0.9311 - val_accuracy: 0.7179\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2506 - accuracy: 0.8852 - val_loss: 0.9262 - val_accuracy: 0.7179\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.9057 - val_accuracy: 0.7179\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 0.9072 - val_accuracy: 0.7179\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.9338 - val_accuracy: 0.7009\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2611 - accuracy: 0.8519 - val_loss: 0.9154 - val_accuracy: 0.7009\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 0.9120 - val_accuracy: 0.7265\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2525 - accuracy: 0.8852 - val_loss: 0.9114 - val_accuracy: 0.7179\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2517 - accuracy: 0.8852 - val_loss: 0.9167 - val_accuracy: 0.6923\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 0.9310 - val_accuracy: 0.7179\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 0.9250 - val_accuracy: 0.7179\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2511 - accuracy: 0.8667 - val_loss: 0.8911 - val_accuracy: 0.7265\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 0.9236 - val_accuracy: 0.7009\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 0.9250 - val_accuracy: 0.7009\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 0.9014 - val_accuracy: 0.7094\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2491 - accuracy: 0.8667 - val_loss: 0.9081 - val_accuracy: 0.7009\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2489 - accuracy: 0.8852 - val_loss: 0.9275 - val_accuracy: 0.7179\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 0.9287 - val_accuracy: 0.7179\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2462 - accuracy: 0.8852 - val_loss: 0.9182 - val_accuracy: 0.7009\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 0.9230 - val_accuracy: 0.7009\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 0.9331 - val_accuracy: 0.7009\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 0.9179 - val_accuracy: 0.7179\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2496 - accuracy: 0.8852 - val_loss: 0.9139 - val_accuracy: 0.6923\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2442 - accuracy: 0.8852 - val_loss: 0.9154 - val_accuracy: 0.7179\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 0.9144 - val_accuracy: 0.7179\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 0.9117 - val_accuracy: 0.7179\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 0.9245 - val_accuracy: 0.7179\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 0.9086 - val_accuracy: 0.7009\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2461 - accuracy: 0.8889 - val_loss: 0.9147 - val_accuracy: 0.7009\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 0.9299 - val_accuracy: 0.6923\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 0.9455 - val_accuracy: 0.7179\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2523 - accuracy: 0.8667 - val_loss: 0.9164 - val_accuracy: 0.7179\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.9289 - val_accuracy: 0.6923\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 0.9198 - val_accuracy: 0.7179\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 0.9218 - val_accuracy: 0.7009\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2478 - accuracy: 0.8852 - val_loss: 0.9421 - val_accuracy: 0.7009\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 0.9270 - val_accuracy: 0.6923\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.9309 - val_accuracy: 0.6923\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2489 - accuracy: 0.8852 - val_loss: 0.9218 - val_accuracy: 0.7179\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 0.9304 - val_accuracy: 0.7179\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 0.9304 - val_accuracy: 0.7009\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 0.9285 - val_accuracy: 0.7179\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2483 - accuracy: 0.8852 - val_loss: 0.9251 - val_accuracy: 0.7179\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 0.9376 - val_accuracy: 0.7179\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 0.9401 - val_accuracy: 0.7179\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2471 - accuracy: 0.8741 - val_loss: 0.9345 - val_accuracy: 0.7009\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2508 - accuracy: 0.8704 - val_loss: 0.9487 - val_accuracy: 0.7009\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2448 - accuracy: 0.8889 - val_loss: 0.9092 - val_accuracy: 0.7009\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2473 - accuracy: 0.8704 - val_loss: 0.9088 - val_accuracy: 0.7009\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.9173 - val_accuracy: 0.7179\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2456 - accuracy: 0.8852 - val_loss: 0.9397 - val_accuracy: 0.7179\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2446 - accuracy: 0.8852 - val_loss: 0.9279 - val_accuracy: 0.7179\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2549 - accuracy: 0.8741 - val_loss: 0.9196 - val_accuracy: 0.7179\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 0.9493 - val_accuracy: 0.6923\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 0.9313 - val_accuracy: 0.7009\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 0.9233 - val_accuracy: 0.7265\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 0.9358 - val_accuracy: 0.7179\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 0.9314 - val_accuracy: 0.7094\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2441 - accuracy: 0.8852 - val_loss: 0.9395 - val_accuracy: 0.7179\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 0.9284 - val_accuracy: 0.7265\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 0.9368 - val_accuracy: 0.7179\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.9375 - val_accuracy: 0.7179\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 0.9314 - val_accuracy: 0.7009\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2445 - accuracy: 0.8852 - val_loss: 0.9407 - val_accuracy: 0.7009\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 0.9328 - val_accuracy: 0.7009\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 0.9243 - val_accuracy: 0.6923\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 0.9599 - val_accuracy: 0.7179\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2461 - accuracy: 0.8852 - val_loss: 0.9591 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 0.9475 - val_accuracy: 0.7179\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 0.9185 - val_accuracy: 0.7009\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 0.9443 - val_accuracy: 0.6923\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.9422 - val_accuracy: 0.7009\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2498 - accuracy: 0.8852 - val_loss: 0.9695 - val_accuracy: 0.7179\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2452 - accuracy: 0.8852 - val_loss: 0.9292 - val_accuracy: 0.7179\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 0.9564 - val_accuracy: 0.7179\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 0.9554 - val_accuracy: 0.7179\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2445 - accuracy: 0.8852 - val_loss: 0.9421 - val_accuracy: 0.7179\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2446 - accuracy: 0.8852 - val_loss: 0.9425 - val_accuracy: 0.7179\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2439 - accuracy: 0.8852 - val_loss: 0.9455 - val_accuracy: 0.7179\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 0.9353 - val_accuracy: 0.7179\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 0.9289 - val_accuracy: 0.7265\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 0.9598 - val_accuracy: 0.7094\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 0.9574 - val_accuracy: 0.7179\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 0.9259 - val_accuracy: 0.7179\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 0.9321 - val_accuracy: 0.7094\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2452 - accuracy: 0.8852 - val_loss: 0.9549 - val_accuracy: 0.6923\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 0.9499 - val_accuracy: 0.7094\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2440 - accuracy: 0.8852 - val_loss: 0.9386 - val_accuracy: 0.7009\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 0.9191 - val_accuracy: 0.7094\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 0.9339 - val_accuracy: 0.7009\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 0.9636 - val_accuracy: 0.6752\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2490 - accuracy: 0.8741 - val_loss: 0.9585 - val_accuracy: 0.7179\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2459 - accuracy: 0.8852 - val_loss: 0.9537 - val_accuracy: 0.7179\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 0.9467 - val_accuracy: 0.6838\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2428 - accuracy: 0.8926 - val_loss: 0.9733 - val_accuracy: 0.7179\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 0.9637 - val_accuracy: 0.7265\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 0.9487 - val_accuracy: 0.7094\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 0.9597 - val_accuracy: 0.7009\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 0.9453 - val_accuracy: 0.7094\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 0.9457 - val_accuracy: 0.7009\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2466 - accuracy: 0.8704 - val_loss: 0.9571 - val_accuracy: 0.7009\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2427 - accuracy: 0.8852 - val_loss: 0.9456 - val_accuracy: 0.7009\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 0.9464 - val_accuracy: 0.7179\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 0.9633 - val_accuracy: 0.7179\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2431 - accuracy: 0.8667 - val_loss: 0.9584 - val_accuracy: 0.7179\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 0.9431 - val_accuracy: 0.7179\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 0.9495 - val_accuracy: 0.7179\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 0.9539 - val_accuracy: 0.7179\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 0.9495 - val_accuracy: 0.6923\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2440 - accuracy: 0.8852 - val_loss: 0.9591 - val_accuracy: 0.7179\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 0.9556 - val_accuracy: 0.7094\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2506 - accuracy: 0.8815 - val_loss: 0.9664 - val_accuracy: 0.7094\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 0.9677 - val_accuracy: 0.6838\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 0.9576 - val_accuracy: 0.7179\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 0.9674 - val_accuracy: 0.7179\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 0.9524 - val_accuracy: 0.7009\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.9672 - val_accuracy: 0.7179\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 0.9562 - val_accuracy: 0.7094\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 0.9554 - val_accuracy: 0.7094\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2464 - accuracy: 0.8852 - val_loss: 0.9625 - val_accuracy: 0.7094\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2441 - accuracy: 0.8667 - val_loss: 0.9683 - val_accuracy: 0.7094\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 0.9693 - val_accuracy: 0.7179\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 325us/step - loss: 0.2482 - accuracy: 0.8630 - val_loss: 0.9480 - val_accuracy: 0.7179\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 0.9598 - val_accuracy: 0.7179\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2461 - accuracy: 0.8852 - val_loss: 0.9909 - val_accuracy: 0.7009\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 0.9803 - val_accuracy: 0.7179\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.9464 - val_accuracy: 0.7179\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2442 - accuracy: 0.8852 - val_loss: 0.9655 - val_accuracy: 0.7179\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 0.9618 - val_accuracy: 0.6923\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 0.9603 - val_accuracy: 0.7179\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 0.9483 - val_accuracy: 0.7009\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 0.9782 - val_accuracy: 0.7179\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.9691 - val_accuracy: 0.7179\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 0.9715 - val_accuracy: 0.7094\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 0.9706 - val_accuracy: 0.7094\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.9683 - val_accuracy: 0.7179\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2460 - accuracy: 0.8852 - val_loss: 0.9616 - val_accuracy: 0.7009\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 0.9470 - val_accuracy: 0.7179\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.9840 - val_accuracy: 0.7179\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2451 - accuracy: 0.8852 - val_loss: 0.9791 - val_accuracy: 0.7009\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 0.9801 - val_accuracy: 0.7094\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 0.9588 - val_accuracy: 0.7179\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2451 - accuracy: 0.8852 - val_loss: 0.9508 - val_accuracy: 0.7265\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 0.9561 - val_accuracy: 0.7179\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 0.9640 - val_accuracy: 0.7009\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2464 - accuracy: 0.8741 - val_loss: 0.9423 - val_accuracy: 0.7009\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 0.9749 - val_accuracy: 0.7179\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2459 - accuracy: 0.8852 - val_loss: 0.9780 - val_accuracy: 0.7179\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 0.9641 - val_accuracy: 0.7094\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 0.9627 - val_accuracy: 0.7179\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2404 - accuracy: 0.8852 - val_loss: 0.9640 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 0.9615 - val_accuracy: 0.7009\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 0.9929 - val_accuracy: 0.7179\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 0.9592 - val_accuracy: 0.7179\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 0.9653 - val_accuracy: 0.7179\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2446 - accuracy: 0.8852 - val_loss: 0.9805 - val_accuracy: 0.7179\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 0.9797 - val_accuracy: 0.7094\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2430 - accuracy: 0.8852 - val_loss: 0.9700 - val_accuracy: 0.7179\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 0.9726 - val_accuracy: 0.7179\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2422 - accuracy: 0.8704 - val_loss: 0.9727 - val_accuracy: 0.7179\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2422 - accuracy: 0.8704 - val_loss: 0.9604 - val_accuracy: 0.7179\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 0.9810 - val_accuracy: 0.7179\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 0.9892 - val_accuracy: 0.7179\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 0.9583 - val_accuracy: 0.6923\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 0.9989 - val_accuracy: 0.6752\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2464 - accuracy: 0.8741 - val_loss: 0.9941 - val_accuracy: 0.7179\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2396 - accuracy: 0.8852 - val_loss: 0.9573 - val_accuracy: 0.7179\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 0.9516 - val_accuracy: 0.7179\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2435 - accuracy: 0.8667 - val_loss: 0.9586 - val_accuracy: 0.7179\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 0.9770 - val_accuracy: 0.7179\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2456 - accuracy: 0.8704 - val_loss: 0.9834 - val_accuracy: 0.7179\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 0.9726 - val_accuracy: 0.7009\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2499 - accuracy: 0.8852 - val_loss: 0.9450 - val_accuracy: 0.7265\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2447 - accuracy: 0.8667 - val_loss: 0.9871 - val_accuracy: 0.7094\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2441 - accuracy: 0.8667 - val_loss: 1.0034 - val_accuracy: 0.7009\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2441 - accuracy: 0.8889 - val_loss: 0.9572 - val_accuracy: 0.7094\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2478 - accuracy: 0.8593 - val_loss: 0.9706 - val_accuracy: 0.7179\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2457 - accuracy: 0.8667 - val_loss: 0.9583 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 86us/step - loss: 0.2413 - accuracy: 0.8889 - val_loss: 0.9931 - val_accuracy: 0.7179\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 0.9909 - val_accuracy: 0.6923\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.0005 - val_accuracy: 0.7094\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 0.9774 - val_accuracy: 0.7179\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2507 - accuracy: 0.8630 - val_loss: 0.9862 - val_accuracy: 0.7009\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2404 - accuracy: 0.8852 - val_loss: 0.9930 - val_accuracy: 0.7009\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 0.9856 - val_accuracy: 0.7179\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 0.9506 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2446 - accuracy: 0.8852 - val_loss: 0.9737 - val_accuracy: 0.7094\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2471 - accuracy: 0.8630 - val_loss: 1.0003 - val_accuracy: 0.7265\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2418 - accuracy: 0.8852 - val_loss: 0.9864 - val_accuracy: 0.7179\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2443 - accuracy: 0.8852 - val_loss: 0.9622 - val_accuracy: 0.7179\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 0.9655 - val_accuracy: 0.7009\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 0.9839 - val_accuracy: 0.7179\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 1.0002 - val_accuracy: 0.7094\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.9698 - val_accuracy: 0.7179\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 0.9966 - val_accuracy: 0.6838\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 0.9611 - val_accuracy: 0.6923\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 0.9895 - val_accuracy: 0.7179\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 0.9984 - val_accuracy: 0.7094\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2425 - accuracy: 0.8889 - val_loss: 0.9870 - val_accuracy: 0.7009\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 0.9723 - val_accuracy: 0.7009\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2420 - accuracy: 0.8852 - val_loss: 0.9624 - val_accuracy: 0.6923\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 0.9892 - val_accuracy: 0.7094\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 0.9833 - val_accuracy: 0.7009\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2461 - accuracy: 0.8852 - val_loss: 0.9914 - val_accuracy: 0.7179\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2399 - accuracy: 0.8778 - val_loss: 0.9939 - val_accuracy: 0.7179\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.0047 - val_accuracy: 0.7179\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2425 - accuracy: 0.8852 - val_loss: 0.9962 - val_accuracy: 0.7179\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2420 - accuracy: 0.8667 - val_loss: 0.9716 - val_accuracy: 0.7179\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2429 - accuracy: 0.8667 - val_loss: 0.9917 - val_accuracy: 0.7094\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 0.9800 - val_accuracy: 0.7179\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 0.9629 - val_accuracy: 0.7094\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 0.9937 - val_accuracy: 0.7179\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.0026 - val_accuracy: 0.7094\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 0.9863 - val_accuracy: 0.7179\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2447 - accuracy: 0.8704 - val_loss: 0.9845 - val_accuracy: 0.6923\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.0075 - val_accuracy: 0.7009\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2441 - accuracy: 0.8593 - val_loss: 0.9905 - val_accuracy: 0.7265\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2406 - accuracy: 0.8889 - val_loss: 1.0006 - val_accuracy: 0.7094\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2496 - accuracy: 0.8704 - val_loss: 0.9832 - val_accuracy: 0.7179\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2434 - accuracy: 0.8889 - val_loss: 1.0157 - val_accuracy: 0.7179\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 0.9879 - val_accuracy: 0.7265\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 0.9811 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 0.9788 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2494 - accuracy: 0.8704 - val_loss: 0.9944 - val_accuracy: 0.7179\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.0069 - val_accuracy: 0.7094\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 0.9838 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 0.9787 - val_accuracy: 0.7009\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2431 - accuracy: 0.8852 - val_loss: 1.0033 - val_accuracy: 0.7094\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2431 - accuracy: 0.8852 - val_loss: 1.0120 - val_accuracy: 0.7094\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 0.9951 - val_accuracy: 0.7009\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2476 - accuracy: 0.8704 - val_loss: 0.9660 - val_accuracy: 0.7094\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2445 - accuracy: 0.8556 - val_loss: 0.9847 - val_accuracy: 0.7009\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 1.0014 - val_accuracy: 0.7179\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 0.9937 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2425 - accuracy: 0.8852 - val_loss: 1.0030 - val_accuracy: 0.7094\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2460 - accuracy: 0.8704 - val_loss: 0.9973 - val_accuracy: 0.7009\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.0051 - val_accuracy: 0.7094\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2417 - accuracy: 0.8852 - val_loss: 0.9925 - val_accuracy: 0.7009\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 0.9877 - val_accuracy: 0.6923\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 0.9976 - val_accuracy: 0.7094\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2402 - accuracy: 0.8852 - val_loss: 0.9911 - val_accuracy: 0.7009\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2416 - accuracy: 0.8852 - val_loss: 1.0074 - val_accuracy: 0.7094\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2441 - accuracy: 0.8667 - val_loss: 0.9787 - val_accuracy: 0.7179\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.0342 - val_accuracy: 0.7094\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2420 - accuracy: 0.8852 - val_loss: 1.0052 - val_accuracy: 0.7094\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.0029 - val_accuracy: 0.7009\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.0050 - val_accuracy: 0.7094\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 1.0123 - val_accuracy: 0.7094\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 1.0024 - val_accuracy: 0.7094\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2399 - accuracy: 0.8852 - val_loss: 1.0081 - val_accuracy: 0.7179\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2390 - accuracy: 0.8704 - val_loss: 1.0136 - val_accuracy: 0.6923\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 0.9951 - val_accuracy: 0.7094\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2398 - accuracy: 0.8704 - val_loss: 1.0033 - val_accuracy: 0.7179\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2414 - accuracy: 0.8667 - val_loss: 0.9949 - val_accuracy: 0.7094\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.0193 - val_accuracy: 0.7094\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2456 - accuracy: 0.8852 - val_loss: 1.0272 - val_accuracy: 0.7094\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2399 - accuracy: 0.8815 - val_loss: 0.9833 - val_accuracy: 0.6923\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.0047 - val_accuracy: 0.7094\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2396 - accuracy: 0.8889 - val_loss: 1.0085 - val_accuracy: 0.7094\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 0.9976 - val_accuracy: 0.7094\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2416 - accuracy: 0.8630 - val_loss: 1.0197 - val_accuracy: 0.7094\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.0051 - val_accuracy: 0.7094\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2459 - accuracy: 0.8852 - val_loss: 1.0124 - val_accuracy: 0.7094\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 0.9974 - val_accuracy: 0.7009\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.0099 - val_accuracy: 0.7094\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.0453 - val_accuracy: 0.7094\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 0.9986 - val_accuracy: 0.6923\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2387 - accuracy: 0.8852 - val_loss: 1.0073 - val_accuracy: 0.7094\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 1.0151 - val_accuracy: 0.7094\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 0.9795 - val_accuracy: 0.7265\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2494 - accuracy: 0.8704 - val_loss: 1.0162 - val_accuracy: 0.7179\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2409 - accuracy: 0.8852 - val_loss: 1.0152 - val_accuracy: 0.7179\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2416 - accuracy: 0.8852 - val_loss: 1.0313 - val_accuracy: 0.7094\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2398 - accuracy: 0.8852 - val_loss: 1.0248 - val_accuracy: 0.7094\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.0084 - val_accuracy: 0.7009\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.0170 - val_accuracy: 0.7179\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.0130 - val_accuracy: 0.7179\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.0059 - val_accuracy: 0.7094\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.0211 - val_accuracy: 0.7094\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2403 - accuracy: 0.8889 - val_loss: 1.0006 - val_accuracy: 0.7265\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.0026 - val_accuracy: 0.7179\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.0206 - val_accuracy: 0.7179\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.0022 - val_accuracy: 0.7179\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 0.9908 - val_accuracy: 0.7009\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 0.9991 - val_accuracy: 0.6923\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.0091 - val_accuracy: 0.7094\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2414 - accuracy: 0.8852 - val_loss: 1.0173 - val_accuracy: 0.7094\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2384 - accuracy: 0.8741 - val_loss: 1.0017 - val_accuracy: 0.7094\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2428 - accuracy: 0.8852 - val_loss: 1.0148 - val_accuracy: 0.6923\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 0.9879 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a320cff98>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 83us/step\n",
      "over-sampling test accuracy: 70.94%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1,\n",
       "       2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 2,\n",
       "       2, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2,\n",
       "       0, 2, 0, 0, 1, 0, 0, 2, 2, 1, 2, 0, 2, 1, 1, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 1, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>834N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         SR4187     0     1\n",
       "1         NRS177     0     0\n",
       "2         NRS109     2     2\n",
       "3    CFBREBSa131     2     2\n",
       "4         SR4152     1     1\n",
       "..           ...   ...   ...\n",
       "112       NRS110     2     1\n",
       "113     CFBRSa25     1     1\n",
       "114         834N     0     0\n",
       "115  CFBREBSa114     1     1\n",
       "116       NRS387     2     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.274309e-01</td>\n",
       "      <td>5.300288e-01</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.455379e-01</td>\n",
       "      <td>4.544108e-01</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.960730e-07</td>\n",
       "      <td>2.832813e-05</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.014884e-07</td>\n",
       "      <td>2.203532e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.429662e-02</td>\n",
       "      <td>6.361464e-01</td>\n",
       "      <td>0.279557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4.274309e-01</td>\n",
       "      <td>5.300288e-01</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2.138136e-01</td>\n",
       "      <td>7.792639e-01</td>\n",
       "      <td>0.006922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>9.998555e-01</td>\n",
       "      <td>1.507464e-05</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4.274309e-01</td>\n",
       "      <td>5.300288e-01</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8.429662e-02</td>\n",
       "      <td>6.361464e-01</td>\n",
       "      <td>0.279557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    4.274309e-01  5.300288e-01  0.042540\n",
       "1    5.455379e-01  4.544108e-01  0.000051\n",
       "2    4.960730e-07  2.832813e-05  0.999971\n",
       "3    4.014884e-07  2.203532e-07  0.999999\n",
       "4    8.429662e-02  6.361464e-01  0.279557\n",
       "..            ...           ...       ...\n",
       "112  4.274309e-01  5.300288e-01  0.042540\n",
       "113  2.138136e-01  7.792639e-01  0.006922\n",
       "114  9.998555e-01  1.507464e-05  0.000129\n",
       "115  4.274309e-01  5.300288e-01  0.042540\n",
       "116  8.429662e-02  6.361464e-01  0.279557\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.2774 - val_accuracy: 0.7094\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2376 - accuracy: 0.8815 - val_loss: 1.2652 - val_accuracy: 0.7094\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2366 - accuracy: 0.8926 - val_loss: 1.2628 - val_accuracy: 0.7094\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2400 - accuracy: 0.8704 - val_loss: 1.2772 - val_accuracy: 0.7009\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2374 - accuracy: 0.8778 - val_loss: 1.2627 - val_accuracy: 0.7094\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2374 - accuracy: 0.8815 - val_loss: 1.2927 - val_accuracy: 0.7009\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2399 - accuracy: 0.8815 - val_loss: 1.2878 - val_accuracy: 0.7094\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2371 - accuracy: 0.8815 - val_loss: 1.2750 - val_accuracy: 0.7009\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2378 - accuracy: 0.8778 - val_loss: 1.2632 - val_accuracy: 0.7094\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2368 - accuracy: 0.8778 - val_loss: 1.2804 - val_accuracy: 0.7094\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2374 - accuracy: 0.8852 - val_loss: 1.2937 - val_accuracy: 0.7009\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.2824 - val_accuracy: 0.7009\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 1.2888 - val_accuracy: 0.7094\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 1.2843 - val_accuracy: 0.7009\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.2652 - val_accuracy: 0.7094\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.2741 - val_accuracy: 0.7009\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2414 - accuracy: 0.8852 - val_loss: 1.3017 - val_accuracy: 0.7265\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.2793 - val_accuracy: 0.7094\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2378 - accuracy: 0.8704 - val_loss: 1.2916 - val_accuracy: 0.7094\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.2804 - val_accuracy: 0.7094\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 1.2734 - val_accuracy: 0.7009\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2357 - accuracy: 0.8741 - val_loss: 1.2829 - val_accuracy: 0.7094\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2365 - accuracy: 0.8741 - val_loss: 1.2873 - val_accuracy: 0.7009\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2375 - accuracy: 0.8815 - val_loss: 1.2698 - val_accuracy: 0.7094\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2387 - accuracy: 0.8778 - val_loss: 1.2782 - val_accuracy: 0.7009\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2383 - accuracy: 0.8852 - val_loss: 1.2971 - val_accuracy: 0.7094\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2370 - accuracy: 0.8741 - val_loss: 1.2812 - val_accuracy: 0.7094\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2385 - accuracy: 0.8815 - val_loss: 1.2718 - val_accuracy: 0.7094\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2384 - accuracy: 0.8815 - val_loss: 1.3117 - val_accuracy: 0.7094\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 1.3056 - val_accuracy: 0.7094\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2364 - accuracy: 0.8741 - val_loss: 1.2839 - val_accuracy: 0.7094\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2399 - accuracy: 0.8741 - val_loss: 1.2759 - val_accuracy: 0.7009\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.3108 - val_accuracy: 0.7094\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2413 - accuracy: 0.8704 - val_loss: 1.2973 - val_accuracy: 0.7094\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2375 - accuracy: 0.8778 - val_loss: 1.2821 - val_accuracy: 0.7179\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.3177 - val_accuracy: 0.7094\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2464 - accuracy: 0.8704 - val_loss: 1.2958 - val_accuracy: 0.7094\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2376 - accuracy: 0.8815 - val_loss: 1.2857 - val_accuracy: 0.7009\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2363 - accuracy: 0.8889 - val_loss: 1.2965 - val_accuracy: 0.7094\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 1.2883 - val_accuracy: 0.7009\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2386 - accuracy: 0.8778 - val_loss: 1.3002 - val_accuracy: 0.7094\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2362 - accuracy: 0.8889 - val_loss: 1.2989 - val_accuracy: 0.7094\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 1.3047 - val_accuracy: 0.7094\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2361 - accuracy: 0.8778 - val_loss: 1.2981 - val_accuracy: 0.7009\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2368 - accuracy: 0.8815 - val_loss: 1.3132 - val_accuracy: 0.7094\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.2898 - val_accuracy: 0.7009\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2380 - accuracy: 0.8667 - val_loss: 1.2894 - val_accuracy: 0.7094\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2396 - accuracy: 0.8704 - val_loss: 1.2996 - val_accuracy: 0.7094\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.3035 - val_accuracy: 0.7179\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.2930 - val_accuracy: 0.7094\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2357 - accuracy: 0.8704 - val_loss: 1.2787 - val_accuracy: 0.7094\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 1.2949 - val_accuracy: 0.7094\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2381 - accuracy: 0.8630 - val_loss: 1.2934 - val_accuracy: 0.7094\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2388 - accuracy: 0.8815 - val_loss: 1.3202 - val_accuracy: 0.7265\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 1.3173 - val_accuracy: 0.7179\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2386 - accuracy: 0.8852 - val_loss: 1.2922 - val_accuracy: 0.7179\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2394 - accuracy: 0.8815 - val_loss: 1.2911 - val_accuracy: 0.7179\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2379 - accuracy: 0.8963 - val_loss: 1.3400 - val_accuracy: 0.7094\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 1.3011 - val_accuracy: 0.7094\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2385 - accuracy: 0.8778 - val_loss: 1.2938 - val_accuracy: 0.7094\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2355 - accuracy: 0.8815 - val_loss: 1.3072 - val_accuracy: 0.7094\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2425 - accuracy: 0.8852 - val_loss: 1.3264 - val_accuracy: 0.7094\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.2375 - accuracy: 0.8815 - val_loss: 1.3092 - val_accuracy: 0.7179\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 331us/step - loss: 0.2364 - accuracy: 0.8815 - val_loss: 1.3067 - val_accuracy: 0.7094\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2367 - accuracy: 0.8741 - val_loss: 1.2965 - val_accuracy: 0.7094\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2368 - accuracy: 0.8778 - val_loss: 1.3125 - val_accuracy: 0.7009\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.3119 - val_accuracy: 0.7094\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.3382 - val_accuracy: 0.7009\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2387 - accuracy: 0.8852 - val_loss: 1.3156 - val_accuracy: 0.7094\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2393 - accuracy: 0.8852 - val_loss: 1.2909 - val_accuracy: 0.7179\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 689us/step - loss: 0.2378 - accuracy: 0.8741 - val_loss: 1.3149 - val_accuracy: 0.7094\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 352us/step - loss: 0.2419 - accuracy: 0.8852 - val_loss: 1.3347 - val_accuracy: 0.7094\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2374 - accuracy: 0.8889 - val_loss: 1.2990 - val_accuracy: 0.7094\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2377 - accuracy: 0.8741 - val_loss: 1.3155 - val_accuracy: 0.7094\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.3563 - val_accuracy: 0.7009\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.3164 - val_accuracy: 0.7094\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2359 - accuracy: 0.8704 - val_loss: 1.3104 - val_accuracy: 0.7094\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2393 - accuracy: 0.8704 - val_loss: 1.3125 - val_accuracy: 0.7094\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2373 - accuracy: 0.8815 - val_loss: 1.3424 - val_accuracy: 0.7265\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2386 - accuracy: 0.8741 - val_loss: 1.3203 - val_accuracy: 0.7094\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2405 - accuracy: 0.8704 - val_loss: 1.3405 - val_accuracy: 0.6923\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2388 - accuracy: 0.8704 - val_loss: 1.3081 - val_accuracy: 0.7094\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.3366 - val_accuracy: 0.7009\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.3454 - val_accuracy: 0.7009\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.3397 - val_accuracy: 0.7094\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2361 - accuracy: 0.8778 - val_loss: 1.3280 - val_accuracy: 0.7179\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.3409 - val_accuracy: 0.7094\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 1.3528 - val_accuracy: 0.7094\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2376 - accuracy: 0.8778 - val_loss: 1.3223 - val_accuracy: 0.7179\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2366 - accuracy: 0.8889 - val_loss: 1.3629 - val_accuracy: 0.7009\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 1.3317 - val_accuracy: 0.7094\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 448us/step - loss: 0.2412 - accuracy: 0.8852 - val_loss: 1.3334 - val_accuracy: 0.7094\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2365 - accuracy: 0.8778 - val_loss: 1.3266 - val_accuracy: 0.7179\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.3218 - val_accuracy: 0.7094\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.3443 - val_accuracy: 0.7179\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2410 - accuracy: 0.8852 - val_loss: 1.3120 - val_accuracy: 0.7179\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2413 - accuracy: 0.8667 - val_loss: 1.3359 - val_accuracy: 0.7179\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.3207 - val_accuracy: 0.7179\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2386 - accuracy: 0.8815 - val_loss: 1.3266 - val_accuracy: 0.7179\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2367 - accuracy: 0.8778 - val_loss: 1.3303 - val_accuracy: 0.7179\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.3627 - val_accuracy: 0.7179\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.3374 - val_accuracy: 0.7094\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 1.3356 - val_accuracy: 0.7179\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 1.3348 - val_accuracy: 0.7094\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.3362 - val_accuracy: 0.7094\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2388 - accuracy: 0.8741 - val_loss: 1.3470 - val_accuracy: 0.7179\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.3251 - val_accuracy: 0.7094\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.3551 - val_accuracy: 0.7094\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.3690 - val_accuracy: 0.7094\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.3504 - val_accuracy: 0.7179\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.3387 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2371 - accuracy: 0.8667 - val_loss: 1.3390 - val_accuracy: 0.7094\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.3525 - val_accuracy: 0.7094\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 1.3412 - val_accuracy: 0.7179\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2425 - accuracy: 0.8593 - val_loss: 1.3228 - val_accuracy: 0.7009\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2373 - accuracy: 0.8704 - val_loss: 1.3626 - val_accuracy: 0.7179\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.3620 - val_accuracy: 0.7179\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2369 - accuracy: 0.8926 - val_loss: 1.3584 - val_accuracy: 0.7179\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 1.3205 - val_accuracy: 0.7179\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.3445 - val_accuracy: 0.7179\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.3642 - val_accuracy: 0.7094\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.3480 - val_accuracy: 0.7094\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.3364 - val_accuracy: 0.7009\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2340 - accuracy: 0.8778 - val_loss: 1.3664 - val_accuracy: 0.7179\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2361 - accuracy: 0.8815 - val_loss: 1.3681 - val_accuracy: 0.7094\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 1.3508 - val_accuracy: 0.7094\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.3645 - val_accuracy: 0.7094\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2358 - accuracy: 0.8889 - val_loss: 1.3333 - val_accuracy: 0.7094\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2392 - accuracy: 0.8741 - val_loss: 1.3525 - val_accuracy: 0.7094\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2379 - accuracy: 0.8852 - val_loss: 1.3568 - val_accuracy: 0.7094\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2377 - accuracy: 0.8741 - val_loss: 1.3655 - val_accuracy: 0.7094\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.3476 - val_accuracy: 0.7009\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.3447 - val_accuracy: 0.7009\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2356 - accuracy: 0.8704 - val_loss: 1.3526 - val_accuracy: 0.7094\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.2352 - accuracy: 0.8778 - val_loss: 1.3739 - val_accuracy: 0.7094\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 489us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.3647 - val_accuracy: 0.7009\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 1.3405 - val_accuracy: 0.7009\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2353 - accuracy: 0.8778 - val_loss: 1.3503 - val_accuracy: 0.7094\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 410us/step - loss: 0.2398 - accuracy: 0.8815 - val_loss: 1.3547 - val_accuracy: 0.7094\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 257us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.3684 - val_accuracy: 0.7094\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 358us/step - loss: 0.2366 - accuracy: 0.8889 - val_loss: 1.3588 - val_accuracy: 0.7009\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.3551 - val_accuracy: 0.7094\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 1.3557 - val_accuracy: 0.7009\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.3572 - val_accuracy: 0.7009\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2416 - accuracy: 0.8889 - val_loss: 1.4003 - val_accuracy: 0.7009\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 1.3579 - val_accuracy: 0.7094\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.3778 - val_accuracy: 0.7009\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.3892 - val_accuracy: 0.7094\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.3782 - val_accuracy: 0.7094\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.3849 - val_accuracy: 0.7094\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2393 - accuracy: 0.8815 - val_loss: 1.3791 - val_accuracy: 0.7094\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2414 - accuracy: 0.8704 - val_loss: 1.3728 - val_accuracy: 0.7009\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2330 - accuracy: 0.8926 - val_loss: 1.3485 - val_accuracy: 0.7179\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.3616 - val_accuracy: 0.7179\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 1.3998 - val_accuracy: 0.7009\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.3949 - val_accuracy: 0.7094\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2383 - accuracy: 0.8852 - val_loss: 1.3714 - val_accuracy: 0.7094\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.2373 - accuracy: 0.8889 - val_loss: 1.3496 - val_accuracy: 0.7179\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.3673 - val_accuracy: 0.7094\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2378 - accuracy: 0.8815 - val_loss: 1.3614 - val_accuracy: 0.7094\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.3883 - val_accuracy: 0.7094\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2380 - accuracy: 0.8852 - val_loss: 1.3826 - val_accuracy: 0.7009\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2372 - accuracy: 0.8815 - val_loss: 1.3677 - val_accuracy: 0.7094\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2368 - accuracy: 0.8778 - val_loss: 1.3845 - val_accuracy: 0.7094\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.3817 - val_accuracy: 0.7094\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.3542 - val_accuracy: 0.7094\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2391 - accuracy: 0.8704 - val_loss: 1.3793 - val_accuracy: 0.7094\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2351 - accuracy: 0.8815 - val_loss: 1.3638 - val_accuracy: 0.7009\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.3816 - val_accuracy: 0.7094\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 1.3883 - val_accuracy: 0.7094\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.3767 - val_accuracy: 0.7009\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.3733 - val_accuracy: 0.7179\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.4088 - val_accuracy: 0.7265\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.3708 - val_accuracy: 0.7179\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.4002 - val_accuracy: 0.7179\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2347 - accuracy: 0.8889 - val_loss: 1.4064 - val_accuracy: 0.7094\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.3921 - val_accuracy: 0.7009\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2374 - accuracy: 0.8630 - val_loss: 1.3770 - val_accuracy: 0.7094\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 1.3714 - val_accuracy: 0.7094\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2371 - accuracy: 0.8815 - val_loss: 1.3762 - val_accuracy: 0.6923\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2355 - accuracy: 0.8815 - val_loss: 1.3927 - val_accuracy: 0.7094\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.4108 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.4041 - val_accuracy: 0.7179\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.2372 - accuracy: 0.8815 - val_loss: 1.3745 - val_accuracy: 0.7094\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2341 - accuracy: 0.8815 - val_loss: 1.3962 - val_accuracy: 0.7009\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.4139 - val_accuracy: 0.7094\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2374 - accuracy: 0.8852 - val_loss: 1.4076 - val_accuracy: 0.7094\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.3903 - val_accuracy: 0.7009\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2397 - accuracy: 0.8852 - val_loss: 1.3808 - val_accuracy: 0.7009\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.3855 - val_accuracy: 0.7179\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.3834 - val_accuracy: 0.7179\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 300us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.4036 - val_accuracy: 0.7179\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 228us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.3938 - val_accuracy: 0.7094\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.3889 - val_accuracy: 0.7179\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2339 - accuracy: 0.8815 - val_loss: 1.4057 - val_accuracy: 0.7094\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.4123 - val_accuracy: 0.7094\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2386 - accuracy: 0.8778 - val_loss: 1.3814 - val_accuracy: 0.7179\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2425 - accuracy: 0.8667 - val_loss: 1.3858 - val_accuracy: 0.6923\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.4329 - val_accuracy: 0.7009\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2391 - accuracy: 0.8741 - val_loss: 1.4110 - val_accuracy: 0.7094\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2390 - accuracy: 0.8778 - val_loss: 1.3932 - val_accuracy: 0.7009\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.4040 - val_accuracy: 0.7009\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2386 - accuracy: 0.8778 - val_loss: 1.4026 - val_accuracy: 0.7094\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2355 - accuracy: 0.8815 - val_loss: 1.4091 - val_accuracy: 0.7009\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2372 - accuracy: 0.8815 - val_loss: 1.4029 - val_accuracy: 0.7094\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.4134 - val_accuracy: 0.7094\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 1.4224 - val_accuracy: 0.7009\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2355 - accuracy: 0.8778 - val_loss: 1.4076 - val_accuracy: 0.7179\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2340 - accuracy: 0.8815 - val_loss: 1.4131 - val_accuracy: 0.6923\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2379 - accuracy: 0.8778 - val_loss: 1.4175 - val_accuracy: 0.7265\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 1.4229 - val_accuracy: 0.7094\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.4026 - val_accuracy: 0.7179\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.3807 - val_accuracy: 0.7179\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2375 - accuracy: 0.8778 - val_loss: 1.3886 - val_accuracy: 0.7094\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2348 - accuracy: 0.8704 - val_loss: 1.4196 - val_accuracy: 0.7009\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2407 - accuracy: 0.8852 - val_loss: 1.4263 - val_accuracy: 0.7009\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 1.3878 - val_accuracy: 0.7009\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2346 - accuracy: 0.8815 - val_loss: 1.4029 - val_accuracy: 0.7179\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2392 - accuracy: 0.8630 - val_loss: 1.4229 - val_accuracy: 0.7094\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2366 - accuracy: 0.8926 - val_loss: 1.4197 - val_accuracy: 0.7009\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 1.3925 - val_accuracy: 0.7094\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 139us/step - loss: 0.2362 - accuracy: 0.8815 - val_loss: 1.4123 - val_accuracy: 0.7094\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2345 - accuracy: 0.8778 - val_loss: 1.4337 - val_accuracy: 0.7009\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2387 - accuracy: 0.8852 - val_loss: 1.4149 - val_accuracy: 0.7265\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.4290 - val_accuracy: 0.7094\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.4168 - val_accuracy: 0.7179\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2355 - accuracy: 0.8704 - val_loss: 1.4152 - val_accuracy: 0.7265\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2352 - accuracy: 0.8926 - val_loss: 1.4181 - val_accuracy: 0.7009\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 1.4205 - val_accuracy: 0.7009\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.3950 - val_accuracy: 0.7094\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2347 - accuracy: 0.8889 - val_loss: 1.4332 - val_accuracy: 0.7009\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 1.4401 - val_accuracy: 0.7009\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2363 - accuracy: 0.8889 - val_loss: 1.4147 - val_accuracy: 0.7094\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.4270 - val_accuracy: 0.7009\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2374 - accuracy: 0.8889 - val_loss: 1.3965 - val_accuracy: 0.7094\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.4333 - val_accuracy: 0.7009\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2362 - accuracy: 0.8889 - val_loss: 1.4304 - val_accuracy: 0.7094\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2386 - accuracy: 0.8815 - val_loss: 1.4259 - val_accuracy: 0.7094\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2378 - accuracy: 0.8704 - val_loss: 1.3810 - val_accuracy: 0.7265\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.3987 - val_accuracy: 0.7094\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 1.4525 - val_accuracy: 0.7009\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2382 - accuracy: 0.8815 - val_loss: 1.4431 - val_accuracy: 0.6923\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2342 - accuracy: 0.8815 - val_loss: 1.4230 - val_accuracy: 0.7009\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2364 - accuracy: 0.8778 - val_loss: 1.4187 - val_accuracy: 0.7009\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.4238 - val_accuracy: 0.6923\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 1.4355 - val_accuracy: 0.7009\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2337 - accuracy: 0.8889 - val_loss: 1.4154 - val_accuracy: 0.7179\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2354 - accuracy: 0.8815 - val_loss: 1.4267 - val_accuracy: 0.7179\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2411 - accuracy: 0.8630 - val_loss: 1.4489 - val_accuracy: 0.7179\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.2320 - accuracy: 0.8926 - val_loss: 1.4357 - val_accuracy: 0.7179\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.4353 - val_accuracy: 0.7094\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 265us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.4413 - val_accuracy: 0.7009\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2415 - accuracy: 0.8852 - val_loss: 1.4450 - val_accuracy: 0.7009\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2379 - accuracy: 0.8815 - val_loss: 1.4274 - val_accuracy: 0.7179\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.4504 - val_accuracy: 0.6923\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.4518 - val_accuracy: 0.7179\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2379 - accuracy: 0.8852 - val_loss: 1.4285 - val_accuracy: 0.7009\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.4492 - val_accuracy: 0.7179\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2362 - accuracy: 0.8815 - val_loss: 1.4444 - val_accuracy: 0.7009\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.4246 - val_accuracy: 0.7094\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2372 - accuracy: 0.8741 - val_loss: 1.3856 - val_accuracy: 0.7179\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2367 - accuracy: 0.8815 - val_loss: 1.4175 - val_accuracy: 0.7179\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 1.4271 - val_accuracy: 0.7094\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2379 - accuracy: 0.8667 - val_loss: 1.4036 - val_accuracy: 0.7179\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.4341 - val_accuracy: 0.7094\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.4246 - val_accuracy: 0.7094\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.4065 - val_accuracy: 0.7179\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2387 - accuracy: 0.8630 - val_loss: 1.4116 - val_accuracy: 0.7009\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.4398 - val_accuracy: 0.7009\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.4590 - val_accuracy: 0.6838\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2350 - accuracy: 0.8778 - val_loss: 1.3990 - val_accuracy: 0.6923\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2410 - accuracy: 0.8852 - val_loss: 1.4015 - val_accuracy: 0.7094\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2379 - accuracy: 0.8815 - val_loss: 1.4376 - val_accuracy: 0.7009\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 1.4412 - val_accuracy: 0.7009\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.4347 - val_accuracy: 0.6923\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2378 - accuracy: 0.8704 - val_loss: 1.4425 - val_accuracy: 0.7009\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2389 - accuracy: 0.8852 - val_loss: 1.4594 - val_accuracy: 0.7009\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 1.4434 - val_accuracy: 0.7009\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2375 - accuracy: 0.8815 - val_loss: 1.4422 - val_accuracy: 0.7179\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.4573 - val_accuracy: 0.7179\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2410 - accuracy: 0.8852 - val_loss: 1.4478 - val_accuracy: 0.7179\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2392 - accuracy: 0.8630 - val_loss: 1.4343 - val_accuracy: 0.7009\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.4393 - val_accuracy: 0.7094\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.4673 - val_accuracy: 0.7179\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.4430 - val_accuracy: 0.7179\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 1.4437 - val_accuracy: 0.7179\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2376 - accuracy: 0.8852 - val_loss: 1.4433 - val_accuracy: 0.7009\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2410 - accuracy: 0.8704 - val_loss: 1.4521 - val_accuracy: 0.7179\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2364 - accuracy: 0.8667 - val_loss: 1.4670 - val_accuracy: 0.7009\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2342 - accuracy: 0.8741 - val_loss: 1.4614 - val_accuracy: 0.7179\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.4627 - val_accuracy: 0.7179\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2378 - accuracy: 0.8889 - val_loss: 1.4274 - val_accuracy: 0.7265\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2357 - accuracy: 0.8889 - val_loss: 1.4678 - val_accuracy: 0.7009\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 1.4488 - val_accuracy: 0.7009\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2374 - accuracy: 0.8741 - val_loss: 1.4188 - val_accuracy: 0.6923\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2364 - accuracy: 0.8889 - val_loss: 1.4460 - val_accuracy: 0.7009\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.4597 - val_accuracy: 0.7009\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2351 - accuracy: 0.8741 - val_loss: 1.4447 - val_accuracy: 0.7009\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2395 - accuracy: 0.8630 - val_loss: 1.4223 - val_accuracy: 0.7094\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2388 - accuracy: 0.8778 - val_loss: 1.4495 - val_accuracy: 0.7009\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2388 - accuracy: 0.8815 - val_loss: 1.4828 - val_accuracy: 0.6923\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2351 - accuracy: 0.8815 - val_loss: 1.4619 - val_accuracy: 0.7094\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2355 - accuracy: 0.8630 - val_loss: 1.4454 - val_accuracy: 0.7009\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 1.4791 - val_accuracy: 0.7009\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.4465 - val_accuracy: 0.6923\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 1.4468 - val_accuracy: 0.6923\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2364 - accuracy: 0.8778 - val_loss: 1.4436 - val_accuracy: 0.7009\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2392 - accuracy: 0.8704 - val_loss: 1.4721 - val_accuracy: 0.7009\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.4614 - val_accuracy: 0.6923\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.4803 - val_accuracy: 0.6923\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.4589 - val_accuracy: 0.7009\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2387 - accuracy: 0.8741 - val_loss: 1.4821 - val_accuracy: 0.7179\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2354 - accuracy: 0.8778 - val_loss: 1.4876 - val_accuracy: 0.7179\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2347 - accuracy: 0.8889 - val_loss: 1.4923 - val_accuracy: 0.7179\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 1.4655 - val_accuracy: 0.7179\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2375 - accuracy: 0.8815 - val_loss: 1.4559 - val_accuracy: 0.7009\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2361 - accuracy: 0.8889 - val_loss: 1.4674 - val_accuracy: 0.7179\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.4524 - val_accuracy: 0.7009\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2374 - accuracy: 0.8704 - val_loss: 1.4636 - val_accuracy: 0.7009\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.4798 - val_accuracy: 0.7009\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.4673 - val_accuracy: 0.7179\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.4699 - val_accuracy: 0.7009\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.4733 - val_accuracy: 0.7009\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2367 - accuracy: 0.8815 - val_loss: 1.4817 - val_accuracy: 0.7009\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2333 - accuracy: 0.8778 - val_loss: 1.4883 - val_accuracy: 0.7265\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2383 - accuracy: 0.8778 - val_loss: 1.4857 - val_accuracy: 0.7179\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.4629 - val_accuracy: 0.7009\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2366 - accuracy: 0.8704 - val_loss: 1.4833 - val_accuracy: 0.7094\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2335 - accuracy: 0.8815 - val_loss: 1.4796 - val_accuracy: 0.7009\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.4765 - val_accuracy: 0.6923\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.4751 - val_accuracy: 0.6923\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 91us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4985 - val_accuracy: 0.7179\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.4606 - val_accuracy: 0.7009\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2359 - accuracy: 0.8815 - val_loss: 1.4809 - val_accuracy: 0.7094\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2373 - accuracy: 0.8815 - val_loss: 1.4963 - val_accuracy: 0.7009\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2333 - accuracy: 0.8963 - val_loss: 1.4775 - val_accuracy: 0.7094\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.4813 - val_accuracy: 0.7094\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2379 - accuracy: 0.8815 - val_loss: 1.4884 - val_accuracy: 0.7009\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.4866 - val_accuracy: 0.7094\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2347 - accuracy: 0.8778 - val_loss: 1.4990 - val_accuracy: 0.7009\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2356 - accuracy: 0.8852 - val_loss: 1.4930 - val_accuracy: 0.7009\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 1.4895 - val_accuracy: 0.7094\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2348 - accuracy: 0.8815 - val_loss: 1.4749 - val_accuracy: 0.7265\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.8556 - val_loss: 1.4880 - val_accuracy: 0.7009\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2372 - accuracy: 0.8778 - val_loss: 1.4718 - val_accuracy: 0.7009\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.4947 - val_accuracy: 0.6923\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2368 - accuracy: 0.8852 - val_loss: 1.5112 - val_accuracy: 0.7009\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.4853 - val_accuracy: 0.6923\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2357 - accuracy: 0.8778 - val_loss: 1.4723 - val_accuracy: 0.7009\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2370 - accuracy: 0.8741 - val_loss: 1.4978 - val_accuracy: 0.7009\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.4947 - val_accuracy: 0.6923\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2377 - accuracy: 0.8704 - val_loss: 1.5117 - val_accuracy: 0.6923\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.4886 - val_accuracy: 0.6923\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.4850 - val_accuracy: 0.6923\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2359 - accuracy: 0.8815 - val_loss: 1.4786 - val_accuracy: 0.6923\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.4999 - val_accuracy: 0.7094\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2377 - accuracy: 0.8852 - val_loss: 1.4996 - val_accuracy: 0.6923\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2383 - accuracy: 0.8741 - val_loss: 1.5044 - val_accuracy: 0.6923\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2373 - accuracy: 0.8667 - val_loss: 1.5252 - val_accuracy: 0.7179\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.5109 - val_accuracy: 0.7094\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.4952 - val_accuracy: 0.7094\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2347 - accuracy: 0.8778 - val_loss: 1.5022 - val_accuracy: 0.7009\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.5077 - val_accuracy: 0.6923\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.5080 - val_accuracy: 0.7009\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.5003 - val_accuracy: 0.7009\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2338 - accuracy: 0.8741 - val_loss: 1.4948 - val_accuracy: 0.7094\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2371 - accuracy: 0.8741 - val_loss: 1.5067 - val_accuracy: 0.6923\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2401 - accuracy: 0.8852 - val_loss: 1.5109 - val_accuracy: 0.7179\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.4726 - val_accuracy: 0.7009\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2371 - accuracy: 0.8815 - val_loss: 1.5219 - val_accuracy: 0.7094\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2383 - accuracy: 0.8852 - val_loss: 1.5086 - val_accuracy: 0.7009\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2383 - accuracy: 0.8630 - val_loss: 1.5281 - val_accuracy: 0.7009\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.5430 - val_accuracy: 0.7179\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.5355 - val_accuracy: 0.7179\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.5162 - val_accuracy: 0.7179\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2380 - accuracy: 0.8815 - val_loss: 1.5239 - val_accuracy: 0.7009\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.4998 - val_accuracy: 0.7009\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2345 - accuracy: 0.8815 - val_loss: 1.5029 - val_accuracy: 0.7094\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2349 - accuracy: 0.8889 - val_loss: 1.4839 - val_accuracy: 0.7179\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2379 - accuracy: 0.8889 - val_loss: 1.5160 - val_accuracy: 0.7094\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.5090 - val_accuracy: 0.7179\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2371 - accuracy: 0.8704 - val_loss: 1.5189 - val_accuracy: 0.7009\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.5045 - val_accuracy: 0.7094\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2364 - accuracy: 0.8815 - val_loss: 1.5086 - val_accuracy: 0.7094\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2360 - accuracy: 0.8778 - val_loss: 1.5228 - val_accuracy: 0.7094\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2374 - accuracy: 0.8852 - val_loss: 1.5309 - val_accuracy: 0.7094\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.5228 - val_accuracy: 0.7094\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2389 - accuracy: 0.8741 - val_loss: 1.5117 - val_accuracy: 0.7094\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.5129 - val_accuracy: 0.7094\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.5553 - val_accuracy: 0.7265\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2404 - accuracy: 0.8889 - val_loss: 1.5445 - val_accuracy: 0.7009\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2372 - accuracy: 0.8778 - val_loss: 1.5090 - val_accuracy: 0.7179\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2362 - accuracy: 0.8778 - val_loss: 1.5231 - val_accuracy: 0.7094\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.5280 - val_accuracy: 0.7009\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.5335 - val_accuracy: 0.7009\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.5126 - val_accuracy: 0.7094\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2329 - accuracy: 0.8889 - val_loss: 1.5223 - val_accuracy: 0.7009\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.5344 - val_accuracy: 0.7094\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.5337 - val_accuracy: 0.7009\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2376 - accuracy: 0.8741 - val_loss: 1.5076 - val_accuracy: 0.7094\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2365 - accuracy: 0.8815 - val_loss: 1.5320 - val_accuracy: 0.7009\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2348 - accuracy: 0.8889 - val_loss: 1.5264 - val_accuracy: 0.7094\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2342 - accuracy: 0.8778 - val_loss: 1.5075 - val_accuracy: 0.7094\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2370 - accuracy: 0.8815 - val_loss: 1.5059 - val_accuracy: 0.7179\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2379 - accuracy: 0.8815 - val_loss: 1.5240 - val_accuracy: 0.7094\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2377 - accuracy: 0.8741 - val_loss: 1.5202 - val_accuracy: 0.7094\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2364 - accuracy: 0.8778 - val_loss: 1.5424 - val_accuracy: 0.7094\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.5432 - val_accuracy: 0.7094\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.5412 - val_accuracy: 0.7009\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.5304 - val_accuracy: 0.7094\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2338 - accuracy: 0.8778 - val_loss: 1.5345 - val_accuracy: 0.7094\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2346 - accuracy: 0.8815 - val_loss: 1.5581 - val_accuracy: 0.7094\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.5465 - val_accuracy: 0.7094\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.5469 - val_accuracy: 0.7094\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.5236 - val_accuracy: 0.7094\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2415 - accuracy: 0.8704 - val_loss: 1.5433 - val_accuracy: 0.7265\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.5259 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2341 - accuracy: 0.8815 - val_loss: 1.5325 - val_accuracy: 0.7009\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2328 - accuracy: 0.8889 - val_loss: 1.5244 - val_accuracy: 0.7094\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.5433 - val_accuracy: 0.7009\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.5523 - val_accuracy: 0.7094\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.5395 - val_accuracy: 0.7009\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2351 - accuracy: 0.8815 - val_loss: 1.5382 - val_accuracy: 0.7094\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2348 - accuracy: 0.8778 - val_loss: 1.5614 - val_accuracy: 0.7094\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 1.5539 - val_accuracy: 0.7009\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.5365 - val_accuracy: 0.7009\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2351 - accuracy: 0.8704 - val_loss: 1.5485 - val_accuracy: 0.7009\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.5599 - val_accuracy: 0.7009\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.5698 - val_accuracy: 0.7009\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2357 - accuracy: 0.8889 - val_loss: 1.5515 - val_accuracy: 0.7094\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2386 - accuracy: 0.8778 - val_loss: 1.5317 - val_accuracy: 0.7094\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2363 - accuracy: 0.8778 - val_loss: 1.5704 - val_accuracy: 0.7265\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2378 - accuracy: 0.8704 - val_loss: 1.5537 - val_accuracy: 0.7009\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 1.5605 - val_accuracy: 0.7009\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2348 - accuracy: 0.8704 - val_loss: 1.5567 - val_accuracy: 0.7009\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2362 - accuracy: 0.8852 - val_loss: 1.5710 - val_accuracy: 0.7009\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.5516 - val_accuracy: 0.7009\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2314 - accuracy: 0.8926 - val_loss: 1.5346 - val_accuracy: 0.7094\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.5428 - val_accuracy: 0.7009\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2342 - accuracy: 0.8815 - val_loss: 1.5677 - val_accuracy: 0.6923\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.5814 - val_accuracy: 0.7009\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.5494 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2369 - accuracy: 0.8741 - val_loss: 1.5641 - val_accuracy: 0.7179\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2350 - accuracy: 0.8778 - val_loss: 1.5703 - val_accuracy: 0.7094\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.5721 - val_accuracy: 0.7009\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.5610 - val_accuracy: 0.6923\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2361 - accuracy: 0.8778 - val_loss: 1.5544 - val_accuracy: 0.7009\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.5676 - val_accuracy: 0.7179\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.5819 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2370 - accuracy: 0.8852 - val_loss: 1.5725 - val_accuracy: 0.7009\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.5561 - val_accuracy: 0.7094\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2366 - accuracy: 0.8815 - val_loss: 1.5615 - val_accuracy: 0.7094\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2360 - accuracy: 0.8593 - val_loss: 1.5533 - val_accuracy: 0.6923\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.5588 - val_accuracy: 0.6923\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2354 - accuracy: 0.8815 - val_loss: 1.5824 - val_accuracy: 0.6923\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2376 - accuracy: 0.8667 - val_loss: 1.5528 - val_accuracy: 0.6923\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2396 - accuracy: 0.8852 - val_loss: 1.5538 - val_accuracy: 0.7009\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2372 - accuracy: 0.8889 - val_loss: 1.5367 - val_accuracy: 0.7094\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2348 - accuracy: 0.8815 - val_loss: 1.5557 - val_accuracy: 0.7009\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2355 - accuracy: 0.8889 - val_loss: 1.5988 - val_accuracy: 0.7009\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2385 - accuracy: 0.8815 - val_loss: 1.5504 - val_accuracy: 0.7009\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.5381 - val_accuracy: 0.7094\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.5493 - val_accuracy: 0.7094\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.5830 - val_accuracy: 0.7009\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.5638 - val_accuracy: 0.7009\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 1.5446 - val_accuracy: 0.7094\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.5585 - val_accuracy: 0.7265\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.5670 - val_accuracy: 0.7265\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.5866 - val_accuracy: 0.7094\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.5759 - val_accuracy: 0.7094\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2354 - accuracy: 0.8704 - val_loss: 1.5706 - val_accuracy: 0.7265\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.5526 - val_accuracy: 0.7265\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2395 - accuracy: 0.8741 - val_loss: 1.5926 - val_accuracy: 0.7179\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2343 - accuracy: 0.8889 - val_loss: 1.5637 - val_accuracy: 0.7094\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2345 - accuracy: 0.8815 - val_loss: 1.5697 - val_accuracy: 0.7094\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 1.5756 - val_accuracy: 0.7179\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2379 - accuracy: 0.8741 - val_loss: 1.5571 - val_accuracy: 0.7094\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2358 - accuracy: 0.8852 - val_loss: 1.5749 - val_accuracy: 0.6923\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.5672 - val_accuracy: 0.6923\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.5755 - val_accuracy: 0.6923\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.5571 - val_accuracy: 0.7009\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2374 - accuracy: 0.8741 - val_loss: 1.5797 - val_accuracy: 0.6923\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2325 - accuracy: 0.8926 - val_loss: 1.5697 - val_accuracy: 0.7094\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.5688 - val_accuracy: 0.7009\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2358 - accuracy: 0.8889 - val_loss: 1.5795 - val_accuracy: 0.7009\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2331 - accuracy: 0.8889 - val_loss: 1.5805 - val_accuracy: 0.7009\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.5650 - val_accuracy: 0.7094\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.5858 - val_accuracy: 0.7179\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.5687 - val_accuracy: 0.7094\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2344 - accuracy: 0.8741 - val_loss: 1.5717 - val_accuracy: 0.7179\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2364 - accuracy: 0.8815 - val_loss: 1.5647 - val_accuracy: 0.7094\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.5971 - val_accuracy: 0.7009\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 1.5711 - val_accuracy: 0.7009\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2359 - accuracy: 0.8778 - val_loss: 1.5753 - val_accuracy: 0.7094\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.5826 - val_accuracy: 0.7094\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.5806 - val_accuracy: 0.6923\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.5893 - val_accuracy: 0.7009\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.5648 - val_accuracy: 0.7094\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2343 - accuracy: 0.8778 - val_loss: 1.5905 - val_accuracy: 0.6923\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.5770 - val_accuracy: 0.6923\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.5735 - val_accuracy: 0.7094\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2340 - accuracy: 0.8667 - val_loss: 1.5807 - val_accuracy: 0.7009\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2345 - accuracy: 0.8741 - val_loss: 1.5897 - val_accuracy: 0.7009\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2380 - accuracy: 0.8741 - val_loss: 1.5898 - val_accuracy: 0.7009\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 1.5764 - val_accuracy: 0.6923\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.5805 - val_accuracy: 0.7094\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.5819 - val_accuracy: 0.7094\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2351 - accuracy: 0.8815 - val_loss: 1.5897 - val_accuracy: 0.6923\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2324 - accuracy: 0.8889 - val_loss: 1.5880 - val_accuracy: 0.7009\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2369 - accuracy: 0.8852 - val_loss: 1.5907 - val_accuracy: 0.7179\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2329 - accuracy: 0.8889 - val_loss: 1.5816 - val_accuracy: 0.7094\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.5931 - val_accuracy: 0.7009\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2334 - accuracy: 0.8778 - val_loss: 1.5968 - val_accuracy: 0.7179\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.5844 - val_accuracy: 0.7179\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.5996 - val_accuracy: 0.7009\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.5927 - val_accuracy: 0.7009\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2399 - accuracy: 0.8741 - val_loss: 1.5720 - val_accuracy: 0.7009\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2322 - accuracy: 0.8741 - val_loss: 1.5847 - val_accuracy: 0.7094\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2360 - accuracy: 0.8815 - val_loss: 1.5843 - val_accuracy: 0.6923\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.5995 - val_accuracy: 0.7009\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2372 - accuracy: 0.8630 - val_loss: 1.5651 - val_accuracy: 0.7179\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2371 - accuracy: 0.8815 - val_loss: 1.5759 - val_accuracy: 0.7094\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.5703 - val_accuracy: 0.7094\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 1.5820 - val_accuracy: 0.7009\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2368 - accuracy: 0.8778 - val_loss: 1.5457 - val_accuracy: 0.7179\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.5712 - val_accuracy: 0.7094\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2352 - accuracy: 0.8889 - val_loss: 1.5737 - val_accuracy: 0.7009\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.5752 - val_accuracy: 0.7094\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2348 - accuracy: 0.8741 - val_loss: 1.5801 - val_accuracy: 0.7009\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.5887 - val_accuracy: 0.7009\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.6002 - val_accuracy: 0.7094\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2360 - accuracy: 0.8778 - val_loss: 1.5727 - val_accuracy: 0.7094\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.5808 - val_accuracy: 0.7009\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2362 - accuracy: 0.8815 - val_loss: 1.6005 - val_accuracy: 0.6923\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2382 - accuracy: 0.8519 - val_loss: 1.5839 - val_accuracy: 0.6923\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2374 - accuracy: 0.8815 - val_loss: 1.6009 - val_accuracy: 0.7009\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2353 - accuracy: 0.8889 - val_loss: 1.5816 - val_accuracy: 0.7094\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.5723 - val_accuracy: 0.7094\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.5897 - val_accuracy: 0.7009\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2378 - accuracy: 0.8778 - val_loss: 1.5815 - val_accuracy: 0.7094\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2365 - accuracy: 0.8778 - val_loss: 1.6007 - val_accuracy: 0.7009\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.5919 - val_accuracy: 0.7009\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2348 - accuracy: 0.8889 - val_loss: 1.5767 - val_accuracy: 0.7094\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2365 - accuracy: 0.8815 - val_loss: 1.5958 - val_accuracy: 0.7009\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2348 - accuracy: 0.8889 - val_loss: 1.5859 - val_accuracy: 0.7094\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2363 - accuracy: 0.8889 - val_loss: 1.6040 - val_accuracy: 0.7179\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2357 - accuracy: 0.8815 - val_loss: 1.5956 - val_accuracy: 0.7009\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2354 - accuracy: 0.8815 - val_loss: 1.6101 - val_accuracy: 0.7009\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2367 - accuracy: 0.8815 - val_loss: 1.6244 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.6053 - val_accuracy: 0.7009\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2326 - accuracy: 0.8926 - val_loss: 1.5901 - val_accuracy: 0.7094\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2361 - accuracy: 0.8815 - val_loss: 1.5901 - val_accuracy: 0.6923\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.6321 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.6133 - val_accuracy: 0.7265\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2369 - accuracy: 0.8815 - val_loss: 1.5810 - val_accuracy: 0.7094\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.6033 - val_accuracy: 0.7009\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2331 - accuracy: 0.8778 - val_loss: 1.5986 - val_accuracy: 0.7009\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.6089 - val_accuracy: 0.7009\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.6087 - val_accuracy: 0.6923\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.5911 - val_accuracy: 0.7094\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.6348 - val_accuracy: 0.7179\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.6294 - val_accuracy: 0.7094\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.6053 - val_accuracy: 0.7179\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.5957 - val_accuracy: 0.7009\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2340 - accuracy: 0.8778 - val_loss: 1.6134 - val_accuracy: 0.7179\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2401 - accuracy: 0.8852 - val_loss: 1.6280 - val_accuracy: 0.7179\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2357 - accuracy: 0.8778 - val_loss: 1.5966 - val_accuracy: 0.7265\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.6107 - val_accuracy: 0.7094\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.6232 - val_accuracy: 0.7179\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.6157 - val_accuracy: 0.7179\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2329 - accuracy: 0.8704 - val_loss: 1.6095 - val_accuracy: 0.7094\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2358 - accuracy: 0.8667 - val_loss: 1.6016 - val_accuracy: 0.7094\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2345 - accuracy: 0.8741 - val_loss: 1.5933 - val_accuracy: 0.6923\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.6025 - val_accuracy: 0.7009\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.6040 - val_accuracy: 0.6923\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2344 - accuracy: 0.8778 - val_loss: 1.6025 - val_accuracy: 0.7009\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2372 - accuracy: 0.8815 - val_loss: 1.6457 - val_accuracy: 0.7179\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.6032 - val_accuracy: 0.7179\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.6145 - val_accuracy: 0.7094\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2341 - accuracy: 0.8815 - val_loss: 1.6337 - val_accuracy: 0.7094\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2379 - accuracy: 0.8667 - val_loss: 1.6368 - val_accuracy: 0.7094\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2339 - accuracy: 0.8815 - val_loss: 1.5989 - val_accuracy: 0.7265\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.6246 - val_accuracy: 0.7094\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2344 - accuracy: 0.8778 - val_loss: 1.6287 - val_accuracy: 0.7094\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.6326 - val_accuracy: 0.7009\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2372 - accuracy: 0.8852 - val_loss: 1.6370 - val_accuracy: 0.7009\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2339 - accuracy: 0.8889 - val_loss: 1.6036 - val_accuracy: 0.7094\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2349 - accuracy: 0.8815 - val_loss: 1.6184 - val_accuracy: 0.7179\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.6504 - val_accuracy: 0.7179\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.6393 - val_accuracy: 0.7179\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.5885 - val_accuracy: 0.7094\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2363 - accuracy: 0.8704 - val_loss: 1.6008 - val_accuracy: 0.6923\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2376 - accuracy: 0.8889 - val_loss: 1.6223 - val_accuracy: 0.7009\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.6230 - val_accuracy: 0.6923\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2344 - accuracy: 0.8778 - val_loss: 1.6261 - val_accuracy: 0.7094\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.6392 - val_accuracy: 0.7094\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2393 - accuracy: 0.8741 - val_loss: 1.6448 - val_accuracy: 0.7265\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 1.6167 - val_accuracy: 0.7094\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2395 - accuracy: 0.8815 - val_loss: 1.6159 - val_accuracy: 0.7094\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2367 - accuracy: 0.8704 - val_loss: 1.6175 - val_accuracy: 0.7179\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2351 - accuracy: 0.8852 - val_loss: 1.6397 - val_accuracy: 0.7179\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.6398 - val_accuracy: 0.7179\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.6382 - val_accuracy: 0.7179\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.6301 - val_accuracy: 0.7179\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2350 - accuracy: 0.8778 - val_loss: 1.6188 - val_accuracy: 0.7094\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2336 - accuracy: 0.8778 - val_loss: 1.6300 - val_accuracy: 0.7094\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.6371 - val_accuracy: 0.7094\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.6245 - val_accuracy: 0.7094\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2350 - accuracy: 0.8704 - val_loss: 1.5981 - val_accuracy: 0.7179\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2378 - accuracy: 0.8630 - val_loss: 1.6180 - val_accuracy: 0.7094\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 337us/step - loss: 0.2366 - accuracy: 0.8815 - val_loss: 1.6182 - val_accuracy: 0.7094\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.6499 - val_accuracy: 0.7094\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2371 - accuracy: 0.8778 - val_loss: 1.6138 - val_accuracy: 0.7094\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2430 - accuracy: 0.8667 - val_loss: 1.6178 - val_accuracy: 0.7179\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2360 - accuracy: 0.8741 - val_loss: 1.6248 - val_accuracy: 0.7094\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2357 - accuracy: 0.8741 - val_loss: 1.6591 - val_accuracy: 0.7009\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2345 - accuracy: 0.8852 - val_loss: 1.6437 - val_accuracy: 0.7009\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2348 - accuracy: 0.8815 - val_loss: 1.6288 - val_accuracy: 0.7179\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 376us/step - loss: 0.2333 - accuracy: 0.8815 - val_loss: 1.6295 - val_accuracy: 0.7179\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.6483 - val_accuracy: 0.7265\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2345 - accuracy: 0.8815 - val_loss: 1.6477 - val_accuracy: 0.7179\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2342 - accuracy: 0.8815 - val_loss: 1.6325 - val_accuracy: 0.7179\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.6361 - val_accuracy: 0.6923\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2337 - accuracy: 0.8889 - val_loss: 1.6335 - val_accuracy: 0.6923\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2333 - accuracy: 0.8741 - val_loss: 1.6346 - val_accuracy: 0.7094\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2339 - accuracy: 0.8778 - val_loss: 1.6610 - val_accuracy: 0.6923\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2355 - accuracy: 0.8889 - val_loss: 1.6566 - val_accuracy: 0.7094\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2353 - accuracy: 0.8667 - val_loss: 1.6467 - val_accuracy: 0.7094\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2337 - accuracy: 0.8778 - val_loss: 1.6399 - val_accuracy: 0.7094\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2350 - accuracy: 0.8889 - val_loss: 1.6543 - val_accuracy: 0.7179\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.6531 - val_accuracy: 0.6923\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2332 - accuracy: 0.8741 - val_loss: 1.6444 - val_accuracy: 0.6923\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2338 - accuracy: 0.8741 - val_loss: 1.6542 - val_accuracy: 0.6923\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2334 - accuracy: 0.8778 - val_loss: 1.6393 - val_accuracy: 0.7009\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2320 - accuracy: 0.8815 - val_loss: 1.6339 - val_accuracy: 0.7179\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.6262 - val_accuracy: 0.7009\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.6473 - val_accuracy: 0.7009\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.6518 - val_accuracy: 0.7009\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2327 - accuracy: 0.8778 - val_loss: 1.6464 - val_accuracy: 0.7094\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2357 - accuracy: 0.8815 - val_loss: 1.6342 - val_accuracy: 0.7094\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2344 - accuracy: 0.8741 - val_loss: 1.6745 - val_accuracy: 0.7009\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.6606 - val_accuracy: 0.7009\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2343 - accuracy: 0.8778 - val_loss: 1.6458 - val_accuracy: 0.6923\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2353 - accuracy: 0.8889 - val_loss: 1.6603 - val_accuracy: 0.7009\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.6581 - val_accuracy: 0.7094\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2335 - accuracy: 0.8926 - val_loss: 1.6484 - val_accuracy: 0.7009\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2361 - accuracy: 0.8815 - val_loss: 1.6450 - val_accuracy: 0.7009\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2362 - accuracy: 0.8778 - val_loss: 1.6818 - val_accuracy: 0.7179\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2343 - accuracy: 0.8778 - val_loss: 1.6619 - val_accuracy: 0.7265\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2407 - accuracy: 0.8630 - val_loss: 1.6389 - val_accuracy: 0.7265\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2365 - accuracy: 0.8815 - val_loss: 1.6768 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.6468 - val_accuracy: 0.7265\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2398 - accuracy: 0.8815 - val_loss: 1.6376 - val_accuracy: 0.7094\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2342 - accuracy: 0.8778 - val_loss: 1.6588 - val_accuracy: 0.7009\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2373 - accuracy: 0.8852 - val_loss: 1.6732 - val_accuracy: 0.7009\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2372 - accuracy: 0.8704 - val_loss: 1.6392 - val_accuracy: 0.7094\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2386 - accuracy: 0.8741 - val_loss: 1.6745 - val_accuracy: 0.7265\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2323 - accuracy: 0.8815 - val_loss: 1.6496 - val_accuracy: 0.7094\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2364 - accuracy: 0.8815 - val_loss: 1.6815 - val_accuracy: 0.7179\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.6542 - val_accuracy: 0.7009\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.2334 - accuracy: 0.8778 - val_loss: 1.6466 - val_accuracy: 0.7009\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.6515 - val_accuracy: 0.7094\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2350 - accuracy: 0.8778 - val_loss: 1.6626 - val_accuracy: 0.7009\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 126us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 1.6622 - val_accuracy: 0.6923\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2435 - accuracy: 0.8852 - val_loss: 1.6448 - val_accuracy: 0.7265\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.6669 - val_accuracy: 0.7094\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.6657 - val_accuracy: 0.7009\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2325 - accuracy: 0.8852 - val_loss: 1.6472 - val_accuracy: 0.7009\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 1.6472 - val_accuracy: 0.7009\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.6569 - val_accuracy: 0.7009\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2347 - accuracy: 0.8778 - val_loss: 1.6656 - val_accuracy: 0.6923\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2341 - accuracy: 0.8889 - val_loss: 1.6632 - val_accuracy: 0.6923\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2349 - accuracy: 0.8778 - val_loss: 1.6648 - val_accuracy: 0.7009\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.6509 - val_accuracy: 0.7009\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2358 - accuracy: 0.8704 - val_loss: 1.6633 - val_accuracy: 0.6923\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.6980 - val_accuracy: 0.7009\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.6701 - val_accuracy: 0.6923\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2359 - accuracy: 0.8815 - val_loss: 1.6578 - val_accuracy: 0.6923\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2357 - accuracy: 0.8741 - val_loss: 1.6631 - val_accuracy: 0.7265\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2348 - accuracy: 0.8815 - val_loss: 1.6860 - val_accuracy: 0.7009\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2319 - accuracy: 0.8852 - val_loss: 1.7206 - val_accuracy: 0.7179\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.6999 - val_accuracy: 0.7009\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2337 - accuracy: 0.8815 - val_loss: 1.6834 - val_accuracy: 0.6923\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 1.6760 - val_accuracy: 0.6923\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.7053 - val_accuracy: 0.6923\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2345 - accuracy: 0.8741 - val_loss: 1.6965 - val_accuracy: 0.6923\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2361 - accuracy: 0.8741 - val_loss: 1.7047 - val_accuracy: 0.7009\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2349 - accuracy: 0.8778 - val_loss: 1.7116 - val_accuracy: 0.7009\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2379 - accuracy: 0.8778 - val_loss: 1.6802 - val_accuracy: 0.7179\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.2344 - accuracy: 0.8704 - val_loss: 1.6863 - val_accuracy: 0.7009\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2365 - accuracy: 0.8815 - val_loss: 1.7066 - val_accuracy: 0.7009\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2343 - accuracy: 0.8926 - val_loss: 1.6985 - val_accuracy: 0.7094\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2354 - accuracy: 0.8815 - val_loss: 1.6884 - val_accuracy: 0.7009\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.6916 - val_accuracy: 0.6923\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.7034 - val_accuracy: 0.6923\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.6871 - val_accuracy: 0.7009\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2326 - accuracy: 0.8815 - val_loss: 1.6916 - val_accuracy: 0.7179\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2360 - accuracy: 0.8815 - val_loss: 1.6965 - val_accuracy: 0.7009\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 1.6958 - val_accuracy: 0.7094\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2356 - accuracy: 0.8741 - val_loss: 1.7020 - val_accuracy: 0.6923\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2359 - accuracy: 0.8852 - val_loss: 1.6910 - val_accuracy: 0.6838\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.7022 - val_accuracy: 0.6923\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2362 - accuracy: 0.8889 - val_loss: 1.6879 - val_accuracy: 0.7094\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.6804 - val_accuracy: 0.7094\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.7318 - val_accuracy: 0.7094\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2340 - accuracy: 0.8778 - val_loss: 1.7038 - val_accuracy: 0.7179\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2331 - accuracy: 0.8815 - val_loss: 1.6926 - val_accuracy: 0.7009\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2337 - accuracy: 0.8741 - val_loss: 1.6960 - val_accuracy: 0.7094\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2335 - accuracy: 0.8815 - val_loss: 1.7094 - val_accuracy: 0.7094\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2376 - accuracy: 0.8778 - val_loss: 1.7028 - val_accuracy: 0.7094\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.6908 - val_accuracy: 0.7009\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.6926 - val_accuracy: 0.7265\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.6830 - val_accuracy: 0.7009\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.6946 - val_accuracy: 0.7094\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 1.7028 - val_accuracy: 0.7094\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.7018 - val_accuracy: 0.7009\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2335 - accuracy: 0.8704 - val_loss: 1.6976 - val_accuracy: 0.7094\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.7039 - val_accuracy: 0.7009\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2382 - accuracy: 0.8778 - val_loss: 1.6822 - val_accuracy: 0.7350\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2354 - accuracy: 0.8815 - val_loss: 1.6860 - val_accuracy: 0.7094\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.6852 - val_accuracy: 0.7094\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2342 - accuracy: 0.8704 - val_loss: 1.7088 - val_accuracy: 0.7009\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2347 - accuracy: 0.8852 - val_loss: 1.7071 - val_accuracy: 0.7094\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.6818 - val_accuracy: 0.7009\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 1.6878 - val_accuracy: 0.7009\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2333 - accuracy: 0.8852 - val_loss: 1.7013 - val_accuracy: 0.7009\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.7024 - val_accuracy: 0.7009\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.6972 - val_accuracy: 0.7179\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.7112 - val_accuracy: 0.7179\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 1.7113 - val_accuracy: 0.7179\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.6998 - val_accuracy: 0.7179\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.7113 - val_accuracy: 0.7179\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2370 - accuracy: 0.8630 - val_loss: 1.7044 - val_accuracy: 0.7094\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2350 - accuracy: 0.8778 - val_loss: 1.6970 - val_accuracy: 0.7009\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.7146 - val_accuracy: 0.7094\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2328 - accuracy: 0.8815 - val_loss: 1.6919 - val_accuracy: 0.6923\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2368 - accuracy: 0.8704 - val_loss: 1.6938 - val_accuracy: 0.7094\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2328 - accuracy: 0.8741 - val_loss: 1.7241 - val_accuracy: 0.6923\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 1.7289 - val_accuracy: 0.7179\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2338 - accuracy: 0.8815 - val_loss: 1.7291 - val_accuracy: 0.7265\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2361 - accuracy: 0.8741 - val_loss: 1.7220 - val_accuracy: 0.7094\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2339 - accuracy: 0.8778 - val_loss: 1.7182 - val_accuracy: 0.6923\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2366 - accuracy: 0.8852 - val_loss: 1.7256 - val_accuracy: 0.7009\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2346 - accuracy: 0.8778 - val_loss: 1.7172 - val_accuracy: 0.7009\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2341 - accuracy: 0.8815 - val_loss: 1.7111 - val_accuracy: 0.7009\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.7038 - val_accuracy: 0.7009\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.6961 - val_accuracy: 0.7009\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2345 - accuracy: 0.8741 - val_loss: 1.7247 - val_accuracy: 0.7009\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2366 - accuracy: 0.8889 - val_loss: 1.7107 - val_accuracy: 0.7009\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2356 - accuracy: 0.8926 - val_loss: 1.7059 - val_accuracy: 0.7179\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2394 - accuracy: 0.8815 - val_loss: 1.7289 - val_accuracy: 0.7179\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2336 - accuracy: 0.8778 - val_loss: 1.6942 - val_accuracy: 0.7265\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2363 - accuracy: 0.8815 - val_loss: 1.6860 - val_accuracy: 0.7094\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.6944 - val_accuracy: 0.7009\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2344 - accuracy: 0.8704 - val_loss: 1.6995 - val_accuracy: 0.7094\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 1.6980 - val_accuracy: 0.7094\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 1.6955 - val_accuracy: 0.7009\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.7126 - val_accuracy: 0.7009\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2334 - accuracy: 0.8741 - val_loss: 1.7027 - val_accuracy: 0.7094\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2345 - accuracy: 0.8815 - val_loss: 1.6932 - val_accuracy: 0.7009\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2364 - accuracy: 0.8667 - val_loss: 1.7280 - val_accuracy: 0.7094\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2367 - accuracy: 0.8778 - val_loss: 1.7302 - val_accuracy: 0.7094\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2340 - accuracy: 0.8778 - val_loss: 1.7163 - val_accuracy: 0.7094\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2391 - accuracy: 0.8778 - val_loss: 1.7264 - val_accuracy: 0.7179\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.6991 - val_accuracy: 0.7179\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.7161 - val_accuracy: 0.7009\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2342 - accuracy: 0.8889 - val_loss: 1.7421 - val_accuracy: 0.6923\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2358 - accuracy: 0.8741 - val_loss: 1.7165 - val_accuracy: 0.7009\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2377 - accuracy: 0.8667 - val_loss: 1.7173 - val_accuracy: 0.7009\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2340 - accuracy: 0.8704 - val_loss: 1.7170 - val_accuracy: 0.7094\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2367 - accuracy: 0.8704 - val_loss: 1.7135 - val_accuracy: 0.7094\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2340 - accuracy: 0.8815 - val_loss: 1.7132 - val_accuracy: 0.7009\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2396 - accuracy: 0.8630 - val_loss: 1.7170 - val_accuracy: 0.7009\n",
      "Epoch 774/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 137us/step - loss: 0.2322 - accuracy: 0.8778 - val_loss: 1.7395 - val_accuracy: 0.7009\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2355 - accuracy: 0.8815 - val_loss: 1.7202 - val_accuracy: 0.7265\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2384 - accuracy: 0.8667 - val_loss: 1.7230 - val_accuracy: 0.7094\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2340 - accuracy: 0.8815 - val_loss: 1.7227 - val_accuracy: 0.7179\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2340 - accuracy: 0.8778 - val_loss: 1.7409 - val_accuracy: 0.7179\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2362 - accuracy: 0.8741 - val_loss: 1.7320 - val_accuracy: 0.7179\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2347 - accuracy: 0.8815 - val_loss: 1.7242 - val_accuracy: 0.7094\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 446us/step - loss: 0.2328 - accuracy: 0.8778 - val_loss: 1.7218 - val_accuracy: 0.7009\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 224us/step - loss: 0.2360 - accuracy: 0.8852 - val_loss: 1.7287 - val_accuracy: 0.7009\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2344 - accuracy: 0.8852 - val_loss: 1.7176 - val_accuracy: 0.6923\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2347 - accuracy: 0.8778 - val_loss: 1.7295 - val_accuracy: 0.7094\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2334 - accuracy: 0.8778 - val_loss: 1.7456 - val_accuracy: 0.7009\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2381 - accuracy: 0.8778 - val_loss: 1.7253 - val_accuracy: 0.7265\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2339 - accuracy: 0.8704 - val_loss: 1.7118 - val_accuracy: 0.7179\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2368 - accuracy: 0.8815 - val_loss: 1.7346 - val_accuracy: 0.7094\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2389 - accuracy: 0.8815 - val_loss: 1.7341 - val_accuracy: 0.7009\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2396 - accuracy: 0.8704 - val_loss: 1.7028 - val_accuracy: 0.7094\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2330 - accuracy: 0.8741 - val_loss: 1.7458 - val_accuracy: 0.7094\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.7469 - val_accuracy: 0.7009\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 1.7301 - val_accuracy: 0.7094\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2369 - accuracy: 0.8741 - val_loss: 1.7018 - val_accuracy: 0.7094\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2329 - accuracy: 0.8741 - val_loss: 1.7399 - val_accuracy: 0.7009\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.7342 - val_accuracy: 0.7009\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2378 - accuracy: 0.8778 - val_loss: 1.7083 - val_accuracy: 0.7009\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2326 - accuracy: 0.8889 - val_loss: 1.7323 - val_accuracy: 0.7009\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 1.7530 - val_accuracy: 0.7009\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2444 - accuracy: 0.8630 - val_loss: 1.7333 - val_accuracy: 0.7009\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2349 - accuracy: 0.8815 - val_loss: 1.7241 - val_accuracy: 0.7009\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2371 - accuracy: 0.8741 - val_loss: 1.7411 - val_accuracy: 0.7179\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2366 - accuracy: 0.8741 - val_loss: 1.7211 - val_accuracy: 0.7094\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2322 - accuracy: 0.8815 - val_loss: 1.7328 - val_accuracy: 0.7094\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 1.7505 - val_accuracy: 0.7009\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.7325 - val_accuracy: 0.6923\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.7289 - val_accuracy: 0.7094\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2356 - accuracy: 0.8815 - val_loss: 1.7435 - val_accuracy: 0.7094\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2367 - accuracy: 0.8778 - val_loss: 1.7238 - val_accuracy: 0.7009\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.7316 - val_accuracy: 0.7094\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2345 - accuracy: 0.8889 - val_loss: 1.7450 - val_accuracy: 0.7094\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2359 - accuracy: 0.8778 - val_loss: 1.7456 - val_accuracy: 0.7094\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2338 - accuracy: 0.8630 - val_loss: 1.7343 - val_accuracy: 0.7094\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.7165 - val_accuracy: 0.7350\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2359 - accuracy: 0.8926 - val_loss: 1.7093 - val_accuracy: 0.7094\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2359 - accuracy: 0.8815 - val_loss: 1.7274 - val_accuracy: 0.7009\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2381 - accuracy: 0.8852 - val_loss: 1.7204 - val_accuracy: 0.7009\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.7212 - val_accuracy: 0.7094\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2342 - accuracy: 0.8815 - val_loss: 1.7451 - val_accuracy: 0.7094\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.7265 - val_accuracy: 0.7009\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 1.7457 - val_accuracy: 0.7179\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 1.7490 - val_accuracy: 0.7009\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2339 - accuracy: 0.8852 - val_loss: 1.7368 - val_accuracy: 0.7265\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.7480 - val_accuracy: 0.7009\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2350 - accuracy: 0.8741 - val_loss: 1.7311 - val_accuracy: 0.7265\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2364 - accuracy: 0.8852 - val_loss: 1.7620 - val_accuracy: 0.7179\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2363 - accuracy: 0.8852 - val_loss: 1.7595 - val_accuracy: 0.7009\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2348 - accuracy: 0.8815 - val_loss: 1.7328 - val_accuracy: 0.7094\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2353 - accuracy: 0.8852 - val_loss: 1.7447 - val_accuracy: 0.7009\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 1.7528 - val_accuracy: 0.7009\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.7693 - val_accuracy: 0.7094\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2373 - accuracy: 0.8815 - val_loss: 1.7405 - val_accuracy: 0.7009\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.7642 - val_accuracy: 0.7179\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2370 - accuracy: 0.8926 - val_loss: 1.7249 - val_accuracy: 0.7094\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2389 - accuracy: 0.8815 - val_loss: 1.7400 - val_accuracy: 0.7179\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 1.7738 - val_accuracy: 0.7009\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.7873 - val_accuracy: 0.7265\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2369 - accuracy: 0.8704 - val_loss: 1.7593 - val_accuracy: 0.7265\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2305 - accuracy: 0.8889 - val_loss: 1.7494 - val_accuracy: 0.7265\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 1.7395 - val_accuracy: 0.7094\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.7345 - val_accuracy: 0.7009\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2324 - accuracy: 0.8852 - val_loss: 1.7750 - val_accuracy: 0.7094\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2400 - accuracy: 0.8667 - val_loss: 1.7840 - val_accuracy: 0.7009\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2350 - accuracy: 0.8741 - val_loss: 1.7519 - val_accuracy: 0.7350\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2353 - accuracy: 0.8778 - val_loss: 1.7510 - val_accuracy: 0.7094\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 410us/step - loss: 0.2343 - accuracy: 0.8778 - val_loss: 1.7270 - val_accuracy: 0.7265\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2343 - accuracy: 0.8815 - val_loss: 1.7432 - val_accuracy: 0.7265\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 1.7550 - val_accuracy: 0.7265\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 1.7690 - val_accuracy: 0.7265\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.7656 - val_accuracy: 0.7094\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2321 - accuracy: 0.8741 - val_loss: 1.7454 - val_accuracy: 0.7094\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2342 - accuracy: 0.8593 - val_loss: 1.7505 - val_accuracy: 0.7009\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2327 - accuracy: 0.8815 - val_loss: 1.7613 - val_accuracy: 0.7179\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 1.7755 - val_accuracy: 0.7094\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2362 - accuracy: 0.8630 - val_loss: 1.7645 - val_accuracy: 0.7094\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2326 - accuracy: 0.8815 - val_loss: 1.7769 - val_accuracy: 0.7265\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.7827 - val_accuracy: 0.7094\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2352 - accuracy: 0.8852 - val_loss: 1.7681 - val_accuracy: 0.7094\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2326 - accuracy: 0.8741 - val_loss: 1.7718 - val_accuracy: 0.7094\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2350 - accuracy: 0.8741 - val_loss: 1.7574 - val_accuracy: 0.7265\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2330 - accuracy: 0.8815 - val_loss: 1.7717 - val_accuracy: 0.7179\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2403 - accuracy: 0.8852 - val_loss: 1.7983 - val_accuracy: 0.7265\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 1.7483 - val_accuracy: 0.7265\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2353 - accuracy: 0.8815 - val_loss: 1.7742 - val_accuracy: 0.7094\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.7685 - val_accuracy: 0.7179\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.7734 - val_accuracy: 0.7265\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2326 - accuracy: 0.8704 - val_loss: 1.7945 - val_accuracy: 0.7265\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2370 - accuracy: 0.8815 - val_loss: 1.8040 - val_accuracy: 0.7265\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2378 - accuracy: 0.8852 - val_loss: 1.7833 - val_accuracy: 0.7265\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2343 - accuracy: 0.8852 - val_loss: 1.8019 - val_accuracy: 0.7265\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2380 - accuracy: 0.8778 - val_loss: 1.7872 - val_accuracy: 0.7179\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.7830 - val_accuracy: 0.7265\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2367 - accuracy: 0.8852 - val_loss: 1.7857 - val_accuracy: 0.7179\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2320 - accuracy: 0.8778 - val_loss: 1.7763 - val_accuracy: 0.7350\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2369 - accuracy: 0.8667 - val_loss: 1.7708 - val_accuracy: 0.7265\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2324 - accuracy: 0.8815 - val_loss: 1.7543 - val_accuracy: 0.7179\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2358 - accuracy: 0.8815 - val_loss: 1.7621 - val_accuracy: 0.7009\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 1.8026 - val_accuracy: 0.7179\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2339 - accuracy: 0.8889 - val_loss: 1.7469 - val_accuracy: 0.7179\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2398 - accuracy: 0.8815 - val_loss: 1.7545 - val_accuracy: 0.7009\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2293 - accuracy: 0.8815 - val_loss: 1.7800 - val_accuracy: 0.7179\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.7785 - val_accuracy: 0.7179\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2328 - accuracy: 0.8889 - val_loss: 1.7559 - val_accuracy: 0.7179\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 128us/step - loss: 0.2360 - accuracy: 0.8815 - val_loss: 1.7633 - val_accuracy: 0.7179\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2329 - accuracy: 0.8852 - val_loss: 1.7840 - val_accuracy: 0.7009\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 1.7689 - val_accuracy: 0.7179\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2357 - accuracy: 0.8667 - val_loss: 1.7720 - val_accuracy: 0.7009\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2335 - accuracy: 0.8815 - val_loss: 1.7767 - val_accuracy: 0.7009\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2327 - accuracy: 0.8852 - val_loss: 1.7880 - val_accuracy: 0.7179\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 1.7823 - val_accuracy: 0.7179\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2317 - accuracy: 0.8852 - val_loss: 1.7680 - val_accuracy: 0.7094\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2337 - accuracy: 0.8815 - val_loss: 1.7641 - val_accuracy: 0.7009\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.7939 - val_accuracy: 0.7179\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.8153 - val_accuracy: 0.7179\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.7926 - val_accuracy: 0.7350\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2351 - accuracy: 0.8815 - val_loss: 1.7825 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2330 - accuracy: 0.8852 - val_loss: 1.7953 - val_accuracy: 0.7179\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2355 - accuracy: 0.8852 - val_loss: 1.7950 - val_accuracy: 0.7094\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2331 - accuracy: 0.8852 - val_loss: 1.7731 - val_accuracy: 0.7094\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2396 - accuracy: 0.8741 - val_loss: 1.7631 - val_accuracy: 0.7179\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2329 - accuracy: 0.8815 - val_loss: 1.8051 - val_accuracy: 0.7179\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.8002 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 1.7935 - val_accuracy: 0.7265\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.7811 - val_accuracy: 0.7179\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.7987 - val_accuracy: 0.7179\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.7932 - val_accuracy: 0.6923\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2332 - accuracy: 0.8852 - val_loss: 1.7825 - val_accuracy: 0.7009\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2341 - accuracy: 0.8778 - val_loss: 1.7923 - val_accuracy: 0.7009\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.8032 - val_accuracy: 0.7265\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2359 - accuracy: 0.8778 - val_loss: 1.7937 - val_accuracy: 0.7350\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2342 - accuracy: 0.8704 - val_loss: 1.8130 - val_accuracy: 0.7350\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.8078 - val_accuracy: 0.7265\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 1.8144 - val_accuracy: 0.7265\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.8055 - val_accuracy: 0.7179\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.7878 - val_accuracy: 0.7179\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.7711 - val_accuracy: 0.7094\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2341 - accuracy: 0.8815 - val_loss: 1.7784 - val_accuracy: 0.7094\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2336 - accuracy: 0.8852 - val_loss: 1.7878 - val_accuracy: 0.7179\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 1.8084 - val_accuracy: 0.7179\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2365 - accuracy: 0.8852 - val_loss: 1.8007 - val_accuracy: 0.7265\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.7782 - val_accuracy: 0.7179\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2367 - accuracy: 0.8741 - val_loss: 1.7967 - val_accuracy: 0.7265\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.8162 - val_accuracy: 0.7009\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2369 - accuracy: 0.8667 - val_loss: 1.8017 - val_accuracy: 0.7094\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2309 - accuracy: 0.8852 - val_loss: 1.8061 - val_accuracy: 0.7009\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.8108 - val_accuracy: 0.7179\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2361 - accuracy: 0.8852 - val_loss: 1.8054 - val_accuracy: 0.7179\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2302 - accuracy: 0.8926 - val_loss: 1.7856 - val_accuracy: 0.7350\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2344 - accuracy: 0.8815 - val_loss: 1.7957 - val_accuracy: 0.7265\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2344 - accuracy: 0.8778 - val_loss: 1.8129 - val_accuracy: 0.7265\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2320 - accuracy: 0.8852 - val_loss: 1.8235 - val_accuracy: 0.7179\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2355 - accuracy: 0.8741 - val_loss: 1.8049 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2334 - accuracy: 0.8815 - val_loss: 1.7919 - val_accuracy: 0.7094\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2341 - accuracy: 0.8778 - val_loss: 1.7930 - val_accuracy: 0.7265\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.7981 - val_accuracy: 0.7009\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 1.8103 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2384 - accuracy: 0.8852 - val_loss: 1.8203 - val_accuracy: 0.7094\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 1.7886 - val_accuracy: 0.7179\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2338 - accuracy: 0.8741 - val_loss: 1.7980 - val_accuracy: 0.7179\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2366 - accuracy: 0.8815 - val_loss: 1.8304 - val_accuracy: 0.7094\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2357 - accuracy: 0.8741 - val_loss: 1.8163 - val_accuracy: 0.7094\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 1.8287 - val_accuracy: 0.7265\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2333 - accuracy: 0.8889 - val_loss: 1.7948 - val_accuracy: 0.7094\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2347 - accuracy: 0.8741 - val_loss: 1.7971 - val_accuracy: 0.7350\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2349 - accuracy: 0.8815 - val_loss: 1.8494 - val_accuracy: 0.7350\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2348 - accuracy: 0.8852 - val_loss: 1.8264 - val_accuracy: 0.7265\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2326 - accuracy: 0.8852 - val_loss: 1.8195 - val_accuracy: 0.7265\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 393us/step - loss: 0.2350 - accuracy: 0.8852 - val_loss: 1.8134 - val_accuracy: 0.7094\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.2328 - accuracy: 0.8852 - val_loss: 1.8048 - val_accuracy: 0.7350\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.2386 - accuracy: 0.8815 - val_loss: 1.8153 - val_accuracy: 0.7265\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2307 - accuracy: 0.8852 - val_loss: 1.8241 - val_accuracy: 0.7350\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2389 - accuracy: 0.8593 - val_loss: 1.8205 - val_accuracy: 0.7265\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.8051 - val_accuracy: 0.7350\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2385 - accuracy: 0.8815 - val_loss: 1.8612 - val_accuracy: 0.7179\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2337 - accuracy: 0.8852 - val_loss: 1.8248 - val_accuracy: 0.7350\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2377 - accuracy: 0.8778 - val_loss: 1.8128 - val_accuracy: 0.7179\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2349 - accuracy: 0.8852 - val_loss: 1.8514 - val_accuracy: 0.7094\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.8556 - val_accuracy: 0.7350\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.8297 - val_accuracy: 0.7350\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2389 - accuracy: 0.8815 - val_loss: 1.8209 - val_accuracy: 0.7350\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2330 - accuracy: 0.8815 - val_loss: 1.8339 - val_accuracy: 0.7350\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2375 - accuracy: 0.8852 - val_loss: 1.8421 - val_accuracy: 0.7265\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2316 - accuracy: 0.8852 - val_loss: 1.8311 - val_accuracy: 0.7094\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2346 - accuracy: 0.8815 - val_loss: 1.8406 - val_accuracy: 0.7094\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2322 - accuracy: 0.8889 - val_loss: 1.8271 - val_accuracy: 0.7350\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2349 - accuracy: 0.8741 - val_loss: 1.8472 - val_accuracy: 0.7265\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2317 - accuracy: 0.8889 - val_loss: 1.8483 - val_accuracy: 0.7265\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2334 - accuracy: 0.8741 - val_loss: 1.8388 - val_accuracy: 0.7350\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2365 - accuracy: 0.8815 - val_loss: 1.8323 - val_accuracy: 0.7350\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2340 - accuracy: 0.8852 - val_loss: 1.8229 - val_accuracy: 0.7094\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2323 - accuracy: 0.8852 - val_loss: 1.8133 - val_accuracy: 0.7179\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2340 - accuracy: 0.8889 - val_loss: 1.8360 - val_accuracy: 0.7265\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2377 - accuracy: 0.8704 - val_loss: 1.8365 - val_accuracy: 0.7179\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 1.8399 - val_accuracy: 0.7094\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.8360 - val_accuracy: 0.7350\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2334 - accuracy: 0.8852 - val_loss: 1.8146 - val_accuracy: 0.7436\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2342 - accuracy: 0.8704 - val_loss: 1.8280 - val_accuracy: 0.7179\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.8213 - val_accuracy: 0.7179\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2354 - accuracy: 0.8630 - val_loss: 1.8266 - val_accuracy: 0.7094\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2352 - accuracy: 0.8815 - val_loss: 1.8238 - val_accuracy: 0.7179\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.90 - 0s 189us/step - loss: 0.2341 - accuracy: 0.8852 - val_loss: 1.8493 - val_accuracy: 0.7094\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2350 - accuracy: 0.8815 - val_loss: 1.8320 - val_accuracy: 0.7179\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2332 - accuracy: 0.8741 - val_loss: 1.8347 - val_accuracy: 0.7265\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2346 - accuracy: 0.8852 - val_loss: 1.8361 - val_accuracy: 0.7179\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2338 - accuracy: 0.8852 - val_loss: 1.8432 - val_accuracy: 0.7350\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.90 - 0s 147us/step - loss: 0.2342 - accuracy: 0.8852 - val_loss: 1.8388 - val_accuracy: 0.7179\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2377 - accuracy: 0.8667 - val_loss: 1.8317 - val_accuracy: 0.7265\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2336 - accuracy: 0.8778 - val_loss: 1.8459 - val_accuracy: 0.7265\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2348 - accuracy: 0.8556 - val_loss: 1.8349 - val_accuracy: 0.7350\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2346 - accuracy: 0.8741 - val_loss: 1.8501 - val_accuracy: 0.7265\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2335 - accuracy: 0.8852 - val_loss: 1.8441 - val_accuracy: 0.7179\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2318 - accuracy: 0.8852 - val_loss: 1.8327 - val_accuracy: 0.7094\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2350 - accuracy: 0.8889 - val_loss: 1.8432 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2332 - accuracy: 0.8815 - val_loss: 1.8388 - val_accuracy: 0.7179\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2353 - accuracy: 0.8704 - val_loss: 1.8408 - val_accuracy: 0.7179\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2319 - accuracy: 0.8815 - val_loss: 1.8504 - val_accuracy: 0.7265\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2359 - accuracy: 0.8778 - val_loss: 1.8453 - val_accuracy: 0.7350\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2349 - accuracy: 0.8889 - val_loss: 1.8474 - val_accuracy: 0.7265\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.8582 - val_accuracy: 0.7350\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2321 - accuracy: 0.8852 - val_loss: 1.8312 - val_accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.10%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [5.45537900e-01, 4.54410760e-01, 5.13159760e-05],\n",
       "       [4.96073000e-07, 2.83281330e-05, 9.99971150e-01],\n",
       "       [4.01488450e-07, 2.20353210e-07, 9.99999400e-01],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [1.76221920e-01, 8.23777600e-01, 5.11233600e-07],\n",
       "       [7.96645300e-05, 9.99894000e-01, 2.63388570e-05],\n",
       "       [4.01488450e-07, 2.20353210e-07, 9.99999400e-01],\n",
       "       [9.78356300e-03, 6.08098800e-02, 9.29406600e-01],\n",
       "       [4.01488450e-07, 2.20353210e-07, 9.99999400e-01],\n",
       "       [3.21095080e-04, 4.97451100e-03, 9.94704400e-01],\n",
       "       [7.13727000e-01, 2.86093320e-01, 1.79655240e-04],\n",
       "       [5.89314900e-04, 1.65953450e-03, 9.97751200e-01],\n",
       "       [1.00000000e+00, 1.61318460e-08, 1.56131460e-11],\n",
       "       [8.88902800e-02, 9.11102300e-01, 7.38604300e-06],\n",
       "       [8.91226230e-01, 1.04236215e-01, 4.53766300e-03],\n",
       "       [3.61728000e-03, 8.88966100e-04, 9.95493770e-01],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [1.00000000e+00, 5.43333260e-11, 1.80820980e-10],\n",
       "       [9.99785500e-01, 2.14549130e-04, 4.29664830e-15],\n",
       "       [2.09023270e-03, 9.97816440e-01, 9.32173400e-05],\n",
       "       [5.73248200e-05, 3.01579440e-05, 9.99912500e-01],\n",
       "       [2.46405560e-02, 1.31427200e-01, 8.43932300e-01],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [2.29106680e-03, 5.60002570e-01, 4.37706350e-01],\n",
       "       [1.57133400e-02, 7.29726700e-01, 2.54560050e-01],\n",
       "       [3.11842900e-03, 7.72371900e-06, 9.96873860e-01],\n",
       "       [4.21944960e-03, 9.93256900e-01, 2.52357400e-03],\n",
       "       [2.09023270e-03, 9.97816440e-01, 9.32173400e-05],\n",
       "       [5.00012500e-01, 4.99860850e-01, 1.26681160e-04],\n",
       "       [3.78748080e-04, 3.72225260e-03, 9.95899000e-01],\n",
       "       [9.19778200e-03, 9.90802200e-01, 6.63054440e-10],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [3.70086900e-02, 9.62860800e-01, 1.30536210e-04],\n",
       "       [3.11842900e-03, 7.72371900e-06, 9.96873860e-01],\n",
       "       [1.00000000e+00, 7.19706600e-10, 7.07996730e-12],\n",
       "       [3.21095080e-04, 4.97451100e-03, 9.94704400e-01],\n",
       "       [5.16969500e-11, 1.05541530e-05, 9.99989400e-01],\n",
       "       [4.59876430e-05, 4.96574200e-04, 9.99457400e-01],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [5.18588240e-02, 9.44251900e-01, 3.88930800e-03],\n",
       "       [4.36401670e-01, 2.21693490e-01, 3.41904880e-01],\n",
       "       [1.58590690e-08, 2.56399530e-02, 9.74360000e-01],\n",
       "       [2.01046040e-04, 6.02965900e-04, 9.99196000e-01],\n",
       "       [3.96804170e-06, 2.36125540e-08, 9.99996070e-01],\n",
       "       [1.18861380e-03, 9.98810300e-01, 1.04135820e-06],\n",
       "       [2.25887140e-04, 8.06486100e-03, 9.91709300e-01],\n",
       "       [2.35266460e-04, 9.99700400e-01, 6.43303600e-05],\n",
       "       [3.61071320e-01, 6.24308350e-01, 1.46203940e-02],\n",
       "       [1.49939230e-02, 9.81723670e-01, 3.28238260e-03],\n",
       "       [9.99970700e-01, 2.93263020e-05, 1.29443930e-21],\n",
       "       [3.16012120e-06, 2.31562480e-09, 9.99996800e-01],\n",
       "       [8.46386760e-05, 2.41590490e-06, 9.99913000e-01],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [9.98885800e-01, 1.01677260e-03, 9.73844500e-05],\n",
       "       [5.73248200e-05, 3.01579440e-05, 9.99912500e-01],\n",
       "       [2.46405560e-02, 1.31427200e-01, 8.43932300e-01],\n",
       "       [7.86155300e-01, 2.13719230e-01, 1.25474340e-04],\n",
       "       [7.13727000e-01, 2.86093320e-01, 1.79655240e-04],\n",
       "       [2.29106680e-03, 5.60002570e-01, 4.37706350e-01],\n",
       "       [2.71983400e-03, 3.50044530e-03, 9.93779700e-01],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [1.57133400e-02, 7.29726700e-01, 2.54560050e-01],\n",
       "       [4.36401670e-01, 2.21693490e-01, 3.41904880e-01],\n",
       "       [6.45435300e-06, 2.60237080e-04, 9.99733270e-01],\n",
       "       [9.99376700e-01, 5.95076240e-04, 2.81819380e-05],\n",
       "       [5.48157230e-07, 4.48088500e-05, 9.99954700e-01],\n",
       "       [5.00012500e-01, 4.99860850e-01, 1.26681160e-04],\n",
       "       [9.95618900e-01, 4.38111970e-03, 2.11162940e-14],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [9.99990340e-01, 9.61091200e-06, 1.21052880e-22],\n",
       "       [9.99985600e-01, 8.40762200e-06, 5.98580700e-06],\n",
       "       [3.11842900e-03, 7.72371900e-06, 9.96873860e-01],\n",
       "       [8.52256900e-05, 1.31087990e-01, 8.68826800e-01],\n",
       "       [1.23857160e-04, 9.99127000e-01, 7.49124330e-04],\n",
       "       [2.25887140e-04, 8.06486100e-03, 9.91709300e-01],\n",
       "       [9.99959700e-01, 4.03340300e-05, 3.85548900e-20],\n",
       "       [1.58590690e-08, 2.56399530e-02, 9.74360000e-01],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [1.30769390e-02, 9.85035060e-01, 1.88796200e-03],\n",
       "       [3.06586260e-05, 8.94152200e-08, 9.99969240e-01],\n",
       "       [2.29106680e-03, 5.60002570e-01, 4.37706350e-01],\n",
       "       [4.96073000e-07, 2.83281330e-05, 9.99971150e-01],\n",
       "       [1.69395360e-01, 8.27041000e-01, 3.56368650e-03],\n",
       "       [1.16500840e-03, 9.98302340e-01, 5.32627400e-04],\n",
       "       [8.52256900e-05, 1.31087990e-01, 8.68826800e-01],\n",
       "       [9.95953200e-01, 4.04684700e-03, 3.23497560e-10],\n",
       "       [9.95258150e-01, 4.74184570e-03, 4.61960550e-12],\n",
       "       [1.57133400e-02, 7.29726700e-01, 2.54560050e-01],\n",
       "       [3.94023320e-02, 9.16299900e-03, 9.51434600e-01],\n",
       "       [9.99999900e-01, 1.02367345e-07, 1.37227400e-11],\n",
       "       [4.06935750e-04, 9.99245900e-01, 3.47192860e-04],\n",
       "       [1.86163350e-01, 8.08988030e-01, 4.84862830e-03],\n",
       "       [1.67445630e-03, 3.09818330e-03, 9.95227340e-01],\n",
       "       [4.01488450e-07, 2.20353210e-07, 9.99999400e-01],\n",
       "       [4.41222340e-01, 5.51391800e-01, 7.38582200e-03],\n",
       "       [2.46405560e-02, 1.31427200e-01, 8.43932300e-01],\n",
       "       [1.21028180e-06, 7.04986720e-06, 9.99991800e-01],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [7.86155300e-01, 2.13719230e-01, 1.25474340e-04],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [8.70938530e-04, 3.72516570e-04, 9.98756500e-01],\n",
       "       [1.00000000e+00, 1.46485400e-08, 2.50316260e-11],\n",
       "       [4.69862160e-01, 5.10855000e-01, 1.92827530e-02],\n",
       "       [2.04618350e-02, 9.79538140e-01, 5.90926840e-21],\n",
       "       [9.99995700e-01, 3.78068010e-06, 4.28136960e-07],\n",
       "       [9.96726300e-06, 6.74163200e-04, 9.99315860e-01],\n",
       "       [1.70885300e-05, 9.99982950e-01, 3.99366570e-13],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01],\n",
       "       [9.99127200e-01, 8.61684700e-04, 1.11007450e-05],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [2.13813590e-01, 7.79263900e-01, 6.92249400e-03],\n",
       "       [9.99855500e-01, 1.50746410e-05, 1.29477430e-04],\n",
       "       [4.27430900e-01, 5.30028760e-01, 4.25402930e-02],\n",
       "       [8.42966200e-02, 6.36146370e-01, 2.79557050e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87146614069691"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87146614069691"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa25     1\n",
       "1       CFBRSa07     0\n",
       "2         NRS247     0\n",
       "3          NY439     2\n",
       "4    CFBREBSa110     1\n",
       "..           ...   ...\n",
       "112       SR1129     0\n",
       "113       NRS172     0\n",
       "114       NRS205     2\n",
       "115        NY439     2\n",
       "116       NRS249     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 612us/step - loss: 1.0966 - accuracy: 0.3852 - val_loss: 1.0931 - val_accuracy: 0.4274\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 1.0420 - accuracy: 0.4815 - val_loss: 1.0589 - val_accuracy: 0.4359\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.9998 - accuracy: 0.5148 - val_loss: 1.0312 - val_accuracy: 0.4786\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9656 - accuracy: 0.5630 - val_loss: 1.0052 - val_accuracy: 0.4786\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.9350 - accuracy: 0.6037 - val_loss: 0.9836 - val_accuracy: 0.5214\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.9053 - accuracy: 0.6296 - val_loss: 0.9618 - val_accuracy: 0.4957\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.8771 - accuracy: 0.6333 - val_loss: 0.9421 - val_accuracy: 0.5043\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.8520 - accuracy: 0.6222 - val_loss: 0.9290 - val_accuracy: 0.5385\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.8324 - accuracy: 0.6370 - val_loss: 0.9188 - val_accuracy: 0.5470\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.8151 - accuracy: 0.6407 - val_loss: 0.9159 - val_accuracy: 0.5556\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8006 - accuracy: 0.6481 - val_loss: 0.9104 - val_accuracy: 0.5812\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7864 - accuracy: 0.6407 - val_loss: 0.9085 - val_accuracy: 0.5812\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7754 - accuracy: 0.6481 - val_loss: 0.9028 - val_accuracy: 0.5897\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7672 - accuracy: 0.6667 - val_loss: 0.8992 - val_accuracy: 0.5556\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.7595 - accuracy: 0.6741 - val_loss: 0.8965 - val_accuracy: 0.5641\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.7479 - accuracy: 0.6852 - val_loss: 0.8983 - val_accuracy: 0.5897\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7397 - accuracy: 0.6815 - val_loss: 0.9001 - val_accuracy: 0.5897\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7305 - accuracy: 0.6778 - val_loss: 0.8968 - val_accuracy: 0.5897\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.7215 - accuracy: 0.6815 - val_loss: 0.8874 - val_accuracy: 0.5983\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.7124 - accuracy: 0.6815 - val_loss: 0.8759 - val_accuracy: 0.6068\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.7021 - accuracy: 0.6926 - val_loss: 0.8739 - val_accuracy: 0.5897\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.6936 - accuracy: 0.6963 - val_loss: 0.8738 - val_accuracy: 0.5983\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6850 - accuracy: 0.6963 - val_loss: 0.8698 - val_accuracy: 0.6068\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6764 - accuracy: 0.6926 - val_loss: 0.8674 - val_accuracy: 0.6068\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6717 - accuracy: 0.7000 - val_loss: 0.8658 - val_accuracy: 0.6752\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.6625 - accuracy: 0.7370 - val_loss: 0.8790 - val_accuracy: 0.6752\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.6546 - accuracy: 0.7333 - val_loss: 0.8764 - val_accuracy: 0.6838\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6442 - accuracy: 0.7333 - val_loss: 0.8582 - val_accuracy: 0.6410\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.6371 - accuracy: 0.7222 - val_loss: 0.8605 - val_accuracy: 0.6581\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6285 - accuracy: 0.7333 - val_loss: 0.8646 - val_accuracy: 0.6838\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6224 - accuracy: 0.7333 - val_loss: 0.8456 - val_accuracy: 0.6667\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.6149 - accuracy: 0.7333 - val_loss: 0.8435 - val_accuracy: 0.6581\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.6078 - accuracy: 0.7333 - val_loss: 0.8466 - val_accuracy: 0.6838\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6001 - accuracy: 0.7407 - val_loss: 0.8393 - val_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.5955 - accuracy: 0.7556 - val_loss: 0.8460 - val_accuracy: 0.6752\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5883 - accuracy: 0.7667 - val_loss: 0.8585 - val_accuracy: 0.6581\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.5809 - accuracy: 0.7556 - val_loss: 0.8471 - val_accuracy: 0.6581\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.5747 - accuracy: 0.7593 - val_loss: 0.8500 - val_accuracy: 0.6838\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.5671 - accuracy: 0.7630 - val_loss: 0.8485 - val_accuracy: 0.6667\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.5655 - accuracy: 0.7556 - val_loss: 0.8367 - val_accuracy: 0.6752\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.5551 - accuracy: 0.7778 - val_loss: 0.8485 - val_accuracy: 0.6923\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5526 - accuracy: 0.7815 - val_loss: 0.8762 - val_accuracy: 0.7009\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5539 - accuracy: 0.7630 - val_loss: 0.8741 - val_accuracy: 0.6838\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5406 - accuracy: 0.7926 - val_loss: 0.8509 - val_accuracy: 0.6752\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5415 - accuracy: 0.8000 - val_loss: 0.8516 - val_accuracy: 0.6923\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5388 - accuracy: 0.7889 - val_loss: 0.8603 - val_accuracy: 0.6838\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.5261 - accuracy: 0.7852 - val_loss: 0.8906 - val_accuracy: 0.6923\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.5217 - accuracy: 0.7926 - val_loss: 0.9011 - val_accuracy: 0.6923\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5165 - accuracy: 0.8074 - val_loss: 0.8907 - val_accuracy: 0.7009\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5084 - accuracy: 0.8148 - val_loss: 0.8752 - val_accuracy: 0.7009\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5041 - accuracy: 0.8037 - val_loss: 0.8697 - val_accuracy: 0.7009\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5002 - accuracy: 0.8037 - val_loss: 0.8801 - val_accuracy: 0.7009\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.5005 - accuracy: 0.8074 - val_loss: 0.8955 - val_accuracy: 0.7009\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4890 - accuracy: 0.8111 - val_loss: 0.8653 - val_accuracy: 0.7094\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4993 - accuracy: 0.8111 - val_loss: 0.8736 - val_accuracy: 0.7009\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4823 - accuracy: 0.8111 - val_loss: 0.9416 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4839 - accuracy: 0.8037 - val_loss: 0.9471 - val_accuracy: 0.7009\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4739 - accuracy: 0.8111 - val_loss: 0.9316 - val_accuracy: 0.7009\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4733 - accuracy: 0.8111 - val_loss: 0.9249 - val_accuracy: 0.6923\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4770 - accuracy: 0.8185 - val_loss: 0.9006 - val_accuracy: 0.7094\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.4658 - accuracy: 0.8185 - val_loss: 0.9202 - val_accuracy: 0.7009\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4573 - accuracy: 0.8037 - val_loss: 0.9248 - val_accuracy: 0.7009\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.4525 - accuracy: 0.8185 - val_loss: 0.9276 - val_accuracy: 0.7179\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4548 - accuracy: 0.8333 - val_loss: 0.9224 - val_accuracy: 0.7179\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4519 - accuracy: 0.8148 - val_loss: 0.9543 - val_accuracy: 0.7265\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4521 - accuracy: 0.8148 - val_loss: 0.9656 - val_accuracy: 0.7009\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4440 - accuracy: 0.8333 - val_loss: 0.9353 - val_accuracy: 0.7179\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4414 - accuracy: 0.8407 - val_loss: 0.9131 - val_accuracy: 0.7265\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4377 - accuracy: 0.8222 - val_loss: 0.9466 - val_accuracy: 0.7179\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4392 - accuracy: 0.8222 - val_loss: 0.9776 - val_accuracy: 0.7179\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4274 - accuracy: 0.8222 - val_loss: 0.9323 - val_accuracy: 0.7179\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4305 - accuracy: 0.8259 - val_loss: 0.9234 - val_accuracy: 0.7265\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4246 - accuracy: 0.8519 - val_loss: 0.9809 - val_accuracy: 0.7009\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.4193 - accuracy: 0.8370 - val_loss: 0.9798 - val_accuracy: 0.7265\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.4224 - accuracy: 0.8296 - val_loss: 0.9660 - val_accuracy: 0.7265\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4119 - accuracy: 0.8333 - val_loss: 0.9893 - val_accuracy: 0.7179\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4155 - accuracy: 0.8407 - val_loss: 0.9930 - val_accuracy: 0.7179\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.4139 - accuracy: 0.8556 - val_loss: 0.9252 - val_accuracy: 0.7436\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.4084 - accuracy: 0.8407 - val_loss: 0.9482 - val_accuracy: 0.7265\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.4030 - accuracy: 0.8407 - val_loss: 0.9756 - val_accuracy: 0.7179\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.3968 - accuracy: 0.8519 - val_loss: 0.9385 - val_accuracy: 0.7265\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3987 - accuracy: 0.8519 - val_loss: 0.9550 - val_accuracy: 0.7265\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.3932 - accuracy: 0.8481 - val_loss: 1.0027 - val_accuracy: 0.7009\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3941 - accuracy: 0.8593 - val_loss: 0.9680 - val_accuracy: 0.7094\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3956 - accuracy: 0.8519 - val_loss: 0.9408 - val_accuracy: 0.7350\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3901 - accuracy: 0.8519 - val_loss: 0.9992 - val_accuracy: 0.7179\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3892 - accuracy: 0.8444 - val_loss: 0.9914 - val_accuracy: 0.7350\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3863 - accuracy: 0.8481 - val_loss: 0.9651 - val_accuracy: 0.7179\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3814 - accuracy: 0.8593 - val_loss: 0.9859 - val_accuracy: 0.7265\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3791 - accuracy: 0.8556 - val_loss: 0.9723 - val_accuracy: 0.7350\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3765 - accuracy: 0.8444 - val_loss: 0.9857 - val_accuracy: 0.7265\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3725 - accuracy: 0.8630 - val_loss: 1.0091 - val_accuracy: 0.7350\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3733 - accuracy: 0.8556 - val_loss: 1.0171 - val_accuracy: 0.7179\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3720 - accuracy: 0.8556 - val_loss: 1.0591 - val_accuracy: 0.7094\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3675 - accuracy: 0.8444 - val_loss: 1.0196 - val_accuracy: 0.7179\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3689 - accuracy: 0.8630 - val_loss: 1.0109 - val_accuracy: 0.7179\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.3624 - accuracy: 0.8667 - val_loss: 1.0224 - val_accuracy: 0.7179\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3583 - accuracy: 0.8630 - val_loss: 1.0284 - val_accuracy: 0.7265\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.3596 - accuracy: 0.8556 - val_loss: 1.0714 - val_accuracy: 0.7265\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.3623 - accuracy: 0.8481 - val_loss: 1.0416 - val_accuracy: 0.7179\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3544 - accuracy: 0.8630 - val_loss: 1.0181 - val_accuracy: 0.7265\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3535 - accuracy: 0.8630 - val_loss: 1.0476 - val_accuracy: 0.7094\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3515 - accuracy: 0.8704 - val_loss: 1.0263 - val_accuracy: 0.7094\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.3502 - accuracy: 0.8667 - val_loss: 1.0358 - val_accuracy: 0.7009\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3466 - accuracy: 0.8704 - val_loss: 1.0726 - val_accuracy: 0.7094\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3443 - accuracy: 0.8667 - val_loss: 1.0462 - val_accuracy: 0.7179\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3471 - accuracy: 0.8667 - val_loss: 1.0109 - val_accuracy: 0.7265\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3487 - accuracy: 0.8630 - val_loss: 1.0429 - val_accuracy: 0.7179\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3476 - accuracy: 0.8704 - val_loss: 1.0868 - val_accuracy: 0.7094\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3483 - accuracy: 0.8704 - val_loss: 1.0552 - val_accuracy: 0.7179\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3395 - accuracy: 0.8630 - val_loss: 1.0420 - val_accuracy: 0.7009\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3423 - accuracy: 0.8704 - val_loss: 1.0702 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3433 - accuracy: 0.8778 - val_loss: 1.1334 - val_accuracy: 0.6923\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3397 - accuracy: 0.8593 - val_loss: 1.1258 - val_accuracy: 0.6923\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3343 - accuracy: 0.8556 - val_loss: 1.1001 - val_accuracy: 0.7094\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3290 - accuracy: 0.8704 - val_loss: 1.0716 - val_accuracy: 0.7094\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3345 - accuracy: 0.8704 - val_loss: 1.0637 - val_accuracy: 0.7265\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3307 - accuracy: 0.8667 - val_loss: 1.0686 - val_accuracy: 0.7265\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3300 - accuracy: 0.8667 - val_loss: 1.1031 - val_accuracy: 0.7179\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 1.0827 - val_accuracy: 0.7265\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3253 - accuracy: 0.8630 - val_loss: 1.0429 - val_accuracy: 0.7094\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3354 - accuracy: 0.8630 - val_loss: 1.0748 - val_accuracy: 0.7265\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3199 - accuracy: 0.8704 - val_loss: 1.1377 - val_accuracy: 0.7094\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3277 - accuracy: 0.8741 - val_loss: 1.1497 - val_accuracy: 0.7094\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3236 - accuracy: 0.8741 - val_loss: 1.1191 - val_accuracy: 0.7094\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3165 - accuracy: 0.8741 - val_loss: 1.0879 - val_accuracy: 0.7009\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3233 - accuracy: 0.8741 - val_loss: 1.0863 - val_accuracy: 0.7009\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3164 - accuracy: 0.8741 - val_loss: 1.1357 - val_accuracy: 0.7179\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3181 - accuracy: 0.8667 - val_loss: 1.1775 - val_accuracy: 0.6752\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3177 - accuracy: 0.8667 - val_loss: 1.1176 - val_accuracy: 0.7265\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3136 - accuracy: 0.8704 - val_loss: 1.0908 - val_accuracy: 0.7265\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3167 - accuracy: 0.8667 - val_loss: 1.0777 - val_accuracy: 0.7179\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3172 - accuracy: 0.8852 - val_loss: 1.1039 - val_accuracy: 0.6752\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3183 - accuracy: 0.8704 - val_loss: 1.1427 - val_accuracy: 0.6752\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3210 - accuracy: 0.8704 - val_loss: 1.1265 - val_accuracy: 0.6752\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3148 - accuracy: 0.8741 - val_loss: 1.1095 - val_accuracy: 0.7179\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3082 - accuracy: 0.8852 - val_loss: 1.1032 - val_accuracy: 0.7009\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3100 - accuracy: 0.8778 - val_loss: 1.1549 - val_accuracy: 0.7265\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3142 - accuracy: 0.8815 - val_loss: 1.2070 - val_accuracy: 0.7094\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3197 - accuracy: 0.8741 - val_loss: 1.1179 - val_accuracy: 0.7179\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3064 - accuracy: 0.8815 - val_loss: 1.1150 - val_accuracy: 0.7009\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3129 - accuracy: 0.8778 - val_loss: 1.1494 - val_accuracy: 0.7009\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3033 - accuracy: 0.8778 - val_loss: 1.1833 - val_accuracy: 0.7265\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3030 - accuracy: 0.8667 - val_loss: 1.1561 - val_accuracy: 0.7179\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3046 - accuracy: 0.8778 - val_loss: 1.1290 - val_accuracy: 0.7179\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3012 - accuracy: 0.8815 - val_loss: 1.1251 - val_accuracy: 0.7265\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3066 - accuracy: 0.8667 - val_loss: 1.1853 - val_accuracy: 0.6752\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.3039 - accuracy: 0.8741 - val_loss: 1.1813 - val_accuracy: 0.7179\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2976 - accuracy: 0.8778 - val_loss: 1.1565 - val_accuracy: 0.7179\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2950 - accuracy: 0.8741 - val_loss: 1.1482 - val_accuracy: 0.7265\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2965 - accuracy: 0.8704 - val_loss: 1.1459 - val_accuracy: 0.7179\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2952 - accuracy: 0.8704 - val_loss: 1.1701 - val_accuracy: 0.7265\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2982 - accuracy: 0.8556 - val_loss: 1.2163 - val_accuracy: 0.6752\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3005 - accuracy: 0.8741 - val_loss: 1.1975 - val_accuracy: 0.7094\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2968 - accuracy: 0.8889 - val_loss: 1.1636 - val_accuracy: 0.7009\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2944 - accuracy: 0.8815 - val_loss: 1.1652 - val_accuracy: 0.7179\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2937 - accuracy: 0.8741 - val_loss: 1.1683 - val_accuracy: 0.7009\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2958 - accuracy: 0.8704 - val_loss: 1.1762 - val_accuracy: 0.7179\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2939 - accuracy: 0.8630 - val_loss: 1.2119 - val_accuracy: 0.7179\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2978 - accuracy: 0.8704 - val_loss: 1.2075 - val_accuracy: 0.7436\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2950 - accuracy: 0.8630 - val_loss: 1.1960 - val_accuracy: 0.7094\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2937 - accuracy: 0.8815 - val_loss: 1.1466 - val_accuracy: 0.7094\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2911 - accuracy: 0.8741 - val_loss: 1.1508 - val_accuracy: 0.7094\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2883 - accuracy: 0.8778 - val_loss: 1.1921 - val_accuracy: 0.7179\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2908 - accuracy: 0.8815 - val_loss: 1.2303 - val_accuracy: 0.7094\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2922 - accuracy: 0.8778 - val_loss: 1.2188 - val_accuracy: 0.7179\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2914 - accuracy: 0.8704 - val_loss: 1.1630 - val_accuracy: 0.7094\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2940 - accuracy: 0.8741 - val_loss: 1.2012 - val_accuracy: 0.7094\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2911 - accuracy: 0.8815 - val_loss: 1.2184 - val_accuracy: 0.7094\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2830 - accuracy: 0.8815 - val_loss: 1.1960 - val_accuracy: 0.7009\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2857 - accuracy: 0.8778 - val_loss: 1.2071 - val_accuracy: 0.6667\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2898 - accuracy: 0.8741 - val_loss: 1.2234 - val_accuracy: 0.6838\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2851 - accuracy: 0.8667 - val_loss: 1.2563 - val_accuracy: 0.7094\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2906 - accuracy: 0.8778 - val_loss: 1.2402 - val_accuracy: 0.7094\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2960 - accuracy: 0.8741 - val_loss: 1.1744 - val_accuracy: 0.7179\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2993 - accuracy: 0.8778 - val_loss: 1.1763 - val_accuracy: 0.7265\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2845 - accuracy: 0.8815 - val_loss: 1.2154 - val_accuracy: 0.7265\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2823 - accuracy: 0.8778 - val_loss: 1.2453 - val_accuracy: 0.7265\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 1.2468 - val_accuracy: 0.7179\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2832 - accuracy: 0.8815 - val_loss: 1.2019 - val_accuracy: 0.7179\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2863 - accuracy: 0.8815 - val_loss: 1.1827 - val_accuracy: 0.7094\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2824 - accuracy: 0.8778 - val_loss: 1.2056 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2798 - accuracy: 0.8741 - val_loss: 1.2293 - val_accuracy: 0.7350\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2836 - accuracy: 0.8815 - val_loss: 1.2381 - val_accuracy: 0.7094\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2781 - accuracy: 0.8815 - val_loss: 1.2365 - val_accuracy: 0.7179\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2767 - accuracy: 0.8741 - val_loss: 1.2618 - val_accuracy: 0.6752\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2805 - accuracy: 0.8741 - val_loss: 1.2727 - val_accuracy: 0.6667\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2873 - accuracy: 0.8852 - val_loss: 1.3045 - val_accuracy: 0.7094\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2893 - accuracy: 0.8667 - val_loss: 1.2491 - val_accuracy: 0.6923\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2767 - accuracy: 0.8852 - val_loss: 1.1815 - val_accuracy: 0.7436\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2906 - accuracy: 0.8630 - val_loss: 1.2084 - val_accuracy: 0.7350\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2783 - accuracy: 0.8815 - val_loss: 1.2673 - val_accuracy: 0.7265\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2738 - accuracy: 0.8704 - val_loss: 1.3189 - val_accuracy: 0.6752\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2846 - accuracy: 0.8630 - val_loss: 1.2914 - val_accuracy: 0.6752\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2739 - accuracy: 0.8741 - val_loss: 1.2528 - val_accuracy: 0.7179\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2825 - accuracy: 0.8778 - val_loss: 1.2385 - val_accuracy: 0.7265\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2770 - accuracy: 0.8778 - val_loss: 1.2701 - val_accuracy: 0.7094\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2768 - accuracy: 0.8704 - val_loss: 1.3099 - val_accuracy: 0.7094\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2766 - accuracy: 0.8815 - val_loss: 1.2918 - val_accuracy: 0.7179\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2786 - accuracy: 0.8778 - val_loss: 1.2384 - val_accuracy: 0.7094\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2737 - accuracy: 0.8778 - val_loss: 1.2847 - val_accuracy: 0.7350\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2744 - accuracy: 0.8667 - val_loss: 1.3210 - val_accuracy: 0.6923\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2753 - accuracy: 0.8593 - val_loss: 1.2594 - val_accuracy: 0.7265\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2841 - accuracy: 0.8815 - val_loss: 1.2365 - val_accuracy: 0.7265\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2711 - accuracy: 0.8815 - val_loss: 1.2540 - val_accuracy: 0.7179\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2750 - accuracy: 0.8704 - val_loss: 1.2765 - val_accuracy: 0.6752\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2657 - accuracy: 0.8889 - val_loss: 1.3220 - val_accuracy: 0.7094\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2795 - accuracy: 0.8815 - val_loss: 1.3245 - val_accuracy: 0.7179\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2743 - accuracy: 0.8778 - val_loss: 1.2749 - val_accuracy: 0.6752\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2879 - accuracy: 0.8667 - val_loss: 1.2659 - val_accuracy: 0.7436\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2677 - accuracy: 0.8926 - val_loss: 1.3220 - val_accuracy: 0.7179\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2856 - accuracy: 0.8815 - val_loss: 1.2875 - val_accuracy: 0.7179\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2749 - accuracy: 0.8815 - val_loss: 1.2526 - val_accuracy: 0.7179\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2691 - accuracy: 0.8852 - val_loss: 1.2477 - val_accuracy: 0.7265\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2678 - accuracy: 0.8815 - val_loss: 1.2885 - val_accuracy: 0.7521\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2711 - accuracy: 0.8741 - val_loss: 1.3008 - val_accuracy: 0.6923\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2663 - accuracy: 0.8704 - val_loss: 1.2989 - val_accuracy: 0.7179\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2695 - accuracy: 0.8815 - val_loss: 1.2787 - val_accuracy: 0.7179\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2685 - accuracy: 0.8778 - val_loss: 1.2889 - val_accuracy: 0.7265\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2652 - accuracy: 0.8815 - val_loss: 1.2958 - val_accuracy: 0.7179\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2640 - accuracy: 0.8815 - val_loss: 1.3048 - val_accuracy: 0.7179\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2661 - accuracy: 0.8852 - val_loss: 1.3204 - val_accuracy: 0.7350\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2644 - accuracy: 0.8815 - val_loss: 1.3530 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2719 - accuracy: 0.8815 - val_loss: 1.3416 - val_accuracy: 0.7179\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2620 - accuracy: 0.8815 - val_loss: 1.3346 - val_accuracy: 0.6923\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2788 - accuracy: 0.8593 - val_loss: 1.3114 - val_accuracy: 0.6581\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2660 - accuracy: 0.8630 - val_loss: 1.3227 - val_accuracy: 0.7179\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2743 - accuracy: 0.8815 - val_loss: 1.3205 - val_accuracy: 0.7179\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2714 - accuracy: 0.8704 - val_loss: 1.2467 - val_accuracy: 0.6410\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2881 - accuracy: 0.8556 - val_loss: 1.2835 - val_accuracy: 0.7350\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2649 - accuracy: 0.8815 - val_loss: 1.3947 - val_accuracy: 0.7179\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2761 - accuracy: 0.8815 - val_loss: 1.3440 - val_accuracy: 0.7179\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2648 - accuracy: 0.8852 - val_loss: 1.2773 - val_accuracy: 0.7436\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2652 - accuracy: 0.8778 - val_loss: 1.3029 - val_accuracy: 0.7179\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2723 - accuracy: 0.8815 - val_loss: 1.3815 - val_accuracy: 0.7179\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2731 - accuracy: 0.8815 - val_loss: 1.3177 - val_accuracy: 0.7179\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2661 - accuracy: 0.8778 - val_loss: 1.3110 - val_accuracy: 0.7436\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2653 - accuracy: 0.8778 - val_loss: 1.3066 - val_accuracy: 0.7350\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2605 - accuracy: 0.8741 - val_loss: 1.3008 - val_accuracy: 0.7350\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.3021 - val_accuracy: 0.7436\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2621 - accuracy: 0.8778 - val_loss: 1.3204 - val_accuracy: 0.7265\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2662 - accuracy: 0.8815 - val_loss: 1.3215 - val_accuracy: 0.7265\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2682 - accuracy: 0.8778 - val_loss: 1.3393 - val_accuracy: 0.7436\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2693 - accuracy: 0.8741 - val_loss: 1.3150 - val_accuracy: 0.7265\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2611 - accuracy: 0.8778 - val_loss: 1.3130 - val_accuracy: 0.7436\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2649 - accuracy: 0.8778 - val_loss: 1.3457 - val_accuracy: 0.7350\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2667 - accuracy: 0.8815 - val_loss: 1.3377 - val_accuracy: 0.7179\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2653 - accuracy: 0.8778 - val_loss: 1.3532 - val_accuracy: 0.7094\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2658 - accuracy: 0.8778 - val_loss: 1.3426 - val_accuracy: 0.7179\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2643 - accuracy: 0.8815 - val_loss: 1.4258 - val_accuracy: 0.7350\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2712 - accuracy: 0.8741 - val_loss: 1.3691 - val_accuracy: 0.7265\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2607 - accuracy: 0.8815 - val_loss: 1.3189 - val_accuracy: 0.7009\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 1.3334 - val_accuracy: 0.7265\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2673 - accuracy: 0.8815 - val_loss: 1.3488 - val_accuracy: 0.7607\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2582 - accuracy: 0.8778 - val_loss: 1.3189 - val_accuracy: 0.7179\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2722 - accuracy: 0.8778 - val_loss: 1.3107 - val_accuracy: 0.7179\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2653 - accuracy: 0.8778 - val_loss: 1.3296 - val_accuracy: 0.7179\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2644 - accuracy: 0.8778 - val_loss: 1.3536 - val_accuracy: 0.7350\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2611 - accuracy: 0.8852 - val_loss: 1.3830 - val_accuracy: 0.7179\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2692 - accuracy: 0.8815 - val_loss: 1.3298 - val_accuracy: 0.7179\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2643 - accuracy: 0.8741 - val_loss: 1.3263 - val_accuracy: 0.7436\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2579 - accuracy: 0.8741 - val_loss: 1.3374 - val_accuracy: 0.7265\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2588 - accuracy: 0.8815 - val_loss: 1.3230 - val_accuracy: 0.7265\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2574 - accuracy: 0.8815 - val_loss: 1.3119 - val_accuracy: 0.7350\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2668 - accuracy: 0.8778 - val_loss: 1.3207 - val_accuracy: 0.7436\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2625 - accuracy: 0.8704 - val_loss: 1.3948 - val_accuracy: 0.7265\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2647 - accuracy: 0.8815 - val_loss: 1.3998 - val_accuracy: 0.7265\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2614 - accuracy: 0.8815 - val_loss: 1.3498 - val_accuracy: 0.7350\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2591 - accuracy: 0.8778 - val_loss: 1.3438 - val_accuracy: 0.7436\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2566 - accuracy: 0.8778 - val_loss: 1.3521 - val_accuracy: 0.7265\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2586 - accuracy: 0.8815 - val_loss: 1.3693 - val_accuracy: 0.7179\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2547 - accuracy: 0.8815 - val_loss: 1.3716 - val_accuracy: 0.7350\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2575 - accuracy: 0.8741 - val_loss: 1.4019 - val_accuracy: 0.6923\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.4166 - val_accuracy: 0.7179\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2584 - accuracy: 0.8815 - val_loss: 1.3873 - val_accuracy: 0.7265\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2603 - accuracy: 0.8741 - val_loss: 1.3896 - val_accuracy: 0.7265\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2592 - accuracy: 0.8815 - val_loss: 1.4374 - val_accuracy: 0.7265\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2703 - accuracy: 0.8815 - val_loss: 1.4356 - val_accuracy: 0.7265\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2604 - accuracy: 0.8815 - val_loss: 1.3832 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2606 - accuracy: 0.8593 - val_loss: 1.3611 - val_accuracy: 0.6667\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2670 - accuracy: 0.8704 - val_loss: 1.3884 - val_accuracy: 0.7179\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2616 - accuracy: 0.8815 - val_loss: 1.4228 - val_accuracy: 0.7265\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2681 - accuracy: 0.8667 - val_loss: 1.4577 - val_accuracy: 0.6923\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2703 - accuracy: 0.8630 - val_loss: 1.4164 - val_accuracy: 0.7265\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2626 - accuracy: 0.8815 - val_loss: 1.3828 - val_accuracy: 0.7265\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2586 - accuracy: 0.8741 - val_loss: 1.3749 - val_accuracy: 0.6923\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 1.3764 - val_accuracy: 0.7350\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.4330 - val_accuracy: 0.7094\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2603 - accuracy: 0.8630 - val_loss: 1.3821 - val_accuracy: 0.7350\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.3457 - val_accuracy: 0.7350\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2658 - accuracy: 0.8778 - val_loss: 1.3767 - val_accuracy: 0.7265\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2609 - accuracy: 0.8815 - val_loss: 1.4119 - val_accuracy: 0.7265\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3943 - val_accuracy: 0.6667\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 1.3825 - val_accuracy: 0.7436\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 1.4217 - val_accuracy: 0.7179\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2577 - accuracy: 0.8815 - val_loss: 1.4334 - val_accuracy: 0.7179\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2599 - accuracy: 0.8815 - val_loss: 1.4020 - val_accuracy: 0.7350\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2567 - accuracy: 0.8852 - val_loss: 1.4153 - val_accuracy: 0.6923\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 1.4326 - val_accuracy: 0.7265\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2590 - accuracy: 0.8815 - val_loss: 1.3947 - val_accuracy: 0.7265\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2589 - accuracy: 0.8815 - val_loss: 1.3316 - val_accuracy: 0.6581\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2696 - accuracy: 0.8778 - val_loss: 1.3580 - val_accuracy: 0.7265\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 1.4434 - val_accuracy: 0.6838\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2680 - accuracy: 0.8741 - val_loss: 1.4761 - val_accuracy: 0.6838\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.3991 - val_accuracy: 0.7265\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2616 - accuracy: 0.8815 - val_loss: 1.3594 - val_accuracy: 0.7350\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2595 - accuracy: 0.8778 - val_loss: 1.4631 - val_accuracy: 0.6923\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2728 - accuracy: 0.8630 - val_loss: 1.4637 - val_accuracy: 0.6923\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2533 - accuracy: 0.8667 - val_loss: 1.3556 - val_accuracy: 0.7265\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2815 - accuracy: 0.8815 - val_loss: 1.3320 - val_accuracy: 0.7350\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2580 - accuracy: 0.8778 - val_loss: 1.4224 - val_accuracy: 0.6923\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2574 - accuracy: 0.8815 - val_loss: 1.4875 - val_accuracy: 0.6838\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2648 - accuracy: 0.8778 - val_loss: 1.4430 - val_accuracy: 0.7265\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2604 - accuracy: 0.8852 - val_loss: 1.3737 - val_accuracy: 0.7350\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2717 - accuracy: 0.8778 - val_loss: 1.3855 - val_accuracy: 0.7350\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2624 - accuracy: 0.8778 - val_loss: 1.4517 - val_accuracy: 0.7265\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2584 - accuracy: 0.8815 - val_loss: 1.4475 - val_accuracy: 0.7265\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.2543 - accuracy: 0.8815 - val_loss: 1.4123 - val_accuracy: 0.7350\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2550 - accuracy: 0.8741 - val_loss: 1.4172 - val_accuracy: 0.6581\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2538 - accuracy: 0.8630 - val_loss: 1.4052 - val_accuracy: 0.7350\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 1.4249 - val_accuracy: 0.7350\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2535 - accuracy: 0.8852 - val_loss: 1.4405 - val_accuracy: 0.7179\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2520 - accuracy: 0.8704 - val_loss: 1.4057 - val_accuracy: 0.7350\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2533 - accuracy: 0.8778 - val_loss: 1.3954 - val_accuracy: 0.7350\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2533 - accuracy: 0.8704 - val_loss: 1.4060 - val_accuracy: 0.7265\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 1.3917 - val_accuracy: 0.7265\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2524 - accuracy: 0.8815 - val_loss: 1.4022 - val_accuracy: 0.7350\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2516 - accuracy: 0.8815 - val_loss: 1.4396 - val_accuracy: 0.6838\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2514 - accuracy: 0.8778 - val_loss: 1.4621 - val_accuracy: 0.6923\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2549 - accuracy: 0.8630 - val_loss: 1.4400 - val_accuracy: 0.6581\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2563 - accuracy: 0.8667 - val_loss: 1.4124 - val_accuracy: 0.6581\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.3977 - val_accuracy: 0.7350\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2541 - accuracy: 0.8667 - val_loss: 1.4527 - val_accuracy: 0.7009\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.4487 - val_accuracy: 0.7009\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.4112 - val_accuracy: 0.7265\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.3934 - val_accuracy: 0.7350\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 1.4057 - val_accuracy: 0.7350\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 1.4719 - val_accuracy: 0.7265\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2665 - accuracy: 0.8815 - val_loss: 1.4758 - val_accuracy: 0.7265\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2574 - accuracy: 0.8815 - val_loss: 1.4161 - val_accuracy: 0.7265\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.4119 - val_accuracy: 0.7350\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 289us/step - loss: 0.2526 - accuracy: 0.8741 - val_loss: 1.4432 - val_accuracy: 0.6923\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 1.4565 - val_accuracy: 0.7265\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2493 - accuracy: 0.8704 - val_loss: 1.4791 - val_accuracy: 0.6838\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2515 - accuracy: 0.8778 - val_loss: 1.4980 - val_accuracy: 0.6838\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2500 - accuracy: 0.8778 - val_loss: 1.4734 - val_accuracy: 0.7265\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2508 - accuracy: 0.8815 - val_loss: 1.4391 - val_accuracy: 0.7265\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.4384 - val_accuracy: 0.7265\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.4704 - val_accuracy: 0.7265\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2541 - accuracy: 0.8778 - val_loss: 1.4634 - val_accuracy: 0.7350\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2506 - accuracy: 0.8778 - val_loss: 1.4418 - val_accuracy: 0.7350\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.4513 - val_accuracy: 0.7265\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.4301 - val_accuracy: 0.7265\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2521 - accuracy: 0.8741 - val_loss: 1.4543 - val_accuracy: 0.7350\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.4788 - val_accuracy: 0.7265\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.4456 - val_accuracy: 0.7265\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.4593 - val_accuracy: 0.6496\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2524 - accuracy: 0.8741 - val_loss: 1.5007 - val_accuracy: 0.6838\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2525 - accuracy: 0.8778 - val_loss: 1.5095 - val_accuracy: 0.6838\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2546 - accuracy: 0.8778 - val_loss: 1.4812 - val_accuracy: 0.7265\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.4392 - val_accuracy: 0.7265\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.3873 - val_accuracy: 0.7350\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2596 - accuracy: 0.8778 - val_loss: 1.3890 - val_accuracy: 0.7265\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2586 - accuracy: 0.8630 - val_loss: 1.4028 - val_accuracy: 0.7265\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2636 - accuracy: 0.8815 - val_loss: 1.4729 - val_accuracy: 0.7265\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2522 - accuracy: 0.8778 - val_loss: 1.4449 - val_accuracy: 0.6496\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2569 - accuracy: 0.8667 - val_loss: 1.4422 - val_accuracy: 0.6581\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2545 - accuracy: 0.8815 - val_loss: 1.4520 - val_accuracy: 0.7265\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2570 - accuracy: 0.8778 - val_loss: 1.4743 - val_accuracy: 0.7265\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2564 - accuracy: 0.8741 - val_loss: 1.4660 - val_accuracy: 0.7265\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.4454 - val_accuracy: 0.6496\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2521 - accuracy: 0.8630 - val_loss: 1.4514 - val_accuracy: 0.7265\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.4786 - val_accuracy: 0.7436\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2510 - accuracy: 0.8704 - val_loss: 1.4183 - val_accuracy: 0.7350\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2546 - accuracy: 0.8778 - val_loss: 1.4048 - val_accuracy: 0.7350\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2506 - accuracy: 0.8852 - val_loss: 1.4407 - val_accuracy: 0.7265\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 1.5032 - val_accuracy: 0.7265\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 1.4631 - val_accuracy: 0.7350\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.4136 - val_accuracy: 0.7350\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2565 - accuracy: 0.8593 - val_loss: 1.4363 - val_accuracy: 0.7265\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2504 - accuracy: 0.8815 - val_loss: 1.4995 - val_accuracy: 0.7265\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.4956 - val_accuracy: 0.7265\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2539 - accuracy: 0.8704 - val_loss: 1.4538 - val_accuracy: 0.7350\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2495 - accuracy: 0.8704 - val_loss: 1.4709 - val_accuracy: 0.7265\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2575 - accuracy: 0.8815 - val_loss: 1.4624 - val_accuracy: 0.7265\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2494 - accuracy: 0.8815 - val_loss: 1.4648 - val_accuracy: 0.7521\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.4728 - val_accuracy: 0.6667\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 1.4785 - val_accuracy: 0.7350\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2493 - accuracy: 0.8815 - val_loss: 1.5190 - val_accuracy: 0.7265\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 95us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 1.5186 - val_accuracy: 0.7265\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 1.4922 - val_accuracy: 0.6581\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2527 - accuracy: 0.8556 - val_loss: 1.4732 - val_accuracy: 0.7265\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.5110 - val_accuracy: 0.7265\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2529 - accuracy: 0.8481 - val_loss: 1.5025 - val_accuracy: 0.6838\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2586 - accuracy: 0.8556 - val_loss: 1.4665 - val_accuracy: 0.6496\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2549 - accuracy: 0.8593 - val_loss: 1.4664 - val_accuracy: 0.7265\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2573 - accuracy: 0.8741 - val_loss: 1.5247 - val_accuracy: 0.7265\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2605 - accuracy: 0.8741 - val_loss: 1.5554 - val_accuracy: 0.6923\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.4935 - val_accuracy: 0.7265\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2550 - accuracy: 0.8741 - val_loss: 1.4911 - val_accuracy: 0.7265\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2562 - accuracy: 0.8852 - val_loss: 1.5148 - val_accuracy: 0.6838\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2528 - accuracy: 0.8778 - val_loss: 1.5154 - val_accuracy: 0.6667\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2562 - accuracy: 0.8630 - val_loss: 1.4739 - val_accuracy: 0.6581\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2538 - accuracy: 0.8667 - val_loss: 1.5439 - val_accuracy: 0.6752\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.5290 - val_accuracy: 0.6752\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2509 - accuracy: 0.8667 - val_loss: 1.4752 - val_accuracy: 0.7350\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2503 - accuracy: 0.8778 - val_loss: 1.4450 - val_accuracy: 0.7265\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2537 - accuracy: 0.8815 - val_loss: 1.4486 - val_accuracy: 0.7265\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 1.4816 - val_accuracy: 0.7265\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2614 - accuracy: 0.8444 - val_loss: 1.5464 - val_accuracy: 0.6923\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2566 - accuracy: 0.8593 - val_loss: 1.4875 - val_accuracy: 0.7265\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.4798 - val_accuracy: 0.7265\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2465 - accuracy: 0.8852 - val_loss: 1.4763 - val_accuracy: 0.7350\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 1.4855 - val_accuracy: 0.7350\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2497 - accuracy: 0.8852 - val_loss: 1.4871 - val_accuracy: 0.7265\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2487 - accuracy: 0.8704 - val_loss: 1.4790 - val_accuracy: 0.7265\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.4947 - val_accuracy: 0.7265\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 1.5001 - val_accuracy: 0.7265\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.4758 - val_accuracy: 0.7350\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2528 - accuracy: 0.8519 - val_loss: 1.4864 - val_accuracy: 0.6581\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2489 - accuracy: 0.8741 - val_loss: 1.4966 - val_accuracy: 0.7265\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2539 - accuracy: 0.8815 - val_loss: 1.5242 - val_accuracy: 0.7265\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2500 - accuracy: 0.8778 - val_loss: 1.5030 - val_accuracy: 0.7350\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.4934 - val_accuracy: 0.7350\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 1.4909 - val_accuracy: 0.7350\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2466 - accuracy: 0.8778 - val_loss: 1.4900 - val_accuracy: 0.7265\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2499 - accuracy: 0.8815 - val_loss: 1.5254 - val_accuracy: 0.7265\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 1.5389 - val_accuracy: 0.7350\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2607 - accuracy: 0.8593 - val_loss: 1.5393 - val_accuracy: 0.6581\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2444 - accuracy: 0.8926 - val_loss: 1.5431 - val_accuracy: 0.7265\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2556 - accuracy: 0.8815 - val_loss: 1.5071 - val_accuracy: 0.7265\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 1.4762 - val_accuracy: 0.7265\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 1.4709 - val_accuracy: 0.7265\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2483 - accuracy: 0.8704 - val_loss: 1.4990 - val_accuracy: 0.6838\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2531 - accuracy: 0.8741 - val_loss: 1.5141 - val_accuracy: 0.6923\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2503 - accuracy: 0.8667 - val_loss: 1.5612 - val_accuracy: 0.6838\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2592 - accuracy: 0.8778 - val_loss: 1.5391 - val_accuracy: 0.6838\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2518 - accuracy: 0.8741 - val_loss: 1.4618 - val_accuracy: 0.7265\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2554 - accuracy: 0.8741 - val_loss: 1.4642 - val_accuracy: 0.6923\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2497 - accuracy: 0.8741 - val_loss: 1.5222 - val_accuracy: 0.6838\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2522 - accuracy: 0.8741 - val_loss: 1.5675 - val_accuracy: 0.6838\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 1.5154 - val_accuracy: 0.6581\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2518 - accuracy: 0.8704 - val_loss: 1.5176 - val_accuracy: 0.7350\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2496 - accuracy: 0.8852 - val_loss: 1.5484 - val_accuracy: 0.7265\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2559 - accuracy: 0.8741 - val_loss: 1.5558 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2546 - accuracy: 0.8556 - val_loss: 1.5530 - val_accuracy: 0.6838\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2511 - accuracy: 0.8815 - val_loss: 1.5122 - val_accuracy: 0.7265\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2537 - accuracy: 0.8815 - val_loss: 1.5151 - val_accuracy: 0.7265\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.5237 - val_accuracy: 0.6838\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2503 - accuracy: 0.8778 - val_loss: 1.5324 - val_accuracy: 0.7265\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2505 - accuracy: 0.8778 - val_loss: 1.5131 - val_accuracy: 0.7350\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.5121 - val_accuracy: 0.7265\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.5365 - val_accuracy: 0.7265\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2469 - accuracy: 0.8667 - val_loss: 1.5499 - val_accuracy: 0.6838\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.5353 - val_accuracy: 0.7265\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2531 - accuracy: 0.8778 - val_loss: 1.5164 - val_accuracy: 0.7265\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 1.6000 - val_accuracy: 0.6667\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2594 - accuracy: 0.8741 - val_loss: 1.5666 - val_accuracy: 0.6667\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2430 - accuracy: 0.8704 - val_loss: 1.4694 - val_accuracy: 0.7350\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2622 - accuracy: 0.8778 - val_loss: 1.4363 - val_accuracy: 0.7350\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 1.4775 - val_accuracy: 0.7265\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.5571 - val_accuracy: 0.6923\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2554 - accuracy: 0.8667 - val_loss: 1.6108 - val_accuracy: 0.6838\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2592 - accuracy: 0.8667 - val_loss: 1.5563 - val_accuracy: 0.6838\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2447 - accuracy: 0.8852 - val_loss: 1.4837 - val_accuracy: 0.7265\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2557 - accuracy: 0.8778 - val_loss: 1.4617 - val_accuracy: 0.7350\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2566 - accuracy: 0.8630 - val_loss: 1.4836 - val_accuracy: 0.7350\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2490 - accuracy: 0.8667 - val_loss: 1.5661 - val_accuracy: 0.7436\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2561 - accuracy: 0.8741 - val_loss: 1.4985 - val_accuracy: 0.7265\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 1.4802 - val_accuracy: 0.7350\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 1.5044 - val_accuracy: 0.7265\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.5317 - val_accuracy: 0.7265\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.5467 - val_accuracy: 0.7436\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2544 - accuracy: 0.8593 - val_loss: 1.4852 - val_accuracy: 0.7350\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2511 - accuracy: 0.8704 - val_loss: 1.4880 - val_accuracy: 0.7265\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.5378 - val_accuracy: 0.7265\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.5682 - val_accuracy: 0.7350\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2476 - accuracy: 0.8741 - val_loss: 1.5781 - val_accuracy: 0.7179\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2473 - accuracy: 0.8741 - val_loss: 1.5749 - val_accuracy: 0.7265\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2484 - accuracy: 0.8815 - val_loss: 1.5365 - val_accuracy: 0.7265\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2530 - accuracy: 0.8852 - val_loss: 1.4568 - val_accuracy: 0.7350\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 1.4904 - val_accuracy: 0.7350\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.5342 - val_accuracy: 0.7179\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2527 - accuracy: 0.8815 - val_loss: 1.5082 - val_accuracy: 0.7265\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.4762 - val_accuracy: 0.7350\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2519 - accuracy: 0.8741 - val_loss: 1.4597 - val_accuracy: 0.7350\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2520 - accuracy: 0.8704 - val_loss: 1.4786 - val_accuracy: 0.7265\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.4656 - val_accuracy: 0.7350\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2506 - accuracy: 0.8778 - val_loss: 1.5026 - val_accuracy: 0.6923\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2497 - accuracy: 0.8704 - val_loss: 1.4950 - val_accuracy: 0.7350\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.4958 - val_accuracy: 0.7436\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2510 - accuracy: 0.8630 - val_loss: 1.5722 - val_accuracy: 0.7265\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 1.5889 - val_accuracy: 0.7265\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.5556 - val_accuracy: 0.7265\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2503 - accuracy: 0.8407 - val_loss: 1.5466 - val_accuracy: 0.6667\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.5367 - val_accuracy: 0.7350\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2439 - accuracy: 0.8741 - val_loss: 1.5817 - val_accuracy: 0.7265\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2578 - accuracy: 0.8815 - val_loss: 1.5851 - val_accuracy: 0.7265\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2522 - accuracy: 0.8741 - val_loss: 1.5874 - val_accuracy: 0.6838\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.5430 - val_accuracy: 0.7265\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.5221 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 1.5206 - val_accuracy: 0.7265\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2511 - accuracy: 0.8889 - val_loss: 1.5509 - val_accuracy: 0.6496\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2510 - accuracy: 0.8667 - val_loss: 1.5531 - val_accuracy: 0.7265\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.5562 - val_accuracy: 0.7265\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.5647 - val_accuracy: 0.7436\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 1.5188 - val_accuracy: 0.7265\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.5200 - val_accuracy: 0.7265\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.5448 - val_accuracy: 0.7265\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.5675 - val_accuracy: 0.7265\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2494 - accuracy: 0.8667 - val_loss: 1.5783 - val_accuracy: 0.6752\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 1.5759 - val_accuracy: 0.7265\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.5853 - val_accuracy: 0.6667\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2484 - accuracy: 0.8667 - val_loss: 1.5741 - val_accuracy: 0.6838\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.5959 - val_accuracy: 0.7265\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2559 - accuracy: 0.8815 - val_loss: 1.5706 - val_accuracy: 0.7265\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.5672 - val_accuracy: 0.7350\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2509 - accuracy: 0.8667 - val_loss: 1.6157 - val_accuracy: 0.7350\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2503 - accuracy: 0.8741 - val_loss: 1.6406 - val_accuracy: 0.7179\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2513 - accuracy: 0.8741 - val_loss: 1.6251 - val_accuracy: 0.7179\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.5915 - val_accuracy: 0.7265\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.5532 - val_accuracy: 0.7350\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.5179 - val_accuracy: 0.7436\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.5259 - val_accuracy: 0.7436\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2481 - accuracy: 0.8815 - val_loss: 1.5870 - val_accuracy: 0.6838\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.5424 - val_accuracy: 0.6667\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.5538 - val_accuracy: 0.6667\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2494 - accuracy: 0.8667 - val_loss: 1.5865 - val_accuracy: 0.6838\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2466 - accuracy: 0.8778 - val_loss: 1.5866 - val_accuracy: 0.7265\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.5573 - val_accuracy: 0.7265\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.5526 - val_accuracy: 0.7265\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2509 - accuracy: 0.8667 - val_loss: 1.5764 - val_accuracy: 0.6496\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 1.6099 - val_accuracy: 0.7265\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 1.6251 - val_accuracy: 0.7265\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.5650 - val_accuracy: 0.7265\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.5446 - val_accuracy: 0.7436\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2529 - accuracy: 0.8630 - val_loss: 1.5710 - val_accuracy: 0.7009\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2488 - accuracy: 0.8667 - val_loss: 1.5631 - val_accuracy: 0.7265\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.5976 - val_accuracy: 0.7265\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2484 - accuracy: 0.8815 - val_loss: 1.5779 - val_accuracy: 0.7350\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2537 - accuracy: 0.8778 - val_loss: 1.5316 - val_accuracy: 0.6581\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2600 - accuracy: 0.8630 - val_loss: 1.5601 - val_accuracy: 0.7265\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2501 - accuracy: 0.8815 - val_loss: 1.6512 - val_accuracy: 0.7265\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2763 - accuracy: 0.8815 - val_loss: 1.5986 - val_accuracy: 0.7265\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.4887 - val_accuracy: 0.6581\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2727 - accuracy: 0.8630 - val_loss: 1.5022 - val_accuracy: 0.7436\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.5943 - val_accuracy: 0.7265\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2599 - accuracy: 0.8815 - val_loss: 1.6256 - val_accuracy: 0.6838\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.6116 - val_accuracy: 0.6923\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 1.5637 - val_accuracy: 0.6581\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2519 - accuracy: 0.8667 - val_loss: 1.5770 - val_accuracy: 0.7265\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.5987 - val_accuracy: 0.7265\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.5868 - val_accuracy: 0.7265\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.5796 - val_accuracy: 0.7009\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.5432 - val_accuracy: 0.7350\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 1.5316 - val_accuracy: 0.7350\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.5495 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2491 - accuracy: 0.8815 - val_loss: 1.5668 - val_accuracy: 0.7265\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.5497 - val_accuracy: 0.7350\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.5750 - val_accuracy: 0.6581\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2577 - accuracy: 0.8556 - val_loss: 1.5990 - val_accuracy: 0.6923\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2477 - accuracy: 0.8667 - val_loss: 1.6073 - val_accuracy: 0.7265\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.6110 - val_accuracy: 0.7265\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.6079 - val_accuracy: 0.6581\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.6031 - val_accuracy: 0.6923\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.5961 - val_accuracy: 0.7350\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.6108 - val_accuracy: 0.7179\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.6056 - val_accuracy: 0.7265\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.5812 - val_accuracy: 0.7265\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.6027 - val_accuracy: 0.7265\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.6101 - val_accuracy: 0.7265\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.6440 - val_accuracy: 0.7265\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.6182 - val_accuracy: 0.6923\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2503 - accuracy: 0.8667 - val_loss: 1.6153 - val_accuracy: 0.6581\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2478 - accuracy: 0.8704 - val_loss: 1.6201 - val_accuracy: 0.7265\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.6227 - val_accuracy: 0.7265\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.5954 - val_accuracy: 0.7265\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.5641 - val_accuracy: 0.7436\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2505 - accuracy: 0.8704 - val_loss: 1.5960 - val_accuracy: 0.7350\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.6631 - val_accuracy: 0.6838\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.6747 - val_accuracy: 0.6752\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2459 - accuracy: 0.8593 - val_loss: 1.6347 - val_accuracy: 0.7265\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.6187 - val_accuracy: 0.7265\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 1.6006 - val_accuracy: 0.7265\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.5887 - val_accuracy: 0.7436\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.6079 - val_accuracy: 0.7436\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2475 - accuracy: 0.8630 - val_loss: 1.6041 - val_accuracy: 0.7350\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2528 - accuracy: 0.8778 - val_loss: 1.5733 - val_accuracy: 0.7350\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 1.6579 - val_accuracy: 0.6838\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 1.7245 - val_accuracy: 0.6838\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2613 - accuracy: 0.8593 - val_loss: 1.6113 - val_accuracy: 0.7265\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2576 - accuracy: 0.8815 - val_loss: 1.5429 - val_accuracy: 0.7350\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2518 - accuracy: 0.8741 - val_loss: 1.5997 - val_accuracy: 0.7265\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.5882 - val_accuracy: 0.7350\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 1.5585 - val_accuracy: 0.7350\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2511 - accuracy: 0.8667 - val_loss: 1.5873 - val_accuracy: 0.7350\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.5960 - val_accuracy: 0.7265\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.6344 - val_accuracy: 0.7265\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2493 - accuracy: 0.8741 - val_loss: 1.6415 - val_accuracy: 0.6752\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2486 - accuracy: 0.8667 - val_loss: 1.6208 - val_accuracy: 0.6667\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.5916 - val_accuracy: 0.7265\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.5914 - val_accuracy: 0.7265\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6258 - val_accuracy: 0.7265\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.6431 - val_accuracy: 0.7265\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.6047 - val_accuracy: 0.7265\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.5628 - val_accuracy: 0.7350\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 1.5617 - val_accuracy: 0.7265\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.5708 - val_accuracy: 0.7265\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2500 - accuracy: 0.8630 - val_loss: 1.5841 - val_accuracy: 0.6838\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 1.6817 - val_accuracy: 0.6667\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2527 - accuracy: 0.8778 - val_loss: 1.6414 - val_accuracy: 0.6838\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.5985 - val_accuracy: 0.6581\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2479 - accuracy: 0.8667 - val_loss: 1.6448 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2516 - accuracy: 0.8741 - val_loss: 1.6782 - val_accuracy: 0.6667\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2494 - accuracy: 0.8741 - val_loss: 1.6053 - val_accuracy: 0.7265\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2498 - accuracy: 0.8815 - val_loss: 1.5679 - val_accuracy: 0.7265\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.6355 - val_accuracy: 0.6838\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2495 - accuracy: 0.8630 - val_loss: 1.6611 - val_accuracy: 0.6667\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.6351 - val_accuracy: 0.7265\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2484 - accuracy: 0.8815 - val_loss: 1.6063 - val_accuracy: 0.7265\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2536 - accuracy: 0.8815 - val_loss: 1.6082 - val_accuracy: 0.6581\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2467 - accuracy: 0.8667 - val_loss: 1.6259 - val_accuracy: 0.7265\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.6168 - val_accuracy: 0.7265\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.6129 - val_accuracy: 0.7265\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2523 - accuracy: 0.8667 - val_loss: 1.6585 - val_accuracy: 0.6838\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.6546 - val_accuracy: 0.6838\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2491 - accuracy: 0.8630 - val_loss: 1.6359 - val_accuracy: 0.6752\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2524 - accuracy: 0.8704 - val_loss: 1.6174 - val_accuracy: 0.7265\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.6354 - val_accuracy: 0.7179\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2464 - accuracy: 0.8630 - val_loss: 1.6568 - val_accuracy: 0.6923\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.6804 - val_accuracy: 0.6752\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.6426 - val_accuracy: 0.7265\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 1.5637 - val_accuracy: 0.6581\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2501 - accuracy: 0.8815 - val_loss: 1.5817 - val_accuracy: 0.7265\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.6217 - val_accuracy: 0.7265\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.6081 - val_accuracy: 0.7265\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.5824 - val_accuracy: 0.7265\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2488 - accuracy: 0.8704 - val_loss: 1.6084 - val_accuracy: 0.6667\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2427 - accuracy: 0.8667 - val_loss: 1.6095 - val_accuracy: 0.7265\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2483 - accuracy: 0.8815 - val_loss: 1.5951 - val_accuracy: 0.7265\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 1.6484 - val_accuracy: 0.6667\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2495 - accuracy: 0.8741 - val_loss: 1.6074 - val_accuracy: 0.7179\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2447 - accuracy: 0.8852 - val_loss: 1.6056 - val_accuracy: 0.7265\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.5788 - val_accuracy: 0.7350\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 1.5848 - val_accuracy: 0.7350\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 1.6281 - val_accuracy: 0.7265\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6525 - val_accuracy: 0.6752\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2457 - accuracy: 0.8556 - val_loss: 1.6348 - val_accuracy: 0.7265\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.6275 - val_accuracy: 0.7265\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.6296 - val_accuracy: 0.7265\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.6765 - val_accuracy: 0.6838\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2493 - accuracy: 0.8593 - val_loss: 1.6238 - val_accuracy: 0.7265\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.5899 - val_accuracy: 0.7265\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.5957 - val_accuracy: 0.7265\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 1.6125 - val_accuracy: 0.7265\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.2507 - accuracy: 0.8593 - val_loss: 1.7022 - val_accuracy: 0.6838\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2518 - accuracy: 0.8593 - val_loss: 1.7109 - val_accuracy: 0.7265\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2519 - accuracy: 0.8815 - val_loss: 1.6510 - val_accuracy: 0.7265\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.6353 - val_accuracy: 0.7265\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.6374 - val_accuracy: 0.6496\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 1.6355 - val_accuracy: 0.7265\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.6002 - val_accuracy: 0.7350\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.6343 - val_accuracy: 0.6752\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2497 - accuracy: 0.8630 - val_loss: 1.6964 - val_accuracy: 0.6838\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 1.6569 - val_accuracy: 0.7265\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 1.6170 - val_accuracy: 0.7265\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2541 - accuracy: 0.8815 - val_loss: 1.5971 - val_accuracy: 0.7265\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.6315 - val_accuracy: 0.7265\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2531 - accuracy: 0.8556 - val_loss: 1.6161 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.5974 - val_accuracy: 0.7179\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 1.6176 - val_accuracy: 0.7265\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.6430 - val_accuracy: 0.7265\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.6829 - val_accuracy: 0.7436\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.6859 - val_accuracy: 0.7265\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.6635 - val_accuracy: 0.7265\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.6446 - val_accuracy: 0.7350\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.5859 - val_accuracy: 0.7350\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2595 - accuracy: 0.8778 - val_loss: 1.6174 - val_accuracy: 0.7265\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6856 - val_accuracy: 0.7265\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2552 - accuracy: 0.8815 - val_loss: 1.7207 - val_accuracy: 0.7094\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2599 - accuracy: 0.8667 - val_loss: 1.6808 - val_accuracy: 0.6752\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2517 - accuracy: 0.8630 - val_loss: 1.6387 - val_accuracy: 0.7265\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6757 - val_accuracy: 0.7265\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.6948 - val_accuracy: 0.6667\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2505 - accuracy: 0.8481 - val_loss: 1.6461 - val_accuracy: 0.7265\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2494 - accuracy: 0.8704 - val_loss: 1.6444 - val_accuracy: 0.7265\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6129 - val_accuracy: 0.7265\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.6249 - val_accuracy: 0.7350\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.6390 - val_accuracy: 0.7265\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6540 - val_accuracy: 0.7265\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.6423 - val_accuracy: 0.7265\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.6337 - val_accuracy: 0.6838\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.6700 - val_accuracy: 0.6667\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.6699 - val_accuracy: 0.6838\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.6243 - val_accuracy: 0.7265\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2480 - accuracy: 0.8667 - val_loss: 1.6064 - val_accuracy: 0.6496\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2474 - accuracy: 0.8667 - val_loss: 1.6106 - val_accuracy: 0.7265\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 1.6500 - val_accuracy: 0.7265\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 1.6874 - val_accuracy: 0.7265\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.6785 - val_accuracy: 0.7265\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.6575 - val_accuracy: 0.7265\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6386 - val_accuracy: 0.7179\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2440 - accuracy: 0.8704 - val_loss: 1.6695 - val_accuracy: 0.6752\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2467 - accuracy: 0.8630 - val_loss: 1.6249 - val_accuracy: 0.6752\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 1.5875 - val_accuracy: 0.7265\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2543 - accuracy: 0.8815 - val_loss: 1.5923 - val_accuracy: 0.7179\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.6622 - val_accuracy: 0.7265\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2511 - accuracy: 0.8667 - val_loss: 1.7115 - val_accuracy: 0.7009\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 1.6536 - val_accuracy: 0.7265\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.6475 - val_accuracy: 0.7265\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.6670 - val_accuracy: 0.7265\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.6962 - val_accuracy: 0.7265\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.7177 - val_accuracy: 0.6667\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.6965 - val_accuracy: 0.6667\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.6810 - val_accuracy: 0.6667\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.6141 - val_accuracy: 0.7265\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2560 - accuracy: 0.8815 - val_loss: 1.6104 - val_accuracy: 0.7265\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.6739 - val_accuracy: 0.6667\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.6875 - val_accuracy: 0.6667\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2506 - accuracy: 0.8630 - val_loss: 1.6409 - val_accuracy: 0.6496\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.6603 - val_accuracy: 0.7265\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.6604 - val_accuracy: 0.7265\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2477 - accuracy: 0.8704 - val_loss: 1.6658 - val_accuracy: 0.6667\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2457 - accuracy: 0.8630 - val_loss: 1.6054 - val_accuracy: 0.7179\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 1.5938 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.6320 - val_accuracy: 0.7265\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2430 - accuracy: 0.8704 - val_loss: 1.6426 - val_accuracy: 0.7265\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.6205 - val_accuracy: 0.7265\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.6359 - val_accuracy: 0.7265\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.6421 - val_accuracy: 0.7265\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2451 - accuracy: 0.8667 - val_loss: 1.6571 - val_accuracy: 0.7350\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.6512 - val_accuracy: 0.7350\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.6657 - val_accuracy: 0.6838\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2446 - accuracy: 0.8889 - val_loss: 1.6425 - val_accuracy: 0.7265\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 1.6222 - val_accuracy: 0.7265\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2529 - accuracy: 0.8815 - val_loss: 1.6480 - val_accuracy: 0.6838\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2462 - accuracy: 0.8667 - val_loss: 1.6751 - val_accuracy: 0.7009\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.6808 - val_accuracy: 0.7265\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2491 - accuracy: 0.8815 - val_loss: 1.6555 - val_accuracy: 0.7265\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 1.5985 - val_accuracy: 0.7265\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.5865 - val_accuracy: 0.7265\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.5914 - val_accuracy: 0.7265\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.6558 - val_accuracy: 0.7265\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.7279 - val_accuracy: 0.6838\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 1.7259 - val_accuracy: 0.6838\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2528 - accuracy: 0.8630 - val_loss: 1.7013 - val_accuracy: 0.6496\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2486 - accuracy: 0.8667 - val_loss: 1.6771 - val_accuracy: 0.7265\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.6572 - val_accuracy: 0.7265\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.6495 - val_accuracy: 0.6838\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6234 - val_accuracy: 0.7265\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 1.6221 - val_accuracy: 0.7179\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 1.6475 - val_accuracy: 0.7179\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.6925 - val_accuracy: 0.7265\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2453 - accuracy: 0.8704 - val_loss: 1.7352 - val_accuracy: 0.6838\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.7237 - val_accuracy: 0.7265\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.7263 - val_accuracy: 0.7265\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 1.7216 - val_accuracy: 0.7265\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.7184 - val_accuracy: 0.6667\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.7232 - val_accuracy: 0.6752\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2474 - accuracy: 0.8630 - val_loss: 1.6707 - val_accuracy: 0.7265\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.6664 - val_accuracy: 0.7265\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.6499 - val_accuracy: 0.7265\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2440 - accuracy: 0.8630 - val_loss: 1.6567 - val_accuracy: 0.7265\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.6930 - val_accuracy: 0.6838\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2487 - accuracy: 0.8704 - val_loss: 1.6983 - val_accuracy: 0.7265\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2531 - accuracy: 0.8815 - val_loss: 1.6324 - val_accuracy: 0.7265\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2571 - accuracy: 0.8667 - val_loss: 1.6413 - val_accuracy: 0.6496\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2504 - accuracy: 0.8741 - val_loss: 1.7549 - val_accuracy: 0.6667\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2588 - accuracy: 0.8741 - val_loss: 1.7633 - val_accuracy: 0.6667\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.6944 - val_accuracy: 0.6752\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2505 - accuracy: 0.8852 - val_loss: 1.6567 - val_accuracy: 0.6496\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2646 - accuracy: 0.8593 - val_loss: 1.7071 - val_accuracy: 0.6325\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2477 - accuracy: 0.8630 - val_loss: 1.7311 - val_accuracy: 0.7265\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6965 - val_accuracy: 0.7265\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.6462 - val_accuracy: 0.7265\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.6084 - val_accuracy: 0.7265\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 1.6218 - val_accuracy: 0.7265\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.6875 - val_accuracy: 0.7009\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2492 - accuracy: 0.8704 - val_loss: 1.6806 - val_accuracy: 0.6838\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.6480 - val_accuracy: 0.7265\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.6499 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.6807 - val_accuracy: 0.7265\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2522 - accuracy: 0.8630 - val_loss: 1.6948 - val_accuracy: 0.6752\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.6143 - val_accuracy: 0.7265\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.6427 - val_accuracy: 0.7265\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2485 - accuracy: 0.8815 - val_loss: 1.6718 - val_accuracy: 0.7265\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.6725 - val_accuracy: 0.6410\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2572 - accuracy: 0.8519 - val_loss: 1.6564 - val_accuracy: 0.7350\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2419 - accuracy: 0.8741 - val_loss: 1.6565 - val_accuracy: 0.7265\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2591 - accuracy: 0.8815 - val_loss: 1.6978 - val_accuracy: 0.7265\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.6941 - val_accuracy: 0.7350\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.7007 - val_accuracy: 0.7350\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.6748 - val_accuracy: 0.7265\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.6653 - val_accuracy: 0.7265\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.6708 - val_accuracy: 0.7265\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.7083 - val_accuracy: 0.7265\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.7100 - val_accuracy: 0.7265\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2399 - accuracy: 0.8815 - val_loss: 1.6628 - val_accuracy: 0.7265\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.6774 - val_accuracy: 0.7265\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.7243 - val_accuracy: 0.7436\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.7646 - val_accuracy: 0.7350\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2553 - accuracy: 0.8741 - val_loss: 1.7586 - val_accuracy: 0.7436\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 274us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.6737 - val_accuracy: 0.7350\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.6361 - val_accuracy: 0.7265\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.6526 - val_accuracy: 0.7350\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2479 - accuracy: 0.8741 - val_loss: 1.7074 - val_accuracy: 0.6838\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2562 - accuracy: 0.8741 - val_loss: 1.7910 - val_accuracy: 0.6667\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2575 - accuracy: 0.8741 - val_loss: 1.7128 - val_accuracy: 0.6667\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2411 - accuracy: 0.8852 - val_loss: 1.6422 - val_accuracy: 0.7265\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 1.6352 - val_accuracy: 0.7265\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.7005 - val_accuracy: 0.7265\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.7609 - val_accuracy: 0.7436\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.6828 - val_accuracy: 0.7265\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.6500 - val_accuracy: 0.7265\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2491 - accuracy: 0.8778 - val_loss: 1.6691 - val_accuracy: 0.7265\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2504 - accuracy: 0.8815 - val_loss: 1.6521 - val_accuracy: 0.7265\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.6641 - val_accuracy: 0.7265\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.89 - 0s 67us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.6798 - val_accuracy: 0.7265\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.6549 - val_accuracy: 0.7265\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2505 - accuracy: 0.8593 - val_loss: 1.6793 - val_accuracy: 0.6752\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2454 - accuracy: 0.8704 - val_loss: 1.7102 - val_accuracy: 0.6838\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 1.6790 - val_accuracy: 0.7265\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2503 - accuracy: 0.8630 - val_loss: 1.6331 - val_accuracy: 0.7265\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 1.6723 - val_accuracy: 0.6838\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.7108 - val_accuracy: 0.6838\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.7264 - val_accuracy: 0.7265\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.7091 - val_accuracy: 0.7265\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.6905 - val_accuracy: 0.7265\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.6652 - val_accuracy: 0.7265\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2506 - accuracy: 0.8667 - val_loss: 1.7371 - val_accuracy: 0.6838\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2524 - accuracy: 0.8778 - val_loss: 1.7364 - val_accuracy: 0.7436\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.6900 - val_accuracy: 0.7265\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.6702 - val_accuracy: 0.7265\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.7140 - val_accuracy: 0.7265\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.7405 - val_accuracy: 0.7265\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6833 - val_accuracy: 0.7265\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2538 - accuracy: 0.8741 - val_loss: 1.6661 - val_accuracy: 0.7265\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2518 - accuracy: 0.8667 - val_loss: 1.7283 - val_accuracy: 0.6838\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2548 - accuracy: 0.8556 - val_loss: 1.7636 - val_accuracy: 0.6838\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2526 - accuracy: 0.8667 - val_loss: 1.7496 - val_accuracy: 0.6838\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 1.6597 - val_accuracy: 0.7265\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.6941 - val_accuracy: 0.7265\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2538 - accuracy: 0.8815 - val_loss: 1.7656 - val_accuracy: 0.7265\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2539 - accuracy: 0.8815 - val_loss: 1.6890 - val_accuracy: 0.7265\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.6576 - val_accuracy: 0.7265\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.6713 - val_accuracy: 0.7179\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.7150 - val_accuracy: 0.6752\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2485 - accuracy: 0.8741 - val_loss: 1.7036 - val_accuracy: 0.7179\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2480 - accuracy: 0.8815 - val_loss: 1.6849 - val_accuracy: 0.7179\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2471 - accuracy: 0.8704 - val_loss: 1.7246 - val_accuracy: 0.6838\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 1.7109 - val_accuracy: 0.6752\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2542 - accuracy: 0.8741 - val_loss: 1.7222 - val_accuracy: 0.7265\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2551 - accuracy: 0.8815 - val_loss: 1.7038 - val_accuracy: 0.7265\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.7207 - val_accuracy: 0.6667\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2467 - accuracy: 0.8704 - val_loss: 1.7340 - val_accuracy: 0.6667\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.7149 - val_accuracy: 0.7265\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.6941 - val_accuracy: 0.7265\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 1.6877 - val_accuracy: 0.7265\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2453 - accuracy: 0.8704 - val_loss: 1.6720 - val_accuracy: 0.7094\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2530 - accuracy: 0.8667 - val_loss: 1.6707 - val_accuracy: 0.7094\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.6948 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2509 - accuracy: 0.8815 - val_loss: 1.7230 - val_accuracy: 0.7265\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.6901 - val_accuracy: 0.7179\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.6547 - val_accuracy: 0.7265\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.6657 - val_accuracy: 0.7265\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.6741 - val_accuracy: 0.7265\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.6520 - val_accuracy: 0.7265\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2432 - accuracy: 0.8926 - val_loss: 1.6952 - val_accuracy: 0.7265\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.7212 - val_accuracy: 0.7265\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.7163 - val_accuracy: 0.6838\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2555 - accuracy: 0.8593 - val_loss: 1.7125 - val_accuracy: 0.6496\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2512 - accuracy: 0.8593 - val_loss: 1.7001 - val_accuracy: 0.7265\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.7347 - val_accuracy: 0.7265\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2529 - accuracy: 0.8815 - val_loss: 1.7148 - val_accuracy: 0.7265\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 1.6711 - val_accuracy: 0.7265\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2509 - accuracy: 0.8741 - val_loss: 1.6897 - val_accuracy: 0.6667\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.6565 - val_accuracy: 0.6838\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.6757 - val_accuracy: 0.7265\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.6831 - val_accuracy: 0.7350\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.7138 - val_accuracy: 0.7265\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.7109 - val_accuracy: 0.7265\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.6821 - val_accuracy: 0.7265\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.6939 - val_accuracy: 0.7521\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 1.7269 - val_accuracy: 0.7009\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2527 - accuracy: 0.8630 - val_loss: 1.7326 - val_accuracy: 0.7436\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2508 - accuracy: 0.8741 - val_loss: 1.7046 - val_accuracy: 0.7265\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.6556 - val_accuracy: 0.7265\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.6680 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.7245 - val_accuracy: 0.6838\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2545 - accuracy: 0.8741 - val_loss: 1.8077 - val_accuracy: 0.6838\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2534 - accuracy: 0.8667 - val_loss: 1.7350 - val_accuracy: 0.6838\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2426 - accuracy: 0.8704 - val_loss: 1.6942 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.6944 - val_accuracy: 0.7265\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.7257 - val_accuracy: 0.7265\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6807 - val_accuracy: 0.7265\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.6734 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.6997 - val_accuracy: 0.7350\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.7312 - val_accuracy: 0.7094\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2483 - accuracy: 0.8667 - val_loss: 1.7426 - val_accuracy: 0.7094\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2417 - accuracy: 0.8963 - val_loss: 1.7140 - val_accuracy: 0.7265\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.6750 - val_accuracy: 0.7265\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2546 - accuracy: 0.8815 - val_loss: 1.6855 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2453 - accuracy: 0.8852 - val_loss: 1.7281 - val_accuracy: 0.6838\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.7201 - val_accuracy: 0.6838\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2445 - accuracy: 0.8852 - val_loss: 1.6873 - val_accuracy: 0.7265\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 1.7313 - val_accuracy: 0.7265\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.7882 - val_accuracy: 0.6838\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2557 - accuracy: 0.8778 - val_loss: 1.8234 - val_accuracy: 0.6752\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2533 - accuracy: 0.8667 - val_loss: 1.7197 - val_accuracy: 0.6838\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.6700 - val_accuracy: 0.7265\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2433 - accuracy: 0.8630 - val_loss: 1.6810 - val_accuracy: 0.6838\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2471 - accuracy: 0.8630 - val_loss: 1.6512 - val_accuracy: 0.7265\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6520 - val_accuracy: 0.7265\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.6584 - val_accuracy: 0.7265\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2485 - accuracy: 0.8630 - val_loss: 1.6765 - val_accuracy: 0.6838\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2408 - accuracy: 0.8852 - val_loss: 1.6804 - val_accuracy: 0.7265\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2656 - accuracy: 0.8815 - val_loss: 1.7149 - val_accuracy: 0.7265\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2513 - accuracy: 0.8741 - val_loss: 1.7161 - val_accuracy: 0.7265\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.7182 - val_accuracy: 0.7265\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2442 - accuracy: 0.8889 - val_loss: 1.7519 - val_accuracy: 0.7265\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 658us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.7003 - val_accuracy: 0.7265\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 543us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.6672 - val_accuracy: 0.7265\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 419us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 1.6543 - val_accuracy: 0.7265\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6693 - val_accuracy: 0.6496\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2502 - accuracy: 0.8704 - val_loss: 1.7176 - val_accuracy: 0.6838\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 856us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.7030 - val_accuracy: 0.7265\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 354us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.6939 - val_accuracy: 0.7265\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 449us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.6817 - val_accuracy: 0.7265\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.6807 - val_accuracy: 0.7179\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2418 - accuracy: 0.8889 - val_loss: 1.6872 - val_accuracy: 0.6838\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2465 - accuracy: 0.8704 - val_loss: 1.6882 - val_accuracy: 0.7265\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.6843 - val_accuracy: 0.7265\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.7118 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2442 - accuracy: 0.8667 - val_loss: 1.7235 - val_accuracy: 0.7265\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.7413 - val_accuracy: 0.7265\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2463 - accuracy: 0.8704 - val_loss: 1.7320 - val_accuracy: 0.6838\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 317us/step - loss: 0.2471 - accuracy: 0.8667 - val_loss: 1.7168 - val_accuracy: 0.7179\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.7419 - val_accuracy: 0.7265\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.7398 - val_accuracy: 0.7350\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.7370 - val_accuracy: 0.7350\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2469 - accuracy: 0.8704 - val_loss: 1.7399 - val_accuracy: 0.7350\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.7856 - val_accuracy: 0.7265\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.8256 - val_accuracy: 0.6838\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2551 - accuracy: 0.8593 - val_loss: 1.8234 - val_accuracy: 0.6838\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.7226 - val_accuracy: 0.6496\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2538 - accuracy: 0.8667 - val_loss: 1.7435 - val_accuracy: 0.6325\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2529 - accuracy: 0.8593 - val_loss: 1.7847 - val_accuracy: 0.6838\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.7258 - val_accuracy: 0.7265\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 353us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.7097 - val_accuracy: 0.7265\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2425 - accuracy: 0.8704 - val_loss: 1.7272 - val_accuracy: 0.7265\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.7518 - val_accuracy: 0.7265\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.7626 - val_accuracy: 0.7265\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2465 - accuracy: 0.8667 - val_loss: 1.7697 - val_accuracy: 0.6667\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2524 - accuracy: 0.8593 - val_loss: 1.7458 - val_accuracy: 0.6838\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2438 - accuracy: 0.8889 - val_loss: 1.7017 - val_accuracy: 0.7265\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.6681 - val_accuracy: 0.7265\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.6548 - val_accuracy: 0.7350\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6649 - val_accuracy: 0.7265\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.7218 - val_accuracy: 0.7094\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.7437 - val_accuracy: 0.7265\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.7015 - val_accuracy: 0.7350\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.6895 - val_accuracy: 0.7350\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2489 - accuracy: 0.8815 - val_loss: 1.6992 - val_accuracy: 0.7265\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2451 - accuracy: 0.8630 - val_loss: 1.7396 - val_accuracy: 0.6923\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2460 - accuracy: 0.8630 - val_loss: 1.7089 - val_accuracy: 0.6923\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.6758 - val_accuracy: 0.7265\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.6919 - val_accuracy: 0.7265\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2434 - accuracy: 0.8630 - val_loss: 1.7446 - val_accuracy: 0.6838\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.7382 - val_accuracy: 0.7265\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.7461 - val_accuracy: 0.7265\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.7537 - val_accuracy: 0.7265\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 1.7534 - val_accuracy: 0.7265\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2462 - accuracy: 0.8852 - val_loss: 1.7601 - val_accuracy: 0.6667\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2520 - accuracy: 0.8704 - val_loss: 1.7717 - val_accuracy: 0.6667\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2478 - accuracy: 0.8667 - val_loss: 1.7524 - val_accuracy: 0.7265\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.7379 - val_accuracy: 0.7265\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2466 - accuracy: 0.8667 - val_loss: 1.6845 - val_accuracy: 0.7265\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 1.6718 - val_accuracy: 0.7179\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2447 - accuracy: 0.8593 - val_loss: 1.7310 - val_accuracy: 0.7009\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.7159 - val_accuracy: 0.6838\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.7003 - val_accuracy: 0.7265\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 847us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.7078 - val_accuracy: 0.7265\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.7565 - val_accuracy: 0.6838\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2456 - accuracy: 0.8704 - val_loss: 1.7785 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.132567). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.2530 - accuracy: 0.8741 - val_loss: 1.7495 - val_accuracy: 0.7265\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.7050 - val_accuracy: 0.7265\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 1.6997 - val_accuracy: 0.7265\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2453 - accuracy: 0.8704 - val_loss: 1.7363 - val_accuracy: 0.6838\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 678us/step - loss: 0.2423 - accuracy: 0.8852 - val_loss: 1.7653 - val_accuracy: 0.7265\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.7585 - val_accuracy: 0.7265\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.7468 - val_accuracy: 0.7265\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.7411 - val_accuracy: 0.7265\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2473 - accuracy: 0.8667 - val_loss: 1.7444 - val_accuracy: 0.7265\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.7883 - val_accuracy: 0.7265\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2443 - accuracy: 0.8704 - val_loss: 1.8217 - val_accuracy: 0.6838\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.7767 - val_accuracy: 0.6838\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 1.7785 - val_accuracy: 0.7350\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2506 - accuracy: 0.8630 - val_loss: 1.8097 - val_accuracy: 0.7265\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.7473 - val_accuracy: 0.7265\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.7333 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a32897128>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 115us/step\n",
      "over-sampling test accuracy: 72.65%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 1, 0, 2, 0, 2, 1, 0, 2, 2, 1, 1, 2, 2, 2, 0, 1, 1, 2,\n",
       "       1, 1, 1, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 2, 0, 0,\n",
       "       1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2, 2, 0, 1,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1,\n",
       "       0, 1, 0, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBRSa07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa25     1     1\n",
       "1       CFBRSa07     0     0\n",
       "2         NRS247     0     0\n",
       "3          NY439     2     2\n",
       "4    CFBREBSa110     1     1\n",
       "..           ...   ...   ...\n",
       "112       SR1129     0     0\n",
       "113       NRS172     0     1\n",
       "114       NRS205     2     2\n",
       "115        NY439     2     2\n",
       "116       NRS249     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127998</td>\n",
       "      <td>8.664240e-01</td>\n",
       "      <td>5.577853e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.990138</td>\n",
       "      <td>9.755548e-03</td>\n",
       "      <td>1.060881e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759890</td>\n",
       "      <td>2.400113e-01</td>\n",
       "      <td>9.896529e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>3.849521e-04</td>\n",
       "      <td>9.995494e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325551</td>\n",
       "      <td>5.760931e-01</td>\n",
       "      <td>9.835556e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.999644</td>\n",
       "      <td>3.559579e-04</td>\n",
       "      <td>7.032389e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>9.999825e-01</td>\n",
       "      <td>3.212149e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.725805e-11</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>3.849521e-04</td>\n",
       "      <td>9.995494e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>3.319367e-03</td>\n",
       "      <td>9.966633e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    0.127998  8.664240e-01  5.577853e-03\n",
       "1    0.990138  9.755548e-03  1.060881e-04\n",
       "2    0.759890  2.400113e-01  9.896529e-05\n",
       "3    0.000066  3.849521e-04  9.995494e-01\n",
       "4    0.325551  5.760931e-01  9.835556e-02\n",
       "..        ...           ...           ...\n",
       "112  0.999644  3.559579e-04  7.032389e-14\n",
       "113  0.000018  9.999825e-01  3.212149e-08\n",
       "114  0.000001  6.725805e-11  9.999989e-01\n",
       "115  0.000066  3.849521e-04  9.995494e-01\n",
       "116  0.000017  3.319367e-03  9.966633e-01\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.6927 - val_accuracy: 0.6838\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6684 - val_accuracy: 0.6838\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.6384 - val_accuracy: 0.6496\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.6457 - val_accuracy: 0.7265\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 1.6767 - val_accuracy: 0.7265\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 1.6787 - val_accuracy: 0.7265\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.6685 - val_accuracy: 0.6838\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2464 - accuracy: 0.8852 - val_loss: 1.6476 - val_accuracy: 0.7265\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6560 - val_accuracy: 0.7265\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2425 - accuracy: 0.8926 - val_loss: 1.6747 - val_accuracy: 0.6838\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2460 - accuracy: 0.8704 - val_loss: 1.6743 - val_accuracy: 0.6838\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.6667 - val_accuracy: 0.7265\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 1.6456 - val_accuracy: 0.7265\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.6577 - val_accuracy: 0.6838\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2511 - accuracy: 0.8630 - val_loss: 1.6602 - val_accuracy: 0.7265\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 1.6389 - val_accuracy: 0.7265\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2558 - accuracy: 0.8815 - val_loss: 1.6444 - val_accuracy: 0.7265\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.6640 - val_accuracy: 0.6667\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.6581 - val_accuracy: 0.6667\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2467 - accuracy: 0.8704 - val_loss: 1.6392 - val_accuracy: 0.7265\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2651 - accuracy: 0.8556 - val_loss: 1.6481 - val_accuracy: 0.6496\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2573 - accuracy: 0.8741 - val_loss: 1.6570 - val_accuracy: 0.7265\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2570 - accuracy: 0.8815 - val_loss: 1.6873 - val_accuracy: 0.7436\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2493 - accuracy: 0.8630 - val_loss: 1.6875 - val_accuracy: 0.6838\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2534 - accuracy: 0.8556 - val_loss: 1.6531 - val_accuracy: 0.7265\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2510 - accuracy: 0.8741 - val_loss: 1.6414 - val_accuracy: 0.7265\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.6734 - val_accuracy: 0.7265\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2493 - accuracy: 0.8815 - val_loss: 1.6870 - val_accuracy: 0.7265\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2425 - accuracy: 0.8852 - val_loss: 1.7001 - val_accuracy: 0.6667\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2506 - accuracy: 0.8704 - val_loss: 1.7076 - val_accuracy: 0.6752\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2507 - accuracy: 0.8704 - val_loss: 1.7042 - val_accuracy: 0.7265\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2565 - accuracy: 0.8815 - val_loss: 1.6823 - val_accuracy: 0.7265\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.6553 - val_accuracy: 0.7265\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2495 - accuracy: 0.8519 - val_loss: 1.6813 - val_accuracy: 0.6752\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2501 - accuracy: 0.8667 - val_loss: 1.6857 - val_accuracy: 0.6667\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2437 - accuracy: 0.8667 - val_loss: 1.6715 - val_accuracy: 0.7265\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.6690 - val_accuracy: 0.7265\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.6655 - val_accuracy: 0.7265\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.6532 - val_accuracy: 0.6496\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2467 - accuracy: 0.8667 - val_loss: 1.6710 - val_accuracy: 0.7009\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2485 - accuracy: 0.8667 - val_loss: 1.7120 - val_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2549 - accuracy: 0.8741 - val_loss: 1.6752 - val_accuracy: 0.6838\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2485 - accuracy: 0.8667 - val_loss: 1.6263 - val_accuracy: 0.7265\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.6543 - val_accuracy: 0.6667\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2477 - accuracy: 0.8630 - val_loss: 1.6538 - val_accuracy: 0.6838\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.87 - 0s 92us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.6727 - val_accuracy: 0.6838\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2434 - accuracy: 0.8852 - val_loss: 1.6550 - val_accuracy: 0.7265\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6497 - val_accuracy: 0.7265\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.6612 - val_accuracy: 0.7265\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2391 - accuracy: 0.9074 - val_loss: 1.6890 - val_accuracy: 0.6667\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2504 - accuracy: 0.8704 - val_loss: 1.6801 - val_accuracy: 0.6667\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2436 - accuracy: 0.8704 - val_loss: 1.6700 - val_accuracy: 0.7265\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2481 - accuracy: 0.8815 - val_loss: 1.6696 - val_accuracy: 0.7265\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2418 - accuracy: 0.8926 - val_loss: 1.6956 - val_accuracy: 0.6667\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2490 - accuracy: 0.8704 - val_loss: 1.6880 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.6753 - val_accuracy: 0.6838\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.6607 - val_accuracy: 0.7265\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.6659 - val_accuracy: 0.7265\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.6726 - val_accuracy: 0.7265\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 1.6595 - val_accuracy: 0.7265\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2401 - accuracy: 0.8815 - val_loss: 1.6681 - val_accuracy: 0.7265\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2578 - accuracy: 0.8593 - val_loss: 1.6785 - val_accuracy: 0.6667\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2601 - accuracy: 0.8556 - val_loss: 1.6514 - val_accuracy: 0.7265\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.6650 - val_accuracy: 0.7350\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 1.7246 - val_accuracy: 0.6667\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2491 - accuracy: 0.8741 - val_loss: 1.7177 - val_accuracy: 0.6667\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2473 - accuracy: 0.8704 - val_loss: 1.6870 - val_accuracy: 0.6667\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2522 - accuracy: 0.8778 - val_loss: 1.6583 - val_accuracy: 0.7265\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.6792 - val_accuracy: 0.7265\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.7043 - val_accuracy: 0.7009\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2541 - accuracy: 0.8667 - val_loss: 1.7038 - val_accuracy: 0.6838\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2487 - accuracy: 0.8704 - val_loss: 1.6825 - val_accuracy: 0.7265\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.6551 - val_accuracy: 0.7265\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2480 - accuracy: 0.8815 - val_loss: 1.6495 - val_accuracy: 0.7265\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.7008 - val_accuracy: 0.6838\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.7156 - val_accuracy: 0.6838\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2419 - accuracy: 0.8852 - val_loss: 1.6933 - val_accuracy: 0.7265\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.6648 - val_accuracy: 0.7265\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2533 - accuracy: 0.8815 - val_loss: 1.6650 - val_accuracy: 0.7265\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2475 - accuracy: 0.8667 - val_loss: 1.7231 - val_accuracy: 0.6752\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2507 - accuracy: 0.8593 - val_loss: 1.7323 - val_accuracy: 0.6667\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.6902 - val_accuracy: 0.7265\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6801 - val_accuracy: 0.7265\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.6990 - val_accuracy: 0.6838\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.7071 - val_accuracy: 0.6838\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2464 - accuracy: 0.8667 - val_loss: 1.6829 - val_accuracy: 0.6923\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2430 - accuracy: 0.8704 - val_loss: 1.6551 - val_accuracy: 0.7265\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.6618 - val_accuracy: 0.7265\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.6827 - val_accuracy: 0.7265\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.6825 - val_accuracy: 0.7265\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2416 - accuracy: 0.8704 - val_loss: 1.6761 - val_accuracy: 0.7265\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2536 - accuracy: 0.8630 - val_loss: 1.6730 - val_accuracy: 0.6838\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2407 - accuracy: 0.8741 - val_loss: 1.6865 - val_accuracy: 0.7265\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.6809 - val_accuracy: 0.7265\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2453 - accuracy: 0.8667 - val_loss: 1.7066 - val_accuracy: 0.6923\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2480 - accuracy: 0.8667 - val_loss: 1.7011 - val_accuracy: 0.6923\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2468 - accuracy: 0.8704 - val_loss: 1.6952 - val_accuracy: 0.6838\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.6937 - val_accuracy: 0.7265\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.7210 - val_accuracy: 0.6838\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.7438 - val_accuracy: 0.6838\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.7235 - val_accuracy: 0.7265\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.6827 - val_accuracy: 0.7265\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2523 - accuracy: 0.8593 - val_loss: 1.6487 - val_accuracy: 0.6581\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2592 - accuracy: 0.8630 - val_loss: 1.6729 - val_accuracy: 0.7350\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2442 - accuracy: 0.8704 - val_loss: 1.7710 - val_accuracy: 0.6667\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 1.7825 - val_accuracy: 0.6667\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2510 - accuracy: 0.8778 - val_loss: 1.6868 - val_accuracy: 0.6496\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2512 - accuracy: 0.8704 - val_loss: 1.6467 - val_accuracy: 0.7265\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.6733 - val_accuracy: 0.7265\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6691 - val_accuracy: 0.7265\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.6816 - val_accuracy: 0.7265\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 61us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.7308 - val_accuracy: 0.6752\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.7148 - val_accuracy: 0.6838\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2433 - accuracy: 0.8593 - val_loss: 1.6865 - val_accuracy: 0.7265\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.6781 - val_accuracy: 0.7265\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.6634 - val_accuracy: 0.7265\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.6922 - val_accuracy: 0.7265\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.7455 - val_accuracy: 0.6667\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2642 - accuracy: 0.8593 - val_loss: 1.7743 - val_accuracy: 0.6838\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2595 - accuracy: 0.8667 - val_loss: 1.7019 - val_accuracy: 0.6838\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2483 - accuracy: 0.8704 - val_loss: 1.6477 - val_accuracy: 0.7265\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2546 - accuracy: 0.8741 - val_loss: 1.6533 - val_accuracy: 0.7265\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.7168 - val_accuracy: 0.6838\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2549 - accuracy: 0.8630 - val_loss: 1.7611 - val_accuracy: 0.6838\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2519 - accuracy: 0.8630 - val_loss: 1.7026 - val_accuracy: 0.6838\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.6716 - val_accuracy: 0.7265\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.6512 - val_accuracy: 0.7350\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2545 - accuracy: 0.8593 - val_loss: 1.6833 - val_accuracy: 0.6667\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2565 - accuracy: 0.8593 - val_loss: 1.7285 - val_accuracy: 0.6667\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.6985 - val_accuracy: 0.7265\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2579 - accuracy: 0.8815 - val_loss: 1.6677 - val_accuracy: 0.7265\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2560 - accuracy: 0.8667 - val_loss: 1.6628 - val_accuracy: 0.7265\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 1.7184 - val_accuracy: 0.6752\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.7357 - val_accuracy: 0.6667\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2443 - accuracy: 0.8926 - val_loss: 1.6751 - val_accuracy: 0.7265\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.6554 - val_accuracy: 0.7265\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2485 - accuracy: 0.8704 - val_loss: 1.6755 - val_accuracy: 0.7265\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.6867 - val_accuracy: 0.7265\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.6790 - val_accuracy: 0.7265\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.7017 - val_accuracy: 0.7265\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2413 - accuracy: 0.8852 - val_loss: 1.7226 - val_accuracy: 0.6838\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.7096 - val_accuracy: 0.7265\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 1.6783 - val_accuracy: 0.7265\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2523 - accuracy: 0.8741 - val_loss: 1.6856 - val_accuracy: 0.7265\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.6944 - val_accuracy: 0.7265\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.6856 - val_accuracy: 0.7265\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.6963 - val_accuracy: 0.6838\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.6963 - val_accuracy: 0.6838\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2462 - accuracy: 0.8630 - val_loss: 1.7062 - val_accuracy: 0.6752\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2472 - accuracy: 0.8704 - val_loss: 1.6755 - val_accuracy: 0.7265\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.6434 - val_accuracy: 0.7179\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2533 - accuracy: 0.8815 - val_loss: 1.6739 - val_accuracy: 0.7265\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2494 - accuracy: 0.8815 - val_loss: 1.6627 - val_accuracy: 0.7265\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2429 - accuracy: 0.8852 - val_loss: 1.6767 - val_accuracy: 0.6923\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 1.7052 - val_accuracy: 0.6752\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.7616 - val_accuracy: 0.6667\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2560 - accuracy: 0.8778 - val_loss: 1.7084 - val_accuracy: 0.7265\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.6454 - val_accuracy: 0.7350\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6606 - val_accuracy: 0.7436\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2419 - accuracy: 0.8741 - val_loss: 1.6800 - val_accuracy: 0.7436\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2484 - accuracy: 0.8741 - val_loss: 1.6722 - val_accuracy: 0.7436\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2485 - accuracy: 0.8704 - val_loss: 1.6816 - val_accuracy: 0.7009\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.6931 - val_accuracy: 0.6838\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.6836 - val_accuracy: 0.6838\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 1.6801 - val_accuracy: 0.6752\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.7027 - val_accuracy: 0.7265\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.7114 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2494 - accuracy: 0.8704 - val_loss: 1.7135 - val_accuracy: 0.7009\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.6888 - val_accuracy: 0.7265\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2450 - accuracy: 0.8704 - val_loss: 1.7029 - val_accuracy: 0.6838\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.6842 - val_accuracy: 0.7265\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.6668 - val_accuracy: 0.7265\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 1.6729 - val_accuracy: 0.7265\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.6788 - val_accuracy: 0.7265\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.6920 - val_accuracy: 0.7265\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.6980 - val_accuracy: 0.6838\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.6956 - val_accuracy: 0.7265\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.6728 - val_accuracy: 0.7265\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 1.6793 - val_accuracy: 0.7265\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2392 - accuracy: 0.8815 - val_loss: 1.6938 - val_accuracy: 0.6838\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2529 - accuracy: 0.8741 - val_loss: 1.7174 - val_accuracy: 0.6838\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2519 - accuracy: 0.8630 - val_loss: 1.6990 - val_accuracy: 0.6838\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2383 - accuracy: 0.8852 - val_loss: 1.6719 - val_accuracy: 0.7265\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2625 - accuracy: 0.8741 - val_loss: 1.6788 - val_accuracy: 0.7265\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2503 - accuracy: 0.8778 - val_loss: 1.7513 - val_accuracy: 0.6838\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2552 - accuracy: 0.8630 - val_loss: 1.7764 - val_accuracy: 0.6838\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2474 - accuracy: 0.8630 - val_loss: 1.7287 - val_accuracy: 0.7265\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.6995 - val_accuracy: 0.7265\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.7119 - val_accuracy: 0.7265\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.7002 - val_accuracy: 0.7265\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.7149 - val_accuracy: 0.7265\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2392 - accuracy: 0.8778 - val_loss: 1.7121 - val_accuracy: 0.6838\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2444 - accuracy: 0.8667 - val_loss: 1.7298 - val_accuracy: 0.6667\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 1.7273 - val_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2468 - accuracy: 0.8741 - val_loss: 1.7090 - val_accuracy: 0.6838\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2480 - accuracy: 0.8815 - val_loss: 1.6622 - val_accuracy: 0.7265\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 1.6848 - val_accuracy: 0.7265\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.7486 - val_accuracy: 0.6838\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2540 - accuracy: 0.8667 - val_loss: 1.7764 - val_accuracy: 0.6838\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2534 - accuracy: 0.8667 - val_loss: 1.7402 - val_accuracy: 0.6923\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.7060 - val_accuracy: 0.7179\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2459 - accuracy: 0.8852 - val_loss: 1.7049 - val_accuracy: 0.7265\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.7318 - val_accuracy: 0.7265\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.7452 - val_accuracy: 0.7009\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.7224 - val_accuracy: 0.7265\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.7293 - val_accuracy: 0.6838\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.7161 - val_accuracy: 0.6752\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.7151 - val_accuracy: 0.6838\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.7111 - val_accuracy: 0.7265\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.7304 - val_accuracy: 0.6838\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2555 - accuracy: 0.8667 - val_loss: 1.7858 - val_accuracy: 0.6667\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 1.7328 - val_accuracy: 0.7265\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.6867 - val_accuracy: 0.7265\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 1.6935 - val_accuracy: 0.7265\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.7179 - val_accuracy: 0.7179\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 1.7312 - val_accuracy: 0.7265\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2517 - accuracy: 0.8815 - val_loss: 1.7293 - val_accuracy: 0.7265\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2485 - accuracy: 0.8815 - val_loss: 1.7453 - val_accuracy: 0.7179\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.7356 - val_accuracy: 0.7179\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.7437 - val_accuracy: 0.6923\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 1.7326 - val_accuracy: 0.7009\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2443 - accuracy: 0.8667 - val_loss: 1.6820 - val_accuracy: 0.7265\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.6893 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.7247 - val_accuracy: 0.6838\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2438 - accuracy: 0.8852 - val_loss: 1.7416 - val_accuracy: 0.6838\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.7388 - val_accuracy: 0.7265\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 1.7482 - val_accuracy: 0.7179\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.7637 - val_accuracy: 0.6838\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2482 - accuracy: 0.8667 - val_loss: 1.7443 - val_accuracy: 0.6838\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2507 - accuracy: 0.8593 - val_loss: 1.7799 - val_accuracy: 0.6838\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.7523 - val_accuracy: 0.7265\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2522 - accuracy: 0.8815 - val_loss: 1.7164 - val_accuracy: 0.7179\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.7354 - val_accuracy: 0.6838\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2536 - accuracy: 0.8704 - val_loss: 1.7609 - val_accuracy: 0.6667\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 1.7811 - val_accuracy: 0.6838\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2490 - accuracy: 0.8741 - val_loss: 1.7707 - val_accuracy: 0.6838\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 1.7668 - val_accuracy: 0.6752\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.7758 - val_accuracy: 0.6752\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.7545 - val_accuracy: 0.6838\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.7362 - val_accuracy: 0.6496\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 1.7186 - val_accuracy: 0.7265\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.7656 - val_accuracy: 0.7265\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 1.7303 - val_accuracy: 0.7265\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.7103 - val_accuracy: 0.7265\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2554 - accuracy: 0.8741 - val_loss: 1.7325 - val_accuracy: 0.6838\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.7368 - val_accuracy: 0.7265\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.7487 - val_accuracy: 0.7265\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.7802 - val_accuracy: 0.6838\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.7882 - val_accuracy: 0.6838\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2521 - accuracy: 0.8667 - val_loss: 1.8024 - val_accuracy: 0.6838\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2433 - accuracy: 0.8667 - val_loss: 1.7418 - val_accuracy: 0.7179\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.7495 - val_accuracy: 0.7265\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2491 - accuracy: 0.8704 - val_loss: 1.7952 - val_accuracy: 0.7265\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 1.7830 - val_accuracy: 0.7009\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2473 - accuracy: 0.8593 - val_loss: 1.7626 - val_accuracy: 0.7265\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2436 - accuracy: 0.8852 - val_loss: 1.7389 - val_accuracy: 0.7265\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.7309 - val_accuracy: 0.7265\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2527 - accuracy: 0.8815 - val_loss: 1.7628 - val_accuracy: 0.7265\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.7557 - val_accuracy: 0.6838\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2490 - accuracy: 0.8593 - val_loss: 1.7677 - val_accuracy: 0.6838\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2482 - accuracy: 0.8667 - val_loss: 1.8010 - val_accuracy: 0.6838\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2508 - accuracy: 0.8778 - val_loss: 1.8079 - val_accuracy: 0.6838\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.7652 - val_accuracy: 0.7265\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2408 - accuracy: 0.8852 - val_loss: 1.7287 - val_accuracy: 0.7265\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2544 - accuracy: 0.8778 - val_loss: 1.7231 - val_accuracy: 0.7179\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.7873 - val_accuracy: 0.7265\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.8059 - val_accuracy: 0.7265\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 1.7807 - val_accuracy: 0.7265\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.7301 - val_accuracy: 0.7265\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.7316 - val_accuracy: 0.7265\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.7549 - val_accuracy: 0.7265\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2526 - accuracy: 0.8815 - val_loss: 1.7722 - val_accuracy: 0.7265\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 1.7621 - val_accuracy: 0.7265\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.7565 - val_accuracy: 0.7265\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.7619 - val_accuracy: 0.7265\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.7226 - val_accuracy: 0.7350\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2556 - accuracy: 0.8556 - val_loss: 1.7483 - val_accuracy: 0.6496\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2489 - accuracy: 0.8630 - val_loss: 1.7944 - val_accuracy: 0.7009\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2429 - accuracy: 0.8741 - val_loss: 1.7779 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.7545 - val_accuracy: 0.7265\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2479 - accuracy: 0.8741 - val_loss: 1.7702 - val_accuracy: 0.7265\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.7952 - val_accuracy: 0.7265\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.7946 - val_accuracy: 0.7265\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.7834 - val_accuracy: 0.7265\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.8004 - val_accuracy: 0.6838\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2454 - accuracy: 0.8667 - val_loss: 1.7877 - val_accuracy: 0.6838\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.7620 - val_accuracy: 0.7265\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.7515 - val_accuracy: 0.7265\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.7653 - val_accuracy: 0.7265\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2414 - accuracy: 0.8889 - val_loss: 1.7528 - val_accuracy: 0.7265\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2522 - accuracy: 0.8741 - val_loss: 1.7528 - val_accuracy: 0.6496\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.8141 - val_accuracy: 0.7009\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.8083 - val_accuracy: 0.7265\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2656 - accuracy: 0.8815 - val_loss: 1.7736 - val_accuracy: 0.7265\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2574 - accuracy: 0.8815 - val_loss: 1.7401 - val_accuracy: 0.7265\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.7673 - val_accuracy: 0.7265\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 1.7860 - val_accuracy: 0.7265\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.8006 - val_accuracy: 0.7265\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.8130 - val_accuracy: 0.7265\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.7787 - val_accuracy: 0.6838\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.7417 - val_accuracy: 0.7265\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.7757 - val_accuracy: 0.7265\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2421 - accuracy: 0.8889 - val_loss: 1.8206 - val_accuracy: 0.6667\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2532 - accuracy: 0.8741 - val_loss: 1.8351 - val_accuracy: 0.6667\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2476 - accuracy: 0.8667 - val_loss: 1.7545 - val_accuracy: 0.6923\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2454 - accuracy: 0.8667 - val_loss: 1.6917 - val_accuracy: 0.6496\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2543 - accuracy: 0.8741 - val_loss: 1.6980 - val_accuracy: 0.7265\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.7382 - val_accuracy: 0.7265\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 341us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.7580 - val_accuracy: 0.6923\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 292us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 1.7761 - val_accuracy: 0.6838\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.7656 - val_accuracy: 0.7265\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2449 - accuracy: 0.8667 - val_loss: 1.7377 - val_accuracy: 0.7350\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.7562 - val_accuracy: 0.7265\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 473us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.7847 - val_accuracy: 0.6838\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.7938 - val_accuracy: 0.6838\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2472 - accuracy: 0.8593 - val_loss: 1.7884 - val_accuracy: 0.7094\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2455 - accuracy: 0.8741 - val_loss: 1.7566 - val_accuracy: 0.7265\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.7470 - val_accuracy: 0.7350\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.7630 - val_accuracy: 0.7350\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2477 - accuracy: 0.8852 - val_loss: 1.8261 - val_accuracy: 0.6838\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2464 - accuracy: 0.8852 - val_loss: 1.8063 - val_accuracy: 0.6923\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2447 - accuracy: 0.8667 - val_loss: 1.8019 - val_accuracy: 0.6838\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.8099 - val_accuracy: 0.7265\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2498 - accuracy: 0.8852 - val_loss: 1.8291 - val_accuracy: 0.6923\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.8019 - val_accuracy: 0.6923\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.7909 - val_accuracy: 0.6923\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2445 - accuracy: 0.8704 - val_loss: 1.8019 - val_accuracy: 0.7265\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 646us/step - loss: 0.2490 - accuracy: 0.8704 - val_loss: 1.8108 - val_accuracy: 0.7436\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2449 - accuracy: 0.8704 - val_loss: 1.7678 - val_accuracy: 0.7265\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 429us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.7488 - val_accuracy: 0.7265\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.7707 - val_accuracy: 0.7265\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.8054 - val_accuracy: 0.7265\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.8058 - val_accuracy: 0.7265\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.7940 - val_accuracy: 0.7265\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2464 - accuracy: 0.8630 - val_loss: 1.8227 - val_accuracy: 0.7009\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.7974 - val_accuracy: 0.7265\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.7598 - val_accuracy: 0.7265\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2575 - accuracy: 0.8741 - val_loss: 1.7754 - val_accuracy: 0.7265\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2483 - accuracy: 0.8815 - val_loss: 1.8330 - val_accuracy: 0.6667\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2584 - accuracy: 0.8667 - val_loss: 1.8279 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.7795 - val_accuracy: 0.7265\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.7461 - val_accuracy: 0.7265\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.7514 - val_accuracy: 0.7265\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.7674 - val_accuracy: 0.7265\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.7915 - val_accuracy: 0.7179\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 1.8385 - val_accuracy: 0.6838\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.7997 - val_accuracy: 0.7265\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.7740 - val_accuracy: 0.7179\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.7999 - val_accuracy: 0.7179\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.7871 - val_accuracy: 0.7179\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.7738 - val_accuracy: 0.7179\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.7759 - val_accuracy: 0.7265\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.7815 - val_accuracy: 0.7265\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.7926 - val_accuracy: 0.7265\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2522 - accuracy: 0.8593 - val_loss: 1.7880 - val_accuracy: 0.7265\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2455 - accuracy: 0.8667 - val_loss: 1.8213 - val_accuracy: 0.6752\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.8251 - val_accuracy: 0.7265\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.8165 - val_accuracy: 0.7265\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.8174 - val_accuracy: 0.7265\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.8363 - val_accuracy: 0.6923\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2473 - accuracy: 0.8741 - val_loss: 1.8379 - val_accuracy: 0.6923\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2476 - accuracy: 0.8741 - val_loss: 1.8203 - val_accuracy: 0.7350\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.8034 - val_accuracy: 0.7265\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.8088 - val_accuracy: 0.7265\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 372us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.8166 - val_accuracy: 0.7265\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 1.8281 - val_accuracy: 0.7265\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 1.8044 - val_accuracy: 0.7265\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.7685 - val_accuracy: 0.7265\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 1.8006 - val_accuracy: 0.7265\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2483 - accuracy: 0.8667 - val_loss: 1.8545 - val_accuracy: 0.6752\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.8546 - val_accuracy: 0.6838\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.8358 - val_accuracy: 0.7265\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.8284 - val_accuracy: 0.7265\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.8092 - val_accuracy: 0.7265\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.8304 - val_accuracy: 0.7265\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.8501 - val_accuracy: 0.7436\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2535 - accuracy: 0.8630 - val_loss: 1.8793 - val_accuracy: 0.6923\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2485 - accuracy: 0.8741 - val_loss: 1.8434 - val_accuracy: 0.7179\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2401 - accuracy: 0.8889 - val_loss: 1.8071 - val_accuracy: 0.7265\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.7980 - val_accuracy: 0.7265\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.8160 - val_accuracy: 0.7265\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.8333 - val_accuracy: 0.7265\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.8481 - val_accuracy: 0.7265\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.8271 - val_accuracy: 0.7265\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.8068 - val_accuracy: 0.7265\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2440 - accuracy: 0.8852 - val_loss: 1.7935 - val_accuracy: 0.7350\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.8116 - val_accuracy: 0.6838\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 1.8194 - val_accuracy: 0.6838\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.7995 - val_accuracy: 0.6838\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 72us/step - loss: 0.2393 - accuracy: 0.8889 - val_loss: 1.7902 - val_accuracy: 0.7265\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 1.8067 - val_accuracy: 0.7265\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.8466 - val_accuracy: 0.6752\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2488 - accuracy: 0.8667 - val_loss: 1.8584 - val_accuracy: 0.6752\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2484 - accuracy: 0.8778 - val_loss: 1.8460 - val_accuracy: 0.6752\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.8170 - val_accuracy: 0.7265\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.2448 - accuracy: 0.8704 - val_loss: 1.8156 - val_accuracy: 0.7265\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.7866 - val_accuracy: 0.7265\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2505 - accuracy: 0.8852 - val_loss: 1.7666 - val_accuracy: 0.7265\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.8085 - val_accuracy: 0.7179\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.8983 - val_accuracy: 0.6752\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2515 - accuracy: 0.8667 - val_loss: 1.8256 - val_accuracy: 0.7179\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.7916 - val_accuracy: 0.7265\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2531 - accuracy: 0.8815 - val_loss: 1.8003 - val_accuracy: 0.7265\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2474 - accuracy: 0.8704 - val_loss: 1.8371 - val_accuracy: 0.6838\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.8431 - val_accuracy: 0.6496\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2471 - accuracy: 0.8556 - val_loss: 1.8352 - val_accuracy: 0.6838\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.8542 - val_accuracy: 0.7265\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.8512 - val_accuracy: 0.6838\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.8532 - val_accuracy: 0.6838\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.8520 - val_accuracy: 0.6838\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2444 - accuracy: 0.8593 - val_loss: 1.8354 - val_accuracy: 0.7265\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.8213 - val_accuracy: 0.7265\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 230us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.8413 - val_accuracy: 0.7265\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2469 - accuracy: 0.8704 - val_loss: 1.8842 - val_accuracy: 0.6838\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2486 - accuracy: 0.8741 - val_loss: 1.8555 - val_accuracy: 0.7265\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.8530 - val_accuracy: 0.7265\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.8343 - val_accuracy: 0.7265\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.8344 - val_accuracy: 0.6838\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2456 - accuracy: 0.8630 - val_loss: 1.8875 - val_accuracy: 0.6838\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2519 - accuracy: 0.8630 - val_loss: 1.8596 - val_accuracy: 0.6923\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2478 - accuracy: 0.8704 - val_loss: 1.8190 - val_accuracy: 0.7265\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.8241 - val_accuracy: 0.6923\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2435 - accuracy: 0.8593 - val_loss: 1.8004 - val_accuracy: 0.7350\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 346us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.7847 - val_accuracy: 0.7350\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2472 - accuracy: 0.8667 - val_loss: 1.8266 - val_accuracy: 0.6923\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2504 - accuracy: 0.8704 - val_loss: 1.8420 - val_accuracy: 0.6838\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2449 - accuracy: 0.8667 - val_loss: 1.8329 - val_accuracy: 0.6838\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2413 - accuracy: 0.8889 - val_loss: 1.8184 - val_accuracy: 0.7265\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.8195 - val_accuracy: 0.7265\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2440 - accuracy: 0.8704 - val_loss: 1.8519 - val_accuracy: 0.6838\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.8671 - val_accuracy: 0.6838\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2451 - accuracy: 0.8630 - val_loss: 1.8413 - val_accuracy: 0.7265\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.8342 - val_accuracy: 0.7265\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2432 - accuracy: 0.8889 - val_loss: 1.8499 - val_accuracy: 0.6838\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.8692 - val_accuracy: 0.6752\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.8616 - val_accuracy: 0.7265\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.8525 - val_accuracy: 0.7265\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.8732 - val_accuracy: 0.6838\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2441 - accuracy: 0.8741 - val_loss: 1.8393 - val_accuracy: 0.6752\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2494 - accuracy: 0.8556 - val_loss: 1.8136 - val_accuracy: 0.7265\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 1.8171 - val_accuracy: 0.7265\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.8582 - val_accuracy: 0.7265\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.8775 - val_accuracy: 0.6838\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2448 - accuracy: 0.8667 - val_loss: 1.8967 - val_accuracy: 0.6752\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2472 - accuracy: 0.8630 - val_loss: 1.8561 - val_accuracy: 0.6923\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2480 - accuracy: 0.8667 - val_loss: 1.8299 - val_accuracy: 0.7350\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.8374 - val_accuracy: 0.7350\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2416 - accuracy: 0.8852 - val_loss: 1.8658 - val_accuracy: 0.7265\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 349us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.8686 - val_accuracy: 0.7265\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.8495 - val_accuracy: 0.7265\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.8647 - val_accuracy: 0.6838\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.8878 - val_accuracy: 0.6752\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.8653 - val_accuracy: 0.7265\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.8384 - val_accuracy: 0.7265\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2420 - accuracy: 0.8852 - val_loss: 1.8436 - val_accuracy: 0.6838\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2470 - accuracy: 0.8667 - val_loss: 1.8563 - val_accuracy: 0.6838\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2429 - accuracy: 0.8741 - val_loss: 1.8116 - val_accuracy: 0.7265\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2439 - accuracy: 0.8667 - val_loss: 1.8166 - val_accuracy: 0.7265\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 1.8522 - val_accuracy: 0.6838\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2481 - accuracy: 0.8556 - val_loss: 1.8500 - val_accuracy: 0.6667\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2512 - accuracy: 0.8667 - val_loss: 1.8512 - val_accuracy: 0.6838\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.8325 - val_accuracy: 0.7265\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2545 - accuracy: 0.8815 - val_loss: 1.8312 - val_accuracy: 0.7265\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.8655 - val_accuracy: 0.6923\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2496 - accuracy: 0.8741 - val_loss: 1.8869 - val_accuracy: 0.6752\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2482 - accuracy: 0.8667 - val_loss: 1.8509 - val_accuracy: 0.6838\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.8470 - val_accuracy: 0.7265\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.8750 - val_accuracy: 0.6838\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 268us/step - loss: 0.2491 - accuracy: 0.8741 - val_loss: 1.8482 - val_accuracy: 0.6923\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2491 - accuracy: 0.8593 - val_loss: 1.8125 - val_accuracy: 0.7265\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.8906 - val_accuracy: 0.6838\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2460 - accuracy: 0.8704 - val_loss: 1.9230 - val_accuracy: 0.6581\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 1.8863 - val_accuracy: 0.6838\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3104 - accuracy: 0.81 - 0s 261us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.8808 - val_accuracy: 0.7265\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.8988 - val_accuracy: 0.7265\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2401 - accuracy: 0.8741 - val_loss: 1.9205 - val_accuracy: 0.6838\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2484 - accuracy: 0.8778 - val_loss: 1.9211 - val_accuracy: 0.7265\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.8759 - val_accuracy: 0.7265\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2375 - accuracy: 0.8815 - val_loss: 1.9110 - val_accuracy: 0.6667\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.9510 - val_accuracy: 0.6667\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 1.9290 - val_accuracy: 0.6667\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.8999 - val_accuracy: 0.7265\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 1.8673 - val_accuracy: 0.7265\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.8680 - val_accuracy: 0.7265\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.8828 - val_accuracy: 0.7265\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2458 - accuracy: 0.8630 - val_loss: 1.8926 - val_accuracy: 0.7436\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.8569 - val_accuracy: 0.7436\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 1.8602 - val_accuracy: 0.7265\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2418 - accuracy: 0.8852 - val_loss: 1.8463 - val_accuracy: 0.7350\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.8378 - val_accuracy: 0.7265\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.8516 - val_accuracy: 0.7265\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2427 - accuracy: 0.8852 - val_loss: 1.8924 - val_accuracy: 0.6752\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.9041 - val_accuracy: 0.6752\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 1.8921 - val_accuracy: 0.7179\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2403 - accuracy: 0.8704 - val_loss: 1.8581 - val_accuracy: 0.7265\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.8509 - val_accuracy: 0.7179\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 275us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.8786 - val_accuracy: 0.7265\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2403 - accuracy: 0.8815 - val_loss: 1.8970 - val_accuracy: 0.6838\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.9123 - val_accuracy: 0.6838\n",
      "Epoch 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 66us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 1.9200 - val_accuracy: 0.6838\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.9089 - val_accuracy: 0.7265\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 1.9022 - val_accuracy: 0.7179\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2528 - accuracy: 0.8778 - val_loss: 1.8561 - val_accuracy: 0.7265\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2428 - accuracy: 0.8704 - val_loss: 1.8310 - val_accuracy: 0.7265\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2573 - accuracy: 0.8741 - val_loss: 1.8434 - val_accuracy: 0.7265\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 1.8606 - val_accuracy: 0.7265\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.9083 - val_accuracy: 0.7265\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2489 - accuracy: 0.8741 - val_loss: 1.9135 - val_accuracy: 0.6838\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 273us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.9251 - val_accuracy: 0.6752\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2482 - accuracy: 0.8593 - val_loss: 1.9151 - val_accuracy: 0.6838\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.8716 - val_accuracy: 0.7265\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.8736 - val_accuracy: 0.7179\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.8881 - val_accuracy: 0.7179\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.8765 - val_accuracy: 0.7179\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.8593 - val_accuracy: 0.7265\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.8622 - val_accuracy: 0.7179\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.8699 - val_accuracy: 0.7265\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.8586 - val_accuracy: 0.7265\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.8524 - val_accuracy: 0.7265\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.8594 - val_accuracy: 0.7265\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 1.8931 - val_accuracy: 0.6838\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 1.8669 - val_accuracy: 0.6838\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.8329 - val_accuracy: 0.7265\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.8366 - val_accuracy: 0.7265\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.8697 - val_accuracy: 0.6838\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2489 - accuracy: 0.8741 - val_loss: 1.8964 - val_accuracy: 0.6838\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.9376 - val_accuracy: 0.6838\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2546 - accuracy: 0.8926 - val_loss: 1.8950 - val_accuracy: 0.7265\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.8403 - val_accuracy: 0.7265\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 1.8470 - val_accuracy: 0.7265\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2440 - accuracy: 0.8852 - val_loss: 1.9008 - val_accuracy: 0.7265\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.9389 - val_accuracy: 0.7265\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.9330 - val_accuracy: 0.7009\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2511 - accuracy: 0.8593 - val_loss: 1.9183 - val_accuracy: 0.7009\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2482 - accuracy: 0.8667 - val_loss: 1.8869 - val_accuracy: 0.7265\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2397 - accuracy: 0.8741 - val_loss: 1.8748 - val_accuracy: 0.7265\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.8746 - val_accuracy: 0.7265\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.8797 - val_accuracy: 0.7265\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.8980 - val_accuracy: 0.6838\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.8901 - val_accuracy: 0.6838\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2456 - accuracy: 0.8704 - val_loss: 1.8694 - val_accuracy: 0.7265\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2423 - accuracy: 0.8889 - val_loss: 1.8697 - val_accuracy: 0.7265\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.8906 - val_accuracy: 0.7265\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.8747 - val_accuracy: 0.7265\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.8702 - val_accuracy: 0.7350\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 421us/step - loss: 0.2424 - accuracy: 0.8630 - val_loss: 1.9080 - val_accuracy: 0.6838\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.2494 - accuracy: 0.8667 - val_loss: 1.9119 - val_accuracy: 0.7009\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 344us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.8677 - val_accuracy: 0.7265\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.8496 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.8565 - val_accuracy: 0.7179\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.9083 - val_accuracy: 0.6838\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.9438 - val_accuracy: 0.6838\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 1.8760 - val_accuracy: 0.7265\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.8576 - val_accuracy: 0.7265\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.8711 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2511 - accuracy: 0.8704 - val_loss: 1.9140 - val_accuracy: 0.6838\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.9409 - val_accuracy: 0.6838\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.9463 - val_accuracy: 0.7009\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.96 - 0s 168us/step - loss: 0.2474 - accuracy: 0.8704 - val_loss: 1.9037 - val_accuracy: 0.7436\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 1.8544 - val_accuracy: 0.7265\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2571 - accuracy: 0.8741 - val_loss: 1.8289 - val_accuracy: 0.7265\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2510 - accuracy: 0.8741 - val_loss: 1.8657 - val_accuracy: 0.7265\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 1.9384 - val_accuracy: 0.6838\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 1.9207 - val_accuracy: 0.6838\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2434 - accuracy: 0.8667 - val_loss: 1.9011 - val_accuracy: 0.6838\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2408 - accuracy: 0.8630 - val_loss: 1.8923 - val_accuracy: 0.6838\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.9034 - val_accuracy: 0.6838\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2436 - accuracy: 0.8630 - val_loss: 1.8910 - val_accuracy: 0.6752\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.8998 - val_accuracy: 0.7265\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.9176 - val_accuracy: 0.7265\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 312us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.9024 - val_accuracy: 0.7179\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2427 - accuracy: 0.8852 - val_loss: 1.8706 - val_accuracy: 0.7265\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.8540 - val_accuracy: 0.7265\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.8457 - val_accuracy: 0.7265\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2519 - accuracy: 0.8815 - val_loss: 1.8773 - val_accuracy: 0.7265\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 1.8976 - val_accuracy: 0.7179\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.8854 - val_accuracy: 0.7179\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.8830 - val_accuracy: 0.7265\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2421 - accuracy: 0.8889 - val_loss: 1.9201 - val_accuracy: 0.7265\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.9498 - val_accuracy: 0.7265\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.9444 - val_accuracy: 0.6838\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.9261 - val_accuracy: 0.6838\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.9126 - val_accuracy: 0.6496\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.8975 - val_accuracy: 0.7265\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.9341 - val_accuracy: 0.7265\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2460 - accuracy: 0.8630 - val_loss: 1.9522 - val_accuracy: 0.6667\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.9457 - val_accuracy: 0.7265\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.9538 - val_accuracy: 0.7265\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 353us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.9134 - val_accuracy: 0.7179\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 348us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.8832 - val_accuracy: 0.7179\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 289us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.9033 - val_accuracy: 0.7179\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2405 - accuracy: 0.8815 - val_loss: 1.8975 - val_accuracy: 0.7265\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.8990 - val_accuracy: 0.7179\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.9568 - val_accuracy: 0.6581\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2471 - accuracy: 0.8704 - val_loss: 1.9617 - val_accuracy: 0.6667\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2452 - accuracy: 0.8667 - val_loss: 1.9097 - val_accuracy: 0.7179\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.8991 - val_accuracy: 0.7265\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.8941 - val_accuracy: 0.7265\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.9195 - val_accuracy: 0.7179\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.9283 - val_accuracy: 0.7179\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 1.9103 - val_accuracy: 0.7179\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.8966 - val_accuracy: 0.7179\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.8856 - val_accuracy: 0.7179\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.9169 - val_accuracy: 0.7265\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.9119 - val_accuracy: 0.7265\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.9049 - val_accuracy: 0.7265\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.9523 - val_accuracy: 0.7179\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.9401 - val_accuracy: 0.7265\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.9194 - val_accuracy: 0.7265\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.9200 - val_accuracy: 0.7179\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.9457 - val_accuracy: 0.7265\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.76 - 0s 89us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 1.9463 - val_accuracy: 0.7436\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2534 - accuracy: 0.8741 - val_loss: 1.9476 - val_accuracy: 0.7436\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.9390 - val_accuracy: 0.7350\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.9359 - val_accuracy: 0.7179\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.9272 - val_accuracy: 0.7179\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.9416 - val_accuracy: 0.7179\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.9195 - val_accuracy: 0.7179\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.9148 - val_accuracy: 0.7179\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.9170 - val_accuracy: 0.7265\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.9099 - val_accuracy: 0.7179\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.9497 - val_accuracy: 0.7265\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2469 - accuracy: 0.8593 - val_loss: 1.9546 - val_accuracy: 0.7265\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.9231 - val_accuracy: 0.7265\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.9160 - val_accuracy: 0.7265\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2446 - accuracy: 0.8741 - val_loss: 1.9657 - val_accuracy: 0.7265\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.9768 - val_accuracy: 0.7265\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2442 - accuracy: 0.8852 - val_loss: 1.9388 - val_accuracy: 0.7265\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.9590 - val_accuracy: 0.6838\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.9427 - val_accuracy: 0.7179\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.9117 - val_accuracy: 0.7265\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.9176 - val_accuracy: 0.7265\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.9316 - val_accuracy: 0.7265\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 1.9293 - val_accuracy: 0.7265\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.9646 - val_accuracy: 0.6667\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 1.9499 - val_accuracy: 0.6838\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2456 - accuracy: 0.8667 - val_loss: 1.9384 - val_accuracy: 0.7265\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.9486 - val_accuracy: 0.7265\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.9352 - val_accuracy: 0.7265\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.9431 - val_accuracy: 0.7265\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.9311 - val_accuracy: 0.7265\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.9308 - val_accuracy: 0.7265\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 1.9494 - val_accuracy: 0.7265\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.9546 - val_accuracy: 0.7179\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.9698 - val_accuracy: 0.7265\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.9732 - val_accuracy: 0.7265\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.9558 - val_accuracy: 0.7179\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2448 - accuracy: 0.8704 - val_loss: 1.9512 - val_accuracy: 0.7350\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2496 - accuracy: 0.8704 - val_loss: 1.9732 - val_accuracy: 0.6923\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2476 - accuracy: 0.8704 - val_loss: 1.9369 - val_accuracy: 0.7179\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 1.9228 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.9461 - val_accuracy: 0.7179\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 2.0023 - val_accuracy: 0.6581\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2492 - accuracy: 0.8667 - val_loss: 2.0212 - val_accuracy: 0.6581\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.9833 - val_accuracy: 0.6838\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.9495 - val_accuracy: 0.7179\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.9380 - val_accuracy: 0.7179\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.9453 - val_accuracy: 0.7179\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.9651 - val_accuracy: 0.7179\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.9801 - val_accuracy: 0.6923\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 1.9580 - val_accuracy: 0.7350\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.9441 - val_accuracy: 0.7265\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.9255 - val_accuracy: 0.7265\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.9274 - val_accuracy: 0.7179\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.9385 - val_accuracy: 0.7265\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 203us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.9764 - val_accuracy: 0.7265\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.9914 - val_accuracy: 0.7265\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.9809 - val_accuracy: 0.7265\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.9937 - val_accuracy: 0.6838\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2412 - accuracy: 0.8852 - val_loss: 1.9996 - val_accuracy: 0.6838\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.9978 - val_accuracy: 0.6838\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2402 - accuracy: 0.8852 - val_loss: 1.9647 - val_accuracy: 0.7265\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.9543 - val_accuracy: 0.7265\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2459 - accuracy: 0.8852 - val_loss: 1.9439 - val_accuracy: 0.7265\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 1.9316 - val_accuracy: 0.7265\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.9389 - val_accuracy: 0.7350\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.9631 - val_accuracy: 0.7265\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.9657 - val_accuracy: 0.7265\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.9987 - val_accuracy: 0.7265\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2441 - accuracy: 0.8852 - val_loss: 1.9976 - val_accuracy: 0.6923\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2457 - accuracy: 0.8704 - val_loss: 2.0178 - val_accuracy: 0.6667\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2477 - accuracy: 0.8704 - val_loss: 1.9979 - val_accuracy: 0.6923\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 1.9632 - val_accuracy: 0.7350\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.9393 - val_accuracy: 0.7265\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.9521 - val_accuracy: 0.7350\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2412 - accuracy: 0.8667 - val_loss: 1.9815 - val_accuracy: 0.7265\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2445 - accuracy: 0.8704 - val_loss: 1.9926 - val_accuracy: 0.6838\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.9844 - val_accuracy: 0.7350\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2391 - accuracy: 0.8778 - val_loss: 1.9762 - val_accuracy: 0.7265\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.9788 - val_accuracy: 0.7265\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2439 - accuracy: 0.8630 - val_loss: 1.9933 - val_accuracy: 0.7350\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.9931 - val_accuracy: 0.7350\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2405 - accuracy: 0.8963 - val_loss: 2.0003 - val_accuracy: 0.7265\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 2.0510 - val_accuracy: 0.7265\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 2.0427 - val_accuracy: 0.7265\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2527 - accuracy: 0.8704 - val_loss: 2.0333 - val_accuracy: 0.6667\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 327us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 2.0164 - val_accuracy: 0.6838\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 2.0054 - val_accuracy: 0.7265\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 269us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 2.0263 - val_accuracy: 0.6838\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.2428 - accuracy: 0.8704 - val_loss: 1.9961 - val_accuracy: 0.7265\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.9961 - val_accuracy: 0.7265\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 348us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.9872 - val_accuracy: 0.7265\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 295us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.9766 - val_accuracy: 0.7265\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 2.0043 - val_accuracy: 0.7265\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 2.0419 - val_accuracy: 0.6923\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2496 - accuracy: 0.8704 - val_loss: 2.0374 - val_accuracy: 0.7350\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.9961 - val_accuracy: 0.7265\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.9875 - val_accuracy: 0.7265\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2469 - accuracy: 0.8667 - val_loss: 2.0614 - val_accuracy: 0.6581\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2472 - accuracy: 0.8704 - val_loss: 2.0306 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2482 - accuracy: 0.8704 - val_loss: 1.9887 - val_accuracy: 0.7265\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2499 - accuracy: 0.8741 - val_loss: 1.9883 - val_accuracy: 0.7265\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2484 - accuracy: 0.8815 - val_loss: 2.0156 - val_accuracy: 0.7265\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 2.0741 - val_accuracy: 0.6667\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 2.0710 - val_accuracy: 0.6667\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 2.0193 - val_accuracy: 0.6838\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.9886 - val_accuracy: 0.7265\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.9651 - val_accuracy: 0.7265\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.9539 - val_accuracy: 0.7265\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2510 - accuracy: 0.8741 - val_loss: 1.9881 - val_accuracy: 0.7265\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 2.0141 - val_accuracy: 0.7265\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2533 - accuracy: 0.8704 - val_loss: 2.0600 - val_accuracy: 0.6752\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2487 - accuracy: 0.8667 - val_loss: 1.9999 - val_accuracy: 0.7350\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2426 - accuracy: 0.8667 - val_loss: 1.9759 - val_accuracy: 0.7265\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.9774 - val_accuracy: 0.7265\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.9768 - val_accuracy: 0.7265\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.9783 - val_accuracy: 0.7265\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.9802 - val_accuracy: 0.7265\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.9711 - val_accuracy: 0.7265\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 2.0052 - val_accuracy: 0.7265\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 2.0239 - val_accuracy: 0.6838\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2448 - accuracy: 0.8556 - val_loss: 2.0032 - val_accuracy: 0.6496\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2467 - accuracy: 0.8704 - val_loss: 1.9910 - val_accuracy: 0.7350\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2457 - accuracy: 0.8667 - val_loss: 2.0156 - val_accuracy: 0.7265\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 2.0206 - val_accuracy: 0.7265\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 2.0099 - val_accuracy: 0.7265\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 2.0073 - val_accuracy: 0.7350\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2394 - accuracy: 0.8852 - val_loss: 2.0241 - val_accuracy: 0.7265\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 2.0349 - val_accuracy: 0.7265\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 2.0017 - val_accuracy: 0.7265\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 2.0087 - val_accuracy: 0.7350\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 2.0312 - val_accuracy: 0.6838\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 2.0364 - val_accuracy: 0.6838\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2451 - accuracy: 0.8630 - val_loss: 2.0253 - val_accuracy: 0.7265\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.9850 - val_accuracy: 0.7265\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 2.0020 - val_accuracy: 0.7350\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 2.0191 - val_accuracy: 0.7265\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 2.0163 - val_accuracy: 0.7265\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.84 - 0s 80us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 2.0043 - val_accuracy: 0.7265\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 2.0480 - val_accuracy: 0.6838\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 2.0663 - val_accuracy: 0.6838\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 2.0106 - val_accuracy: 0.7265\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.9807 - val_accuracy: 0.7265\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 1.9984 - val_accuracy: 0.7265\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 2.0264 - val_accuracy: 0.7265\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2511 - accuracy: 0.8815 - val_loss: 2.0635 - val_accuracy: 0.7265\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2510 - accuracy: 0.8667 - val_loss: 2.0636 - val_accuracy: 0.6838\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 2.0399 - val_accuracy: 0.6838\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 2.0102 - val_accuracy: 0.7265\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 2.0210 - val_accuracy: 0.7265\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 2.0370 - val_accuracy: 0.7179\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 2.0445 - val_accuracy: 0.7265\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 2.0216 - val_accuracy: 0.7265\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 2.0294 - val_accuracy: 0.7265\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 2.0208 - val_accuracy: 0.6838\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.9908 - val_accuracy: 0.7265\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 2.0016 - val_accuracy: 0.7265\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 229us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.9953 - val_accuracy: 0.7179\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 2.0013 - val_accuracy: 0.7265\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 589us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 2.0593 - val_accuracy: 0.7265\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 2.0375 - val_accuracy: 0.7265\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 2.0285 - val_accuracy: 0.7179\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 2.0300 - val_accuracy: 0.6838\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 2.0305 - val_accuracy: 0.7265\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 2.0698 - val_accuracy: 0.7265\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 154us/step - loss: 0.2551 - accuracy: 0.8815 - val_loss: 2.0837 - val_accuracy: 0.7265\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 2.0467 - val_accuracy: 0.7265\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 2.0041 - val_accuracy: 0.7265\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 2.0152 - val_accuracy: 0.7265\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 2.0325 - val_accuracy: 0.7265\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 2.0682 - val_accuracy: 0.6838\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 2.0677 - val_accuracy: 0.6838\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2501 - accuracy: 0.8667 - val_loss: 2.0484 - val_accuracy: 0.6325\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2481 - accuracy: 0.8667 - val_loss: 1.9939 - val_accuracy: 0.6496\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2528 - accuracy: 0.8667 - val_loss: 1.9764 - val_accuracy: 0.7265\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2543 - accuracy: 0.8815 - val_loss: 2.0028 - val_accuracy: 0.7265\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 2.0347 - val_accuracy: 0.7265\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 2.0477 - val_accuracy: 0.7265\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 2.0456 - val_accuracy: 0.7265\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 2.0518 - val_accuracy: 0.7265\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 2.0438 - val_accuracy: 0.7265\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 2.0499 - val_accuracy: 0.7265\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 2.0762 - val_accuracy: 0.7265\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2439 - accuracy: 0.8556 - val_loss: 2.0862 - val_accuracy: 0.6838\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 2.0568 - val_accuracy: 0.7265\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 2.0371 - val_accuracy: 0.7265\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 2.0324 - val_accuracy: 0.7265\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 2.0376 - val_accuracy: 0.7265\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 2.0922 - val_accuracy: 0.6923\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2544 - accuracy: 0.8667 - val_loss: 2.0999 - val_accuracy: 0.6923\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2502 - accuracy: 0.8667 - val_loss: 2.0482 - val_accuracy: 0.7179\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 2.0052 - val_accuracy: 0.7265\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2524 - accuracy: 0.8815 - val_loss: 2.0103 - val_accuracy: 0.7265\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 2.0628 - val_accuracy: 0.7350\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2460 - accuracy: 0.8630 - val_loss: 2.0842 - val_accuracy: 0.6838\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2419 - accuracy: 0.8667 - val_loss: 2.0652 - val_accuracy: 0.7265\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 2.0548 - val_accuracy: 0.7265\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 2.0392 - val_accuracy: 0.7265\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 2.0320 - val_accuracy: 0.7265\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 2.0533 - val_accuracy: 0.7265\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 2.0807 - val_accuracy: 0.7265\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 2.0895 - val_accuracy: 0.6838\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 2.1061 - val_accuracy: 0.6838\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 2.0837 - val_accuracy: 0.6838\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 2.0676 - val_accuracy: 0.7265\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 2.0548 - val_accuracy: 0.7350\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2452 - accuracy: 0.8667 - val_loss: 2.0568 - val_accuracy: 0.6496\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2468 - accuracy: 0.8667 - val_loss: 2.0916 - val_accuracy: 0.6923\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2425 - accuracy: 0.8667 - val_loss: 2.1213 - val_accuracy: 0.6752\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 2.1235 - val_accuracy: 0.6752\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 2.1183 - val_accuracy: 0.6581\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2488 - accuracy: 0.8630 - val_loss: 2.0706 - val_accuracy: 0.7265\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 2.0649 - val_accuracy: 0.7265\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 2.1074 - val_accuracy: 0.7179\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 2.0839 - val_accuracy: 0.7265\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2387 - accuracy: 0.8778 - val_loss: 2.0604 - val_accuracy: 0.7265\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 2.0683 - val_accuracy: 0.7265\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 260us/step - loss: 0.2482 - accuracy: 0.8630 - val_loss: 2.0810 - val_accuracy: 0.6838\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 2.0695 - val_accuracy: 0.7350\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 2.0666 - val_accuracy: 0.7265\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 2.0672 - val_accuracy: 0.7265\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 2.0583 - val_accuracy: 0.7265\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 2.0589 - val_accuracy: 0.7265\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 2.0615 - val_accuracy: 0.7265\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2440 - accuracy: 0.8704 - val_loss: 2.0932 - val_accuracy: 0.7265\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2457 - accuracy: 0.8593 - val_loss: 2.0859 - val_accuracy: 0.7350\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 2.0478 - val_accuracy: 0.7265\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 2.0469 - val_accuracy: 0.7265\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 2.0699 - val_accuracy: 0.7265\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 2.0979 - val_accuracy: 0.6838\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 2.0764 - val_accuracy: 0.6838\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2457 - accuracy: 0.8704 - val_loss: 2.0485 - val_accuracy: 0.7265\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 2.0655 - val_accuracy: 0.7265\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 2.0739 - val_accuracy: 0.7265\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 2.1052 - val_accuracy: 0.7265\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.89 - 0s 70us/step - loss: 0.2479 - accuracy: 0.8815 - val_loss: 2.1369 - val_accuracy: 0.6838\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 2.1108 - val_accuracy: 0.6838\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 2.0694 - val_accuracy: 0.7265\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 2.0654 - val_accuracy: 0.7265\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2464 - accuracy: 0.8704 - val_loss: 2.0869 - val_accuracy: 0.7265\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2479 - accuracy: 0.8815 - val_loss: 2.1231 - val_accuracy: 0.7265\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 2.1498 - val_accuracy: 0.6752\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 248us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 2.1289 - val_accuracy: 0.6838\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 2.1179 - val_accuracy: 0.6838\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 2.1164 - val_accuracy: 0.6838\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 2.1553 - val_accuracy: 0.6581\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2503 - accuracy: 0.8741 - val_loss: 2.1994 - val_accuracy: 0.6581\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 2.1377 - val_accuracy: 0.6581\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2453 - accuracy: 0.8741 - val_loss: 2.0934 - val_accuracy: 0.7265\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 2.0823 - val_accuracy: 0.7179\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 2.0943 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 2.0785 - val_accuracy: 0.7265\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 2.0771 - val_accuracy: 0.7265\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 2.0712 - val_accuracy: 0.7350\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 2.0707 - val_accuracy: 0.7265\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2431 - accuracy: 0.8852 - val_loss: 2.1021 - val_accuracy: 0.6838\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 2.1093 - val_accuracy: 0.7265\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 2.0927 - val_accuracy: 0.7265\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 2.0747 - val_accuracy: 0.7265\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 2.0852 - val_accuracy: 0.7265\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 2.1153 - val_accuracy: 0.6838\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2442 - accuracy: 0.8667 - val_loss: 2.1282 - val_accuracy: 0.6667\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2443 - accuracy: 0.8630 - val_loss: 2.1040 - val_accuracy: 0.7265\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 2.0545 - val_accuracy: 0.7265\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 2.0622 - val_accuracy: 0.7265\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 2.0824 - val_accuracy: 0.7265\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 2.0711 - val_accuracy: 0.7265\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2450 - accuracy: 0.8667 - val_loss: 2.0539 - val_accuracy: 0.7265\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2447 - accuracy: 0.8704 - val_loss: 2.0618 - val_accuracy: 0.7265\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2458 - accuracy: 0.8667 - val_loss: 2.0928 - val_accuracy: 0.6667\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2450 - accuracy: 0.8667 - val_loss: 2.1026 - val_accuracy: 0.6838\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 2.0831 - val_accuracy: 0.7265\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 2.1019 - val_accuracy: 0.7265\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 2.1320 - val_accuracy: 0.6581\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2422 - accuracy: 0.8667 - val_loss: 2.1112 - val_accuracy: 0.6752\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 80us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 2.0712 - val_accuracy: 0.7265\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 2.0988 - val_accuracy: 0.7265\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 2.1106 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 2.0987 - val_accuracy: 0.7265\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2451 - accuracy: 0.8741 - val_loss: 2.0956 - val_accuracy: 0.7265\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 2.0971 - val_accuracy: 0.7265\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 2.0976 - val_accuracy: 0.7265\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 2.1305 - val_accuracy: 0.7179\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 2.1725 - val_accuracy: 0.7094\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.90 - 0s 144us/step - loss: 0.2455 - accuracy: 0.8667 - val_loss: 2.1469 - val_accuracy: 0.7265\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 2.1321 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 329us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 2.1509 - val_accuracy: 0.7265\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 2.1728 - val_accuracy: 0.7179\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 2.1546 - val_accuracy: 0.7265\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 2.1459 - val_accuracy: 0.7265\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 2.1625 - val_accuracy: 0.6838\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2451 - accuracy: 0.8704 - val_loss: 2.1357 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 2.1293 - val_accuracy: 0.7179\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 2.1330 - val_accuracy: 0.7265\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 2.1492 - val_accuracy: 0.7265\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 2.1918 - val_accuracy: 0.6752\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2504 - accuracy: 0.8667 - val_loss: 2.1945 - val_accuracy: 0.6923\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2466 - accuracy: 0.8630 - val_loss: 2.1288 - val_accuracy: 0.7265\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2444 - accuracy: 0.8926 - val_loss: 2.1009 - val_accuracy: 0.7350\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 2.1266 - val_accuracy: 0.6923\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 2.1676 - val_accuracy: 0.6838\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2523 - accuracy: 0.8778 - val_loss: 2.1633 - val_accuracy: 0.6838\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2517 - accuracy: 0.8815 - val_loss: 2.1020 - val_accuracy: 0.7265\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 2.1000 - val_accuracy: 0.7265\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 2.1216 - val_accuracy: 0.7265\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 2.1295 - val_accuracy: 0.6838\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 2.1286 - val_accuracy: 0.6838\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2455 - accuracy: 0.8556 - val_loss: 2.1266 - val_accuracy: 0.7265\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 2.1272 - val_accuracy: 0.7265\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2449 - accuracy: 0.8630 - val_loss: 2.1644 - val_accuracy: 0.6838\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 2.2009 - val_accuracy: 0.6752\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 2.2043 - val_accuracy: 0.7179\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 2.1797 - val_accuracy: 0.7179\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 2.1625 - val_accuracy: 0.7179\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 2.1532 - val_accuracy: 0.7179\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 2.1569 - val_accuracy: 0.7179\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 2.1691 - val_accuracy: 0.7094\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 2.1971 - val_accuracy: 0.6752\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 2.1985 - val_accuracy: 0.6752\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2468 - accuracy: 0.8704 - val_loss: 2.1759 - val_accuracy: 0.6752\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 2.1677 - val_accuracy: 0.6752\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2405 - accuracy: 0.8815 - val_loss: 2.1680 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 2.1817 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2536 - accuracy: 0.8815 - val_loss: 2.1605 - val_accuracy: 0.7265\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2568 - accuracy: 0.8741 - val_loss: 2.1693 - val_accuracy: 0.7265\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2510 - accuracy: 0.8630 - val_loss: 2.2435 - val_accuracy: 0.6581\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2493 - accuracy: 0.8704 - val_loss: 2.2302 - val_accuracy: 0.6581\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 2.1560 - val_accuracy: 0.7179\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 2.1263 - val_accuracy: 0.7179\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 2.1150 - val_accuracy: 0.7179\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 2.1591 - val_accuracy: 0.7094\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2467 - accuracy: 0.8667 - val_loss: 2.1789 - val_accuracy: 0.7265\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 2.1814 - val_accuracy: 0.7094\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 2.1704 - val_accuracy: 0.7094\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 2.1490 - val_accuracy: 0.7179\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 2.1490 - val_accuracy: 0.7265\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 2.1520 - val_accuracy: 0.7179\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2409 - accuracy: 0.8852 - val_loss: 2.1711 - val_accuracy: 0.7265\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 2.2255 - val_accuracy: 0.6752\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2532 - accuracy: 0.8667 - val_loss: 2.2075 - val_accuracy: 0.6667\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 2.1696 - val_accuracy: 0.6838\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2417 - accuracy: 0.8704 - val_loss: 2.1448 - val_accuracy: 0.7179\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 2.1590 - val_accuracy: 0.7265\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 2.1573 - val_accuracy: 0.7265\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 2.1835 - val_accuracy: 0.7265\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 2.2352 - val_accuracy: 0.6581\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2492 - accuracy: 0.8667 - val_loss: 2.2366 - val_accuracy: 0.6581\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 2.1848 - val_accuracy: 0.7265\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 2.1603 - val_accuracy: 0.7265\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 2.1885 - val_accuracy: 0.7265\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 2.2307 - val_accuracy: 0.6752\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 2.2106 - val_accuracy: 0.6838\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 2.1724 - val_accuracy: 0.7350\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 2.1540 - val_accuracy: 0.7350\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 2.1637 - val_accuracy: 0.7265\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 2.1398 - val_accuracy: 0.7265\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 2.1703 - val_accuracy: 0.7265\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2520 - accuracy: 0.8815 - val_loss: 2.1912 - val_accuracy: 0.7265\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 2.2133 - val_accuracy: 0.6838\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2439 - accuracy: 0.8593 - val_loss: 2.1982 - val_accuracy: 0.6923\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2411 - accuracy: 0.8704 - val_loss: 2.1748 - val_accuracy: 0.7350\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 2.1948 - val_accuracy: 0.6838\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 2.2302 - val_accuracy: 0.6752\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 2.2229 - val_accuracy: 0.6752\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 2.2150 - val_accuracy: 0.6752\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 2.1630 - val_accuracy: 0.7265\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 2.1415 - val_accuracy: 0.7350\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 2.1536 - val_accuracy: 0.7265\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 2.1721 - val_accuracy: 0.7265\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 2.1885 - val_accuracy: 0.7265\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2397 - accuracy: 0.8741 - val_loss: 2.2309 - val_accuracy: 0.6838\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2436 - accuracy: 0.8704 - val_loss: 2.2458 - val_accuracy: 0.6752\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 2.2121 - val_accuracy: 0.7265\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2404 - accuracy: 0.8852 - val_loss: 2.1746 - val_accuracy: 0.7265\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 2.1586 - val_accuracy: 0.7265\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 2.1842 - val_accuracy: 0.7179\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2456 - accuracy: 0.8704 - val_loss: 2.1990 - val_accuracy: 0.7436\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2445 - accuracy: 0.8704 - val_loss: 2.2078 - val_accuracy: 0.7436\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2441 - accuracy: 0.8630 - val_loss: 2.2004 - val_accuracy: 0.7094\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2403 - accuracy: 0.8815 - val_loss: 2.1696 - val_accuracy: 0.7265\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 2.1548 - val_accuracy: 0.7179\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2478 - accuracy: 0.8630 - val_loss: 2.1866 - val_accuracy: 0.6838\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 2.2298 - val_accuracy: 0.6496\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 2.2296 - val_accuracy: 0.6752\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2530 - accuracy: 0.8630 - val_loss: 2.1911 - val_accuracy: 0.7265\n",
      "Epoch 996/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 106us/step - loss: 0.2511 - accuracy: 0.8815 - val_loss: 2.1962 - val_accuracy: 0.7265\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 2.2082 - val_accuracy: 0.7265\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2489 - accuracy: 0.8481 - val_loss: 2.2088 - val_accuracy: 0.6496\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 2.2094 - val_accuracy: 0.7265\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 2.2115 - val_accuracy: 0.7265\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 87.63%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27998140e-01, 8.66424000e-01, 5.57785340e-03],\n",
       "       [9.90138300e-01, 9.75554800e-03, 1.06088126e-04],\n",
       "       [7.59889660e-01, 2.40011300e-01, 9.89652900e-05],\n",
       "       [6.56236100e-05, 3.84952150e-04, 9.99549450e-01],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [1.00000000e+00, 1.19036870e-11, 1.36924656e-11],\n",
       "       [8.18993100e-11, 1.04420610e-11, 1.00000000e+00],\n",
       "       [9.99537940e-01, 4.62038150e-04, 5.37932000e-10],\n",
       "       [1.45181120e-01, 1.13316300e-01, 7.41502500e-01],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [9.92524800e-01, 7.43914160e-03, 3.60887900e-05],\n",
       "       [6.19076200e-04, 3.13929620e-01, 6.85451300e-01],\n",
       "       [1.45181120e-01, 1.13316300e-01, 7.41502500e-01],\n",
       "       [9.09975850e-04, 9.99086600e-01, 3.47870420e-06],\n",
       "       [3.20201500e-04, 9.99228100e-01, 4.51702100e-04],\n",
       "       [5.00588700e-08, 1.13294950e-01, 8.86705000e-01],\n",
       "       [5.95785150e-15, 1.28512440e-13, 1.00000000e+00],\n",
       "       [3.50018400e-07, 1.60826140e-06, 9.99998100e-01],\n",
       "       [9.99964100e-01, 3.52616440e-05, 5.51519400e-07],\n",
       "       [3.84990330e-04, 9.98349100e-01, 1.26588680e-03],\n",
       "       [7.78127750e-04, 6.93448200e-01, 3.05773700e-01],\n",
       "       [1.45181120e-01, 1.13316300e-01, 7.41502500e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [1.48768980e-03, 6.76731700e-01, 3.21780620e-01],\n",
       "       [9.93034500e-01, 6.96509500e-03, 4.56596500e-07],\n",
       "       [4.47775060e-05, 1.45189010e-04, 9.99810040e-01],\n",
       "       [4.90313100e-04, 5.69755140e-06, 9.99503970e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [8.41618000e-10, 1.03062050e-07, 9.99999900e-01],\n",
       "       [2.06565760e-10, 1.01449180e-05, 9.99989870e-01],\n",
       "       [1.83870390e-04, 9.94687700e-01, 5.12842300e-03],\n",
       "       [9.99928100e-01, 4.34756900e-05, 2.83611080e-05],\n",
       "       [5.31446500e-07, 9.96579350e-01, 3.42015300e-03],\n",
       "       [1.36285940e-06, 5.52951500e-05, 9.99943400e-01],\n",
       "       [3.49564540e-06, 3.51985340e-07, 9.99996200e-01],\n",
       "       [1.48768980e-03, 6.76731700e-01, 3.21780620e-01],\n",
       "       [9.99928100e-01, 4.34756900e-05, 2.83611080e-05],\n",
       "       [2.59264800e-01, 7.07911500e-01, 3.28237080e-02],\n",
       "       [1.42712080e-02, 9.81236460e-01, 4.49238070e-03],\n",
       "       [2.84142400e-07, 9.99991660e-01, 8.10614900e-06],\n",
       "       [1.83432380e-06, 6.70331100e-04, 9.99327900e-01],\n",
       "       [1.00000000e+00, 1.08445630e-09, 3.45869550e-13],\n",
       "       [9.90559340e-01, 9.35097300e-03, 8.96847900e-05],\n",
       "       [2.81805340e-02, 9.70622960e-01, 1.19658220e-03],\n",
       "       [3.80733360e-10, 6.01527400e-04, 9.99398470e-01],\n",
       "       [1.00000000e+00, 2.16157580e-08, 1.39923400e-17],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [9.95399400e-01, 4.55023900e-03, 5.02719200e-05],\n",
       "       [1.48768980e-03, 6.76731700e-01, 3.21780620e-01],\n",
       "       [9.99956370e-01, 4.34505160e-05, 1.34760480e-07],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [1.81914160e-02, 9.81284560e-01, 5.24113600e-04],\n",
       "       [3.37265300e-05, 2.40195430e-02, 9.75946800e-01],\n",
       "       [1.27998140e-01, 8.66424000e-01, 5.57785340e-03],\n",
       "       [9.99814330e-01, 1.85664090e-04, 2.51220950e-08],\n",
       "       [8.35427500e-01, 1.63436200e-01, 1.13624510e-03],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [1.36285940e-06, 5.52951500e-05, 9.99943400e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [3.40446860e-01, 6.49666400e-01, 9.88668400e-03],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [8.18993100e-11, 1.04420610e-11, 1.00000000e+00],\n",
       "       [5.31446500e-07, 9.96579350e-01, 3.42015300e-03],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [7.78127750e-04, 6.93448200e-01, 3.05773700e-01],\n",
       "       [1.73610800e-05, 3.31936660e-03, 9.96663300e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [1.23817350e-08, 2.92845200e-05, 9.99970700e-01],\n",
       "       [3.87327080e-04, 3.92384550e-03, 9.95688860e-01],\n",
       "       [2.81805340e-02, 9.70622960e-01, 1.19658220e-03],\n",
       "       [8.18993100e-11, 1.04420610e-11, 1.00000000e+00],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [3.49564540e-06, 3.51985340e-07, 9.99996200e-01],\n",
       "       [8.02763740e-04, 9.99197200e-01, 1.34628120e-07],\n",
       "       [3.84990330e-04, 9.98349100e-01, 1.26588680e-03],\n",
       "       [1.73610800e-05, 3.31936660e-03, 9.96663300e-01],\n",
       "       [7.39056100e-12, 6.60955930e-12, 1.00000000e+00],\n",
       "       [9.98302100e-01, 1.69788230e-03, 4.55761350e-13],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [1.48768980e-03, 6.76731700e-01, 3.21780620e-01],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [9.99592960e-01, 3.82021880e-04, 2.49916320e-05],\n",
       "       [5.00588700e-08, 1.13294950e-01, 8.86705000e-01],\n",
       "       [3.51292140e-04, 4.99227800e-03, 9.94656440e-01],\n",
       "       [9.64729000e-01, 8.95299500e-03, 2.63179540e-02],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [2.06565760e-10, 1.01449180e-05, 9.99989870e-01],\n",
       "       [3.42450440e-08, 3.11066450e-11, 1.00000000e+00],\n",
       "       [1.07575680e-06, 6.72580460e-11, 9.99998900e-01],\n",
       "       [1.36285940e-06, 5.52951500e-05, 9.99943400e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [8.67717400e-03, 5.05776800e-03, 9.86265000e-01],\n",
       "       [8.13132900e-07, 3.01655720e-06, 9.99996200e-01],\n",
       "       [1.73610800e-05, 3.31936660e-03, 9.96663300e-01],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [3.25551450e-01, 5.76093100e-01, 9.83555600e-02],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [8.20758800e-05, 9.99780830e-01, 1.37083520e-04],\n",
       "       [1.83432380e-06, 6.70331100e-04, 9.99327900e-01],\n",
       "       [6.36733700e-06, 2.38880720e-03, 9.97604850e-01],\n",
       "       [1.87982170e-01, 4.91666530e-01, 3.20351200e-01],\n",
       "       [1.05035240e-06, 9.99757100e-01, 2.41872350e-04],\n",
       "       [3.51292140e-04, 4.99227800e-03, 9.94656440e-01],\n",
       "       [8.20758800e-05, 9.99780830e-01, 1.37083520e-04],\n",
       "       [9.99995000e-01, 5.05270700e-06, 2.91898720e-18],\n",
       "       [5.00588700e-08, 1.13294950e-01, 8.86705000e-01],\n",
       "       [5.52335600e-04, 9.51094870e-01, 4.83528080e-02],\n",
       "       [2.81805340e-02, 9.70622960e-01, 1.19658220e-03],\n",
       "       [1.00000000e+00, 1.95545620e-08, 2.94649580e-10],\n",
       "       [8.92065800e-05, 9.99836560e-01, 7.42724900e-05],\n",
       "       [9.99644040e-01, 3.55957950e-04, 7.03238900e-14],\n",
       "       [1.75125590e-05, 9.99982500e-01, 3.21214880e-08],\n",
       "       [1.07575680e-06, 6.72580460e-11, 9.99998900e-01],\n",
       "       [6.56236100e-05, 3.84952150e-04, 9.99549450e-01],\n",
       "       [1.73610800e-05, 3.31936660e-03, 9.96663300e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474687705456937"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474687705456937"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685897435897436"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015545149319474582"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8685897435897436"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015545149319474582"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 72.01%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.027941658229038786\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 88.18%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.008183083\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X_over[:,1:], y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features_over = np.vstack((names, X_over[:,1:]))\n",
    "X_train_features_over = pd.DataFrame(X_train_features_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 94\n",
      "selected features: 61\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features_over.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features_over.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12, 13, 15, 16, 17, 18,\n",
       "        20, 21, 22, 23, 24, 25, 27, 29, 31, 32, 34, 38, 40, 41, 42, 45,\n",
       "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
       "        64, 67, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTAATTTAATAGA', 'TTAACATAATAAT', 'TGCAATCTCTTTAT',\n",
       "       'TATTATGTTAATG', 'TACATACCGAT', 'GTGTATCATAAT', 'GCTGTTGAAATGGC',\n",
       "       'GAGTCCTGTT', 'GAGTCCTGTTT',\n",
       "       'GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG',\n",
       "       'CTTTTTCACCTGT', 'CTTGTGAATTTAG', 'CGCCATTATGTT', 'CAGAAAAGCGT',\n",
       "       'ACAATTACTATATTT', 'X1_102334_C_T', 'X1_143918_T_C',\n",
       "       'X1_144092_A_G', 'X1_144113_T_C', 'X1_238886_T_C', 'X1_287706_A_G',\n",
       "       'X1_327716_C_T', 'X1_449085_T_A', 'X1_569187_A_G', 'X1_655318_C_T',\n",
       "       'X1_655324_T_C', 'X1_655369_T_A', 'X1_698337_T_C', 'X1_791797_A_T',\n",
       "       'X1_810661_T_C', 'X1_829088_C_T', 'kdpA', 'group_5991',\n",
       "       'group_3022', 'sdrE_1', 'group_1251', 'group_482', 'group_6857',\n",
       "       'group_1087', 'group_2822', 'group_1748', 'clpA', 'group_3572',\n",
       "       'group_3937', 'group_1320', 'group_34', 'dus_1', 'group_9051',\n",
       "       'group_6900', 'group_7995', 'group_11094', 'group_7803',\n",
       "       'group_870', 'group_465', 'group_2236', 'group_7824', 'group_7845',\n",
       "       'group_10140', 'group_10143', 'group_7172', 'group_9586'],\n",
       "      dtype='<U99')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTAATTTAATAGA</th>\n",
       "      <th>TTAACATAATAAT</th>\n",
       "      <th>TGCAATCTCTTTAT</th>\n",
       "      <th>TATTATGTTAATG</th>\n",
       "      <th>TACATACCGAT</th>\n",
       "      <th>GTGTATCATAAT</th>\n",
       "      <th>GCTGTTGAAATGGC</th>\n",
       "      <th>GAGTCCTGTT</th>\n",
       "      <th>GAGTCCTGTTT</th>\n",
       "      <th>GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG</th>\n",
       "      <th>...</th>\n",
       "      <th>group_465</th>\n",
       "      <th>group_2236</th>\n",
       "      <th>group_7824</th>\n",
       "      <th>group_7845</th>\n",
       "      <th>group_10140</th>\n",
       "      <th>group_10143</th>\n",
       "      <th>group_7172</th>\n",
       "      <th>group_9586</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTAATTTAATAGA  TTAACATAATAAT  TGCAATCTCTTTAT  TATTATGTTAATG  TACATACCGAT  \\\n",
       "0                1              1               1              1            1   \n",
       "1                1              1               1              1            1   \n",
       "2                1              1               1              1            1   \n",
       "3                1              1               1              1            1   \n",
       "4                1              1               1              1            1   \n",
       "..             ...            ...             ...            ...          ...   \n",
       "248              1              1               1              1            1   \n",
       "249              1              1               1              1            1   \n",
       "250              1              1               1              1            1   \n",
       "251              1              1               1              1            1   \n",
       "252              1              1               1              1            1   \n",
       "\n",
       "     GTGTATCATAAT  GCTGTTGAAATGGC  GAGTCCTGTT  GAGTCCTGTTT  \\\n",
       "0               1               1           1            1   \n",
       "1               1               1           1            1   \n",
       "2               1               1           1            1   \n",
       "3               1               1           1            1   \n",
       "4               1               1           1            1   \n",
       "..            ...             ...         ...          ...   \n",
       "248             1               1           1            1   \n",
       "249             1               1           1            1   \n",
       "250             1               1           1            1   \n",
       "251             1               1           1            1   \n",
       "252             1               1           1            1   \n",
       "\n",
       "     GACAAACATGTATTAGCGTTATGTCGCGAACATCATAACCAGCAACATGCGATTGGCGTTAAGTCGTTTGATGATAAATATCACTTGCATGACTCGTGG  \\\n",
       "0                                                    0                                                     \n",
       "1                                                    0                                                     \n",
       "2                                                    0                                                     \n",
       "3                                                    0                                                     \n",
       "4                                                    0                                                     \n",
       "..                                                 ...                                                     \n",
       "248                                                  0                                                     \n",
       "249                                                  0                                                     \n",
       "250                                                  0                                                     \n",
       "251                                                  0                                                     \n",
       "252                                                  0                                                     \n",
       "\n",
       "     ...  group_465  group_2236  group_7824  group_7845  group_10140  \\\n",
       "0    ...          0           0           0           0            0   \n",
       "1    ...          0           0           0           0            0   \n",
       "2    ...          0           0           0           0            0   \n",
       "3    ...          0           0           0           0            0   \n",
       "4    ...          0           0           0           0            0   \n",
       "..   ...        ...         ...         ...         ...          ...   \n",
       "248  ...          0           0           0           0            0   \n",
       "249  ...          0           0           0           0            0   \n",
       "250  ...          0           0           0           0            0   \n",
       "251  ...          0           0           0           0            0   \n",
       "252  ...          0           0           0           0            0   \n",
       "\n",
       "     group_10143  group_7172  group_9586  pheno  strain  \n",
       "0              0           0           0      1     107  \n",
       "1              0           0           0      0     109  \n",
       "2              0           0           0      1     115  \n",
       "3              0           0           0      1  120335  \n",
       "4              0           0           0      1  120337  \n",
       "..           ...         ...         ...    ...     ...  \n",
       "248            0           0           0      1  SR4152  \n",
       "249            0           0           0      0  SR4153  \n",
       "250            0           0           0      0  SR4155  \n",
       "251            0           0           0      0  SR4156  \n",
       "252            0           0           0      0  SR4187  \n",
       "\n",
       "[253 rows x 63 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 62) (253,) (253, 63)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    129\n",
       "1     85\n",
       "2     39\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 129), (1, 129), (2, 129)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_sel_over, y_sel_over = overS.fit_resample(X_sel, y_sel)\n",
    "print(sorted(Counter(y_sel_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat5['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS245     1\n",
       "1          NY439     2\n",
       "2          CA544     1\n",
       "3          CA541     2\n",
       "4          EUH15     1\n",
       "..           ...   ...\n",
       "112       NRS112     0\n",
       "113     CFBRSa51     2\n",
       "114       NRS383     1\n",
       "115       NRS247     0\n",
       "116  CFBREBSa103     0\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model2_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 402us/step - loss: 1.0975 - accuracy: 0.3815 - val_loss: 1.0901 - val_accuracy: 0.3590\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 1.0489 - accuracy: 0.4852 - val_loss: 1.0577 - val_accuracy: 0.4359\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 1.0154 - accuracy: 0.5222 - val_loss: 1.0306 - val_accuracy: 0.5043\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.9875 - accuracy: 0.5593 - val_loss: 1.0091 - val_accuracy: 0.5556\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.9637 - accuracy: 0.5741 - val_loss: 0.9904 - val_accuracy: 0.5983\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.9450 - accuracy: 0.6185 - val_loss: 0.9731 - val_accuracy: 0.6154\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.9265 - accuracy: 0.6259 - val_loss: 0.9573 - val_accuracy: 0.6239\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.9089 - accuracy: 0.6259 - val_loss: 0.9426 - val_accuracy: 0.6325\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.8936 - accuracy: 0.6185 - val_loss: 0.9311 - val_accuracy: 0.6325\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8780 - accuracy: 0.6370 - val_loss: 0.9216 - val_accuracy: 0.6496\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.8642 - accuracy: 0.6481 - val_loss: 0.9155 - val_accuracy: 0.6838\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.8513 - accuracy: 0.6741 - val_loss: 0.9111 - val_accuracy: 0.6923\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.8397 - accuracy: 0.6630 - val_loss: 0.9067 - val_accuracy: 0.6923\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.8291 - accuracy: 0.6667 - val_loss: 0.9024 - val_accuracy: 0.6838\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.8190 - accuracy: 0.6667 - val_loss: 0.8977 - val_accuracy: 0.6838\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.8098 - accuracy: 0.6667 - val_loss: 0.8937 - val_accuracy: 0.6838\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8023 - accuracy: 0.6630 - val_loss: 0.8907 - val_accuracy: 0.6752\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.7945 - accuracy: 0.6667 - val_loss: 0.8878 - val_accuracy: 0.6838\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7871 - accuracy: 0.6667 - val_loss: 0.8849 - val_accuracy: 0.6838\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7805 - accuracy: 0.6667 - val_loss: 0.8819 - val_accuracy: 0.6838\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.7749 - accuracy: 0.6630 - val_loss: 0.8786 - val_accuracy: 0.6581\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7675 - accuracy: 0.6519 - val_loss: 0.8760 - val_accuracy: 0.6410\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7618 - accuracy: 0.6481 - val_loss: 0.8744 - val_accuracy: 0.6496\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7547 - accuracy: 0.6593 - val_loss: 0.8742 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.7497 - accuracy: 0.6630 - val_loss: 0.8742 - val_accuracy: 0.6496\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7443 - accuracy: 0.6667 - val_loss: 0.8730 - val_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7365 - accuracy: 0.6741 - val_loss: 0.8727 - val_accuracy: 0.6496\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7346 - accuracy: 0.6704 - val_loss: 0.8753 - val_accuracy: 0.6667\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7281 - accuracy: 0.6667 - val_loss: 0.8710 - val_accuracy: 0.6581\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.7206 - accuracy: 0.6667 - val_loss: 0.8648 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7145 - accuracy: 0.6963 - val_loss: 0.8616 - val_accuracy: 0.6581\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7086 - accuracy: 0.7000 - val_loss: 0.8590 - val_accuracy: 0.6667\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7024 - accuracy: 0.7074 - val_loss: 0.8577 - val_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.6993 - accuracy: 0.7111 - val_loss: 0.8573 - val_accuracy: 0.6496\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6944 - accuracy: 0.7148 - val_loss: 0.8528 - val_accuracy: 0.6496\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.6882 - accuracy: 0.7111 - val_loss: 0.8488 - val_accuracy: 0.6410\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.6834 - accuracy: 0.7148 - val_loss: 0.8479 - val_accuracy: 0.6581\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6781 - accuracy: 0.7259 - val_loss: 0.8494 - val_accuracy: 0.6581\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.6754 - accuracy: 0.7259 - val_loss: 0.8500 - val_accuracy: 0.6496\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6717 - accuracy: 0.7222 - val_loss: 0.8512 - val_accuracy: 0.6581\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.6673 - accuracy: 0.7296 - val_loss: 0.8465 - val_accuracy: 0.6667\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6621 - accuracy: 0.7333 - val_loss: 0.8433 - val_accuracy: 0.6752\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.6574 - accuracy: 0.7333 - val_loss: 0.8413 - val_accuracy: 0.6752\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6528 - accuracy: 0.7333 - val_loss: 0.8393 - val_accuracy: 0.6752\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6490 - accuracy: 0.7296 - val_loss: 0.8378 - val_accuracy: 0.6667\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6453 - accuracy: 0.7296 - val_loss: 0.8346 - val_accuracy: 0.6581\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6411 - accuracy: 0.7296 - val_loss: 0.8318 - val_accuracy: 0.6667\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6375 - accuracy: 0.7333 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6337 - accuracy: 0.7333 - val_loss: 0.8292 - val_accuracy: 0.6752\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6297 - accuracy: 0.7370 - val_loss: 0.8294 - val_accuracy: 0.6752\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6266 - accuracy: 0.7370 - val_loss: 0.8295 - val_accuracy: 0.6581\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6242 - accuracy: 0.7259 - val_loss: 0.8276 - val_accuracy: 0.6667\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6212 - accuracy: 0.7407 - val_loss: 0.8262 - val_accuracy: 0.6581\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.6176 - accuracy: 0.7407 - val_loss: 0.8266 - val_accuracy: 0.6581\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.6127 - accuracy: 0.7481 - val_loss: 0.8263 - val_accuracy: 0.6667\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6115 - accuracy: 0.7444 - val_loss: 0.8262 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.6067 - accuracy: 0.7481 - val_loss: 0.8222 - val_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6019 - accuracy: 0.7333 - val_loss: 0.8199 - val_accuracy: 0.6581\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5998 - accuracy: 0.7333 - val_loss: 0.8196 - val_accuracy: 0.6581\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5971 - accuracy: 0.7333 - val_loss: 0.8193 - val_accuracy: 0.6581\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.5939 - accuracy: 0.7333 - val_loss: 0.8190 - val_accuracy: 0.6667\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5909 - accuracy: 0.7333 - val_loss: 0.8181 - val_accuracy: 0.6667\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5877 - accuracy: 0.7333 - val_loss: 0.8172 - val_accuracy: 0.6667\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5853 - accuracy: 0.7333 - val_loss: 0.8160 - val_accuracy: 0.6667\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.5816 - accuracy: 0.7333 - val_loss: 0.8180 - val_accuracy: 0.6752\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.5793 - accuracy: 0.7370 - val_loss: 0.8219 - val_accuracy: 0.6752\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.5781 - accuracy: 0.7444 - val_loss: 0.8225 - val_accuracy: 0.6838\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.5765 - accuracy: 0.7481 - val_loss: 0.8210 - val_accuracy: 0.6838\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.5735 - accuracy: 0.7444 - val_loss: 0.8172 - val_accuracy: 0.6667\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.5693 - accuracy: 0.7556 - val_loss: 0.8179 - val_accuracy: 0.6667\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.5670 - accuracy: 0.7593 - val_loss: 0.8178 - val_accuracy: 0.6923\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5645 - accuracy: 0.7556 - val_loss: 0.8174 - val_accuracy: 0.6838\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.5619 - accuracy: 0.7630 - val_loss: 0.8169 - val_accuracy: 0.6923\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.5599 - accuracy: 0.7556 - val_loss: 0.8167 - val_accuracy: 0.6923\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5575 - accuracy: 0.7519 - val_loss: 0.8180 - val_accuracy: 0.6838\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.5565 - accuracy: 0.7519 - val_loss: 0.8172 - val_accuracy: 0.6752\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.5536 - accuracy: 0.7556 - val_loss: 0.8150 - val_accuracy: 0.6752\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.5502 - accuracy: 0.7593 - val_loss: 0.8142 - val_accuracy: 0.6752\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5492 - accuracy: 0.7407 - val_loss: 0.8140 - val_accuracy: 0.6752\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5467 - accuracy: 0.7556 - val_loss: 0.8154 - val_accuracy: 0.6838\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5439 - accuracy: 0.7593 - val_loss: 0.8127 - val_accuracy: 0.6752\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5419 - accuracy: 0.7630 - val_loss: 0.8112 - val_accuracy: 0.6752\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5389 - accuracy: 0.7667 - val_loss: 0.8127 - val_accuracy: 0.6838\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5363 - accuracy: 0.7741 - val_loss: 0.8172 - val_accuracy: 0.6923\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5353 - accuracy: 0.7778 - val_loss: 0.8149 - val_accuracy: 0.6923\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5337 - accuracy: 0.7704 - val_loss: 0.8097 - val_accuracy: 0.6752\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.5321 - accuracy: 0.7778 - val_loss: 0.8093 - val_accuracy: 0.6923\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5303 - accuracy: 0.7519 - val_loss: 0.8103 - val_accuracy: 0.6752\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5297 - accuracy: 0.7741 - val_loss: 0.8148 - val_accuracy: 0.6923\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5254 - accuracy: 0.7667 - val_loss: 0.8142 - val_accuracy: 0.6923\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5232 - accuracy: 0.7667 - val_loss: 0.8111 - val_accuracy: 0.6923\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.5207 - accuracy: 0.7778 - val_loss: 0.8146 - val_accuracy: 0.6838\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.89 - 0s 77us/step - loss: 0.5191 - accuracy: 0.7889 - val_loss: 0.8145 - val_accuracy: 0.6923\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.5172 - accuracy: 0.7963 - val_loss: 0.8134 - val_accuracy: 0.6838\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.5148 - accuracy: 0.8000 - val_loss: 0.8141 - val_accuracy: 0.6838\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.5129 - accuracy: 0.7889 - val_loss: 0.8144 - val_accuracy: 0.6838\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.5121 - accuracy: 0.7926 - val_loss: 0.8162 - val_accuracy: 0.6838\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.5112 - accuracy: 0.7963 - val_loss: 0.8147 - val_accuracy: 0.6838\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.5087 - accuracy: 0.7963 - val_loss: 0.8148 - val_accuracy: 0.6838\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.5061 - accuracy: 0.8000 - val_loss: 0.8141 - val_accuracy: 0.6838\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.5059 - accuracy: 0.7963 - val_loss: 0.8110 - val_accuracy: 0.6838\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.5034 - accuracy: 0.7889 - val_loss: 0.8132 - val_accuracy: 0.6923\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.5013 - accuracy: 0.7852 - val_loss: 0.8126 - val_accuracy: 0.6923\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.5011 - accuracy: 0.7815 - val_loss: 0.8155 - val_accuracy: 0.6923\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.4985 - accuracy: 0.7815 - val_loss: 0.8147 - val_accuracy: 0.6923\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.4965 - accuracy: 0.7889 - val_loss: 0.8146 - val_accuracy: 0.6923\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4955 - accuracy: 0.7926 - val_loss: 0.8141 - val_accuracy: 0.6923\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4952 - accuracy: 0.8000 - val_loss: 0.8150 - val_accuracy: 0.6838\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4941 - accuracy: 0.8111 - val_loss: 0.8146 - val_accuracy: 0.7009\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4919 - accuracy: 0.8148 - val_loss: 0.8128 - val_accuracy: 0.7094\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4912 - accuracy: 0.8222 - val_loss: 0.8125 - val_accuracy: 0.7179\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4877 - accuracy: 0.8222 - val_loss: 0.8164 - val_accuracy: 0.6923\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4845 - accuracy: 0.8259 - val_loss: 0.8252 - val_accuracy: 0.6923\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4871 - accuracy: 0.7963 - val_loss: 0.8345 - val_accuracy: 0.6838\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4859 - accuracy: 0.8000 - val_loss: 0.8284 - val_accuracy: 0.6923\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.4821 - accuracy: 0.8000 - val_loss: 0.8223 - val_accuracy: 0.6838\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.4804 - accuracy: 0.8148 - val_loss: 0.8195 - val_accuracy: 0.6752\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4795 - accuracy: 0.8222 - val_loss: 0.8189 - val_accuracy: 0.6752\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4795 - accuracy: 0.8222 - val_loss: 0.8181 - val_accuracy: 0.6838\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4791 - accuracy: 0.8185 - val_loss: 0.8224 - val_accuracy: 0.7009\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4748 - accuracy: 0.8222 - val_loss: 0.8233 - val_accuracy: 0.7009\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4726 - accuracy: 0.8111 - val_loss: 0.8250 - val_accuracy: 0.6752\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4704 - accuracy: 0.8185 - val_loss: 0.8311 - val_accuracy: 0.6923\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4745 - accuracy: 0.8259 - val_loss: 0.8400 - val_accuracy: 0.6838\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4720 - accuracy: 0.8111 - val_loss: 0.8315 - val_accuracy: 0.6923\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4665 - accuracy: 0.8259 - val_loss: 0.8229 - val_accuracy: 0.7009\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4653 - accuracy: 0.8333 - val_loss: 0.8209 - val_accuracy: 0.7009\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4660 - accuracy: 0.8296 - val_loss: 0.8186 - val_accuracy: 0.6838\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4639 - accuracy: 0.8222 - val_loss: 0.8205 - val_accuracy: 0.6838\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.4612 - accuracy: 0.8259 - val_loss: 0.8228 - val_accuracy: 0.6838\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4594 - accuracy: 0.8222 - val_loss: 0.8241 - val_accuracy: 0.6838\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4584 - accuracy: 0.8185 - val_loss: 0.8253 - val_accuracy: 0.6923\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4578 - accuracy: 0.8222 - val_loss: 0.8224 - val_accuracy: 0.6838\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.4573 - accuracy: 0.8185 - val_loss: 0.8193 - val_accuracy: 0.6838\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4544 - accuracy: 0.8296 - val_loss: 0.8230 - val_accuracy: 0.6752\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.4545 - accuracy: 0.8296 - val_loss: 0.8261 - val_accuracy: 0.6923\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4547 - accuracy: 0.8259 - val_loss: 0.8232 - val_accuracy: 0.6838\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.4544 - accuracy: 0.8259 - val_loss: 0.8197 - val_accuracy: 0.6838\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.4529 - accuracy: 0.8185 - val_loss: 0.8159 - val_accuracy: 0.6838\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.4495 - accuracy: 0.8296 - val_loss: 0.8205 - val_accuracy: 0.6838\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.4484 - accuracy: 0.8370 - val_loss: 0.8301 - val_accuracy: 0.6923\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.4489 - accuracy: 0.8333 - val_loss: 0.8281 - val_accuracy: 0.7094\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.4465 - accuracy: 0.8370 - val_loss: 0.8256 - val_accuracy: 0.7009\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.4468 - accuracy: 0.8370 - val_loss: 0.8338 - val_accuracy: 0.7009\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.4431 - accuracy: 0.8370 - val_loss: 0.8264 - val_accuracy: 0.7009\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4413 - accuracy: 0.8407 - val_loss: 0.8231 - val_accuracy: 0.6923\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.4397 - accuracy: 0.8407 - val_loss: 0.8200 - val_accuracy: 0.7009\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4390 - accuracy: 0.8370 - val_loss: 0.8187 - val_accuracy: 0.7179\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.4406 - accuracy: 0.8333 - val_loss: 0.8246 - val_accuracy: 0.7179\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.4414 - accuracy: 0.8296 - val_loss: 0.8335 - val_accuracy: 0.7179\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4392 - accuracy: 0.8370 - val_loss: 0.8373 - val_accuracy: 0.7094\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4361 - accuracy: 0.8444 - val_loss: 0.8350 - val_accuracy: 0.7265\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.4349 - accuracy: 0.8481 - val_loss: 0.8381 - val_accuracy: 0.7179\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.4330 - accuracy: 0.8481 - val_loss: 0.8365 - val_accuracy: 0.6923\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4335 - accuracy: 0.8407 - val_loss: 0.8313 - val_accuracy: 0.6923\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.4319 - accuracy: 0.8407 - val_loss: 0.8343 - val_accuracy: 0.6923\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.4288 - accuracy: 0.8407 - val_loss: 0.8447 - val_accuracy: 0.6923\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.4317 - accuracy: 0.8444 - val_loss: 0.8527 - val_accuracy: 0.7009\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.4319 - accuracy: 0.8444 - val_loss: 0.8481 - val_accuracy: 0.7009\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4280 - accuracy: 0.8407 - val_loss: 0.8417 - val_accuracy: 0.7009\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.4259 - accuracy: 0.8407 - val_loss: 0.8471 - val_accuracy: 0.7009\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4252 - accuracy: 0.8444 - val_loss: 0.8406 - val_accuracy: 0.6923\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4226 - accuracy: 0.8444 - val_loss: 0.8356 - val_accuracy: 0.7009\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4232 - accuracy: 0.8407 - val_loss: 0.8377 - val_accuracy: 0.7009\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4223 - accuracy: 0.8259 - val_loss: 0.8420 - val_accuracy: 0.7009\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.4205 - accuracy: 0.8481 - val_loss: 0.8479 - val_accuracy: 0.7094\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.4191 - accuracy: 0.8444 - val_loss: 0.8511 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4185 - accuracy: 0.8481 - val_loss: 0.8517 - val_accuracy: 0.7094\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.4201 - accuracy: 0.8481 - val_loss: 0.8424 - val_accuracy: 0.7179\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.4171 - accuracy: 0.8296 - val_loss: 0.8433 - val_accuracy: 0.7265\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.4151 - accuracy: 0.8481 - val_loss: 0.8502 - val_accuracy: 0.7179\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.4147 - accuracy: 0.8481 - val_loss: 0.8532 - val_accuracy: 0.7179\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.4141 - accuracy: 0.8444 - val_loss: 0.8475 - val_accuracy: 0.7009\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4130 - accuracy: 0.8444 - val_loss: 0.8437 - val_accuracy: 0.6923\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4117 - accuracy: 0.8407 - val_loss: 0.8391 - val_accuracy: 0.6923\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4106 - accuracy: 0.8444 - val_loss: 0.8440 - val_accuracy: 0.7094\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.4086 - accuracy: 0.8481 - val_loss: 0.8529 - val_accuracy: 0.7094\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.4093 - accuracy: 0.8519 - val_loss: 0.8606 - val_accuracy: 0.6923\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4091 - accuracy: 0.8481 - val_loss: 0.8546 - val_accuracy: 0.7009\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.4071 - accuracy: 0.8444 - val_loss: 0.8425 - val_accuracy: 0.7009\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4133 - accuracy: 0.8370 - val_loss: 0.8399 - val_accuracy: 0.7350\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.4104 - accuracy: 0.8370 - val_loss: 0.8484 - val_accuracy: 0.7009\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4055 - accuracy: 0.8407 - val_loss: 0.8586 - val_accuracy: 0.7009\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4040 - accuracy: 0.8481 - val_loss: 0.8638 - val_accuracy: 0.7009\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4044 - accuracy: 0.8519 - val_loss: 0.8528 - val_accuracy: 0.7009\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4021 - accuracy: 0.8481 - val_loss: 0.8467 - val_accuracy: 0.7009\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4014 - accuracy: 0.8481 - val_loss: 0.8441 - val_accuracy: 0.7009\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3998 - accuracy: 0.8481 - val_loss: 0.8527 - val_accuracy: 0.7094\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3987 - accuracy: 0.8481 - val_loss: 0.8554 - val_accuracy: 0.7094\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3983 - accuracy: 0.8519 - val_loss: 0.8530 - val_accuracy: 0.7094\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3972 - accuracy: 0.8556 - val_loss: 0.8477 - val_accuracy: 0.7094\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3988 - accuracy: 0.8519 - val_loss: 0.8430 - val_accuracy: 0.6923\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.3966 - accuracy: 0.8481 - val_loss: 0.8505 - val_accuracy: 0.7094\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3961 - accuracy: 0.8519 - val_loss: 0.8606 - val_accuracy: 0.7094\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3959 - accuracy: 0.8519 - val_loss: 0.8550 - val_accuracy: 0.7094\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3946 - accuracy: 0.8519 - val_loss: 0.8540 - val_accuracy: 0.7094\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3932 - accuracy: 0.8519 - val_loss: 0.8561 - val_accuracy: 0.7094\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.3927 - accuracy: 0.8519 - val_loss: 0.8559 - val_accuracy: 0.7009\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.3899 - accuracy: 0.8593 - val_loss: 0.8589 - val_accuracy: 0.7009\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3917 - accuracy: 0.8481 - val_loss: 0.8591 - val_accuracy: 0.7094\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3897 - accuracy: 0.8481 - val_loss: 0.8559 - val_accuracy: 0.7009\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3905 - accuracy: 0.8556 - val_loss: 0.8636 - val_accuracy: 0.7179\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3891 - accuracy: 0.8556 - val_loss: 0.8592 - val_accuracy: 0.7009\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3905 - accuracy: 0.8556 - val_loss: 0.8564 - val_accuracy: 0.7094\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3870 - accuracy: 0.8556 - val_loss: 0.8610 - val_accuracy: 0.7009\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 202us/step - loss: 0.3857 - accuracy: 0.8556 - val_loss: 0.8583 - val_accuracy: 0.7094\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3862 - accuracy: 0.8556 - val_loss: 0.8619 - val_accuracy: 0.7094\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 210us/step - loss: 0.3859 - accuracy: 0.8593 - val_loss: 0.8664 - val_accuracy: 0.7094\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3837 - accuracy: 0.8593 - val_loss: 0.8719 - val_accuracy: 0.7009\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3829 - accuracy: 0.8556 - val_loss: 0.8667 - val_accuracy: 0.7094\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.3841 - accuracy: 0.8556 - val_loss: 0.8621 - val_accuracy: 0.7009\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3841 - accuracy: 0.8407 - val_loss: 0.8627 - val_accuracy: 0.7350\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3834 - accuracy: 0.8481 - val_loss: 0.8694 - val_accuracy: 0.7179\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3822 - accuracy: 0.8593 - val_loss: 0.8726 - val_accuracy: 0.7179\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3801 - accuracy: 0.8630 - val_loss: 0.8726 - val_accuracy: 0.7179\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.3796 - accuracy: 0.8630 - val_loss: 0.8779 - val_accuracy: 0.7179\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3797 - accuracy: 0.8593 - val_loss: 0.8805 - val_accuracy: 0.7179\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3778 - accuracy: 0.8593 - val_loss: 0.8770 - val_accuracy: 0.7179\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3767 - accuracy: 0.8593 - val_loss: 0.8741 - val_accuracy: 0.7009\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3779 - accuracy: 0.8556 - val_loss: 0.8750 - val_accuracy: 0.7009\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3773 - accuracy: 0.8556 - val_loss: 0.8805 - val_accuracy: 0.7265\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3764 - accuracy: 0.8593 - val_loss: 0.8766 - val_accuracy: 0.7265\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3752 - accuracy: 0.8630 - val_loss: 0.8734 - val_accuracy: 0.7265\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3747 - accuracy: 0.8593 - val_loss: 0.8717 - val_accuracy: 0.7265\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3727 - accuracy: 0.8630 - val_loss: 0.8733 - val_accuracy: 0.7179\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3719 - accuracy: 0.8593 - val_loss: 0.8798 - val_accuracy: 0.7179\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3718 - accuracy: 0.8630 - val_loss: 0.8787 - val_accuracy: 0.7265\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3706 - accuracy: 0.8630 - val_loss: 0.8721 - val_accuracy: 0.7265\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3709 - accuracy: 0.8593 - val_loss: 0.8722 - val_accuracy: 0.7265\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3702 - accuracy: 0.8630 - val_loss: 0.8759 - val_accuracy: 0.7265\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3687 - accuracy: 0.8593 - val_loss: 0.8860 - val_accuracy: 0.7265\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3706 - accuracy: 0.8593 - val_loss: 0.8952 - val_accuracy: 0.7265\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3705 - accuracy: 0.8630 - val_loss: 0.8874 - val_accuracy: 0.7179\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3672 - accuracy: 0.8630 - val_loss: 0.8724 - val_accuracy: 0.7265\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3699 - accuracy: 0.8444 - val_loss: 0.8733 - val_accuracy: 0.7436\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3691 - accuracy: 0.8481 - val_loss: 0.8858 - val_accuracy: 0.7265\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.3667 - accuracy: 0.8630 - val_loss: 0.8868 - val_accuracy: 0.7179\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.3654 - accuracy: 0.8593 - val_loss: 0.8893 - val_accuracy: 0.7265\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3655 - accuracy: 0.8593 - val_loss: 0.8893 - val_accuracy: 0.7265\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3631 - accuracy: 0.8630 - val_loss: 0.8806 - val_accuracy: 0.7265\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.93 - 0s 121us/step - loss: 0.3639 - accuracy: 0.8630 - val_loss: 0.8822 - val_accuracy: 0.7265\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.3635 - accuracy: 0.8593 - val_loss: 0.8957 - val_accuracy: 0.7265\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.85 - 0s 99us/step - loss: 0.3642 - accuracy: 0.8630 - val_loss: 0.8974 - val_accuracy: 0.7265\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3639 - accuracy: 0.8630 - val_loss: 0.8925 - val_accuracy: 0.7265\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.3615 - accuracy: 0.8593 - val_loss: 0.8919 - val_accuracy: 0.7265\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.3621 - accuracy: 0.8593 - val_loss: 0.8957 - val_accuracy: 0.7265\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3616 - accuracy: 0.8593 - val_loss: 0.8913 - val_accuracy: 0.7350\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3600 - accuracy: 0.8630 - val_loss: 0.8873 - val_accuracy: 0.7265\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3598 - accuracy: 0.8630 - val_loss: 0.8859 - val_accuracy: 0.7350\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3599 - accuracy: 0.8630 - val_loss: 0.8920 - val_accuracy: 0.7350\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3601 - accuracy: 0.8630 - val_loss: 0.8938 - val_accuracy: 0.7350\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3601 - accuracy: 0.8593 - val_loss: 0.9020 - val_accuracy: 0.7265\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3571 - accuracy: 0.8593 - val_loss: 0.8891 - val_accuracy: 0.7265\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3613 - accuracy: 0.8481 - val_loss: 0.8847 - val_accuracy: 0.7436\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3571 - accuracy: 0.8667 - val_loss: 0.8954 - val_accuracy: 0.7265\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.3558 - accuracy: 0.8593 - val_loss: 0.9113 - val_accuracy: 0.7265\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3574 - accuracy: 0.8630 - val_loss: 0.9137 - val_accuracy: 0.7265\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3560 - accuracy: 0.8630 - val_loss: 0.9050 - val_accuracy: 0.7265\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3547 - accuracy: 0.8630 - val_loss: 0.9003 - val_accuracy: 0.7265\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3555 - accuracy: 0.8556 - val_loss: 0.8994 - val_accuracy: 0.7265\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3541 - accuracy: 0.8556 - val_loss: 0.9059 - val_accuracy: 0.7265\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3522 - accuracy: 0.8630 - val_loss: 0.9120 - val_accuracy: 0.7265\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3549 - accuracy: 0.8630 - val_loss: 0.9233 - val_accuracy: 0.7265\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3555 - accuracy: 0.8630 - val_loss: 0.9080 - val_accuracy: 0.7265\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3539 - accuracy: 0.8630 - val_loss: 0.8972 - val_accuracy: 0.7265\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3515 - accuracy: 0.8593 - val_loss: 0.8955 - val_accuracy: 0.7350\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3519 - accuracy: 0.8630 - val_loss: 0.8945 - val_accuracy: 0.7265\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3505 - accuracy: 0.8630 - val_loss: 0.9066 - val_accuracy: 0.7265\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3509 - accuracy: 0.8630 - val_loss: 0.9088 - val_accuracy: 0.7265\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3495 - accuracy: 0.8630 - val_loss: 0.9056 - val_accuracy: 0.7350\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3487 - accuracy: 0.8667 - val_loss: 0.9046 - val_accuracy: 0.7350\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3486 - accuracy: 0.8667 - val_loss: 0.9148 - val_accuracy: 0.7350\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3506 - accuracy: 0.8667 - val_loss: 0.9121 - val_accuracy: 0.7350\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3471 - accuracy: 0.8667 - val_loss: 0.9005 - val_accuracy: 0.7265\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3481 - accuracy: 0.8370 - val_loss: 0.8974 - val_accuracy: 0.7265\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3465 - accuracy: 0.8630 - val_loss: 0.9151 - val_accuracy: 0.7265\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3458 - accuracy: 0.8630 - val_loss: 0.9139 - val_accuracy: 0.7265\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 60us/step - loss: 0.3455 - accuracy: 0.8593 - val_loss: 0.9078 - val_accuracy: 0.7265\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3466 - accuracy: 0.8630 - val_loss: 0.9050 - val_accuracy: 0.7265\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3449 - accuracy: 0.8630 - val_loss: 0.9102 - val_accuracy: 0.7265\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3444 - accuracy: 0.8630 - val_loss: 0.9196 - val_accuracy: 0.7265\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3455 - accuracy: 0.8630 - val_loss: 0.9212 - val_accuracy: 0.7265\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3439 - accuracy: 0.8630 - val_loss: 0.9114 - val_accuracy: 0.7350\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3448 - accuracy: 0.8481 - val_loss: 0.9024 - val_accuracy: 0.7436\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3468 - accuracy: 0.8556 - val_loss: 0.9126 - val_accuracy: 0.7436\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3443 - accuracy: 0.8556 - val_loss: 0.9267 - val_accuracy: 0.7265\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3425 - accuracy: 0.8630 - val_loss: 0.9246 - val_accuracy: 0.7265\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3430 - accuracy: 0.8630 - val_loss: 0.9123 - val_accuracy: 0.7265\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3418 - accuracy: 0.8630 - val_loss: 0.9061 - val_accuracy: 0.7350\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3426 - accuracy: 0.8630 - val_loss: 0.9166 - val_accuracy: 0.7350\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3414 - accuracy: 0.8667 - val_loss: 0.9226 - val_accuracy: 0.7265\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3410 - accuracy: 0.8630 - val_loss: 0.9357 - val_accuracy: 0.7265\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3458 - accuracy: 0.8630 - val_loss: 0.9337 - val_accuracy: 0.7265\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3422 - accuracy: 0.8630 - val_loss: 0.9107 - val_accuracy: 0.7350\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3398 - accuracy: 0.8630 - val_loss: 0.9067 - val_accuracy: 0.7350\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3412 - accuracy: 0.8667 - val_loss: 0.9098 - val_accuracy: 0.7265\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3443 - accuracy: 0.8667 - val_loss: 0.9098 - val_accuracy: 0.7350\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3394 - accuracy: 0.8667 - val_loss: 0.9268 - val_accuracy: 0.7265\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3414 - accuracy: 0.8593 - val_loss: 0.9448 - val_accuracy: 0.7265\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3421 - accuracy: 0.8630 - val_loss: 0.9384 - val_accuracy: 0.7265\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3396 - accuracy: 0.8630 - val_loss: 0.9290 - val_accuracy: 0.7350\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3373 - accuracy: 0.8630 - val_loss: 0.9268 - val_accuracy: 0.7350\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3384 - accuracy: 0.8593 - val_loss: 0.9378 - val_accuracy: 0.7265\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3395 - accuracy: 0.8630 - val_loss: 0.9240 - val_accuracy: 0.7265\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3382 - accuracy: 0.8667 - val_loss: 0.9164 - val_accuracy: 0.7350\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3364 - accuracy: 0.8667 - val_loss: 0.9185 - val_accuracy: 0.7350\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3361 - accuracy: 0.8667 - val_loss: 0.9230 - val_accuracy: 0.7521\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3348 - accuracy: 0.8556 - val_loss: 0.9280 - val_accuracy: 0.7265\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3337 - accuracy: 0.8556 - val_loss: 0.9343 - val_accuracy: 0.7265\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3346 - accuracy: 0.8630 - val_loss: 0.9347 - val_accuracy: 0.7265\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3342 - accuracy: 0.8630 - val_loss: 0.9381 - val_accuracy: 0.7350\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3333 - accuracy: 0.8667 - val_loss: 0.9330 - val_accuracy: 0.7350\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3332 - accuracy: 0.8667 - val_loss: 0.9317 - val_accuracy: 0.7350\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3318 - accuracy: 0.8667 - val_loss: 0.9364 - val_accuracy: 0.7265\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3312 - accuracy: 0.8630 - val_loss: 0.9393 - val_accuracy: 0.7350\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3314 - accuracy: 0.8667 - val_loss: 0.9375 - val_accuracy: 0.7350\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3316 - accuracy: 0.8667 - val_loss: 0.9252 - val_accuracy: 0.7350\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3314 - accuracy: 0.8630 - val_loss: 0.9233 - val_accuracy: 0.7521\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3317 - accuracy: 0.8667 - val_loss: 0.9367 - val_accuracy: 0.7265\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3294 - accuracy: 0.8630 - val_loss: 0.9388 - val_accuracy: 0.7350\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3293 - accuracy: 0.8667 - val_loss: 0.9378 - val_accuracy: 0.7350\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3331 - accuracy: 0.8667 - val_loss: 0.9396 - val_accuracy: 0.7350\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3298 - accuracy: 0.8667 - val_loss: 0.9289 - val_accuracy: 0.7350\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3289 - accuracy: 0.8593 - val_loss: 0.9272 - val_accuracy: 0.7350\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3281 - accuracy: 0.8630 - val_loss: 0.9350 - val_accuracy: 0.7350\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3279 - accuracy: 0.8667 - val_loss: 0.9425 - val_accuracy: 0.7350\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3275 - accuracy: 0.8667 - val_loss: 0.9392 - val_accuracy: 0.7350\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3268 - accuracy: 0.8667 - val_loss: 0.9326 - val_accuracy: 0.7350\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3262 - accuracy: 0.8630 - val_loss: 0.9333 - val_accuracy: 0.7350\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3255 - accuracy: 0.8667 - val_loss: 0.9347 - val_accuracy: 0.7350\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3265 - accuracy: 0.8667 - val_loss: 0.9351 - val_accuracy: 0.7350\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 0.9330 - val_accuracy: 0.7350\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3279 - accuracy: 0.8630 - val_loss: 0.9333 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3286 - accuracy: 0.8630 - val_loss: 0.9422 - val_accuracy: 0.7265\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3250 - accuracy: 0.8630 - val_loss: 0.9345 - val_accuracy: 0.7350\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3243 - accuracy: 0.8667 - val_loss: 0.9375 - val_accuracy: 0.7350\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3242 - accuracy: 0.8667 - val_loss: 0.9427 - val_accuracy: 0.7350\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3239 - accuracy: 0.8667 - val_loss: 0.9416 - val_accuracy: 0.7350\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3236 - accuracy: 0.8704 - val_loss: 0.9340 - val_accuracy: 0.7350\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3240 - accuracy: 0.8667 - val_loss: 0.9432 - val_accuracy: 0.7350\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3232 - accuracy: 0.8556 - val_loss: 0.9509 - val_accuracy: 0.7350\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3236 - accuracy: 0.8667 - val_loss: 0.9488 - val_accuracy: 0.7350\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3233 - accuracy: 0.8667 - val_loss: 0.9378 - val_accuracy: 0.7350\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3236 - accuracy: 0.8667 - val_loss: 0.9351 - val_accuracy: 0.7350\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3236 - accuracy: 0.8667 - val_loss: 0.9455 - val_accuracy: 0.7350\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3218 - accuracy: 0.8630 - val_loss: 0.9509 - val_accuracy: 0.7350\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3231 - accuracy: 0.8667 - val_loss: 0.9438 - val_accuracy: 0.7350\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3237 - accuracy: 0.8704 - val_loss: 0.9355 - val_accuracy: 0.7350\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3221 - accuracy: 0.8667 - val_loss: 0.9447 - val_accuracy: 0.7350\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3202 - accuracy: 0.8630 - val_loss: 0.9596 - val_accuracy: 0.7350\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3204 - accuracy: 0.8667 - val_loss: 0.9550 - val_accuracy: 0.7350\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3191 - accuracy: 0.8667 - val_loss: 0.9464 - val_accuracy: 0.7350\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3198 - accuracy: 0.8556 - val_loss: 0.9409 - val_accuracy: 0.7521\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3215 - accuracy: 0.8481 - val_loss: 0.9405 - val_accuracy: 0.7350\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3197 - accuracy: 0.8667 - val_loss: 0.9437 - val_accuracy: 0.7350\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3185 - accuracy: 0.8667 - val_loss: 0.9523 - val_accuracy: 0.7350\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3181 - accuracy: 0.8704 - val_loss: 0.9603 - val_accuracy: 0.7350\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3210 - accuracy: 0.8630 - val_loss: 0.9655 - val_accuracy: 0.7350\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3189 - accuracy: 0.8593 - val_loss: 0.9451 - val_accuracy: 0.7350\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3190 - accuracy: 0.8667 - val_loss: 0.9421 - val_accuracy: 0.7350\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3217 - accuracy: 0.8667 - val_loss: 0.9412 - val_accuracy: 0.7350\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3227 - accuracy: 0.8519 - val_loss: 0.9541 - val_accuracy: 0.7521\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3200 - accuracy: 0.8556 - val_loss: 0.9562 - val_accuracy: 0.7350\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3170 - accuracy: 0.8667 - val_loss: 0.9647 - val_accuracy: 0.7350\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3216 - accuracy: 0.8630 - val_loss: 0.9712 - val_accuracy: 0.7350\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3189 - accuracy: 0.8630 - val_loss: 0.9554 - val_accuracy: 0.7350\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3178 - accuracy: 0.8630 - val_loss: 0.9484 - val_accuracy: 0.7521\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3191 - accuracy: 0.8593 - val_loss: 0.9532 - val_accuracy: 0.7350\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3176 - accuracy: 0.8741 - val_loss: 0.9576 - val_accuracy: 0.7350\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3195 - accuracy: 0.8667 - val_loss: 0.9706 - val_accuracy: 0.7350\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3199 - accuracy: 0.8667 - val_loss: 0.9696 - val_accuracy: 0.7350\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3171 - accuracy: 0.8667 - val_loss: 0.9623 - val_accuracy: 0.7350\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3164 - accuracy: 0.8667 - val_loss: 0.9574 - val_accuracy: 0.7350\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3141 - accuracy: 0.8741 - val_loss: 0.9475 - val_accuracy: 0.7350\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3168 - accuracy: 0.8667 - val_loss: 0.9505 - val_accuracy: 0.7350\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3171 - accuracy: 0.8667 - val_loss: 0.9564 - val_accuracy: 0.7350\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3135 - accuracy: 0.8667 - val_loss: 0.9654 - val_accuracy: 0.7350\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3141 - accuracy: 0.8667 - val_loss: 0.9677 - val_accuracy: 0.7350\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3154 - accuracy: 0.8667 - val_loss: 0.9636 - val_accuracy: 0.7350\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3136 - accuracy: 0.8704 - val_loss: 0.9645 - val_accuracy: 0.7350\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3145 - accuracy: 0.8481 - val_loss: 0.9625 - val_accuracy: 0.7350\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3124 - accuracy: 0.8667 - val_loss: 0.9581 - val_accuracy: 0.7350\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3133 - accuracy: 0.8667 - val_loss: 0.9595 - val_accuracy: 0.7350\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3129 - accuracy: 0.8667 - val_loss: 0.9627 - val_accuracy: 0.7350\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3144 - accuracy: 0.8630 - val_loss: 0.9740 - val_accuracy: 0.7350\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3149 - accuracy: 0.8667 - val_loss: 0.9650 - val_accuracy: 0.7350\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3149 - accuracy: 0.8630 - val_loss: 0.9692 - val_accuracy: 0.7350\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3137 - accuracy: 0.8667 - val_loss: 0.9709 - val_accuracy: 0.7350\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3145 - accuracy: 0.8667 - val_loss: 0.9582 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3121 - accuracy: 0.8667 - val_loss: 0.9670 - val_accuracy: 0.7350\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3103 - accuracy: 0.8667 - val_loss: 0.9632 - val_accuracy: 0.7350\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3108 - accuracy: 0.8667 - val_loss: 0.9538 - val_accuracy: 0.7350\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3113 - accuracy: 0.8667 - val_loss: 0.9599 - val_accuracy: 0.7350\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3100 - accuracy: 0.8667 - val_loss: 0.9603 - val_accuracy: 0.7350\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3091 - accuracy: 0.8667 - val_loss: 0.9679 - val_accuracy: 0.7350\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3092 - accuracy: 0.8667 - val_loss: 0.9762 - val_accuracy: 0.7350\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3110 - accuracy: 0.8593 - val_loss: 0.9654 - val_accuracy: 0.7521\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3119 - accuracy: 0.8593 - val_loss: 0.9565 - val_accuracy: 0.7521\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3120 - accuracy: 0.8556 - val_loss: 0.9615 - val_accuracy: 0.7350\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3098 - accuracy: 0.8704 - val_loss: 0.9719 - val_accuracy: 0.7350\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3081 - accuracy: 0.8667 - val_loss: 0.9832 - val_accuracy: 0.7350\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3102 - accuracy: 0.8667 - val_loss: 0.9917 - val_accuracy: 0.7350\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3102 - accuracy: 0.8667 - val_loss: 0.9829 - val_accuracy: 0.7350\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3083 - accuracy: 0.8667 - val_loss: 0.9744 - val_accuracy: 0.7350\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3122 - accuracy: 0.8667 - val_loss: 0.9655 - val_accuracy: 0.7350\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3146 - accuracy: 0.8630 - val_loss: 0.9609 - val_accuracy: 0.7350\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3098 - accuracy: 0.8630 - val_loss: 0.9756 - val_accuracy: 0.7350\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3071 - accuracy: 0.8667 - val_loss: 0.9752 - val_accuracy: 0.7350\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3067 - accuracy: 0.8630 - val_loss: 0.9819 - val_accuracy: 0.7350\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3093 - accuracy: 0.8630 - val_loss: 0.9864 - val_accuracy: 0.7350\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3083 - accuracy: 0.8704 - val_loss: 0.9770 - val_accuracy: 0.7350\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3065 - accuracy: 0.8593 - val_loss: 0.9668 - val_accuracy: 0.7350\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3065 - accuracy: 0.8667 - val_loss: 0.9700 - val_accuracy: 0.7350\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3059 - accuracy: 0.8667 - val_loss: 0.9752 - val_accuracy: 0.7350\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3065 - accuracy: 0.8667 - val_loss: 0.9678 - val_accuracy: 0.7350\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3047 - accuracy: 0.8667 - val_loss: 0.9741 - val_accuracy: 0.7350\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3050 - accuracy: 0.8667 - val_loss: 0.9824 - val_accuracy: 0.7350\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3053 - accuracy: 0.8741 - val_loss: 0.9865 - val_accuracy: 0.7350\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.3056 - accuracy: 0.8667 - val_loss: 0.9775 - val_accuracy: 0.7350\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3053 - accuracy: 0.8667 - val_loss: 0.9697 - val_accuracy: 0.7350\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3041 - accuracy: 0.8667 - val_loss: 0.9752 - val_accuracy: 0.7350\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3044 - accuracy: 0.8667 - val_loss: 0.9851 - val_accuracy: 0.7350\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3053 - accuracy: 0.8667 - val_loss: 0.9746 - val_accuracy: 0.7350\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3054 - accuracy: 0.8667 - val_loss: 0.9683 - val_accuracy: 0.7350\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3060 - accuracy: 0.8556 - val_loss: 0.9796 - val_accuracy: 0.7350\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3057 - accuracy: 0.8667 - val_loss: 0.9769 - val_accuracy: 0.7350\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3047 - accuracy: 0.8667 - val_loss: 0.9850 - val_accuracy: 0.7350\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3052 - accuracy: 0.8667 - val_loss: 0.9864 - val_accuracy: 0.7350\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3019 - accuracy: 0.8667 - val_loss: 0.9719 - val_accuracy: 0.7350\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3031 - accuracy: 0.8667 - val_loss: 0.9665 - val_accuracy: 0.7350\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3044 - accuracy: 0.8667 - val_loss: 0.9739 - val_accuracy: 0.7350\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3033 - accuracy: 0.8667 - val_loss: 0.9824 - val_accuracy: 0.7350\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3049 - accuracy: 0.8630 - val_loss: 0.9795 - val_accuracy: 0.7350\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3031 - accuracy: 0.8667 - val_loss: 0.9790 - val_accuracy: 0.7350\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3017 - accuracy: 0.8630 - val_loss: 0.9892 - val_accuracy: 0.7350\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3040 - accuracy: 0.8630 - val_loss: 0.9952 - val_accuracy: 0.7350\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3031 - accuracy: 0.8667 - val_loss: 0.9809 - val_accuracy: 0.7350\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3017 - accuracy: 0.8667 - val_loss: 0.9707 - val_accuracy: 0.7350\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3030 - accuracy: 0.8667 - val_loss: 0.9732 - val_accuracy: 0.7350\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3006 - accuracy: 0.8667 - val_loss: 0.9842 - val_accuracy: 0.7350\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3049 - accuracy: 0.8667 - val_loss: 1.0022 - val_accuracy: 0.7350\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3052 - accuracy: 0.8667 - val_loss: 0.9922 - val_accuracy: 0.7350\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.3010 - accuracy: 0.8630 - val_loss: 0.9691 - val_accuracy: 0.7350\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3029 - accuracy: 0.8667 - val_loss: 0.9708 - val_accuracy: 0.7350\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.3019 - accuracy: 0.8667 - val_loss: 0.9835 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3014 - accuracy: 0.8667 - val_loss: 0.9932 - val_accuracy: 0.7350\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2994 - accuracy: 0.8667 - val_loss: 0.9824 - val_accuracy: 0.7350\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2977 - accuracy: 0.8630 - val_loss: 0.9727 - val_accuracy: 0.7350\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2998 - accuracy: 0.8667 - val_loss: 0.9663 - val_accuracy: 0.7350\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3035 - accuracy: 0.8630 - val_loss: 0.9688 - val_accuracy: 0.7350\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3005 - accuracy: 0.8667 - val_loss: 0.9717 - val_accuracy: 0.7350\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2988 - accuracy: 0.8630 - val_loss: 0.9790 - val_accuracy: 0.7350\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3016 - accuracy: 0.8704 - val_loss: 0.9804 - val_accuracy: 0.7521\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3017 - accuracy: 0.8593 - val_loss: 0.9794 - val_accuracy: 0.7521\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2988 - accuracy: 0.8593 - val_loss: 0.9798 - val_accuracy: 0.7350\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2973 - accuracy: 0.8667 - val_loss: 0.9847 - val_accuracy: 0.7350\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2988 - accuracy: 0.8667 - val_loss: 0.9919 - val_accuracy: 0.7350\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2978 - accuracy: 0.8667 - val_loss: 0.9902 - val_accuracy: 0.7350\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2974 - accuracy: 0.8667 - val_loss: 0.9881 - val_accuracy: 0.7350\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2959 - accuracy: 0.8630 - val_loss: 0.9769 - val_accuracy: 0.7521\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2997 - accuracy: 0.8593 - val_loss: 0.9755 - val_accuracy: 0.7521\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3013 - accuracy: 0.8593 - val_loss: 0.9842 - val_accuracy: 0.7350\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2960 - accuracy: 0.8667 - val_loss: 0.9731 - val_accuracy: 0.7350\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3006 - accuracy: 0.8667 - val_loss: 0.9778 - val_accuracy: 0.7350\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3033 - accuracy: 0.8667 - val_loss: 0.9766 - val_accuracy: 0.7350\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2989 - accuracy: 0.8667 - val_loss: 0.9705 - val_accuracy: 0.7350\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2971 - accuracy: 0.8741 - val_loss: 0.9863 - val_accuracy: 0.7521\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2977 - accuracy: 0.8667 - val_loss: 0.9999 - val_accuracy: 0.7350\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2959 - accuracy: 0.8630 - val_loss: 1.0005 - val_accuracy: 0.7350\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2976 - accuracy: 0.8667 - val_loss: 1.0087 - val_accuracy: 0.7350\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3007 - accuracy: 0.8630 - val_loss: 0.9902 - val_accuracy: 0.7350\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2993 - accuracy: 0.8667 - val_loss: 0.9813 - val_accuracy: 0.7350\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2971 - accuracy: 0.8667 - val_loss: 0.9720 - val_accuracy: 0.7350\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2987 - accuracy: 0.8667 - val_loss: 0.9771 - val_accuracy: 0.7350\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2965 - accuracy: 0.8667 - val_loss: 0.9978 - val_accuracy: 0.7350\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2950 - accuracy: 0.8667 - val_loss: 1.0099 - val_accuracy: 0.7350\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2989 - accuracy: 0.8667 - val_loss: 1.0217 - val_accuracy: 0.7350\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2985 - accuracy: 0.8667 - val_loss: 0.9935 - val_accuracy: 0.7350\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2926 - accuracy: 0.8704 - val_loss: 0.9788 - val_accuracy: 0.7350\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2953 - accuracy: 0.8667 - val_loss: 0.9769 - val_accuracy: 0.7350\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2949 - accuracy: 0.8667 - val_loss: 0.9821 - val_accuracy: 0.7350\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2930 - accuracy: 0.8667 - val_loss: 0.9930 - val_accuracy: 0.7350\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2933 - accuracy: 0.8667 - val_loss: 1.0008 - val_accuracy: 0.7350\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2937 - accuracy: 0.8667 - val_loss: 1.0014 - val_accuracy: 0.7350\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2945 - accuracy: 0.8667 - val_loss: 0.9917 - val_accuracy: 0.7350\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2925 - accuracy: 0.8667 - val_loss: 0.9818 - val_accuracy: 0.7350\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2936 - accuracy: 0.8704 - val_loss: 0.9818 - val_accuracy: 0.7350\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2951 - accuracy: 0.8704 - val_loss: 0.9847 - val_accuracy: 0.7350\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2931 - accuracy: 0.8667 - val_loss: 0.9969 - val_accuracy: 0.7350\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2939 - accuracy: 0.8593 - val_loss: 1.0089 - val_accuracy: 0.7350\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2941 - accuracy: 0.8630 - val_loss: 1.0030 - val_accuracy: 0.7350\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2934 - accuracy: 0.8630 - val_loss: 0.9950 - val_accuracy: 0.7350\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2933 - accuracy: 0.8667 - val_loss: 0.9903 - val_accuracy: 0.7350\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2934 - accuracy: 0.8667 - val_loss: 0.9963 - val_accuracy: 0.7350\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2913 - accuracy: 0.8630 - val_loss: 1.0058 - val_accuracy: 0.7350\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2939 - accuracy: 0.8704 - val_loss: 1.0090 - val_accuracy: 0.7350\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2940 - accuracy: 0.8630 - val_loss: 1.0035 - val_accuracy: 0.7350\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2907 - accuracy: 0.8630 - val_loss: 0.9972 - val_accuracy: 0.7350\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2912 - accuracy: 0.8704 - val_loss: 0.9996 - val_accuracy: 0.7350\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2945 - accuracy: 0.8704 - val_loss: 1.0026 - val_accuracy: 0.7350\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2939 - accuracy: 0.8704 - val_loss: 1.0030 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2907 - accuracy: 0.8667 - val_loss: 0.9973 - val_accuracy: 0.7350\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2906 - accuracy: 0.8667 - val_loss: 0.9994 - val_accuracy: 0.7350\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2932 - accuracy: 0.8630 - val_loss: 1.0008 - val_accuracy: 0.7350\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2935 - accuracy: 0.8704 - val_loss: 0.9975 - val_accuracy: 0.7350\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2918 - accuracy: 0.8667 - val_loss: 0.9929 - val_accuracy: 0.7350\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2920 - accuracy: 0.8667 - val_loss: 0.9949 - val_accuracy: 0.7350\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2895 - accuracy: 0.8667 - val_loss: 1.0148 - val_accuracy: 0.7350\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2935 - accuracy: 0.8667 - val_loss: 1.0319 - val_accuracy: 0.7350\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2923 - accuracy: 0.8667 - val_loss: 1.0239 - val_accuracy: 0.7350\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2899 - accuracy: 0.8667 - val_loss: 1.0085 - val_accuracy: 0.7350\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2888 - accuracy: 0.8667 - val_loss: 1.0103 - val_accuracy: 0.7350\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2891 - accuracy: 0.8667 - val_loss: 1.0084 - val_accuracy: 0.7350\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2899 - accuracy: 0.8667 - val_loss: 1.0051 - val_accuracy: 0.7350\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2915 - accuracy: 0.8667 - val_loss: 1.0235 - val_accuracy: 0.7350\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2930 - accuracy: 0.8667 - val_loss: 1.0088 - val_accuracy: 0.7350\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2928 - accuracy: 0.8704 - val_loss: 0.9992 - val_accuracy: 0.7350\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2892 - accuracy: 0.8667 - val_loss: 0.9964 - val_accuracy: 0.7350\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2883 - accuracy: 0.8667 - val_loss: 0.9979 - val_accuracy: 0.7350\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2889 - accuracy: 0.8704 - val_loss: 1.0026 - val_accuracy: 0.7350\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2880 - accuracy: 0.8704 - val_loss: 1.0068 - val_accuracy: 0.7350\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2903 - accuracy: 0.8630 - val_loss: 1.0027 - val_accuracy: 0.7521\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2889 - accuracy: 0.8630 - val_loss: 0.9952 - val_accuracy: 0.7521\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2918 - accuracy: 0.8519 - val_loss: 0.9979 - val_accuracy: 0.7350\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2888 - accuracy: 0.8704 - val_loss: 1.0122 - val_accuracy: 0.7350\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2883 - accuracy: 0.8667 - val_loss: 1.0175 - val_accuracy: 0.7350\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2861 - accuracy: 0.8667 - val_loss: 1.0095 - val_accuracy: 0.7350\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2892 - accuracy: 0.8741 - val_loss: 1.0033 - val_accuracy: 0.7521\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2914 - accuracy: 0.8593 - val_loss: 1.0004 - val_accuracy: 0.7350\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2888 - accuracy: 0.8667 - val_loss: 1.0106 - val_accuracy: 0.7350\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2877 - accuracy: 0.8704 - val_loss: 1.0184 - val_accuracy: 0.7350\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2872 - accuracy: 0.8667 - val_loss: 1.0177 - val_accuracy: 0.7350\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2860 - accuracy: 0.8667 - val_loss: 1.0156 - val_accuracy: 0.7350\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2881 - accuracy: 0.8630 - val_loss: 1.0155 - val_accuracy: 0.7350\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2892 - accuracy: 0.8667 - val_loss: 1.0122 - val_accuracy: 0.7350\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2874 - accuracy: 0.8667 - val_loss: 1.0133 - val_accuracy: 0.7350\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2872 - accuracy: 0.8667 - val_loss: 1.0171 - val_accuracy: 0.7350\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2870 - accuracy: 0.8704 - val_loss: 1.0193 - val_accuracy: 0.7350\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2884 - accuracy: 0.8593 - val_loss: 1.0291 - val_accuracy: 0.7350\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2870 - accuracy: 0.8667 - val_loss: 1.0234 - val_accuracy: 0.7350\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2858 - accuracy: 0.8667 - val_loss: 1.0150 - val_accuracy: 0.7350\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2874 - accuracy: 0.8704 - val_loss: 1.0203 - val_accuracy: 0.7350\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2899 - accuracy: 0.8704 - val_loss: 1.0335 - val_accuracy: 0.7436\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2882 - accuracy: 0.8704 - val_loss: 1.0265 - val_accuracy: 0.7350\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2858 - accuracy: 0.8630 - val_loss: 1.0136 - val_accuracy: 0.7350\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2876 - accuracy: 0.8556 - val_loss: 1.0040 - val_accuracy: 0.7436\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2874 - accuracy: 0.8593 - val_loss: 1.0047 - val_accuracy: 0.7521\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2861 - accuracy: 0.8593 - val_loss: 1.0043 - val_accuracy: 0.7436\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2898 - accuracy: 0.8704 - val_loss: 1.0053 - val_accuracy: 0.7436\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2863 - accuracy: 0.8704 - val_loss: 1.0171 - val_accuracy: 0.7436\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2846 - accuracy: 0.8704 - val_loss: 1.0242 - val_accuracy: 0.7350\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2844 - accuracy: 0.8630 - val_loss: 1.0356 - val_accuracy: 0.7436\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2863 - accuracy: 0.8667 - val_loss: 1.0451 - val_accuracy: 0.7436\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2885 - accuracy: 0.8667 - val_loss: 1.0325 - val_accuracy: 0.7350\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2854 - accuracy: 0.8667 - val_loss: 1.0180 - val_accuracy: 0.7350\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2838 - accuracy: 0.8630 - val_loss: 1.0139 - val_accuracy: 0.7350\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2850 - accuracy: 0.8704 - val_loss: 1.0117 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2887 - accuracy: 0.8704 - val_loss: 1.0096 - val_accuracy: 0.7350\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2869 - accuracy: 0.8704 - val_loss: 1.0192 - val_accuracy: 0.7350\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2836 - accuracy: 0.8667 - val_loss: 1.0314 - val_accuracy: 0.7350\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2848 - accuracy: 0.8667 - val_loss: 1.0350 - val_accuracy: 0.7350\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2856 - accuracy: 0.8630 - val_loss: 1.0241 - val_accuracy: 0.7436\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2845 - accuracy: 0.8704 - val_loss: 1.0175 - val_accuracy: 0.7350\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2840 - accuracy: 0.8667 - val_loss: 1.0293 - val_accuracy: 0.7350\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2833 - accuracy: 0.8630 - val_loss: 1.0262 - val_accuracy: 0.7350\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2844 - accuracy: 0.8704 - val_loss: 1.0358 - val_accuracy: 0.7350\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2845 - accuracy: 0.8667 - val_loss: 1.0455 - val_accuracy: 0.7350\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2844 - accuracy: 0.8667 - val_loss: 1.0449 - val_accuracy: 0.7350\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2844 - accuracy: 0.8667 - val_loss: 1.0327 - val_accuracy: 0.7521\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2836 - accuracy: 0.8519 - val_loss: 1.0254 - val_accuracy: 0.7436\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2840 - accuracy: 0.8704 - val_loss: 1.0252 - val_accuracy: 0.7436\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2832 - accuracy: 0.8704 - val_loss: 1.0314 - val_accuracy: 0.7436\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2822 - accuracy: 0.8704 - val_loss: 1.0433 - val_accuracy: 0.7436\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2831 - accuracy: 0.8667 - val_loss: 1.0420 - val_accuracy: 0.7350\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2842 - accuracy: 0.8667 - val_loss: 1.0331 - val_accuracy: 0.7521\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2831 - accuracy: 0.8593 - val_loss: 1.0265 - val_accuracy: 0.7521\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2836 - accuracy: 0.8481 - val_loss: 1.0276 - val_accuracy: 0.7350\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2841 - accuracy: 0.8704 - val_loss: 1.0242 - val_accuracy: 0.7436\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2827 - accuracy: 0.8704 - val_loss: 1.0280 - val_accuracy: 0.7436\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2823 - accuracy: 0.8741 - val_loss: 1.0341 - val_accuracy: 0.7436\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2819 - accuracy: 0.8704 - val_loss: 1.0284 - val_accuracy: 0.7350\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2820 - accuracy: 0.8667 - val_loss: 1.0270 - val_accuracy: 0.7350\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2813 - accuracy: 0.8704 - val_loss: 1.0261 - val_accuracy: 0.7350\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2812 - accuracy: 0.8704 - val_loss: 1.0246 - val_accuracy: 0.7350\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2803 - accuracy: 0.8741 - val_loss: 1.0193 - val_accuracy: 0.7521\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2823 - accuracy: 0.8556 - val_loss: 1.0205 - val_accuracy: 0.7521\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2832 - accuracy: 0.8519 - val_loss: 1.0417 - val_accuracy: 0.7436\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2817 - accuracy: 0.8667 - val_loss: 1.0445 - val_accuracy: 0.7436\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2813 - accuracy: 0.8667 - val_loss: 1.0371 - val_accuracy: 0.7436\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2808 - accuracy: 0.8704 - val_loss: 1.0292 - val_accuracy: 0.7436\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2806 - accuracy: 0.8704 - val_loss: 1.0257 - val_accuracy: 0.7521\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2813 - accuracy: 0.8630 - val_loss: 1.0310 - val_accuracy: 0.7521\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2814 - accuracy: 0.8556 - val_loss: 1.0410 - val_accuracy: 0.7521\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2818 - accuracy: 0.8593 - val_loss: 1.0311 - val_accuracy: 0.7521\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2814 - accuracy: 0.8556 - val_loss: 1.0276 - val_accuracy: 0.7350\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2802 - accuracy: 0.8667 - val_loss: 1.0255 - val_accuracy: 0.7350\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2799 - accuracy: 0.8667 - val_loss: 1.0267 - val_accuracy: 0.7350\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2801 - accuracy: 0.8667 - val_loss: 1.0284 - val_accuracy: 0.7350\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2807 - accuracy: 0.8556 - val_loss: 1.0408 - val_accuracy: 0.7436\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2801 - accuracy: 0.8704 - val_loss: 1.0468 - val_accuracy: 0.7436\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2816 - accuracy: 0.8704 - val_loss: 1.0460 - val_accuracy: 0.7436\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2803 - accuracy: 0.8667 - val_loss: 1.0403 - val_accuracy: 0.7436\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2790 - accuracy: 0.8704 - val_loss: 1.0274 - val_accuracy: 0.7350\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2806 - accuracy: 0.8593 - val_loss: 1.0239 - val_accuracy: 0.7521\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2836 - accuracy: 0.8630 - val_loss: 1.0273 - val_accuracy: 0.7607\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2799 - accuracy: 0.8741 - val_loss: 1.0572 - val_accuracy: 0.7436\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2876 - accuracy: 0.8667 - val_loss: 1.0777 - val_accuracy: 0.7436\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2846 - accuracy: 0.8667 - val_loss: 1.0483 - val_accuracy: 0.7436\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2799 - accuracy: 0.8704 - val_loss: 1.0257 - val_accuracy: 0.7350\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2788 - accuracy: 0.8704 - val_loss: 1.0147 - val_accuracy: 0.7350\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2792 - accuracy: 0.8704 - val_loss: 1.0221 - val_accuracy: 0.7350\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2806 - accuracy: 0.8704 - val_loss: 1.0392 - val_accuracy: 0.7350\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2807 - accuracy: 0.8667 - val_loss: 1.0435 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2789 - accuracy: 0.8704 - val_loss: 1.0374 - val_accuracy: 0.7436\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2790 - accuracy: 0.8704 - val_loss: 1.0406 - val_accuracy: 0.7436\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2792 - accuracy: 0.8667 - val_loss: 1.0589 - val_accuracy: 0.7436\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2808 - accuracy: 0.8667 - val_loss: 1.0616 - val_accuracy: 0.7436\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2776 - accuracy: 0.8704 - val_loss: 1.0435 - val_accuracy: 0.7436\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2777 - accuracy: 0.8667 - val_loss: 1.0422 - val_accuracy: 0.7436\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2775 - accuracy: 0.8704 - val_loss: 1.0481 - val_accuracy: 0.7436\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2779 - accuracy: 0.8704 - val_loss: 1.0425 - val_accuracy: 0.7436\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2784 - accuracy: 0.8704 - val_loss: 1.0409 - val_accuracy: 0.7350\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2796 - accuracy: 0.8704 - val_loss: 1.0297 - val_accuracy: 0.7265\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2811 - accuracy: 0.8704 - val_loss: 1.0441 - val_accuracy: 0.7436\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2793 - accuracy: 0.8667 - val_loss: 1.0590 - val_accuracy: 0.7436\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2802 - accuracy: 0.8667 - val_loss: 1.0597 - val_accuracy: 0.7350\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2812 - accuracy: 0.8667 - val_loss: 1.0548 - val_accuracy: 0.7436\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2784 - accuracy: 0.8667 - val_loss: 1.0402 - val_accuracy: 0.7436\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2786 - accuracy: 0.8778 - val_loss: 1.0326 - val_accuracy: 0.7436\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2816 - accuracy: 0.8704 - val_loss: 1.0428 - val_accuracy: 0.7436\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2774 - accuracy: 0.8704 - val_loss: 1.0543 - val_accuracy: 0.7436\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2777 - accuracy: 0.8741 - val_loss: 1.0676 - val_accuracy: 0.7436\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2779 - accuracy: 0.8704 - val_loss: 1.0621 - val_accuracy: 0.7436\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2784 - accuracy: 0.8630 - val_loss: 1.0621 - val_accuracy: 0.7436\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2778 - accuracy: 0.8704 - val_loss: 1.0551 - val_accuracy: 0.7436\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2778 - accuracy: 0.8667 - val_loss: 1.0423 - val_accuracy: 0.7436\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2777 - accuracy: 0.8704 - val_loss: 1.0430 - val_accuracy: 0.7436\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2773 - accuracy: 0.8704 - val_loss: 1.0456 - val_accuracy: 0.7436\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2759 - accuracy: 0.8667 - val_loss: 1.0684 - val_accuracy: 0.7436\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2781 - accuracy: 0.8704 - val_loss: 1.0704 - val_accuracy: 0.7436\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2791 - accuracy: 0.8667 - val_loss: 1.0570 - val_accuracy: 0.7265\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2782 - accuracy: 0.8667 - val_loss: 1.0522 - val_accuracy: 0.7265\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2780 - accuracy: 0.8704 - val_loss: 1.0475 - val_accuracy: 0.7436\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2761 - accuracy: 0.8704 - val_loss: 1.0553 - val_accuracy: 0.7436\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2766 - accuracy: 0.8704 - val_loss: 1.0672 - val_accuracy: 0.7436\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2764 - accuracy: 0.8704 - val_loss: 1.0636 - val_accuracy: 0.7436\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2762 - accuracy: 0.8630 - val_loss: 1.0606 - val_accuracy: 0.7436\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2745 - accuracy: 0.8704 - val_loss: 1.0593 - val_accuracy: 0.7436\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.90 - 0s 59us/step - loss: 0.2776 - accuracy: 0.8704 - val_loss: 1.0605 - val_accuracy: 0.7436\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2778 - accuracy: 0.8741 - val_loss: 1.0745 - val_accuracy: 0.7436\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2775 - accuracy: 0.8704 - val_loss: 1.0736 - val_accuracy: 0.7436\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2766 - accuracy: 0.8704 - val_loss: 1.0642 - val_accuracy: 0.7436\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2763 - accuracy: 0.8704 - val_loss: 1.0681 - val_accuracy: 0.7436\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2770 - accuracy: 0.8704 - val_loss: 1.0595 - val_accuracy: 0.7436\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2770 - accuracy: 0.8704 - val_loss: 1.0455 - val_accuracy: 0.7436\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2845 - accuracy: 0.8704 - val_loss: 1.0414 - val_accuracy: 0.7436\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2833 - accuracy: 0.8704 - val_loss: 1.0500 - val_accuracy: 0.7436\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2771 - accuracy: 0.8704 - val_loss: 1.0685 - val_accuracy: 0.7436\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2762 - accuracy: 0.8630 - val_loss: 1.1050 - val_accuracy: 0.7436\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2838 - accuracy: 0.8667 - val_loss: 1.1122 - val_accuracy: 0.7436\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2849 - accuracy: 0.8667 - val_loss: 1.0887 - val_accuracy: 0.7436\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2798 - accuracy: 0.8704 - val_loss: 1.0616 - val_accuracy: 0.7436\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2750 - accuracy: 0.8630 - val_loss: 1.0551 - val_accuracy: 0.7350\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2744 - accuracy: 0.8704 - val_loss: 1.0635 - val_accuracy: 0.7350\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2741 - accuracy: 0.8704 - val_loss: 1.0690 - val_accuracy: 0.7350\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2744 - accuracy: 0.8704 - val_loss: 1.0722 - val_accuracy: 0.7436\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2758 - accuracy: 0.8704 - val_loss: 1.0839 - val_accuracy: 0.7436\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2750 - accuracy: 0.8704 - val_loss: 1.0786 - val_accuracy: 0.7436\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2745 - accuracy: 0.8704 - val_loss: 1.0724 - val_accuracy: 0.7436\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2736 - accuracy: 0.8704 - val_loss: 1.0643 - val_accuracy: 0.7436\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2735 - accuracy: 0.8704 - val_loss: 1.0693 - val_accuracy: 0.7436\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2745 - accuracy: 0.8704 - val_loss: 1.0697 - val_accuracy: 0.7436\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2756 - accuracy: 0.8704 - val_loss: 1.0641 - val_accuracy: 0.7436\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2742 - accuracy: 0.8704 - val_loss: 1.0641 - val_accuracy: 0.7436\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2729 - accuracy: 0.8704 - val_loss: 1.0625 - val_accuracy: 0.7436\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2737 - accuracy: 0.8704 - val_loss: 1.0777 - val_accuracy: 0.7436\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2754 - accuracy: 0.8704 - val_loss: 1.0893 - val_accuracy: 0.7436\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2763 - accuracy: 0.8704 - val_loss: 1.0800 - val_accuracy: 0.7350\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2761 - accuracy: 0.8667 - val_loss: 1.0749 - val_accuracy: 0.7350\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2748 - accuracy: 0.8704 - val_loss: 1.0687 - val_accuracy: 0.7350\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2738 - accuracy: 0.8741 - val_loss: 1.0593 - val_accuracy: 0.7350\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2739 - accuracy: 0.8704 - val_loss: 1.0562 - val_accuracy: 0.7436\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2735 - accuracy: 0.8704 - val_loss: 1.0667 - val_accuracy: 0.7436\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2753 - accuracy: 0.8704 - val_loss: 1.0866 - val_accuracy: 0.7436\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2750 - accuracy: 0.8704 - val_loss: 1.0765 - val_accuracy: 0.7436\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2727 - accuracy: 0.8704 - val_loss: 1.0676 - val_accuracy: 0.7436\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2730 - accuracy: 0.8704 - val_loss: 1.0635 - val_accuracy: 0.7436\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2737 - accuracy: 0.8704 - val_loss: 1.0672 - val_accuracy: 0.7436\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2739 - accuracy: 0.8704 - val_loss: 1.0796 - val_accuracy: 0.7436\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2760 - accuracy: 0.8704 - val_loss: 1.0867 - val_accuracy: 0.7436\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2732 - accuracy: 0.8704 - val_loss: 1.0665 - val_accuracy: 0.7436\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2773 - accuracy: 0.8630 - val_loss: 1.0628 - val_accuracy: 0.7350\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2740 - accuracy: 0.8704 - val_loss: 1.0746 - val_accuracy: 0.7350\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2728 - accuracy: 0.8704 - val_loss: 1.0870 - val_accuracy: 0.7350\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2731 - accuracy: 0.8741 - val_loss: 1.0949 - val_accuracy: 0.7350\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2742 - accuracy: 0.8667 - val_loss: 1.0895 - val_accuracy: 0.7436\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2735 - accuracy: 0.8704 - val_loss: 1.0791 - val_accuracy: 0.7436\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2760 - accuracy: 0.8630 - val_loss: 1.0737 - val_accuracy: 0.7607\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2727 - accuracy: 0.8667 - val_loss: 1.0881 - val_accuracy: 0.7436\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2725 - accuracy: 0.8741 - val_loss: 1.1084 - val_accuracy: 0.7436\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2730 - accuracy: 0.8704 - val_loss: 1.0962 - val_accuracy: 0.7436\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2723 - accuracy: 0.8704 - val_loss: 1.0781 - val_accuracy: 0.7436\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2752 - accuracy: 0.8704 - val_loss: 1.0684 - val_accuracy: 0.7350\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2741 - accuracy: 0.8704 - val_loss: 1.0721 - val_accuracy: 0.7350\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2726 - accuracy: 0.8704 - val_loss: 1.0833 - val_accuracy: 0.7350\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 1.0921 - val_accuracy: 0.7436\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2719 - accuracy: 0.8704 - val_loss: 1.1092 - val_accuracy: 0.7436\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2741 - accuracy: 0.8704 - val_loss: 1.0999 - val_accuracy: 0.7436\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2737 - accuracy: 0.8667 - val_loss: 1.0786 - val_accuracy: 0.7350\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2714 - accuracy: 0.8704 - val_loss: 1.0736 - val_accuracy: 0.7350\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2723 - accuracy: 0.8704 - val_loss: 1.0813 - val_accuracy: 0.7350\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2710 - accuracy: 0.8704 - val_loss: 1.0921 - val_accuracy: 0.7436\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2732 - accuracy: 0.8704 - val_loss: 1.1179 - val_accuracy: 0.7436\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2739 - accuracy: 0.8704 - val_loss: 1.1266 - val_accuracy: 0.7436\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2767 - accuracy: 0.8704 - val_loss: 1.1275 - val_accuracy: 0.7436\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2775 - accuracy: 0.8704 - val_loss: 1.1111 - val_accuracy: 0.7436\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2738 - accuracy: 0.8704 - val_loss: 1.0811 - val_accuracy: 0.7436\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2745 - accuracy: 0.8704 - val_loss: 1.0766 - val_accuracy: 0.7436\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2732 - accuracy: 0.8704 - val_loss: 1.0851 - val_accuracy: 0.7350\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2696 - accuracy: 0.8704 - val_loss: 1.0856 - val_accuracy: 0.7521\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2742 - accuracy: 0.8630 - val_loss: 1.0804 - val_accuracy: 0.7521\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2734 - accuracy: 0.8630 - val_loss: 1.0872 - val_accuracy: 0.7350\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2720 - accuracy: 0.8704 - val_loss: 1.0957 - val_accuracy: 0.7436\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2767 - accuracy: 0.8704 - val_loss: 1.1096 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2725 - accuracy: 0.8704 - val_loss: 1.0911 - val_accuracy: 0.7350\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2741 - accuracy: 0.8667 - val_loss: 1.0959 - val_accuracy: 0.7436\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2708 - accuracy: 0.8704 - val_loss: 1.1033 - val_accuracy: 0.7436\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2745 - accuracy: 0.8667 - val_loss: 1.1272 - val_accuracy: 0.7436\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2737 - accuracy: 0.8704 - val_loss: 1.1239 - val_accuracy: 0.7436\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2716 - accuracy: 0.8704 - val_loss: 1.0998 - val_accuracy: 0.7436\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2719 - accuracy: 0.8667 - val_loss: 1.0816 - val_accuracy: 0.7521\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2736 - accuracy: 0.8630 - val_loss: 1.0787 - val_accuracy: 0.7521\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2734 - accuracy: 0.8667 - val_loss: 1.0871 - val_accuracy: 0.7521\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2715 - accuracy: 0.8630 - val_loss: 1.0934 - val_accuracy: 0.7521\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2709 - accuracy: 0.8667 - val_loss: 1.1081 - val_accuracy: 0.7436\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2700 - accuracy: 0.8704 - val_loss: 1.1146 - val_accuracy: 0.7436\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2735 - accuracy: 0.8704 - val_loss: 1.0928 - val_accuracy: 0.7436\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2746 - accuracy: 0.8667 - val_loss: 1.0774 - val_accuracy: 0.7436\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2715 - accuracy: 0.8704 - val_loss: 1.0745 - val_accuracy: 0.7350\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2694 - accuracy: 0.8704 - val_loss: 1.0805 - val_accuracy: 0.7350\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2711 - accuracy: 0.8593 - val_loss: 1.0907 - val_accuracy: 0.7521\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2706 - accuracy: 0.8778 - val_loss: 1.0831 - val_accuracy: 0.7350\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2707 - accuracy: 0.8741 - val_loss: 1.0863 - val_accuracy: 0.7436\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2730 - accuracy: 0.8704 - val_loss: 1.0972 - val_accuracy: 0.7436\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2752 - accuracy: 0.8704 - val_loss: 1.0934 - val_accuracy: 0.7436\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2733 - accuracy: 0.8704 - val_loss: 1.0962 - val_accuracy: 0.7350\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2734 - accuracy: 0.8741 - val_loss: 1.1160 - val_accuracy: 0.7436\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 1.1054 - val_accuracy: 0.7436\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2716 - accuracy: 0.8704 - val_loss: 1.0952 - val_accuracy: 0.7436\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2706 - accuracy: 0.8704 - val_loss: 1.0900 - val_accuracy: 0.7436\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2686 - accuracy: 0.8741 - val_loss: 1.0952 - val_accuracy: 0.7436\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2709 - accuracy: 0.8704 - val_loss: 1.0964 - val_accuracy: 0.7436\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2723 - accuracy: 0.8704 - val_loss: 1.0798 - val_accuracy: 0.7350\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2693 - accuracy: 0.8704 - val_loss: 1.0751 - val_accuracy: 0.7350\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2692 - accuracy: 0.8704 - val_loss: 1.0790 - val_accuracy: 0.7350\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2703 - accuracy: 0.8704 - val_loss: 1.0885 - val_accuracy: 0.7521\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2689 - accuracy: 0.8741 - val_loss: 1.0997 - val_accuracy: 0.7350\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2717 - accuracy: 0.8704 - val_loss: 1.1160 - val_accuracy: 0.7350\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2699 - accuracy: 0.8704 - val_loss: 1.1001 - val_accuracy: 0.7350\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2683 - accuracy: 0.8704 - val_loss: 1.0866 - val_accuracy: 0.7350\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2698 - accuracy: 0.8630 - val_loss: 1.1001 - val_accuracy: 0.7521\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2692 - accuracy: 0.8593 - val_loss: 1.1121 - val_accuracy: 0.7350\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2703 - accuracy: 0.8667 - val_loss: 1.1063 - val_accuracy: 0.7350\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2713 - accuracy: 0.8630 - val_loss: 1.0887 - val_accuracy: 0.7521\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2700 - accuracy: 0.8630 - val_loss: 1.0939 - val_accuracy: 0.7521\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2698 - accuracy: 0.8630 - val_loss: 1.0980 - val_accuracy: 0.7521\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2722 - accuracy: 0.8630 - val_loss: 1.1192 - val_accuracy: 0.7521\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2724 - accuracy: 0.8630 - val_loss: 1.1155 - val_accuracy: 0.7521\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2696 - accuracy: 0.8630 - val_loss: 1.1113 - val_accuracy: 0.7350\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2677 - accuracy: 0.8704 - val_loss: 1.1056 - val_accuracy: 0.7436\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2687 - accuracy: 0.8667 - val_loss: 1.0990 - val_accuracy: 0.7521\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2686 - accuracy: 0.8630 - val_loss: 1.0984 - val_accuracy: 0.7521\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2732 - accuracy: 0.8630 - val_loss: 1.1059 - val_accuracy: 0.7521\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2725 - accuracy: 0.8630 - val_loss: 1.1073 - val_accuracy: 0.7521\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2708 - accuracy: 0.8593 - val_loss: 1.1079 - val_accuracy: 0.7436\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2671 - accuracy: 0.8704 - val_loss: 1.1175 - val_accuracy: 0.7436\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2690 - accuracy: 0.8704 - val_loss: 1.1211 - val_accuracy: 0.7436\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2718 - accuracy: 0.8704 - val_loss: 1.1146 - val_accuracy: 0.7350\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2707 - accuracy: 0.8704 - val_loss: 1.1064 - val_accuracy: 0.7350\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2687 - accuracy: 0.8704 - val_loss: 1.0964 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2676 - accuracy: 0.8704 - val_loss: 1.0904 - val_accuracy: 0.7350\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2676 - accuracy: 0.8667 - val_loss: 1.0959 - val_accuracy: 0.7350\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2677 - accuracy: 0.8704 - val_loss: 1.1123 - val_accuracy: 0.7350\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2680 - accuracy: 0.8704 - val_loss: 1.0975 - val_accuracy: 0.7350\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2679 - accuracy: 0.8704 - val_loss: 1.0913 - val_accuracy: 0.7350\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 1.0923 - val_accuracy: 0.7350\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2677 - accuracy: 0.8630 - val_loss: 1.0911 - val_accuracy: 0.7350\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.0897 - val_accuracy: 0.7350\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2682 - accuracy: 0.8704 - val_loss: 1.0890 - val_accuracy: 0.7350\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2689 - accuracy: 0.8704 - val_loss: 1.0943 - val_accuracy: 0.7350\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2689 - accuracy: 0.8741 - val_loss: 1.1100 - val_accuracy: 0.7350\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2693 - accuracy: 0.8593 - val_loss: 1.1224 - val_accuracy: 0.7350\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2692 - accuracy: 0.8704 - val_loss: 1.1225 - val_accuracy: 0.7350\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2684 - accuracy: 0.8704 - val_loss: 1.1146 - val_accuracy: 0.7350\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2664 - accuracy: 0.8704 - val_loss: 1.1075 - val_accuracy: 0.7521\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2684 - accuracy: 0.8630 - val_loss: 1.1024 - val_accuracy: 0.7521\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2673 - accuracy: 0.8630 - val_loss: 1.1034 - val_accuracy: 0.7350\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2683 - accuracy: 0.8667 - val_loss: 1.1163 - val_accuracy: 0.7607\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2693 - accuracy: 0.8704 - val_loss: 1.1245 - val_accuracy: 0.7350\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2714 - accuracy: 0.8704 - val_loss: 1.1258 - val_accuracy: 0.7350\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2704 - accuracy: 0.8704 - val_loss: 1.1059 - val_accuracy: 0.7350\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2664 - accuracy: 0.8704 - val_loss: 1.0952 - val_accuracy: 0.7350\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2674 - accuracy: 0.8704 - val_loss: 1.0970 - val_accuracy: 0.7350\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2687 - accuracy: 0.8704 - val_loss: 1.0955 - val_accuracy: 0.7350\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2749 - accuracy: 0.8704 - val_loss: 1.0919 - val_accuracy: 0.7350\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 1.1014 - val_accuracy: 0.7350\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2675 - accuracy: 0.8630 - val_loss: 1.1252 - val_accuracy: 0.7350\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2700 - accuracy: 0.8741 - val_loss: 1.1374 - val_accuracy: 0.7350\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2711 - accuracy: 0.8704 - val_loss: 1.1296 - val_accuracy: 0.7350\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2676 - accuracy: 0.8704 - val_loss: 1.1125 - val_accuracy: 0.7350\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2682 - accuracy: 0.8667 - val_loss: 1.1000 - val_accuracy: 0.7350\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2680 - accuracy: 0.8704 - val_loss: 1.0986 - val_accuracy: 0.7350\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2676 - accuracy: 0.8704 - val_loss: 1.1051 - val_accuracy: 0.7350\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 1.1126 - val_accuracy: 0.7350\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 1.1238 - val_accuracy: 0.7350\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2682 - accuracy: 0.8704 - val_loss: 1.1341 - val_accuracy: 0.7350\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2713 - accuracy: 0.8704 - val_loss: 1.1340 - val_accuracy: 0.7350\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2689 - accuracy: 0.8704 - val_loss: 1.1060 - val_accuracy: 0.7350\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2699 - accuracy: 0.8667 - val_loss: 1.0968 - val_accuracy: 0.7521\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2768 - accuracy: 0.8630 - val_loss: 1.0957 - val_accuracy: 0.7521\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2726 - accuracy: 0.8630 - val_loss: 1.1171 - val_accuracy: 0.7350\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2648 - accuracy: 0.8741 - val_loss: 1.1335 - val_accuracy: 0.7350\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2683 - accuracy: 0.8704 - val_loss: 1.1521 - val_accuracy: 0.7350\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2682 - accuracy: 0.8704 - val_loss: 1.1314 - val_accuracy: 0.7350\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2674 - accuracy: 0.8593 - val_loss: 1.1081 - val_accuracy: 0.7350\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2665 - accuracy: 0.8704 - val_loss: 1.1073 - val_accuracy: 0.7350\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2664 - accuracy: 0.8741 - val_loss: 1.1141 - val_accuracy: 0.7350\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2668 - accuracy: 0.8667 - val_loss: 1.1241 - val_accuracy: 0.7350\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2660 - accuracy: 0.8704 - val_loss: 1.1301 - val_accuracy: 0.7350\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2657 - accuracy: 0.8704 - val_loss: 1.1390 - val_accuracy: 0.7350\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2664 - accuracy: 0.8704 - val_loss: 1.1489 - val_accuracy: 0.7350\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2668 - accuracy: 0.8704 - val_loss: 1.1371 - val_accuracy: 0.7350\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 1.1254 - val_accuracy: 0.7350\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.1276 - val_accuracy: 0.7350\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2662 - accuracy: 0.8704 - val_loss: 1.1302 - val_accuracy: 0.7350\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.1376 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2670 - accuracy: 0.8630 - val_loss: 1.1412 - val_accuracy: 0.7350\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2666 - accuracy: 0.8704 - val_loss: 1.1368 - val_accuracy: 0.7350\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 1.1338 - val_accuracy: 0.7350\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2655 - accuracy: 0.8704 - val_loss: 1.1406 - val_accuracy: 0.7350\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2654 - accuracy: 0.8704 - val_loss: 1.1339 - val_accuracy: 0.7350\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2659 - accuracy: 0.8704 - val_loss: 1.1290 - val_accuracy: 0.7350\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 1.1306 - val_accuracy: 0.7350\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2643 - accuracy: 0.8741 - val_loss: 1.1268 - val_accuracy: 0.7521\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2671 - accuracy: 0.8630 - val_loss: 1.1257 - val_accuracy: 0.7521\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2675 - accuracy: 0.8593 - val_loss: 1.1401 - val_accuracy: 0.7350\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 1.1465 - val_accuracy: 0.7521\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2646 - accuracy: 0.8741 - val_loss: 1.1277 - val_accuracy: 0.7350\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1159 - val_accuracy: 0.7350\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 1.1132 - val_accuracy: 0.7350\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2653 - accuracy: 0.8481 - val_loss: 1.1173 - val_accuracy: 0.7521\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2668 - accuracy: 0.8667 - val_loss: 1.1256 - val_accuracy: 0.7521\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 1.1244 - val_accuracy: 0.7350\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2680 - accuracy: 0.8704 - val_loss: 1.1241 - val_accuracy: 0.7521\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2697 - accuracy: 0.8667 - val_loss: 1.1334 - val_accuracy: 0.7521\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2656 - accuracy: 0.8704 - val_loss: 1.1364 - val_accuracy: 0.7521\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2642 - accuracy: 0.8704 - val_loss: 1.1503 - val_accuracy: 0.7350\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2696 - accuracy: 0.8704 - val_loss: 1.1574 - val_accuracy: 0.7350\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2641 - accuracy: 0.8741 - val_loss: 1.1260 - val_accuracy: 0.7350\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2655 - accuracy: 0.8704 - val_loss: 1.1167 - val_accuracy: 0.7350\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2680 - accuracy: 0.8704 - val_loss: 1.1261 - val_accuracy: 0.7350\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2670 - accuracy: 0.8704 - val_loss: 1.1359 - val_accuracy: 0.7350\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 1.1419 - val_accuracy: 0.7350\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 1.1550 - val_accuracy: 0.7350\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2684 - accuracy: 0.8704 - val_loss: 1.1571 - val_accuracy: 0.7607\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2656 - accuracy: 0.8704 - val_loss: 1.1378 - val_accuracy: 0.7350\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2642 - accuracy: 0.8704 - val_loss: 1.1220 - val_accuracy: 0.7350\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 1.1217 - val_accuracy: 0.7521\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2660 - accuracy: 0.8556 - val_loss: 1.1288 - val_accuracy: 0.7350\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 1.1331 - val_accuracy: 0.7350\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2659 - accuracy: 0.8704 - val_loss: 1.1227 - val_accuracy: 0.7350\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2657 - accuracy: 0.8593 - val_loss: 1.1312 - val_accuracy: 0.7350\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2662 - accuracy: 0.8630 - val_loss: 1.1417 - val_accuracy: 0.7436\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.1550 - val_accuracy: 0.7521\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2665 - accuracy: 0.8704 - val_loss: 1.1417 - val_accuracy: 0.7521\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2663 - accuracy: 0.8704 - val_loss: 1.1348 - val_accuracy: 0.7436\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.1423 - val_accuracy: 0.7436\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 1.1518 - val_accuracy: 0.7436\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 1.1511 - val_accuracy: 0.7436\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2669 - accuracy: 0.8704 - val_loss: 1.1590 - val_accuracy: 0.7436\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2657 - accuracy: 0.8704 - val_loss: 1.1472 - val_accuracy: 0.7436\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2634 - accuracy: 0.8704 - val_loss: 1.1326 - val_accuracy: 0.7436\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2659 - accuracy: 0.8704 - val_loss: 1.1267 - val_accuracy: 0.7436\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2643 - accuracy: 0.8704 - val_loss: 1.1330 - val_accuracy: 0.7350\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2662 - accuracy: 0.8593 - val_loss: 1.1383 - val_accuracy: 0.7350\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 1.1434 - val_accuracy: 0.7436\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 1.1423 - val_accuracy: 0.7436\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2638 - accuracy: 0.8704 - val_loss: 1.1536 - val_accuracy: 0.7436\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2634 - accuracy: 0.8704 - val_loss: 1.1563 - val_accuracy: 0.7436\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2648 - accuracy: 0.8704 - val_loss: 1.1534 - val_accuracy: 0.7436\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1406 - val_accuracy: 0.7436\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2644 - accuracy: 0.8704 - val_loss: 1.1501 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2669 - accuracy: 0.8704 - val_loss: 1.1492 - val_accuracy: 0.7436\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 1.1440 - val_accuracy: 0.7350\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2637 - accuracy: 0.8704 - val_loss: 1.1580 - val_accuracy: 0.7350\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2660 - accuracy: 0.8704 - val_loss: 1.1590 - val_accuracy: 0.7350\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.1466 - val_accuracy: 0.7350\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2645 - accuracy: 0.8704 - val_loss: 1.1381 - val_accuracy: 0.7521\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2663 - accuracy: 0.8630 - val_loss: 1.1235 - val_accuracy: 0.7521\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2675 - accuracy: 0.8519 - val_loss: 1.1296 - val_accuracy: 0.7521\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2641 - accuracy: 0.8593 - val_loss: 1.1313 - val_accuracy: 0.7436\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.1354 - val_accuracy: 0.7521\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2671 - accuracy: 0.8704 - val_loss: 1.1345 - val_accuracy: 0.7521\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 1.1282 - val_accuracy: 0.7436\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.1202 - val_accuracy: 0.7521\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 1.1215 - val_accuracy: 0.7521\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2694 - accuracy: 0.8630 - val_loss: 1.1246 - val_accuracy: 0.7436\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2646 - accuracy: 0.8704 - val_loss: 1.1516 - val_accuracy: 0.7521\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2651 - accuracy: 0.8704 - val_loss: 1.1442 - val_accuracy: 0.7436\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1415 - val_accuracy: 0.7436\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2625 - accuracy: 0.8741 - val_loss: 1.1585 - val_accuracy: 0.7436\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2655 - accuracy: 0.8704 - val_loss: 1.1602 - val_accuracy: 0.7436\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2651 - accuracy: 0.8704 - val_loss: 1.1520 - val_accuracy: 0.7436\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.1470 - val_accuracy: 0.7436\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 1.1368 - val_accuracy: 0.7607\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 1.1381 - val_accuracy: 0.7521\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 1.1411 - val_accuracy: 0.7436\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1530 - val_accuracy: 0.7521\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2640 - accuracy: 0.8593 - val_loss: 1.1607 - val_accuracy: 0.7521\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2625 - accuracy: 0.8741 - val_loss: 1.1489 - val_accuracy: 0.7436\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1448 - val_accuracy: 0.7350\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1500 - val_accuracy: 0.7436\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.1577 - val_accuracy: 0.7436\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2634 - accuracy: 0.8704 - val_loss: 1.1614 - val_accuracy: 0.7436\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2631 - accuracy: 0.8704 - val_loss: 1.1623 - val_accuracy: 0.7436\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 382us/step - loss: 0.2625 - accuracy: 0.8704 - val_loss: 1.1716 - val_accuracy: 0.7350\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2647 - accuracy: 0.8704 - val_loss: 1.1575 - val_accuracy: 0.7521\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2633 - accuracy: 0.8593 - val_loss: 1.1543 - val_accuracy: 0.7521\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2652 - accuracy: 0.8630 - val_loss: 1.1559 - val_accuracy: 0.7607\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 1.1670 - val_accuracy: 0.7436\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2615 - accuracy: 0.8593 - val_loss: 1.1749 - val_accuracy: 0.7521\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.1901 - val_accuracy: 0.7436\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2684 - accuracy: 0.8704 - val_loss: 1.1926 - val_accuracy: 0.7436\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2648 - accuracy: 0.8704 - val_loss: 1.1671 - val_accuracy: 0.7436\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2589 - accuracy: 0.8741 - val_loss: 1.1342 - val_accuracy: 0.7521\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 1.1274 - val_accuracy: 0.7521\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2691 - accuracy: 0.8630 - val_loss: 1.1422 - val_accuracy: 0.7521\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2665 - accuracy: 0.8741 - val_loss: 1.1692 - val_accuracy: 0.7436\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.1770 - val_accuracy: 0.7436\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 1.1697 - val_accuracy: 0.7436\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.1515 - val_accuracy: 0.7436\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2638 - accuracy: 0.8704 - val_loss: 1.1423 - val_accuracy: 0.7436\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2645 - accuracy: 0.8704 - val_loss: 1.1474 - val_accuracy: 0.7436\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 1.1558 - val_accuracy: 0.7436\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2620 - accuracy: 0.8741 - val_loss: 1.1617 - val_accuracy: 0.7436\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2650 - accuracy: 0.8556 - val_loss: 1.1654 - val_accuracy: 0.7436\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 1.1688 - val_accuracy: 0.7436\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2619 - accuracy: 0.8704 - val_loss: 1.1590 - val_accuracy: 0.7436\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2618 - accuracy: 0.8741 - val_loss: 1.1609 - val_accuracy: 0.7521\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2642 - accuracy: 0.8630 - val_loss: 1.1730 - val_accuracy: 0.7436\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.1673 - val_accuracy: 0.7521\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 609us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 1.1492 - val_accuracy: 0.7436\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.2625 - accuracy: 0.8704 - val_loss: 1.1471 - val_accuracy: 0.7436\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 334us/step - loss: 0.2627 - accuracy: 0.8704 - val_loss: 1.1527 - val_accuracy: 0.7436\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 1.1679 - val_accuracy: 0.7521\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 1.1725 - val_accuracy: 0.7521\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 1.1709 - val_accuracy: 0.7436\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2646 - accuracy: 0.8704 - val_loss: 1.1648 - val_accuracy: 0.7436\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 1.1451 - val_accuracy: 0.7436\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2640 - accuracy: 0.8481 - val_loss: 1.1446 - val_accuracy: 0.7436\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 1.1435 - val_accuracy: 0.7436\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 1.1525 - val_accuracy: 0.7521\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2692 - accuracy: 0.8630 - val_loss: 1.1590 - val_accuracy: 0.7436\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.1600 - val_accuracy: 0.7436\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.1548 - val_accuracy: 0.7436\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2615 - accuracy: 0.8741 - val_loss: 1.1456 - val_accuracy: 0.7436\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.1567 - val_accuracy: 0.7436\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1534 - val_accuracy: 0.7436\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.1575 - val_accuracy: 0.7436\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.2627 - accuracy: 0.8704 - val_loss: 1.1621 - val_accuracy: 0.7436\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 1.1529 - val_accuracy: 0.7436\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 291us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1570 - val_accuracy: 0.7436\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.1566 - val_accuracy: 0.7436\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.1535 - val_accuracy: 0.7436\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.1474 - val_accuracy: 0.7436\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 1.1540 - val_accuracy: 0.7436\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 1.1605 - val_accuracy: 0.7436\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.1643 - val_accuracy: 0.7436\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.1702 - val_accuracy: 0.7436\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2622 - accuracy: 0.8704 - val_loss: 1.1660 - val_accuracy: 0.7436\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2609 - accuracy: 0.8593 - val_loss: 1.1668 - val_accuracy: 0.7436\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.1654 - val_accuracy: 0.7436\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.1754 - val_accuracy: 0.7436\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2609 - accuracy: 0.8593 - val_loss: 1.1747 - val_accuracy: 0.7521\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.1621 - val_accuracy: 0.7521\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.1550 - val_accuracy: 0.7521\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 1.1594 - val_accuracy: 0.7521\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2596 - accuracy: 0.8741 - val_loss: 1.1792 - val_accuracy: 0.7521\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2653 - accuracy: 0.8630 - val_loss: 1.2026 - val_accuracy: 0.7179\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2669 - accuracy: 0.8593 - val_loss: 1.1862 - val_accuracy: 0.7521\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2611 - accuracy: 0.8704 - val_loss: 1.1655 - val_accuracy: 0.7436\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 1.1585 - val_accuracy: 0.7436\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2635 - accuracy: 0.8593 - val_loss: 1.1474 - val_accuracy: 0.7607\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2669 - accuracy: 0.8481 - val_loss: 1.1613 - val_accuracy: 0.7436\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.84 - 0s 108us/step - loss: 0.2651 - accuracy: 0.8704 - val_loss: 1.1885 - val_accuracy: 0.7436\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 1.1963 - val_accuracy: 0.7521\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2641 - accuracy: 0.8667 - val_loss: 1.1939 - val_accuracy: 0.7607\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 1.1726 - val_accuracy: 0.7607\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.87 - 0s 76us/step - loss: 0.2638 - accuracy: 0.8741 - val_loss: 1.1567 - val_accuracy: 0.7521\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2648 - accuracy: 0.8704 - val_loss: 1.1717 - val_accuracy: 0.7521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a32dbdd30>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 64us/step\n",
      "over-sampling test accuracy: 75.21%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over = model2_over.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 1,\n",
       "       0, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0, 2, 0, 0, 2, 2, 1, 1,\n",
       "       1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0, 0, 1, 1, 0, 2, 1, 2, 0, 0,\n",
       "       2, 1, 0, 2, 2, 1, 0, 1, 2, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 1, 0,\n",
       "       1, 0, 0, 2, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 0, 1, 0, 1, 0, 1,\n",
       "       2, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model2_over.predict_classes(X_sel_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBRSa51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS245     1     1\n",
       "1          NY439     2     2\n",
       "2          CA544     1     1\n",
       "3          CA541     2     1\n",
       "4          EUH15     1     1\n",
       "..           ...   ...   ...\n",
       "112       NRS112     0     0\n",
       "113     CFBRSa51     2     1\n",
       "114       NRS383     1     0\n",
       "115       NRS247     0     0\n",
       "116  CFBREBSa103     0     0\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model2_over.predict_proba(X_sel_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113622</td>\n",
       "      <td>0.870446</td>\n",
       "      <td>0.015932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052619</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.946505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100919</td>\n",
       "      <td>0.583063</td>\n",
       "      <td>0.316018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100919</td>\n",
       "      <td>0.583063</td>\n",
       "      <td>0.316018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.346191</td>\n",
       "      <td>0.644950</td>\n",
       "      <td>0.008858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.909846</td>\n",
       "      <td>0.089374</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.100919</td>\n",
       "      <td>0.583063</td>\n",
       "      <td>0.316018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.909846</td>\n",
       "      <td>0.089374</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.960853</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.999575</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.113622  0.870446  0.015932\n",
       "1    0.052619  0.000876  0.946505\n",
       "2    0.100919  0.583063  0.316018\n",
       "3    0.100919  0.583063  0.316018\n",
       "4    0.346191  0.644950  0.008858\n",
       "..        ...       ...       ...\n",
       "112  0.909846  0.089374  0.000780\n",
       "113  0.100919  0.583063  0.316018\n",
       "114  0.909846  0.089374  0.000780\n",
       "115  0.960853  0.039130  0.000017\n",
       "116  0.999575  0.000419  0.000005\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2655 - accuracy: 0.8778 - val_loss: 1.2036 - val_accuracy: 0.7607\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 1.2063 - val_accuracy: 0.7607\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 1.2027 - val_accuracy: 0.7607\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 1.2005 - val_accuracy: 0.7607\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2648 - accuracy: 0.8704 - val_loss: 1.1975 - val_accuracy: 0.7607\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.2035 - val_accuracy: 0.7607\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2643 - accuracy: 0.8704 - val_loss: 1.1977 - val_accuracy: 0.7607\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2627 - accuracy: 0.8704 - val_loss: 1.1901 - val_accuracy: 0.7607\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2627 - accuracy: 0.8704 - val_loss: 1.1939 - val_accuracy: 0.7607\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.1980 - val_accuracy: 0.7607\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 1.2025 - val_accuracy: 0.7607\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 1.1987 - val_accuracy: 0.7607\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1978 - val_accuracy: 0.7607\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2637 - accuracy: 0.8704 - val_loss: 1.2117 - val_accuracy: 0.7607\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2677 - accuracy: 0.8667 - val_loss: 1.2268 - val_accuracy: 0.7436\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2692 - accuracy: 0.8667 - val_loss: 1.2108 - val_accuracy: 0.7436\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 1.1882 - val_accuracy: 0.7521\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 1.1794 - val_accuracy: 0.7521\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 1.1792 - val_accuracy: 0.7521\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.1760 - val_accuracy: 0.7521\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 1.1701 - val_accuracy: 0.7607\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2684 - accuracy: 0.8593 - val_loss: 1.1674 - val_accuracy: 0.7778\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2701 - accuracy: 0.8630 - val_loss: 1.1707 - val_accuracy: 0.7778\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2677 - accuracy: 0.8630 - val_loss: 1.1893 - val_accuracy: 0.7521\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2662 - accuracy: 0.8704 - val_loss: 1.1952 - val_accuracy: 0.7521\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2671 - accuracy: 0.8667 - val_loss: 1.1990 - val_accuracy: 0.7607\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 31us/step - loss: 0.2647 - accuracy: 0.8593 - val_loss: 1.2093 - val_accuracy: 0.7607\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2642 - accuracy: 0.8704 - val_loss: 1.2010 - val_accuracy: 0.7607\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 1.1961 - val_accuracy: 0.7607\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2646 - accuracy: 0.8704 - val_loss: 1.1985 - val_accuracy: 0.7607\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.2117 - val_accuracy: 0.7607\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 36us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.2118 - val_accuracy: 0.7607\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2627 - accuracy: 0.8704 - val_loss: 1.2094 - val_accuracy: 0.7607\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 1.2147 - val_accuracy: 0.7607\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 32us/step - loss: 0.2638 - accuracy: 0.8704 - val_loss: 1.2054 - val_accuracy: 0.7607\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 1.2004 - val_accuracy: 0.7607\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2643 - accuracy: 0.8704 - val_loss: 1.1791 - val_accuracy: 0.7607\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 1.1798 - val_accuracy: 0.7607\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 31us/step - loss: 0.2660 - accuracy: 0.8630 - val_loss: 1.1844 - val_accuracy: 0.7607\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2636 - accuracy: 0.8667 - val_loss: 1.1851 - val_accuracy: 0.7607\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 1.1919 - val_accuracy: 0.7607\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2610 - accuracy: 0.8704 - val_loss: 1.2020 - val_accuracy: 0.7521\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.2050 - val_accuracy: 0.7607\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 1.2070 - val_accuracy: 0.7607\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 35us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.2043 - val_accuracy: 0.7607\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2659 - accuracy: 0.8593 - val_loss: 1.1933 - val_accuracy: 0.7607\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2657 - accuracy: 0.8704 - val_loss: 1.1942 - val_accuracy: 0.7607\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 33us/step - loss: 0.2658 - accuracy: 0.8704 - val_loss: 1.1939 - val_accuracy: 0.7607\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.1949 - val_accuracy: 0.7607\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2668 - accuracy: 0.8593 - val_loss: 1.2050 - val_accuracy: 0.7521\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 34us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 1.1991 - val_accuracy: 0.7521\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 1.1953 - val_accuracy: 0.7607\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 1.1995 - val_accuracy: 0.7607\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.1954 - val_accuracy: 0.7607\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 1.1988 - val_accuracy: 0.7778\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 1.1962 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2641 - accuracy: 0.8519 - val_loss: 1.1957 - val_accuracy: 0.7607\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1994 - val_accuracy: 0.7521\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2651 - accuracy: 0.8704 - val_loss: 1.2114 - val_accuracy: 0.7521\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2654 - accuracy: 0.8704 - val_loss: 1.2125 - val_accuracy: 0.7607\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2626 - accuracy: 0.8704 - val_loss: 1.2161 - val_accuracy: 0.7607\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.2081 - val_accuracy: 0.7607\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 1.2006 - val_accuracy: 0.7607\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 1.2098 - val_accuracy: 0.7607\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2630 - accuracy: 0.8741 - val_loss: 1.2224 - val_accuracy: 0.7521\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 1.2301 - val_accuracy: 0.7521\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 1.2161 - val_accuracy: 0.7607\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.2113 - val_accuracy: 0.7607\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2647 - accuracy: 0.8519 - val_loss: 1.2061 - val_accuracy: 0.7778\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2634 - accuracy: 0.8593 - val_loss: 1.1987 - val_accuracy: 0.7607\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.1916 - val_accuracy: 0.7607\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2658 - accuracy: 0.8630 - val_loss: 1.1948 - val_accuracy: 0.7607\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 1.2024 - val_accuracy: 0.7607\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 1.2082 - val_accuracy: 0.7607\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2610 - accuracy: 0.8704 - val_loss: 1.2162 - val_accuracy: 0.7607\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 1.2260 - val_accuracy: 0.7607\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2623 - accuracy: 0.8630 - val_loss: 1.2172 - val_accuracy: 0.7607\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 1.2084 - val_accuracy: 0.7607\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.2091 - val_accuracy: 0.7607\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2631 - accuracy: 0.8704 - val_loss: 1.2223 - val_accuracy: 0.7778\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2637 - accuracy: 0.8407 - val_loss: 1.2300 - val_accuracy: 0.7436\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 1.2238 - val_accuracy: 0.7607\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.2126 - val_accuracy: 0.7607\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2634 - accuracy: 0.8741 - val_loss: 1.1959 - val_accuracy: 0.7607\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 1.1938 - val_accuracy: 0.7607\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 1.1983 - val_accuracy: 0.7607\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2612 - accuracy: 0.8704 - val_loss: 1.2078 - val_accuracy: 0.7607\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.2179 - val_accuracy: 0.7607\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 1.2273 - val_accuracy: 0.7607\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 1.2269 - val_accuracy: 0.7607\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2622 - accuracy: 0.8704 - val_loss: 1.2215 - val_accuracy: 0.7607\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 1.2095 - val_accuracy: 0.7607\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2652 - accuracy: 0.8593 - val_loss: 1.2006 - val_accuracy: 0.7778\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2616 - accuracy: 0.8741 - val_loss: 1.2138 - val_accuracy: 0.7607\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 1.2166 - val_accuracy: 0.7607\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.2113 - val_accuracy: 0.7778\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2647 - accuracy: 0.8630 - val_loss: 1.2108 - val_accuracy: 0.7607\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 1.2313 - val_accuracy: 0.7436\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2683 - accuracy: 0.8370 - val_loss: 1.2339 - val_accuracy: 0.7265\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 1.2146 - val_accuracy: 0.7607\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2638 - accuracy: 0.8593 - val_loss: 1.1967 - val_accuracy: 0.7607\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 1.2029 - val_accuracy: 0.7607\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 1.2090 - val_accuracy: 0.7607\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.2053 - val_accuracy: 0.7607\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 1.2037 - val_accuracy: 0.7607\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2632 - accuracy: 0.8741 - val_loss: 1.2117 - val_accuracy: 0.7778\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2635 - accuracy: 0.8593 - val_loss: 1.2103 - val_accuracy: 0.7607\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2638 - accuracy: 0.8593 - val_loss: 1.2116 - val_accuracy: 0.7778\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2643 - accuracy: 0.8630 - val_loss: 1.2129 - val_accuracy: 0.7778\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 1.2126 - val_accuracy: 0.7607\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 1.2048 - val_accuracy: 0.7607\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 1.2061 - val_accuracy: 0.7607\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 89us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.2103 - val_accuracy: 0.7607\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.2112 - val_accuracy: 0.7607\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 1.2177 - val_accuracy: 0.7607\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.2270 - val_accuracy: 0.7607\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2595 - accuracy: 0.8593 - val_loss: 1.2148 - val_accuracy: 0.7607\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2622 - accuracy: 0.8704 - val_loss: 1.2074 - val_accuracy: 0.7607\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2619 - accuracy: 0.8704 - val_loss: 1.2085 - val_accuracy: 0.7607\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.2136 - val_accuracy: 0.7607\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2619 - accuracy: 0.8704 - val_loss: 1.2146 - val_accuracy: 0.7607\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.2298 - val_accuracy: 0.7607\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.2344 - val_accuracy: 0.7607\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2635 - accuracy: 0.8741 - val_loss: 1.2399 - val_accuracy: 0.7607\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 1.2252 - val_accuracy: 0.7607\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2640 - accuracy: 0.8593 - val_loss: 1.2161 - val_accuracy: 0.7607\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.2218 - val_accuracy: 0.7607\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2622 - accuracy: 0.8630 - val_loss: 1.2386 - val_accuracy: 0.7521\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2671 - accuracy: 0.8704 - val_loss: 1.2393 - val_accuracy: 0.7521\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2701 - accuracy: 0.8704 - val_loss: 1.2246 - val_accuracy: 0.7521\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 1.2185 - val_accuracy: 0.7607\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2635 - accuracy: 0.8704 - val_loss: 1.2211 - val_accuracy: 0.7778\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 1.2178 - val_accuracy: 0.7778\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2633 - accuracy: 0.8556 - val_loss: 1.2174 - val_accuracy: 0.7607\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.2169 - val_accuracy: 0.7778\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 448us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 1.2101 - val_accuracy: 0.7778\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2624 - accuracy: 0.8852 - val_loss: 1.2191 - val_accuracy: 0.7607\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 1.2328 - val_accuracy: 0.7521\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 367us/step - loss: 0.2636 - accuracy: 0.8704 - val_loss: 1.2351 - val_accuracy: 0.7607\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.2311 - val_accuracy: 0.7778\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.78 - 0s 113us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 1.2264 - val_accuracy: 0.7778\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 1.2190 - val_accuracy: 0.7778\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 1.2207 - val_accuracy: 0.7607\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.2364 - val_accuracy: 0.7607\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2626 - accuracy: 0.8704 - val_loss: 1.2398 - val_accuracy: 0.7607\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.2375 - val_accuracy: 0.7607\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 1.2411 - val_accuracy: 0.7607\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2597 - accuracy: 0.8704 - val_loss: 1.2451 - val_accuracy: 0.7607\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 1.2448 - val_accuracy: 0.7607\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 322us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.2420 - val_accuracy: 0.7607\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2598 - accuracy: 0.8778 - val_loss: 1.2370 - val_accuracy: 0.7607\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.2333 - val_accuracy: 0.7521\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 1.2389 - val_accuracy: 0.7607\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.2477 - val_accuracy: 0.7607\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 1.2560 - val_accuracy: 0.7607\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.2642 - val_accuracy: 0.7607\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2607 - accuracy: 0.8630 - val_loss: 1.2646 - val_accuracy: 0.7607\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2615 - accuracy: 0.8593 - val_loss: 1.2609 - val_accuracy: 0.7778\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2620 - accuracy: 0.8630 - val_loss: 1.2555 - val_accuracy: 0.7778\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2605 - accuracy: 0.8630 - val_loss: 1.2472 - val_accuracy: 0.7607\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.2394 - val_accuracy: 0.7607\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 1.2448 - val_accuracy: 0.7521\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 1.2490 - val_accuracy: 0.7521\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2624 - accuracy: 0.8593 - val_loss: 1.2539 - val_accuracy: 0.7607\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.2658 - val_accuracy: 0.7778\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2641 - accuracy: 0.8593 - val_loss: 1.2552 - val_accuracy: 0.7778\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 1.2578 - val_accuracy: 0.7778\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2627 - accuracy: 0.8593 - val_loss: 1.2702 - val_accuracy: 0.7607\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 1.2729 - val_accuracy: 0.7607\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.2660 - val_accuracy: 0.7607\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 1.2549 - val_accuracy: 0.7607\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2606 - accuracy: 0.8741 - val_loss: 1.2517 - val_accuracy: 0.7607\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.2551 - val_accuracy: 0.7607\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2617 - accuracy: 0.8593 - val_loss: 1.2521 - val_accuracy: 0.7778\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 1.2545 - val_accuracy: 0.7692\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2638 - accuracy: 0.8741 - val_loss: 1.2594 - val_accuracy: 0.7607\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.2514 - val_accuracy: 0.7521\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2603 - accuracy: 0.8704 - val_loss: 1.2441 - val_accuracy: 0.7607\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2600 - accuracy: 0.8630 - val_loss: 1.2437 - val_accuracy: 0.7607\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 372us/step - loss: 0.2585 - accuracy: 0.8741 - val_loss: 1.2550 - val_accuracy: 0.7607\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.2586 - val_accuracy: 0.7607\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 1.2644 - val_accuracy: 0.7607\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2601 - accuracy: 0.8704 - val_loss: 1.2608 - val_accuracy: 0.7607\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 1.2593 - val_accuracy: 0.7607\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.2599 - val_accuracy: 0.7607\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2642 - accuracy: 0.8741 - val_loss: 1.2619 - val_accuracy: 0.7607\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 1.2633 - val_accuracy: 0.7607\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2606 - accuracy: 0.8704 - val_loss: 1.2635 - val_accuracy: 0.7607\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.2630 - val_accuracy: 0.7607\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 1.2694 - val_accuracy: 0.7521\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 1.2692 - val_accuracy: 0.7607\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.2539 - val_accuracy: 0.7607\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2594 - accuracy: 0.8704 - val_loss: 1.2459 - val_accuracy: 0.7607\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2607 - accuracy: 0.8593 - val_loss: 1.2513 - val_accuracy: 0.7607\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2636 - accuracy: 0.8667 - val_loss: 1.2580 - val_accuracy: 0.7607\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 1.2615 - val_accuracy: 0.7607\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 1.2713 - val_accuracy: 0.7607\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 1.2742 - val_accuracy: 0.7607\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2623 - accuracy: 0.8704 - val_loss: 1.2700 - val_accuracy: 0.7607\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2618 - accuracy: 0.8593 - val_loss: 1.2747 - val_accuracy: 0.7607\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2597 - accuracy: 0.8630 - val_loss: 1.2720 - val_accuracy: 0.7607\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2618 - accuracy: 0.8741 - val_loss: 1.2774 - val_accuracy: 0.7521\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2649 - accuracy: 0.8704 - val_loss: 1.2755 - val_accuracy: 0.7521\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 1.2644 - val_accuracy: 0.7521\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.2590 - val_accuracy: 0.7521\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.2535 - val_accuracy: 0.7607\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2675 - accuracy: 0.8630 - val_loss: 1.2519 - val_accuracy: 0.7778\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2652 - accuracy: 0.8630 - val_loss: 1.2582 - val_accuracy: 0.7607\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2607 - accuracy: 0.8704 - val_loss: 1.2624 - val_accuracy: 0.7521\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2610 - accuracy: 0.8704 - val_loss: 1.2618 - val_accuracy: 0.7607\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2588 - accuracy: 0.8741 - val_loss: 1.2580 - val_accuracy: 0.7607\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2610 - accuracy: 0.8704 - val_loss: 1.2582 - val_accuracy: 0.7607\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 1.2670 - val_accuracy: 0.7778\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 1.2702 - val_accuracy: 0.7607\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.2738 - val_accuracy: 0.7607\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 1.2714 - val_accuracy: 0.7607\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 1.2677 - val_accuracy: 0.7607\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2601 - accuracy: 0.8704 - val_loss: 1.2600 - val_accuracy: 0.7607\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 429us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.2628 - val_accuracy: 0.7607\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.2669 - val_accuracy: 0.7607\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 384us/step - loss: 0.2599 - accuracy: 0.8704 - val_loss: 1.2712 - val_accuracy: 0.7607\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2613 - accuracy: 0.8704 - val_loss: 1.2754 - val_accuracy: 0.7607\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2611 - accuracy: 0.8704 - val_loss: 1.2667 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.2622 - val_accuracy: 0.7607\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2599 - accuracy: 0.8704 - val_loss: 1.2603 - val_accuracy: 0.7607\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.2580 - val_accuracy: 0.7607\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 1.2640 - val_accuracy: 0.7778\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2594 - accuracy: 0.8630 - val_loss: 1.2759 - val_accuracy: 0.7607\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2622 - accuracy: 0.8704 - val_loss: 1.2824 - val_accuracy: 0.7607\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.2687 - val_accuracy: 0.7521\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 1.2575 - val_accuracy: 0.7607\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.2626 - val_accuracy: 0.7607\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2660 - accuracy: 0.8704 - val_loss: 1.2811 - val_accuracy: 0.7607\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 1.2674 - val_accuracy: 0.7521\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2625 - accuracy: 0.8704 - val_loss: 1.2533 - val_accuracy: 0.7521\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 1.2413 - val_accuracy: 0.7607\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2619 - accuracy: 0.8704 - val_loss: 1.2454 - val_accuracy: 0.7778\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2660 - accuracy: 0.8630 - val_loss: 1.2525 - val_accuracy: 0.7778\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2607 - accuracy: 0.8593 - val_loss: 1.2633 - val_accuracy: 0.7607\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2583 - accuracy: 0.8704 - val_loss: 1.2665 - val_accuracy: 0.7607\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 1.2641 - val_accuracy: 0.7607\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 1.2612 - val_accuracy: 0.7607\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.2589 - val_accuracy: 0.7607\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 1.2501 - val_accuracy: 0.7778\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2619 - accuracy: 0.8519 - val_loss: 1.2475 - val_accuracy: 0.7607\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2603 - accuracy: 0.8519 - val_loss: 1.2553 - val_accuracy: 0.7778\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2592 - accuracy: 0.8667 - val_loss: 1.2645 - val_accuracy: 0.7607\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.2823 - val_accuracy: 0.7607\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 1.2861 - val_accuracy: 0.7607\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2623 - accuracy: 0.8704 - val_loss: 1.2908 - val_accuracy: 0.7436\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 1.2885 - val_accuracy: 0.7436\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 1.2818 - val_accuracy: 0.7607\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 1.2713 - val_accuracy: 0.7607\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2580 - accuracy: 0.8704 - val_loss: 1.2764 - val_accuracy: 0.7607\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.2799 - val_accuracy: 0.7607\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.2803 - val_accuracy: 0.7607\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 1.2716 - val_accuracy: 0.7607\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2598 - accuracy: 0.8593 - val_loss: 1.2740 - val_accuracy: 0.7607\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2583 - accuracy: 0.8741 - val_loss: 1.2653 - val_accuracy: 0.7778\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2600 - accuracy: 0.8630 - val_loss: 1.2684 - val_accuracy: 0.7778\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2607 - accuracy: 0.8630 - val_loss: 1.2668 - val_accuracy: 0.7778\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2597 - accuracy: 0.8630 - val_loss: 1.2700 - val_accuracy: 0.7778\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2591 - accuracy: 0.8593 - val_loss: 1.2812 - val_accuracy: 0.7607\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2594 - accuracy: 0.8704 - val_loss: 1.2827 - val_accuracy: 0.7607\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.2848 - val_accuracy: 0.7521\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2694 - accuracy: 0.8704 - val_loss: 1.2803 - val_accuracy: 0.7521\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2689 - accuracy: 0.8704 - val_loss: 1.2714 - val_accuracy: 0.7521\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 1.2733 - val_accuracy: 0.7778\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2610 - accuracy: 0.8630 - val_loss: 1.2803 - val_accuracy: 0.7778\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2604 - accuracy: 0.8630 - val_loss: 1.2782 - val_accuracy: 0.7607\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2625 - accuracy: 0.8704 - val_loss: 1.2843 - val_accuracy: 0.7607\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2584 - accuracy: 0.8667 - val_loss: 1.2838 - val_accuracy: 0.7607\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.2937 - val_accuracy: 0.7607\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2595 - accuracy: 0.8630 - val_loss: 1.2983 - val_accuracy: 0.7607\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2594 - accuracy: 0.8704 - val_loss: 1.3006 - val_accuracy: 0.7607\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2583 - accuracy: 0.8704 - val_loss: 1.2883 - val_accuracy: 0.7607\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.2857 - val_accuracy: 0.7607\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.2778 - val_accuracy: 0.7607\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.2753 - val_accuracy: 0.7607\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2592 - accuracy: 0.8704 - val_loss: 1.2806 - val_accuracy: 0.7607\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2588 - accuracy: 0.8741 - val_loss: 1.2931 - val_accuracy: 0.7607\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2583 - accuracy: 0.8741 - val_loss: 1.2896 - val_accuracy: 0.7521\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.2828 - val_accuracy: 0.7607\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 1.2896 - val_accuracy: 0.7778\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2597 - accuracy: 0.8630 - val_loss: 1.2879 - val_accuracy: 0.7778\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2591 - accuracy: 0.8630 - val_loss: 1.2891 - val_accuracy: 0.7778\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2584 - accuracy: 0.8519 - val_loss: 1.2849 - val_accuracy: 0.7607\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2578 - accuracy: 0.8741 - val_loss: 1.2848 - val_accuracy: 0.7521\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.2817 - val_accuracy: 0.7521\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2585 - accuracy: 0.8704 - val_loss: 1.2787 - val_accuracy: 0.7521\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.2690 - val_accuracy: 0.7521\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.2695 - val_accuracy: 0.7521\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.2775 - val_accuracy: 0.7521\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2585 - accuracy: 0.8667 - val_loss: 1.2848 - val_accuracy: 0.7607\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.2846 - val_accuracy: 0.7607\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.2865 - val_accuracy: 0.7607\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.2877 - val_accuracy: 0.7607\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2583 - accuracy: 0.8704 - val_loss: 1.2907 - val_accuracy: 0.7607\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2590 - accuracy: 0.8593 - val_loss: 1.2942 - val_accuracy: 0.7607\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2577 - accuracy: 0.8667 - val_loss: 1.3011 - val_accuracy: 0.7521\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2626 - accuracy: 0.8704 - val_loss: 1.3186 - val_accuracy: 0.7521\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2655 - accuracy: 0.8704 - val_loss: 1.3070 - val_accuracy: 0.7607\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 358us/step - loss: 0.2563 - accuracy: 0.8741 - val_loss: 1.2927 - val_accuracy: 0.7778\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 1.2884 - val_accuracy: 0.7778\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 1.2898 - val_accuracy: 0.7607\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2588 - accuracy: 0.8741 - val_loss: 1.3036 - val_accuracy: 0.7521\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2606 - accuracy: 0.8704 - val_loss: 1.3063 - val_accuracy: 0.7521\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.2951 - val_accuracy: 0.7521\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2587 - accuracy: 0.8704 - val_loss: 1.2906 - val_accuracy: 0.7521\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.2867 - val_accuracy: 0.7607\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.2801 - val_accuracy: 0.7607\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2593 - accuracy: 0.8630 - val_loss: 1.2805 - val_accuracy: 0.7521\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.2878 - val_accuracy: 0.7521\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 1.2993 - val_accuracy: 0.7521\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3072 - val_accuracy: 0.7521\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.3057 - val_accuracy: 0.7521\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.3004 - val_accuracy: 0.7521\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.2972 - val_accuracy: 0.7607\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3020 - val_accuracy: 0.7607\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3035 - val_accuracy: 0.7607\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2607 - accuracy: 0.8704 - val_loss: 1.3017 - val_accuracy: 0.7607\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 1.3067 - val_accuracy: 0.7607\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.3139 - val_accuracy: 0.7607\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.3226 - val_accuracy: 0.7436\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2600 - accuracy: 0.8630 - val_loss: 1.3174 - val_accuracy: 0.7607\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 1.3039 - val_accuracy: 0.7778\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2599 - accuracy: 0.8593 - val_loss: 1.3102 - val_accuracy: 0.7778\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3112 - val_accuracy: 0.7607\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2599 - accuracy: 0.8704 - val_loss: 1.3097 - val_accuracy: 0.7607\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3123 - val_accuracy: 0.7607\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2586 - accuracy: 0.8741 - val_loss: 1.3030 - val_accuracy: 0.7607\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2598 - accuracy: 0.8741 - val_loss: 1.3002 - val_accuracy: 0.7607\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2603 - accuracy: 0.8704 - val_loss: 1.3099 - val_accuracy: 0.7607\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 101us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3136 - val_accuracy: 0.7607\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2571 - accuracy: 0.8778 - val_loss: 1.3113 - val_accuracy: 0.7607\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.3088 - val_accuracy: 0.7607\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.3204 - val_accuracy: 0.7607\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2591 - accuracy: 0.8704 - val_loss: 1.3163 - val_accuracy: 0.7607\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3029 - val_accuracy: 0.7607\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2603 - accuracy: 0.8704 - val_loss: 1.3004 - val_accuracy: 0.7607\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 1.3056 - val_accuracy: 0.7607\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2585 - accuracy: 0.8704 - val_loss: 1.3108 - val_accuracy: 0.7607\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 244us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.3105 - val_accuracy: 0.7607\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2591 - accuracy: 0.8704 - val_loss: 1.2997 - val_accuracy: 0.7607\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.3005 - val_accuracy: 0.7607\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3029 - val_accuracy: 0.7607\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3174 - val_accuracy: 0.7521\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2587 - accuracy: 0.8741 - val_loss: 1.3232 - val_accuracy: 0.7607\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2591 - accuracy: 0.8741 - val_loss: 1.3233 - val_accuracy: 0.7607\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2607 - accuracy: 0.8704 - val_loss: 1.3251 - val_accuracy: 0.7607\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 1.3345 - val_accuracy: 0.7436\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2595 - accuracy: 0.8667 - val_loss: 1.3232 - val_accuracy: 0.7607\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.3107 - val_accuracy: 0.7607\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.3026 - val_accuracy: 0.7607\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2587 - accuracy: 0.8704 - val_loss: 1.3119 - val_accuracy: 0.7521\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 1.3218 - val_accuracy: 0.7521\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.3172 - val_accuracy: 0.7607\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3137 - val_accuracy: 0.7607\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3130 - val_accuracy: 0.7778\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2582 - accuracy: 0.8630 - val_loss: 1.3227 - val_accuracy: 0.7607\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2568 - accuracy: 0.8667 - val_loss: 1.3300 - val_accuracy: 0.7350\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3289 - val_accuracy: 0.7350\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3131 - val_accuracy: 0.7521\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2608 - accuracy: 0.8667 - val_loss: 1.3099 - val_accuracy: 0.7521\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2571 - accuracy: 0.8741 - val_loss: 1.3194 - val_accuracy: 0.7521\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.3341 - val_accuracy: 0.7436\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 1.3395 - val_accuracy: 0.7436\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 1.3344 - val_accuracy: 0.7778\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 1.3205 - val_accuracy: 0.7778\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 1.3178 - val_accuracy: 0.7607\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3151 - val_accuracy: 0.7521\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 1.3085 - val_accuracy: 0.7607\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 1.3108 - val_accuracy: 0.7607\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2570 - accuracy: 0.8630 - val_loss: 1.3273 - val_accuracy: 0.7607\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.3278 - val_accuracy: 0.7607\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2603 - accuracy: 0.8704 - val_loss: 1.3215 - val_accuracy: 0.7607\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.3064 - val_accuracy: 0.7607\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3054 - val_accuracy: 0.7607\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.3057 - val_accuracy: 0.7607\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2586 - accuracy: 0.8667 - val_loss: 1.3141 - val_accuracy: 0.7607\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.3213 - val_accuracy: 0.7607\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.3317 - val_accuracy: 0.7607\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 1.3325 - val_accuracy: 0.7778\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2652 - accuracy: 0.8333 - val_loss: 1.3547 - val_accuracy: 0.7179\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2636 - accuracy: 0.8481 - val_loss: 1.3394 - val_accuracy: 0.7350\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3204 - val_accuracy: 0.7521\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.3081 - val_accuracy: 0.7521\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2585 - accuracy: 0.8667 - val_loss: 1.3067 - val_accuracy: 0.7607\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3092 - val_accuracy: 0.7607\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.3119 - val_accuracy: 0.7778\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2581 - accuracy: 0.8630 - val_loss: 1.3273 - val_accuracy: 0.7607\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 1.3409 - val_accuracy: 0.7521\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2590 - accuracy: 0.8704 - val_loss: 1.3324 - val_accuracy: 0.7521\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3227 - val_accuracy: 0.7778\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2582 - accuracy: 0.8630 - val_loss: 1.3231 - val_accuracy: 0.7778\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2584 - accuracy: 0.8444 - val_loss: 1.3191 - val_accuracy: 0.7521\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3172 - val_accuracy: 0.7521\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3215 - val_accuracy: 0.7521\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 1.3338 - val_accuracy: 0.7521\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2619 - accuracy: 0.8704 - val_loss: 1.3328 - val_accuracy: 0.7521\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 1.3181 - val_accuracy: 0.7521\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3127 - val_accuracy: 0.7521\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3161 - val_accuracy: 0.7521\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.3242 - val_accuracy: 0.7521\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3281 - val_accuracy: 0.7521\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2591 - accuracy: 0.8630 - val_loss: 1.3202 - val_accuracy: 0.7521\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 297us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3260 - val_accuracy: 0.7607\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2560 - accuracy: 0.8741 - val_loss: 1.3204 - val_accuracy: 0.7607\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.3255 - val_accuracy: 0.7607\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3308 - val_accuracy: 0.7607\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.3300 - val_accuracy: 0.7521\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.3217 - val_accuracy: 0.7521\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2556 - accuracy: 0.8667 - val_loss: 1.3096 - val_accuracy: 0.7521\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 1.3126 - val_accuracy: 0.7521\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 1.3138 - val_accuracy: 0.7521\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2597 - accuracy: 0.8667 - val_loss: 1.3189 - val_accuracy: 0.7521\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2572 - accuracy: 0.8667 - val_loss: 1.3270 - val_accuracy: 0.7521\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2578 - accuracy: 0.8667 - val_loss: 1.3411 - val_accuracy: 0.7692\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2597 - accuracy: 0.8593 - val_loss: 1.3444 - val_accuracy: 0.7521\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3341 - val_accuracy: 0.7521\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3426 - val_accuracy: 0.7521\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2595 - accuracy: 0.8444 - val_loss: 1.3507 - val_accuracy: 0.7521\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2587 - accuracy: 0.8704 - val_loss: 1.3479 - val_accuracy: 0.7521\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.3397 - val_accuracy: 0.7521\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.3324 - val_accuracy: 0.7521\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 383us/step - loss: 0.2573 - accuracy: 0.8667 - val_loss: 1.3309 - val_accuracy: 0.7607\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3309 - val_accuracy: 0.7521\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2587 - accuracy: 0.8704 - val_loss: 1.3426 - val_accuracy: 0.7521\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.3414 - val_accuracy: 0.7521\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3371 - val_accuracy: 0.7521\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2563 - accuracy: 0.8704 - val_loss: 1.3310 - val_accuracy: 0.7521\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.3251 - val_accuracy: 0.7778\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2598 - accuracy: 0.8630 - val_loss: 1.3302 - val_accuracy: 0.7778\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2594 - accuracy: 0.8519 - val_loss: 1.3361 - val_accuracy: 0.7607\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3432 - val_accuracy: 0.7607\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2577 - accuracy: 0.8667 - val_loss: 1.3464 - val_accuracy: 0.7607\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.3443 - val_accuracy: 0.7521\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2568 - accuracy: 0.8741 - val_loss: 1.3367 - val_accuracy: 0.7521\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 1.3324 - val_accuracy: 0.7607\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2584 - accuracy: 0.8741 - val_loss: 1.3290 - val_accuracy: 0.7778\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2599 - accuracy: 0.8630 - val_loss: 1.3310 - val_accuracy: 0.7778\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2575 - accuracy: 0.8667 - val_loss: 1.3363 - val_accuracy: 0.7607\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2563 - accuracy: 0.8667 - val_loss: 1.3335 - val_accuracy: 0.7607\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.3329 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2602 - accuracy: 0.8630 - val_loss: 1.3343 - val_accuracy: 0.7607\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2580 - accuracy: 0.8667 - val_loss: 1.3493 - val_accuracy: 0.7607\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2575 - accuracy: 0.8741 - val_loss: 1.3720 - val_accuracy: 0.7350\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 1.3776 - val_accuracy: 0.7350\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 1.3688 - val_accuracy: 0.7607\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2592 - accuracy: 0.8704 - val_loss: 1.3551 - val_accuracy: 0.7607\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.3481 - val_accuracy: 0.7607\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.3411 - val_accuracy: 0.7521\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2584 - accuracy: 0.8667 - val_loss: 1.3467 - val_accuracy: 0.7521\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2571 - accuracy: 0.8778 - val_loss: 1.3429 - val_accuracy: 0.7521\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 1.3472 - val_accuracy: 0.7521\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.3434 - val_accuracy: 0.7521\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3449 - val_accuracy: 0.7521\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3550 - val_accuracy: 0.7350\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2577 - accuracy: 0.8667 - val_loss: 1.3630 - val_accuracy: 0.7350\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3649 - val_accuracy: 0.7607\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.3707 - val_accuracy: 0.7607\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.3713 - val_accuracy: 0.7521\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 1.3735 - val_accuracy: 0.7521\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 1.3747 - val_accuracy: 0.7778\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 1.3744 - val_accuracy: 0.7778\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 1.3725 - val_accuracy: 0.7778\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 1.3644 - val_accuracy: 0.7607\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 1.3517 - val_accuracy: 0.7521\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2569 - accuracy: 0.8667 - val_loss: 1.3397 - val_accuracy: 0.7607\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.3334 - val_accuracy: 0.7607\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2585 - accuracy: 0.8704 - val_loss: 1.3325 - val_accuracy: 0.7607\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3382 - val_accuracy: 0.7607\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 1.3384 - val_accuracy: 0.7607\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.3477 - val_accuracy: 0.7607\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.3453 - val_accuracy: 0.7607\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.2597 - accuracy: 0.8704 - val_loss: 1.3427 - val_accuracy: 0.7607\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.3405 - val_accuracy: 0.7607\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.3505 - val_accuracy: 0.7607\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 1.3669 - val_accuracy: 0.7521\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 1.3768 - val_accuracy: 0.7607\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2600 - accuracy: 0.8704 - val_loss: 1.3700 - val_accuracy: 0.7607\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 1.3579 - val_accuracy: 0.7607\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3606 - val_accuracy: 0.7607\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3620 - val_accuracy: 0.7607\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3569 - val_accuracy: 0.7521\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2563 - accuracy: 0.8704 - val_loss: 1.3543 - val_accuracy: 0.7607\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2567 - accuracy: 0.8667 - val_loss: 1.3522 - val_accuracy: 0.7607\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2572 - accuracy: 0.8630 - val_loss: 1.3598 - val_accuracy: 0.7778\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2582 - accuracy: 0.8481 - val_loss: 1.3634 - val_accuracy: 0.7607\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.3701 - val_accuracy: 0.7607\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2580 - accuracy: 0.8593 - val_loss: 1.3747 - val_accuracy: 0.7778\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2580 - accuracy: 0.8556 - val_loss: 1.3701 - val_accuracy: 0.7607\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2547 - accuracy: 0.8704 - val_loss: 1.3597 - val_accuracy: 0.7521\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.3590 - val_accuracy: 0.7521\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2612 - accuracy: 0.8704 - val_loss: 1.3690 - val_accuracy: 0.7521\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2582 - accuracy: 0.8704 - val_loss: 1.3660 - val_accuracy: 0.7521\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2555 - accuracy: 0.8704 - val_loss: 1.3623 - val_accuracy: 0.7521\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2566 - accuracy: 0.8667 - val_loss: 1.3652 - val_accuracy: 0.7521\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.3748 - val_accuracy: 0.7521\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3705 - val_accuracy: 0.7521\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3607 - val_accuracy: 0.7521\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.3533 - val_accuracy: 0.7521\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.3474 - val_accuracy: 0.7607\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2582 - accuracy: 0.8630 - val_loss: 1.3434 - val_accuracy: 0.7521\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.3440 - val_accuracy: 0.7521\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2572 - accuracy: 0.8667 - val_loss: 1.3456 - val_accuracy: 0.7607\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 1.3516 - val_accuracy: 0.7521\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.3557 - val_accuracy: 0.7521\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2571 - accuracy: 0.8667 - val_loss: 1.3629 - val_accuracy: 0.7607\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.3583 - val_accuracy: 0.7607\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.3590 - val_accuracy: 0.7607\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2572 - accuracy: 0.8481 - val_loss: 1.3613 - val_accuracy: 0.7778\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2567 - accuracy: 0.8630 - val_loss: 1.3646 - val_accuracy: 0.7607\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2557 - accuracy: 0.8704 - val_loss: 1.3671 - val_accuracy: 0.7521\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.3634 - val_accuracy: 0.7521\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2557 - accuracy: 0.8704 - val_loss: 1.3552 - val_accuracy: 0.7607\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3509 - val_accuracy: 0.7778\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.3521 - val_accuracy: 0.7778\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2563 - accuracy: 0.8630 - val_loss: 1.3600 - val_accuracy: 0.7607\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2552 - accuracy: 0.8741 - val_loss: 1.3761 - val_accuracy: 0.7350\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2586 - accuracy: 0.8630 - val_loss: 1.3806 - val_accuracy: 0.7436\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2579 - accuracy: 0.8667 - val_loss: 1.3665 - val_accuracy: 0.7521\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.3587 - val_accuracy: 0.7607\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3550 - val_accuracy: 0.7607\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2589 - accuracy: 0.8630 - val_loss: 1.3480 - val_accuracy: 0.7778\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2585 - accuracy: 0.8667 - val_loss: 1.3512 - val_accuracy: 0.7607\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2547 - accuracy: 0.8704 - val_loss: 1.3714 - val_accuracy: 0.7521\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.3747 - val_accuracy: 0.7521\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3579 - val_accuracy: 0.7521\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2557 - accuracy: 0.8556 - val_loss: 1.3509 - val_accuracy: 0.7778\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2590 - accuracy: 0.8593 - val_loss: 1.3562 - val_accuracy: 0.7778\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2617 - accuracy: 0.8630 - val_loss: 1.3633 - val_accuracy: 0.7778\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2575 - accuracy: 0.8556 - val_loss: 1.3700 - val_accuracy: 0.7521\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3693 - val_accuracy: 0.7521\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.3606 - val_accuracy: 0.7521\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 1.3532 - val_accuracy: 0.7778\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2647 - accuracy: 0.8630 - val_loss: 1.3598 - val_accuracy: 0.7778\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3754 - val_accuracy: 0.7607\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.3905 - val_accuracy: 0.7607\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2570 - accuracy: 0.8667 - val_loss: 1.3821 - val_accuracy: 0.7607\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2544 - accuracy: 0.8741 - val_loss: 1.3835 - val_accuracy: 0.7607\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2571 - accuracy: 0.8630 - val_loss: 1.3904 - val_accuracy: 0.7607\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3875 - val_accuracy: 0.7607\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2555 - accuracy: 0.8704 - val_loss: 1.3778 - val_accuracy: 0.7607\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3663 - val_accuracy: 0.7607\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2601 - accuracy: 0.8704 - val_loss: 1.3661 - val_accuracy: 0.7521\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2599 - accuracy: 0.8667 - val_loss: 1.3809 - val_accuracy: 0.7521\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.3788 - val_accuracy: 0.7521\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2535 - accuracy: 0.8741 - val_loss: 1.3743 - val_accuracy: 0.7607\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2561 - accuracy: 0.8741 - val_loss: 1.3697 - val_accuracy: 0.7778\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 1.3756 - val_accuracy: 0.7778\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2593 - accuracy: 0.8593 - val_loss: 1.3852 - val_accuracy: 0.7607\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2555 - accuracy: 0.8704 - val_loss: 1.3822 - val_accuracy: 0.7607\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2581 - accuracy: 0.8667 - val_loss: 1.3840 - val_accuracy: 0.7607\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2571 - accuracy: 0.8741 - val_loss: 1.3927 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2592 - accuracy: 0.8630 - val_loss: 1.3938 - val_accuracy: 0.7778\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.4009 - val_accuracy: 0.7607\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2555 - accuracy: 0.8667 - val_loss: 1.4006 - val_accuracy: 0.7521\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2568 - accuracy: 0.8630 - val_loss: 1.4039 - val_accuracy: 0.7350\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 1.4016 - val_accuracy: 0.7436\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.3805 - val_accuracy: 0.7607\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.3794 - val_accuracy: 0.7521\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2592 - accuracy: 0.8630 - val_loss: 1.3945 - val_accuracy: 0.7521\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2568 - accuracy: 0.8667 - val_loss: 1.3942 - val_accuracy: 0.7521\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2550 - accuracy: 0.8741 - val_loss: 1.3844 - val_accuracy: 0.7607\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2571 - accuracy: 0.8667 - val_loss: 1.3786 - val_accuracy: 0.7607\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.3805 - val_accuracy: 0.7607\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2564 - accuracy: 0.8667 - val_loss: 1.3836 - val_accuracy: 0.7607\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2554 - accuracy: 0.8741 - val_loss: 1.3810 - val_accuracy: 0.7607\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.3835 - val_accuracy: 0.7607\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.3882 - val_accuracy: 0.7607\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.3895 - val_accuracy: 0.7607\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2570 - accuracy: 0.8667 - val_loss: 1.3821 - val_accuracy: 0.7607\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.3837 - val_accuracy: 0.7607\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.3847 - val_accuracy: 0.7607\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2579 - accuracy: 0.8630 - val_loss: 1.3999 - val_accuracy: 0.7607\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.4044 - val_accuracy: 0.7607\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.4045 - val_accuracy: 0.7607\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2563 - accuracy: 0.8704 - val_loss: 1.4026 - val_accuracy: 0.7607\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.3997 - val_accuracy: 0.7607\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4037 - val_accuracy: 0.7607\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4109 - val_accuracy: 0.7607\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.4122 - val_accuracy: 0.7607\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.3992 - val_accuracy: 0.7607\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 1.3889 - val_accuracy: 0.7607\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.3903 - val_accuracy: 0.7607\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.2606 - accuracy: 0.8704 - val_loss: 1.4088 - val_accuracy: 0.7521\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2597 - accuracy: 0.8667 - val_loss: 1.3938 - val_accuracy: 0.7521\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2555 - accuracy: 0.8667 - val_loss: 1.3856 - val_accuracy: 0.7607\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2577 - accuracy: 0.8630 - val_loss: 1.3898 - val_accuracy: 0.7778\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2593 - accuracy: 0.8593 - val_loss: 1.3985 - val_accuracy: 0.7778\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.4130 - val_accuracy: 0.7521\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2582 - accuracy: 0.8704 - val_loss: 1.4011 - val_accuracy: 0.7521\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.3910 - val_accuracy: 0.7521\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2561 - accuracy: 0.8667 - val_loss: 1.3836 - val_accuracy: 0.7607\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.3826 - val_accuracy: 0.7607\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2594 - accuracy: 0.8667 - val_loss: 1.3852 - val_accuracy: 0.7521\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.3915 - val_accuracy: 0.7607\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.89 - 0s 148us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.4005 - val_accuracy: 0.7607\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.4058 - val_accuracy: 0.7607\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.3923 - val_accuracy: 0.7607\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2569 - accuracy: 0.8630 - val_loss: 1.3848 - val_accuracy: 0.7778\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2581 - accuracy: 0.8630 - val_loss: 1.3839 - val_accuracy: 0.7607\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.3970 - val_accuracy: 0.7607\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.4104 - val_accuracy: 0.7521\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2573 - accuracy: 0.8667 - val_loss: 1.4102 - val_accuracy: 0.7607\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.3987 - val_accuracy: 0.7607\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.3926 - val_accuracy: 0.7607\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2564 - accuracy: 0.8667 - val_loss: 1.3885 - val_accuracy: 0.7521\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2558 - accuracy: 0.8667 - val_loss: 1.3933 - val_accuracy: 0.7607\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.4081 - val_accuracy: 0.7607\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2566 - accuracy: 0.8667 - val_loss: 1.3983 - val_accuracy: 0.7607\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.3944 - val_accuracy: 0.7607\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2562 - accuracy: 0.8667 - val_loss: 1.4043 - val_accuracy: 0.7521\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2582 - accuracy: 0.8704 - val_loss: 1.4056 - val_accuracy: 0.7607\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.3902 - val_accuracy: 0.7778\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.3866 - val_accuracy: 0.7778\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2598 - accuracy: 0.8630 - val_loss: 1.3866 - val_accuracy: 0.7778\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2568 - accuracy: 0.8667 - val_loss: 1.3861 - val_accuracy: 0.7607\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2599 - accuracy: 0.8704 - val_loss: 1.3885 - val_accuracy: 0.7521\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2603 - accuracy: 0.8704 - val_loss: 1.3958 - val_accuracy: 0.7521\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.4083 - val_accuracy: 0.7607\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 1.4237 - val_accuracy: 0.7692\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 1.4119 - val_accuracy: 0.7778\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2554 - accuracy: 0.8667 - val_loss: 1.4013 - val_accuracy: 0.7521\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2579 - accuracy: 0.8704 - val_loss: 1.3954 - val_accuracy: 0.7521\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.3804 - val_accuracy: 0.7607\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2577 - accuracy: 0.8778 - val_loss: 1.3851 - val_accuracy: 0.7778\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2571 - accuracy: 0.8593 - val_loss: 1.3964 - val_accuracy: 0.7607\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2562 - accuracy: 0.8704 - val_loss: 1.4088 - val_accuracy: 0.7521\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2571 - accuracy: 0.8704 - val_loss: 1.4075 - val_accuracy: 0.7521\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.3954 - val_accuracy: 0.7521\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.3971 - val_accuracy: 0.7521\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.3852 - val_accuracy: 0.7521\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2549 - accuracy: 0.8741 - val_loss: 1.3880 - val_accuracy: 0.7607\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.3881 - val_accuracy: 0.7607\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.3919 - val_accuracy: 0.7607\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2559 - accuracy: 0.8630 - val_loss: 1.4026 - val_accuracy: 0.7607\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.4045 - val_accuracy: 0.7521\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4003 - val_accuracy: 0.7778\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.85 - 0s 56us/step - loss: 0.2555 - accuracy: 0.8630 - val_loss: 1.3980 - val_accuracy: 0.7778\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2558 - accuracy: 0.8667 - val_loss: 1.3994 - val_accuracy: 0.7607\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.3986 - val_accuracy: 0.7692\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.4085 - val_accuracy: 0.7607\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.4016 - val_accuracy: 0.7521\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.4043 - val_accuracy: 0.7607\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2559 - accuracy: 0.8519 - val_loss: 1.4048 - val_accuracy: 0.7778\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2557 - accuracy: 0.8630 - val_loss: 1.4101 - val_accuracy: 0.7607\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.4134 - val_accuracy: 0.7607\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.4084 - val_accuracy: 0.7607\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2620 - accuracy: 0.8704 - val_loss: 1.4131 - val_accuracy: 0.7607\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2595 - accuracy: 0.8704 - val_loss: 1.4122 - val_accuracy: 0.7607\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.4168 - val_accuracy: 0.7607\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.4208 - val_accuracy: 0.7607\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4226 - val_accuracy: 0.7607\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2558 - accuracy: 0.8741 - val_loss: 1.4203 - val_accuracy: 0.7607\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2564 - accuracy: 0.8741 - val_loss: 1.4214 - val_accuracy: 0.7607\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 1.4199 - val_accuracy: 0.7607\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2580 - accuracy: 0.8704 - val_loss: 1.4166 - val_accuracy: 0.7607\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2577 - accuracy: 0.8630 - val_loss: 1.4145 - val_accuracy: 0.7778\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2574 - accuracy: 0.8556 - val_loss: 1.4137 - val_accuracy: 0.7778\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2563 - accuracy: 0.8630 - val_loss: 1.4157 - val_accuracy: 0.7778\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2558 - accuracy: 0.8630 - val_loss: 1.4189 - val_accuracy: 0.7778\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2561 - accuracy: 0.8630 - val_loss: 1.4219 - val_accuracy: 0.7607\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.4193 - val_accuracy: 0.7607\n",
      "Epoch 666/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 71us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.4172 - val_accuracy: 0.7521\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4249 - val_accuracy: 0.7521\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2555 - accuracy: 0.8704 - val_loss: 1.4238 - val_accuracy: 0.7607\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2550 - accuracy: 0.8667 - val_loss: 1.4182 - val_accuracy: 0.7607\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2538 - accuracy: 0.8704 - val_loss: 1.4200 - val_accuracy: 0.7778\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2591 - accuracy: 0.8630 - val_loss: 1.4253 - val_accuracy: 0.7778\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2571 - accuracy: 0.8556 - val_loss: 1.4340 - val_accuracy: 0.7607\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.4320 - val_accuracy: 0.7607\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2553 - accuracy: 0.8667 - val_loss: 1.4236 - val_accuracy: 0.7607\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2536 - accuracy: 0.8704 - val_loss: 1.4219 - val_accuracy: 0.7607\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4215 - val_accuracy: 0.7778\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2545 - accuracy: 0.8667 - val_loss: 1.4209 - val_accuracy: 0.7778\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2555 - accuracy: 0.8630 - val_loss: 1.4314 - val_accuracy: 0.7607\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.4430 - val_accuracy: 0.7607\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 1.4431 - val_accuracy: 0.7521\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2594 - accuracy: 0.8741 - val_loss: 1.4241 - val_accuracy: 0.7607\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2562 - accuracy: 0.8704 - val_loss: 1.4116 - val_accuracy: 0.7607\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2580 - accuracy: 0.8704 - val_loss: 1.4166 - val_accuracy: 0.7607\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2577 - accuracy: 0.8704 - val_loss: 1.4404 - val_accuracy: 0.7692\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4353 - val_accuracy: 0.7607\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4272 - val_accuracy: 0.7607\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2573 - accuracy: 0.8667 - val_loss: 1.4165 - val_accuracy: 0.7607\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.4194 - val_accuracy: 0.7521\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.4216 - val_accuracy: 0.7521\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.4281 - val_accuracy: 0.7521\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.4358 - val_accuracy: 0.7607\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2547 - accuracy: 0.8741 - val_loss: 1.4432 - val_accuracy: 0.7607\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.4496 - val_accuracy: 0.7778\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2570 - accuracy: 0.8667 - val_loss: 1.4473 - val_accuracy: 0.7607\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2547 - accuracy: 0.8704 - val_loss: 1.4389 - val_accuracy: 0.7607\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2584 - accuracy: 0.8704 - val_loss: 1.4291 - val_accuracy: 0.7607\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.4384 - val_accuracy: 0.7607\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4508 - val_accuracy: 0.7436\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.4528 - val_accuracy: 0.7436\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.4360 - val_accuracy: 0.7607\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2546 - accuracy: 0.8741 - val_loss: 1.4248 - val_accuracy: 0.7778\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2585 - accuracy: 0.8556 - val_loss: 1.4207 - val_accuracy: 0.7778\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2571 - accuracy: 0.8630 - val_loss: 1.4317 - val_accuracy: 0.7607\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.4419 - val_accuracy: 0.7692\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.4371 - val_accuracy: 0.7692\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2557 - accuracy: 0.8630 - val_loss: 1.4327 - val_accuracy: 0.7778\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2561 - accuracy: 0.8630 - val_loss: 1.4285 - val_accuracy: 0.7778\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2555 - accuracy: 0.8630 - val_loss: 1.4281 - val_accuracy: 0.7607\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.4356 - val_accuracy: 0.7692\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2592 - accuracy: 0.8667 - val_loss: 1.4409 - val_accuracy: 0.7607\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.4342 - val_accuracy: 0.7607\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2546 - accuracy: 0.8593 - val_loss: 1.4326 - val_accuracy: 0.7692\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2565 - accuracy: 0.8667 - val_loss: 1.4290 - val_accuracy: 0.7778\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2585 - accuracy: 0.8630 - val_loss: 1.4263 - val_accuracy: 0.7778\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.85 - 0s 87us/step - loss: 0.2577 - accuracy: 0.8519 - val_loss: 1.4321 - val_accuracy: 0.7607\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4372 - val_accuracy: 0.7607\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.4333 - val_accuracy: 0.7607\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2567 - accuracy: 0.8667 - val_loss: 1.4180 - val_accuracy: 0.7607\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2562 - accuracy: 0.8630 - val_loss: 1.4084 - val_accuracy: 0.7863\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2609 - accuracy: 0.8630 - val_loss: 1.4053 - val_accuracy: 0.7863\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 1.4151 - val_accuracy: 0.7863\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2586 - accuracy: 0.8593 - val_loss: 1.4305 - val_accuracy: 0.7778\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2572 - accuracy: 0.8593 - val_loss: 1.4348 - val_accuracy: 0.7607\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.4210 - val_accuracy: 0.7607\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.4122 - val_accuracy: 0.7607\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4167 - val_accuracy: 0.7692\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2544 - accuracy: 0.8778 - val_loss: 1.4296 - val_accuracy: 0.7692\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 1.4404 - val_accuracy: 0.7692\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2595 - accuracy: 0.8630 - val_loss: 1.4429 - val_accuracy: 0.7607\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.4492 - val_accuracy: 0.7607\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.90 - 0s 252us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4580 - val_accuracy: 0.7607\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.4491 - val_accuracy: 0.7607\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2549 - accuracy: 0.8667 - val_loss: 1.4242 - val_accuracy: 0.7521\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.4158 - val_accuracy: 0.7521\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 1.4152 - val_accuracy: 0.7607\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2574 - accuracy: 0.8667 - val_loss: 1.4227 - val_accuracy: 0.7436\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2570 - accuracy: 0.8667 - val_loss: 1.4317 - val_accuracy: 0.7607\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2606 - accuracy: 0.8519 - val_loss: 1.4287 - val_accuracy: 0.7778\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2603 - accuracy: 0.8630 - val_loss: 1.4202 - val_accuracy: 0.7778\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2567 - accuracy: 0.8667 - val_loss: 1.4136 - val_accuracy: 0.7607\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2543 - accuracy: 0.8704 - val_loss: 1.4011 - val_accuracy: 0.7607\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2582 - accuracy: 0.8704 - val_loss: 1.3937 - val_accuracy: 0.7607\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 1.3944 - val_accuracy: 0.7607\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 1.4000 - val_accuracy: 0.7607\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4174 - val_accuracy: 0.7607\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2564 - accuracy: 0.8593 - val_loss: 1.4328 - val_accuracy: 0.7607\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.4331 - val_accuracy: 0.7607\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.4344 - val_accuracy: 0.7607\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4317 - val_accuracy: 0.7607\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2557 - accuracy: 0.8704 - val_loss: 1.4335 - val_accuracy: 0.7607\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4420 - val_accuracy: 0.7607\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2576 - accuracy: 0.8704 - val_loss: 1.4403 - val_accuracy: 0.7778\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2572 - accuracy: 0.8630 - val_loss: 1.4239 - val_accuracy: 0.7778\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2571 - accuracy: 0.8630 - val_loss: 1.4283 - val_accuracy: 0.7778\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2570 - accuracy: 0.8593 - val_loss: 1.4441 - val_accuracy: 0.7607\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2541 - accuracy: 0.8704 - val_loss: 1.4491 - val_accuracy: 0.7692\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.4445 - val_accuracy: 0.7607\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2578 - accuracy: 0.8667 - val_loss: 1.4368 - val_accuracy: 0.7607\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4443 - val_accuracy: 0.7607\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2567 - accuracy: 0.8667 - val_loss: 1.4413 - val_accuracy: 0.7607\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.4517 - val_accuracy: 0.7607\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.4536 - val_accuracy: 0.7607\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.4456 - val_accuracy: 0.7607\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2557 - accuracy: 0.8704 - val_loss: 1.4448 - val_accuracy: 0.7607\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2543 - accuracy: 0.8704 - val_loss: 1.4376 - val_accuracy: 0.7607\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2572 - accuracy: 0.8667 - val_loss: 1.4369 - val_accuracy: 0.7521\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.4336 - val_accuracy: 0.7607\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4393 - val_accuracy: 0.7607\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2543 - accuracy: 0.8667 - val_loss: 1.4377 - val_accuracy: 0.7521\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.4366 - val_accuracy: 0.7607\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.4363 - val_accuracy: 0.7607\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2559 - accuracy: 0.8741 - val_loss: 1.4272 - val_accuracy: 0.7521\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2555 - accuracy: 0.8630 - val_loss: 1.4241 - val_accuracy: 0.7607\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2555 - accuracy: 0.8667 - val_loss: 1.4306 - val_accuracy: 0.7607\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2563 - accuracy: 0.8630 - val_loss: 1.4397 - val_accuracy: 0.7607\n",
      "Epoch 776/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 80us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4336 - val_accuracy: 0.7607\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.4295 - val_accuracy: 0.7607\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2547 - accuracy: 0.8556 - val_loss: 1.4309 - val_accuracy: 0.7607\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.4423 - val_accuracy: 0.7607\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.4569 - val_accuracy: 0.7607\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.4416 - val_accuracy: 0.7521\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.4402 - val_accuracy: 0.7521\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4461 - val_accuracy: 0.7521\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4402 - val_accuracy: 0.7521\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4433 - val_accuracy: 0.7521\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4456 - val_accuracy: 0.7521\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.4519 - val_accuracy: 0.7607\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2548 - accuracy: 0.8667 - val_loss: 1.4638 - val_accuracy: 0.7607\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2567 - accuracy: 0.8704 - val_loss: 1.4660 - val_accuracy: 0.7521\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2574 - accuracy: 0.8704 - val_loss: 1.4470 - val_accuracy: 0.7692\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.4463 - val_accuracy: 0.7607\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.4460 - val_accuracy: 0.7607\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.4396 - val_accuracy: 0.7607\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.4318 - val_accuracy: 0.7607\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2536 - accuracy: 0.8704 - val_loss: 1.4316 - val_accuracy: 0.7778\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2585 - accuracy: 0.8593 - val_loss: 1.4349 - val_accuracy: 0.7778\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2587 - accuracy: 0.8519 - val_loss: 1.4403 - val_accuracy: 0.7863\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2557 - accuracy: 0.8593 - val_loss: 1.4502 - val_accuracy: 0.7692\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4560 - val_accuracy: 0.7607\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2545 - accuracy: 0.8704 - val_loss: 1.4465 - val_accuracy: 0.7692\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2541 - accuracy: 0.8704 - val_loss: 1.4425 - val_accuracy: 0.7692\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.4383 - val_accuracy: 0.7607\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.4526 - val_accuracy: 0.7692\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4744 - val_accuracy: 0.7607\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2564 - accuracy: 0.8704 - val_loss: 1.4792 - val_accuracy: 0.7521\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 1.4769 - val_accuracy: 0.7692\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2575 - accuracy: 0.8593 - val_loss: 1.4670 - val_accuracy: 0.7692\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.4568 - val_accuracy: 0.7692\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2562 - accuracy: 0.8667 - val_loss: 1.4494 - val_accuracy: 0.7692\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2558 - accuracy: 0.8593 - val_loss: 1.4462 - val_accuracy: 0.7692\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2547 - accuracy: 0.8778 - val_loss: 1.4495 - val_accuracy: 0.7607\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2547 - accuracy: 0.8741 - val_loss: 1.4632 - val_accuracy: 0.7607\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4727 - val_accuracy: 0.7607\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 1.4738 - val_accuracy: 0.7778\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2582 - accuracy: 0.8630 - val_loss: 1.4690 - val_accuracy: 0.7778\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2576 - accuracy: 0.8630 - val_loss: 1.4695 - val_accuracy: 0.7863\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2550 - accuracy: 0.8630 - val_loss: 1.4704 - val_accuracy: 0.7607\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4703 - val_accuracy: 0.7607\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.4579 - val_accuracy: 0.7607\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2543 - accuracy: 0.8741 - val_loss: 1.4555 - val_accuracy: 0.7607\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2548 - accuracy: 0.8704 - val_loss: 1.4571 - val_accuracy: 0.7778\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.4596 - val_accuracy: 0.7607\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2560 - accuracy: 0.8667 - val_loss: 1.4658 - val_accuracy: 0.7692\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2534 - accuracy: 0.8704 - val_loss: 1.4585 - val_accuracy: 0.7607\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2547 - accuracy: 0.8704 - val_loss: 1.4494 - val_accuracy: 0.7607\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2565 - accuracy: 0.8704 - val_loss: 1.4578 - val_accuracy: 0.7607\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4682 - val_accuracy: 0.7607\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.4799 - val_accuracy: 0.7607\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2585 - accuracy: 0.8704 - val_loss: 1.4852 - val_accuracy: 0.7436\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2574 - accuracy: 0.8741 - val_loss: 1.4809 - val_accuracy: 0.7436\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2578 - accuracy: 0.8704 - val_loss: 1.4657 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2596 - accuracy: 0.8704 - val_loss: 1.4656 - val_accuracy: 0.7607\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2565 - accuracy: 0.8741 - val_loss: 1.4611 - val_accuracy: 0.7607\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2560 - accuracy: 0.8741 - val_loss: 1.4588 - val_accuracy: 0.7692\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4620 - val_accuracy: 0.7692\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4701 - val_accuracy: 0.7607\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2547 - accuracy: 0.8593 - val_loss: 1.4667 - val_accuracy: 0.7607\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2528 - accuracy: 0.8704 - val_loss: 1.4604 - val_accuracy: 0.7692\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2554 - accuracy: 0.8630 - val_loss: 1.4573 - val_accuracy: 0.7778\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2604 - accuracy: 0.8630 - val_loss: 1.4578 - val_accuracy: 0.7778\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2587 - accuracy: 0.8630 - val_loss: 1.4612 - val_accuracy: 0.7863\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2552 - accuracy: 0.8778 - val_loss: 1.4642 - val_accuracy: 0.7607\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.4662 - val_accuracy: 0.7607\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2539 - accuracy: 0.8704 - val_loss: 1.4708 - val_accuracy: 0.7607\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.4721 - val_accuracy: 0.7607\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4704 - val_accuracy: 0.7607\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4788 - val_accuracy: 0.7692\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2554 - accuracy: 0.8593 - val_loss: 1.4742 - val_accuracy: 0.7521\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.4722 - val_accuracy: 0.7692\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4629 - val_accuracy: 0.7692\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.4644 - val_accuracy: 0.7692\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4724 - val_accuracy: 0.7692\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.4834 - val_accuracy: 0.7863\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2576 - accuracy: 0.8630 - val_loss: 1.4865 - val_accuracy: 0.7863\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2565 - accuracy: 0.8630 - val_loss: 1.4804 - val_accuracy: 0.7692\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2536 - accuracy: 0.8704 - val_loss: 1.4786 - val_accuracy: 0.7692\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2543 - accuracy: 0.8704 - val_loss: 1.4820 - val_accuracy: 0.7692\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2559 - accuracy: 0.8704 - val_loss: 1.4831 - val_accuracy: 0.7692\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2552 - accuracy: 0.8741 - val_loss: 1.4785 - val_accuracy: 0.7692\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.2560 - accuracy: 0.8630 - val_loss: 1.4787 - val_accuracy: 0.7692\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 337us/step - loss: 0.2557 - accuracy: 0.8704 - val_loss: 1.4894 - val_accuracy: 0.7692\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2568 - accuracy: 0.8667 - val_loss: 1.4870 - val_accuracy: 0.7607\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4703 - val_accuracy: 0.7607\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.4591 - val_accuracy: 0.7778\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2560 - accuracy: 0.8630 - val_loss: 1.4613 - val_accuracy: 0.7692\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2585 - accuracy: 0.8630 - val_loss: 1.4691 - val_accuracy: 0.7692\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2558 - accuracy: 0.8630 - val_loss: 1.4732 - val_accuracy: 0.7607\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2533 - accuracy: 0.8704 - val_loss: 1.4797 - val_accuracy: 0.7607\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.4812 - val_accuracy: 0.7607\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2546 - accuracy: 0.8741 - val_loss: 1.4837 - val_accuracy: 0.7692\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2543 - accuracy: 0.8667 - val_loss: 1.4763 - val_accuracy: 0.7692\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.4716 - val_accuracy: 0.7692\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.4813 - val_accuracy: 0.7692\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2545 - accuracy: 0.8704 - val_loss: 1.4931 - val_accuracy: 0.7692\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2539 - accuracy: 0.8667 - val_loss: 1.4966 - val_accuracy: 0.7607\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2541 - accuracy: 0.8667 - val_loss: 1.5023 - val_accuracy: 0.7692\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.5075 - val_accuracy: 0.7607\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.4877 - val_accuracy: 0.7607\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2530 - accuracy: 0.8741 - val_loss: 1.4741 - val_accuracy: 0.7607\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4761 - val_accuracy: 0.7607\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 1.4777 - val_accuracy: 0.7607\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2546 - accuracy: 0.8667 - val_loss: 1.4789 - val_accuracy: 0.7607\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 1.4757 - val_accuracy: 0.7607\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2535 - accuracy: 0.8741 - val_loss: 1.4844 - val_accuracy: 0.7692\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2523 - accuracy: 0.8704 - val_loss: 1.4945 - val_accuracy: 0.7778\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.4980 - val_accuracy: 0.7778\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2614 - accuracy: 0.8630 - val_loss: 1.4915 - val_accuracy: 0.7863\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2570 - accuracy: 0.8630 - val_loss: 1.4890 - val_accuracy: 0.7692\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.4920 - val_accuracy: 0.7692\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2560 - accuracy: 0.8741 - val_loss: 1.5011 - val_accuracy: 0.7607\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2555 - accuracy: 0.8741 - val_loss: 1.5024 - val_accuracy: 0.7692\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.4977 - val_accuracy: 0.7863\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2559 - accuracy: 0.8444 - val_loss: 1.5006 - val_accuracy: 0.7692\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.5054 - val_accuracy: 0.7607\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2543 - accuracy: 0.8593 - val_loss: 1.4842 - val_accuracy: 0.7607\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.4782 - val_accuracy: 0.7607\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.4842 - val_accuracy: 0.7607\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4974 - val_accuracy: 0.7521\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2541 - accuracy: 0.8704 - val_loss: 1.4945 - val_accuracy: 0.7607\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.5046 - val_accuracy: 0.7350\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2553 - accuracy: 0.8667 - val_loss: 1.5089 - val_accuracy: 0.7350\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2551 - accuracy: 0.8667 - val_loss: 1.5004 - val_accuracy: 0.7521\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2533 - accuracy: 0.8704 - val_loss: 1.4937 - val_accuracy: 0.7607\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 1.4976 - val_accuracy: 0.7607\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2545 - accuracy: 0.8704 - val_loss: 1.4985 - val_accuracy: 0.7607\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.5087 - val_accuracy: 0.7607\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2556 - accuracy: 0.8667 - val_loss: 1.5181 - val_accuracy: 0.7607\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.5162 - val_accuracy: 0.7607\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2538 - accuracy: 0.8741 - val_loss: 1.5082 - val_accuracy: 0.7692\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2582 - accuracy: 0.8704 - val_loss: 1.5079 - val_accuracy: 0.7692\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2569 - accuracy: 0.8704 - val_loss: 1.5154 - val_accuracy: 0.7692\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.5169 - val_accuracy: 0.7863\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2573 - accuracy: 0.8630 - val_loss: 1.5197 - val_accuracy: 0.7863\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2557 - accuracy: 0.8630 - val_loss: 1.5280 - val_accuracy: 0.7521\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2582 - accuracy: 0.8778 - val_loss: 1.5219 - val_accuracy: 0.7607\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 1.5105 - val_accuracy: 0.7692\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 1.4988 - val_accuracy: 0.7863\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2550 - accuracy: 0.8630 - val_loss: 1.4962 - val_accuracy: 0.7863\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2542 - accuracy: 0.8556 - val_loss: 1.5009 - val_accuracy: 0.7692\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2524 - accuracy: 0.8704 - val_loss: 1.5117 - val_accuracy: 0.7692\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2562 - accuracy: 0.8741 - val_loss: 1.5131 - val_accuracy: 0.7607\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2547 - accuracy: 0.8667 - val_loss: 1.5021 - val_accuracy: 0.7692\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2517 - accuracy: 0.8963 - val_loss: 1.4960 - val_accuracy: 0.7863\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 277us/step - loss: 0.2583 - accuracy: 0.8630 - val_loss: 1.4986 - val_accuracy: 0.7863\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2569 - accuracy: 0.8667 - val_loss: 1.5078 - val_accuracy: 0.7692\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.5164 - val_accuracy: 0.7692\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2543 - accuracy: 0.8667 - val_loss: 1.5141 - val_accuracy: 0.7607\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.5047 - val_accuracy: 0.7607\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.4960 - val_accuracy: 0.7692\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.4971 - val_accuracy: 0.7607\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2518 - accuracy: 0.8704 - val_loss: 1.5124 - val_accuracy: 0.7607\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2563 - accuracy: 0.8593 - val_loss: 1.5327 - val_accuracy: 0.7607\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2608 - accuracy: 0.8593 - val_loss: 1.5311 - val_accuracy: 0.7607\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2565 - accuracy: 0.8593 - val_loss: 1.5155 - val_accuracy: 0.7692\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2539 - accuracy: 0.8704 - val_loss: 1.5094 - val_accuracy: 0.7692\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2551 - accuracy: 0.8667 - val_loss: 1.5065 - val_accuracy: 0.7607\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2552 - accuracy: 0.8667 - val_loss: 1.5120 - val_accuracy: 0.7692\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.5203 - val_accuracy: 0.7692\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2546 - accuracy: 0.8704 - val_loss: 1.5216 - val_accuracy: 0.7692\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2549 - accuracy: 0.8667 - val_loss: 1.5126 - val_accuracy: 0.7692\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2532 - accuracy: 0.8704 - val_loss: 1.4967 - val_accuracy: 0.7692\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2550 - accuracy: 0.8704 - val_loss: 1.4910 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2593 - accuracy: 0.8630 - val_loss: 1.4909 - val_accuracy: 0.7863\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2576 - accuracy: 0.8667 - val_loss: 1.5030 - val_accuracy: 0.7692\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2553 - accuracy: 0.8704 - val_loss: 1.5172 - val_accuracy: 0.7692\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2553 - accuracy: 0.8630 - val_loss: 1.5241 - val_accuracy: 0.7692\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.5146 - val_accuracy: 0.7692\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2540 - accuracy: 0.8667 - val_loss: 1.5092 - val_accuracy: 0.7863\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2544 - accuracy: 0.8556 - val_loss: 1.5062 - val_accuracy: 0.7863\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2581 - accuracy: 0.8630 - val_loss: 1.5166 - val_accuracy: 0.7778\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2583 - accuracy: 0.8593 - val_loss: 1.5298 - val_accuracy: 0.7607\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2559 - accuracy: 0.8556 - val_loss: 1.5226 - val_accuracy: 0.7863\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2541 - accuracy: 0.8741 - val_loss: 1.5150 - val_accuracy: 0.7607\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.5187 - val_accuracy: 0.7607\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2548 - accuracy: 0.8630 - val_loss: 1.5114 - val_accuracy: 0.7607\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2530 - accuracy: 0.8704 - val_loss: 1.5149 - val_accuracy: 0.7607\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2547 - accuracy: 0.8667 - val_loss: 1.5106 - val_accuracy: 0.7778\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.5031 - val_accuracy: 0.7863\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 1.4978 - val_accuracy: 0.7863\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2631 - accuracy: 0.8593 - val_loss: 1.5058 - val_accuracy: 0.7607\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2576 - accuracy: 0.8667 - val_loss: 1.5211 - val_accuracy: 0.7607\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2566 - accuracy: 0.8704 - val_loss: 1.5254 - val_accuracy: 0.7607\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2560 - accuracy: 0.8704 - val_loss: 1.5128 - val_accuracy: 0.7607\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2593 - accuracy: 0.8593 - val_loss: 1.5050 - val_accuracy: 0.7863\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2571 - accuracy: 0.8556 - val_loss: 1.5018 - val_accuracy: 0.7607\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.5017 - val_accuracy: 0.7607\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2549 - accuracy: 0.8667 - val_loss: 1.5025 - val_accuracy: 0.7607\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.5108 - val_accuracy: 0.7607\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2548 - accuracy: 0.8667 - val_loss: 1.5280 - val_accuracy: 0.7607\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.5328 - val_accuracy: 0.7607\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2552 - accuracy: 0.8741 - val_loss: 1.5302 - val_accuracy: 0.7692\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2545 - accuracy: 0.8704 - val_loss: 1.5240 - val_accuracy: 0.7692\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2533 - accuracy: 0.8704 - val_loss: 1.5150 - val_accuracy: 0.7692\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2538 - accuracy: 0.8630 - val_loss: 1.5062 - val_accuracy: 0.7692\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.4990 - val_accuracy: 0.7692\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.5042 - val_accuracy: 0.7692\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2534 - accuracy: 0.8704 - val_loss: 1.5240 - val_accuracy: 0.7692\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.5307 - val_accuracy: 0.7692\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2552 - accuracy: 0.8704 - val_loss: 1.5286 - val_accuracy: 0.7692\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2537 - accuracy: 0.8704 - val_loss: 1.5196 - val_accuracy: 0.7692\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2551 - accuracy: 0.8630 - val_loss: 1.5143 - val_accuracy: 0.7692\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2556 - accuracy: 0.8704 - val_loss: 1.5200 - val_accuracy: 0.7692\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2561 - accuracy: 0.8741 - val_loss: 1.5336 - val_accuracy: 0.7607\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2568 - accuracy: 0.8704 - val_loss: 1.5384 - val_accuracy: 0.7607\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.5362 - val_accuracy: 0.7692\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.5333 - val_accuracy: 0.7607\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2544 - accuracy: 0.8704 - val_loss: 1.5283 - val_accuracy: 0.7692\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2541 - accuracy: 0.8704 - val_loss: 1.5249 - val_accuracy: 0.7607\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2549 - accuracy: 0.8704 - val_loss: 1.5200 - val_accuracy: 0.7607\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 301us/step - loss: 0.2553 - accuracy: 0.8667 - val_loss: 1.5196 - val_accuracy: 0.7607\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2531 - accuracy: 0.8704 - val_loss: 1.5367 - val_accuracy: 0.7607\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 1.5508 - val_accuracy: 0.7692\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2572 - accuracy: 0.8704 - val_loss: 1.5527 - val_accuracy: 0.7778\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2584 - accuracy: 0.8593 - val_loss: 1.5528 - val_accuracy: 0.7778\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2562 - accuracy: 0.8593 - val_loss: 1.5435 - val_accuracy: 0.7863\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2566 - accuracy: 0.8741 - val_loss: 1.5614 - val_accuracy: 0.7521\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2564 - accuracy: 0.8630 - val_loss: 1.5583 - val_accuracy: 0.7692\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2554 - accuracy: 0.8704 - val_loss: 1.5581 - val_accuracy: 0.7692\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2537 - accuracy: 0.8704 - val_loss: 1.5473 - val_accuracy: 0.7692\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2528 - accuracy: 0.8667 - val_loss: 1.5398 - val_accuracy: 0.7863\n"
     ]
    }
   ],
   "source": [
    "hist2_over = model2_over.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 86.80%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS245</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345807e-02</td>\n",
       "      <td>2.164788e-01</td>\n",
       "      <td>7.700630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.674153e-02</td>\n",
       "      <td>9.294230e-04</td>\n",
       "      <td>9.723290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.147484e-01</td>\n",
       "      <td>3.626331e-01</td>\n",
       "      <td>2.226184e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.723218e-01</td>\n",
       "      <td>6.276781e-01</td>\n",
       "      <td>1.945911e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194510e-08</td>\n",
       "      <td>7.508231e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.372800e-01</td>\n",
       "      <td>2.627200e-01</td>\n",
       "      <td>4.197748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.943684e-01</td>\n",
       "      <td>6.056316e-01</td>\n",
       "      <td>2.843107e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS245          1           2  1.345807e-02   \n",
       "1     p0006kpresabs_qual     NY439          2           2  2.674153e-02   \n",
       "2     p0006kpresabs_qual     CA544          1           0  4.147484e-01   \n",
       "3     p0006kpresabs_qual     CA541          2           0  4.147484e-01   \n",
       "4     p0006kpresabs_qual     EUH15          1           0  4.147484e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual     CA541          1           1  3.723218e-01   \n",
       "985  p0017Skpresabs_qual    SR4152          1           0  7.372800e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  4.194510e-08   \n",
       "987  p0017Skpresabs_qual  CFBRSa70          0           0  7.372800e-01   \n",
       "988  p0017Skpresabs_qual    NRS021          0           1  3.943684e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.164788e-01  7.700630e-01  \n",
       "1    9.294230e-04  9.723290e-01  \n",
       "2    3.626331e-01  2.226184e-01  \n",
       "3    3.626331e-01  2.226184e-01  \n",
       "4    3.626331e-01  2.226184e-01  \n",
       "..            ...           ...  \n",
       "984  6.276781e-01  1.945911e-08  \n",
       "985  2.627200e-01  4.197748e-08  \n",
       "986  7.508231e-09  1.000000e+00  \n",
       "987  2.627200e-01  4.197748e-08  \n",
       "988  6.056316e-01  2.843107e-08  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.13621786e-01, 8.70445970e-01, 1.59322710e-02],\n",
       "       [5.26185630e-02, 8.76052770e-04, 9.46505300e-01],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [3.46191400e-01, 6.44950200e-01, 8.85843800e-03],\n",
       "       [3.66983870e-03, 3.28549300e-03, 9.93044700e-01],\n",
       "       [9.85246600e-02, 8.94542750e-01, 6.93248720e-03],\n",
       "       [5.15567700e-01, 3.64493520e-01, 1.19938820e-01],\n",
       "       [9.99999900e-01, 1.54699700e-07, 3.24824200e-11],\n",
       "       [2.66017580e-02, 3.57331580e-06, 9.73394630e-01],\n",
       "       [9.99998900e-01, 1.04783080e-06, 1.13333650e-09],\n",
       "       [4.92268240e-06, 5.65362630e-03, 9.94341500e-01],\n",
       "       [9.46227900e-05, 1.15727100e-03, 9.98748060e-01],\n",
       "       [4.30122540e-02, 9.56769100e-01, 2.18604080e-04],\n",
       "       [9.30907900e-05, 3.41646720e-03, 9.96490400e-01],\n",
       "       [6.26257300e-03, 8.80636200e-03, 9.84931100e-01],\n",
       "       [3.39146220e-02, 1.89631710e-03, 9.64189100e-01],\n",
       "       [3.14550400e-04, 2.12784300e-02, 9.78406970e-01],\n",
       "       [3.09379500e-01, 1.07671455e-01, 5.82949040e-01],\n",
       "       [9.95067100e-01, 4.85410870e-03, 7.88112200e-05],\n",
       "       [6.58684130e-03, 3.93568500e-05, 9.93373900e-01],\n",
       "       [5.42012370e-03, 9.86161950e-01, 8.41797200e-03],\n",
       "       [9.99914170e-01, 6.50093300e-05, 2.08428480e-05],\n",
       "       [8.35551500e-03, 6.25142500e-04, 9.91019300e-01],\n",
       "       [8.22942350e-07, 5.29465000e-09, 9.99999170e-01],\n",
       "       [3.09379500e-01, 1.07671455e-01, 5.82949040e-01],\n",
       "       [6.23693500e-03, 9.93741000e-01, 2.20552940e-05],\n",
       "       [1.06208000e-03, 9.98849150e-01, 8.86761040e-05],\n",
       "       [6.67594150e-02, 9.33173660e-01, 6.68692200e-05],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [7.70686800e-06, 1.08863920e-07, 9.99992130e-01],\n",
       "       [3.46191400e-01, 6.44950200e-01, 8.85843800e-03],\n",
       "       [1.13621786e-01, 8.70445970e-01, 1.59322710e-02],\n",
       "       [9.99930600e-01, 4.52288500e-05, 2.42499050e-05],\n",
       "       [3.09379500e-01, 1.07671455e-01, 5.82949040e-01],\n",
       "       [9.75303770e-01, 2.46733480e-02, 2.29205540e-05],\n",
       "       [9.99993200e-01, 5.96301100e-06, 8.46220500e-07],\n",
       "       [2.35589090e-05, 9.32230260e-04, 9.99044240e-01],\n",
       "       [9.99999900e-01, 1.54699700e-07, 3.24824200e-11],\n",
       "       [9.97991100e-01, 1.95849480e-03, 5.04789600e-05],\n",
       "       [9.46227900e-05, 1.15727100e-03, 9.98748060e-01],\n",
       "       [3.14550400e-04, 2.12784300e-02, 9.78406970e-01],\n",
       "       [3.46191400e-01, 6.44950200e-01, 8.85843800e-03],\n",
       "       [8.34737250e-03, 9.59676400e-01, 3.19763100e-02],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [1.79214600e-02, 3.56434600e-03, 9.78514130e-01],\n",
       "       [5.26185630e-02, 8.76052770e-04, 9.46505300e-01],\n",
       "       [9.98148900e-01, 1.84625680e-03, 4.90018740e-06],\n",
       "       [6.26257300e-03, 8.80636200e-03, 9.84931100e-01],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [9.98809800e-01, 1.19002370e-03, 1.59880270e-07],\n",
       "       [5.26185630e-02, 8.76052770e-04, 9.46505300e-01],\n",
       "       [3.09379500e-01, 1.07671455e-01, 5.82949040e-01],\n",
       "       [1.97322300e-01, 1.10627330e-07, 8.02677630e-01],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [2.04499830e-04, 1.06148370e-04, 9.99689340e-01],\n",
       "       [9.97736450e-01, 2.25850520e-03, 4.99058020e-06],\n",
       "       [5.50066500e-01, 4.21299040e-01, 2.86345180e-02],\n",
       "       [1.06208000e-03, 9.98849150e-01, 8.86761040e-05],\n",
       "       [4.18469600e-01, 5.81529140e-01, 1.27886930e-06],\n",
       "       [5.50066500e-01, 4.21299040e-01, 2.86345180e-02],\n",
       "       [1.58659530e-04, 4.21608800e-03, 9.95625260e-01],\n",
       "       [3.46191400e-01, 6.44950200e-01, 8.85843800e-03],\n",
       "       [1.22064390e-02, 6.43728440e-03, 9.81356260e-01],\n",
       "       [9.87329240e-01, 1.14172520e-02, 1.25343530e-03],\n",
       "       [8.48939240e-01, 1.31206140e-01, 1.98546350e-02],\n",
       "       [1.10744050e-02, 4.15088900e-01, 5.73836740e-01],\n",
       "       [3.85047640e-01, 6.09515370e-01, 5.43704700e-03],\n",
       "       [9.23593760e-01, 2.50729270e-06, 7.64036500e-02],\n",
       "       [7.37887530e-03, 3.16158570e-03, 9.89459500e-01],\n",
       "       [8.06232500e-03, 4.09393940e-05, 9.91896800e-01],\n",
       "       [1.35404580e-02, 6.13296600e-01, 3.73162930e-01],\n",
       "       [6.60397400e-01, 3.39107780e-01, 4.94836950e-04],\n",
       "       [5.99657670e-02, 9.40025900e-01, 8.33779450e-06],\n",
       "       [2.85045450e-04, 7.98825700e-04, 9.98916150e-01],\n",
       "       [3.08643300e-01, 6.91298100e-01, 5.85711420e-05],\n",
       "       [1.45772740e-03, 6.60011900e-03, 9.91942170e-01],\n",
       "       [9.84674600e-01, 1.51459980e-02, 1.79449230e-04],\n",
       "       [1.41063160e-02, 9.85837200e-01, 5.65208000e-05],\n",
       "       [5.50066500e-01, 4.21299040e-01, 2.86345180e-02],\n",
       "       [1.03810610e-06, 4.80935470e-08, 9.99998900e-01],\n",
       "       [9.68821170e-01, 1.08419390e-05, 3.11679020e-02],\n",
       "       [9.99999400e-01, 6.40318700e-07, 2.51406920e-12],\n",
       "       [3.39146220e-02, 1.89631710e-03, 9.64189100e-01],\n",
       "       [8.04922760e-01, 1.81875900e-01, 1.32013220e-02],\n",
       "       [8.35551500e-03, 6.25142500e-04, 9.91019300e-01],\n",
       "       [1.35404580e-02, 6.13296600e-01, 3.73162930e-01],\n",
       "       [9.99914170e-01, 6.50093300e-05, 2.08428480e-05],\n",
       "       [4.14362970e-03, 9.95400130e-01, 4.56279430e-04],\n",
       "       [5.50066500e-01, 4.21299040e-01, 2.86345180e-02],\n",
       "       [9.84209800e-01, 1.57526960e-02, 3.75461820e-05],\n",
       "       [1.58659530e-04, 4.21608800e-03, 9.95625260e-01],\n",
       "       [9.99940400e-01, 3.13692400e-05, 2.82314670e-05],\n",
       "       [9.09846200e-01, 8.93741850e-02, 7.79662630e-04],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [5.24646020e-05, 1.23925090e-03, 9.98708250e-01],\n",
       "       [7.70686800e-06, 1.08863920e-07, 9.99992130e-01],\n",
       "       [1.10744050e-02, 4.15088900e-01, 5.73836740e-01],\n",
       "       [9.26641200e-01, 7.33585950e-02, 1.18852476e-07],\n",
       "       [7.57431150e-04, 1.29181910e-03, 9.97950730e-01],\n",
       "       [1.51732750e-02, 1.68705250e-03, 9.83139700e-01],\n",
       "       [3.39942460e-02, 9.65764340e-01, 2.41445540e-04],\n",
       "       [1.22064390e-02, 6.43728440e-03, 9.81356260e-01],\n",
       "       [5.89731300e-01, 2.81424050e-01, 1.28844710e-01],\n",
       "       [9.99990600e-01, 9.20932700e-06, 1.79301570e-07],\n",
       "       [2.95259540e-02, 9.62670740e-01, 7.80323750e-03],\n",
       "       [9.99998000e-01, 3.78329230e-08, 2.07168400e-06],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [9.97679300e-01, 2.11209500e-03, 2.08646120e-04],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [3.39146220e-02, 1.89631710e-03, 9.64189100e-01],\n",
       "       [5.50066500e-01, 4.21299040e-01, 2.86345180e-02],\n",
       "       [9.09846200e-01, 8.93741850e-02, 7.79662630e-04],\n",
       "       [1.00919420e-01, 5.83062770e-01, 3.16017840e-01],\n",
       "       [9.09846200e-01, 8.93741850e-02, 7.79662630e-04],\n",
       "       [9.60852700e-01, 3.91304700e-02, 1.68293720e-05],\n",
       "       [9.99575440e-01, 4.19485380e-04, 5.18070830e-06]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566732412886259"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566732412886259"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat6['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS249     2\n",
       "1         NRS188     1\n",
       "2         NRS232     2\n",
       "3          NY439     2\n",
       "4           GA27     2\n",
       "..           ...   ...\n",
       "112       SR3569     0\n",
       "113       NRS204     0\n",
       "114       NRS203     0\n",
       "115     CFBRSa25     1\n",
       "116  CFBREBSa131     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 491us/step - loss: 1.1870 - accuracy: 0.3333 - val_loss: 1.1303 - val_accuracy: 0.3333\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 1.1037 - accuracy: 0.3519 - val_loss: 1.0828 - val_accuracy: 0.3248\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 1.0495 - accuracy: 0.4407 - val_loss: 1.0529 - val_accuracy: 0.4274\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 1.0117 - accuracy: 0.4778 - val_loss: 1.0308 - val_accuracy: 0.4444\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9818 - accuracy: 0.5370 - val_loss: 1.0150 - val_accuracy: 0.4701\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.9560 - accuracy: 0.5741 - val_loss: 1.0006 - val_accuracy: 0.5299\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.9316 - accuracy: 0.6296 - val_loss: 0.9894 - val_accuracy: 0.5214\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.9119 - accuracy: 0.6148 - val_loss: 0.9803 - val_accuracy: 0.5214\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.8929 - accuracy: 0.6148 - val_loss: 0.9737 - val_accuracy: 0.5299\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8757 - accuracy: 0.6259 - val_loss: 0.9680 - val_accuracy: 0.5299\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.8587 - accuracy: 0.6444 - val_loss: 0.9640 - val_accuracy: 0.5214\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.8443 - accuracy: 0.6630 - val_loss: 0.9586 - val_accuracy: 0.5470\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.8309 - accuracy: 0.6815 - val_loss: 0.9523 - val_accuracy: 0.5470\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8168 - accuracy: 0.6889 - val_loss: 0.9460 - val_accuracy: 0.5470\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.8037 - accuracy: 0.7000 - val_loss: 0.9394 - val_accuracy: 0.5470\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.7920 - accuracy: 0.7000 - val_loss: 0.9348 - val_accuracy: 0.5470\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.7819 - accuracy: 0.7000 - val_loss: 0.9313 - val_accuracy: 0.5470\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.7715 - accuracy: 0.6889 - val_loss: 0.9262 - val_accuracy: 0.5470\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.7602 - accuracy: 0.6926 - val_loss: 0.9180 - val_accuracy: 0.5214\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.7494 - accuracy: 0.7000 - val_loss: 0.9122 - val_accuracy: 0.5556\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.7404 - accuracy: 0.7111 - val_loss: 0.9069 - val_accuracy: 0.5641\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.7291 - accuracy: 0.7111 - val_loss: 0.9038 - val_accuracy: 0.5556\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.7197 - accuracy: 0.7222 - val_loss: 0.9001 - val_accuracy: 0.5556\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7115 - accuracy: 0.7222 - val_loss: 0.8969 - val_accuracy: 0.5385\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.7021 - accuracy: 0.7259 - val_loss: 0.8907 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.6930 - accuracy: 0.7259 - val_loss: 0.8866 - val_accuracy: 0.5641\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6843 - accuracy: 0.7296 - val_loss: 0.8796 - val_accuracy: 0.5641\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6766 - accuracy: 0.7259 - val_loss: 0.8716 - val_accuracy: 0.5726\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6676 - accuracy: 0.7296 - val_loss: 0.8670 - val_accuracy: 0.5897\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.6604 - accuracy: 0.7370 - val_loss: 0.8659 - val_accuracy: 0.5897\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.6529 - accuracy: 0.7407 - val_loss: 0.8647 - val_accuracy: 0.5726\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.6478 - accuracy: 0.7370 - val_loss: 0.8608 - val_accuracy: 0.5897\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6381 - accuracy: 0.7444 - val_loss: 0.8570 - val_accuracy: 0.5641\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.6366 - accuracy: 0.7481 - val_loss: 0.8495 - val_accuracy: 0.5812\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.6260 - accuracy: 0.7704 - val_loss: 0.8432 - val_accuracy: 0.5641\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6227 - accuracy: 0.7519 - val_loss: 0.8460 - val_accuracy: 0.5470\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.6186 - accuracy: 0.7593 - val_loss: 0.8396 - val_accuracy: 0.5556\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.6056 - accuracy: 0.7778 - val_loss: 0.8382 - val_accuracy: 0.5897\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6026 - accuracy: 0.7778 - val_loss: 0.8371 - val_accuracy: 0.5983\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5978 - accuracy: 0.7852 - val_loss: 0.8341 - val_accuracy: 0.5897\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.5891 - accuracy: 0.7852 - val_loss: 0.8296 - val_accuracy: 0.5556\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.5831 - accuracy: 0.7778 - val_loss: 0.8299 - val_accuracy: 0.5726\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.5812 - accuracy: 0.7889 - val_loss: 0.8296 - val_accuracy: 0.5726\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5759 - accuracy: 0.7889 - val_loss: 0.8247 - val_accuracy: 0.5812\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.5683 - accuracy: 0.7926 - val_loss: 0.8279 - val_accuracy: 0.5556\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.5649 - accuracy: 0.7852 - val_loss: 0.8283 - val_accuracy: 0.5812\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5599 - accuracy: 0.7889 - val_loss: 0.8192 - val_accuracy: 0.5726\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5522 - accuracy: 0.7963 - val_loss: 0.8144 - val_accuracy: 0.5897\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5477 - accuracy: 0.8000 - val_loss: 0.8101 - val_accuracy: 0.5983\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.5421 - accuracy: 0.8074 - val_loss: 0.8037 - val_accuracy: 0.5983\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.5384 - accuracy: 0.7926 - val_loss: 0.7959 - val_accuracy: 0.5983\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.5343 - accuracy: 0.7889 - val_loss: 0.7923 - val_accuracy: 0.5983\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5298 - accuracy: 0.8074 - val_loss: 0.7911 - val_accuracy: 0.5983\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.5251 - accuracy: 0.8111 - val_loss: 0.7977 - val_accuracy: 0.5983\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5204 - accuracy: 0.8037 - val_loss: 0.7885 - val_accuracy: 0.5983\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5154 - accuracy: 0.8037 - val_loss: 0.7836 - val_accuracy: 0.6068\n",
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.5099 - accuracy: 0.8074 - val_loss: 0.7833 - val_accuracy: 0.6068\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.5053 - accuracy: 0.8148 - val_loss: 0.7860 - val_accuracy: 0.6154\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.5016 - accuracy: 0.8148 - val_loss: 0.7879 - val_accuracy: 0.6154\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4983 - accuracy: 0.8074 - val_loss: 0.7833 - val_accuracy: 0.5983\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4986 - accuracy: 0.7963 - val_loss: 0.7848 - val_accuracy: 0.6325\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.4896 - accuracy: 0.8074 - val_loss: 0.7875 - val_accuracy: 0.6154\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4833 - accuracy: 0.8148 - val_loss: 0.7954 - val_accuracy: 0.6068\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.4924 - accuracy: 0.8037 - val_loss: 0.7870 - val_accuracy: 0.6154\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4758 - accuracy: 0.8222 - val_loss: 0.7753 - val_accuracy: 0.6410\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4805 - accuracy: 0.8148 - val_loss: 0.7747 - val_accuracy: 0.6325\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4763 - accuracy: 0.8074 - val_loss: 0.7768 - val_accuracy: 0.6325\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.4702 - accuracy: 0.8222 - val_loss: 0.7865 - val_accuracy: 0.6496\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.4709 - accuracy: 0.8222 - val_loss: 0.7903 - val_accuracy: 0.6496\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.4632 - accuracy: 0.8296 - val_loss: 0.7776 - val_accuracy: 0.6410\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.4610 - accuracy: 0.8259 - val_loss: 0.7731 - val_accuracy: 0.6325\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.4560 - accuracy: 0.8259 - val_loss: 0.7657 - val_accuracy: 0.6496\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4561 - accuracy: 0.8222 - val_loss: 0.7696 - val_accuracy: 0.6496\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.4493 - accuracy: 0.8296 - val_loss: 0.7790 - val_accuracy: 0.6496\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.4498 - accuracy: 0.8185 - val_loss: 0.7867 - val_accuracy: 0.6581\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.7839 - val_accuracy: 0.6410\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.4396 - accuracy: 0.8370 - val_loss: 0.7796 - val_accuracy: 0.6496\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.4405 - accuracy: 0.8370 - val_loss: 0.7799 - val_accuracy: 0.6410\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.4354 - accuracy: 0.8370 - val_loss: 0.7829 - val_accuracy: 0.6239\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.4344 - accuracy: 0.8333 - val_loss: 0.7741 - val_accuracy: 0.6410\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.4290 - accuracy: 0.8370 - val_loss: 0.7744 - val_accuracy: 0.6325\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.4382 - accuracy: 0.8259 - val_loss: 0.7676 - val_accuracy: 0.6581\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 212us/step - loss: 0.4268 - accuracy: 0.8407 - val_loss: 0.7824 - val_accuracy: 0.6325\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.4269 - accuracy: 0.8296 - val_loss: 0.7744 - val_accuracy: 0.6410\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.4178 - accuracy: 0.8407 - val_loss: 0.7668 - val_accuracy: 0.6581\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.4131 - accuracy: 0.8444 - val_loss: 0.7707 - val_accuracy: 0.6667\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.4130 - accuracy: 0.8333 - val_loss: 0.7754 - val_accuracy: 0.6581\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.4097 - accuracy: 0.8481 - val_loss: 0.7810 - val_accuracy: 0.6581\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4085 - accuracy: 0.8370 - val_loss: 0.7747 - val_accuracy: 0.6496\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4054 - accuracy: 0.8333 - val_loss: 0.7712 - val_accuracy: 0.6581\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4042 - accuracy: 0.8444 - val_loss: 0.7840 - val_accuracy: 0.6581\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.4025 - accuracy: 0.8444 - val_loss: 0.7896 - val_accuracy: 0.6581\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3984 - accuracy: 0.8519 - val_loss: 0.8021 - val_accuracy: 0.6752\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4110 - accuracy: 0.8519 - val_loss: 0.7968 - val_accuracy: 0.6923\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3995 - accuracy: 0.8519 - val_loss: 0.7792 - val_accuracy: 0.6667\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.3929 - accuracy: 0.8481 - val_loss: 0.7930 - val_accuracy: 0.6496\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3934 - accuracy: 0.8481 - val_loss: 0.7992 - val_accuracy: 0.6496\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.3871 - accuracy: 0.8481 - val_loss: 0.7870 - val_accuracy: 0.6752\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.3877 - accuracy: 0.8519 - val_loss: 0.7836 - val_accuracy: 0.6410\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3823 - accuracy: 0.8556 - val_loss: 0.7798 - val_accuracy: 0.6667\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.7915 - val_accuracy: 0.6667\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3807 - accuracy: 0.8519 - val_loss: 0.7881 - val_accuracy: 0.6667\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3733 - accuracy: 0.8593 - val_loss: 0.7870 - val_accuracy: 0.6838\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.3780 - accuracy: 0.8593 - val_loss: 0.7897 - val_accuracy: 0.6667\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3763 - accuracy: 0.8593 - val_loss: 0.8159 - val_accuracy: 0.6667\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3770 - accuracy: 0.8630 - val_loss: 0.8019 - val_accuracy: 0.6581\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3688 - accuracy: 0.8519 - val_loss: 0.7914 - val_accuracy: 0.6667\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.3783 - accuracy: 0.8519 - val_loss: 0.8023 - val_accuracy: 0.6923\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.3705 - accuracy: 0.8630 - val_loss: 0.8022 - val_accuracy: 0.6752\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3626 - accuracy: 0.8519 - val_loss: 0.7941 - val_accuracy: 0.6752\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.3749 - accuracy: 0.8519 - val_loss: 0.7917 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3621 - accuracy: 0.8519 - val_loss: 0.8012 - val_accuracy: 0.6667\n",
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.3661 - accuracy: 0.8556 - val_loss: 0.8349 - val_accuracy: 0.6667\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.3684 - accuracy: 0.8630 - val_loss: 0.8045 - val_accuracy: 0.6667\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.3544 - accuracy: 0.8593 - val_loss: 0.7862 - val_accuracy: 0.6496\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.3568 - accuracy: 0.8556 - val_loss: 0.7935 - val_accuracy: 0.6496\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.3528 - accuracy: 0.8593 - val_loss: 0.8007 - val_accuracy: 0.6667\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 443us/step - loss: 0.3505 - accuracy: 0.8593 - val_loss: 0.8130 - val_accuracy: 0.6667\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3478 - accuracy: 0.8593 - val_loss: 0.8025 - val_accuracy: 0.6838\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3486 - accuracy: 0.8593 - val_loss: 0.7998 - val_accuracy: 0.6752\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3504 - accuracy: 0.8630 - val_loss: 0.8042 - val_accuracy: 0.6496\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3497 - accuracy: 0.8630 - val_loss: 0.8096 - val_accuracy: 0.6752\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3451 - accuracy: 0.8667 - val_loss: 0.8072 - val_accuracy: 0.6667\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3412 - accuracy: 0.8704 - val_loss: 0.8170 - val_accuracy: 0.6581\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3389 - accuracy: 0.8741 - val_loss: 0.8171 - val_accuracy: 0.6581\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3375 - accuracy: 0.8667 - val_loss: 0.8186 - val_accuracy: 0.6496\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3419 - accuracy: 0.8444 - val_loss: 0.8231 - val_accuracy: 0.6667\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.3459 - accuracy: 0.8630 - val_loss: 0.8498 - val_accuracy: 0.6581\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3405 - accuracy: 0.8630 - val_loss: 0.8211 - val_accuracy: 0.6581\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3410 - accuracy: 0.8444 - val_loss: 0.8139 - val_accuracy: 0.6581\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.3353 - accuracy: 0.8704 - val_loss: 0.8433 - val_accuracy: 0.6496\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3438 - accuracy: 0.8630 - val_loss: 0.8559 - val_accuracy: 0.6581\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3328 - accuracy: 0.8667 - val_loss: 0.8262 - val_accuracy: 0.6752\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3294 - accuracy: 0.8630 - val_loss: 0.8305 - val_accuracy: 0.6496\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3300 - accuracy: 0.8667 - val_loss: 0.8341 - val_accuracy: 0.6496\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3264 - accuracy: 0.8667 - val_loss: 0.8201 - val_accuracy: 0.6752\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3294 - accuracy: 0.8667 - val_loss: 0.8140 - val_accuracy: 0.6667\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3247 - accuracy: 0.8593 - val_loss: 0.8461 - val_accuracy: 0.6752\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.8448 - val_accuracy: 0.6752\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3239 - accuracy: 0.8704 - val_loss: 0.8247 - val_accuracy: 0.6838\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3250 - accuracy: 0.8630 - val_loss: 0.8255 - val_accuracy: 0.6667\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3206 - accuracy: 0.8630 - val_loss: 0.8265 - val_accuracy: 0.6581\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3207 - accuracy: 0.8630 - val_loss: 0.8317 - val_accuracy: 0.6581\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3184 - accuracy: 0.8667 - val_loss: 0.8321 - val_accuracy: 0.6581\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3169 - accuracy: 0.8667 - val_loss: 0.8405 - val_accuracy: 0.6581\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3161 - accuracy: 0.8667 - val_loss: 0.8449 - val_accuracy: 0.6581\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3174 - accuracy: 0.8630 - val_loss: 0.8442 - val_accuracy: 0.6581\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3163 - accuracy: 0.8630 - val_loss: 0.8463 - val_accuracy: 0.6752\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.3148 - accuracy: 0.8704 - val_loss: 0.8590 - val_accuracy: 0.6496\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3122 - accuracy: 0.8704 - val_loss: 0.8511 - val_accuracy: 0.6581\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3160 - accuracy: 0.8593 - val_loss: 0.8458 - val_accuracy: 0.6752\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.3147 - accuracy: 0.8593 - val_loss: 0.8548 - val_accuracy: 0.6496\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3113 - accuracy: 0.8704 - val_loss: 0.8658 - val_accuracy: 0.6496\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3149 - accuracy: 0.8704 - val_loss: 0.8442 - val_accuracy: 0.6496\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3085 - accuracy: 0.8704 - val_loss: 0.8453 - val_accuracy: 0.6667\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3110 - accuracy: 0.8667 - val_loss: 0.8593 - val_accuracy: 0.6752\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3148 - accuracy: 0.8667 - val_loss: 0.8474 - val_accuracy: 0.6581\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3109 - accuracy: 0.8667 - val_loss: 0.8652 - val_accuracy: 0.6410\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3065 - accuracy: 0.8667 - val_loss: 0.8592 - val_accuracy: 0.6581\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3103 - accuracy: 0.8704 - val_loss: 0.8511 - val_accuracy: 0.6581\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3079 - accuracy: 0.8667 - val_loss: 0.8375 - val_accuracy: 0.6496\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3104 - accuracy: 0.8667 - val_loss: 0.8454 - val_accuracy: 0.6496\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3083 - accuracy: 0.8704 - val_loss: 0.8751 - val_accuracy: 0.6410\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3052 - accuracy: 0.8741 - val_loss: 0.8991 - val_accuracy: 0.6410\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3049 - accuracy: 0.8704 - val_loss: 0.8938 - val_accuracy: 0.6496\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3031 - accuracy: 0.8556 - val_loss: 0.8800 - val_accuracy: 0.6667\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.3043 - accuracy: 0.8704 - val_loss: 0.9013 - val_accuracy: 0.6496\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3067 - accuracy: 0.8704 - val_loss: 0.9161 - val_accuracy: 0.6496\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2978 - accuracy: 0.8741 - val_loss: 0.8770 - val_accuracy: 0.6667\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2992 - accuracy: 0.8667 - val_loss: 0.8692 - val_accuracy: 0.6581\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2992 - accuracy: 0.8667 - val_loss: 0.8735 - val_accuracy: 0.6667\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2981 - accuracy: 0.8667 - val_loss: 0.8771 - val_accuracy: 0.6752\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2969 - accuracy: 0.8704 - val_loss: 0.8780 - val_accuracy: 0.6667\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2968 - accuracy: 0.8667 - val_loss: 0.8998 - val_accuracy: 0.6496\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3005 - accuracy: 0.8704 - val_loss: 0.9118 - val_accuracy: 0.6496\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2973 - accuracy: 0.8778 - val_loss: 0.9147 - val_accuracy: 0.6667\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3023 - accuracy: 0.8556 - val_loss: 0.9023 - val_accuracy: 0.6752\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2947 - accuracy: 0.8778 - val_loss: 0.9177 - val_accuracy: 0.6581\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2986 - accuracy: 0.8667 - val_loss: 0.9297 - val_accuracy: 0.6581\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2948 - accuracy: 0.8852 - val_loss: 0.9387 - val_accuracy: 0.6410\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2909 - accuracy: 0.8778 - val_loss: 0.9298 - val_accuracy: 0.6496\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2901 - accuracy: 0.8704 - val_loss: 0.9119 - val_accuracy: 0.6581\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2905 - accuracy: 0.8704 - val_loss: 0.9303 - val_accuracy: 0.6581\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2924 - accuracy: 0.8741 - val_loss: 0.9367 - val_accuracy: 0.6581\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2879 - accuracy: 0.8741 - val_loss: 0.9179 - val_accuracy: 0.6496\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2930 - accuracy: 0.8741 - val_loss: 0.9256 - val_accuracy: 0.6496\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2994 - accuracy: 0.8741 - val_loss: 0.9158 - val_accuracy: 0.6496\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2908 - accuracy: 0.8815 - val_loss: 0.9178 - val_accuracy: 0.6581\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2879 - accuracy: 0.8741 - val_loss: 0.9099 - val_accuracy: 0.6581\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2864 - accuracy: 0.8741 - val_loss: 0.9133 - val_accuracy: 0.6581\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2924 - accuracy: 0.8741 - val_loss: 0.8969 - val_accuracy: 0.6581\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2901 - accuracy: 0.8741 - val_loss: 0.8973 - val_accuracy: 0.6667\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2881 - accuracy: 0.8741 - val_loss: 0.9106 - val_accuracy: 0.6581\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2861 - accuracy: 0.8741 - val_loss: 0.9235 - val_accuracy: 0.6496\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2831 - accuracy: 0.8778 - val_loss: 0.9284 - val_accuracy: 0.6667\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2845 - accuracy: 0.8704 - val_loss: 0.9206 - val_accuracy: 0.6667\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2856 - accuracy: 0.8630 - val_loss: 0.9470 - val_accuracy: 0.6581\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2838 - accuracy: 0.8815 - val_loss: 0.9532 - val_accuracy: 0.6496\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2852 - accuracy: 0.8667 - val_loss: 0.9324 - val_accuracy: 0.6581\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2915 - accuracy: 0.8741 - val_loss: 0.9592 - val_accuracy: 0.6667\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2862 - accuracy: 0.8815 - val_loss: 0.9958 - val_accuracy: 0.6496\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2920 - accuracy: 0.8704 - val_loss: 0.9596 - val_accuracy: 0.6410\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2900 - accuracy: 0.8593 - val_loss: 0.9135 - val_accuracy: 0.6496\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3019 - accuracy: 0.8667 - val_loss: 0.9255 - val_accuracy: 0.6667\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2874 - accuracy: 0.8556 - val_loss: 1.0196 - val_accuracy: 0.6581\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2954 - accuracy: 0.8741 - val_loss: 1.0109 - val_accuracy: 0.6410\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2852 - accuracy: 0.8778 - val_loss: 0.9568 - val_accuracy: 0.6496\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2843 - accuracy: 0.8741 - val_loss: 0.9462 - val_accuracy: 0.6581\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2815 - accuracy: 0.8741 - val_loss: 0.9684 - val_accuracy: 0.6581\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2763 - accuracy: 0.8741 - val_loss: 0.9484 - val_accuracy: 0.6581\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2773 - accuracy: 0.8815 - val_loss: 0.9305 - val_accuracy: 0.6496\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2987 - accuracy: 0.8519 - val_loss: 0.9430 - val_accuracy: 0.6752\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2870 - accuracy: 0.8704 - val_loss: 0.9839 - val_accuracy: 0.6581\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2776 - accuracy: 0.8741 - val_loss: 0.9691 - val_accuracy: 0.6581\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2812 - accuracy: 0.8741 - val_loss: 0.9907 - val_accuracy: 0.6496\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2818 - accuracy: 0.8667 - val_loss: 1.0040 - val_accuracy: 0.6410\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2787 - accuracy: 0.8778 - val_loss: 1.0046 - val_accuracy: 0.6496\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2728 - accuracy: 0.8815 - val_loss: 0.9715 - val_accuracy: 0.6581\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2754 - accuracy: 0.8741 - val_loss: 0.9790 - val_accuracy: 0.6581\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2741 - accuracy: 0.8741 - val_loss: 0.9979 - val_accuracy: 0.6581\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2746 - accuracy: 0.8741 - val_loss: 1.0294 - val_accuracy: 0.6410\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2774 - accuracy: 0.8778 - val_loss: 1.0157 - val_accuracy: 0.6496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2723 - accuracy: 0.8778 - val_loss: 0.9922 - val_accuracy: 0.6496\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2748 - accuracy: 0.8593 - val_loss: 0.9765 - val_accuracy: 0.6667\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2734 - accuracy: 0.8778 - val_loss: 1.0033 - val_accuracy: 0.6496\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2724 - accuracy: 0.8815 - val_loss: 1.0305 - val_accuracy: 0.6496\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2740 - accuracy: 0.8778 - val_loss: 1.0093 - val_accuracy: 0.6496\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2734 - accuracy: 0.8778 - val_loss: 0.9898 - val_accuracy: 0.6496\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2732 - accuracy: 0.8815 - val_loss: 0.9992 - val_accuracy: 0.6667\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2784 - accuracy: 0.8741 - val_loss: 0.9717 - val_accuracy: 0.6667\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2743 - accuracy: 0.8704 - val_loss: 1.0023 - val_accuracy: 0.6667\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2720 - accuracy: 0.8815 - val_loss: 1.0228 - val_accuracy: 0.6496\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2756 - accuracy: 0.8852 - val_loss: 1.0050 - val_accuracy: 0.6667\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2745 - accuracy: 0.8741 - val_loss: 1.0159 - val_accuracy: 0.6752\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2722 - accuracy: 0.8704 - val_loss: 1.0320 - val_accuracy: 0.6581\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2675 - accuracy: 0.8815 - val_loss: 1.0068 - val_accuracy: 0.6667\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2700 - accuracy: 0.8704 - val_loss: 0.9914 - val_accuracy: 0.6581\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2740 - accuracy: 0.8667 - val_loss: 1.0114 - val_accuracy: 0.6581\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2702 - accuracy: 0.8741 - val_loss: 1.0471 - val_accuracy: 0.6496\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2760 - accuracy: 0.8593 - val_loss: 1.0412 - val_accuracy: 0.6496\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2672 - accuracy: 0.8778 - val_loss: 1.0159 - val_accuracy: 0.6496\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2674 - accuracy: 0.8778 - val_loss: 1.0057 - val_accuracy: 0.6581\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2758 - accuracy: 0.8704 - val_loss: 1.0211 - val_accuracy: 0.6667\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2686 - accuracy: 0.8704 - val_loss: 1.0572 - val_accuracy: 0.6581\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2715 - accuracy: 0.8778 - val_loss: 1.0703 - val_accuracy: 0.6581\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2705 - accuracy: 0.8778 - val_loss: 1.0347 - val_accuracy: 0.6496\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2656 - accuracy: 0.8778 - val_loss: 1.0138 - val_accuracy: 0.6581\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2687 - accuracy: 0.8778 - val_loss: 1.0221 - val_accuracy: 0.6581\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2688 - accuracy: 0.8778 - val_loss: 1.0546 - val_accuracy: 0.6496\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2677 - accuracy: 0.8778 - val_loss: 1.0405 - val_accuracy: 0.6496\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2634 - accuracy: 0.8778 - val_loss: 1.0168 - val_accuracy: 0.6581\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2646 - accuracy: 0.8778 - val_loss: 1.0286 - val_accuracy: 0.6752\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2717 - accuracy: 0.8667 - val_loss: 1.0571 - val_accuracy: 0.6581\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2627 - accuracy: 0.8741 - val_loss: 1.0685 - val_accuracy: 0.6496\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2760 - accuracy: 0.8778 - val_loss: 1.0629 - val_accuracy: 0.6496\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2669 - accuracy: 0.8741 - val_loss: 1.0633 - val_accuracy: 0.6667\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2652 - accuracy: 0.8815 - val_loss: 1.0530 - val_accuracy: 0.6838\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2625 - accuracy: 0.8741 - val_loss: 1.0596 - val_accuracy: 0.6581\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2687 - accuracy: 0.8741 - val_loss: 1.0669 - val_accuracy: 0.6581\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2690 - accuracy: 0.8778 - val_loss: 1.0673 - val_accuracy: 0.6581\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 1.0367 - val_accuracy: 0.6752\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2717 - accuracy: 0.8667 - val_loss: 1.0260 - val_accuracy: 0.6667\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2643 - accuracy: 0.8741 - val_loss: 1.0715 - val_accuracy: 0.6496\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2670 - accuracy: 0.8778 - val_loss: 1.1171 - val_accuracy: 0.6496\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2728 - accuracy: 0.8778 - val_loss: 1.0939 - val_accuracy: 0.6581\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2717 - accuracy: 0.8778 - val_loss: 1.0588 - val_accuracy: 0.6752\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2697 - accuracy: 0.8704 - val_loss: 1.0504 - val_accuracy: 0.6667\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2618 - accuracy: 0.8778 - val_loss: 1.0902 - val_accuracy: 0.6581\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2771 - accuracy: 0.8704 - val_loss: 1.1050 - val_accuracy: 0.6496\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2664 - accuracy: 0.8704 - val_loss: 1.0649 - val_accuracy: 0.6752\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2722 - accuracy: 0.8667 - val_loss: 1.0697 - val_accuracy: 0.6752\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2644 - accuracy: 0.8815 - val_loss: 1.0722 - val_accuracy: 0.6581\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2644 - accuracy: 0.8704 - val_loss: 1.0831 - val_accuracy: 0.6496\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2678 - accuracy: 0.8741 - val_loss: 1.0901 - val_accuracy: 0.6581\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2668 - accuracy: 0.8704 - val_loss: 1.1015 - val_accuracy: 0.6581\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2648 - accuracy: 0.8741 - val_loss: 1.0930 - val_accuracy: 0.6496\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2656 - accuracy: 0.8778 - val_loss: 1.1009 - val_accuracy: 0.6496\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 1.0819 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 1.0599 - val_accuracy: 0.6667\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 1.0614 - val_accuracy: 0.6581\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2619 - accuracy: 0.8741 - val_loss: 1.0729 - val_accuracy: 0.6581\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2628 - accuracy: 0.8778 - val_loss: 1.0935 - val_accuracy: 0.6581\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2607 - accuracy: 0.8889 - val_loss: 1.1381 - val_accuracy: 0.6496\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2682 - accuracy: 0.8815 - val_loss: 1.1551 - val_accuracy: 0.6581\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2704 - accuracy: 0.8704 - val_loss: 1.0804 - val_accuracy: 0.6581\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2600 - accuracy: 0.8778 - val_loss: 1.0481 - val_accuracy: 0.6581\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2704 - accuracy: 0.8778 - val_loss: 1.0752 - val_accuracy: 0.6496\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2630 - accuracy: 0.8815 - val_loss: 1.1268 - val_accuracy: 0.6667\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2665 - accuracy: 0.8741 - val_loss: 1.0889 - val_accuracy: 0.6581\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2587 - accuracy: 0.8815 - val_loss: 1.0503 - val_accuracy: 0.6752\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2703 - accuracy: 0.8778 - val_loss: 1.0619 - val_accuracy: 0.6667\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2637 - accuracy: 0.8778 - val_loss: 1.1254 - val_accuracy: 0.6410\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2671 - accuracy: 0.8778 - val_loss: 1.1353 - val_accuracy: 0.6667\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.0684 - val_accuracy: 0.6752\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2747 - accuracy: 0.8778 - val_loss: 1.0629 - val_accuracy: 0.6752\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2659 - accuracy: 0.8630 - val_loss: 1.1019 - val_accuracy: 0.6581\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2585 - accuracy: 0.8778 - val_loss: 1.0734 - val_accuracy: 0.6581\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2608 - accuracy: 0.8778 - val_loss: 1.0832 - val_accuracy: 0.6581\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 1.0961 - val_accuracy: 0.6667\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2596 - accuracy: 0.8741 - val_loss: 1.1002 - val_accuracy: 0.6667\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2614 - accuracy: 0.8778 - val_loss: 1.0913 - val_accuracy: 0.6581\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2584 - accuracy: 0.8778 - val_loss: 1.1177 - val_accuracy: 0.6496\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2567 - accuracy: 0.8741 - val_loss: 1.1275 - val_accuracy: 0.6581\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.1245 - val_accuracy: 0.6496\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2576 - accuracy: 0.8815 - val_loss: 1.1109 - val_accuracy: 0.6581\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2558 - accuracy: 0.8778 - val_loss: 1.1427 - val_accuracy: 0.6496\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2570 - accuracy: 0.8815 - val_loss: 1.1536 - val_accuracy: 0.6496\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2554 - accuracy: 0.8778 - val_loss: 1.1311 - val_accuracy: 0.6496\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2554 - accuracy: 0.8815 - val_loss: 1.1245 - val_accuracy: 0.6667\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2568 - accuracy: 0.8778 - val_loss: 1.1096 - val_accuracy: 0.6752\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2572 - accuracy: 0.8778 - val_loss: 1.1293 - val_accuracy: 0.6667\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2575 - accuracy: 0.8815 - val_loss: 1.1230 - val_accuracy: 0.6581\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2578 - accuracy: 0.8815 - val_loss: 1.1300 - val_accuracy: 0.6581\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2567 - accuracy: 0.8815 - val_loss: 1.1333 - val_accuracy: 0.6496\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2565 - accuracy: 0.8889 - val_loss: 1.1017 - val_accuracy: 0.6667\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2669 - accuracy: 0.8667 - val_loss: 1.1245 - val_accuracy: 0.6752\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2602 - accuracy: 0.8741 - val_loss: 1.1685 - val_accuracy: 0.6496\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2613 - accuracy: 0.8778 - val_loss: 1.1691 - val_accuracy: 0.6581\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.1087 - val_accuracy: 0.6752\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2599 - accuracy: 0.8778 - val_loss: 1.1278 - val_accuracy: 0.6667\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.1282 - val_accuracy: 0.6581\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2529 - accuracy: 0.8778 - val_loss: 1.1459 - val_accuracy: 0.6581\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2553 - accuracy: 0.8815 - val_loss: 1.1732 - val_accuracy: 0.6496\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 1.1438 - val_accuracy: 0.6496\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2567 - accuracy: 0.8778 - val_loss: 1.1051 - val_accuracy: 0.6581\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2623 - accuracy: 0.8778 - val_loss: 1.0935 - val_accuracy: 0.6581\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2561 - accuracy: 0.8741 - val_loss: 1.1299 - val_accuracy: 0.6838\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2564 - accuracy: 0.8815 - val_loss: 1.1612 - val_accuracy: 0.6581\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2554 - accuracy: 0.8815 - val_loss: 1.1318 - val_accuracy: 0.6667\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2656 - accuracy: 0.8778 - val_loss: 1.1080 - val_accuracy: 0.6667\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2602 - accuracy: 0.8741 - val_loss: 1.1717 - val_accuracy: 0.6581\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2626 - accuracy: 0.8815 - val_loss: 1.1804 - val_accuracy: 0.6581\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2601 - accuracy: 0.8815 - val_loss: 1.1390 - val_accuracy: 0.6581\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2581 - accuracy: 0.8704 - val_loss: 1.1338 - val_accuracy: 0.6667\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2589 - accuracy: 0.8778 - val_loss: 1.1708 - val_accuracy: 0.6581\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2527 - accuracy: 0.8815 - val_loss: 1.1571 - val_accuracy: 0.6581\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2546 - accuracy: 0.8630 - val_loss: 1.1357 - val_accuracy: 0.6667\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2587 - accuracy: 0.8778 - val_loss: 1.1497 - val_accuracy: 0.6581\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2563 - accuracy: 0.8815 - val_loss: 1.1729 - val_accuracy: 0.6581\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2592 - accuracy: 0.8852 - val_loss: 1.1350 - val_accuracy: 0.6667\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2553 - accuracy: 0.8778 - val_loss: 1.1281 - val_accuracy: 0.6667\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2604 - accuracy: 0.8778 - val_loss: 1.1535 - val_accuracy: 0.6581\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2561 - accuracy: 0.8852 - val_loss: 1.2160 - val_accuracy: 0.6581\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2640 - accuracy: 0.8815 - val_loss: 1.1918 - val_accuracy: 0.6667\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2562 - accuracy: 0.8852 - val_loss: 1.1326 - val_accuracy: 0.6667\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2566 - accuracy: 0.8778 - val_loss: 1.1347 - val_accuracy: 0.6667\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2524 - accuracy: 0.8704 - val_loss: 1.1893 - val_accuracy: 0.6667\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.89 - 0s 78us/step - loss: 0.2584 - accuracy: 0.8778 - val_loss: 1.1717 - val_accuracy: 0.6667\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2583 - accuracy: 0.8778 - val_loss: 1.1514 - val_accuracy: 0.6667\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2529 - accuracy: 0.8778 - val_loss: 1.1581 - val_accuracy: 0.6667\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 1.1710 - val_accuracy: 0.6581\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2548 - accuracy: 0.8815 - val_loss: 1.1521 - val_accuracy: 0.6581\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2558 - accuracy: 0.8741 - val_loss: 1.1229 - val_accuracy: 0.6752\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2521 - accuracy: 0.8778 - val_loss: 1.1347 - val_accuracy: 0.6667\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 340us/step - loss: 0.2546 - accuracy: 0.8667 - val_loss: 1.1802 - val_accuracy: 0.6496\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2534 - accuracy: 0.8815 - val_loss: 1.1552 - val_accuracy: 0.6667\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2578 - accuracy: 0.8741 - val_loss: 1.1621 - val_accuracy: 0.6838\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2550 - accuracy: 0.8778 - val_loss: 1.2030 - val_accuracy: 0.6667\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2577 - accuracy: 0.8741 - val_loss: 1.1834 - val_accuracy: 0.6667\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2583 - accuracy: 0.8741 - val_loss: 1.1811 - val_accuracy: 0.6581\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 1.2168 - val_accuracy: 0.6667\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2562 - accuracy: 0.8741 - val_loss: 1.2367 - val_accuracy: 0.6581\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2566 - accuracy: 0.8778 - val_loss: 1.1906 - val_accuracy: 0.6496\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2528 - accuracy: 0.8815 - val_loss: 1.1842 - val_accuracy: 0.6496\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.1605 - val_accuracy: 0.6752\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2528 - accuracy: 0.8741 - val_loss: 1.1597 - val_accuracy: 0.6752\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.2551 - accuracy: 0.8704 - val_loss: 1.1921 - val_accuracy: 0.6752\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.2305 - val_accuracy: 0.6581\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 1.2140 - val_accuracy: 0.6581\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 1.2043 - val_accuracy: 0.6581\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2508 - accuracy: 0.8704 - val_loss: 1.1816 - val_accuracy: 0.6752\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2484 - accuracy: 0.8741 - val_loss: 1.1638 - val_accuracy: 0.6667\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2525 - accuracy: 0.8704 - val_loss: 1.1938 - val_accuracy: 0.6581\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2547 - accuracy: 0.8778 - val_loss: 1.2385 - val_accuracy: 0.6581\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2504 - accuracy: 0.8778 - val_loss: 1.2281 - val_accuracy: 0.6667\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2567 - accuracy: 0.8815 - val_loss: 1.2237 - val_accuracy: 0.6752\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2522 - accuracy: 0.8778 - val_loss: 1.2569 - val_accuracy: 0.6581\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2572 - accuracy: 0.8815 - val_loss: 1.2551 - val_accuracy: 0.6581\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2559 - accuracy: 0.8815 - val_loss: 1.2015 - val_accuracy: 0.6581\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.1616 - val_accuracy: 0.6752\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 1.1817 - val_accuracy: 0.6752\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2499 - accuracy: 0.8741 - val_loss: 1.1967 - val_accuracy: 0.6581\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2517 - accuracy: 0.8815 - val_loss: 1.2029 - val_accuracy: 0.6752\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2512 - accuracy: 0.8741 - val_loss: 1.2259 - val_accuracy: 0.6667\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 1.2406 - val_accuracy: 0.6581\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 1.2229 - val_accuracy: 0.6581\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.1926 - val_accuracy: 0.6838\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2607 - accuracy: 0.8704 - val_loss: 1.1652 - val_accuracy: 0.6838\n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 73us/step - loss: 0.2583 - accuracy: 0.8741 - val_loss: 1.2103 - val_accuracy: 0.6581\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2569 - accuracy: 0.8852 - val_loss: 1.2475 - val_accuracy: 0.6581\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2560 - accuracy: 0.8815 - val_loss: 1.2450 - val_accuracy: 0.6581\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 1.2071 - val_accuracy: 0.6667\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2547 - accuracy: 0.8667 - val_loss: 1.2227 - val_accuracy: 0.6667\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2509 - accuracy: 0.8815 - val_loss: 1.2259 - val_accuracy: 0.6581\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2501 - accuracy: 0.8815 - val_loss: 1.2174 - val_accuracy: 0.6667\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.1939 - val_accuracy: 0.6838\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2576 - accuracy: 0.8667 - val_loss: 1.2059 - val_accuracy: 0.6838\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2514 - accuracy: 0.8704 - val_loss: 1.2133 - val_accuracy: 0.6581\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2541 - accuracy: 0.8815 - val_loss: 1.2273 - val_accuracy: 0.6581\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2521 - accuracy: 0.8704 - val_loss: 1.1961 - val_accuracy: 0.6581\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.1886 - val_accuracy: 0.6667\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.2485 - accuracy: 0.8741 - val_loss: 1.2018 - val_accuracy: 0.6581\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 1.2174 - val_accuracy: 0.6581\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.2351 - val_accuracy: 0.6581\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.2212 - val_accuracy: 0.6581\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2537 - accuracy: 0.8778 - val_loss: 1.2165 - val_accuracy: 0.6667\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2514 - accuracy: 0.8852 - val_loss: 1.2466 - val_accuracy: 0.6581\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2519 - accuracy: 0.8741 - val_loss: 1.2629 - val_accuracy: 0.6752\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 1.2525 - val_accuracy: 0.6581\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2483 - accuracy: 0.8815 - val_loss: 1.2571 - val_accuracy: 0.6496\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 1.2489 - val_accuracy: 0.6496\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2563 - accuracy: 0.8778 - val_loss: 1.2465 - val_accuracy: 0.6667\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 1.2268 - val_accuracy: 0.6752\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2563 - accuracy: 0.8741 - val_loss: 1.2816 - val_accuracy: 0.6581\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2545 - accuracy: 0.8852 - val_loss: 1.2956 - val_accuracy: 0.6581\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 1.2363 - val_accuracy: 0.6581\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.2306 - val_accuracy: 0.6581\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.2305 - val_accuracy: 0.6581\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2536 - accuracy: 0.8741 - val_loss: 1.2049 - val_accuracy: 0.6752\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2500 - accuracy: 0.8704 - val_loss: 1.2380 - val_accuracy: 0.6581\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2499 - accuracy: 0.8815 - val_loss: 1.2659 - val_accuracy: 0.6581\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2605 - accuracy: 0.8815 - val_loss: 1.2669 - val_accuracy: 0.6581\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2548 - accuracy: 0.8741 - val_loss: 1.2430 - val_accuracy: 0.6667\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2547 - accuracy: 0.8741 - val_loss: 1.2392 - val_accuracy: 0.6667\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 1.2416 - val_accuracy: 0.6581\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2515 - accuracy: 0.8815 - val_loss: 1.2432 - val_accuracy: 0.6581\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2505 - accuracy: 0.8778 - val_loss: 1.2374 - val_accuracy: 0.6581\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.2560 - val_accuracy: 0.6581\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.2494 - val_accuracy: 0.6581\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2533 - accuracy: 0.8852 - val_loss: 1.2334 - val_accuracy: 0.6667\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.2579 - val_accuracy: 0.6667\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2532 - accuracy: 0.8741 - val_loss: 1.2530 - val_accuracy: 0.6752\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.2306 - val_accuracy: 0.6496\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 1.2266 - val_accuracy: 0.6581\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.2214 - val_accuracy: 0.6752\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2493 - accuracy: 0.8667 - val_loss: 1.2335 - val_accuracy: 0.6752\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2485 - accuracy: 0.8741 - val_loss: 1.2672 - val_accuracy: 0.6581\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.2443 - val_accuracy: 0.6667\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.1958 - val_accuracy: 0.6667\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2627 - accuracy: 0.8778 - val_loss: 1.2100 - val_accuracy: 0.6752\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2552 - accuracy: 0.8778 - val_loss: 1.2840 - val_accuracy: 0.6581\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 1.2632 - val_accuracy: 0.6581\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.2506 - val_accuracy: 0.6667\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2716 - accuracy: 0.8741 - val_loss: 1.2426 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2586 - accuracy: 0.8630 - val_loss: 1.2214 - val_accuracy: 0.6581\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.2439 - val_accuracy: 0.6496\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2514 - accuracy: 0.8778 - val_loss: 1.2715 - val_accuracy: 0.6496\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 1.2344 - val_accuracy: 0.6581\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2493 - accuracy: 0.8815 - val_loss: 1.2619 - val_accuracy: 0.6581\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 1.2627 - val_accuracy: 0.6752\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2542 - accuracy: 0.8778 - val_loss: 1.2719 - val_accuracy: 0.6752\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2490 - accuracy: 0.8741 - val_loss: 1.2677 - val_accuracy: 0.6496\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2492 - accuracy: 0.8778 - val_loss: 1.2580 - val_accuracy: 0.6496\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.2381 - val_accuracy: 0.6752\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.2483 - val_accuracy: 0.6667\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 1.2788 - val_accuracy: 0.6496\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.2846 - val_accuracy: 0.6496\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.2490 - val_accuracy: 0.6667\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2471 - accuracy: 0.8667 - val_loss: 1.2452 - val_accuracy: 0.6667\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2503 - accuracy: 0.8667 - val_loss: 1.2404 - val_accuracy: 0.6752\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2522 - accuracy: 0.8852 - val_loss: 1.2759 - val_accuracy: 0.6667\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.2862 - val_accuracy: 0.6581\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 1.2745 - val_accuracy: 0.6581\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.2665 - val_accuracy: 0.6496\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2464 - accuracy: 0.8852 - val_loss: 1.2507 - val_accuracy: 0.6667\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.2609 - val_accuracy: 0.6667\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2493 - accuracy: 0.8741 - val_loss: 1.2763 - val_accuracy: 0.6496\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.2686 - val_accuracy: 0.6496\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2509 - accuracy: 0.8667 - val_loss: 1.2531 - val_accuracy: 0.6581\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2526 - accuracy: 0.8630 - val_loss: 1.2831 - val_accuracy: 0.6667\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2524 - accuracy: 0.8667 - val_loss: 1.2727 - val_accuracy: 0.6496\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2473 - accuracy: 0.8667 - val_loss: 1.2618 - val_accuracy: 0.6581\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2508 - accuracy: 0.8630 - val_loss: 1.2888 - val_accuracy: 0.6581\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.2814 - val_accuracy: 0.6581\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2504 - accuracy: 0.8667 - val_loss: 1.2695 - val_accuracy: 0.6667\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.2668 - val_accuracy: 0.6667\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.2993 - val_accuracy: 0.6667\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.3050 - val_accuracy: 0.6667\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2494 - accuracy: 0.8741 - val_loss: 1.2955 - val_accuracy: 0.6667\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.2679 - val_accuracy: 0.6581\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 1.2735 - val_accuracy: 0.6581\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.3189 - val_accuracy: 0.6581\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.3036 - val_accuracy: 0.6667\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2624 - accuracy: 0.8741 - val_loss: 1.2628 - val_accuracy: 0.6752\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2557 - accuracy: 0.8667 - val_loss: 1.2401 - val_accuracy: 0.6667\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2532 - accuracy: 0.8778 - val_loss: 1.2847 - val_accuracy: 0.6581\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2560 - accuracy: 0.8815 - val_loss: 1.3342 - val_accuracy: 0.6581\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2586 - accuracy: 0.8815 - val_loss: 1.3220 - val_accuracy: 0.6581\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2516 - accuracy: 0.8852 - val_loss: 1.2213 - val_accuracy: 0.6838\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2509 - accuracy: 0.8741 - val_loss: 1.1954 - val_accuracy: 0.6838\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2526 - accuracy: 0.8741 - val_loss: 1.2522 - val_accuracy: 0.6667\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.3109 - val_accuracy: 0.6581\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 1.3214 - val_accuracy: 0.6581\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2503 - accuracy: 0.8704 - val_loss: 1.2730 - val_accuracy: 0.6581\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2458 - accuracy: 0.8852 - val_loss: 1.2628 - val_accuracy: 0.6752\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.3017 - val_accuracy: 0.6581\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 1.3099 - val_accuracy: 0.6581\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 1.2746 - val_accuracy: 0.6667\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2598 - accuracy: 0.8778 - val_loss: 1.2830 - val_accuracy: 0.6667\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2426 - accuracy: 0.8889 - val_loss: 1.3416 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.2660 - accuracy: 0.8741 - val_loss: 1.3394 - val_accuracy: 0.6667\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2614 - accuracy: 0.8778 - val_loss: 1.2705 - val_accuracy: 0.6581\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2489 - accuracy: 0.8815 - val_loss: 1.2536 - val_accuracy: 0.6581\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.2733 - val_accuracy: 0.6667\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2605 - accuracy: 0.8630 - val_loss: 1.2648 - val_accuracy: 0.6752\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2499 - accuracy: 0.8630 - val_loss: 1.2768 - val_accuracy: 0.6581\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2569 - accuracy: 0.8667 - val_loss: 1.2795 - val_accuracy: 0.6581\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.2687 - val_accuracy: 0.6838\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2563 - accuracy: 0.8704 - val_loss: 1.2933 - val_accuracy: 0.6838\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2507 - accuracy: 0.8704 - val_loss: 1.2872 - val_accuracy: 0.6667\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2536 - accuracy: 0.8778 - val_loss: 1.2937 - val_accuracy: 0.6667\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2542 - accuracy: 0.8852 - val_loss: 1.3275 - val_accuracy: 0.6667\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.2756 - val_accuracy: 0.6667\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.2434 - val_accuracy: 0.6752\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2530 - accuracy: 0.8704 - val_loss: 1.3036 - val_accuracy: 0.6667\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.3342 - val_accuracy: 0.6581\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.3126 - val_accuracy: 0.6581\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.2865 - val_accuracy: 0.6581\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.2719 - val_accuracy: 0.6581\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.2638 - val_accuracy: 0.6667\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.2521 - val_accuracy: 0.6667\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.2725 - val_accuracy: 0.6581\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.2808 - val_accuracy: 0.6496\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.2746 - val_accuracy: 0.6581\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.2875 - val_accuracy: 0.6667\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.3015 - val_accuracy: 0.6667\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.2987 - val_accuracy: 0.6581\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2473 - accuracy: 0.8704 - val_loss: 1.2880 - val_accuracy: 0.6667\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.2665 - val_accuracy: 0.6752\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2491 - accuracy: 0.8778 - val_loss: 1.2891 - val_accuracy: 0.6667\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.82 - 0s 48us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.3025 - val_accuracy: 0.6581\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.2910 - val_accuracy: 0.6581\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2524 - accuracy: 0.8815 - val_loss: 1.2623 - val_accuracy: 0.6667\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 1.2742 - val_accuracy: 0.6581\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.3081 - val_accuracy: 0.6581\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.3426 - val_accuracy: 0.6581\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.2954 - val_accuracy: 0.6581\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.2515 - val_accuracy: 0.6496\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2448 - accuracy: 0.8667 - val_loss: 1.2618 - val_accuracy: 0.6581\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.3032 - val_accuracy: 0.6667\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2542 - accuracy: 0.8741 - val_loss: 1.2965 - val_accuracy: 0.6667\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.2945 - val_accuracy: 0.6581\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2573 - accuracy: 0.8704 - val_loss: 1.2983 - val_accuracy: 0.6581\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 1.2833 - val_accuracy: 0.6667\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 1.2615 - val_accuracy: 0.6752\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 1.2754 - val_accuracy: 0.6667\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 1.3161 - val_accuracy: 0.6581\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3496 - val_accuracy: 0.6496\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.3053 - val_accuracy: 0.6667\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2465 - accuracy: 0.8926 - val_loss: 1.2669 - val_accuracy: 0.6752\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2503 - accuracy: 0.8741 - val_loss: 1.2909 - val_accuracy: 0.6752\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2484 - accuracy: 0.8704 - val_loss: 1.3094 - val_accuracy: 0.6667\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.3058 - val_accuracy: 0.6667\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2483 - accuracy: 0.8704 - val_loss: 1.3377 - val_accuracy: 0.6581\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2508 - accuracy: 0.8741 - val_loss: 1.3192 - val_accuracy: 0.6581\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.3108 - val_accuracy: 0.6496\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.3023 - val_accuracy: 0.6581\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.3127 - val_accuracy: 0.6496\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.3048 - val_accuracy: 0.6581\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.3121 - val_accuracy: 0.6496\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.2827 - val_accuracy: 0.6752\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.3135 - val_accuracy: 0.6667\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2528 - accuracy: 0.8556 - val_loss: 1.3332 - val_accuracy: 0.6581\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2544 - accuracy: 0.8778 - val_loss: 1.3159 - val_accuracy: 0.6667\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2509 - accuracy: 0.8815 - val_loss: 1.3102 - val_accuracy: 0.6667\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.3078 - val_accuracy: 0.6667\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2477 - accuracy: 0.8815 - val_loss: 1.3152 - val_accuracy: 0.6581\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2458 - accuracy: 0.8630 - val_loss: 1.2701 - val_accuracy: 0.6667\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.3029 - val_accuracy: 0.6667\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.3326 - val_accuracy: 0.6752\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2494 - accuracy: 0.8741 - val_loss: 1.3495 - val_accuracy: 0.6752\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.3535 - val_accuracy: 0.6581\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2499 - accuracy: 0.8667 - val_loss: 1.3066 - val_accuracy: 0.6581\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.3127 - val_accuracy: 0.6752\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2482 - accuracy: 0.8741 - val_loss: 1.3364 - val_accuracy: 0.6752\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2442 - accuracy: 0.8704 - val_loss: 1.3429 - val_accuracy: 0.6581\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.3465 - val_accuracy: 0.6581\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.3278 - val_accuracy: 0.6496\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2448 - accuracy: 0.8704 - val_loss: 1.3309 - val_accuracy: 0.6667\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.3242 - val_accuracy: 0.6667\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.2636 - val_accuracy: 0.6752\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2474 - accuracy: 0.8704 - val_loss: 1.2546 - val_accuracy: 0.6667\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2489 - accuracy: 0.8741 - val_loss: 1.2869 - val_accuracy: 0.6752\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.3378 - val_accuracy: 0.6581\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.3668 - val_accuracy: 0.6496\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2523 - accuracy: 0.8815 - val_loss: 1.3302 - val_accuracy: 0.6496\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.3045 - val_accuracy: 0.6667\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.3116 - val_accuracy: 0.6667\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2442 - accuracy: 0.8704 - val_loss: 1.3361 - val_accuracy: 0.6581\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.3330 - val_accuracy: 0.6752\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 1.3080 - val_accuracy: 0.6667\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.3228 - val_accuracy: 0.6581\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2491 - accuracy: 0.8778 - val_loss: 1.3541 - val_accuracy: 0.6496\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.3867 - val_accuracy: 0.6496\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2632 - accuracy: 0.8778 - val_loss: 1.4003 - val_accuracy: 0.6581\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2536 - accuracy: 0.8704 - val_loss: 1.3076 - val_accuracy: 0.6667\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2557 - accuracy: 0.8815 - val_loss: 1.2950 - val_accuracy: 0.6667\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2536 - accuracy: 0.8778 - val_loss: 1.3447 - val_accuracy: 0.6496\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.84 - 0s 49us/step - loss: 0.2430 - accuracy: 0.8889 - val_loss: 1.4156 - val_accuracy: 0.6667\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2583 - accuracy: 0.8704 - val_loss: 1.4002 - val_accuracy: 0.6581\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2507 - accuracy: 0.8704 - val_loss: 1.3249 - val_accuracy: 0.6496\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.2962 - val_accuracy: 0.6667\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 1.3184 - val_accuracy: 0.6667\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.3403 - val_accuracy: 0.6496\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2547 - accuracy: 0.8741 - val_loss: 1.3594 - val_accuracy: 0.6496\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.3455 - val_accuracy: 0.6410\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2527 - accuracy: 0.8556 - val_loss: 1.3309 - val_accuracy: 0.6581\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.3248 - val_accuracy: 0.6667\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2526 - accuracy: 0.8667 - val_loss: 1.3540 - val_accuracy: 0.6667\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2512 - accuracy: 0.8741 - val_loss: 1.3580 - val_accuracy: 0.6581\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 45us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.3916 - val_accuracy: 0.6496\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2514 - accuracy: 0.8815 - val_loss: 1.3763 - val_accuracy: 0.6496\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2505 - accuracy: 0.8741 - val_loss: 1.3344 - val_accuracy: 0.6752\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.2953 - val_accuracy: 0.6838\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2486 - accuracy: 0.8667 - val_loss: 1.2778 - val_accuracy: 0.6667\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2520 - accuracy: 0.8741 - val_loss: 1.3142 - val_accuracy: 0.6496\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.3416 - val_accuracy: 0.6581\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.3543 - val_accuracy: 0.6581\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.3424 - val_accuracy: 0.6581\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.3051 - val_accuracy: 0.6667\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2408 - accuracy: 0.8889 - val_loss: 1.3025 - val_accuracy: 0.6752\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2519 - accuracy: 0.8778 - val_loss: 1.3335 - val_accuracy: 0.6752\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.3672 - val_accuracy: 0.6581\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.3773 - val_accuracy: 0.6581\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 1.3490 - val_accuracy: 0.6581\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.3386 - val_accuracy: 0.6581\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2457 - accuracy: 0.8741 - val_loss: 1.3271 - val_accuracy: 0.6667\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2434 - accuracy: 0.8667 - val_loss: 1.3263 - val_accuracy: 0.6752\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.3303 - val_accuracy: 0.6667\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.3255 - val_accuracy: 0.6752\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 1.3389 - val_accuracy: 0.6667\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.3345 - val_accuracy: 0.6581\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.2953 - val_accuracy: 0.6667\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2546 - accuracy: 0.8556 - val_loss: 1.3131 - val_accuracy: 0.6581\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2527 - accuracy: 0.8556 - val_loss: 1.3397 - val_accuracy: 0.6581\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.3339 - val_accuracy: 0.6667\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.3434 - val_accuracy: 0.6667\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2508 - accuracy: 0.8741 - val_loss: 1.4054 - val_accuracy: 0.6667\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2503 - accuracy: 0.8667 - val_loss: 1.3791 - val_accuracy: 0.6667\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.3746 - val_accuracy: 0.6667\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.3721 - val_accuracy: 0.6581\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.3606 - val_accuracy: 0.6667\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.3452 - val_accuracy: 0.6752\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 1.3583 - val_accuracy: 0.6752\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.3811 - val_accuracy: 0.6581\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.3611 - val_accuracy: 0.6581\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2536 - accuracy: 0.8519 - val_loss: 1.3110 - val_accuracy: 0.6581\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2518 - accuracy: 0.8481 - val_loss: 1.3174 - val_accuracy: 0.6667\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 1.3314 - val_accuracy: 0.6581\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2451 - accuracy: 0.8704 - val_loss: 1.3309 - val_accuracy: 0.6581\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.3256 - val_accuracy: 0.6667\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.3483 - val_accuracy: 0.6581\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3652 - val_accuracy: 0.6581\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.3682 - val_accuracy: 0.6581\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2451 - accuracy: 0.8704 - val_loss: 1.3292 - val_accuracy: 0.6667\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.3364 - val_accuracy: 0.6667\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.3506 - val_accuracy: 0.6752\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.3577 - val_accuracy: 0.6752\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2450 - accuracy: 0.8926 - val_loss: 1.3638 - val_accuracy: 0.6667\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.3452 - val_accuracy: 0.6667\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.3105 - val_accuracy: 0.6752\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.3359 - val_accuracy: 0.6667\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.3951 - val_accuracy: 0.6752\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.4035 - val_accuracy: 0.6667\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 1.3790 - val_accuracy: 0.6581\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2528 - accuracy: 0.8815 - val_loss: 1.3615 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.3237 - val_accuracy: 0.6667\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.3074 - val_accuracy: 0.6667\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2465 - accuracy: 0.8630 - val_loss: 1.3101 - val_accuracy: 0.6752\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.3393 - val_accuracy: 0.6752\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.3493 - val_accuracy: 0.6752\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2460 - accuracy: 0.8704 - val_loss: 1.3597 - val_accuracy: 0.6838\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.3686 - val_accuracy: 0.6667\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.3518 - val_accuracy: 0.6752\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.3287 - val_accuracy: 0.6752\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.3255 - val_accuracy: 0.6752\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.3410 - val_accuracy: 0.6752\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 1.3979 - val_accuracy: 0.6496\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2493 - accuracy: 0.8815 - val_loss: 1.3933 - val_accuracy: 0.6496\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.3393 - val_accuracy: 0.6667\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2542 - accuracy: 0.8778 - val_loss: 1.3369 - val_accuracy: 0.6667\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 1.3745 - val_accuracy: 0.6581\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.3973 - val_accuracy: 0.6496\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2557 - accuracy: 0.8556 - val_loss: 1.4054 - val_accuracy: 0.6410\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2496 - accuracy: 0.8741 - val_loss: 1.3662 - val_accuracy: 0.6667\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2452 - accuracy: 0.8741 - val_loss: 1.3210 - val_accuracy: 0.6752\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.3239 - val_accuracy: 0.6667\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2396 - accuracy: 0.8778 - val_loss: 1.3628 - val_accuracy: 0.6496\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2529 - accuracy: 0.8815 - val_loss: 1.3942 - val_accuracy: 0.6496\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2519 - accuracy: 0.8778 - val_loss: 1.3565 - val_accuracy: 0.6581\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.3515 - val_accuracy: 0.6667\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2491 - accuracy: 0.8630 - val_loss: 1.3308 - val_accuracy: 0.6752\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2509 - accuracy: 0.8741 - val_loss: 1.3076 - val_accuracy: 0.6752\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2461 - accuracy: 0.8667 - val_loss: 1.3506 - val_accuracy: 0.6581\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2447 - accuracy: 0.8704 - val_loss: 1.3517 - val_accuracy: 0.6581\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 1.3680 - val_accuracy: 0.6581\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2447 - accuracy: 0.8852 - val_loss: 1.3465 - val_accuracy: 0.6752\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.3443 - val_accuracy: 0.6667\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.3720 - val_accuracy: 0.6667\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.3811 - val_accuracy: 0.6581\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 1.3468 - val_accuracy: 0.6581\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 1.3457 - val_accuracy: 0.6667\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2471 - accuracy: 0.8741 - val_loss: 1.3598 - val_accuracy: 0.6581\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.3537 - val_accuracy: 0.6581\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.3612 - val_accuracy: 0.6581\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2558 - accuracy: 0.8704 - val_loss: 1.3948 - val_accuracy: 0.6581\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2534 - accuracy: 0.8815 - val_loss: 1.4240 - val_accuracy: 0.6581\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2556 - accuracy: 0.8815 - val_loss: 1.4289 - val_accuracy: 0.6581\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2480 - accuracy: 0.8815 - val_loss: 1.3494 - val_accuracy: 0.6667\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2495 - accuracy: 0.8852 - val_loss: 1.2987 - val_accuracy: 0.6667\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.3342 - val_accuracy: 0.6667\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.3886 - val_accuracy: 0.6581\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2511 - accuracy: 0.8815 - val_loss: 1.4083 - val_accuracy: 0.6581\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.3770 - val_accuracy: 0.6496\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.3381 - val_accuracy: 0.6667\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2469 - accuracy: 0.8667 - val_loss: 1.3262 - val_accuracy: 0.6752\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.3810 - val_accuracy: 0.6581\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.4135 - val_accuracy: 0.6667\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.3900 - val_accuracy: 0.6581\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.3450 - val_accuracy: 0.6667\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 1.3403 - val_accuracy: 0.6667\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.3695 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.4160 - val_accuracy: 0.6667\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.3846 - val_accuracy: 0.6667\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.3250 - val_accuracy: 0.6667\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.3532 - val_accuracy: 0.6496\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.4083 - val_accuracy: 0.6581\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2452 - accuracy: 0.8852 - val_loss: 1.3934 - val_accuracy: 0.6581\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.3921 - val_accuracy: 0.6581\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 1.3516 - val_accuracy: 0.6581\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3658 - val_accuracy: 0.6667\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.3792 - val_accuracy: 0.6581\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2486 - accuracy: 0.8778 - val_loss: 1.3831 - val_accuracy: 0.6581\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2439 - accuracy: 0.8852 - val_loss: 1.3447 - val_accuracy: 0.6838\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.3302 - val_accuracy: 0.6752\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2441 - accuracy: 0.8741 - val_loss: 1.3671 - val_accuracy: 0.6581\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3919 - val_accuracy: 0.6496\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.3580 - val_accuracy: 0.6581\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.3443 - val_accuracy: 0.6667\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2504 - accuracy: 0.8741 - val_loss: 1.3374 - val_accuracy: 0.6667\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.3763 - val_accuracy: 0.6581\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2422 - accuracy: 0.8852 - val_loss: 1.3994 - val_accuracy: 0.6667\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2487 - accuracy: 0.8741 - val_loss: 1.4215 - val_accuracy: 0.6667\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.3811 - val_accuracy: 0.6752\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.3411 - val_accuracy: 0.6752\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.3324 - val_accuracy: 0.6838\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2471 - accuracy: 0.8741 - val_loss: 1.3402 - val_accuracy: 0.6667\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.3712 - val_accuracy: 0.6667\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.3781 - val_accuracy: 0.6667\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.3594 - val_accuracy: 0.6752\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2448 - accuracy: 0.8704 - val_loss: 1.3458 - val_accuracy: 0.6838\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2476 - accuracy: 0.8741 - val_loss: 1.3553 - val_accuracy: 0.6838\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2450 - accuracy: 0.8704 - val_loss: 1.3774 - val_accuracy: 0.6752\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.3986 - val_accuracy: 0.6667\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.4059 - val_accuracy: 0.6752\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2501 - accuracy: 0.8741 - val_loss: 1.3802 - val_accuracy: 0.6667\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.3755 - val_accuracy: 0.6667\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.3674 - val_accuracy: 0.6581\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.3509 - val_accuracy: 0.6667\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.3992 - val_accuracy: 0.6581\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.4050 - val_accuracy: 0.6581\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.4094 - val_accuracy: 0.6581\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.4095 - val_accuracy: 0.6496\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2469 - accuracy: 0.8704 - val_loss: 1.3787 - val_accuracy: 0.6667\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2484 - accuracy: 0.8630 - val_loss: 1.3793 - val_accuracy: 0.6752\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.3753 - val_accuracy: 0.6838\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.3739 - val_accuracy: 0.6752\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.3992 - val_accuracy: 0.6667\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.4463 - val_accuracy: 0.6581\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2494 - accuracy: 0.8815 - val_loss: 1.4268 - val_accuracy: 0.6581\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.3781 - val_accuracy: 0.6667\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.3657 - val_accuracy: 0.6667\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3929 - val_accuracy: 0.6667\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.3778 - val_accuracy: 0.6581\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.3663 - val_accuracy: 0.6581\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.3781 - val_accuracy: 0.6581\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.3789 - val_accuracy: 0.6752\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.3422 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2530 - accuracy: 0.8741 - val_loss: 1.3355 - val_accuracy: 0.6838\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2563 - accuracy: 0.8741 - val_loss: 1.3634 - val_accuracy: 0.6838\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2469 - accuracy: 0.8630 - val_loss: 1.4036 - val_accuracy: 0.6667\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2506 - accuracy: 0.8815 - val_loss: 1.4163 - val_accuracy: 0.6581\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2498 - accuracy: 0.8815 - val_loss: 1.3832 - val_accuracy: 0.6667\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2403 - accuracy: 0.8889 - val_loss: 1.3366 - val_accuracy: 0.6752\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2519 - accuracy: 0.8704 - val_loss: 1.3621 - val_accuracy: 0.6667\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2510 - accuracy: 0.8741 - val_loss: 1.3855 - val_accuracy: 0.6581\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.4138 - val_accuracy: 0.6581\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.3852 - val_accuracy: 0.6581\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.3282 - val_accuracy: 0.6667\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2550 - accuracy: 0.8667 - val_loss: 1.3595 - val_accuracy: 0.6752\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2512 - accuracy: 0.8593 - val_loss: 1.4121 - val_accuracy: 0.6410\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2518 - accuracy: 0.8519 - val_loss: 1.4253 - val_accuracy: 0.6496\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.3822 - val_accuracy: 0.6752\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.3738 - val_accuracy: 0.6667\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.4137 - val_accuracy: 0.6581\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2494 - accuracy: 0.8815 - val_loss: 1.4062 - val_accuracy: 0.6581\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.4029 - val_accuracy: 0.6581\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2405 - accuracy: 0.8889 - val_loss: 1.3688 - val_accuracy: 0.6667\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2503 - accuracy: 0.8778 - val_loss: 1.3764 - val_accuracy: 0.6581\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.3839 - val_accuracy: 0.6667\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.3850 - val_accuracy: 0.6752\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2429 - accuracy: 0.8741 - val_loss: 1.3957 - val_accuracy: 0.6667\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.4260 - val_accuracy: 0.6581\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.4333 - val_accuracy: 0.6667\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.4338 - val_accuracy: 0.6667\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3932 - val_accuracy: 0.6667\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.3468 - val_accuracy: 0.6667\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2546 - accuracy: 0.8667 - val_loss: 1.3709 - val_accuracy: 0.6496\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.4110 - val_accuracy: 0.6581\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2500 - accuracy: 0.8667 - val_loss: 1.4099 - val_accuracy: 0.6752\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2489 - accuracy: 0.8741 - val_loss: 1.3643 - val_accuracy: 0.6752\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.3637 - val_accuracy: 0.6667\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3931 - val_accuracy: 0.6581\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.4287 - val_accuracy: 0.6581\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.4387 - val_accuracy: 0.6581\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.3966 - val_accuracy: 0.6667\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.3839 - val_accuracy: 0.6752\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.3766 - val_accuracy: 0.6752\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.3833 - val_accuracy: 0.6752\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 1.4192 - val_accuracy: 0.6667\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.4323 - val_accuracy: 0.6667\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.4227 - val_accuracy: 0.6752\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 1.3771 - val_accuracy: 0.6752\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.3507 - val_accuracy: 0.6752\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2483 - accuracy: 0.8741 - val_loss: 1.3736 - val_accuracy: 0.6667\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2497 - accuracy: 0.8519 - val_loss: 1.4221 - val_accuracy: 0.6496\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.4325 - val_accuracy: 0.6667\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.84 - 0s 70us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.3961 - val_accuracy: 0.6752\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.3789 - val_accuracy: 0.6752\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.3618 - val_accuracy: 0.6752\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.3970 - val_accuracy: 0.6752\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.4275 - val_accuracy: 0.6752\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.3925 - val_accuracy: 0.6752\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2423 - accuracy: 0.8667 - val_loss: 1.3903 - val_accuracy: 0.6581\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.4136 - val_accuracy: 0.6752\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2441 - accuracy: 0.8741 - val_loss: 1.4183 - val_accuracy: 0.6667\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.4145 - val_accuracy: 0.6667\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2429 - accuracy: 0.8852 - val_loss: 1.3896 - val_accuracy: 0.6752\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2542 - accuracy: 0.8778 - val_loss: 1.3890 - val_accuracy: 0.6752\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.4555 - val_accuracy: 0.6667\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.89 - 0s 69us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.4746 - val_accuracy: 0.6667\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2470 - accuracy: 0.8778 - val_loss: 1.4447 - val_accuracy: 0.6667\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.4346 - val_accuracy: 0.6667\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.3957 - val_accuracy: 0.6752\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2418 - accuracy: 0.8778 - val_loss: 1.3865 - val_accuracy: 0.6752\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.4053 - val_accuracy: 0.6667\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.4208 - val_accuracy: 0.6667\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.4334 - val_accuracy: 0.6667\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.4478 - val_accuracy: 0.6667\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.4118 - val_accuracy: 0.6667\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2410 - accuracy: 0.8889 - val_loss: 1.3765 - val_accuracy: 0.6752\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2530 - accuracy: 0.8778 - val_loss: 1.3560 - val_accuracy: 0.6752\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2469 - accuracy: 0.8667 - val_loss: 1.3962 - val_accuracy: 0.6752\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 1.4363 - val_accuracy: 0.6752\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.4553 - val_accuracy: 0.6667\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.4245 - val_accuracy: 0.6667\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.4157 - val_accuracy: 0.6667\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.4100 - val_accuracy: 0.6752\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.4002 - val_accuracy: 0.6838\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.4135 - val_accuracy: 0.6838\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.4017 - val_accuracy: 0.6667\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.4240 - val_accuracy: 0.6667\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.4261 - val_accuracy: 0.6667\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2465 - accuracy: 0.8704 - val_loss: 1.4343 - val_accuracy: 0.6581\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.4528 - val_accuracy: 0.6667\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.4366 - val_accuracy: 0.6752\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.4092 - val_accuracy: 0.6752\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2530 - accuracy: 0.8778 - val_loss: 1.4071 - val_accuracy: 0.6752\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2500 - accuracy: 0.8778 - val_loss: 1.4115 - val_accuracy: 0.6752\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 1.3997 - val_accuracy: 0.6752\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.4258 - val_accuracy: 0.6667\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.4041 - val_accuracy: 0.6581\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.3691 - val_accuracy: 0.6838\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2441 - accuracy: 0.8741 - val_loss: 1.3718 - val_accuracy: 0.6838\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2479 - accuracy: 0.8704 - val_loss: 1.3777 - val_accuracy: 0.6752\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.4032 - val_accuracy: 0.6581\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.4205 - val_accuracy: 0.6581\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2509 - accuracy: 0.8815 - val_loss: 1.4305 - val_accuracy: 0.6581\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2481 - accuracy: 0.8815 - val_loss: 1.4347 - val_accuracy: 0.6581\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.3853 - val_accuracy: 0.6581\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 1.3521 - val_accuracy: 0.6838\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2495 - accuracy: 0.8741 - val_loss: 1.3828 - val_accuracy: 0.6752\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.4614 - val_accuracy: 0.6581\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.4836 - val_accuracy: 0.6581\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2513 - accuracy: 0.8778 - val_loss: 1.4383 - val_accuracy: 0.6667\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.3718 - val_accuracy: 0.6667\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2471 - accuracy: 0.8741 - val_loss: 1.3690 - val_accuracy: 0.6667\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.4100 - val_accuracy: 0.6581\n",
      "Epoch 889/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 78us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.4418 - val_accuracy: 0.6581\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 1.4625 - val_accuracy: 0.6667\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.4313 - val_accuracy: 0.6667\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.3800 - val_accuracy: 0.6667\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.3859 - val_accuracy: 0.6325\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2506 - accuracy: 0.8667 - val_loss: 1.4404 - val_accuracy: 0.6667\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.4838 - val_accuracy: 0.6667\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2486 - accuracy: 0.8741 - val_loss: 1.5095 - val_accuracy: 0.6667\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2586 - accuracy: 0.8741 - val_loss: 1.4248 - val_accuracy: 0.6667\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2458 - accuracy: 0.8704 - val_loss: 1.3692 - val_accuracy: 0.6667\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2483 - accuracy: 0.8778 - val_loss: 1.3782 - val_accuracy: 0.6667\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 1.4102 - val_accuracy: 0.6581\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2449 - accuracy: 0.8852 - val_loss: 1.4704 - val_accuracy: 0.6667\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.4962 - val_accuracy: 0.6667\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2506 - accuracy: 0.8815 - val_loss: 1.4708 - val_accuracy: 0.6667\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.4364 - val_accuracy: 0.6752\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.3911 - val_accuracy: 0.6752\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.4073 - val_accuracy: 0.6667\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.4295 - val_accuracy: 0.6667\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.4673 - val_accuracy: 0.6667\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.4657 - val_accuracy: 0.6667\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.4311 - val_accuracy: 0.6667\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2495 - accuracy: 0.8778 - val_loss: 1.4093 - val_accuracy: 0.6752\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.4058 - val_accuracy: 0.6581\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2517 - accuracy: 0.8704 - val_loss: 1.4521 - val_accuracy: 0.6667\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2556 - accuracy: 0.8741 - val_loss: 1.4402 - val_accuracy: 0.6752\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2498 - accuracy: 0.8704 - val_loss: 1.4218 - val_accuracy: 0.6581\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2512 - accuracy: 0.8667 - val_loss: 1.4053 - val_accuracy: 0.6581\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2373 - accuracy: 0.8815 - val_loss: 1.3991 - val_accuracy: 0.6667\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.4221 - val_accuracy: 0.6667\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2588 - accuracy: 0.8704 - val_loss: 1.4120 - val_accuracy: 0.6667\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2473 - accuracy: 0.8741 - val_loss: 1.4010 - val_accuracy: 0.6667\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.4270 - val_accuracy: 0.6667\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 1.4578 - val_accuracy: 0.6581\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.4156 - val_accuracy: 0.6667\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.3708 - val_accuracy: 0.6667\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2685 - accuracy: 0.8704 - val_loss: 1.3836 - val_accuracy: 0.6667\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2504 - accuracy: 0.8630 - val_loss: 1.4310 - val_accuracy: 0.6752\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2436 - accuracy: 0.8704 - val_loss: 1.4779 - val_accuracy: 0.6752\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.4647 - val_accuracy: 0.6496\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.4157 - val_accuracy: 0.6496\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.4100 - val_accuracy: 0.6496\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.4183 - val_accuracy: 0.6581\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.4139 - val_accuracy: 0.6581\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.3850 - val_accuracy: 0.6667\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.4003 - val_accuracy: 0.6752\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.4139 - val_accuracy: 0.6667\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2405 - accuracy: 0.8815 - val_loss: 1.4126 - val_accuracy: 0.6667\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4085 - val_accuracy: 0.6667\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.4101 - val_accuracy: 0.6667\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.4115 - val_accuracy: 0.6752\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.4038 - val_accuracy: 0.6667\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.4126 - val_accuracy: 0.6667\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.4084 - val_accuracy: 0.6752\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4285 - val_accuracy: 0.6667\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2401 - accuracy: 0.8889 - val_loss: 1.4197 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.3904 - val_accuracy: 0.6752\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.3904 - val_accuracy: 0.6667\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.4409 - val_accuracy: 0.6581\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.4780 - val_accuracy: 0.6667\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.4665 - val_accuracy: 0.6667\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.4370 - val_accuracy: 0.6667\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.4037 - val_accuracy: 0.6752\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2516 - accuracy: 0.8778 - val_loss: 1.4172 - val_accuracy: 0.6667\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2440 - accuracy: 0.8889 - val_loss: 1.4111 - val_accuracy: 0.6752\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.4310 - val_accuracy: 0.6667\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 1.4121 - val_accuracy: 0.6581\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2518 - accuracy: 0.8704 - val_loss: 1.3545 - val_accuracy: 0.6667\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.3711 - val_accuracy: 0.6752\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.3874 - val_accuracy: 0.6752\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.4250 - val_accuracy: 0.6752\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.4532 - val_accuracy: 0.6667\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.4360 - val_accuracy: 0.6752\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.4044 - val_accuracy: 0.6667\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2479 - accuracy: 0.8778 - val_loss: 1.3912 - val_accuracy: 0.6752\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.4033 - val_accuracy: 0.6667\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.4671 - val_accuracy: 0.6752\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2505 - accuracy: 0.8778 - val_loss: 1.4393 - val_accuracy: 0.6667\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.3904 - val_accuracy: 0.6667\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2457 - accuracy: 0.8741 - val_loss: 1.3772 - val_accuracy: 0.6752\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2468 - accuracy: 0.8556 - val_loss: 1.4067 - val_accuracy: 0.6667\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2507 - accuracy: 0.8741 - val_loss: 1.4095 - val_accuracy: 0.6667\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2533 - accuracy: 0.8741 - val_loss: 1.4076 - val_accuracy: 0.6667\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.4235 - val_accuracy: 0.6667\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2461 - accuracy: 0.8667 - val_loss: 1.4159 - val_accuracy: 0.6752\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.4122 - val_accuracy: 0.6667\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2410 - accuracy: 0.8963 - val_loss: 1.4342 - val_accuracy: 0.6667\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.4466 - val_accuracy: 0.6667\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.4325 - val_accuracy: 0.6667\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.4103 - val_accuracy: 0.6752\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.4237 - val_accuracy: 0.6752\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.3985 - val_accuracy: 0.6752\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.3714 - val_accuracy: 0.6752\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2466 - accuracy: 0.8704 - val_loss: 1.3697 - val_accuracy: 0.6752\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.4220 - val_accuracy: 0.6667\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2413 - accuracy: 0.8704 - val_loss: 1.4623 - val_accuracy: 0.6667\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.4667 - val_accuracy: 0.6667\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 1.4339 - val_accuracy: 0.6581\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.4151 - val_accuracy: 0.6581\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.4109 - val_accuracy: 0.6581\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.4086 - val_accuracy: 0.6581\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.4213 - val_accuracy: 0.6667\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.4547 - val_accuracy: 0.6581\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.4986 - val_accuracy: 0.6581\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 1.4844 - val_accuracy: 0.6581\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2514 - accuracy: 0.8741 - val_loss: 1.3999 - val_accuracy: 0.6581\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2461 - accuracy: 0.8630 - val_loss: 1.3751 - val_accuracy: 0.6667\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2423 - accuracy: 0.8704 - val_loss: 1.4312 - val_accuracy: 0.6581\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.4282 - val_accuracy: 0.6581\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2402 - accuracy: 0.8778 - val_loss: 1.4128 - val_accuracy: 0.6667\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.4097 - val_accuracy: 0.6667\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2439 - accuracy: 0.8667 - val_loss: 1.4292 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3340a1d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 96us/step\n",
      "over-sampling test accuracy: 72.65%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over2 = model2_over2.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 0, 1, 2, 1, 1, 2, 2, 0, 0,\n",
       "       0, 2, 1, 1, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 0,\n",
       "       0, 1, 0, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 1, 2, 2, 0, 1, 2, 0, 1, 0, 1, 2,\n",
       "       0, 0, 0, 0, 2, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model2_over2.predict_classes(X_sel_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS249     2     2\n",
       "1         NRS188     1     1\n",
       "2         NRS232     2     2\n",
       "3          NY439     2     2\n",
       "4           GA27     2     2\n",
       "..           ...   ...   ...\n",
       "112       SR3569     0     0\n",
       "113       NRS204     0     0\n",
       "114       NRS203     0     2\n",
       "115     CFBRSa25     1     1\n",
       "116  CFBREBSa131     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model2_over2.predict_proba(X_sel_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482748e-06</td>\n",
       "      <td>3.357116e-03</td>\n",
       "      <td>0.996641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.502702e-04</td>\n",
       "      <td>8.620075e-01</td>\n",
       "      <td>0.137642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.214145e-08</td>\n",
       "      <td>1.826003e-04</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.244555e-03</td>\n",
       "      <td>3.042703e-05</td>\n",
       "      <td>0.997725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.452473e-08</td>\n",
       "      <td>5.293663e-03</td>\n",
       "      <td>0.994706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>9.999979e-01</td>\n",
       "      <td>3.866272e-08</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8.595100e-01</td>\n",
       "      <td>1.400107e-01</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8.794755e-02</td>\n",
       "      <td>4.880720e-04</td>\n",
       "      <td>0.911564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2.951578e-01</td>\n",
       "      <td>7.014401e-01</td>\n",
       "      <td>0.003402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.113034e-09</td>\n",
       "      <td>3.871774e-06</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1         2\n",
       "0    1.482748e-06  3.357116e-03  0.996641\n",
       "1    3.502702e-04  8.620075e-01  0.137642\n",
       "2    6.214145e-08  1.826003e-04  0.999817\n",
       "3    2.244555e-03  3.042703e-05  0.997725\n",
       "4    2.452473e-08  5.293663e-03  0.994706\n",
       "..            ...           ...       ...\n",
       "112  9.999979e-01  3.866272e-08  0.000002\n",
       "113  8.595100e-01  1.400107e-01  0.000479\n",
       "114  8.794755e-02  4.880720e-04  0.911564\n",
       "115  2.951578e-01  7.014401e-01  0.003402\n",
       "116  1.113034e-09  3.871774e-06  0.999996\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2518 - accuracy: 0.8778 - val_loss: 1.3424 - val_accuracy: 0.7094\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2514 - accuracy: 0.8815 - val_loss: 1.3570 - val_accuracy: 0.7094\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.3155 - val_accuracy: 0.7094\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.2681 - val_accuracy: 0.7094\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.2539 - val_accuracy: 0.7094\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2453 - accuracy: 0.8704 - val_loss: 1.2531 - val_accuracy: 0.7094\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.2822 - val_accuracy: 0.7094\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.3072 - val_accuracy: 0.7179\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2440 - accuracy: 0.8704 - val_loss: 1.3135 - val_accuracy: 0.7265\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2462 - accuracy: 0.8630 - val_loss: 1.2693 - val_accuracy: 0.7265\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.2596 - val_accuracy: 0.7265\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2482 - accuracy: 0.8667 - val_loss: 1.2791 - val_accuracy: 0.7179\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.2791 - val_accuracy: 0.7179\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.2698 - val_accuracy: 0.7179\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.2730 - val_accuracy: 0.7094\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.3012 - val_accuracy: 0.7179\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.3133 - val_accuracy: 0.7179\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.3135 - val_accuracy: 0.7179\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.3029 - val_accuracy: 0.7265\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2413 - accuracy: 0.8889 - val_loss: 1.3311 - val_accuracy: 0.7179\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 1.3411 - val_accuracy: 0.7179\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2534 - accuracy: 0.8630 - val_loss: 1.3104 - val_accuracy: 0.7094\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2565 - accuracy: 0.8556 - val_loss: 1.2725 - val_accuracy: 0.7179\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2504 - accuracy: 0.8704 - val_loss: 1.3125 - val_accuracy: 0.7179\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2524 - accuracy: 0.8741 - val_loss: 1.3544 - val_accuracy: 0.7179\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2508 - accuracy: 0.8741 - val_loss: 1.3935 - val_accuracy: 0.7094\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2520 - accuracy: 0.8815 - val_loss: 1.3472 - val_accuracy: 0.7094\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.2997 - val_accuracy: 0.7179\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.3022 - val_accuracy: 0.7179\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.3319 - val_accuracy: 0.7094\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2485 - accuracy: 0.8630 - val_loss: 1.3529 - val_accuracy: 0.7094\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.3292 - val_accuracy: 0.7179\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.3181 - val_accuracy: 0.7179\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.3239 - val_accuracy: 0.7179\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.3420 - val_accuracy: 0.7179\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.2532 - val_accuracy: 0.7179\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2444 - accuracy: 0.8667 - val_loss: 1.2274 - val_accuracy: 0.7094\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.2324 - val_accuracy: 0.7179\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2511 - accuracy: 0.8741 - val_loss: 1.2163 - val_accuracy: 0.7094\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.1937 - val_accuracy: 0.7179\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2533 - accuracy: 0.8741 - val_loss: 1.1859 - val_accuracy: 0.7179\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2488 - accuracy: 0.8630 - val_loss: 1.2533 - val_accuracy: 0.7179\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.3093 - val_accuracy: 0.7094\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.3606 - val_accuracy: 0.7009\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2494 - accuracy: 0.8778 - val_loss: 1.3519 - val_accuracy: 0.7009\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.2825 - val_accuracy: 0.7179\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2476 - accuracy: 0.8778 - val_loss: 1.2469 - val_accuracy: 0.7179\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.2950 - val_accuracy: 0.7265\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.3627 - val_accuracy: 0.7009\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2518 - accuracy: 0.8815 - val_loss: 1.3657 - val_accuracy: 0.7094\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2544 - accuracy: 0.8815 - val_loss: 1.3343 - val_accuracy: 0.7179\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2523 - accuracy: 0.8852 - val_loss: 1.2333 - val_accuracy: 0.7350\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2505 - accuracy: 0.8778 - val_loss: 1.2331 - val_accuracy: 0.7265\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.2621 - val_accuracy: 0.7265\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2445 - accuracy: 0.8667 - val_loss: 1.2649 - val_accuracy: 0.7350\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.2836 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.3314 - val_accuracy: 0.7179\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.3339 - val_accuracy: 0.7179\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.3053 - val_accuracy: 0.7265\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2471 - accuracy: 0.8704 - val_loss: 1.2688 - val_accuracy: 0.7094\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.2723 - val_accuracy: 0.7179\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 1.2804 - val_accuracy: 0.7094\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.2786 - val_accuracy: 0.7179\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.2972 - val_accuracy: 0.7094\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.3219 - val_accuracy: 0.7094\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.3158 - val_accuracy: 0.7094\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.2944 - val_accuracy: 0.7094\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.2795 - val_accuracy: 0.7094\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 1.2793 - val_accuracy: 0.7094\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.2715 - val_accuracy: 0.7179\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2565 - accuracy: 0.8741 - val_loss: 1.2714 - val_accuracy: 0.7179\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.2859 - val_accuracy: 0.7179\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.3084 - val_accuracy: 0.7179\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2433 - accuracy: 0.8852 - val_loss: 1.2885 - val_accuracy: 0.7265\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.2984 - val_accuracy: 0.7265\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.3109 - val_accuracy: 0.7265\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.3428 - val_accuracy: 0.7179\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.3617 - val_accuracy: 0.7265\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.3544 - val_accuracy: 0.7179\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 1.3397 - val_accuracy: 0.7179\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.2899 - val_accuracy: 0.7179\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.2903 - val_accuracy: 0.7179\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2433 - accuracy: 0.8741 - val_loss: 1.3022 - val_accuracy: 0.7265\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.3184 - val_accuracy: 0.7179\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.3361 - val_accuracy: 0.7179\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.3308 - val_accuracy: 0.7094\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.3159 - val_accuracy: 0.7179\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2426 - accuracy: 0.8704 - val_loss: 1.2985 - val_accuracy: 0.7094\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 1.3029 - val_accuracy: 0.7179\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.3604 - val_accuracy: 0.7094\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.3773 - val_accuracy: 0.7009\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2501 - accuracy: 0.8815 - val_loss: 1.3419 - val_accuracy: 0.7179\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.2997 - val_accuracy: 0.7179\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2540 - accuracy: 0.8704 - val_loss: 1.3366 - val_accuracy: 0.7094\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2569 - accuracy: 0.8741 - val_loss: 1.3415 - val_accuracy: 0.7009\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2435 - accuracy: 0.8852 - val_loss: 1.3097 - val_accuracy: 0.7179\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2515 - accuracy: 0.8778 - val_loss: 1.2913 - val_accuracy: 0.7179\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2484 - accuracy: 0.8741 - val_loss: 1.3156 - val_accuracy: 0.7094\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.3674 - val_accuracy: 0.7009\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 317us/step - loss: 0.2523 - accuracy: 0.8778 - val_loss: 1.3663 - val_accuracy: 0.7009\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 288us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.3007 - val_accuracy: 0.7179\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2511 - accuracy: 0.8741 - val_loss: 1.2527 - val_accuracy: 0.7265\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2481 - accuracy: 0.8741 - val_loss: 1.2737 - val_accuracy: 0.7265\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.3525 - val_accuracy: 0.7179\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.3287 - val_accuracy: 0.7179\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 1.3417 - val_accuracy: 0.7179\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.3461 - val_accuracy: 0.7179\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.3401 - val_accuracy: 0.7094\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.3386 - val_accuracy: 0.7094\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.3006 - val_accuracy: 0.7094\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.2917 - val_accuracy: 0.7179\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.2810 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.2981 - val_accuracy: 0.7179\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.3106 - val_accuracy: 0.7094\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 1.3146 - val_accuracy: 0.7179\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2523 - accuracy: 0.8778 - val_loss: 1.3018 - val_accuracy: 0.7265\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2492 - accuracy: 0.8704 - val_loss: 1.3238 - val_accuracy: 0.7179\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.3570 - val_accuracy: 0.7179\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.3974 - val_accuracy: 0.7094\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.3890 - val_accuracy: 0.7179\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.3481 - val_accuracy: 0.7094\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.3465 - val_accuracy: 0.7094\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2442 - accuracy: 0.8741 - val_loss: 1.3609 - val_accuracy: 0.7179\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.3526 - val_accuracy: 0.7179\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 262us/step - loss: 0.2482 - accuracy: 0.8815 - val_loss: 1.3345 - val_accuracy: 0.7179\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.3220 - val_accuracy: 0.7179\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.3036 - val_accuracy: 0.7094\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2457 - accuracy: 0.8630 - val_loss: 1.2881 - val_accuracy: 0.7179\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.3284 - val_accuracy: 0.7094\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.3501 - val_accuracy: 0.7094\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.3523 - val_accuracy: 0.7179\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.3474 - val_accuracy: 0.7179\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 412us/step - loss: 0.2421 - accuracy: 0.8852 - val_loss: 1.3799 - val_accuracy: 0.7094\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.3805 - val_accuracy: 0.7094\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.3487 - val_accuracy: 0.7094\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.3408 - val_accuracy: 0.7094\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 1.3568 - val_accuracy: 0.7179\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2435 - accuracy: 0.8741 - val_loss: 1.3917 - val_accuracy: 0.7265\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.4034 - val_accuracy: 0.7265\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.3784 - val_accuracy: 0.7179\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3749 - val_accuracy: 0.7265\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.3797 - val_accuracy: 0.7179\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.4058 - val_accuracy: 0.7179\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2554 - accuracy: 0.8815 - val_loss: 1.3748 - val_accuracy: 0.7179\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3568 - val_accuracy: 0.7179\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2520 - accuracy: 0.8778 - val_loss: 1.3395 - val_accuracy: 0.7179\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.3204 - val_accuracy: 0.7179\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.3646 - val_accuracy: 0.7094\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.4026 - val_accuracy: 0.7094\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.4044 - val_accuracy: 0.7094\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.3987 - val_accuracy: 0.7094\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.3582 - val_accuracy: 0.7179\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.3095 - val_accuracy: 0.7179\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.3102 - val_accuracy: 0.7094\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2547 - accuracy: 0.8667 - val_loss: 1.3109 - val_accuracy: 0.7265\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2435 - accuracy: 0.8741 - val_loss: 1.3440 - val_accuracy: 0.7265\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2524 - accuracy: 0.8741 - val_loss: 1.3848 - val_accuracy: 0.7179\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.4049 - val_accuracy: 0.7179\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2399 - accuracy: 0.8815 - val_loss: 1.4514 - val_accuracy: 0.7179\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2570 - accuracy: 0.8667 - val_loss: 1.4695 - val_accuracy: 0.7009\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2526 - accuracy: 0.8815 - val_loss: 1.4156 - val_accuracy: 0.7094\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.3781 - val_accuracy: 0.7179\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.3303 - val_accuracy: 0.7179\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.3456 - val_accuracy: 0.7179\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2422 - accuracy: 0.8852 - val_loss: 1.3631 - val_accuracy: 0.7179\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.3432 - val_accuracy: 0.7265\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2467 - accuracy: 0.8741 - val_loss: 1.3470 - val_accuracy: 0.7265\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 390us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.3666 - val_accuracy: 0.7179\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.3876 - val_accuracy: 0.7179\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.4123 - val_accuracy: 0.7009\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.4049 - val_accuracy: 0.7094\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.3990 - val_accuracy: 0.7009\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 677us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.3687 - val_accuracy: 0.7179\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.3618 - val_accuracy: 0.7179\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.3828 - val_accuracy: 0.7094\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.3862 - val_accuracy: 0.7009\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.3841 - val_accuracy: 0.7094\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.3598 - val_accuracy: 0.7179\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.3283 - val_accuracy: 0.7265\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.3472 - val_accuracy: 0.7265\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.3878 - val_accuracy: 0.7265\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2417 - accuracy: 0.8889 - val_loss: 1.4369 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2524 - accuracy: 0.8630 - val_loss: 1.4242 - val_accuracy: 0.7094\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.3871 - val_accuracy: 0.7265\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.2460 - accuracy: 0.8741 - val_loss: 1.3769 - val_accuracy: 0.7265\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.3739 - val_accuracy: 0.7265\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.3858 - val_accuracy: 0.7179\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.4071 - val_accuracy: 0.7094\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2463 - accuracy: 0.8593 - val_loss: 1.3910 - val_accuracy: 0.7265\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.3823 - val_accuracy: 0.7265\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.2408 - accuracy: 0.8778 - val_loss: 1.3832 - val_accuracy: 0.7179\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2432 - accuracy: 0.8704 - val_loss: 1.3845 - val_accuracy: 0.7094\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2447 - accuracy: 0.8815 - val_loss: 1.3965 - val_accuracy: 0.7179\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.3784 - val_accuracy: 0.7094\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3692 - val_accuracy: 0.7179\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 1.3698 - val_accuracy: 0.7265\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.4083 - val_accuracy: 0.7265\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.4261 - val_accuracy: 0.7179\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2487 - accuracy: 0.8778 - val_loss: 1.4543 - val_accuracy: 0.7094\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 1.4410 - val_accuracy: 0.7179\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.4224 - val_accuracy: 0.7179\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.3895 - val_accuracy: 0.7179\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.3730 - val_accuracy: 0.7179\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2529 - accuracy: 0.8741 - val_loss: 1.3373 - val_accuracy: 0.7350\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2497 - accuracy: 0.8741 - val_loss: 1.3770 - val_accuracy: 0.7179\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.4606 - val_accuracy: 0.7094\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 1.4721 - val_accuracy: 0.7009\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.4089 - val_accuracy: 0.7094\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.3272 - val_accuracy: 0.6838\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.2541 - accuracy: 0.8630 - val_loss: 1.3341 - val_accuracy: 0.7179\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.3846 - val_accuracy: 0.7265\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2473 - accuracy: 0.8741 - val_loss: 1.4203 - val_accuracy: 0.7179\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2492 - accuracy: 0.8741 - val_loss: 1.4051 - val_accuracy: 0.7179\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.3605 - val_accuracy: 0.7094\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2485 - accuracy: 0.8704 - val_loss: 1.3426 - val_accuracy: 0.7179\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2506 - accuracy: 0.8778 - val_loss: 1.3567 - val_accuracy: 0.7179\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 1.4074 - val_accuracy: 0.7094\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.3970 - val_accuracy: 0.7009\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.3752 - val_accuracy: 0.7094\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2443 - accuracy: 0.8778 - val_loss: 1.3485 - val_accuracy: 0.7265\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2430 - accuracy: 0.8741 - val_loss: 1.3544 - val_accuracy: 0.7179\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.3409 - val_accuracy: 0.7265\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 74us/step - loss: 0.2425 - accuracy: 0.8741 - val_loss: 1.3900 - val_accuracy: 0.7179\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.4356 - val_accuracy: 0.7179\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.4268 - val_accuracy: 0.7094\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 1.3966 - val_accuracy: 0.7094\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 432us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.3891 - val_accuracy: 0.7179\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.3865 - val_accuracy: 0.7179\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 252us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.4050 - val_accuracy: 0.7179\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 276us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.4300 - val_accuracy: 0.7094\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.4159 - val_accuracy: 0.7094\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2444 - accuracy: 0.8667 - val_loss: 1.3646 - val_accuracy: 0.7179\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.3885 - val_accuracy: 0.7179\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.4216 - val_accuracy: 0.7094\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.4533 - val_accuracy: 0.7009\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.4372 - val_accuracy: 0.7009\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.4191 - val_accuracy: 0.7094\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.4053 - val_accuracy: 0.7179\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.3930 - val_accuracy: 0.7094\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2394 - accuracy: 0.8889 - val_loss: 1.3789 - val_accuracy: 0.7179\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.3758 - val_accuracy: 0.7265\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2444 - accuracy: 0.8667 - val_loss: 1.4298 - val_accuracy: 0.7094\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.4650 - val_accuracy: 0.7179\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.4769 - val_accuracy: 0.7094\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.4270 - val_accuracy: 0.7179\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2448 - accuracy: 0.8741 - val_loss: 1.3610 - val_accuracy: 0.7350\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2458 - accuracy: 0.8741 - val_loss: 1.3727 - val_accuracy: 0.7350\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4026 - val_accuracy: 0.7179\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.4500 - val_accuracy: 0.7094\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.4187 - val_accuracy: 0.7179\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 356us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.3993 - val_accuracy: 0.7094\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 299us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.3730 - val_accuracy: 0.7179\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2506 - accuracy: 0.8778 - val_loss: 1.3802 - val_accuracy: 0.7179\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2471 - accuracy: 0.8778 - val_loss: 1.4031 - val_accuracy: 0.7179\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2455 - accuracy: 0.8704 - val_loss: 1.4207 - val_accuracy: 0.7094\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.4061 - val_accuracy: 0.7179\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.3790 - val_accuracy: 0.7350\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.4164 - val_accuracy: 0.7179\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.4368 - val_accuracy: 0.7094\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.4318 - val_accuracy: 0.7094\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.4170 - val_accuracy: 0.7094\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.4155 - val_accuracy: 0.7179\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2438 - accuracy: 0.8815 - val_loss: 1.3923 - val_accuracy: 0.7179\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.4265 - val_accuracy: 0.7094\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.4350 - val_accuracy: 0.7094\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2448 - accuracy: 0.8815 - val_loss: 1.4214 - val_accuracy: 0.7179\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2416 - accuracy: 0.8704 - val_loss: 1.3735 - val_accuracy: 0.7179\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2437 - accuracy: 0.8667 - val_loss: 1.3761 - val_accuracy: 0.7265\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.4178 - val_accuracy: 0.7179\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.4242 - val_accuracy: 0.7179\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2450 - accuracy: 0.8815 - val_loss: 1.4196 - val_accuracy: 0.7179\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.3738 - val_accuracy: 0.7179\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.3749 - val_accuracy: 0.7179\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.4352 - val_accuracy: 0.7179\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.4576 - val_accuracy: 0.7094\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2501 - accuracy: 0.8778 - val_loss: 1.4520 - val_accuracy: 0.7179\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.4117 - val_accuracy: 0.7265\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 1.4248 - val_accuracy: 0.7179\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4247 - val_accuracy: 0.7179\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2431 - accuracy: 0.8667 - val_loss: 1.3910 - val_accuracy: 0.7179\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.4084 - val_accuracy: 0.7094\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.4298 - val_accuracy: 0.7094\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.4307 - val_accuracy: 0.7094\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.3919 - val_accuracy: 0.7094\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2439 - accuracy: 0.8741 - val_loss: 1.3836 - val_accuracy: 0.7179\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.3978 - val_accuracy: 0.7179\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.4166 - val_accuracy: 0.7179\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.4274 - val_accuracy: 0.7265\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2497 - accuracy: 0.8778 - val_loss: 1.3997 - val_accuracy: 0.7179\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.4028 - val_accuracy: 0.7179\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.4359 - val_accuracy: 0.7094\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2481 - accuracy: 0.8704 - val_loss: 1.4610 - val_accuracy: 0.7009\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2504 - accuracy: 0.8815 - val_loss: 1.4495 - val_accuracy: 0.7009\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2438 - accuracy: 0.8630 - val_loss: 1.3859 - val_accuracy: 0.7265\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2481 - accuracy: 0.8741 - val_loss: 1.3667 - val_accuracy: 0.7265\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 309us/step - loss: 0.2439 - accuracy: 0.8704 - val_loss: 1.4117 - val_accuracy: 0.7094\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2450 - accuracy: 0.8704 - val_loss: 1.4689 - val_accuracy: 0.7094\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2449 - accuracy: 0.8741 - val_loss: 1.4499 - val_accuracy: 0.7094\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2479 - accuracy: 0.8556 - val_loss: 1.4273 - val_accuracy: 0.7265\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 1.4357 - val_accuracy: 0.7179\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2418 - accuracy: 0.8852 - val_loss: 1.4555 - val_accuracy: 0.7009\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.4455 - val_accuracy: 0.7179\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.4337 - val_accuracy: 0.7265\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2401 - accuracy: 0.8852 - val_loss: 1.4247 - val_accuracy: 0.7179\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2465 - accuracy: 0.8778 - val_loss: 1.4303 - val_accuracy: 0.7179\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.4631 - val_accuracy: 0.7094\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.4863 - val_accuracy: 0.7094\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2495 - accuracy: 0.8704 - val_loss: 1.4831 - val_accuracy: 0.7179\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.4464 - val_accuracy: 0.7179\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.4118 - val_accuracy: 0.7265\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.3943 - val_accuracy: 0.7179\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2440 - accuracy: 0.8630 - val_loss: 1.4255 - val_accuracy: 0.7179\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 1.4622 - val_accuracy: 0.7094\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.4994 - val_accuracy: 0.7094\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2459 - accuracy: 0.8741 - val_loss: 1.5186 - val_accuracy: 0.7094\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.4781 - val_accuracy: 0.7094\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2432 - accuracy: 0.8741 - val_loss: 1.4493 - val_accuracy: 0.7179\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.4353 - val_accuracy: 0.7179\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.4294 - val_accuracy: 0.7179\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.4029 - val_accuracy: 0.7265\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.3756 - val_accuracy: 0.7179\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2615 - accuracy: 0.8519 - val_loss: 1.4652 - val_accuracy: 0.7009\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2555 - accuracy: 0.8481 - val_loss: 1.4893 - val_accuracy: 0.7094\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.4731 - val_accuracy: 0.7179\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.4857 - val_accuracy: 0.7179\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.4912 - val_accuracy: 0.7179\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.4822 - val_accuracy: 0.7179\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 286us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.4559 - val_accuracy: 0.7179\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.4156 - val_accuracy: 0.7179\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.3866 - val_accuracy: 0.7265\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2472 - accuracy: 0.8667 - val_loss: 1.3626 - val_accuracy: 0.7179\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2445 - accuracy: 0.8741 - val_loss: 1.3549 - val_accuracy: 0.7350\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2477 - accuracy: 0.8704 - val_loss: 1.3807 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2445 - accuracy: 0.8852 - val_loss: 1.4156 - val_accuracy: 0.7179\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.4405 - val_accuracy: 0.7094\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.4365 - val_accuracy: 0.7179\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.4237 - val_accuracy: 0.7179\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.3908 - val_accuracy: 0.7265\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2468 - accuracy: 0.8778 - val_loss: 1.4081 - val_accuracy: 0.7265\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2498 - accuracy: 0.8667 - val_loss: 1.4714 - val_accuracy: 0.7094\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.4550 - val_accuracy: 0.7179\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.4097 - val_accuracy: 0.7265\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2466 - accuracy: 0.8778 - val_loss: 1.3861 - val_accuracy: 0.7265\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.3798 - val_accuracy: 0.7350\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2472 - accuracy: 0.8741 - val_loss: 1.3884 - val_accuracy: 0.7350\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2417 - accuracy: 0.8704 - val_loss: 1.4381 - val_accuracy: 0.7179\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2488 - accuracy: 0.8815 - val_loss: 1.4549 - val_accuracy: 0.7179\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2535 - accuracy: 0.8704 - val_loss: 1.4388 - val_accuracy: 0.7179\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 552us/step - loss: 0.2472 - accuracy: 0.8815 - val_loss: 1.4634 - val_accuracy: 0.7179\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.4700 - val_accuracy: 0.7094\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.4739 - val_accuracy: 0.7094\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 203us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.4773 - val_accuracy: 0.7094\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 198us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.4633 - val_accuracy: 0.7179\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.4734 - val_accuracy: 0.7265\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2491 - accuracy: 0.8741 - val_loss: 1.4608 - val_accuracy: 0.7179\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.4803 - val_accuracy: 0.7094\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.4611 - val_accuracy: 0.7094\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.4576 - val_accuracy: 0.7179\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.4375 - val_accuracy: 0.7265\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.3805 - val_accuracy: 0.7179\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2536 - accuracy: 0.8741 - val_loss: 1.3649 - val_accuracy: 0.7265\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2556 - accuracy: 0.8741 - val_loss: 1.3995 - val_accuracy: 0.7265\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2437 - accuracy: 0.8741 - val_loss: 1.4245 - val_accuracy: 0.7179\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2427 - accuracy: 0.8778 - val_loss: 1.4530 - val_accuracy: 0.7179\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2496 - accuracy: 0.8778 - val_loss: 1.4563 - val_accuracy: 0.7265\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 1.4893 - val_accuracy: 0.7179\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.5032 - val_accuracy: 0.7179\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.4792 - val_accuracy: 0.7179\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.4636 - val_accuracy: 0.7179\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 326us/step - loss: 0.2435 - accuracy: 0.8852 - val_loss: 1.4431 - val_accuracy: 0.7094\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.4238 - val_accuracy: 0.7094\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2412 - accuracy: 0.8704 - val_loss: 1.4257 - val_accuracy: 0.7179\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 1.4471 - val_accuracy: 0.7094\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.4507 - val_accuracy: 0.7179\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.4895 - val_accuracy: 0.7094\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.5259 - val_accuracy: 0.7009\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2472 - accuracy: 0.8778 - val_loss: 1.5293 - val_accuracy: 0.7094\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.5160 - val_accuracy: 0.7094\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.4895 - val_accuracy: 0.7179\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.4350 - val_accuracy: 0.7265\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.3980 - val_accuracy: 0.7179\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.4255 - val_accuracy: 0.7265\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.4768 - val_accuracy: 0.7094\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.4815 - val_accuracy: 0.7094\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.4743 - val_accuracy: 0.7009\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2408 - accuracy: 0.8741 - val_loss: 1.4456 - val_accuracy: 0.7179\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2428 - accuracy: 0.8667 - val_loss: 1.4390 - val_accuracy: 0.7265\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2472 - accuracy: 0.8704 - val_loss: 1.4700 - val_accuracy: 0.7094\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2475 - accuracy: 0.8815 - val_loss: 1.5163 - val_accuracy: 0.7094\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2466 - accuracy: 0.8741 - val_loss: 1.4698 - val_accuracy: 0.7094\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.4568 - val_accuracy: 0.7179\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.4398 - val_accuracy: 0.7265\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2435 - accuracy: 0.8741 - val_loss: 1.4382 - val_accuracy: 0.7265\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2479 - accuracy: 0.8741 - val_loss: 1.4442 - val_accuracy: 0.7265\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.4761 - val_accuracy: 0.7179\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 214us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.4840 - val_accuracy: 0.7179\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.4875 - val_accuracy: 0.7094\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.4685 - val_accuracy: 0.7179\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2469 - accuracy: 0.8667 - val_loss: 1.4722 - val_accuracy: 0.7179\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.4962 - val_accuracy: 0.7094\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.5330 - val_accuracy: 0.7009\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2525 - accuracy: 0.8667 - val_loss: 1.5272 - val_accuracy: 0.7094\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2486 - accuracy: 0.8741 - val_loss: 1.4917 - val_accuracy: 0.7179\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2481 - accuracy: 0.8778 - val_loss: 1.4793 - val_accuracy: 0.7179\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.4273 - val_accuracy: 0.7179\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2460 - accuracy: 0.8778 - val_loss: 1.4279 - val_accuracy: 0.7179\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.4143 - val_accuracy: 0.7265\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.4552 - val_accuracy: 0.7094\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.4476 - val_accuracy: 0.7179\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.4351 - val_accuracy: 0.7265\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2488 - accuracy: 0.8741 - val_loss: 1.4737 - val_accuracy: 0.7179\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.5020 - val_accuracy: 0.7179\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.4677 - val_accuracy: 0.7094\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 1.4397 - val_accuracy: 0.7179\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.4415 - val_accuracy: 0.7265\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.4689 - val_accuracy: 0.7094\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.5000 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.4996 - val_accuracy: 0.7179\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.4845 - val_accuracy: 0.7094\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 1.4359 - val_accuracy: 0.7179\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2411 - accuracy: 0.8704 - val_loss: 1.4024 - val_accuracy: 0.7265\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2413 - accuracy: 0.8741 - val_loss: 1.4453 - val_accuracy: 0.7179\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2387 - accuracy: 0.8815 - val_loss: 1.5009 - val_accuracy: 0.7179\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2466 - accuracy: 0.8815 - val_loss: 1.5025 - val_accuracy: 0.7179\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.4796 - val_accuracy: 0.7179\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.4406 - val_accuracy: 0.7265\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.4285 - val_accuracy: 0.7350\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2428 - accuracy: 0.8852 - val_loss: 1.4508 - val_accuracy: 0.7265\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.4620 - val_accuracy: 0.7179\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2533 - accuracy: 0.8741 - val_loss: 1.4712 - val_accuracy: 0.7179\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 1.4752 - val_accuracy: 0.7094\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2481 - accuracy: 0.8630 - val_loss: 1.4584 - val_accuracy: 0.7179\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2501 - accuracy: 0.8778 - val_loss: 1.4434 - val_accuracy: 0.7179\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2467 - accuracy: 0.8778 - val_loss: 1.4894 - val_accuracy: 0.7094\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.5295 - val_accuracy: 0.7094\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.5639 - val_accuracy: 0.7179\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.5382 - val_accuracy: 0.7179\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.5031 - val_accuracy: 0.7179\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.2462 - accuracy: 0.8704 - val_loss: 1.4317 - val_accuracy: 0.7265\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.4296 - val_accuracy: 0.7265\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.4636 - val_accuracy: 0.7265\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.4876 - val_accuracy: 0.7094\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.5133 - val_accuracy: 0.7009\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 109us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.4945 - val_accuracy: 0.7094\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4837 - val_accuracy: 0.7094\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.4971 - val_accuracy: 0.7094\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.5229 - val_accuracy: 0.7094\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.5297 - val_accuracy: 0.7094\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 1.5368 - val_accuracy: 0.7179\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2452 - accuracy: 0.8852 - val_loss: 1.5018 - val_accuracy: 0.7179\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2399 - accuracy: 0.8815 - val_loss: 1.4969 - val_accuracy: 0.7179\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.4884 - val_accuracy: 0.7179\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.4774 - val_accuracy: 0.7179\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.4753 - val_accuracy: 0.7179\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2387 - accuracy: 0.8815 - val_loss: 1.4739 - val_accuracy: 0.7179\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.4888 - val_accuracy: 0.7179\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.4963 - val_accuracy: 0.7094\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.4880 - val_accuracy: 0.7179\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.4904 - val_accuracy: 0.7094\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2414 - accuracy: 0.8852 - val_loss: 1.5071 - val_accuracy: 0.7094\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.5106 - val_accuracy: 0.7094\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.4740 - val_accuracy: 0.7179\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.4828 - val_accuracy: 0.7179\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.5187 - val_accuracy: 0.7179\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2389 - accuracy: 0.8815 - val_loss: 1.5375 - val_accuracy: 0.7179\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2467 - accuracy: 0.8815 - val_loss: 1.5313 - val_accuracy: 0.7179\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.5014 - val_accuracy: 0.7179\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2398 - accuracy: 0.8815 - val_loss: 1.4651 - val_accuracy: 0.7265\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.4540 - val_accuracy: 0.7265\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.4639 - val_accuracy: 0.7179\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.4990 - val_accuracy: 0.7094\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.4683 - val_accuracy: 0.7094\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.4667 - val_accuracy: 0.7179\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.5212 - val_accuracy: 0.7179\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2436 - accuracy: 0.8704 - val_loss: 1.5645 - val_accuracy: 0.7094\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2538 - accuracy: 0.8778 - val_loss: 1.6082 - val_accuracy: 0.7009\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2540 - accuracy: 0.8778 - val_loss: 1.5575 - val_accuracy: 0.7094\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.4681 - val_accuracy: 0.7179\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.4692 - val_accuracy: 0.7179\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.4956 - val_accuracy: 0.7179\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2455 - accuracy: 0.8815 - val_loss: 1.4947 - val_accuracy: 0.7094\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.4644 - val_accuracy: 0.7094\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.4138 - val_accuracy: 0.7265\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.4084 - val_accuracy: 0.7265\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2464 - accuracy: 0.8630 - val_loss: 1.4329 - val_accuracy: 0.7179\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.4355 - val_accuracy: 0.7265\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.4643 - val_accuracy: 0.7179\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 1.5028 - val_accuracy: 0.7265\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 1.5587 - val_accuracy: 0.7179\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.5420 - val_accuracy: 0.7179\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2392 - accuracy: 0.8815 - val_loss: 1.4975 - val_accuracy: 0.7265\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.4645 - val_accuracy: 0.7265\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.4894 - val_accuracy: 0.7265\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2423 - accuracy: 0.8667 - val_loss: 1.5288 - val_accuracy: 0.7179\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.5296 - val_accuracy: 0.7094\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2434 - accuracy: 0.8815 - val_loss: 1.4852 - val_accuracy: 0.7179\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.4233 - val_accuracy: 0.7265\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2496 - accuracy: 0.8741 - val_loss: 1.4448 - val_accuracy: 0.7179\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.5388 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.5779 - val_accuracy: 0.7009\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2454 - accuracy: 0.8815 - val_loss: 1.5894 - val_accuracy: 0.7009\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2437 - accuracy: 0.8815 - val_loss: 1.5700 - val_accuracy: 0.7009\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.5127 - val_accuracy: 0.7179\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2455 - accuracy: 0.8741 - val_loss: 1.4512 - val_accuracy: 0.7265\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2500 - accuracy: 0.8704 - val_loss: 1.4396 - val_accuracy: 0.7265\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.4936 - val_accuracy: 0.7094\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.5563 - val_accuracy: 0.7094\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.5416 - val_accuracy: 0.7009\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2461 - accuracy: 0.8741 - val_loss: 1.5334 - val_accuracy: 0.7094\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.5321 - val_accuracy: 0.7094\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 296us/step - loss: 0.2480 - accuracy: 0.8741 - val_loss: 1.5218 - val_accuracy: 0.7179\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.4921 - val_accuracy: 0.7265\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2487 - accuracy: 0.8630 - val_loss: 1.4989 - val_accuracy: 0.7179\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2563 - accuracy: 0.8741 - val_loss: 1.5023 - val_accuracy: 0.7179\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2467 - accuracy: 0.8593 - val_loss: 1.5409 - val_accuracy: 0.7009\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.5774 - val_accuracy: 0.7009\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 1.5473 - val_accuracy: 0.7009\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.5100 - val_accuracy: 0.7179\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.5010 - val_accuracy: 0.7265\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.5033 - val_accuracy: 0.7265\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.5283 - val_accuracy: 0.7094\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.5447 - val_accuracy: 0.7094\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.5336 - val_accuracy: 0.7094\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2394 - accuracy: 0.8815 - val_loss: 1.5283 - val_accuracy: 0.7009\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.5253 - val_accuracy: 0.7009\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.5027 - val_accuracy: 0.7094\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.4541 - val_accuracy: 0.7179\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.4350 - val_accuracy: 0.7179\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2409 - accuracy: 0.8704 - val_loss: 1.4550 - val_accuracy: 0.7265\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2475 - accuracy: 0.8741 - val_loss: 1.4781 - val_accuracy: 0.7265\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2436 - accuracy: 0.8704 - val_loss: 1.4952 - val_accuracy: 0.7265\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2462 - accuracy: 0.8852 - val_loss: 1.5364 - val_accuracy: 0.7094\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.4573 - val_accuracy: 0.7179\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2379 - accuracy: 0.8815 - val_loss: 1.4170 - val_accuracy: 0.7265\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2488 - accuracy: 0.8778 - val_loss: 1.4208 - val_accuracy: 0.7265\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.4573 - val_accuracy: 0.7094\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2446 - accuracy: 0.8815 - val_loss: 1.4848 - val_accuracy: 0.7094\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.4628 - val_accuracy: 0.7094\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2392 - accuracy: 0.8852 - val_loss: 1.4536 - val_accuracy: 0.7179\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2475 - accuracy: 0.8778 - val_loss: 1.4294 - val_accuracy: 0.7179\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.4181 - val_accuracy: 0.7265\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2399 - accuracy: 0.8704 - val_loss: 1.4137 - val_accuracy: 0.7265\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 1.4375 - val_accuracy: 0.7179\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 323us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 1.4441 - val_accuracy: 0.7265\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2459 - accuracy: 0.8778 - val_loss: 1.4446 - val_accuracy: 0.7265\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.4420 - val_accuracy: 0.7179\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2390 - accuracy: 0.8815 - val_loss: 1.4628 - val_accuracy: 0.7094\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.4849 - val_accuracy: 0.7179\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.4612 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2383 - accuracy: 0.8667 - val_loss: 1.4313 - val_accuracy: 0.7350\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2530 - accuracy: 0.8741 - val_loss: 1.4399 - val_accuracy: 0.7265\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.5601 - val_accuracy: 0.7179\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 1.6153 - val_accuracy: 0.7094\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2502 - accuracy: 0.8815 - val_loss: 1.5344 - val_accuracy: 0.7094\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.4245 - val_accuracy: 0.7094\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2429 - accuracy: 0.8630 - val_loss: 1.3648 - val_accuracy: 0.7179\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.3875 - val_accuracy: 0.7179\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.4134 - val_accuracy: 0.7094\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2439 - accuracy: 0.8815 - val_loss: 1.4016 - val_accuracy: 0.7094\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.4035 - val_accuracy: 0.7179\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2423 - accuracy: 0.8778 - val_loss: 1.3938 - val_accuracy: 0.7179\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.4107 - val_accuracy: 0.7179\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2410 - accuracy: 0.8889 - val_loss: 1.4293 - val_accuracy: 0.7179\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.4216 - val_accuracy: 0.7179\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 1.4029 - val_accuracy: 0.7265\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2404 - accuracy: 0.8741 - val_loss: 1.4311 - val_accuracy: 0.7179\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.4854 - val_accuracy: 0.7094\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.5040 - val_accuracy: 0.7179\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.4977 - val_accuracy: 0.7179\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.5003 - val_accuracy: 0.7179\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2454 - accuracy: 0.8630 - val_loss: 1.5045 - val_accuracy: 0.7179\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2415 - accuracy: 0.8630 - val_loss: 1.4768 - val_accuracy: 0.7265\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.4774 - val_accuracy: 0.7179\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.4861 - val_accuracy: 0.7094\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.4760 - val_accuracy: 0.7094\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2406 - accuracy: 0.8630 - val_loss: 1.4419 - val_accuracy: 0.7265\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2424 - accuracy: 0.8741 - val_loss: 1.4636 - val_accuracy: 0.7179\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2435 - accuracy: 0.8630 - val_loss: 1.4959 - val_accuracy: 0.7179\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.5351 - val_accuracy: 0.7094\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.5618 - val_accuracy: 0.7094\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 1.5683 - val_accuracy: 0.7009\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.5298 - val_accuracy: 0.7179\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.4599 - val_accuracy: 0.7179\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.4634 - val_accuracy: 0.7179\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.4878 - val_accuracy: 0.7179\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.5302 - val_accuracy: 0.7179\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.5391 - val_accuracy: 0.7179\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.5426 - val_accuracy: 0.7094\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.5119 - val_accuracy: 0.7179\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.4912 - val_accuracy: 0.7265\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2398 - accuracy: 0.8778 - val_loss: 1.4646 - val_accuracy: 0.7179\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.4595 - val_accuracy: 0.7179\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2419 - accuracy: 0.8778 - val_loss: 1.5007 - val_accuracy: 0.7265\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.5393 - val_accuracy: 0.7265\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.5542 - val_accuracy: 0.7179\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2427 - accuracy: 0.8741 - val_loss: 1.5446 - val_accuracy: 0.7265\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.5651 - val_accuracy: 0.7179\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.5461 - val_accuracy: 0.7179\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.5381 - val_accuracy: 0.7179\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 1.5255 - val_accuracy: 0.7265\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2456 - accuracy: 0.8741 - val_loss: 1.4930 - val_accuracy: 0.7350\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.4756 - val_accuracy: 0.7265\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.4996 - val_accuracy: 0.7265\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.5283 - val_accuracy: 0.7265\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.5443 - val_accuracy: 0.7179\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2415 - accuracy: 0.8741 - val_loss: 1.5414 - val_accuracy: 0.7179\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.5560 - val_accuracy: 0.7094\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2450 - accuracy: 0.8778 - val_loss: 1.5801 - val_accuracy: 0.7094\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.5452 - val_accuracy: 0.7179\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.5419 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.5288 - val_accuracy: 0.7094\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.5007 - val_accuracy: 0.7179\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.5408 - val_accuracy: 0.7179\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.5551 - val_accuracy: 0.7179\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.5467 - val_accuracy: 0.7094\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2394 - accuracy: 0.8778 - val_loss: 1.5425 - val_accuracy: 0.7179\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2469 - accuracy: 0.8778 - val_loss: 1.5457 - val_accuracy: 0.7179\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 209us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.5604 - val_accuracy: 0.7094\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.5822 - val_accuracy: 0.7179\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.6024 - val_accuracy: 0.7179\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.5778 - val_accuracy: 0.7094\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.5574 - val_accuracy: 0.7179\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.5803 - val_accuracy: 0.7179\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.5595 - val_accuracy: 0.7094\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.5191 - val_accuracy: 0.7179\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2486 - accuracy: 0.8741 - val_loss: 1.5112 - val_accuracy: 0.7179\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.2522 - accuracy: 0.8778 - val_loss: 1.5452 - val_accuracy: 0.7179\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.2437 - accuracy: 0.8889 - val_loss: 1.6295 - val_accuracy: 0.7094\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 1.6566 - val_accuracy: 0.7094\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.5814 - val_accuracy: 0.7094\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.5285 - val_accuracy: 0.7179\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2456 - accuracy: 0.8778 - val_loss: 1.5160 - val_accuracy: 0.7179\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.5646 - val_accuracy: 0.7094\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.5931 - val_accuracy: 0.7094\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.5863 - val_accuracy: 0.7009\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.5572 - val_accuracy: 0.7094\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.5331 - val_accuracy: 0.7179\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2442 - accuracy: 0.8778 - val_loss: 1.5392 - val_accuracy: 0.7094\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.5740 - val_accuracy: 0.7094\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2412 - accuracy: 0.8815 - val_loss: 1.6101 - val_accuracy: 0.7094\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2429 - accuracy: 0.8815 - val_loss: 1.6302 - val_accuracy: 0.7009\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.6261 - val_accuracy: 0.7009\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2489 - accuracy: 0.8815 - val_loss: 1.5572 - val_accuracy: 0.7179\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.5049 - val_accuracy: 0.7179\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.5171 - val_accuracy: 0.7179\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2433 - accuracy: 0.8889 - val_loss: 1.5736 - val_accuracy: 0.7094\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.6048 - val_accuracy: 0.7094\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.5920 - val_accuracy: 0.7094\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2427 - accuracy: 0.8815 - val_loss: 1.5700 - val_accuracy: 0.7179\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.5885 - val_accuracy: 0.7179\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2426 - accuracy: 0.8815 - val_loss: 1.5870 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.5969 - val_accuracy: 0.7179\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.5755 - val_accuracy: 0.7094\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2413 - accuracy: 0.8926 - val_loss: 1.5693 - val_accuracy: 0.7179\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.5810 - val_accuracy: 0.7179\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.6019 - val_accuracy: 0.7094\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2392 - accuracy: 0.8815 - val_loss: 1.6190 - val_accuracy: 0.7094\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2431 - accuracy: 0.8852 - val_loss: 1.6188 - val_accuracy: 0.7094\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2437 - accuracy: 0.8852 - val_loss: 1.5700 - val_accuracy: 0.7265\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2523 - accuracy: 0.8704 - val_loss: 1.5755 - val_accuracy: 0.7350\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.5494 - val_accuracy: 0.7265\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.5340 - val_accuracy: 0.7265\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2483 - accuracy: 0.8667 - val_loss: 1.5442 - val_accuracy: 0.7350\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.6004 - val_accuracy: 0.7094\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.6213 - val_accuracy: 0.7094\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.6156 - val_accuracy: 0.7265\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.6087 - val_accuracy: 0.7265\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.5905 - val_accuracy: 0.7179\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2422 - accuracy: 0.8741 - val_loss: 1.5802 - val_accuracy: 0.7265\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.5835 - val_accuracy: 0.7179\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.5765 - val_accuracy: 0.7265\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.5843 - val_accuracy: 0.7265\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2416 - accuracy: 0.8741 - val_loss: 1.6235 - val_accuracy: 0.7179\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.6513 - val_accuracy: 0.7094\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.6574 - val_accuracy: 0.7094\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.6203 - val_accuracy: 0.7094\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2448 - accuracy: 0.8778 - val_loss: 1.5773 - val_accuracy: 0.7265\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 1.5441 - val_accuracy: 0.7179\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.5497 - val_accuracy: 0.7094\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2428 - accuracy: 0.8593 - val_loss: 1.5831 - val_accuracy: 0.7094\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2430 - accuracy: 0.8815 - val_loss: 1.6143 - val_accuracy: 0.7094\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.6405 - val_accuracy: 0.7094\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2403 - accuracy: 0.8704 - val_loss: 1.6275 - val_accuracy: 0.7179\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.6491 - val_accuracy: 0.7179\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2465 - accuracy: 0.8815 - val_loss: 1.6105 - val_accuracy: 0.7179\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.5894 - val_accuracy: 0.7179\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2400 - accuracy: 0.8741 - val_loss: 1.5757 - val_accuracy: 0.7179\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2405 - accuracy: 0.8815 - val_loss: 1.5996 - val_accuracy: 0.7179\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2395 - accuracy: 0.8815 - val_loss: 1.5921 - val_accuracy: 0.7094\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2474 - accuracy: 0.8778 - val_loss: 1.5831 - val_accuracy: 0.7179\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2533 - accuracy: 0.8778 - val_loss: 1.5179 - val_accuracy: 0.7179\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2479 - accuracy: 0.8778 - val_loss: 1.4945 - val_accuracy: 0.7179\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2458 - accuracy: 0.8815 - val_loss: 1.5312 - val_accuracy: 0.7179\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 1.5033 - val_accuracy: 0.7179\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.4943 - val_accuracy: 0.7179\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.5341 - val_accuracy: 0.7179\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.5662 - val_accuracy: 0.7094\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2443 - accuracy: 0.8815 - val_loss: 1.5571 - val_accuracy: 0.7094\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2395 - accuracy: 0.8741 - val_loss: 1.5438 - val_accuracy: 0.7179\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 1.5910 - val_accuracy: 0.6838\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2485 - accuracy: 0.8741 - val_loss: 1.5886 - val_accuracy: 0.7179\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2421 - accuracy: 0.8704 - val_loss: 1.6162 - val_accuracy: 0.7179\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2538 - accuracy: 0.8519 - val_loss: 1.6036 - val_accuracy: 0.7179\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 1.5966 - val_accuracy: 0.7179\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.6134 - val_accuracy: 0.7179\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2458 - accuracy: 0.8778 - val_loss: 1.5890 - val_accuracy: 0.7094\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2395 - accuracy: 0.8815 - val_loss: 1.5786 - val_accuracy: 0.7094\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.5615 - val_accuracy: 0.7179\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.5370 - val_accuracy: 0.7179\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.5247 - val_accuracy: 0.7265\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2457 - accuracy: 0.8556 - val_loss: 1.5366 - val_accuracy: 0.7265\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2465 - accuracy: 0.8741 - val_loss: 1.5728 - val_accuracy: 0.7265\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2470 - accuracy: 0.8704 - val_loss: 1.5909 - val_accuracy: 0.7265\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.6139 - val_accuracy: 0.7094\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.6258 - val_accuracy: 0.7094\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2446 - accuracy: 0.8704 - val_loss: 1.5806 - val_accuracy: 0.7265\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.5397 - val_accuracy: 0.7265\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.5220 - val_accuracy: 0.7265\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.5466 - val_accuracy: 0.7094\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2407 - accuracy: 0.8815 - val_loss: 1.5331 - val_accuracy: 0.7179\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.5583 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2416 - accuracy: 0.8778 - val_loss: 1.5806 - val_accuracy: 0.7094\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2409 - accuracy: 0.8667 - val_loss: 1.5629 - val_accuracy: 0.7265\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.5733 - val_accuracy: 0.7265\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.5661 - val_accuracy: 0.7265\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2393 - accuracy: 0.8778 - val_loss: 1.5827 - val_accuracy: 0.7094\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2463 - accuracy: 0.8741 - val_loss: 1.5904 - val_accuracy: 0.7179\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2410 - accuracy: 0.8704 - val_loss: 1.5757 - val_accuracy: 0.7265\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.5234 - val_accuracy: 0.7265\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2451 - accuracy: 0.8778 - val_loss: 1.5140 - val_accuracy: 0.7265\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.5344 - val_accuracy: 0.7350\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2429 - accuracy: 0.8704 - val_loss: 1.5510 - val_accuracy: 0.7094\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2408 - accuracy: 0.8704 - val_loss: 1.5443 - val_accuracy: 0.7265\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2406 - accuracy: 0.8741 - val_loss: 1.5666 - val_accuracy: 0.7179\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2404 - accuracy: 0.8778 - val_loss: 1.5884 - val_accuracy: 0.7094\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2418 - accuracy: 0.8741 - val_loss: 1.6153 - val_accuracy: 0.7094\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.5948 - val_accuracy: 0.7179\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.5721 - val_accuracy: 0.7265\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2457 - accuracy: 0.8778 - val_loss: 1.5479 - val_accuracy: 0.7350\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2528 - accuracy: 0.8741 - val_loss: 1.5466 - val_accuracy: 0.7350\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.5968 - val_accuracy: 0.7179\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2440 - accuracy: 0.8815 - val_loss: 1.6245 - val_accuracy: 0.7094\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2480 - accuracy: 0.8630 - val_loss: 1.5800 - val_accuracy: 0.7179\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.5972 - val_accuracy: 0.7265\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.6298 - val_accuracy: 0.7094\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.6154 - val_accuracy: 0.7094\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2449 - accuracy: 0.8593 - val_loss: 1.5643 - val_accuracy: 0.7350\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.5803 - val_accuracy: 0.7265\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2399 - accuracy: 0.8852 - val_loss: 1.6342 - val_accuracy: 0.7094\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 1.6496 - val_accuracy: 0.7094\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2452 - accuracy: 0.8778 - val_loss: 1.6198 - val_accuracy: 0.7094\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 1.6086 - val_accuracy: 0.7094\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2499 - accuracy: 0.8778 - val_loss: 1.5609 - val_accuracy: 0.7179\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2504 - accuracy: 0.8741 - val_loss: 1.5763 - val_accuracy: 0.7179\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2463 - accuracy: 0.8593 - val_loss: 1.5931 - val_accuracy: 0.7094\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2414 - accuracy: 0.8778 - val_loss: 1.5588 - val_accuracy: 0.7265\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2440 - accuracy: 0.8778 - val_loss: 1.5573 - val_accuracy: 0.7265\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.5593 - val_accuracy: 0.7265\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.5810 - val_accuracy: 0.7265\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2442 - accuracy: 0.8815 - val_loss: 1.5826 - val_accuracy: 0.7179\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 234us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.5757 - val_accuracy: 0.7179\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2463 - accuracy: 0.8778 - val_loss: 1.5825 - val_accuracy: 0.7179\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.5920 - val_accuracy: 0.7265\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.6341 - val_accuracy: 0.7179\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.6171 - val_accuracy: 0.7179\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2426 - accuracy: 0.8852 - val_loss: 1.5936 - val_accuracy: 0.7265\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2438 - accuracy: 0.8778 - val_loss: 1.5694 - val_accuracy: 0.7265\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.5573 - val_accuracy: 0.7265\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2412 - accuracy: 0.8741 - val_loss: 1.5465 - val_accuracy: 0.7350\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2436 - accuracy: 0.8741 - val_loss: 1.5705 - val_accuracy: 0.7179\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2410 - accuracy: 0.8778 - val_loss: 1.6086 - val_accuracy: 0.7179\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2410 - accuracy: 0.8815 - val_loss: 1.6042 - val_accuracy: 0.7179\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2409 - accuracy: 0.8815 - val_loss: 1.5793 - val_accuracy: 0.7179\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2430 - accuracy: 0.8667 - val_loss: 1.5399 - val_accuracy: 0.7265\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.5571 - val_accuracy: 0.7265\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.5936 - val_accuracy: 0.7179\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2417 - accuracy: 0.8778 - val_loss: 1.6446 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2455 - accuracy: 0.8778 - val_loss: 1.6465 - val_accuracy: 0.7179\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 274us/step - loss: 0.2466 - accuracy: 0.8667 - val_loss: 1.6155 - val_accuracy: 0.7265\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2449 - accuracy: 0.8778 - val_loss: 1.6246 - val_accuracy: 0.7265\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 287us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.6307 - val_accuracy: 0.7179\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.6209 - val_accuracy: 0.7179\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2396 - accuracy: 0.8815 - val_loss: 1.5852 - val_accuracy: 0.7179\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2411 - accuracy: 0.8815 - val_loss: 1.5767 - val_accuracy: 0.7179\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2412 - accuracy: 0.8630 - val_loss: 1.6050 - val_accuracy: 0.7265\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2411 - accuracy: 0.8741 - val_loss: 1.6421 - val_accuracy: 0.7179\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.6205 - val_accuracy: 0.7179\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2419 - accuracy: 0.8593 - val_loss: 1.5794 - val_accuracy: 0.7350\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2410 - accuracy: 0.8741 - val_loss: 1.5672 - val_accuracy: 0.7265\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2405 - accuracy: 0.8778 - val_loss: 1.5796 - val_accuracy: 0.7265\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.5931 - val_accuracy: 0.7265\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2412 - accuracy: 0.8889 - val_loss: 1.6255 - val_accuracy: 0.7179\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.6450 - val_accuracy: 0.7179\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.6279 - val_accuracy: 0.7179\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2395 - accuracy: 0.8815 - val_loss: 1.6179 - val_accuracy: 0.7179\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.6196 - val_accuracy: 0.7094\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.6112 - val_accuracy: 0.7094\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.5880 - val_accuracy: 0.7179\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2434 - accuracy: 0.8704 - val_loss: 1.6136 - val_accuracy: 0.7094\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.6508 - val_accuracy: 0.7179\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2454 - accuracy: 0.8778 - val_loss: 1.6771 - val_accuracy: 0.7094\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2455 - accuracy: 0.8852 - val_loss: 1.6650 - val_accuracy: 0.7179\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.6366 - val_accuracy: 0.7179\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2445 - accuracy: 0.8815 - val_loss: 1.6212 - val_accuracy: 0.7179\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2441 - accuracy: 0.8815 - val_loss: 1.6126 - val_accuracy: 0.7179\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.6268 - val_accuracy: 0.7179\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.6250 - val_accuracy: 0.7179\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2446 - accuracy: 0.8778 - val_loss: 1.5824 - val_accuracy: 0.7265\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2439 - accuracy: 0.8778 - val_loss: 1.5849 - val_accuracy: 0.7265\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2404 - accuracy: 0.8815 - val_loss: 1.6330 - val_accuracy: 0.7179\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 1.6826 - val_accuracy: 0.7094\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.6766 - val_accuracy: 0.7094\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2437 - accuracy: 0.8778 - val_loss: 1.6060 - val_accuracy: 0.7179\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2413 - accuracy: 0.8926 - val_loss: 1.5479 - val_accuracy: 0.7265\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2462 - accuracy: 0.8778 - val_loss: 1.5116 - val_accuracy: 0.7265\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.5592 - val_accuracy: 0.7179\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.5933 - val_accuracy: 0.7179\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2473 - accuracy: 0.8778 - val_loss: 1.6108 - val_accuracy: 0.7179\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.6014 - val_accuracy: 0.7094\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.5576 - val_accuracy: 0.7179\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2477 - accuracy: 0.8778 - val_loss: 1.5741 - val_accuracy: 0.7265\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2433 - accuracy: 0.8778 - val_loss: 1.5999 - val_accuracy: 0.7265\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2404 - accuracy: 0.8889 - val_loss: 1.6165 - val_accuracy: 0.7094\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.6008 - val_accuracy: 0.7094\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2422 - accuracy: 0.8815 - val_loss: 1.5788 - val_accuracy: 0.7094\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2451 - accuracy: 0.8815 - val_loss: 1.5566 - val_accuracy: 0.7094\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2433 - accuracy: 0.8815 - val_loss: 1.5023 - val_accuracy: 0.7179\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2416 - accuracy: 0.8889 - val_loss: 1.4793 - val_accuracy: 0.7265\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2495 - accuracy: 0.8667 - val_loss: 1.4975 - val_accuracy: 0.7179\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2537 - accuracy: 0.8556 - val_loss: 1.5210 - val_accuracy: 0.7179\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2450 - accuracy: 0.8852 - val_loss: 1.5198 - val_accuracy: 0.7094\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.5361 - val_accuracy: 0.7094\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2464 - accuracy: 0.8741 - val_loss: 1.5579 - val_accuracy: 0.7094\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2471 - accuracy: 0.8815 - val_loss: 1.5905 - val_accuracy: 0.7009\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.5624 - val_accuracy: 0.7094\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2517 - accuracy: 0.8778 - val_loss: 1.5185 - val_accuracy: 0.7179\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2534 - accuracy: 0.8778 - val_loss: 1.5253 - val_accuracy: 0.7179\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2504 - accuracy: 0.8852 - val_loss: 1.6076 - val_accuracy: 0.7179\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2464 - accuracy: 0.8778 - val_loss: 1.6005 - val_accuracy: 0.7094\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2377 - accuracy: 0.8815 - val_loss: 1.5840 - val_accuracy: 0.7009\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2502 - accuracy: 0.8593 - val_loss: 1.5777 - val_accuracy: 0.7094\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2431 - accuracy: 0.8815 - val_loss: 1.5815 - val_accuracy: 0.7094\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2380 - accuracy: 0.8815 - val_loss: 1.6040 - val_accuracy: 0.7179\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.2413 - accuracy: 0.8778 - val_loss: 1.5984 - val_accuracy: 0.7094\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2415 - accuracy: 0.8815 - val_loss: 1.5822 - val_accuracy: 0.7094\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.5901 - val_accuracy: 0.7094\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2430 - accuracy: 0.8778 - val_loss: 1.6285 - val_accuracy: 0.7094\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.6599 - val_accuracy: 0.7094\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2443 - accuracy: 0.8741 - val_loss: 1.6638 - val_accuracy: 0.7009\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2421 - accuracy: 0.8778 - val_loss: 1.6117 - val_accuracy: 0.7179\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2434 - accuracy: 0.8741 - val_loss: 1.5531 - val_accuracy: 0.7179\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2424 - accuracy: 0.8815 - val_loss: 1.4848 - val_accuracy: 0.7265\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2466 - accuracy: 0.8704 - val_loss: 1.5026 - val_accuracy: 0.7265\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2459 - accuracy: 0.8704 - val_loss: 1.5473 - val_accuracy: 0.7179\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.5722 - val_accuracy: 0.7265\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2431 - accuracy: 0.8778 - val_loss: 1.5782 - val_accuracy: 0.7265\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 378us/step - loss: 0.2437 - accuracy: 0.8704 - val_loss: 1.5785 - val_accuracy: 0.7265\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 253us/step - loss: 0.2421 - accuracy: 0.8741 - val_loss: 1.5847 - val_accuracy: 0.7179\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2443 - accuracy: 0.8667 - val_loss: 1.6062 - val_accuracy: 0.7179\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2426 - accuracy: 0.8741 - val_loss: 1.6061 - val_accuracy: 0.7094\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2432 - accuracy: 0.8778 - val_loss: 1.5937 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.5772 - val_accuracy: 0.7179\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2411 - accuracy: 0.8778 - val_loss: 1.5692 - val_accuracy: 0.7179\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.5919 - val_accuracy: 0.7094\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.6337 - val_accuracy: 0.7179\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 1.6222 - val_accuracy: 0.7179\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.5810 - val_accuracy: 0.7179\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.5958 - val_accuracy: 0.7179\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2423 - accuracy: 0.8741 - val_loss: 1.6022 - val_accuracy: 0.7265\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2461 - accuracy: 0.8704 - val_loss: 1.6111 - val_accuracy: 0.7179\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2408 - accuracy: 0.8704 - val_loss: 1.6234 - val_accuracy: 0.7094\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.6144 - val_accuracy: 0.7094\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.6080 - val_accuracy: 0.7094\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2462 - accuracy: 0.8667 - val_loss: 1.5855 - val_accuracy: 0.7179\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2431 - accuracy: 0.8741 - val_loss: 1.5904 - val_accuracy: 0.7094\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2447 - accuracy: 0.8741 - val_loss: 1.5776 - val_accuracy: 0.7094\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2498 - accuracy: 0.8556 - val_loss: 1.5602 - val_accuracy: 0.7179\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.5601 - val_accuracy: 0.7265\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2438 - accuracy: 0.8741 - val_loss: 1.6055 - val_accuracy: 0.7265\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.6668 - val_accuracy: 0.7179\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2418 - accuracy: 0.8815 - val_loss: 1.7067 - val_accuracy: 0.7094\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 1.6871 - val_accuracy: 0.7179\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2474 - accuracy: 0.8815 - val_loss: 1.6346 - val_accuracy: 0.7179\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2403 - accuracy: 0.8815 - val_loss: 1.6167 - val_accuracy: 0.7179\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2502 - accuracy: 0.8741 - val_loss: 1.6088 - val_accuracy: 0.7265\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2461 - accuracy: 0.8815 - val_loss: 1.5777 - val_accuracy: 0.7179\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.5800 - val_accuracy: 0.7179\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 75us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.5866 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2403 - accuracy: 0.8741 - val_loss: 1.5967 - val_accuracy: 0.7265\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2402 - accuracy: 0.8741 - val_loss: 1.6212 - val_accuracy: 0.7265\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.6592 - val_accuracy: 0.7009\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2422 - accuracy: 0.8778 - val_loss: 1.6548 - val_accuracy: 0.7094\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2436 - accuracy: 0.8778 - val_loss: 1.6465 - val_accuracy: 0.7094\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.6504 - val_accuracy: 0.7179\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.6496 - val_accuracy: 0.7094\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2412 - accuracy: 0.8704 - val_loss: 1.6484 - val_accuracy: 0.7094\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2460 - accuracy: 0.8815 - val_loss: 1.6883 - val_accuracy: 0.7009\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2462 - accuracy: 0.8815 - val_loss: 1.6442 - val_accuracy: 0.7094\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.6072 - val_accuracy: 0.7265\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2407 - accuracy: 0.8778 - val_loss: 1.6182 - val_accuracy: 0.7265\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2397 - accuracy: 0.8778 - val_loss: 1.6402 - val_accuracy: 0.7179\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.6512 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2415 - accuracy: 0.8667 - val_loss: 1.6256 - val_accuracy: 0.7179\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2393 - accuracy: 0.8815 - val_loss: 1.6031 - val_accuracy: 0.7265\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 1.6038 - val_accuracy: 0.7350\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2435 - accuracy: 0.8704 - val_loss: 1.6357 - val_accuracy: 0.7265\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2414 - accuracy: 0.8741 - val_loss: 1.6470 - val_accuracy: 0.7009\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.6321 - val_accuracy: 0.7179\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2444 - accuracy: 0.8741 - val_loss: 1.6376 - val_accuracy: 0.7009\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2452 - accuracy: 0.8815 - val_loss: 1.6253 - val_accuracy: 0.7179\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2480 - accuracy: 0.8778 - val_loss: 1.6428 - val_accuracy: 0.7179\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2450 - accuracy: 0.8741 - val_loss: 1.6760 - val_accuracy: 0.7094\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2415 - accuracy: 0.8778 - val_loss: 1.7086 - val_accuracy: 0.7009\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2444 - accuracy: 0.8815 - val_loss: 1.6965 - val_accuracy: 0.7009\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2424 - accuracy: 0.8852 - val_loss: 1.6539 - val_accuracy: 0.7179\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2402 - accuracy: 0.8704 - val_loss: 1.6599 - val_accuracy: 0.7094\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2401 - accuracy: 0.8815 - val_loss: 1.7041 - val_accuracy: 0.7009\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.7085 - val_accuracy: 0.7009\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2428 - accuracy: 0.8815 - val_loss: 1.6928 - val_accuracy: 0.7009\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.6747 - val_accuracy: 0.7094\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2423 - accuracy: 0.8815 - val_loss: 1.6598 - val_accuracy: 0.7094\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.6662 - val_accuracy: 0.7094\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2405 - accuracy: 0.8815 - val_loss: 1.6583 - val_accuracy: 0.7179\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2403 - accuracy: 0.8778 - val_loss: 1.6741 - val_accuracy: 0.7179\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2444 - accuracy: 0.8778 - val_loss: 1.6676 - val_accuracy: 0.7179\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2428 - accuracy: 0.8778 - val_loss: 1.6479 - val_accuracy: 0.7179\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2413 - accuracy: 0.8815 - val_loss: 1.6716 - val_accuracy: 0.7009\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2495 - accuracy: 0.8593 - val_loss: 1.6746 - val_accuracy: 0.7009\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2474 - accuracy: 0.8741 - val_loss: 1.6259 - val_accuracy: 0.7179\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2470 - accuracy: 0.8741 - val_loss: 1.6025 - val_accuracy: 0.7265\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2488 - accuracy: 0.8741 - val_loss: 1.6242 - val_accuracy: 0.7179\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2445 - accuracy: 0.8778 - val_loss: 1.6632 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2417 - accuracy: 0.8815 - val_loss: 1.7023 - val_accuracy: 0.7094\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2408 - accuracy: 0.8815 - val_loss: 1.7175 - val_accuracy: 0.7009\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2420 - accuracy: 0.8815 - val_loss: 1.6911 - val_accuracy: 0.7009\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2384 - accuracy: 0.8815 - val_loss: 1.6361 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2434 - accuracy: 0.8556 - val_loss: 1.6119 - val_accuracy: 0.7179\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.6348 - val_accuracy: 0.7179\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2449 - accuracy: 0.8815 - val_loss: 1.6721 - val_accuracy: 0.7179\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2436 - accuracy: 0.8815 - val_loss: 1.6971 - val_accuracy: 0.7094\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2402 - accuracy: 0.8815 - val_loss: 1.6920 - val_accuracy: 0.7094\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 268us/step - loss: 0.2481 - accuracy: 0.8741 - val_loss: 1.6717 - val_accuracy: 0.7179\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2431 - accuracy: 0.8704 - val_loss: 1.6973 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2447 - accuracy: 0.8778 - val_loss: 1.6856 - val_accuracy: 0.7094\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2459 - accuracy: 0.8815 - val_loss: 1.6492 - val_accuracy: 0.7179\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2437 - accuracy: 0.8481 - val_loss: 1.6234 - val_accuracy: 0.7179\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2428 - accuracy: 0.8741 - val_loss: 1.6181 - val_accuracy: 0.7179\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 166us/step - loss: 0.2440 - accuracy: 0.8852 - val_loss: 1.6590 - val_accuracy: 0.7179\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.2414 - accuracy: 0.8815 - val_loss: 1.7017 - val_accuracy: 0.7179\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2416 - accuracy: 0.8815 - val_loss: 1.7009 - val_accuracy: 0.7179\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2400 - accuracy: 0.8889 - val_loss: 1.6681 - val_accuracy: 0.7179\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2421 - accuracy: 0.8815 - val_loss: 1.6710 - val_accuracy: 0.7265\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2441 - accuracy: 0.8778 - val_loss: 1.6966 - val_accuracy: 0.7265\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2413 - accuracy: 0.8741 - val_loss: 1.7091 - val_accuracy: 0.7094\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2393 - accuracy: 0.8815 - val_loss: 1.6946 - val_accuracy: 0.7094\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2454 - accuracy: 0.8741 - val_loss: 1.6789 - val_accuracy: 0.7179\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2429 - accuracy: 0.8778 - val_loss: 1.6382 - val_accuracy: 0.7094\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2420 - accuracy: 0.8741 - val_loss: 1.6063 - val_accuracy: 0.7265\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.6479 - val_accuracy: 0.7265\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2419 - accuracy: 0.8741 - val_loss: 1.6972 - val_accuracy: 0.7094\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2400 - accuracy: 0.8815 - val_loss: 1.7126 - val_accuracy: 0.7094\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2433 - accuracy: 0.8704 - val_loss: 1.7109 - val_accuracy: 0.7009\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2426 - accuracy: 0.8778 - val_loss: 1.7058 - val_accuracy: 0.7009\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2461 - accuracy: 0.8778 - val_loss: 1.6945 - val_accuracy: 0.7009\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2424 - accuracy: 0.8778 - val_loss: 1.6643 - val_accuracy: 0.7094\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2412 - accuracy: 0.8778 - val_loss: 1.6578 - val_accuracy: 0.7094\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2714 - accuracy: 0.8630 - val_loss: 1.6493 - val_accuracy: 0.7179\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 1.6416 - val_accuracy: 0.7094\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2613 - accuracy: 0.8556 - val_loss: 1.6743 - val_accuracy: 0.7094\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2523 - accuracy: 0.8630 - val_loss: 1.6145 - val_accuracy: 0.7265\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2444 - accuracy: 0.8704 - val_loss: 1.6027 - val_accuracy: 0.7350\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2511 - accuracy: 0.8667 - val_loss: 1.6204 - val_accuracy: 0.7350\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2425 - accuracy: 0.8778 - val_loss: 1.6713 - val_accuracy: 0.7094\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2406 - accuracy: 0.8815 - val_loss: 1.6970 - val_accuracy: 0.7094\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 303us/step - loss: 0.2425 - accuracy: 0.8815 - val_loss: 1.6973 - val_accuracy: 0.7094\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.6904 - val_accuracy: 0.7094\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.6556 - val_accuracy: 0.7179\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.6338 - val_accuracy: 0.7179\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2433 - accuracy: 0.8667 - val_loss: 1.6470 - val_accuracy: 0.7179\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2391 - accuracy: 0.8815 - val_loss: 1.6885 - val_accuracy: 0.7094\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2398 - accuracy: 0.8815 - val_loss: 1.7032 - val_accuracy: 0.7009\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2438 - accuracy: 0.8667 - val_loss: 1.6790 - val_accuracy: 0.7094\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2440 - accuracy: 0.8704 - val_loss: 1.6338 - val_accuracy: 0.7179\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2434 - accuracy: 0.8778 - val_loss: 1.6261 - val_accuracy: 0.7265\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2409 - accuracy: 0.8778 - val_loss: 1.6628 - val_accuracy: 0.7094\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2401 - accuracy: 0.8778 - val_loss: 1.6779 - val_accuracy: 0.7094\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 431us/step - loss: 0.2420 - accuracy: 0.8778 - val_loss: 1.6505 - val_accuracy: 0.7094\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.6147 - val_accuracy: 0.7179\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2433 - accuracy: 0.8630 - val_loss: 1.6123 - val_accuracy: 0.7179\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2406 - accuracy: 0.8778 - val_loss: 1.6494 - val_accuracy: 0.7094\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2449 - accuracy: 0.8667 - val_loss: 1.6812 - val_accuracy: 0.7179\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2478 - accuracy: 0.8741 - val_loss: 1.6868 - val_accuracy: 0.7094\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.6777 - val_accuracy: 0.7009\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2435 - accuracy: 0.8815 - val_loss: 1.6938 - val_accuracy: 0.7009\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2419 - accuracy: 0.8815 - val_loss: 1.6747 - val_accuracy: 0.7094\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2435 - accuracy: 0.8778 - val_loss: 1.6678 - val_accuracy: 0.7179\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2399 - accuracy: 0.8852 - val_loss: 1.6924 - val_accuracy: 0.7094\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2506 - accuracy: 0.8741 - val_loss: 1.7261 - val_accuracy: 0.7094\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2453 - accuracy: 0.8778 - val_loss: 1.6897 - val_accuracy: 0.7009\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2392 - accuracy: 0.8815 - val_loss: 1.6512 - val_accuracy: 0.7009\n"
     ]
    }
   ],
   "source": [
    "hist2_over2 = model2_over2.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 87.74%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.888869e-01</td>\n",
       "      <td>5.108038e-01</td>\n",
       "      <td>3.003094e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS232</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222906e-01</td>\n",
       "      <td>7.029924e-02</td>\n",
       "      <td>5.074101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.558408e-04</td>\n",
       "      <td>2.976018e-04</td>\n",
       "      <td>9.993465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.940971e-01</td>\n",
       "      <td>4.184215e-01</td>\n",
       "      <td>1.874814e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.239556e-01</td>\n",
       "      <td>2.760444e-01</td>\n",
       "      <td>1.176030e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052276e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.101559e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS108</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.011977e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.888959e-01</td>\n",
       "      <td>3.111042e-01</td>\n",
       "      <td>2.228958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.097719e-09</td>\n",
       "      <td>4.404655e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS249          2           1  1.888869e-01   \n",
       "1     p0006kpresabs_qual  NRS188          1           1  1.888869e-01   \n",
       "2     p0006kpresabs_qual  NRS232          2           2  4.222906e-01   \n",
       "3     p0006kpresabs_qual   NY439          2           2  3.558408e-04   \n",
       "4     p0006kpresabs_qual    GA27          2           1  3.940971e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS252          0           0  7.239556e-01   \n",
       "985  p0017Skpresabs_qual  SR2852          1           1  1.052276e-07   \n",
       "986  p0017Skpresabs_qual  NRS108          1           1  1.540350e-17   \n",
       "987  p0017Skpresabs_qual  NRS202          0           0  6.888959e-01   \n",
       "988  p0017Skpresabs_qual  NRS110          2           2  1.097719e-09   \n",
       "\n",
       "                1             2  \n",
       "0    5.108038e-01  3.003094e-01  \n",
       "1    5.108038e-01  3.003094e-01  \n",
       "2    7.029924e-02  5.074101e-01  \n",
       "3    2.976018e-04  9.993465e-01  \n",
       "4    4.184215e-01  1.874814e-01  \n",
       "..            ...           ...  \n",
       "984  2.760444e-01  1.176030e-09  \n",
       "985  9.999999e-01  1.101559e-28  \n",
       "986  1.000000e+00  9.011977e-16  \n",
       "987  3.111042e-01  2.228958e-09  \n",
       "988  4.404655e-08  1.000000e+00  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48274810e-06, 3.35711570e-03, 9.96641400e-01],\n",
       "       [3.50270250e-04, 8.62007500e-01, 1.37642200e-01],\n",
       "       [6.21414500e-08, 1.82600270e-04, 9.99817300e-01],\n",
       "       [2.24455470e-03, 3.04270340e-05, 9.97725070e-01],\n",
       "       [2.45247290e-08, 5.29366300e-03, 9.94706330e-01],\n",
       "       [1.48274810e-06, 3.35711570e-03, 9.96641400e-01],\n",
       "       [5.33735550e-04, 1.25956920e-02, 9.86870600e-01],\n",
       "       [9.47450340e-01, 1.88820180e-02, 3.36676720e-02],\n",
       "       [1.33940570e-03, 9.98509800e-01, 1.50717420e-04],\n",
       "       [2.24455470e-03, 3.04270340e-05, 9.97725070e-01],\n",
       "       [9.10449450e-01, 7.02621340e-02, 1.92884100e-02],\n",
       "       [4.41411400e-03, 9.92614750e-01, 2.97114670e-03],\n",
       "       [5.93028730e-03, 1.49903550e-01, 8.44166200e-01],\n",
       "       [2.66369790e-02, 3.78765050e-01, 5.94598000e-01],\n",
       "       [5.57191450e-05, 9.99899150e-01, 4.51526540e-05],\n",
       "       [1.45759020e-09, 9.21292100e-09, 1.00000000e+00],\n",
       "       [2.14298140e-02, 9.78318630e-01, 2.51612040e-04],\n",
       "       [1.98544900e-03, 9.98014330e-01, 2.03810020e-07],\n",
       "       [9.10449450e-01, 7.02621340e-02, 1.92884100e-02],\n",
       "       [9.91576140e-01, 1.01342295e-04, 8.32253600e-03],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [4.94365200e-03, 9.95038000e-01, 1.83551640e-05],\n",
       "       [9.99999900e-01, 1.28825480e-07, 1.77993730e-11],\n",
       "       [1.45759020e-09, 9.21292100e-09, 1.00000000e+00],\n",
       "       [8.53442500e-01, 1.45929680e-01, 6.27857170e-04],\n",
       "       [3.18932370e-06, 9.99627100e-01, 3.69603400e-04],\n",
       "       [9.91253900e-01, 8.44753000e-03, 2.98615920e-04],\n",
       "       [1.00000000e+00, 1.41711120e-13, 1.68191640e-11],\n",
       "       [1.33893400e-03, 9.98628500e-01, 3.26332630e-05],\n",
       "       [1.00000000e+00, 1.11691680e-09, 1.68574400e-08],\n",
       "       [9.99999400e-01, 2.07578750e-07, 4.11882920e-07],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [3.21764300e-05, 9.68061030e-01, 3.19067400e-02],\n",
       "       [4.26864340e-04, 4.30458070e-01, 5.69115040e-01],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [6.02341960e-03, 9.93950100e-01, 2.64603880e-05],\n",
       "       [1.23930500e-04, 1.63000310e-05, 9.99859700e-01],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [5.93028730e-03, 1.49903550e-01, 8.44166200e-01],\n",
       "       [1.97862060e-04, 4.63451400e-04, 9.99338700e-01],\n",
       "       [8.93285750e-01, 1.05952150e-01, 7.62174100e-04],\n",
       "       [8.53442500e-01, 1.45929680e-01, 6.27857170e-04],\n",
       "       [9.99716000e-01, 2.76029370e-04, 7.94150200e-06],\n",
       "       [1.01436920e-06, 3.53200440e-01, 6.46798600e-01],\n",
       "       [8.24629900e-03, 9.91680200e-01, 7.35298700e-05],\n",
       "       [3.11995180e-03, 9.96603850e-01, 2.76182520e-04],\n",
       "       [4.26172400e-06, 8.79107200e-06, 9.99987000e-01],\n",
       "       [2.67788500e-06, 5.90768130e-03, 9.94089700e-01],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [3.18932370e-06, 9.99627100e-01, 3.69603400e-04],\n",
       "       [1.11303360e-09, 3.87177440e-06, 9.99996200e-01],\n",
       "       [4.26172400e-06, 8.79107200e-06, 9.99987000e-01],\n",
       "       [9.99997850e-01, 3.86627160e-08, 2.20333870e-06],\n",
       "       [3.50270250e-04, 8.62007500e-01, 1.37642200e-01],\n",
       "       [3.50270250e-04, 8.62007500e-01, 1.37642200e-01],\n",
       "       [6.62526470e-04, 5.51463600e-04, 9.98786030e-01],\n",
       "       [2.68074420e-04, 9.98630500e-01, 1.10137720e-03],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [6.62526470e-04, 5.51463600e-04, 9.98786030e-01],\n",
       "       [3.91514800e-03, 9.95705540e-01, 3.79309170e-04],\n",
       "       [2.78510300e-05, 9.33774000e-04, 9.99038460e-01],\n",
       "       [2.71850990e-03, 9.97166000e-01, 1.15585710e-04],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [2.95157800e-01, 7.01440100e-01, 3.40208900e-03],\n",
       "       [8.93285750e-01, 1.05952150e-01, 7.62174100e-04],\n",
       "       [1.87068870e-03, 9.98084200e-01, 4.50844960e-05],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [3.28130600e-05, 1.61435990e-01, 8.38531200e-01],\n",
       "       [2.95157800e-01, 7.01440100e-01, 3.40208900e-03],\n",
       "       [2.67788500e-06, 5.90768130e-03, 9.94089700e-01],\n",
       "       [6.16654900e-08, 3.22507800e-05, 9.99967700e-01],\n",
       "       [5.93028730e-03, 1.49903550e-01, 8.44166200e-01],\n",
       "       [3.28130600e-05, 1.61435990e-01, 8.38531200e-01],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [8.53442500e-01, 1.45929680e-01, 6.27857170e-04],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [2.61396730e-02, 4.51527920e-05, 9.73815200e-01],\n",
       "       [9.11867400e-06, 8.48442800e-04, 9.99142400e-01],\n",
       "       [5.71762600e-04, 9.99420050e-01, 8.19251100e-06],\n",
       "       [2.95157800e-01, 7.01440100e-01, 3.40208900e-03],\n",
       "       [2.74692700e-03, 9.30456940e-01, 6.67961700e-02],\n",
       "       [6.44795800e-01, 6.64347000e-02, 2.88769540e-01],\n",
       "       [6.20550800e-04, 9.99299300e-01, 8.01843700e-05],\n",
       "       [5.71762600e-04, 9.99420050e-01, 8.19251100e-06],\n",
       "       [9.99724700e-01, 2.67951550e-04, 7.38021840e-06],\n",
       "       [3.50270250e-04, 8.62007500e-01, 1.37642200e-01],\n",
       "       [9.89798550e-01, 9.39338750e-03, 8.07989800e-04],\n",
       "       [5.22079900e-03, 9.94318660e-01, 4.60585840e-04],\n",
       "       [3.91514800e-03, 9.95705540e-01, 3.79309170e-04],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [9.99996800e-01, 3.17707960e-06, 1.17810850e-08],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [1.48274810e-06, 3.35711570e-03, 9.96641400e-01],\n",
       "       [9.99999900e-01, 5.99938000e-08, 1.10579816e-10],\n",
       "       [1.50727070e-03, 9.98491400e-01, 1.32829370e-06],\n",
       "       [2.22825580e-04, 9.99196600e-01, 5.80504360e-04],\n",
       "       [5.93028730e-03, 1.49903550e-01, 8.44166200e-01],\n",
       "       [5.93028730e-03, 1.49903550e-01, 8.44166200e-01],\n",
       "       [9.97994800e-01, 1.89022800e-03, 1.15081410e-04],\n",
       "       [3.18932370e-06, 9.99627100e-01, 3.69603400e-04],\n",
       "       [3.28130600e-05, 1.61435990e-01, 8.38531200e-01],\n",
       "       [4.89066750e-01, 4.64927080e-01, 4.60060900e-02],\n",
       "       [9.45951960e-04, 9.98027860e-01, 1.02620100e-03],\n",
       "       [9.99985000e-01, 1.50364890e-05, 3.12307990e-10],\n",
       "       [1.21222414e-01, 6.04618550e-01, 2.74158980e-01],\n",
       "       [3.28130600e-05, 1.61435990e-01, 8.38531200e-01],\n",
       "       [6.58079400e-01, 3.41740580e-01, 1.79928360e-04],\n",
       "       [8.53442500e-01, 1.45929680e-01, 6.27857170e-04],\n",
       "       [9.99997850e-01, 3.86627160e-08, 2.20333870e-06],\n",
       "       [8.59510000e-01, 1.40010700e-01, 4.79335780e-04],\n",
       "       [8.79475500e-02, 4.88072020e-04, 9.11564350e-01],\n",
       "       [2.95157800e-01, 7.01440100e-01, 3.40208900e-03],\n",
       "       [1.11303360e-09, 3.87177440e-06, 9.99996200e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210607056760902"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210607056760902"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat7['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS210     0\n",
       "1         NRS205     2\n",
       "2            312     2\n",
       "3           GA15     2\n",
       "4         SR4035     0\n",
       "..           ...   ...\n",
       "112       NRS265     2\n",
       "113  CFBREBSa108     1\n",
       "114        NY224     1\n",
       "115       NRS386     2\n",
       "116       NRS168     2\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 867us/step - loss: 1.1220 - accuracy: 0.2852 - val_loss: 1.0656 - val_accuracy: 0.4274\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 1.0702 - accuracy: 0.4000 - val_loss: 1.0274 - val_accuracy: 0.4957\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 195us/step - loss: 1.0359 - accuracy: 0.4815 - val_loss: 0.9970 - val_accuracy: 0.5983\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 1.0042 - accuracy: 0.5889 - val_loss: 0.9707 - val_accuracy: 0.6325\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.9791 - accuracy: 0.6000 - val_loss: 0.9457 - val_accuracy: 0.6581\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.9540 - accuracy: 0.6111 - val_loss: 0.9228 - val_accuracy: 0.6667\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.9346 - accuracy: 0.6148 - val_loss: 0.9046 - val_accuracy: 0.6752\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.9153 - accuracy: 0.6259 - val_loss: 0.8885 - val_accuracy: 0.6752\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.8992 - accuracy: 0.6370 - val_loss: 0.8735 - val_accuracy: 0.6752\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.8845 - accuracy: 0.6333 - val_loss: 0.8609 - val_accuracy: 0.6752\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.8696 - accuracy: 0.6370 - val_loss: 0.8501 - val_accuracy: 0.6752\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8557 - accuracy: 0.6444 - val_loss: 0.8409 - val_accuracy: 0.6752\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.8411 - accuracy: 0.6481 - val_loss: 0.8344 - val_accuracy: 0.6667\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.8293 - accuracy: 0.6407 - val_loss: 0.8254 - val_accuracy: 0.6496\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.8187 - accuracy: 0.6407 - val_loss: 0.8163 - val_accuracy: 0.6581\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.8073 - accuracy: 0.6333 - val_loss: 0.8048 - val_accuracy: 0.6496\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.7957 - accuracy: 0.6333 - val_loss: 0.7966 - val_accuracy: 0.6667\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.7847 - accuracy: 0.6333 - val_loss: 0.7897 - val_accuracy: 0.6496\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.7727 - accuracy: 0.6667 - val_loss: 0.7860 - val_accuracy: 0.6581\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7625 - accuracy: 0.6704 - val_loss: 0.7816 - val_accuracy: 0.6667\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.7526 - accuracy: 0.6889 - val_loss: 0.7761 - val_accuracy: 0.6752\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.7401 - accuracy: 0.6815 - val_loss: 0.7600 - val_accuracy: 0.6923\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.7332 - accuracy: 0.6963 - val_loss: 0.7513 - val_accuracy: 0.6838\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.7245 - accuracy: 0.6963 - val_loss: 0.7502 - val_accuracy: 0.6923\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.7135 - accuracy: 0.7111 - val_loss: 0.7475 - val_accuracy: 0.6923\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.7052 - accuracy: 0.7074 - val_loss: 0.7424 - val_accuracy: 0.6838\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6968 - accuracy: 0.7074 - val_loss: 0.7407 - val_accuracy: 0.6923\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6884 - accuracy: 0.7000 - val_loss: 0.7363 - val_accuracy: 0.6838\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.6827 - accuracy: 0.7037 - val_loss: 0.7317 - val_accuracy: 0.6838\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6753 - accuracy: 0.7074 - val_loss: 0.7336 - val_accuracy: 0.6838\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6676 - accuracy: 0.7000 - val_loss: 0.7394 - val_accuracy: 0.6581\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.6604 - accuracy: 0.7000 - val_loss: 0.7325 - val_accuracy: 0.6752\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.6530 - accuracy: 0.7074 - val_loss: 0.7298 - val_accuracy: 0.6752\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6489 - accuracy: 0.7037 - val_loss: 0.7222 - val_accuracy: 0.6752\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.6386 - accuracy: 0.7000 - val_loss: 0.7226 - val_accuracy: 0.6496\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.6336 - accuracy: 0.7037 - val_loss: 0.7268 - val_accuracy: 0.6667\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.6305 - accuracy: 0.7259 - val_loss: 0.7197 - val_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.6226 - accuracy: 0.7111 - val_loss: 0.7085 - val_accuracy: 0.7009\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.6161 - accuracy: 0.7185 - val_loss: 0.7065 - val_accuracy: 0.6923\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.6082 - accuracy: 0.7185 - val_loss: 0.7105 - val_accuracy: 0.6923\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.6033 - accuracy: 0.7296 - val_loss: 0.7153 - val_accuracy: 0.6923\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.6004 - accuracy: 0.7259 - val_loss: 0.7100 - val_accuracy: 0.6923\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5930 - accuracy: 0.7444 - val_loss: 0.7050 - val_accuracy: 0.7179\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5884 - accuracy: 0.7333 - val_loss: 0.7060 - val_accuracy: 0.7265\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5847 - accuracy: 0.7481 - val_loss: 0.6988 - val_accuracy: 0.7179\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5770 - accuracy: 0.7593 - val_loss: 0.7001 - val_accuracy: 0.7179\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5735 - accuracy: 0.7593 - val_loss: 0.7075 - val_accuracy: 0.7009\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.5708 - accuracy: 0.7370 - val_loss: 0.7084 - val_accuracy: 0.7009\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.5657 - accuracy: 0.7481 - val_loss: 0.6981 - val_accuracy: 0.7094\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5633 - accuracy: 0.7519 - val_loss: 0.6874 - val_accuracy: 0.7179\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5598 - accuracy: 0.7481 - val_loss: 0.6880 - val_accuracy: 0.7265\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.5518 - accuracy: 0.7593 - val_loss: 0.6994 - val_accuracy: 0.7179\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5513 - accuracy: 0.7556 - val_loss: 0.7072 - val_accuracy: 0.7094\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.5449 - accuracy: 0.7593 - val_loss: 0.6968 - val_accuracy: 0.7265\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5413 - accuracy: 0.7667 - val_loss: 0.6928 - val_accuracy: 0.7265\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.5390 - accuracy: 0.7556 - val_loss: 0.6948 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.5332 - accuracy: 0.7556 - val_loss: 0.6927 - val_accuracy: 0.7265\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.5279 - accuracy: 0.7667 - val_loss: 0.6874 - val_accuracy: 0.7521\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5286 - accuracy: 0.7704 - val_loss: 0.6870 - val_accuracy: 0.7436\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5251 - accuracy: 0.7667 - val_loss: 0.6941 - val_accuracy: 0.7265\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.5194 - accuracy: 0.7667 - val_loss: 0.6880 - val_accuracy: 0.7350\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.5132 - accuracy: 0.7630 - val_loss: 0.6873 - val_accuracy: 0.7265\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5118 - accuracy: 0.7704 - val_loss: 0.6950 - val_accuracy: 0.7265\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.5100 - accuracy: 0.7704 - val_loss: 0.6932 - val_accuracy: 0.7350\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.5048 - accuracy: 0.7778 - val_loss: 0.6816 - val_accuracy: 0.7436\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.5040 - accuracy: 0.7630 - val_loss: 0.6818 - val_accuracy: 0.7436\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.4993 - accuracy: 0.7815 - val_loss: 0.6897 - val_accuracy: 0.7350\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.4974 - accuracy: 0.7778 - val_loss: 0.6790 - val_accuracy: 0.7350\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.4960 - accuracy: 0.7778 - val_loss: 0.6765 - val_accuracy: 0.7436\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4948 - accuracy: 0.7778 - val_loss: 0.6791 - val_accuracy: 0.7350\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.4896 - accuracy: 0.7815 - val_loss: 0.6746 - val_accuracy: 0.7436\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.4837 - accuracy: 0.7926 - val_loss: 0.6795 - val_accuracy: 0.7436\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.4803 - accuracy: 0.7926 - val_loss: 0.6868 - val_accuracy: 0.7350\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.4811 - accuracy: 0.7815 - val_loss: 0.6862 - val_accuracy: 0.7436\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.4799 - accuracy: 0.7926 - val_loss: 0.6814 - val_accuracy: 0.7436\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.4801 - accuracy: 0.7852 - val_loss: 0.6766 - val_accuracy: 0.7436\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.4759 - accuracy: 0.8037 - val_loss: 0.6888 - val_accuracy: 0.7436\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4694 - accuracy: 0.8037 - val_loss: 0.6910 - val_accuracy: 0.7350\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4722 - accuracy: 0.7815 - val_loss: 0.6853 - val_accuracy: 0.7436\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.4641 - accuracy: 0.8037 - val_loss: 0.6761 - val_accuracy: 0.7607\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.4664 - accuracy: 0.8037 - val_loss: 0.6862 - val_accuracy: 0.7521\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.4627 - accuracy: 0.8074 - val_loss: 0.6858 - val_accuracy: 0.7436\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4582 - accuracy: 0.7963 - val_loss: 0.6799 - val_accuracy: 0.7436\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.4571 - accuracy: 0.8037 - val_loss: 0.6768 - val_accuracy: 0.7436\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4551 - accuracy: 0.8185 - val_loss: 0.6814 - val_accuracy: 0.7436\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.4503 - accuracy: 0.8222 - val_loss: 0.6828 - val_accuracy: 0.7521\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.4488 - accuracy: 0.8111 - val_loss: 0.6791 - val_accuracy: 0.7521\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.4479 - accuracy: 0.8185 - val_loss: 0.6742 - val_accuracy: 0.7521\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.4404 - accuracy: 0.8222 - val_loss: 0.6735 - val_accuracy: 0.7521\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.4383 - accuracy: 0.8259 - val_loss: 0.6845 - val_accuracy: 0.7436\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.4387 - accuracy: 0.8259 - val_loss: 0.6876 - val_accuracy: 0.7436\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4333 - accuracy: 0.8296 - val_loss: 0.6831 - val_accuracy: 0.7436\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4323 - accuracy: 0.8333 - val_loss: 0.6886 - val_accuracy: 0.7436\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.4272 - accuracy: 0.8259 - val_loss: 0.6944 - val_accuracy: 0.7436\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4328 - accuracy: 0.8074 - val_loss: 0.6848 - val_accuracy: 0.7521\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4270 - accuracy: 0.8222 - val_loss: 0.6816 - val_accuracy: 0.7521\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.4272 - accuracy: 0.8444 - val_loss: 0.6892 - val_accuracy: 0.7607\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.4234 - accuracy: 0.8148 - val_loss: 0.6870 - val_accuracy: 0.7521\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.6846 - val_accuracy: 0.7521\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.4206 - accuracy: 0.8074 - val_loss: 0.6823 - val_accuracy: 0.7607\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.4193 - accuracy: 0.8111 - val_loss: 0.6882 - val_accuracy: 0.7521\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.4147 - accuracy: 0.8259 - val_loss: 0.6845 - val_accuracy: 0.7607\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.4140 - accuracy: 0.8222 - val_loss: 0.6908 - val_accuracy: 0.7436\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.4126 - accuracy: 0.8407 - val_loss: 0.6966 - val_accuracy: 0.7436\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.4111 - accuracy: 0.8333 - val_loss: 0.6914 - val_accuracy: 0.7436\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4037 - accuracy: 0.8407 - val_loss: 0.6851 - val_accuracy: 0.7521\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4020 - accuracy: 0.8444 - val_loss: 0.6878 - val_accuracy: 0.7521\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4015 - accuracy: 0.8370 - val_loss: 0.6929 - val_accuracy: 0.7521\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4002 - accuracy: 0.8407 - val_loss: 0.6923 - val_accuracy: 0.7521\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3987 - accuracy: 0.8481 - val_loss: 0.6846 - val_accuracy: 0.7521\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3984 - accuracy: 0.8481 - val_loss: 0.6851 - val_accuracy: 0.7607\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3950 - accuracy: 0.8407 - val_loss: 0.7092 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4007 - accuracy: 0.8148 - val_loss: 0.6832 - val_accuracy: 0.7692\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3940 - accuracy: 0.8481 - val_loss: 0.6747 - val_accuracy: 0.7521\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3909 - accuracy: 0.8444 - val_loss: 0.6841 - val_accuracy: 0.7692\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3887 - accuracy: 0.8481 - val_loss: 0.6995 - val_accuracy: 0.7521\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3928 - accuracy: 0.8370 - val_loss: 0.7089 - val_accuracy: 0.7607\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3995 - accuracy: 0.8185 - val_loss: 0.7283 - val_accuracy: 0.7692\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.3884 - accuracy: 0.8519 - val_loss: 0.6851 - val_accuracy: 0.7521\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3904 - accuracy: 0.8519 - val_loss: 0.6844 - val_accuracy: 0.7692\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3837 - accuracy: 0.8556 - val_loss: 0.7063 - val_accuracy: 0.7607\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3803 - accuracy: 0.8407 - val_loss: 0.7019 - val_accuracy: 0.7692\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3781 - accuracy: 0.8519 - val_loss: 0.6924 - val_accuracy: 0.7521\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3765 - accuracy: 0.8519 - val_loss: 0.7002 - val_accuracy: 0.7692\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3745 - accuracy: 0.8519 - val_loss: 0.7125 - val_accuracy: 0.7692\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3730 - accuracy: 0.8481 - val_loss: 0.7133 - val_accuracy: 0.7692\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3700 - accuracy: 0.8481 - val_loss: 0.7067 - val_accuracy: 0.7521\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3719 - accuracy: 0.8519 - val_loss: 0.7038 - val_accuracy: 0.7521\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3687 - accuracy: 0.8593 - val_loss: 0.7111 - val_accuracy: 0.7692\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3667 - accuracy: 0.8519 - val_loss: 0.7145 - val_accuracy: 0.7692\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.3640 - accuracy: 0.8556 - val_loss: 0.6978 - val_accuracy: 0.7692\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3645 - accuracy: 0.8556 - val_loss: 0.6969 - val_accuracy: 0.7692\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.3626 - accuracy: 0.8481 - val_loss: 0.7163 - val_accuracy: 0.7692\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3622 - accuracy: 0.8519 - val_loss: 0.7163 - val_accuracy: 0.7607\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3566 - accuracy: 0.8556 - val_loss: 0.6992 - val_accuracy: 0.7607\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3587 - accuracy: 0.8556 - val_loss: 0.6934 - val_accuracy: 0.7607\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3600 - accuracy: 0.8481 - val_loss: 0.6999 - val_accuracy: 0.7692\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3625 - accuracy: 0.8556 - val_loss: 0.7276 - val_accuracy: 0.7692\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3625 - accuracy: 0.8593 - val_loss: 0.7107 - val_accuracy: 0.7692\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3638 - accuracy: 0.8481 - val_loss: 0.7011 - val_accuracy: 0.7607\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3642 - accuracy: 0.8481 - val_loss: 0.7111 - val_accuracy: 0.7778\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3549 - accuracy: 0.8593 - val_loss: 0.7683 - val_accuracy: 0.7521\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3711 - accuracy: 0.8333 - val_loss: 0.7284 - val_accuracy: 0.7778\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3494 - accuracy: 0.8593 - val_loss: 0.7059 - val_accuracy: 0.7692\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3525 - accuracy: 0.8556 - val_loss: 0.7140 - val_accuracy: 0.7778\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3493 - accuracy: 0.8630 - val_loss: 0.7370 - val_accuracy: 0.7692\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3509 - accuracy: 0.8630 - val_loss: 0.7477 - val_accuracy: 0.7692\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3489 - accuracy: 0.8593 - val_loss: 0.7181 - val_accuracy: 0.7692\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3587 - accuracy: 0.8556 - val_loss: 0.7035 - val_accuracy: 0.7778\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3426 - accuracy: 0.8667 - val_loss: 0.7297 - val_accuracy: 0.7778\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3459 - accuracy: 0.8593 - val_loss: 0.7408 - val_accuracy: 0.7692\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3418 - accuracy: 0.8556 - val_loss: 0.7125 - val_accuracy: 0.7607\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3464 - accuracy: 0.8704 - val_loss: 0.7119 - val_accuracy: 0.7692\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3507 - accuracy: 0.8630 - val_loss: 0.7231 - val_accuracy: 0.7607\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3416 - accuracy: 0.8630 - val_loss: 0.7460 - val_accuracy: 0.7607\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3433 - accuracy: 0.8630 - val_loss: 0.7771 - val_accuracy: 0.7436\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.3538 - accuracy: 0.8370 - val_loss: 0.7567 - val_accuracy: 0.7521\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3372 - accuracy: 0.8444 - val_loss: 0.7214 - val_accuracy: 0.7692\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3333 - accuracy: 0.8630 - val_loss: 0.7195 - val_accuracy: 0.7778\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3367 - accuracy: 0.8519 - val_loss: 0.7401 - val_accuracy: 0.7692\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3331 - accuracy: 0.8593 - val_loss: 0.7474 - val_accuracy: 0.7778\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3342 - accuracy: 0.8630 - val_loss: 0.7284 - val_accuracy: 0.7692\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3359 - accuracy: 0.8630 - val_loss: 0.7256 - val_accuracy: 0.7692\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3411 - accuracy: 0.8556 - val_loss: 0.7511 - val_accuracy: 0.7692\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3323 - accuracy: 0.8593 - val_loss: 0.7416 - val_accuracy: 0.7692\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3292 - accuracy: 0.8593 - val_loss: 0.7375 - val_accuracy: 0.7607\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3275 - accuracy: 0.8630 - val_loss: 0.7608 - val_accuracy: 0.7692\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3336 - accuracy: 0.8519 - val_loss: 0.7493 - val_accuracy: 0.7692\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3275 - accuracy: 0.8630 - val_loss: 0.7234 - val_accuracy: 0.7607\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3351 - accuracy: 0.8630 - val_loss: 0.7271 - val_accuracy: 0.7778\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3337 - accuracy: 0.8593 - val_loss: 0.7691 - val_accuracy: 0.7607\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3325 - accuracy: 0.8593 - val_loss: 0.7633 - val_accuracy: 0.7521\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.3274 - accuracy: 0.8593 - val_loss: 0.7371 - val_accuracy: 0.7692\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3252 - accuracy: 0.8667 - val_loss: 0.7451 - val_accuracy: 0.7692\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3215 - accuracy: 0.8667 - val_loss: 0.7580 - val_accuracy: 0.7607\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3197 - accuracy: 0.8704 - val_loss: 0.7624 - val_accuracy: 0.7607\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3209 - accuracy: 0.8630 - val_loss: 0.7601 - val_accuracy: 0.7692\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3269 - accuracy: 0.8519 - val_loss: 0.7622 - val_accuracy: 0.7778\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.3247 - accuracy: 0.8630 - val_loss: 0.7434 - val_accuracy: 0.7778\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3187 - accuracy: 0.8704 - val_loss: 0.7409 - val_accuracy: 0.7692\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3247 - accuracy: 0.8593 - val_loss: 0.7505 - val_accuracy: 0.7778\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3166 - accuracy: 0.8630 - val_loss: 0.7579 - val_accuracy: 0.7607\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3201 - accuracy: 0.8630 - val_loss: 0.7472 - val_accuracy: 0.7521\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3188 - accuracy: 0.8704 - val_loss: 0.7498 - val_accuracy: 0.7607\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3187 - accuracy: 0.8630 - val_loss: 0.7653 - val_accuracy: 0.7692\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3143 - accuracy: 0.8630 - val_loss: 0.7599 - val_accuracy: 0.7692\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3186 - accuracy: 0.8630 - val_loss: 0.7669 - val_accuracy: 0.7863\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3152 - accuracy: 0.8630 - val_loss: 0.7468 - val_accuracy: 0.7778\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3138 - accuracy: 0.8630 - val_loss: 0.7519 - val_accuracy: 0.7692\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3170 - accuracy: 0.8630 - val_loss: 0.7595 - val_accuracy: 0.7778\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3124 - accuracy: 0.8667 - val_loss: 0.7770 - val_accuracy: 0.7607\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3120 - accuracy: 0.8630 - val_loss: 0.7842 - val_accuracy: 0.7607\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3119 - accuracy: 0.8630 - val_loss: 0.7846 - val_accuracy: 0.7607\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3116 - accuracy: 0.8630 - val_loss: 0.7761 - val_accuracy: 0.7692\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.7574 - val_accuracy: 0.7778\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3107 - accuracy: 0.8630 - val_loss: 0.7614 - val_accuracy: 0.7692\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3121 - accuracy: 0.8593 - val_loss: 0.7840 - val_accuracy: 0.7607\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3084 - accuracy: 0.8630 - val_loss: 0.7714 - val_accuracy: 0.7607\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3129 - accuracy: 0.8481 - val_loss: 0.7568 - val_accuracy: 0.7607\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3091 - accuracy: 0.8556 - val_loss: 0.7594 - val_accuracy: 0.7778\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3092 - accuracy: 0.8630 - val_loss: 0.7763 - val_accuracy: 0.7521\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3061 - accuracy: 0.8741 - val_loss: 0.7713 - val_accuracy: 0.7607\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3049 - accuracy: 0.8667 - val_loss: 0.7643 - val_accuracy: 0.7778\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.3084 - accuracy: 0.8630 - val_loss: 0.7773 - val_accuracy: 0.7607\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3075 - accuracy: 0.8630 - val_loss: 0.7900 - val_accuracy: 0.7607\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3031 - accuracy: 0.8630 - val_loss: 0.7902 - val_accuracy: 0.7607\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3065 - accuracy: 0.8630 - val_loss: 0.7902 - val_accuracy: 0.7607\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3090 - accuracy: 0.8630 - val_loss: 0.7820 - val_accuracy: 0.7607\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3067 - accuracy: 0.8593 - val_loss: 0.7922 - val_accuracy: 0.7692\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3030 - accuracy: 0.8519 - val_loss: 0.7866 - val_accuracy: 0.7607\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3092 - accuracy: 0.8667 - val_loss: 0.7988 - val_accuracy: 0.7692\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3047 - accuracy: 0.8667 - val_loss: 0.7815 - val_accuracy: 0.7607\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3041 - accuracy: 0.8667 - val_loss: 0.7904 - val_accuracy: 0.7607\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3080 - accuracy: 0.8630 - val_loss: 0.8089 - val_accuracy: 0.7436\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3107 - accuracy: 0.8444 - val_loss: 0.7703 - val_accuracy: 0.7692\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.3123 - accuracy: 0.8630 - val_loss: 0.7525 - val_accuracy: 0.7607\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3121 - accuracy: 0.8630 - val_loss: 0.7889 - val_accuracy: 0.7607\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3087 - accuracy: 0.8556 - val_loss: 0.8208 - val_accuracy: 0.7607\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3083 - accuracy: 0.8481 - val_loss: 0.7875 - val_accuracy: 0.7607\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3051 - accuracy: 0.8556 - val_loss: 0.7921 - val_accuracy: 0.7692\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2972 - accuracy: 0.8630 - val_loss: 0.7782 - val_accuracy: 0.7607\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3007 - accuracy: 0.8630 - val_loss: 0.7899 - val_accuracy: 0.7607\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2973 - accuracy: 0.8556 - val_loss: 0.7816 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3003 - accuracy: 0.8556 - val_loss: 0.7946 - val_accuracy: 0.7692\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2984 - accuracy: 0.8667 - val_loss: 0.7987 - val_accuracy: 0.7521\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2968 - accuracy: 0.8593 - val_loss: 0.7728 - val_accuracy: 0.7607\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2990 - accuracy: 0.8667 - val_loss: 0.7732 - val_accuracy: 0.7607\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2993 - accuracy: 0.8519 - val_loss: 0.7957 - val_accuracy: 0.7521\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2956 - accuracy: 0.8667 - val_loss: 0.8154 - val_accuracy: 0.7521\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2964 - accuracy: 0.8630 - val_loss: 0.7963 - val_accuracy: 0.7607\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2961 - accuracy: 0.8630 - val_loss: 0.7809 - val_accuracy: 0.7521\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3012 - accuracy: 0.8630 - val_loss: 0.7924 - val_accuracy: 0.7692\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3047 - accuracy: 0.8630 - val_loss: 0.8033 - val_accuracy: 0.7607\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2944 - accuracy: 0.8630 - val_loss: 0.8163 - val_accuracy: 0.7607\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2943 - accuracy: 0.8519 - val_loss: 0.8208 - val_accuracy: 0.7692\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2994 - accuracy: 0.8630 - val_loss: 0.8075 - val_accuracy: 0.7607\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2918 - accuracy: 0.8556 - val_loss: 0.8289 - val_accuracy: 0.7607\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2989 - accuracy: 0.8667 - val_loss: 0.7997 - val_accuracy: 0.7607\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3032 - accuracy: 0.8519 - val_loss: 0.7687 - val_accuracy: 0.7521\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2942 - accuracy: 0.8630 - val_loss: 0.8057 - val_accuracy: 0.7607\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2932 - accuracy: 0.8593 - val_loss: 0.8173 - val_accuracy: 0.7607\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2919 - accuracy: 0.8667 - val_loss: 0.8019 - val_accuracy: 0.7607\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2893 - accuracy: 0.8667 - val_loss: 0.7965 - val_accuracy: 0.7692\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3001 - accuracy: 0.8630 - val_loss: 0.7968 - val_accuracy: 0.7607\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2968 - accuracy: 0.8704 - val_loss: 0.8362 - val_accuracy: 0.7607\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2930 - accuracy: 0.8556 - val_loss: 0.8163 - val_accuracy: 0.7607\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2882 - accuracy: 0.8704 - val_loss: 0.7935 - val_accuracy: 0.7692\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2893 - accuracy: 0.8630 - val_loss: 0.7932 - val_accuracy: 0.7692\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2915 - accuracy: 0.8593 - val_loss: 0.8025 - val_accuracy: 0.7607\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2917 - accuracy: 0.8593 - val_loss: 0.8142 - val_accuracy: 0.7607\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2930 - accuracy: 0.8667 - val_loss: 0.8059 - val_accuracy: 0.7521\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2958 - accuracy: 0.8593 - val_loss: 0.8264 - val_accuracy: 0.7607\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2973 - accuracy: 0.8593 - val_loss: 0.8221 - val_accuracy: 0.7607\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2918 - accuracy: 0.8630 - val_loss: 0.8102 - val_accuracy: 0.7521\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2891 - accuracy: 0.8667 - val_loss: 0.8451 - val_accuracy: 0.7436\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3016 - accuracy: 0.8481 - val_loss: 0.8267 - val_accuracy: 0.7436\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2891 - accuracy: 0.8630 - val_loss: 0.7761 - val_accuracy: 0.7607\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2916 - accuracy: 0.8630 - val_loss: 0.7850 - val_accuracy: 0.7692\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2848 - accuracy: 0.8630 - val_loss: 0.8327 - val_accuracy: 0.7607\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2889 - accuracy: 0.8667 - val_loss: 0.8342 - val_accuracy: 0.7607\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2862 - accuracy: 0.8667 - val_loss: 0.8184 - val_accuracy: 0.7607\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2859 - accuracy: 0.8667 - val_loss: 0.8125 - val_accuracy: 0.7521\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2889 - accuracy: 0.8667 - val_loss: 0.8115 - val_accuracy: 0.7607\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 298us/step - loss: 0.2859 - accuracy: 0.8630 - val_loss: 0.8067 - val_accuracy: 0.7607\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2908 - accuracy: 0.8593 - val_loss: 0.7985 - val_accuracy: 0.7607\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2854 - accuracy: 0.8630 - val_loss: 0.8295 - val_accuracy: 0.7607\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2858 - accuracy: 0.8593 - val_loss: 0.8428 - val_accuracy: 0.7607\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2926 - accuracy: 0.8667 - val_loss: 0.8352 - val_accuracy: 0.7607\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2891 - accuracy: 0.8593 - val_loss: 0.8150 - val_accuracy: 0.7607\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2868 - accuracy: 0.8667 - val_loss: 0.8016 - val_accuracy: 0.7607\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2900 - accuracy: 0.8593 - val_loss: 0.7947 - val_accuracy: 0.7521\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2906 - accuracy: 0.8630 - val_loss: 0.7923 - val_accuracy: 0.7692\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2877 - accuracy: 0.8741 - val_loss: 0.8160 - val_accuracy: 0.7607\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2869 - accuracy: 0.8704 - val_loss: 0.8197 - val_accuracy: 0.7607\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2879 - accuracy: 0.8630 - val_loss: 0.8128 - val_accuracy: 0.7692\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2875 - accuracy: 0.8630 - val_loss: 0.8453 - val_accuracy: 0.7607\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2872 - accuracy: 0.8667 - val_loss: 0.8437 - val_accuracy: 0.7607\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2871 - accuracy: 0.8667 - val_loss: 0.8306 - val_accuracy: 0.7607\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2813 - accuracy: 0.8667 - val_loss: 0.7973 - val_accuracy: 0.7607\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2864 - accuracy: 0.8630 - val_loss: 0.7909 - val_accuracy: 0.7607\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2845 - accuracy: 0.8667 - val_loss: 0.8217 - val_accuracy: 0.7607\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2853 - accuracy: 0.8667 - val_loss: 0.8639 - val_accuracy: 0.7607\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2857 - accuracy: 0.8667 - val_loss: 0.8420 - val_accuracy: 0.7607\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2829 - accuracy: 0.8667 - val_loss: 0.8218 - val_accuracy: 0.7692\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2850 - accuracy: 0.8630 - val_loss: 0.8466 - val_accuracy: 0.7436\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2890 - accuracy: 0.8519 - val_loss: 0.8420 - val_accuracy: 0.7436\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2828 - accuracy: 0.8741 - val_loss: 0.8054 - val_accuracy: 0.7692\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2831 - accuracy: 0.8593 - val_loss: 0.8093 - val_accuracy: 0.7607\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2852 - accuracy: 0.8519 - val_loss: 0.8168 - val_accuracy: 0.7692\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2859 - accuracy: 0.8593 - val_loss: 0.8532 - val_accuracy: 0.7607\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2832 - accuracy: 0.8667 - val_loss: 0.8425 - val_accuracy: 0.7607\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2813 - accuracy: 0.8667 - val_loss: 0.8427 - val_accuracy: 0.7521\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2808 - accuracy: 0.8481 - val_loss: 0.8236 - val_accuracy: 0.7692\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2817 - accuracy: 0.8593 - val_loss: 0.8184 - val_accuracy: 0.7607\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2868 - accuracy: 0.8556 - val_loss: 0.8418 - val_accuracy: 0.7521\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2810 - accuracy: 0.8667 - val_loss: 0.8625 - val_accuracy: 0.7607\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2818 - accuracy: 0.8741 - val_loss: 0.8700 - val_accuracy: 0.7521\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2835 - accuracy: 0.8630 - val_loss: 0.8246 - val_accuracy: 0.7607\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.2845 - accuracy: 0.8704 - val_loss: 0.8224 - val_accuracy: 0.7436\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2902 - accuracy: 0.8667 - val_loss: 0.8401 - val_accuracy: 0.7692\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2889 - accuracy: 0.8556 - val_loss: 0.8626 - val_accuracy: 0.7436\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2858 - accuracy: 0.8481 - val_loss: 0.8440 - val_accuracy: 0.7607\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2809 - accuracy: 0.8667 - val_loss: 0.8301 - val_accuracy: 0.7607\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2790 - accuracy: 0.8630 - val_loss: 0.8229 - val_accuracy: 0.7607\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2805 - accuracy: 0.8593 - val_loss: 0.8231 - val_accuracy: 0.7521\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2851 - accuracy: 0.8481 - val_loss: 0.8383 - val_accuracy: 0.7607\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2798 - accuracy: 0.8630 - val_loss: 0.8646 - val_accuracy: 0.7607\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2794 - accuracy: 0.8667 - val_loss: 0.8669 - val_accuracy: 0.7607\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2798 - accuracy: 0.8667 - val_loss: 0.8498 - val_accuracy: 0.7607\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2779 - accuracy: 0.8593 - val_loss: 0.8401 - val_accuracy: 0.7607\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2774 - accuracy: 0.8667 - val_loss: 0.8379 - val_accuracy: 0.7607\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2748 - accuracy: 0.8667 - val_loss: 0.8361 - val_accuracy: 0.7607\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2777 - accuracy: 0.8667 - val_loss: 0.8422 - val_accuracy: 0.7692\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2783 - accuracy: 0.8630 - val_loss: 0.8531 - val_accuracy: 0.7607\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2769 - accuracy: 0.8667 - val_loss: 0.8734 - val_accuracy: 0.7521\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2803 - accuracy: 0.8667 - val_loss: 0.8457 - val_accuracy: 0.7607\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2827 - accuracy: 0.8630 - val_loss: 0.8157 - val_accuracy: 0.7692\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2838 - accuracy: 0.8556 - val_loss: 0.8627 - val_accuracy: 0.7607\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2794 - accuracy: 0.8667 - val_loss: 0.8927 - val_accuracy: 0.7607\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2834 - accuracy: 0.8667 - val_loss: 0.8646 - val_accuracy: 0.7607\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2753 - accuracy: 0.8667 - val_loss: 0.8467 - val_accuracy: 0.7607\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2776 - accuracy: 0.8667 - val_loss: 0.8390 - val_accuracy: 0.7607\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2795 - accuracy: 0.8630 - val_loss: 0.8467 - val_accuracy: 0.7607\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2760 - accuracy: 0.8667 - val_loss: 0.8729 - val_accuracy: 0.7607\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2769 - accuracy: 0.8704 - val_loss: 0.8713 - val_accuracy: 0.7607\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2809 - accuracy: 0.8630 - val_loss: 0.8554 - val_accuracy: 0.7692\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2765 - accuracy: 0.8630 - val_loss: 0.8603 - val_accuracy: 0.7521\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2791 - accuracy: 0.8519 - val_loss: 0.8811 - val_accuracy: 0.7350\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2877 - accuracy: 0.8630 - val_loss: 0.8436 - val_accuracy: 0.7607\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2786 - accuracy: 0.8667 - val_loss: 0.8607 - val_accuracy: 0.7607\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2769 - accuracy: 0.8630 - val_loss: 0.8668 - val_accuracy: 0.7607\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2783 - accuracy: 0.8667 - val_loss: 0.8492 - val_accuracy: 0.7607\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2775 - accuracy: 0.8667 - val_loss: 0.8487 - val_accuracy: 0.7607\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2832 - accuracy: 0.8593 - val_loss: 0.8703 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2794 - accuracy: 0.8556 - val_loss: 0.8411 - val_accuracy: 0.7607\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2727 - accuracy: 0.8630 - val_loss: 0.8359 - val_accuracy: 0.7778\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2808 - accuracy: 0.8667 - val_loss: 0.8487 - val_accuracy: 0.7692\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2775 - accuracy: 0.8481 - val_loss: 0.8854 - val_accuracy: 0.7521\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2876 - accuracy: 0.8556 - val_loss: 0.9019 - val_accuracy: 0.7521\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2790 - accuracy: 0.8593 - val_loss: 0.8794 - val_accuracy: 0.7607\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2858 - accuracy: 0.8593 - val_loss: 0.8522 - val_accuracy: 0.7692\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2803 - accuracy: 0.8630 - val_loss: 0.8504 - val_accuracy: 0.7521\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2743 - accuracy: 0.8667 - val_loss: 0.8664 - val_accuracy: 0.7521\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2795 - accuracy: 0.8667 - val_loss: 0.8746 - val_accuracy: 0.7521\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2802 - accuracy: 0.8630 - val_loss: 0.8588 - val_accuracy: 0.7607\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2781 - accuracy: 0.8593 - val_loss: 0.8613 - val_accuracy: 0.7521\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2752 - accuracy: 0.8667 - val_loss: 0.8476 - val_accuracy: 0.7607\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2894 - accuracy: 0.8593 - val_loss: 0.8500 - val_accuracy: 0.7692\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2782 - accuracy: 0.8667 - val_loss: 0.8793 - val_accuracy: 0.7521\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2820 - accuracy: 0.8444 - val_loss: 0.8891 - val_accuracy: 0.7350\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2812 - accuracy: 0.8444 - val_loss: 0.8434 - val_accuracy: 0.7778\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2792 - accuracy: 0.8593 - val_loss: 0.8427 - val_accuracy: 0.7692\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2737 - accuracy: 0.8667 - val_loss: 0.8796 - val_accuracy: 0.7521\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2755 - accuracy: 0.8667 - val_loss: 0.8778 - val_accuracy: 0.7521\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2718 - accuracy: 0.8667 - val_loss: 0.8794 - val_accuracy: 0.7692\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2817 - accuracy: 0.8667 - val_loss: 0.8696 - val_accuracy: 0.7692\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2779 - accuracy: 0.8556 - val_loss: 0.8770 - val_accuracy: 0.7521\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2792 - accuracy: 0.8667 - val_loss: 0.8760 - val_accuracy: 0.7521\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2748 - accuracy: 0.8593 - val_loss: 0.8720 - val_accuracy: 0.7607\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2762 - accuracy: 0.8593 - val_loss: 0.8440 - val_accuracy: 0.7778\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2748 - accuracy: 0.8630 - val_loss: 0.8290 - val_accuracy: 0.7692\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2793 - accuracy: 0.8667 - val_loss: 0.8475 - val_accuracy: 0.7607\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2807 - accuracy: 0.8630 - val_loss: 0.8789 - val_accuracy: 0.7521\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2758 - accuracy: 0.8407 - val_loss: 0.9027 - val_accuracy: 0.7436\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2764 - accuracy: 0.8667 - val_loss: 0.8820 - val_accuracy: 0.7778\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2819 - accuracy: 0.8630 - val_loss: 0.8538 - val_accuracy: 0.7778\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2797 - accuracy: 0.8593 - val_loss: 0.8551 - val_accuracy: 0.7607\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2759 - accuracy: 0.8630 - val_loss: 0.8651 - val_accuracy: 0.7521\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2750 - accuracy: 0.8593 - val_loss: 0.8732 - val_accuracy: 0.7521\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2760 - accuracy: 0.8519 - val_loss: 0.8812 - val_accuracy: 0.7607\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2741 - accuracy: 0.8519 - val_loss: 0.8977 - val_accuracy: 0.7521\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2734 - accuracy: 0.8519 - val_loss: 0.8777 - val_accuracy: 0.7607\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2745 - accuracy: 0.8667 - val_loss: 0.8659 - val_accuracy: 0.7778\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2731 - accuracy: 0.8593 - val_loss: 0.8644 - val_accuracy: 0.7607\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2719 - accuracy: 0.8630 - val_loss: 0.8823 - val_accuracy: 0.7521\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2799 - accuracy: 0.8630 - val_loss: 0.9242 - val_accuracy: 0.7350\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2775 - accuracy: 0.8519 - val_loss: 0.9104 - val_accuracy: 0.7607\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2794 - accuracy: 0.8667 - val_loss: 0.8704 - val_accuracy: 0.7692\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2774 - accuracy: 0.8667 - val_loss: 0.8568 - val_accuracy: 0.7607\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2720 - accuracy: 0.8630 - val_loss: 0.8705 - val_accuracy: 0.7607\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2704 - accuracy: 0.8630 - val_loss: 0.8915 - val_accuracy: 0.7521\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2730 - accuracy: 0.8556 - val_loss: 0.9187 - val_accuracy: 0.7521\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2794 - accuracy: 0.8704 - val_loss: 0.9004 - val_accuracy: 0.7607\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2751 - accuracy: 0.8667 - val_loss: 0.8921 - val_accuracy: 0.7607\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2695 - accuracy: 0.8667 - val_loss: 0.8736 - val_accuracy: 0.7607\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2756 - accuracy: 0.8630 - val_loss: 0.8699 - val_accuracy: 0.7607\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2744 - accuracy: 0.8593 - val_loss: 0.8824 - val_accuracy: 0.7607\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2785 - accuracy: 0.8481 - val_loss: 0.9112 - val_accuracy: 0.7350\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2746 - accuracy: 0.8519 - val_loss: 0.8754 - val_accuracy: 0.7607\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2722 - accuracy: 0.8630 - val_loss: 0.8644 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2715 - accuracy: 0.8630 - val_loss: 0.8777 - val_accuracy: 0.7521\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2697 - accuracy: 0.8630 - val_loss: 0.8828 - val_accuracy: 0.7607\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2725 - accuracy: 0.8667 - val_loss: 0.9109 - val_accuracy: 0.7607\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2752 - accuracy: 0.8667 - val_loss: 0.9140 - val_accuracy: 0.7607\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2718 - accuracy: 0.8667 - val_loss: 0.9035 - val_accuracy: 0.7607\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.8922 - val_accuracy: 0.7607\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2669 - accuracy: 0.8593 - val_loss: 0.8729 - val_accuracy: 0.7521\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2720 - accuracy: 0.8630 - val_loss: 0.8660 - val_accuracy: 0.7607\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2728 - accuracy: 0.8630 - val_loss: 0.8756 - val_accuracy: 0.7607\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2712 - accuracy: 0.8593 - val_loss: 0.9008 - val_accuracy: 0.7521\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2697 - accuracy: 0.8667 - val_loss: 0.9004 - val_accuracy: 0.7521\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2773 - accuracy: 0.8370 - val_loss: 0.9060 - val_accuracy: 0.7350\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2720 - accuracy: 0.8630 - val_loss: 0.8762 - val_accuracy: 0.7607\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2747 - accuracy: 0.8630 - val_loss: 0.8919 - val_accuracy: 0.7692\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2748 - accuracy: 0.8556 - val_loss: 0.9070 - val_accuracy: 0.7350\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2740 - accuracy: 0.8556 - val_loss: 0.8965 - val_accuracy: 0.7607\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2724 - accuracy: 0.8630 - val_loss: 0.8874 - val_accuracy: 0.7607\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2720 - accuracy: 0.8593 - val_loss: 0.8937 - val_accuracy: 0.7521\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2687 - accuracy: 0.8667 - val_loss: 0.9003 - val_accuracy: 0.7521\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2701 - accuracy: 0.8667 - val_loss: 0.9127 - val_accuracy: 0.7521\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2714 - accuracy: 0.8667 - val_loss: 0.9048 - val_accuracy: 0.7521\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2688 - accuracy: 0.8630 - val_loss: 0.9073 - val_accuracy: 0.7521\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2738 - accuracy: 0.8630 - val_loss: 0.9092 - val_accuracy: 0.7521\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 38us/step - loss: 0.2701 - accuracy: 0.8593 - val_loss: 0.9010 - val_accuracy: 0.7692\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2696 - accuracy: 0.8667 - val_loss: 0.9067 - val_accuracy: 0.7607\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2699 - accuracy: 0.8667 - val_loss: 0.8966 - val_accuracy: 0.7521\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 0.8993 - val_accuracy: 0.7521\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2689 - accuracy: 0.8630 - val_loss: 0.8902 - val_accuracy: 0.7692\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2688 - accuracy: 0.8704 - val_loss: 0.8968 - val_accuracy: 0.7607\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2724 - accuracy: 0.8630 - val_loss: 0.9079 - val_accuracy: 0.7521\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2728 - accuracy: 0.8667 - val_loss: 0.8933 - val_accuracy: 0.7607\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2728 - accuracy: 0.8630 - val_loss: 0.8960 - val_accuracy: 0.7692\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2713 - accuracy: 0.8667 - val_loss: 0.8940 - val_accuracy: 0.7692\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2780 - accuracy: 0.8556 - val_loss: 0.8969 - val_accuracy: 0.7521\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2743 - accuracy: 0.8593 - val_loss: 0.8623 - val_accuracy: 0.7692\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2770 - accuracy: 0.8704 - val_loss: 0.8798 - val_accuracy: 0.7607\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2761 - accuracy: 0.8667 - val_loss: 0.9267 - val_accuracy: 0.7521\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2729 - accuracy: 0.8667 - val_loss: 0.9161 - val_accuracy: 0.7521\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2703 - accuracy: 0.8667 - val_loss: 0.9002 - val_accuracy: 0.7521\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 0.9049 - val_accuracy: 0.7521\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2693 - accuracy: 0.8667 - val_loss: 0.9102 - val_accuracy: 0.7521\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2674 - accuracy: 0.8593 - val_loss: 0.8997 - val_accuracy: 0.7692\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2705 - accuracy: 0.8667 - val_loss: 0.9132 - val_accuracy: 0.7607\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2741 - accuracy: 0.8667 - val_loss: 0.9205 - val_accuracy: 0.7521\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2728 - accuracy: 0.8667 - val_loss: 0.9149 - val_accuracy: 0.7521\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2712 - accuracy: 0.8630 - val_loss: 0.9032 - val_accuracy: 0.7692\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.8990 - val_accuracy: 0.7692\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2702 - accuracy: 0.8667 - val_loss: 0.8936 - val_accuracy: 0.7607\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2675 - accuracy: 0.8519 - val_loss: 0.9227 - val_accuracy: 0.7350\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2741 - accuracy: 0.8481 - val_loss: 0.9083 - val_accuracy: 0.7350\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2711 - accuracy: 0.8407 - val_loss: 0.8966 - val_accuracy: 0.7778\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2688 - accuracy: 0.8630 - val_loss: 0.9019 - val_accuracy: 0.7778\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2698 - accuracy: 0.8630 - val_loss: 0.9006 - val_accuracy: 0.7692\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2683 - accuracy: 0.8667 - val_loss: 0.9098 - val_accuracy: 0.7607\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2723 - accuracy: 0.8667 - val_loss: 0.8926 - val_accuracy: 0.7692\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2703 - accuracy: 0.8630 - val_loss: 0.8809 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2688 - accuracy: 0.8667 - val_loss: 0.8874 - val_accuracy: 0.7778\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2687 - accuracy: 0.8593 - val_loss: 0.9196 - val_accuracy: 0.7607\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2724 - accuracy: 0.8370 - val_loss: 0.9249 - val_accuracy: 0.7521\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2749 - accuracy: 0.8667 - val_loss: 0.9262 - val_accuracy: 0.7521\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2718 - accuracy: 0.8741 - val_loss: 0.8916 - val_accuracy: 0.7521\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2827 - accuracy: 0.8593 - val_loss: 0.8877 - val_accuracy: 0.7607\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2752 - accuracy: 0.8593 - val_loss: 0.9269 - val_accuracy: 0.7521\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2753 - accuracy: 0.8667 - val_loss: 0.9247 - val_accuracy: 0.7521\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2693 - accuracy: 0.8667 - val_loss: 0.8930 - val_accuracy: 0.7521\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2674 - accuracy: 0.8667 - val_loss: 0.8818 - val_accuracy: 0.7607\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2792 - accuracy: 0.8667 - val_loss: 0.8936 - val_accuracy: 0.7607\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.8920 - val_accuracy: 0.7607\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2697 - accuracy: 0.8667 - val_loss: 0.9144 - val_accuracy: 0.7607\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2727 - accuracy: 0.8667 - val_loss: 0.9244 - val_accuracy: 0.7521\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2718 - accuracy: 0.8630 - val_loss: 0.8999 - val_accuracy: 0.7521\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2697 - accuracy: 0.8556 - val_loss: 0.8956 - val_accuracy: 0.7521\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2722 - accuracy: 0.8556 - val_loss: 0.9135 - val_accuracy: 0.7521\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2682 - accuracy: 0.8667 - val_loss: 0.8911 - val_accuracy: 0.7692\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2702 - accuracy: 0.8593 - val_loss: 0.9075 - val_accuracy: 0.7778\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2674 - accuracy: 0.8667 - val_loss: 0.9278 - val_accuracy: 0.7350\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2708 - accuracy: 0.8593 - val_loss: 0.9276 - val_accuracy: 0.7521\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2685 - accuracy: 0.8593 - val_loss: 0.8968 - val_accuracy: 0.7607\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2694 - accuracy: 0.8667 - val_loss: 0.8995 - val_accuracy: 0.7607\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2690 - accuracy: 0.8630 - val_loss: 0.9251 - val_accuracy: 0.7521\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2696 - accuracy: 0.8667 - val_loss: 0.9379 - val_accuracy: 0.7607\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2733 - accuracy: 0.8667 - val_loss: 0.9273 - val_accuracy: 0.7607\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2690 - accuracy: 0.8667 - val_loss: 0.9035 - val_accuracy: 0.7692\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2687 - accuracy: 0.8667 - val_loss: 0.8933 - val_accuracy: 0.7607\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2685 - accuracy: 0.8667 - val_loss: 0.9091 - val_accuracy: 0.7607\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2696 - accuracy: 0.8667 - val_loss: 0.9330 - val_accuracy: 0.7521\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2716 - accuracy: 0.8704 - val_loss: 0.9291 - val_accuracy: 0.7692\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2665 - accuracy: 0.8667 - val_loss: 0.9013 - val_accuracy: 0.7778\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2660 - accuracy: 0.8704 - val_loss: 0.9111 - val_accuracy: 0.7778\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2669 - accuracy: 0.8630 - val_loss: 0.9286 - val_accuracy: 0.7692\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2687 - accuracy: 0.8667 - val_loss: 0.9297 - val_accuracy: 0.7521\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2690 - accuracy: 0.8556 - val_loss: 0.9206 - val_accuracy: 0.7521\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2708 - accuracy: 0.8667 - val_loss: 0.8879 - val_accuracy: 0.7607\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2671 - accuracy: 0.8778 - val_loss: 0.8806 - val_accuracy: 0.7607\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2707 - accuracy: 0.8667 - val_loss: 0.8924 - val_accuracy: 0.7521\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2726 - accuracy: 0.8667 - val_loss: 0.9254 - val_accuracy: 0.7521\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2724 - accuracy: 0.8667 - val_loss: 0.9117 - val_accuracy: 0.7521\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2715 - accuracy: 0.8593 - val_loss: 0.8986 - val_accuracy: 0.7692\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2671 - accuracy: 0.8630 - val_loss: 0.9338 - val_accuracy: 0.7692\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2691 - accuracy: 0.8667 - val_loss: 0.9660 - val_accuracy: 0.7521\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2767 - accuracy: 0.8519 - val_loss: 0.9479 - val_accuracy: 0.7692\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.9228 - val_accuracy: 0.7778\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2785 - accuracy: 0.8630 - val_loss: 0.9302 - val_accuracy: 0.7692\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2744 - accuracy: 0.8556 - val_loss: 0.9496 - val_accuracy: 0.7521\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2803 - accuracy: 0.8667 - val_loss: 0.9003 - val_accuracy: 0.7607\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 0.8986 - val_accuracy: 0.7607\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2692 - accuracy: 0.8704 - val_loss: 0.8932 - val_accuracy: 0.7607\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2707 - accuracy: 0.8593 - val_loss: 0.9144 - val_accuracy: 0.7521\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2688 - accuracy: 0.8667 - val_loss: 0.9110 - val_accuracy: 0.7607\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2668 - accuracy: 0.8630 - val_loss: 0.9011 - val_accuracy: 0.7607\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2672 - accuracy: 0.8630 - val_loss: 0.8917 - val_accuracy: 0.7692\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2702 - accuracy: 0.8593 - val_loss: 0.9014 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2670 - accuracy: 0.8630 - val_loss: 0.9325 - val_accuracy: 0.7607\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2686 - accuracy: 0.8704 - val_loss: 0.9372 - val_accuracy: 0.7692\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2703 - accuracy: 0.8667 - val_loss: 0.9321 - val_accuracy: 0.7607\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2708 - accuracy: 0.8481 - val_loss: 0.9214 - val_accuracy: 0.7607\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.8916 - val_accuracy: 0.7692\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2714 - accuracy: 0.8630 - val_loss: 0.8885 - val_accuracy: 0.7692\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2697 - accuracy: 0.8630 - val_loss: 0.9187 - val_accuracy: 0.7778\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2734 - accuracy: 0.8593 - val_loss: 0.9286 - val_accuracy: 0.7692\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2743 - accuracy: 0.8370 - val_loss: 0.9245 - val_accuracy: 0.7607\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.9118 - val_accuracy: 0.7607\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 0.9205 - val_accuracy: 0.7607\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 0.9281 - val_accuracy: 0.7692\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2648 - accuracy: 0.8593 - val_loss: 0.9211 - val_accuracy: 0.7692\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.9068 - val_accuracy: 0.7692\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2652 - accuracy: 0.8667 - val_loss: 0.9074 - val_accuracy: 0.7607\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 0.9238 - val_accuracy: 0.7607\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2660 - accuracy: 0.8667 - val_loss: 0.9148 - val_accuracy: 0.7692\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9261 - val_accuracy: 0.7692\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2656 - accuracy: 0.8667 - val_loss: 0.9514 - val_accuracy: 0.7607\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2687 - accuracy: 0.8481 - val_loss: 0.9338 - val_accuracy: 0.7692\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2702 - accuracy: 0.8704 - val_loss: 0.9244 - val_accuracy: 0.7692\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2660 - accuracy: 0.8778 - val_loss: 0.8957 - val_accuracy: 0.7692\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2683 - accuracy: 0.8667 - val_loss: 0.8982 - val_accuracy: 0.7692\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 0.9149 - val_accuracy: 0.7692\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2711 - accuracy: 0.8630 - val_loss: 0.9274 - val_accuracy: 0.7607\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2696 - accuracy: 0.8630 - val_loss: 0.9036 - val_accuracy: 0.7778\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2678 - accuracy: 0.8630 - val_loss: 0.9262 - val_accuracy: 0.7778\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2642 - accuracy: 0.8815 - val_loss: 0.9601 - val_accuracy: 0.7521\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2705 - accuracy: 0.8667 - val_loss: 0.9383 - val_accuracy: 0.7607\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2674 - accuracy: 0.8630 - val_loss: 0.8987 - val_accuracy: 0.7778\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2732 - accuracy: 0.8556 - val_loss: 0.9015 - val_accuracy: 0.7778\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 0.9449 - val_accuracy: 0.7521\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2672 - accuracy: 0.8667 - val_loss: 0.9622 - val_accuracy: 0.7521\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2691 - accuracy: 0.8667 - val_loss: 0.9306 - val_accuracy: 0.7607\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2728 - accuracy: 0.8519 - val_loss: 0.9041 - val_accuracy: 0.7778\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2779 - accuracy: 0.8630 - val_loss: 0.9232 - val_accuracy: 0.7778\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2689 - accuracy: 0.8593 - val_loss: 0.9440 - val_accuracy: 0.7607\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2671 - accuracy: 0.8481 - val_loss: 0.9376 - val_accuracy: 0.7692\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2653 - accuracy: 0.8704 - val_loss: 0.9560 - val_accuracy: 0.7607\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.9876 - val_accuracy: 0.7350\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2699 - accuracy: 0.8444 - val_loss: 0.9531 - val_accuracy: 0.7521\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.9199 - val_accuracy: 0.7607\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 0.9084 - val_accuracy: 0.7692\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2682 - accuracy: 0.8630 - val_loss: 0.9281 - val_accuracy: 0.7607\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2682 - accuracy: 0.8593 - val_loss: 0.9867 - val_accuracy: 0.7436\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2777 - accuracy: 0.8630 - val_loss: 0.9297 - val_accuracy: 0.7778\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2688 - accuracy: 0.8630 - val_loss: 0.8934 - val_accuracy: 0.7778\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2679 - accuracy: 0.8556 - val_loss: 0.9110 - val_accuracy: 0.7607\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2737 - accuracy: 0.8630 - val_loss: 0.9114 - val_accuracy: 0.7607\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.8883 - val_accuracy: 0.7778\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2676 - accuracy: 0.8630 - val_loss: 0.9165 - val_accuracy: 0.7778\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2657 - accuracy: 0.8630 - val_loss: 0.9565 - val_accuracy: 0.7607\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.2723 - accuracy: 0.8593 - val_loss: 0.9607 - val_accuracy: 0.7521\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2670 - accuracy: 0.8556 - val_loss: 0.9076 - val_accuracy: 0.7607\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2657 - accuracy: 0.8667 - val_loss: 0.8915 - val_accuracy: 0.7607\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2695 - accuracy: 0.8630 - val_loss: 0.9071 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2704 - accuracy: 0.8481 - val_loss: 0.9771 - val_accuracy: 0.7350\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2743 - accuracy: 0.8519 - val_loss: 0.9413 - val_accuracy: 0.7521\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.9163 - val_accuracy: 0.7607\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 0.9152 - val_accuracy: 0.7607\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2660 - accuracy: 0.8519 - val_loss: 0.9233 - val_accuracy: 0.7607\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.9300 - val_accuracy: 0.7607\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9359 - val_accuracy: 0.7607\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2657 - accuracy: 0.8630 - val_loss: 0.9399 - val_accuracy: 0.7607\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2657 - accuracy: 0.8667 - val_loss: 0.9097 - val_accuracy: 0.7607\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2704 - accuracy: 0.8630 - val_loss: 0.9078 - val_accuracy: 0.7692\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2675 - accuracy: 0.8593 - val_loss: 0.9204 - val_accuracy: 0.7607\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2688 - accuracy: 0.8667 - val_loss: 0.9471 - val_accuracy: 0.7692\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2722 - accuracy: 0.8630 - val_loss: 0.9256 - val_accuracy: 0.7607\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2642 - accuracy: 0.8593 - val_loss: 0.9240 - val_accuracy: 0.7692\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2652 - accuracy: 0.8630 - val_loss: 0.9368 - val_accuracy: 0.7692\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2662 - accuracy: 0.8667 - val_loss: 0.9274 - val_accuracy: 0.7607\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9290 - val_accuracy: 0.7607\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2667 - accuracy: 0.8630 - val_loss: 0.9278 - val_accuracy: 0.7607\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2682 - accuracy: 0.8630 - val_loss: 0.9247 - val_accuracy: 0.7607\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2676 - accuracy: 0.8519 - val_loss: 0.9122 - val_accuracy: 0.7778\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.9343 - val_accuracy: 0.7607\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.9467 - val_accuracy: 0.7607\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2659 - accuracy: 0.8556 - val_loss: 0.9368 - val_accuracy: 0.7607\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 40us/step - loss: 0.2664 - accuracy: 0.8667 - val_loss: 0.9327 - val_accuracy: 0.7692\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 37us/step - loss: 0.2677 - accuracy: 0.8556 - val_loss: 0.9074 - val_accuracy: 0.7607\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.2656 - accuracy: 0.8667 - val_loss: 0.8953 - val_accuracy: 0.7692\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2861 - accuracy: 0.8593 - val_loss: 0.9147 - val_accuracy: 0.7692\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2693 - accuracy: 0.8593 - val_loss: 0.9835 - val_accuracy: 0.7436\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2765 - accuracy: 0.8481 - val_loss: 0.9905 - val_accuracy: 0.7607\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2727 - accuracy: 0.8630 - val_loss: 0.9637 - val_accuracy: 0.7607\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2661 - accuracy: 0.8704 - val_loss: 0.9539 - val_accuracy: 0.7692\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.9482 - val_accuracy: 0.7692\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.9443 - val_accuracy: 0.7692\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2672 - accuracy: 0.8704 - val_loss: 0.9522 - val_accuracy: 0.7607\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2703 - accuracy: 0.8481 - val_loss: 0.9697 - val_accuracy: 0.7436\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2688 - accuracy: 0.8481 - val_loss: 0.9630 - val_accuracy: 0.7692\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 0.9639 - val_accuracy: 0.7607\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2729 - accuracy: 0.8630 - val_loss: 0.9434 - val_accuracy: 0.7607\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2716 - accuracy: 0.8593 - val_loss: 0.9395 - val_accuracy: 0.7692\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2671 - accuracy: 0.8593 - val_loss: 0.9643 - val_accuracy: 0.7607\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2697 - accuracy: 0.8667 - val_loss: 0.9484 - val_accuracy: 0.7692\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2663 - accuracy: 0.8630 - val_loss: 0.9378 - val_accuracy: 0.7607\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 0.9430 - val_accuracy: 0.7607\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.9618 - val_accuracy: 0.7607\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2689 - accuracy: 0.8667 - val_loss: 0.9653 - val_accuracy: 0.7607\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.9337 - val_accuracy: 0.7692\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2683 - accuracy: 0.8630 - val_loss: 0.9299 - val_accuracy: 0.7607\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2707 - accuracy: 0.8519 - val_loss: 0.9392 - val_accuracy: 0.7692\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 0.9689 - val_accuracy: 0.7607\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2667 - accuracy: 0.8630 - val_loss: 0.9555 - val_accuracy: 0.7607\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2657 - accuracy: 0.8630 - val_loss: 0.9616 - val_accuracy: 0.7607\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2685 - accuracy: 0.8556 - val_loss: 0.9567 - val_accuracy: 0.7692\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2681 - accuracy: 0.8444 - val_loss: 0.9617 - val_accuracy: 0.7607\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.9462 - val_accuracy: 0.7607\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 0.9325 - val_accuracy: 0.7607\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2722 - accuracy: 0.8593 - val_loss: 0.9397 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.9688 - val_accuracy: 0.7607\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2667 - accuracy: 0.8556 - val_loss: 1.0024 - val_accuracy: 0.7350\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2706 - accuracy: 0.8481 - val_loss: 0.9608 - val_accuracy: 0.7607\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2655 - accuracy: 0.8556 - val_loss: 0.9368 - val_accuracy: 0.7607\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2673 - accuracy: 0.8481 - val_loss: 0.9505 - val_accuracy: 0.7607\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.9608 - val_accuracy: 0.7607\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.9696 - val_accuracy: 0.7607\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 0.9669 - val_accuracy: 0.7607\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.9636 - val_accuracy: 0.7607\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.9413 - val_accuracy: 0.7607\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2635 - accuracy: 0.8667 - val_loss: 0.9517 - val_accuracy: 0.7607\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2676 - accuracy: 0.8556 - val_loss: 0.9443 - val_accuracy: 0.7692\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2673 - accuracy: 0.8630 - val_loss: 0.9528 - val_accuracy: 0.7607\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2647 - accuracy: 0.8593 - val_loss: 0.9494 - val_accuracy: 0.7607\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2667 - accuracy: 0.8630 - val_loss: 0.9443 - val_accuracy: 0.7692\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2658 - accuracy: 0.8630 - val_loss: 0.9474 - val_accuracy: 0.7692\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.9655 - val_accuracy: 0.7692\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9732 - val_accuracy: 0.7692\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 0.9786 - val_accuracy: 0.7692\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 0.9706 - val_accuracy: 0.7607\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2646 - accuracy: 0.8778 - val_loss: 0.9557 - val_accuracy: 0.7692\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 0.9304 - val_accuracy: 0.7607\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2663 - accuracy: 0.8630 - val_loss: 0.9392 - val_accuracy: 0.7692\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2682 - accuracy: 0.8630 - val_loss: 0.9707 - val_accuracy: 0.7607\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2710 - accuracy: 0.8444 - val_loss: 1.0029 - val_accuracy: 0.7436\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2692 - accuracy: 0.8481 - val_loss: 0.9503 - val_accuracy: 0.7607\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2738 - accuracy: 0.8481 - val_loss: 0.9236 - val_accuracy: 0.7692\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2668 - accuracy: 0.8593 - val_loss: 0.9396 - val_accuracy: 0.7692\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2650 - accuracy: 0.8519 - val_loss: 0.9658 - val_accuracy: 0.7350\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2668 - accuracy: 0.8556 - val_loss: 0.9613 - val_accuracy: 0.7607\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2675 - accuracy: 0.8741 - val_loss: 0.9592 - val_accuracy: 0.7607\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2673 - accuracy: 0.8667 - val_loss: 0.9568 - val_accuracy: 0.7607\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.9540 - val_accuracy: 0.7692\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2720 - accuracy: 0.8593 - val_loss: 0.9595 - val_accuracy: 0.7692\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2702 - accuracy: 0.8593 - val_loss: 0.9893 - val_accuracy: 0.7692\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2747 - accuracy: 0.8704 - val_loss: 0.9908 - val_accuracy: 0.7607\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2667 - accuracy: 0.8704 - val_loss: 0.9644 - val_accuracy: 0.7692\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2739 - accuracy: 0.8667 - val_loss: 0.9515 - val_accuracy: 0.7692\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.9563 - val_accuracy: 0.7607\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.9569 - val_accuracy: 0.7607\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2636 - accuracy: 0.8667 - val_loss: 0.9373 - val_accuracy: 0.7607\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 156us/step - loss: 0.2662 - accuracy: 0.8556 - val_loss: 0.9249 - val_accuracy: 0.7778\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.9507 - val_accuracy: 0.7692\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 0.9796 - val_accuracy: 0.7607\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2717 - accuracy: 0.8667 - val_loss: 0.9682 - val_accuracy: 0.7607\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2616 - accuracy: 0.8815 - val_loss: 0.9364 - val_accuracy: 0.7778\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2772 - accuracy: 0.8593 - val_loss: 0.9518 - val_accuracy: 0.7778\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2684 - accuracy: 0.8630 - val_loss: 0.9744 - val_accuracy: 0.7692\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.9693 - val_accuracy: 0.7692\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2672 - accuracy: 0.8630 - val_loss: 0.9498 - val_accuracy: 0.7607\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2718 - accuracy: 0.8481 - val_loss: 0.9441 - val_accuracy: 0.7692\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2671 - accuracy: 0.8593 - val_loss: 0.9518 - val_accuracy: 0.7692\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2676 - accuracy: 0.8630 - val_loss: 0.9672 - val_accuracy: 0.7778\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2645 - accuracy: 0.8556 - val_loss: 0.9770 - val_accuracy: 0.7692\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2634 - accuracy: 0.8704 - val_loss: 0.9673 - val_accuracy: 0.7692\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.9568 - val_accuracy: 0.7607\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2671 - accuracy: 0.8556 - val_loss: 0.9682 - val_accuracy: 0.7692\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9531 - val_accuracy: 0.7778\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 0.9461 - val_accuracy: 0.7692\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.9533 - val_accuracy: 0.7692\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2644 - accuracy: 0.8704 - val_loss: 0.9924 - val_accuracy: 0.7607\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2709 - accuracy: 0.8407 - val_loss: 0.9753 - val_accuracy: 0.7692\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2672 - accuracy: 0.8370 - val_loss: 0.9496 - val_accuracy: 0.7778\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2652 - accuracy: 0.8556 - val_loss: 0.9458 - val_accuracy: 0.7692\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2704 - accuracy: 0.8593 - val_loss: 0.9454 - val_accuracy: 0.7778\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2689 - accuracy: 0.8593 - val_loss: 0.9334 - val_accuracy: 0.7692\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.9546 - val_accuracy: 0.7607\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2690 - accuracy: 0.8667 - val_loss: 0.9741 - val_accuracy: 0.7607\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.9545 - val_accuracy: 0.7692\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2652 - accuracy: 0.8815 - val_loss: 0.9698 - val_accuracy: 0.7692\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.9826 - val_accuracy: 0.7607\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2701 - accuracy: 0.8407 - val_loss: 0.9955 - val_accuracy: 0.7436\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2669 - accuracy: 0.8556 - val_loss: 0.9489 - val_accuracy: 0.7607\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.9288 - val_accuracy: 0.7692\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2674 - accuracy: 0.8630 - val_loss: 0.9328 - val_accuracy: 0.7692\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 0.9564 - val_accuracy: 0.7607\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.9826 - val_accuracy: 0.7607\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2680 - accuracy: 0.8667 - val_loss: 0.9852 - val_accuracy: 0.7607\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2717 - accuracy: 0.8630 - val_loss: 0.9613 - val_accuracy: 0.7692\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2642 - accuracy: 0.8630 - val_loss: 0.9701 - val_accuracy: 0.7607\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.9778 - val_accuracy: 0.7607\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2690 - accuracy: 0.8667 - val_loss: 0.9623 - val_accuracy: 0.7692\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 0.9888 - val_accuracy: 0.7607\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2665 - accuracy: 0.8630 - val_loss: 1.0300 - val_accuracy: 0.7350\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2697 - accuracy: 0.8370 - val_loss: 0.9965 - val_accuracy: 0.7607\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.9706 - val_accuracy: 0.7778\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2760 - accuracy: 0.8630 - val_loss: 0.9496 - val_accuracy: 0.7778\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2669 - accuracy: 0.8741 - val_loss: 0.9861 - val_accuracy: 0.7607\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2905 - accuracy: 0.8370 - val_loss: 1.0019 - val_accuracy: 0.7436\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2732 - accuracy: 0.8407 - val_loss: 0.9698 - val_accuracy: 0.7692\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2681 - accuracy: 0.8667 - val_loss: 0.9704 - val_accuracy: 0.7778\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2677 - accuracy: 0.8630 - val_loss: 0.9541 - val_accuracy: 0.7692\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2638 - accuracy: 0.8704 - val_loss: 0.9512 - val_accuracy: 0.7607\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 0.9673 - val_accuracy: 0.7607\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 0.9588 - val_accuracy: 0.7692\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2611 - accuracy: 0.8630 - val_loss: 0.9398 - val_accuracy: 0.7607\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 0.9383 - val_accuracy: 0.7607\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2685 - accuracy: 0.8630 - val_loss: 0.9317 - val_accuracy: 0.7692\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2709 - accuracy: 0.8519 - val_loss: 0.9422 - val_accuracy: 0.7607\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 0.9612 - val_accuracy: 0.7607\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2631 - accuracy: 0.8556 - val_loss: 0.9771 - val_accuracy: 0.7607\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2645 - accuracy: 0.8741 - val_loss: 0.9820 - val_accuracy: 0.7607\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2640 - accuracy: 0.8667 - val_loss: 0.9694 - val_accuracy: 0.7692\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.9821 - val_accuracy: 0.7692\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 1.0047 - val_accuracy: 0.7692\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2676 - accuracy: 0.8593 - val_loss: 1.0104 - val_accuracy: 0.7607\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2665 - accuracy: 0.8630 - val_loss: 0.9729 - val_accuracy: 0.7607\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.9527 - val_accuracy: 0.7607\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2651 - accuracy: 0.8593 - val_loss: 0.9516 - val_accuracy: 0.7692\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 0.9915 - val_accuracy: 0.7521\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2705 - accuracy: 0.8407 - val_loss: 0.9823 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2620 - accuracy: 0.8778 - val_loss: 0.9445 - val_accuracy: 0.7778\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.9301 - val_accuracy: 0.7607\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2676 - accuracy: 0.8519 - val_loss: 0.9420 - val_accuracy: 0.7607\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2667 - accuracy: 0.8630 - val_loss: 0.9763 - val_accuracy: 0.7607\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2700 - accuracy: 0.8667 - val_loss: 0.9835 - val_accuracy: 0.7607\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.9722 - val_accuracy: 0.7692\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2677 - accuracy: 0.8667 - val_loss: 0.9846 - val_accuracy: 0.7692\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2606 - accuracy: 0.8704 - val_loss: 1.0160 - val_accuracy: 0.7436\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2729 - accuracy: 0.8481 - val_loss: 1.0018 - val_accuracy: 0.7436\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2671 - accuracy: 0.8778 - val_loss: 0.9458 - val_accuracy: 0.7607\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2760 - accuracy: 0.8593 - val_loss: 0.9364 - val_accuracy: 0.7692\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2765 - accuracy: 0.8704 - val_loss: 0.9645 - val_accuracy: 0.7607\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2708 - accuracy: 0.8630 - val_loss: 0.9745 - val_accuracy: 0.7607\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2656 - accuracy: 0.8556 - val_loss: 0.9772 - val_accuracy: 0.7607\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.9945 - val_accuracy: 0.7692\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 1.0006 - val_accuracy: 0.7692\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2660 - accuracy: 0.8704 - val_loss: 0.9738 - val_accuracy: 0.7607\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2657 - accuracy: 0.8630 - val_loss: 0.9421 - val_accuracy: 0.7607\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2671 - accuracy: 0.8481 - val_loss: 0.9444 - val_accuracy: 0.7692\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2660 - accuracy: 0.8630 - val_loss: 0.9580 - val_accuracy: 0.7778\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2638 - accuracy: 0.8630 - val_loss: 0.9680 - val_accuracy: 0.7692\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2611 - accuracy: 0.8593 - val_loss: 0.9775 - val_accuracy: 0.7607\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 0.9690 - val_accuracy: 0.7607\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2621 - accuracy: 0.8741 - val_loss: 0.9621 - val_accuracy: 0.7607\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2683 - accuracy: 0.8630 - val_loss: 0.9700 - val_accuracy: 0.7692\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2770 - accuracy: 0.8667 - val_loss: 0.9744 - val_accuracy: 0.7692\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2691 - accuracy: 0.8593 - val_loss: 0.9876 - val_accuracy: 0.7692\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2666 - accuracy: 0.8667 - val_loss: 0.9642 - val_accuracy: 0.7607\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.9461 - val_accuracy: 0.7692\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 0.9626 - val_accuracy: 0.7607\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2653 - accuracy: 0.8778 - val_loss: 0.9838 - val_accuracy: 0.7607\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.9862 - val_accuracy: 0.7607\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2646 - accuracy: 0.8667 - val_loss: 0.9816 - val_accuracy: 0.7607\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 0.9651 - val_accuracy: 0.7607\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2636 - accuracy: 0.8593 - val_loss: 0.9383 - val_accuracy: 0.7607\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2656 - accuracy: 0.8556 - val_loss: 0.9676 - val_accuracy: 0.7692\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 0.9673 - val_accuracy: 0.7692\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 0.9680 - val_accuracy: 0.7692\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2690 - accuracy: 0.8593 - val_loss: 0.9674 - val_accuracy: 0.7692\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.9960 - val_accuracy: 0.7607\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2678 - accuracy: 0.8556 - val_loss: 0.9956 - val_accuracy: 0.7607\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2660 - accuracy: 0.8593 - val_loss: 1.0018 - val_accuracy: 0.7607\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2639 - accuracy: 0.8667 - val_loss: 0.9903 - val_accuracy: 0.7607\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2662 - accuracy: 0.8667 - val_loss: 0.9761 - val_accuracy: 0.7607\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2610 - accuracy: 0.8630 - val_loss: 0.9530 - val_accuracy: 0.7607\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2640 - accuracy: 0.8667 - val_loss: 0.9619 - val_accuracy: 0.7607\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.9429 - val_accuracy: 0.7607\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2674 - accuracy: 0.8630 - val_loss: 0.9428 - val_accuracy: 0.7607\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2712 - accuracy: 0.8630 - val_loss: 0.9761 - val_accuracy: 0.7607\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.9745 - val_accuracy: 0.7607\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.9703 - val_accuracy: 0.7607\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2636 - accuracy: 0.8667 - val_loss: 0.9650 - val_accuracy: 0.7607\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.9701 - val_accuracy: 0.7607\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2608 - accuracy: 0.8667 - val_loss: 0.9831 - val_accuracy: 0.7607\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2660 - accuracy: 0.8667 - val_loss: 0.9625 - val_accuracy: 0.7607\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2611 - accuracy: 0.8852 - val_loss: 0.9652 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2703 - accuracy: 0.8630 - val_loss: 0.9773 - val_accuracy: 0.7607\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.9829 - val_accuracy: 0.7692\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2643 - accuracy: 0.8593 - val_loss: 0.9942 - val_accuracy: 0.7607\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2676 - accuracy: 0.8481 - val_loss: 0.9644 - val_accuracy: 0.7778\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2636 - accuracy: 0.8593 - val_loss: 0.9587 - val_accuracy: 0.7607\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 0.9685 - val_accuracy: 0.7607\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.9849 - val_accuracy: 0.7607\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.9903 - val_accuracy: 0.7607\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 1.0000 - val_accuracy: 0.7607\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 1.0083 - val_accuracy: 0.7607\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2676 - accuracy: 0.8667 - val_loss: 1.0052 - val_accuracy: 0.7607\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 0.9819 - val_accuracy: 0.7607\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.9549 - val_accuracy: 0.7778\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2698 - accuracy: 0.8556 - val_loss: 0.9479 - val_accuracy: 0.7692\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2722 - accuracy: 0.8593 - val_loss: 0.9841 - val_accuracy: 0.7692\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2678 - accuracy: 0.8444 - val_loss: 1.0294 - val_accuracy: 0.7607\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.9948 - val_accuracy: 0.7607\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2656 - accuracy: 0.8704 - val_loss: 0.9846 - val_accuracy: 0.7607\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.9921 - val_accuracy: 0.7607\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2661 - accuracy: 0.8556 - val_loss: 1.0149 - val_accuracy: 0.7436\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2654 - accuracy: 0.8481 - val_loss: 0.9963 - val_accuracy: 0.7692\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2670 - accuracy: 0.8741 - val_loss: 0.9681 - val_accuracy: 0.7778\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2659 - accuracy: 0.8630 - val_loss: 0.9536 - val_accuracy: 0.7778\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 0.9693 - val_accuracy: 0.7607\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2684 - accuracy: 0.8630 - val_loss: 0.9916 - val_accuracy: 0.7607\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.9763 - val_accuracy: 0.7778\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.9649 - val_accuracy: 0.7778\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.9626 - val_accuracy: 0.7778\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2626 - accuracy: 0.8556 - val_loss: 0.9912 - val_accuracy: 0.7692\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2659 - accuracy: 0.8593 - val_loss: 1.0051 - val_accuracy: 0.7607\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2670 - accuracy: 0.8630 - val_loss: 0.9799 - val_accuracy: 0.7692\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.9798 - val_accuracy: 0.7692\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 1.0183 - val_accuracy: 0.7692\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2723 - accuracy: 0.8481 - val_loss: 1.0184 - val_accuracy: 0.7521\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2733 - accuracy: 0.8481 - val_loss: 0.9884 - val_accuracy: 0.7436\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2697 - accuracy: 0.8741 - val_loss: 0.9539 - val_accuracy: 0.7607\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2690 - accuracy: 0.8593 - val_loss: 0.9450 - val_accuracy: 0.7607\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2694 - accuracy: 0.8630 - val_loss: 0.9593 - val_accuracy: 0.7692\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2700 - accuracy: 0.8667 - val_loss: 0.9799 - val_accuracy: 0.7692\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2662 - accuracy: 0.8667 - val_loss: 0.9789 - val_accuracy: 0.7778\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2667 - accuracy: 0.8593 - val_loss: 1.0257 - val_accuracy: 0.7436\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2702 - accuracy: 0.8481 - val_loss: 1.0125 - val_accuracy: 0.7692\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2647 - accuracy: 0.8593 - val_loss: 0.9796 - val_accuracy: 0.7692\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.9751 - val_accuracy: 0.7778\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 0.9946 - val_accuracy: 0.7692\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 1.0029 - val_accuracy: 0.7607\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2684 - accuracy: 0.8630 - val_loss: 0.9962 - val_accuracy: 0.7607\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2679 - accuracy: 0.8593 - val_loss: 0.9964 - val_accuracy: 0.7607\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2708 - accuracy: 0.8630 - val_loss: 0.9952 - val_accuracy: 0.7607\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.9693 - val_accuracy: 0.7778\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2697 - accuracy: 0.8519 - val_loss: 0.9582 - val_accuracy: 0.7692\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2707 - accuracy: 0.8630 - val_loss: 0.9742 - val_accuracy: 0.7692\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2624 - accuracy: 0.8593 - val_loss: 0.9882 - val_accuracy: 0.7692\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 0.9936 - val_accuracy: 0.7692\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2662 - accuracy: 0.8667 - val_loss: 0.9965 - val_accuracy: 0.7692\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.9825 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2640 - accuracy: 0.8556 - val_loss: 0.9853 - val_accuracy: 0.7778\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2632 - accuracy: 0.8556 - val_loss: 1.0018 - val_accuracy: 0.7778\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 1.0209 - val_accuracy: 0.7692\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 1.0093 - val_accuracy: 0.7692\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.9942 - val_accuracy: 0.7692\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2646 - accuracy: 0.8593 - val_loss: 1.0094 - val_accuracy: 0.7607\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2663 - accuracy: 0.8630 - val_loss: 1.0047 - val_accuracy: 0.7607\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.9823 - val_accuracy: 0.7778\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 0.9788 - val_accuracy: 0.7778\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2605 - accuracy: 0.8593 - val_loss: 1.0005 - val_accuracy: 0.7521\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2632 - accuracy: 0.8481 - val_loss: 1.0162 - val_accuracy: 0.7436\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2682 - accuracy: 0.8481 - val_loss: 1.0079 - val_accuracy: 0.7607\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 1.0021 - val_accuracy: 0.7607\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.9954 - val_accuracy: 0.7692\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9860 - val_accuracy: 0.7607\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.9918 - val_accuracy: 0.7607\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.9900 - val_accuracy: 0.7607\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.9864 - val_accuracy: 0.7692\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.9772 - val_accuracy: 0.7692\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2612 - accuracy: 0.8593 - val_loss: 0.9800 - val_accuracy: 0.7607\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 0.9973 - val_accuracy: 0.7607\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 1.0018 - val_accuracy: 0.7607\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2647 - accuracy: 0.8630 - val_loss: 1.0004 - val_accuracy: 0.7692\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2671 - accuracy: 0.8667 - val_loss: 1.0222 - val_accuracy: 0.7692\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2668 - accuracy: 0.8667 - val_loss: 1.0042 - val_accuracy: 0.7692\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.9740 - val_accuracy: 0.7607\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.9874 - val_accuracy: 0.7692\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2691 - accuracy: 0.8593 - val_loss: 1.0191 - val_accuracy: 0.7521\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2660 - accuracy: 0.8667 - val_loss: 1.0181 - val_accuracy: 0.7521\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2681 - accuracy: 0.8593 - val_loss: 0.9776 - val_accuracy: 0.7692\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 0.9510 - val_accuracy: 0.7692\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2668 - accuracy: 0.8519 - val_loss: 0.9439 - val_accuracy: 0.7692\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2675 - accuracy: 0.8519 - val_loss: 0.9497 - val_accuracy: 0.7778\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2631 - accuracy: 0.8630 - val_loss: 1.0032 - val_accuracy: 0.7521\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2685 - accuracy: 0.8481 - val_loss: 1.0188 - val_accuracy: 0.7521\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2651 - accuracy: 0.8481 - val_loss: 0.9896 - val_accuracy: 0.7692\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2616 - accuracy: 0.8519 - val_loss: 0.9789 - val_accuracy: 0.7692\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.9997 - val_accuracy: 0.7692\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 1.0080 - val_accuracy: 0.7607\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2639 - accuracy: 0.8667 - val_loss: 1.0007 - val_accuracy: 0.7607\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.9896 - val_accuracy: 0.7692\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.9841 - val_accuracy: 0.7692\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2716 - accuracy: 0.8667 - val_loss: 0.9855 - val_accuracy: 0.7692\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2564 - accuracy: 0.8630 - val_loss: 1.0368 - val_accuracy: 0.7436\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2839 - accuracy: 0.8481 - val_loss: 1.0397 - val_accuracy: 0.7436\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2638 - accuracy: 0.8630 - val_loss: 0.9781 - val_accuracy: 0.7692\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.9631 - val_accuracy: 0.7778\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2746 - accuracy: 0.8630 - val_loss: 0.9705 - val_accuracy: 0.7692\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2661 - accuracy: 0.8556 - val_loss: 0.9939 - val_accuracy: 0.7692\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 0.9912 - val_accuracy: 0.7692\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.9988 - val_accuracy: 0.7692\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2625 - accuracy: 0.8593 - val_loss: 1.0069 - val_accuracy: 0.7607\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2609 - accuracy: 0.8630 - val_loss: 0.9981 - val_accuracy: 0.7692\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2607 - accuracy: 0.8667 - val_loss: 1.0011 - val_accuracy: 0.7692\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.9971 - val_accuracy: 0.7692\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2634 - accuracy: 0.8593 - val_loss: 0.9936 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 0.9948 - val_accuracy: 0.7692\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2630 - accuracy: 0.8556 - val_loss: 1.0284 - val_accuracy: 0.7436\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2657 - accuracy: 0.8704 - val_loss: 0.9726 - val_accuracy: 0.7778\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2661 - accuracy: 0.8556 - val_loss: 0.9619 - val_accuracy: 0.7607\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2668 - accuracy: 0.8593 - val_loss: 0.9906 - val_accuracy: 0.7692\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2669 - accuracy: 0.8593 - val_loss: 1.0206 - val_accuracy: 0.7607\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 1.0365 - val_accuracy: 0.7607\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 1.0320 - val_accuracy: 0.7692\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2635 - accuracy: 0.8519 - val_loss: 1.0102 - val_accuracy: 0.7692\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2635 - accuracy: 0.8593 - val_loss: 1.0128 - val_accuracy: 0.7692\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2639 - accuracy: 0.8667 - val_loss: 1.0286 - val_accuracy: 0.7692\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 1.0240 - val_accuracy: 0.7692\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 1.0074 - val_accuracy: 0.7692\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2632 - accuracy: 0.8593 - val_loss: 1.0069 - val_accuracy: 0.7778\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 1.0238 - val_accuracy: 0.7778\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2622 - accuracy: 0.8630 - val_loss: 1.0368 - val_accuracy: 0.7692\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 1.0421 - val_accuracy: 0.7692\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 1.0359 - val_accuracy: 0.7692\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2605 - accuracy: 0.8630 - val_loss: 1.0143 - val_accuracy: 0.7692\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 1.0043 - val_accuracy: 0.7692\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2641 - accuracy: 0.8630 - val_loss: 1.0139 - val_accuracy: 0.7692\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2604 - accuracy: 0.8704 - val_loss: 1.0247 - val_accuracy: 0.7692\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2665 - accuracy: 0.8630 - val_loss: 0.9998 - val_accuracy: 0.7607\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 0.9701 - val_accuracy: 0.7778\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2646 - accuracy: 0.8630 - val_loss: 0.9781 - val_accuracy: 0.7778\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2638 - accuracy: 0.8593 - val_loss: 0.9971 - val_accuracy: 0.7692\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2613 - accuracy: 0.8593 - val_loss: 1.0034 - val_accuracy: 0.7692\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2691 - accuracy: 0.8444 - val_loss: 1.0158 - val_accuracy: 0.7521\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2599 - accuracy: 0.8556 - val_loss: 0.9714 - val_accuracy: 0.7778\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2699 - accuracy: 0.8630 - val_loss: 0.9702 - val_accuracy: 0.7778\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2729 - accuracy: 0.8630 - val_loss: 0.9858 - val_accuracy: 0.7692\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2708 - accuracy: 0.8593 - val_loss: 1.0629 - val_accuracy: 0.7436\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2885 - accuracy: 0.8407 - val_loss: 1.0511 - val_accuracy: 0.7436\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2773 - accuracy: 0.8407 - val_loss: 0.9863 - val_accuracy: 0.7607\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2672 - accuracy: 0.8630 - val_loss: 0.9578 - val_accuracy: 0.7692\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2681 - accuracy: 0.8556 - val_loss: 0.9525 - val_accuracy: 0.7692\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.9747 - val_accuracy: 0.7607\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2622 - accuracy: 0.8556 - val_loss: 0.9872 - val_accuracy: 0.7692\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2623 - accuracy: 0.8630 - val_loss: 1.0018 - val_accuracy: 0.7692\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 1.0157 - val_accuracy: 0.7692\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 1.0208 - val_accuracy: 0.7692\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 1.0065 - val_accuracy: 0.7692\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 1.0046 - val_accuracy: 0.7607\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.9991 - val_accuracy: 0.7607\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.9950 - val_accuracy: 0.7607\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 0.9914 - val_accuracy: 0.7607\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.9864 - val_accuracy: 0.7607\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2611 - accuracy: 0.8704 - val_loss: 0.9845 - val_accuracy: 0.7607\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.9841 - val_accuracy: 0.7607\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2585 - accuracy: 0.8889 - val_loss: 1.0005 - val_accuracy: 0.7692\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2605 - accuracy: 0.8667 - val_loss: 1.0021 - val_accuracy: 0.7692\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.9958 - val_accuracy: 0.7692\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 1.0100 - val_accuracy: 0.7607\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 1.0161 - val_accuracy: 0.7692\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 1.0194 - val_accuracy: 0.7521\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2669 - accuracy: 0.8593 - val_loss: 1.0222 - val_accuracy: 0.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2671 - accuracy: 0.8593 - val_loss: 0.9995 - val_accuracy: 0.7692\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 1.0177 - val_accuracy: 0.7607\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2627 - accuracy: 0.8630 - val_loss: 1.0240 - val_accuracy: 0.7692\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2688 - accuracy: 0.8630 - val_loss: 1.0236 - val_accuracy: 0.7607\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2621 - accuracy: 0.8630 - val_loss: 0.9892 - val_accuracy: 0.7607\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.9747 - val_accuracy: 0.7778\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2651 - accuracy: 0.8630 - val_loss: 0.9875 - val_accuracy: 0.7778\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 1.0233 - val_accuracy: 0.7692\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 1.0459 - val_accuracy: 0.7607\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2682 - accuracy: 0.8519 - val_loss: 1.0496 - val_accuracy: 0.7436\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2673 - accuracy: 0.8593 - val_loss: 1.0089 - val_accuracy: 0.7778\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2674 - accuracy: 0.8630 - val_loss: 0.9900 - val_accuracy: 0.7778\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2643 - accuracy: 0.8704 - val_loss: 1.0037 - val_accuracy: 0.7607\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2637 - accuracy: 0.8593 - val_loss: 1.0444 - val_accuracy: 0.7607\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2638 - accuracy: 0.8630 - val_loss: 1.0436 - val_accuracy: 0.7692\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2634 - accuracy: 0.8704 - val_loss: 1.0033 - val_accuracy: 0.7778\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2653 - accuracy: 0.8556 - val_loss: 0.9719 - val_accuracy: 0.7607\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2667 - accuracy: 0.8593 - val_loss: 0.9757 - val_accuracy: 0.7607\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2694 - accuracy: 0.8556 - val_loss: 0.9818 - val_accuracy: 0.7607\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 1.0156 - val_accuracy: 0.7778\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2669 - accuracy: 0.8630 - val_loss: 1.0272 - val_accuracy: 0.7778\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2694 - accuracy: 0.8630 - val_loss: 1.0063 - val_accuracy: 0.7692\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2617 - accuracy: 0.8630 - val_loss: 1.0290 - val_accuracy: 0.7607\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2727 - accuracy: 0.8630 - val_loss: 1.0281 - val_accuracy: 0.7607\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2670 - accuracy: 0.8630 - val_loss: 1.0041 - val_accuracy: 0.7607\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2579 - accuracy: 0.8667 - val_loss: 1.0102 - val_accuracy: 0.7692\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2731 - accuracy: 0.8593 - val_loss: 1.0211 - val_accuracy: 0.7521\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2718 - accuracy: 0.8630 - val_loss: 0.9957 - val_accuracy: 0.7692\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2589 - accuracy: 0.8741 - val_loss: 1.0026 - val_accuracy: 0.7607\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 1.0018 - val_accuracy: 0.7607\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2705 - accuracy: 0.8667 - val_loss: 0.9766 - val_accuracy: 0.7607\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 0.9951 - val_accuracy: 0.7692\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.9989 - val_accuracy: 0.7692\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2631 - accuracy: 0.8630 - val_loss: 0.9998 - val_accuracy: 0.7692\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.9929 - val_accuracy: 0.7692\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.9870 - val_accuracy: 0.7607\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2632 - accuracy: 0.8593 - val_loss: 0.9874 - val_accuracy: 0.7607\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.81 - 0s 67us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 1.0110 - val_accuracy: 0.7607\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2605 - accuracy: 0.8630 - val_loss: 1.0112 - val_accuracy: 0.7778\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 1.0274 - val_accuracy: 0.7692\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 1.0138 - val_accuracy: 0.7692\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2614 - accuracy: 0.8630 - val_loss: 0.9920 - val_accuracy: 0.7778\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.9840 - val_accuracy: 0.7778\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2642 - accuracy: 0.8704 - val_loss: 1.0113 - val_accuracy: 0.7607\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2603 - accuracy: 0.8630 - val_loss: 1.0224 - val_accuracy: 0.7692\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 1.0236 - val_accuracy: 0.7607\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 1.0296 - val_accuracy: 0.7607\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2641 - accuracy: 0.8630 - val_loss: 1.0262 - val_accuracy: 0.7778\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2652 - accuracy: 0.8630 - val_loss: 1.0193 - val_accuracy: 0.7692\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2668 - accuracy: 0.8593 - val_loss: 1.0306 - val_accuracy: 0.7778\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2647 - accuracy: 0.8556 - val_loss: 1.0287 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a339df3c8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 121us/step\n",
      "over-sampling test accuracy: 78.63%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over3 = model2_over3.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0,\n",
       "       1, 2, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0, 2, 2,\n",
       "       1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0,\n",
       "       2, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 0,\n",
       "       2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model2_over3.predict_classes(X_sel_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CFBREBSa108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS210     0     0\n",
       "1         NRS205     2     2\n",
       "2            312     2     2\n",
       "3           GA15     2     2\n",
       "4         SR4035     0     0\n",
       "..           ...   ...   ...\n",
       "112       NRS265     2     2\n",
       "113  CFBREBSa108     1     0\n",
       "114        NY224     1     1\n",
       "115       NRS386     2     2\n",
       "116       NRS168     2     2\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model2_over3.predict_proba(X_sel_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.117269e-01</td>\n",
       "      <td>2.882596e-01</td>\n",
       "      <td>1.355703e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.645844e-13</td>\n",
       "      <td>3.129307e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.420781e-07</td>\n",
       "      <td>2.026271e-08</td>\n",
       "      <td>9.999995e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.050341e-03</td>\n",
       "      <td>8.900376e-04</td>\n",
       "      <td>9.980596e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.988620e-01</td>\n",
       "      <td>1.137946e-03</td>\n",
       "      <td>1.812745e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4.759788e-06</td>\n",
       "      <td>3.114278e-06</td>\n",
       "      <td>9.999921e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.931377e-01</td>\n",
       "      <td>3.554063e-01</td>\n",
       "      <td>5.145596e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3.256392e-03</td>\n",
       "      <td>7.567788e-01</td>\n",
       "      <td>2.399649e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3.174596e-09</td>\n",
       "      <td>1.028540e-02</td>\n",
       "      <td>9.897146e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.078798e-06</td>\n",
       "      <td>1.199017e-01</td>\n",
       "      <td>8.800972e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    7.117269e-01  2.882596e-01  1.355703e-05\n",
       "1    8.645844e-13  3.129307e-12  1.000000e+00\n",
       "2    4.420781e-07  2.026271e-08  9.999995e-01\n",
       "3    1.050341e-03  8.900376e-04  9.980596e-01\n",
       "4    9.988620e-01  1.137946e-03  1.812745e-09\n",
       "..            ...           ...           ...\n",
       "112  4.759788e-06  3.114278e-06  9.999921e-01\n",
       "113  5.931377e-01  3.554063e-01  5.145596e-02\n",
       "114  3.256392e-03  7.567788e-01  2.399649e-01\n",
       "115  3.174596e-09  1.028540e-02  9.897146e-01\n",
       "116  1.078798e-06  1.199017e-01  8.800972e-01\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2690 - accuracy: 0.8259 - val_loss: 0.7458 - val_accuracy: 0.8034\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2625 - accuracy: 0.8593 - val_loss: 0.7340 - val_accuracy: 0.8034\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 0.7400 - val_accuracy: 0.8034\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 0.7479 - val_accuracy: 0.7949\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2656 - accuracy: 0.8667 - val_loss: 0.7557 - val_accuracy: 0.7949\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.7467 - val_accuracy: 0.8120\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2660 - accuracy: 0.8593 - val_loss: 0.7442 - val_accuracy: 0.8034\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2619 - accuracy: 0.8630 - val_loss: 0.7497 - val_accuracy: 0.8034\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2680 - accuracy: 0.8630 - val_loss: 0.7525 - val_accuracy: 0.8034\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.7567 - val_accuracy: 0.8034\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2759 - accuracy: 0.8630 - val_loss: 0.7763 - val_accuracy: 0.8034\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2689 - accuracy: 0.8704 - val_loss: 0.7580 - val_accuracy: 0.8120\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.7608 - val_accuracy: 0.8205\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.7633 - val_accuracy: 0.8034\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2630 - accuracy: 0.8704 - val_loss: 0.7832 - val_accuracy: 0.7863\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2825 - accuracy: 0.8444 - val_loss: 0.7783 - val_accuracy: 0.8034\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2618 - accuracy: 0.8741 - val_loss: 0.7582 - val_accuracy: 0.8205\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2712 - accuracy: 0.8630 - val_loss: 0.7647 - val_accuracy: 0.8034\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2682 - accuracy: 0.8667 - val_loss: 0.7721 - val_accuracy: 0.8034\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2723 - accuracy: 0.8630 - val_loss: 0.7492 - val_accuracy: 0.8034\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.7500 - val_accuracy: 0.8120\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2740 - accuracy: 0.8630 - val_loss: 0.7487 - val_accuracy: 0.8034\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2660 - accuracy: 0.8593 - val_loss: 0.7776 - val_accuracy: 0.8034\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2755 - accuracy: 0.8630 - val_loss: 0.7712 - val_accuracy: 0.8034\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2643 - accuracy: 0.8704 - val_loss: 0.7739 - val_accuracy: 0.7949\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.7595 - val_accuracy: 0.7949\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2657 - accuracy: 0.8556 - val_loss: 0.7455 - val_accuracy: 0.7949\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 0.7445 - val_accuracy: 0.8034\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.7603 - val_accuracy: 0.8034\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2669 - accuracy: 0.8667 - val_loss: 0.7607 - val_accuracy: 0.7949\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.7566 - val_accuracy: 0.8034\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2681 - accuracy: 0.8630 - val_loss: 0.7440 - val_accuracy: 0.8034\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2599 - accuracy: 0.8630 - val_loss: 0.7587 - val_accuracy: 0.7949\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2641 - accuracy: 0.8704 - val_loss: 0.7612 - val_accuracy: 0.8034\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2701 - accuracy: 0.8556 - val_loss: 0.7558 - val_accuracy: 0.7863\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2699 - accuracy: 0.8370 - val_loss: 0.7443 - val_accuracy: 0.8120\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2659 - accuracy: 0.8444 - val_loss: 0.7525 - val_accuracy: 0.7863\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2617 - accuracy: 0.8704 - val_loss: 0.7502 - val_accuracy: 0.7949\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 0.7528 - val_accuracy: 0.8034\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2713 - accuracy: 0.8630 - val_loss: 0.7486 - val_accuracy: 0.8034\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 0.7535 - val_accuracy: 0.7949\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2650 - accuracy: 0.8741 - val_loss: 0.7561 - val_accuracy: 0.7949\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.7589 - val_accuracy: 0.7949\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2636 - accuracy: 0.8556 - val_loss: 0.7456 - val_accuracy: 0.7949\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 0.7374 - val_accuracy: 0.8034\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2640 - accuracy: 0.8444 - val_loss: 0.7454 - val_accuracy: 0.7949\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 0.7630 - val_accuracy: 0.8034\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 0.7579 - val_accuracy: 0.8034\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2708 - accuracy: 0.8519 - val_loss: 0.7633 - val_accuracy: 0.8034\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2681 - accuracy: 0.8667 - val_loss: 0.7398 - val_accuracy: 0.7949\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2761 - accuracy: 0.8556 - val_loss: 0.7354 - val_accuracy: 0.8034\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2693 - accuracy: 0.8593 - val_loss: 0.7535 - val_accuracy: 0.8034\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.7707 - val_accuracy: 0.7778\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2709 - accuracy: 0.8481 - val_loss: 0.7548 - val_accuracy: 0.7949\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2656 - accuracy: 0.8519 - val_loss: 0.7259 - val_accuracy: 0.7949\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.2716 - accuracy: 0.8481 - val_loss: 0.7358 - val_accuracy: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.7530 - val_accuracy: 0.7949\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2648 - accuracy: 0.8593 - val_loss: 0.7629 - val_accuracy: 0.7949\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2606 - accuracy: 0.8741 - val_loss: 0.7575 - val_accuracy: 0.7949\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.7495 - val_accuracy: 0.7949\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2608 - accuracy: 0.8667 - val_loss: 0.7566 - val_accuracy: 0.7949\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2638 - accuracy: 0.8556 - val_loss: 0.7593 - val_accuracy: 0.8034\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2619 - accuracy: 0.8630 - val_loss: 0.7432 - val_accuracy: 0.8034\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2687 - accuracy: 0.8630 - val_loss: 0.7348 - val_accuracy: 0.8034\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2737 - accuracy: 0.8630 - val_loss: 0.7415 - val_accuracy: 0.8120\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2607 - accuracy: 0.8667 - val_loss: 0.7629 - val_accuracy: 0.8034\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2676 - accuracy: 0.8519 - val_loss: 0.7759 - val_accuracy: 0.7863\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2709 - accuracy: 0.8481 - val_loss: 0.7460 - val_accuracy: 0.8034\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2680 - accuracy: 0.8630 - val_loss: 0.7340 - val_accuracy: 0.8034\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2644 - accuracy: 0.8630 - val_loss: 0.7398 - val_accuracy: 0.8034\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2663 - accuracy: 0.8556 - val_loss: 0.7535 - val_accuracy: 0.8034\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2618 - accuracy: 0.8593 - val_loss: 0.7455 - val_accuracy: 0.7949\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7536 - val_accuracy: 0.8034\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2638 - accuracy: 0.8593 - val_loss: 0.7580 - val_accuracy: 0.7949\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.7586 - val_accuracy: 0.7949\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 0.7725 - val_accuracy: 0.7949\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2669 - accuracy: 0.8667 - val_loss: 0.7635 - val_accuracy: 0.7949\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.7554 - val_accuracy: 0.7949\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2613 - accuracy: 0.8519 - val_loss: 0.7464 - val_accuracy: 0.8034\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2617 - accuracy: 0.8556 - val_loss: 0.7373 - val_accuracy: 0.8120\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 0.7381 - val_accuracy: 0.8120\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.7530 - val_accuracy: 0.8034\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.7505 - val_accuracy: 0.8120\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 237us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7351 - val_accuracy: 0.8120\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2679 - accuracy: 0.8630 - val_loss: 0.7348 - val_accuracy: 0.8120\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2626 - accuracy: 0.8593 - val_loss: 0.7585 - val_accuracy: 0.8034\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2677 - accuracy: 0.8667 - val_loss: 0.7679 - val_accuracy: 0.8120\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 0.7525 - val_accuracy: 0.8034\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2705 - accuracy: 0.8667 - val_loss: 0.7426 - val_accuracy: 0.8034\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2652 - accuracy: 0.8704 - val_loss: 0.7523 - val_accuracy: 0.8034\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2694 - accuracy: 0.8667 - val_loss: 0.7648 - val_accuracy: 0.7949\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2660 - accuracy: 0.8667 - val_loss: 0.7549 - val_accuracy: 0.8034\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.7459 - val_accuracy: 0.8034\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7438 - val_accuracy: 0.7949\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.7563 - val_accuracy: 0.8034\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2662 - accuracy: 0.8667 - val_loss: 0.7353 - val_accuracy: 0.8120\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7437 - val_accuracy: 0.8120\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2664 - accuracy: 0.8667 - val_loss: 0.7442 - val_accuracy: 0.8034\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2659 - accuracy: 0.8630 - val_loss: 0.7620 - val_accuracy: 0.8034\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2726 - accuracy: 0.8519 - val_loss: 0.7785 - val_accuracy: 0.7863\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2706 - accuracy: 0.8370 - val_loss: 0.7656 - val_accuracy: 0.8034\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 525us/step - loss: 0.2664 - accuracy: 0.8667 - val_loss: 0.7506 - val_accuracy: 0.8120\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2588 - accuracy: 0.8741 - val_loss: 0.7534 - val_accuracy: 0.8034\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2729 - accuracy: 0.8630 - val_loss: 0.7743 - val_accuracy: 0.8034\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2711 - accuracy: 0.8630 - val_loss: 0.7692 - val_accuracy: 0.8034\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2695 - accuracy: 0.8593 - val_loss: 0.7718 - val_accuracy: 0.8034\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 0.7685 - val_accuracy: 0.8034\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2725 - accuracy: 0.8630 - val_loss: 0.7497 - val_accuracy: 0.8034\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2673 - accuracy: 0.8630 - val_loss: 0.7380 - val_accuracy: 0.8034\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2620 - accuracy: 0.8593 - val_loss: 0.7587 - val_accuracy: 0.8034\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7536 - val_accuracy: 0.8034\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2646 - accuracy: 0.8667 - val_loss: 0.7502 - val_accuracy: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 0.7471 - val_accuracy: 0.8034\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2651 - accuracy: 0.8630 - val_loss: 0.7542 - val_accuracy: 0.7949\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.7423 - val_accuracy: 0.7949\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 0.7463 - val_accuracy: 0.7949\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2621 - accuracy: 0.8630 - val_loss: 0.7429 - val_accuracy: 0.8034\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.7463 - val_accuracy: 0.7949\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2653 - accuracy: 0.8593 - val_loss: 0.7472 - val_accuracy: 0.8034\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2662 - accuracy: 0.8519 - val_loss: 0.7349 - val_accuracy: 0.8034\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2714 - accuracy: 0.8593 - val_loss: 0.7353 - val_accuracy: 0.8034\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2674 - accuracy: 0.8593 - val_loss: 0.7474 - val_accuracy: 0.8034\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2634 - accuracy: 0.8556 - val_loss: 0.7448 - val_accuracy: 0.8120\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2618 - accuracy: 0.8741 - val_loss: 0.7416 - val_accuracy: 0.8034\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2629 - accuracy: 0.8519 - val_loss: 0.7494 - val_accuracy: 0.8034\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2691 - accuracy: 0.8630 - val_loss: 0.7551 - val_accuracy: 0.8034\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2647 - accuracy: 0.8630 - val_loss: 0.7472 - val_accuracy: 0.7949\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2602 - accuracy: 0.8630 - val_loss: 0.7456 - val_accuracy: 0.8034\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2613 - accuracy: 0.8519 - val_loss: 0.7399 - val_accuracy: 0.8034\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7419 - val_accuracy: 0.7949\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 562us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.7458 - val_accuracy: 0.7949\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 335us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 0.7521 - val_accuracy: 0.7949\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 472us/step - loss: 0.2633 - accuracy: 0.8593 - val_loss: 0.7552 - val_accuracy: 0.8034\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2647 - accuracy: 0.8704 - val_loss: 0.7583 - val_accuracy: 0.8034\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.7623 - val_accuracy: 0.8120\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2621 - accuracy: 0.8741 - val_loss: 0.7891 - val_accuracy: 0.8034\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2717 - accuracy: 0.8667 - val_loss: 0.7735 - val_accuracy: 0.8034\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7446 - val_accuracy: 0.8120\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 0.7403 - val_accuracy: 0.8120\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7431 - val_accuracy: 0.8120\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7450 - val_accuracy: 0.8120\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.7408 - val_accuracy: 0.8120\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2628 - accuracy: 0.8593 - val_loss: 0.7429 - val_accuracy: 0.8034\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 232us/step - loss: 0.2603 - accuracy: 0.8556 - val_loss: 0.7431 - val_accuracy: 0.8034\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 0.7590 - val_accuracy: 0.8034\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 356us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 0.7515 - val_accuracy: 0.8034\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2607 - accuracy: 0.8704 - val_loss: 0.7546 - val_accuracy: 0.8120\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2670 - accuracy: 0.8630 - val_loss: 0.7527 - val_accuracy: 0.8120\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 0.7527 - val_accuracy: 0.8034\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.7537 - val_accuracy: 0.8034\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 0.7446 - val_accuracy: 0.8034\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2675 - accuracy: 0.8704 - val_loss: 0.7437 - val_accuracy: 0.8034\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2652 - accuracy: 0.8556 - val_loss: 0.7449 - val_accuracy: 0.8120\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2727 - accuracy: 0.8667 - val_loss: 0.7667 - val_accuracy: 0.8034\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2752 - accuracy: 0.8630 - val_loss: 0.7766 - val_accuracy: 0.8034\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2665 - accuracy: 0.8667 - val_loss: 0.7553 - val_accuracy: 0.8034\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 462us/step - loss: 0.2576 - accuracy: 0.8630 - val_loss: 0.7554 - val_accuracy: 0.8120\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2738 - accuracy: 0.8630 - val_loss: 0.7548 - val_accuracy: 0.8120\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 405us/step - loss: 0.2629 - accuracy: 0.8741 - val_loss: 0.7937 - val_accuracy: 0.7863\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2778 - accuracy: 0.8481 - val_loss: 0.7888 - val_accuracy: 0.8034\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2649 - accuracy: 0.8667 - val_loss: 0.7541 - val_accuracy: 0.8120\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2688 - accuracy: 0.8667 - val_loss: 0.7511 - val_accuracy: 0.8120\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2751 - accuracy: 0.8481 - val_loss: 0.7562 - val_accuracy: 0.8120\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2707 - accuracy: 0.8630 - val_loss: 0.7604 - val_accuracy: 0.8034\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7810 - val_accuracy: 0.7863\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2704 - accuracy: 0.8481 - val_loss: 0.7683 - val_accuracy: 0.8034\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.7579 - val_accuracy: 0.8034\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2676 - accuracy: 0.8556 - val_loss: 0.7422 - val_accuracy: 0.8034\n",
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 284us/step - loss: 0.2675 - accuracy: 0.8593 - val_loss: 0.7609 - val_accuracy: 0.7949\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2655 - accuracy: 0.8519 - val_loss: 0.7831 - val_accuracy: 0.7949\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 303us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 0.7623 - val_accuracy: 0.8034\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7463 - val_accuracy: 0.8120\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2687 - accuracy: 0.8593 - val_loss: 0.7425 - val_accuracy: 0.8120\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2656 - accuracy: 0.8593 - val_loss: 0.7467 - val_accuracy: 0.8034\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7786 - val_accuracy: 0.8034\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2819 - accuracy: 0.8593 - val_loss: 0.7855 - val_accuracy: 0.7863\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2772 - accuracy: 0.8444 - val_loss: 0.7366 - val_accuracy: 0.8120\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2627 - accuracy: 0.8630 - val_loss: 0.7272 - val_accuracy: 0.8120\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2607 - accuracy: 0.8630 - val_loss: 0.7336 - val_accuracy: 0.8120\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 324us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.7484 - val_accuracy: 0.8120\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7508 - val_accuracy: 0.8120\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.7507 - val_accuracy: 0.8120\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2676 - accuracy: 0.8593 - val_loss: 0.7745 - val_accuracy: 0.7863\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2696 - accuracy: 0.8444 - val_loss: 0.7501 - val_accuracy: 0.8120\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.7499 - val_accuracy: 0.8120\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2615 - accuracy: 0.8519 - val_loss: 0.7438 - val_accuracy: 0.8034\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.7450 - val_accuracy: 0.8034\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2656 - accuracy: 0.8519 - val_loss: 0.7494 - val_accuracy: 0.8034\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2607 - accuracy: 0.8667 - val_loss: 0.7670 - val_accuracy: 0.7949\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2689 - accuracy: 0.8667 - val_loss: 0.8033 - val_accuracy: 0.7863\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2821 - accuracy: 0.8481 - val_loss: 0.7626 - val_accuracy: 0.7949\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2631 - accuracy: 0.8741 - val_loss: 0.7410 - val_accuracy: 0.8120\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2697 - accuracy: 0.8593 - val_loss: 0.7514 - val_accuracy: 0.8120\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2653 - accuracy: 0.8630 - val_loss: 0.7623 - val_accuracy: 0.7949\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 0.7664 - val_accuracy: 0.7949\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2637 - accuracy: 0.8741 - val_loss: 0.7585 - val_accuracy: 0.7949\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7715 - val_accuracy: 0.8034\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2708 - accuracy: 0.8519 - val_loss: 0.7813 - val_accuracy: 0.7778\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2708 - accuracy: 0.8481 - val_loss: 0.7394 - val_accuracy: 0.7949\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2646 - accuracy: 0.8593 - val_loss: 0.7290 - val_accuracy: 0.8034\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 154us/step - loss: 0.2746 - accuracy: 0.8593 - val_loss: 0.7471 - val_accuracy: 0.8034\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 0.7572 - val_accuracy: 0.7949\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2687 - accuracy: 0.8444 - val_loss: 0.7786 - val_accuracy: 0.7778\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2663 - accuracy: 0.8444 - val_loss: 0.7462 - val_accuracy: 0.8034\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2732 - accuracy: 0.8519 - val_loss: 0.7216 - val_accuracy: 0.8034\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2825 - accuracy: 0.8593 - val_loss: 0.7277 - val_accuracy: 0.8120\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 0.7726 - val_accuracy: 0.7949\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2752 - accuracy: 0.8481 - val_loss: 0.7838 - val_accuracy: 0.7949\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2661 - accuracy: 0.8481 - val_loss: 0.7551 - val_accuracy: 0.8034\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2645 - accuracy: 0.8556 - val_loss: 0.7413 - val_accuracy: 0.8034\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2699 - accuracy: 0.8593 - val_loss: 0.7429 - val_accuracy: 0.7949\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2646 - accuracy: 0.8593 - val_loss: 0.7654 - val_accuracy: 0.7949\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2666 - accuracy: 0.8667 - val_loss: 0.7738 - val_accuracy: 0.7949\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 390us/step - loss: 0.2623 - accuracy: 0.8630 - val_loss: 0.7537 - val_accuracy: 0.7949\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.2635 - accuracy: 0.8593 - val_loss: 0.7579 - val_accuracy: 0.7949\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 160us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.7696 - val_accuracy: 0.7949\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.7723 - val_accuracy: 0.7949\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 0.7769 - val_accuracy: 0.7949\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.7580 - val_accuracy: 0.8034\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2695 - accuracy: 0.8444 - val_loss: 0.7552 - val_accuracy: 0.8034\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 0.7686 - val_accuracy: 0.7863\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2721 - accuracy: 0.8444 - val_loss: 0.7932 - val_accuracy: 0.7863\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2755 - accuracy: 0.8481 - val_loss: 0.7507 - val_accuracy: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2626 - accuracy: 0.8741 - val_loss: 0.7328 - val_accuracy: 0.8120\n",
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 218us/step - loss: 0.2659 - accuracy: 0.8630 - val_loss: 0.7390 - val_accuracy: 0.8120\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 487us/step - loss: 0.2637 - accuracy: 0.8593 - val_loss: 0.7461 - val_accuracy: 0.8034\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2656 - accuracy: 0.8556 - val_loss: 0.7515 - val_accuracy: 0.8120\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.7491 - val_accuracy: 0.8034\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.7598 - val_accuracy: 0.8034\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 287us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.7558 - val_accuracy: 0.8034\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.7641 - val_accuracy: 0.7949\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2648 - accuracy: 0.8556 - val_loss: 0.7640 - val_accuracy: 0.8034\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.7537 - val_accuracy: 0.8034\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2646 - accuracy: 0.8630 - val_loss: 0.7520 - val_accuracy: 0.7949\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2650 - accuracy: 0.8593 - val_loss: 0.7350 - val_accuracy: 0.8120\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 0.7457 - val_accuracy: 0.8034\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2650 - accuracy: 0.8667 - val_loss: 0.7542 - val_accuracy: 0.8034\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.7534 - val_accuracy: 0.8034\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2669 - accuracy: 0.8667 - val_loss: 0.7601 - val_accuracy: 0.8034\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2614 - accuracy: 0.8741 - val_loss: 0.7509 - val_accuracy: 0.8034\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 0.7598 - val_accuracy: 0.8034\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2621 - accuracy: 0.8741 - val_loss: 0.7684 - val_accuracy: 0.8034\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2641 - accuracy: 0.8556 - val_loss: 0.7698 - val_accuracy: 0.8034\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2635 - accuracy: 0.8667 - val_loss: 0.7548 - val_accuracy: 0.8120\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2619 - accuracy: 0.8556 - val_loss: 0.7479 - val_accuracy: 0.8120\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 340us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.7504 - val_accuracy: 0.8120\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2602 - accuracy: 0.8481 - val_loss: 0.7509 - val_accuracy: 0.8120\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7545 - val_accuracy: 0.8120\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 0.7488 - val_accuracy: 0.8120\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.7425 - val_accuracy: 0.8205\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 0.7552 - val_accuracy: 0.8120\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 0.7660 - val_accuracy: 0.8120\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.7709 - val_accuracy: 0.8120\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2646 - accuracy: 0.8667 - val_loss: 0.7803 - val_accuracy: 0.8034\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2670 - accuracy: 0.8593 - val_loss: 0.7634 - val_accuracy: 0.8034\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7471 - val_accuracy: 0.8120\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2725 - accuracy: 0.8593 - val_loss: 0.7524 - val_accuracy: 0.8034\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2661 - accuracy: 0.8630 - val_loss: 0.7696 - val_accuracy: 0.7949\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2639 - accuracy: 0.8667 - val_loss: 0.7903 - val_accuracy: 0.7949\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2697 - accuracy: 0.8593 - val_loss: 0.7740 - val_accuracy: 0.8034\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2760 - accuracy: 0.8593 - val_loss: 0.7513 - val_accuracy: 0.8034\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2754 - accuracy: 0.8593 - val_loss: 0.7465 - val_accuracy: 0.8120\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2644 - accuracy: 0.8630 - val_loss: 0.7616 - val_accuracy: 0.8120\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2621 - accuracy: 0.8704 - val_loss: 0.7644 - val_accuracy: 0.8120\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2605 - accuracy: 0.8667 - val_loss: 0.7525 - val_accuracy: 0.8120\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2775 - accuracy: 0.8593 - val_loss: 0.7422 - val_accuracy: 0.8120\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2646 - accuracy: 0.8778 - val_loss: 0.7665 - val_accuracy: 0.8120\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2614 - accuracy: 0.8667 - val_loss: 0.7663 - val_accuracy: 0.8120\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2639 - accuracy: 0.8593 - val_loss: 0.7614 - val_accuracy: 0.7949\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2618 - accuracy: 0.8593 - val_loss: 0.7522 - val_accuracy: 0.7949\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2620 - accuracy: 0.8593 - val_loss: 0.7551 - val_accuracy: 0.7949\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.7593 - val_accuracy: 0.7949\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7599 - val_accuracy: 0.7949\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 0.7511 - val_accuracy: 0.8034\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 0.7698 - val_accuracy: 0.7949\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.7791 - val_accuracy: 0.7949\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2660 - accuracy: 0.8519 - val_loss: 0.7677 - val_accuracy: 0.8034\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.7552 - val_accuracy: 0.8034\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7558 - val_accuracy: 0.8034\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.7452 - val_accuracy: 0.8205\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2603 - accuracy: 0.8630 - val_loss: 0.7573 - val_accuracy: 0.8120\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2718 - accuracy: 0.8630 - val_loss: 0.7790 - val_accuracy: 0.7863\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2699 - accuracy: 0.8444 - val_loss: 0.7705 - val_accuracy: 0.8034\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.7578 - val_accuracy: 0.8034\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7614 - val_accuracy: 0.8034\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.7569 - val_accuracy: 0.8034\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.7632 - val_accuracy: 0.7949\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2612 - accuracy: 0.8704 - val_loss: 0.7471 - val_accuracy: 0.8034\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2605 - accuracy: 0.8593 - val_loss: 0.7393 - val_accuracy: 0.8034\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2684 - accuracy: 0.8593 - val_loss: 0.7479 - val_accuracy: 0.8034\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.7596 - val_accuracy: 0.8034\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.7720 - val_accuracy: 0.8034\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2669 - accuracy: 0.8630 - val_loss: 0.7819 - val_accuracy: 0.8034\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.7781 - val_accuracy: 0.8034\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.7615 - val_accuracy: 0.8034\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2647 - accuracy: 0.8704 - val_loss: 0.7486 - val_accuracy: 0.8034\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2609 - accuracy: 0.8630 - val_loss: 0.7627 - val_accuracy: 0.7949\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.7652 - val_accuracy: 0.7949\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 0.7618 - val_accuracy: 0.8034\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.7593 - val_accuracy: 0.8034\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.7586 - val_accuracy: 0.8034\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2628 - accuracy: 0.8704 - val_loss: 0.7610 - val_accuracy: 0.8034\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.7633 - val_accuracy: 0.8034\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.7710 - val_accuracy: 0.8034\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2644 - accuracy: 0.8630 - val_loss: 0.7791 - val_accuracy: 0.7949\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7714 - val_accuracy: 0.8034\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.7749 - val_accuracy: 0.8034\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7708 - val_accuracy: 0.8034\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2599 - accuracy: 0.8630 - val_loss: 0.7625 - val_accuracy: 0.7949\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7591 - val_accuracy: 0.8034\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.7796 - val_accuracy: 0.8034\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2667 - accuracy: 0.8593 - val_loss: 0.7832 - val_accuracy: 0.7863\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2636 - accuracy: 0.8593 - val_loss: 0.7464 - val_accuracy: 0.7949\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2674 - accuracy: 0.8593 - val_loss: 0.7465 - val_accuracy: 0.7949\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2658 - accuracy: 0.8593 - val_loss: 0.7484 - val_accuracy: 0.8034\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2612 - accuracy: 0.8630 - val_loss: 0.7596 - val_accuracy: 0.7949\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.7743 - val_accuracy: 0.7949\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.7779 - val_accuracy: 0.7949\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2627 - accuracy: 0.8593 - val_loss: 0.7776 - val_accuracy: 0.8034\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.7799 - val_accuracy: 0.8034\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2712 - accuracy: 0.8667 - val_loss: 0.7678 - val_accuracy: 0.8034\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2614 - accuracy: 0.8667 - val_loss: 0.7589 - val_accuracy: 0.8034\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.7633 - val_accuracy: 0.7949\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2630 - accuracy: 0.8593 - val_loss: 0.7528 - val_accuracy: 0.8034\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2648 - accuracy: 0.8630 - val_loss: 0.7488 - val_accuracy: 0.7949\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2658 - accuracy: 0.8556 - val_loss: 0.7747 - val_accuracy: 0.8034\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2643 - accuracy: 0.8630 - val_loss: 0.7793 - val_accuracy: 0.8120\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2619 - accuracy: 0.8630 - val_loss: 0.7647 - val_accuracy: 0.8120\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 0.7581 - val_accuracy: 0.8034\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.7764 - val_accuracy: 0.8120\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2651 - accuracy: 0.8704 - val_loss: 0.7796 - val_accuracy: 0.8034\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.7572 - val_accuracy: 0.8034\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2612 - accuracy: 0.8593 - val_loss: 0.7492 - val_accuracy: 0.8034\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 190us/step - loss: 0.2644 - accuracy: 0.8593 - val_loss: 0.7522 - val_accuracy: 0.8120\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2621 - accuracy: 0.8630 - val_loss: 0.7624 - val_accuracy: 0.7949\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.7891 - val_accuracy: 0.8034\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.7730 - val_accuracy: 0.8034\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2624 - accuracy: 0.8704 - val_loss: 0.7596 - val_accuracy: 0.8034\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.7494 - val_accuracy: 0.8120\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 302us/step - loss: 0.2626 - accuracy: 0.8519 - val_loss: 0.7543 - val_accuracy: 0.8034\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7501 - val_accuracy: 0.8034\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 0.7442 - val_accuracy: 0.8034\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2723 - accuracy: 0.8667 - val_loss: 0.7695 - val_accuracy: 0.7863\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2659 - accuracy: 0.8630 - val_loss: 0.7441 - val_accuracy: 0.8120\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2734 - accuracy: 0.8630 - val_loss: 0.7505 - val_accuracy: 0.8205\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2720 - accuracy: 0.8593 - val_loss: 0.7508 - val_accuracy: 0.8034\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2622 - accuracy: 0.8630 - val_loss: 0.7696 - val_accuracy: 0.8034\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2678 - accuracy: 0.8630 - val_loss: 0.7585 - val_accuracy: 0.8034\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 261us/step - loss: 0.2622 - accuracy: 0.8630 - val_loss: 0.7725 - val_accuracy: 0.8034\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.7835 - val_accuracy: 0.8034\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2652 - accuracy: 0.8556 - val_loss: 0.7866 - val_accuracy: 0.7778\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2666 - accuracy: 0.8667 - val_loss: 0.7598 - val_accuracy: 0.8034\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.7417 - val_accuracy: 0.8034\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2686 - accuracy: 0.8556 - val_loss: 0.7493 - val_accuracy: 0.8034\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2707 - accuracy: 0.8556 - val_loss: 0.7580 - val_accuracy: 0.8034\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 0.7617 - val_accuracy: 0.7949\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.7570 - val_accuracy: 0.7949\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7579 - val_accuracy: 0.8034\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.7580 - val_accuracy: 0.8034\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2641 - accuracy: 0.8667 - val_loss: 0.7674 - val_accuracy: 0.7949\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2646 - accuracy: 0.8593 - val_loss: 0.7554 - val_accuracy: 0.8034\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2636 - accuracy: 0.8593 - val_loss: 0.7540 - val_accuracy: 0.7949\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.7727 - val_accuracy: 0.7949\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.7966 - val_accuracy: 0.7949\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2686 - accuracy: 0.8519 - val_loss: 0.8015 - val_accuracy: 0.8034\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2635 - accuracy: 0.8556 - val_loss: 0.7847 - val_accuracy: 0.7949\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2624 - accuracy: 0.8556 - val_loss: 0.7690 - val_accuracy: 0.8034\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2594 - accuracy: 0.8667 - val_loss: 0.7693 - val_accuracy: 0.7949\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.7618 - val_accuracy: 0.7949\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2605 - accuracy: 0.8667 - val_loss: 0.7566 - val_accuracy: 0.7949\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.7727 - val_accuracy: 0.7949\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7842 - val_accuracy: 0.8034\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2615 - accuracy: 0.8704 - val_loss: 0.7788 - val_accuracy: 0.7949\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 0.7678 - val_accuracy: 0.7949\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.7728 - val_accuracy: 0.8034\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2652 - accuracy: 0.8667 - val_loss: 0.7699 - val_accuracy: 0.7949\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2610 - accuracy: 0.8593 - val_loss: 0.7705 - val_accuracy: 0.8120\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2642 - accuracy: 0.8519 - val_loss: 0.7783 - val_accuracy: 0.8034\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.7610 - val_accuracy: 0.8120\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2667 - accuracy: 0.8741 - val_loss: 0.7566 - val_accuracy: 0.8120\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.7773 - val_accuracy: 0.8120\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2692 - accuracy: 0.8481 - val_loss: 0.8073 - val_accuracy: 0.7863\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2720 - accuracy: 0.8630 - val_loss: 0.7894 - val_accuracy: 0.7778\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 266us/step - loss: 0.2687 - accuracy: 0.8593 - val_loss: 0.7705 - val_accuracy: 0.8034\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2774 - accuracy: 0.8519 - val_loss: 0.7747 - val_accuracy: 0.7949\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2697 - accuracy: 0.8481 - val_loss: 0.7829 - val_accuracy: 0.7863\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 0.7666 - val_accuracy: 0.8120\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2643 - accuracy: 0.8593 - val_loss: 0.7680 - val_accuracy: 0.8120\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2633 - accuracy: 0.8593 - val_loss: 0.7804 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2665 - accuracy: 0.8667 - val_loss: 0.7947 - val_accuracy: 0.8034\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.7685 - val_accuracy: 0.8120\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2713 - accuracy: 0.8593 - val_loss: 0.7649 - val_accuracy: 0.8034\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2651 - accuracy: 0.8630 - val_loss: 0.8014 - val_accuracy: 0.7863\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2673 - accuracy: 0.8481 - val_loss: 0.7986 - val_accuracy: 0.8034\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 295us/step - loss: 0.2579 - accuracy: 0.8667 - val_loss: 0.7836 - val_accuracy: 0.8034\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 233us/step - loss: 0.2768 - accuracy: 0.8593 - val_loss: 0.7756 - val_accuracy: 0.7949\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2742 - accuracy: 0.8667 - val_loss: 0.8061 - val_accuracy: 0.7949\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2671 - accuracy: 0.8667 - val_loss: 0.7978 - val_accuracy: 0.7949\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2660 - accuracy: 0.8593 - val_loss: 0.7841 - val_accuracy: 0.8034\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2680 - accuracy: 0.8630 - val_loss: 0.7772 - val_accuracy: 0.7949\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2658 - accuracy: 0.8630 - val_loss: 0.7692 - val_accuracy: 0.7949\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2622 - accuracy: 0.8593 - val_loss: 0.7740 - val_accuracy: 0.7949\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.7817 - val_accuracy: 0.8034\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2630 - accuracy: 0.8593 - val_loss: 0.7894 - val_accuracy: 0.7949\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2640 - accuracy: 0.8630 - val_loss: 0.7865 - val_accuracy: 0.7949\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2598 - accuracy: 0.8630 - val_loss: 0.7699 - val_accuracy: 0.8120\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2620 - accuracy: 0.8630 - val_loss: 0.7692 - val_accuracy: 0.8120\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2665 - accuracy: 0.8630 - val_loss: 0.7664 - val_accuracy: 0.8034\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 140us/step - loss: 0.2614 - accuracy: 0.8667 - val_loss: 0.7726 - val_accuracy: 0.8034\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2599 - accuracy: 0.8630 - val_loss: 0.7815 - val_accuracy: 0.8034\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2658 - accuracy: 0.8444 - val_loss: 0.7982 - val_accuracy: 0.7778\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2659 - accuracy: 0.8519 - val_loss: 0.7790 - val_accuracy: 0.8034\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2570 - accuracy: 0.8704 - val_loss: 0.7494 - val_accuracy: 0.8034\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2773 - accuracy: 0.8593 - val_loss: 0.7554 - val_accuracy: 0.7949\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2770 - accuracy: 0.8593 - val_loss: 0.7586 - val_accuracy: 0.8034\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.7747 - val_accuracy: 0.8034\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2635 - accuracy: 0.8667 - val_loss: 0.7918 - val_accuracy: 0.7949\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.7815 - val_accuracy: 0.7949\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2629 - accuracy: 0.8556 - val_loss: 0.7699 - val_accuracy: 0.8034\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2587 - accuracy: 0.8630 - val_loss: 0.7789 - val_accuracy: 0.7949\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2683 - accuracy: 0.8370 - val_loss: 0.7904 - val_accuracy: 0.7778\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7633 - val_accuracy: 0.8034\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2686 - accuracy: 0.8630 - val_loss: 0.7662 - val_accuracy: 0.8034\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2772 - accuracy: 0.8667 - val_loss: 0.7771 - val_accuracy: 0.8034\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2694 - accuracy: 0.8593 - val_loss: 0.7478 - val_accuracy: 0.8034\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2680 - accuracy: 0.8630 - val_loss: 0.7650 - val_accuracy: 0.8120\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2642 - accuracy: 0.8630 - val_loss: 0.7700 - val_accuracy: 0.8034\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 0.7658 - val_accuracy: 0.8120\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.7645 - val_accuracy: 0.8034\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.7531 - val_accuracy: 0.8120\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 0.7654 - val_accuracy: 0.8034\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2743 - accuracy: 0.8444 - val_loss: 0.8053 - val_accuracy: 0.7863\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2766 - accuracy: 0.8481 - val_loss: 0.7713 - val_accuracy: 0.7949\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2611 - accuracy: 0.8630 - val_loss: 0.7511 - val_accuracy: 0.8034\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 0.7497 - val_accuracy: 0.8034\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2703 - accuracy: 0.8630 - val_loss: 0.7652 - val_accuracy: 0.8120\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 0.7818 - val_accuracy: 0.7863\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.2695 - accuracy: 0.8481 - val_loss: 0.7723 - val_accuracy: 0.8034\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2594 - accuracy: 0.8667 - val_loss: 0.7564 - val_accuracy: 0.8034\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2697 - accuracy: 0.8593 - val_loss: 0.7558 - val_accuracy: 0.8120\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2684 - accuracy: 0.8630 - val_loss: 0.7639 - val_accuracy: 0.8034\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2612 - accuracy: 0.8630 - val_loss: 0.7596 - val_accuracy: 0.8034\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.7503 - val_accuracy: 0.8120\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2719 - accuracy: 0.8630 - val_loss: 0.7491 - val_accuracy: 0.8120\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2609 - accuracy: 0.8593 - val_loss: 0.7664 - val_accuracy: 0.8034\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.7958 - val_accuracy: 0.7778\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2812 - accuracy: 0.8481 - val_loss: 0.8022 - val_accuracy: 0.7863\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2692 - accuracy: 0.8519 - val_loss: 0.7579 - val_accuracy: 0.8034\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2652 - accuracy: 0.8519 - val_loss: 0.7488 - val_accuracy: 0.8034\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2669 - accuracy: 0.8593 - val_loss: 0.7595 - val_accuracy: 0.8120\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2678 - accuracy: 0.8593 - val_loss: 0.7768 - val_accuracy: 0.8034\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2582 - accuracy: 0.8667 - val_loss: 0.7807 - val_accuracy: 0.8034\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2676 - accuracy: 0.8704 - val_loss: 0.7961 - val_accuracy: 0.7949\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2656 - accuracy: 0.8667 - val_loss: 0.7761 - val_accuracy: 0.8034\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.7553 - val_accuracy: 0.8034\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2624 - accuracy: 0.8444 - val_loss: 0.7405 - val_accuracy: 0.8120\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2665 - accuracy: 0.8556 - val_loss: 0.7493 - val_accuracy: 0.7949\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.7593 - val_accuracy: 0.7949\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.7637 - val_accuracy: 0.8034\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2649 - accuracy: 0.8630 - val_loss: 0.7452 - val_accuracy: 0.7949\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2803 - accuracy: 0.8556 - val_loss: 0.7542 - val_accuracy: 0.7949\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2781 - accuracy: 0.8593 - val_loss: 0.7746 - val_accuracy: 0.8034\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2667 - accuracy: 0.8407 - val_loss: 0.7904 - val_accuracy: 0.7778\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2692 - accuracy: 0.8556 - val_loss: 0.7801 - val_accuracy: 0.8120\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2702 - accuracy: 0.8630 - val_loss: 0.7591 - val_accuracy: 0.7949\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2659 - accuracy: 0.8593 - val_loss: 0.7678 - val_accuracy: 0.8034\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2719 - accuracy: 0.8667 - val_loss: 0.7913 - val_accuracy: 0.8034\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2656 - accuracy: 0.8704 - val_loss: 0.7760 - val_accuracy: 0.7949\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 159us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 0.8099 - val_accuracy: 0.7778\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2743 - accuracy: 0.8481 - val_loss: 0.7920 - val_accuracy: 0.7692\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2639 - accuracy: 0.8444 - val_loss: 0.7547 - val_accuracy: 0.8034\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2656 - accuracy: 0.8593 - val_loss: 0.7504 - val_accuracy: 0.7949\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2662 - accuracy: 0.8630 - val_loss: 0.7620 - val_accuracy: 0.8034\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 0.7841 - val_accuracy: 0.7949\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7923 - val_accuracy: 0.7949\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2655 - accuracy: 0.8593 - val_loss: 0.7817 - val_accuracy: 0.7949\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7858 - val_accuracy: 0.8034\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.7881 - val_accuracy: 0.7949\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.7993 - val_accuracy: 0.7949\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.7934 - val_accuracy: 0.7949\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2597 - accuracy: 0.8630 - val_loss: 0.7742 - val_accuracy: 0.8034\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2644 - accuracy: 0.8630 - val_loss: 0.7645 - val_accuracy: 0.8120\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2639 - accuracy: 0.8519 - val_loss: 0.7666 - val_accuracy: 0.8120\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2597 - accuracy: 0.8667 - val_loss: 0.7717 - val_accuracy: 0.8034\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2671 - accuracy: 0.8593 - val_loss: 0.7918 - val_accuracy: 0.7778\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 174us/step - loss: 0.2732 - accuracy: 0.8444 - val_loss: 0.7802 - val_accuracy: 0.8034\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.2599 - accuracy: 0.8481 - val_loss: 0.7730 - val_accuracy: 0.8120\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 267us/step - loss: 0.2626 - accuracy: 0.8556 - val_loss: 0.7726 - val_accuracy: 0.8034\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 0.7813 - val_accuracy: 0.8034\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2607 - accuracy: 0.8630 - val_loss: 0.7772 - val_accuracy: 0.8034\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 0.7930 - val_accuracy: 0.7778\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 196us/step - loss: 0.2665 - accuracy: 0.8444 - val_loss: 0.7739 - val_accuracy: 0.8034\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.7599 - val_accuracy: 0.8034\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2614 - accuracy: 0.8630 - val_loss: 0.7640 - val_accuracy: 0.7949\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2673 - accuracy: 0.8630 - val_loss: 0.7760 - val_accuracy: 0.7949\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.7643 - val_accuracy: 0.7949\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2610 - accuracy: 0.8741 - val_loss: 0.7603 - val_accuracy: 0.8034\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.7765 - val_accuracy: 0.8120\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.8040 - val_accuracy: 0.7949\n",
      "Epoch 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 77us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.7849 - val_accuracy: 0.8120\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2635 - accuracy: 0.8556 - val_loss: 0.7676 - val_accuracy: 0.8034\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.7706 - val_accuracy: 0.8205\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2635 - accuracy: 0.8593 - val_loss: 0.7692 - val_accuracy: 0.8120\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.7754 - val_accuracy: 0.8120\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2633 - accuracy: 0.8630 - val_loss: 0.7723 - val_accuracy: 0.8120\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.7703 - val_accuracy: 0.8120\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.7548 - val_accuracy: 0.8120\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 204us/step - loss: 0.2699 - accuracy: 0.8556 - val_loss: 0.7531 - val_accuracy: 0.8205\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2655 - accuracy: 0.8519 - val_loss: 0.7673 - val_accuracy: 0.8034\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2597 - accuracy: 0.8667 - val_loss: 0.7824 - val_accuracy: 0.8034\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 0.7948 - val_accuracy: 0.7863\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7925 - val_accuracy: 0.7863\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.7848 - val_accuracy: 0.7949\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2605 - accuracy: 0.8667 - val_loss: 0.7590 - val_accuracy: 0.7949\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.7493 - val_accuracy: 0.8034\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2615 - accuracy: 0.8593 - val_loss: 0.7564 - val_accuracy: 0.7949\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 208us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 0.7646 - val_accuracy: 0.7949\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.7552 - val_accuracy: 0.8034\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2623 - accuracy: 0.8444 - val_loss: 0.7558 - val_accuracy: 0.8034\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2610 - accuracy: 0.8630 - val_loss: 0.7572 - val_accuracy: 0.8034\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2625 - accuracy: 0.8630 - val_loss: 0.7574 - val_accuracy: 0.8034\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2646 - accuracy: 0.8630 - val_loss: 0.7671 - val_accuracy: 0.7949\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 0.7653 - val_accuracy: 0.8120\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2625 - accuracy: 0.8593 - val_loss: 0.7657 - val_accuracy: 0.8034\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 0.7615 - val_accuracy: 0.7949\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2579 - accuracy: 0.8667 - val_loss: 0.7521 - val_accuracy: 0.7949\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2605 - accuracy: 0.8704 - val_loss: 0.7500 - val_accuracy: 0.8034\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2638 - accuracy: 0.8556 - val_loss: 0.7533 - val_accuracy: 0.7949\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 168us/step - loss: 0.2623 - accuracy: 0.8630 - val_loss: 0.7590 - val_accuracy: 0.7949\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.7631 - val_accuracy: 0.7949\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.7636 - val_accuracy: 0.8034\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2599 - accuracy: 0.8667 - val_loss: 0.7661 - val_accuracy: 0.8034\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.7643 - val_accuracy: 0.8034\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7703 - val_accuracy: 0.8034\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7786 - val_accuracy: 0.8034\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2616 - accuracy: 0.8556 - val_loss: 0.7681 - val_accuracy: 0.7949\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2640 - accuracy: 0.8667 - val_loss: 0.7644 - val_accuracy: 0.7949\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2748 - accuracy: 0.8593 - val_loss: 0.7798 - val_accuracy: 0.8034\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2699 - accuracy: 0.8667 - val_loss: 0.7777 - val_accuracy: 0.7949\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 171us/step - loss: 0.2616 - accuracy: 0.8704 - val_loss: 0.7768 - val_accuracy: 0.8034\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7809 - val_accuracy: 0.8034\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 219us/step - loss: 0.2608 - accuracy: 0.8593 - val_loss: 0.7762 - val_accuracy: 0.8034\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2588 - accuracy: 0.8667 - val_loss: 0.7678 - val_accuracy: 0.8034\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2601 - accuracy: 0.8704 - val_loss: 0.7748 - val_accuracy: 0.8120\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2610 - accuracy: 0.8556 - val_loss: 0.7992 - val_accuracy: 0.7863\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7959 - val_accuracy: 0.7949\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2593 - accuracy: 0.8630 - val_loss: 0.7838 - val_accuracy: 0.7949\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2733 - accuracy: 0.8667 - val_loss: 0.7731 - val_accuracy: 0.7949\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2609 - accuracy: 0.8704 - val_loss: 0.7840 - val_accuracy: 0.7949\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2646 - accuracy: 0.8667 - val_loss: 0.8065 - val_accuracy: 0.7949\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2727 - accuracy: 0.8667 - val_loss: 0.7821 - val_accuracy: 0.8034\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2638 - accuracy: 0.8667 - val_loss: 0.7643 - val_accuracy: 0.7949\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2664 - accuracy: 0.8630 - val_loss: 0.7527 - val_accuracy: 0.8034\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2658 - accuracy: 0.8630 - val_loss: 0.7652 - val_accuracy: 0.7949\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2609 - accuracy: 0.8593 - val_loss: 0.7915 - val_accuracy: 0.7863\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7959 - val_accuracy: 0.7949\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2648 - accuracy: 0.8593 - val_loss: 0.7927 - val_accuracy: 0.8034\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7745 - val_accuracy: 0.8034\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2610 - accuracy: 0.8630 - val_loss: 0.7681 - val_accuracy: 0.8034\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2622 - accuracy: 0.8593 - val_loss: 0.7669 - val_accuracy: 0.8120\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2597 - accuracy: 0.8556 - val_loss: 0.7811 - val_accuracy: 0.7949\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2613 - accuracy: 0.8556 - val_loss: 0.7778 - val_accuracy: 0.8120\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2641 - accuracy: 0.8667 - val_loss: 0.7691 - val_accuracy: 0.8034\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2612 - accuracy: 0.8593 - val_loss: 0.7796 - val_accuracy: 0.8034\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.7825 - val_accuracy: 0.8034\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.7826 - val_accuracy: 0.7949\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2596 - accuracy: 0.8778 - val_loss: 0.7812 - val_accuracy: 0.7949\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7729 - val_accuracy: 0.7949\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 0.7727 - val_accuracy: 0.8034\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.84 - 0s 120us/step - loss: 0.2605 - accuracy: 0.8630 - val_loss: 0.7775 - val_accuracy: 0.8034\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 0.7753 - val_accuracy: 0.8034\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.7815 - val_accuracy: 0.8034\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2589 - accuracy: 0.8630 - val_loss: 0.7876 - val_accuracy: 0.8034\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.7760 - val_accuracy: 0.8034\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 263us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7641 - val_accuracy: 0.8034\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2605 - accuracy: 0.8593 - val_loss: 0.7690 - val_accuracy: 0.8034\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2653 - accuracy: 0.8593 - val_loss: 0.7726 - val_accuracy: 0.7949\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2654 - accuracy: 0.8630 - val_loss: 0.7737 - val_accuracy: 0.8034\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7840 - val_accuracy: 0.7949\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2660 - accuracy: 0.8667 - val_loss: 0.7879 - val_accuracy: 0.7949\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2595 - accuracy: 0.8630 - val_loss: 0.7759 - val_accuracy: 0.8034\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 0.7708 - val_accuracy: 0.8120\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2642 - accuracy: 0.8593 - val_loss: 0.7780 - val_accuracy: 0.7949\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2633 - accuracy: 0.8556 - val_loss: 0.7810 - val_accuracy: 0.8034\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 0.7792 - val_accuracy: 0.8034\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.7512 - val_accuracy: 0.8205\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2675 - accuracy: 0.8519 - val_loss: 0.7513 - val_accuracy: 0.8120\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2657 - accuracy: 0.8556 - val_loss: 0.7535 - val_accuracy: 0.8205\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 251us/step - loss: 0.2616 - accuracy: 0.8593 - val_loss: 0.7781 - val_accuracy: 0.7949\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 188us/step - loss: 0.2707 - accuracy: 0.8444 - val_loss: 0.7775 - val_accuracy: 0.8120\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.7652 - val_accuracy: 0.8034\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.7645 - val_accuracy: 0.8120\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2657 - accuracy: 0.8593 - val_loss: 0.7677 - val_accuracy: 0.8034\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 0.7790 - val_accuracy: 0.8034\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 0.7869 - val_accuracy: 0.7949\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.7834 - val_accuracy: 0.7949\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2640 - accuracy: 0.8667 - val_loss: 0.7711 - val_accuracy: 0.8034\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2665 - accuracy: 0.8630 - val_loss: 0.7543 - val_accuracy: 0.7949\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2777 - accuracy: 0.8593 - val_loss: 0.7753 - val_accuracy: 0.8034\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2666 - accuracy: 0.8630 - val_loss: 0.7911 - val_accuracy: 0.7949\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2605 - accuracy: 0.8519 - val_loss: 0.8082 - val_accuracy: 0.7692\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2710 - accuracy: 0.8370 - val_loss: 0.7893 - val_accuracy: 0.7949\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.7707 - val_accuracy: 0.8291\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2655 - accuracy: 0.8630 - val_loss: 0.7613 - val_accuracy: 0.8034\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2674 - accuracy: 0.8593 - val_loss: 0.7744 - val_accuracy: 0.8034\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.7861 - val_accuracy: 0.7949\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7930 - val_accuracy: 0.8034\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2662 - accuracy: 0.8593 - val_loss: 0.7968 - val_accuracy: 0.8034\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2595 - accuracy: 0.8630 - val_loss: 0.7822 - val_accuracy: 0.8034\n",
      "Epoch 610/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 109us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7817 - val_accuracy: 0.8120\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2626 - accuracy: 0.8704 - val_loss: 0.7874 - val_accuracy: 0.8034\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 0.7787 - val_accuracy: 0.8120\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2648 - accuracy: 0.8556 - val_loss: 0.7985 - val_accuracy: 0.8034\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2596 - accuracy: 0.8630 - val_loss: 0.7866 - val_accuracy: 0.8034\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 0.7774 - val_accuracy: 0.8120\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2655 - accuracy: 0.8556 - val_loss: 0.7676 - val_accuracy: 0.8120\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 0.7760 - val_accuracy: 0.8034\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2647 - accuracy: 0.8630 - val_loss: 0.7941 - val_accuracy: 0.8034\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.7877 - val_accuracy: 0.8034\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.7858 - val_accuracy: 0.7949\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 0.7993 - val_accuracy: 0.7949\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.7953 - val_accuracy: 0.7949\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2642 - accuracy: 0.8630 - val_loss: 0.7818 - val_accuracy: 0.8034\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.7953 - val_accuracy: 0.7949\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 242us/step - loss: 0.2629 - accuracy: 0.8667 - val_loss: 0.8070 - val_accuracy: 0.7863\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.8043 - val_accuracy: 0.7863\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 296us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7840 - val_accuracy: 0.7949\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 0.7800 - val_accuracy: 0.7949\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 0.7753 - val_accuracy: 0.7949\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 0.7873 - val_accuracy: 0.7949\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 194us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.7839 - val_accuracy: 0.7949\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2606 - accuracy: 0.8593 - val_loss: 0.7829 - val_accuracy: 0.7949\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.7898 - val_accuracy: 0.7949\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 181us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 0.7872 - val_accuracy: 0.8034\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2581 - accuracy: 0.8667 - val_loss: 0.7827 - val_accuracy: 0.8034\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 216us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 0.7854 - val_accuracy: 0.7949\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.7850 - val_accuracy: 0.8034\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2646 - accuracy: 0.8556 - val_loss: 0.7691 - val_accuracy: 0.8034\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2609 - accuracy: 0.8519 - val_loss: 0.7937 - val_accuracy: 0.7949\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2640 - accuracy: 0.8704 - val_loss: 0.8092 - val_accuracy: 0.8034\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2607 - accuracy: 0.8815 - val_loss: 0.7975 - val_accuracy: 0.8120\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.7892 - val_accuracy: 0.8120\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2706 - accuracy: 0.8667 - val_loss: 0.7932 - val_accuracy: 0.8120\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.8018 - val_accuracy: 0.8034\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.7839 - val_accuracy: 0.7949\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2630 - accuracy: 0.8741 - val_loss: 0.7990 - val_accuracy: 0.7949\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2670 - accuracy: 0.8667 - val_loss: 0.7839 - val_accuracy: 0.8034\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2610 - accuracy: 0.8704 - val_loss: 0.7787 - val_accuracy: 0.7949\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2608 - accuracy: 0.8667 - val_loss: 0.7684 - val_accuracy: 0.8034\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2599 - accuracy: 0.8704 - val_loss: 0.7604 - val_accuracy: 0.8120\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2670 - accuracy: 0.8593 - val_loss: 0.7770 - val_accuracy: 0.8120\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2632 - accuracy: 0.8704 - val_loss: 0.7960 - val_accuracy: 0.8034\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.8013 - val_accuracy: 0.8034\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.7931 - val_accuracy: 0.8034\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.7806 - val_accuracy: 0.8034\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2647 - accuracy: 0.8667 - val_loss: 0.7772 - val_accuracy: 0.8034\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2586 - accuracy: 0.8741 - val_loss: 0.7897 - val_accuracy: 0.7949\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2742 - accuracy: 0.8481 - val_loss: 0.8064 - val_accuracy: 0.7949\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.7769 - val_accuracy: 0.8034\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2613 - accuracy: 0.8630 - val_loss: 0.7703 - val_accuracy: 0.8120\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2651 - accuracy: 0.8741 - val_loss: 0.7801 - val_accuracy: 0.7949\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 0.7885 - val_accuracy: 0.8034\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2633 - accuracy: 0.8667 - val_loss: 0.7774 - val_accuracy: 0.8120\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.7804 - val_accuracy: 0.8034\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2629 - accuracy: 0.8630 - val_loss: 0.7941 - val_accuracy: 0.8034\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2771 - accuracy: 0.8630 - val_loss: 0.7899 - val_accuracy: 0.8034\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2626 - accuracy: 0.8593 - val_loss: 0.7835 - val_accuracy: 0.8034\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2652 - accuracy: 0.8519 - val_loss: 0.7854 - val_accuracy: 0.7778\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 0.7733 - val_accuracy: 0.8120\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2669 - accuracy: 0.8556 - val_loss: 0.7793 - val_accuracy: 0.8120\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7835 - val_accuracy: 0.7949\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7966 - val_accuracy: 0.7949\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.7993 - val_accuracy: 0.7949\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2626 - accuracy: 0.8667 - val_loss: 0.8051 - val_accuracy: 0.8034\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2675 - accuracy: 0.8667 - val_loss: 0.8033 - val_accuracy: 0.8034\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.8037 - val_accuracy: 0.8034\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2654 - accuracy: 0.8407 - val_loss: 0.7955 - val_accuracy: 0.8034\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2679 - accuracy: 0.8481 - val_loss: 0.7757 - val_accuracy: 0.8120\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2601 - accuracy: 0.8630 - val_loss: 0.7772 - val_accuracy: 0.7949\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2609 - accuracy: 0.8593 - val_loss: 0.7777 - val_accuracy: 0.7949\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2590 - accuracy: 0.8667 - val_loss: 0.7932 - val_accuracy: 0.7949\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2611 - accuracy: 0.8630 - val_loss: 0.7975 - val_accuracy: 0.8034\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2646 - accuracy: 0.8630 - val_loss: 0.7797 - val_accuracy: 0.8034\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2678 - accuracy: 0.8630 - val_loss: 0.7922 - val_accuracy: 0.7949\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2659 - accuracy: 0.8667 - val_loss: 0.8039 - val_accuracy: 0.7778\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2617 - accuracy: 0.8741 - val_loss: 0.7918 - val_accuracy: 0.7949\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2675 - accuracy: 0.8667 - val_loss: 0.7775 - val_accuracy: 0.8034\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7696 - val_accuracy: 0.7949\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2698 - accuracy: 0.8667 - val_loss: 0.7812 - val_accuracy: 0.7949\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2664 - accuracy: 0.8630 - val_loss: 0.8033 - val_accuracy: 0.7949\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2651 - accuracy: 0.8667 - val_loss: 0.8110 - val_accuracy: 0.7863\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.7989 - val_accuracy: 0.7863\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2636 - accuracy: 0.8667 - val_loss: 0.7874 - val_accuracy: 0.7949\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2601 - accuracy: 0.8741 - val_loss: 0.7884 - val_accuracy: 0.7949\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7822 - val_accuracy: 0.7949\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2644 - accuracy: 0.8630 - val_loss: 0.7790 - val_accuracy: 0.8120\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2717 - accuracy: 0.8630 - val_loss: 0.7833 - val_accuracy: 0.8034\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.7888 - val_accuracy: 0.7949\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2656 - accuracy: 0.8630 - val_loss: 0.7978 - val_accuracy: 0.8034\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2600 - accuracy: 0.8741 - val_loss: 0.8023 - val_accuracy: 0.8034\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2828 - accuracy: 0.8667 - val_loss: 0.8315 - val_accuracy: 0.7863\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2738 - accuracy: 0.8667 - val_loss: 0.8001 - val_accuracy: 0.7949\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2669 - accuracy: 0.8667 - val_loss: 0.8075 - val_accuracy: 0.7949\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2721 - accuracy: 0.8630 - val_loss: 0.7888 - val_accuracy: 0.7949\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2591 - accuracy: 0.8630 - val_loss: 0.7955 - val_accuracy: 0.7949\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.8018 - val_accuracy: 0.7949\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2656 - accuracy: 0.8667 - val_loss: 0.7937 - val_accuracy: 0.7949\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7882 - val_accuracy: 0.7949\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2593 - accuracy: 0.8704 - val_loss: 0.7833 - val_accuracy: 0.7949\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 0.7800 - val_accuracy: 0.7949\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.7947 - val_accuracy: 0.8034\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2627 - accuracy: 0.8519 - val_loss: 0.7949 - val_accuracy: 0.7949\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2631 - accuracy: 0.8556 - val_loss: 0.7829 - val_accuracy: 0.8120\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 0.7979 - val_accuracy: 0.8034\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.8189 - val_accuracy: 0.7949\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2668 - accuracy: 0.8667 - val_loss: 0.8022 - val_accuracy: 0.7949\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2631 - accuracy: 0.8630 - val_loss: 0.7715 - val_accuracy: 0.8034\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2667 - accuracy: 0.8667 - val_loss: 0.7777 - val_accuracy: 0.8120\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2671 - accuracy: 0.8593 - val_loss: 0.7988 - val_accuracy: 0.7949\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2709 - accuracy: 0.8667 - val_loss: 0.8210 - val_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2684 - accuracy: 0.8444 - val_loss: 0.8144 - val_accuracy: 0.7692\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.7831 - val_accuracy: 0.7949\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2653 - accuracy: 0.8593 - val_loss: 0.7782 - val_accuracy: 0.7949\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2652 - accuracy: 0.8593 - val_loss: 0.7868 - val_accuracy: 0.8120\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.8116 - val_accuracy: 0.7949\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.8037 - val_accuracy: 0.7863\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2607 - accuracy: 0.8667 - val_loss: 0.7886 - val_accuracy: 0.7949\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 0.7899 - val_accuracy: 0.7863\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2602 - accuracy: 0.8630 - val_loss: 0.7864 - val_accuracy: 0.7863\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7713 - val_accuracy: 0.8034\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2629 - accuracy: 0.8556 - val_loss: 0.7853 - val_accuracy: 0.7949\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2608 - accuracy: 0.8667 - val_loss: 0.7985 - val_accuracy: 0.7949\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.8085 - val_accuracy: 0.7949\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 205us/step - loss: 0.2661 - accuracy: 0.8556 - val_loss: 0.8006 - val_accuracy: 0.8034\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2628 - accuracy: 0.8630 - val_loss: 0.7905 - val_accuracy: 0.8120\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2592 - accuracy: 0.8556 - val_loss: 0.7886 - val_accuracy: 0.7949\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.85 - 0s 81us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.7836 - val_accuracy: 0.7949\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2614 - accuracy: 0.8556 - val_loss: 0.7779 - val_accuracy: 0.8120\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 0.7855 - val_accuracy: 0.8034\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2593 - accuracy: 0.8667 - val_loss: 0.8012 - val_accuracy: 0.7949\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.8127 - val_accuracy: 0.7949\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2698 - accuracy: 0.8444 - val_loss: 0.7991 - val_accuracy: 0.7949\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.7741 - val_accuracy: 0.7949\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2731 - accuracy: 0.8667 - val_loss: 0.7664 - val_accuracy: 0.8034\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2678 - accuracy: 0.8630 - val_loss: 0.7786 - val_accuracy: 0.8120\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2654 - accuracy: 0.8593 - val_loss: 0.7859 - val_accuracy: 0.8034\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2590 - accuracy: 0.8667 - val_loss: 0.7926 - val_accuracy: 0.7949\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2592 - accuracy: 0.8667 - val_loss: 0.8003 - val_accuracy: 0.7949\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2656 - accuracy: 0.8370 - val_loss: 0.7967 - val_accuracy: 0.8034\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2693 - accuracy: 0.8593 - val_loss: 0.7844 - val_accuracy: 0.7949\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2649 - accuracy: 0.8593 - val_loss: 0.7865 - val_accuracy: 0.7949\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2624 - accuracy: 0.8630 - val_loss: 0.7999 - val_accuracy: 0.7863\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2587 - accuracy: 0.8667 - val_loss: 0.8159 - val_accuracy: 0.7949\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2637 - accuracy: 0.8667 - val_loss: 0.8206 - val_accuracy: 0.7949\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2628 - accuracy: 0.8667 - val_loss: 0.8222 - val_accuracy: 0.7863\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7973 - val_accuracy: 0.7949\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2641 - accuracy: 0.8630 - val_loss: 0.7913 - val_accuracy: 0.8034\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2620 - accuracy: 0.8630 - val_loss: 0.7912 - val_accuracy: 0.7949\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2597 - accuracy: 0.8630 - val_loss: 0.7878 - val_accuracy: 0.7949\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.7959 - val_accuracy: 0.7863\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2611 - accuracy: 0.8593 - val_loss: 0.8049 - val_accuracy: 0.7863\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2618 - accuracy: 0.8667 - val_loss: 0.7916 - val_accuracy: 0.7949\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2605 - accuracy: 0.8593 - val_loss: 0.7775 - val_accuracy: 0.8034\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 0.7890 - val_accuracy: 0.7949\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 0.7952 - val_accuracy: 0.7949\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.7937 - val_accuracy: 0.8034\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2756 - accuracy: 0.8593 - val_loss: 0.7839 - val_accuracy: 0.7949\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2711 - accuracy: 0.8593 - val_loss: 0.7832 - val_accuracy: 0.8034\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2684 - accuracy: 0.8667 - val_loss: 0.7908 - val_accuracy: 0.8034\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2625 - accuracy: 0.8593 - val_loss: 0.7935 - val_accuracy: 0.8034\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.7947 - val_accuracy: 0.8034\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.7804 - val_accuracy: 0.8034\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7886 - val_accuracy: 0.8034\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.7941 - val_accuracy: 0.8034\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2591 - accuracy: 0.8667 - val_loss: 0.7925 - val_accuracy: 0.8034\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2583 - accuracy: 0.8630 - val_loss: 0.7944 - val_accuracy: 0.7949\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2596 - accuracy: 0.8556 - val_loss: 0.8020 - val_accuracy: 0.7949\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.8197 - val_accuracy: 0.7949\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 0.7880 - val_accuracy: 0.8034\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2726 - accuracy: 0.8630 - val_loss: 0.7870 - val_accuracy: 0.8120\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2732 - accuracy: 0.8630 - val_loss: 0.7842 - val_accuracy: 0.7949\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2662 - accuracy: 0.8630 - val_loss: 0.8018 - val_accuracy: 0.7949\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2700 - accuracy: 0.8630 - val_loss: 0.7796 - val_accuracy: 0.7949\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2643 - accuracy: 0.8556 - val_loss: 0.7940 - val_accuracy: 0.8034\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2685 - accuracy: 0.8333 - val_loss: 0.8318 - val_accuracy: 0.7692\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2659 - accuracy: 0.8556 - val_loss: 0.8093 - val_accuracy: 0.7863\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2580 - accuracy: 0.8667 - val_loss: 0.7950 - val_accuracy: 0.8034\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2606 - accuracy: 0.8630 - val_loss: 0.7816 - val_accuracy: 0.8034\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2693 - accuracy: 0.8667 - val_loss: 0.7816 - val_accuracy: 0.8034\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2701 - accuracy: 0.8667 - val_loss: 0.7998 - val_accuracy: 0.8034\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2615 - accuracy: 0.8667 - val_loss: 0.7986 - val_accuracy: 0.7949\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.7886 - val_accuracy: 0.7949\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.7809 - val_accuracy: 0.8034\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2612 - accuracy: 0.8630 - val_loss: 0.7836 - val_accuracy: 0.7949\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2613 - accuracy: 0.8519 - val_loss: 0.7903 - val_accuracy: 0.7949\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2579 - accuracy: 0.8667 - val_loss: 0.7901 - val_accuracy: 0.7949\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.7829 - val_accuracy: 0.7949\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2581 - accuracy: 0.8667 - val_loss: 0.7864 - val_accuracy: 0.7949\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2612 - accuracy: 0.8667 - val_loss: 0.7927 - val_accuracy: 0.7949\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2589 - accuracy: 0.8704 - val_loss: 0.7806 - val_accuracy: 0.8034\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2615 - accuracy: 0.8630 - val_loss: 0.7766 - val_accuracy: 0.8034\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2601 - accuracy: 0.8630 - val_loss: 0.7839 - val_accuracy: 0.8034\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2619 - accuracy: 0.8630 - val_loss: 0.8032 - val_accuracy: 0.7863\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.7970 - val_accuracy: 0.7949\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2585 - accuracy: 0.8667 - val_loss: 0.8003 - val_accuracy: 0.7949\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2598 - accuracy: 0.8593 - val_loss: 0.7985 - val_accuracy: 0.7949\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.7892 - val_accuracy: 0.8034\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2621 - accuracy: 0.8667 - val_loss: 0.7830 - val_accuracy: 0.8034\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2661 - accuracy: 0.8667 - val_loss: 0.7856 - val_accuracy: 0.8034\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2597 - accuracy: 0.8741 - val_loss: 0.7831 - val_accuracy: 0.8120\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2620 - accuracy: 0.8630 - val_loss: 0.7831 - val_accuracy: 0.8120\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2614 - accuracy: 0.8630 - val_loss: 0.7875 - val_accuracy: 0.7949\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2613 - accuracy: 0.8741 - val_loss: 0.8185 - val_accuracy: 0.7692\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2676 - accuracy: 0.8481 - val_loss: 0.8199 - val_accuracy: 0.7863\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2638 - accuracy: 0.8704 - val_loss: 0.7878 - val_accuracy: 0.8034\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2673 - accuracy: 0.8407 - val_loss: 0.7866 - val_accuracy: 0.7949\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2720 - accuracy: 0.8593 - val_loss: 0.7936 - val_accuracy: 0.7949\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2617 - accuracy: 0.8556 - val_loss: 0.8013 - val_accuracy: 0.7949\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.8043 - val_accuracy: 0.7863\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.7920 - val_accuracy: 0.7949\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.7948 - val_accuracy: 0.7949\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.7903 - val_accuracy: 0.7949\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2595 - accuracy: 0.8481 - val_loss: 0.7874 - val_accuracy: 0.7863\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.7811 - val_accuracy: 0.7949\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2592 - accuracy: 0.8667 - val_loss: 0.7793 - val_accuracy: 0.7949\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2679 - accuracy: 0.8667 - val_loss: 0.7902 - val_accuracy: 0.8034\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2618 - accuracy: 0.8519 - val_loss: 0.8038 - val_accuracy: 0.7949\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2643 - accuracy: 0.8667 - val_loss: 0.8193 - val_accuracy: 0.7863\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2629 - accuracy: 0.8704 - val_loss: 0.8211 - val_accuracy: 0.7949\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2664 - accuracy: 0.8667 - val_loss: 0.8026 - val_accuracy: 0.7949\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2599 - accuracy: 0.8667 - val_loss: 0.8099 - val_accuracy: 0.7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 0.8174 - val_accuracy: 0.7863\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2601 - accuracy: 0.8593 - val_loss: 0.7942 - val_accuracy: 0.7949\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2606 - accuracy: 0.8481 - val_loss: 0.7824 - val_accuracy: 0.8034\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2608 - accuracy: 0.8630 - val_loss: 0.7883 - val_accuracy: 0.8034\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2630 - accuracy: 0.8630 - val_loss: 0.7838 - val_accuracy: 0.8034\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 372us/step - loss: 0.2627 - accuracy: 0.8593 - val_loss: 0.7932 - val_accuracy: 0.8034\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 281us/step - loss: 0.2623 - accuracy: 0.8630 - val_loss: 0.8115 - val_accuracy: 0.7949\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 525us/step - loss: 0.2631 - accuracy: 0.8667 - val_loss: 0.8207 - val_accuracy: 0.7863\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2618 - accuracy: 0.8741 - val_loss: 0.7932 - val_accuracy: 0.7949\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.7924 - val_accuracy: 0.8034\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2635 - accuracy: 0.8630 - val_loss: 0.8120 - val_accuracy: 0.7863\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2655 - accuracy: 0.8667 - val_loss: 0.8128 - val_accuracy: 0.7863\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.8000 - val_accuracy: 0.7863\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2588 - accuracy: 0.8667 - val_loss: 0.8090 - val_accuracy: 0.7863\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 0.7969 - val_accuracy: 0.7949\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.7958 - val_accuracy: 0.7863\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2575 - accuracy: 0.8593 - val_loss: 0.8027 - val_accuracy: 0.7949\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 206us/step - loss: 0.2614 - accuracy: 0.8667 - val_loss: 0.8090 - val_accuracy: 0.7863\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2603 - accuracy: 0.8667 - val_loss: 0.8033 - val_accuracy: 0.7863\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2590 - accuracy: 0.8667 - val_loss: 0.8017 - val_accuracy: 0.7863\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 0.8087 - val_accuracy: 0.7949\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2671 - accuracy: 0.8667 - val_loss: 0.8184 - val_accuracy: 0.7949\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2654 - accuracy: 0.8667 - val_loss: 0.8294 - val_accuracy: 0.7863\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2704 - accuracy: 0.8667 - val_loss: 0.8387 - val_accuracy: 0.7949\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2712 - accuracy: 0.8667 - val_loss: 0.7973 - val_accuracy: 0.8034\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2689 - accuracy: 0.8556 - val_loss: 0.8025 - val_accuracy: 0.7949\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2659 - accuracy: 0.8593 - val_loss: 0.8326 - val_accuracy: 0.7692\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2640 - accuracy: 0.8444 - val_loss: 0.8067 - val_accuracy: 0.7949\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2595 - accuracy: 0.8667 - val_loss: 0.7911 - val_accuracy: 0.7949\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2632 - accuracy: 0.8630 - val_loss: 0.7890 - val_accuracy: 0.7949\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2629 - accuracy: 0.8593 - val_loss: 0.8004 - val_accuracy: 0.7949\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.8015 - val_accuracy: 0.8034\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2635 - accuracy: 0.8667 - val_loss: 0.8078 - val_accuracy: 0.7949\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2592 - accuracy: 0.8704 - val_loss: 0.8083 - val_accuracy: 0.8034\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2616 - accuracy: 0.8630 - val_loss: 0.8036 - val_accuracy: 0.7949\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2632 - accuracy: 0.8667 - val_loss: 0.7930 - val_accuracy: 0.8034\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.7994 - val_accuracy: 0.8120\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2599 - accuracy: 0.8630 - val_loss: 0.7964 - val_accuracy: 0.8120\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2661 - accuracy: 0.8593 - val_loss: 0.7897 - val_accuracy: 0.8120\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2594 - accuracy: 0.8667 - val_loss: 0.7990 - val_accuracy: 0.8034\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2615 - accuracy: 0.8741 - val_loss: 0.8131 - val_accuracy: 0.7949\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2668 - accuracy: 0.8667 - val_loss: 0.8104 - val_accuracy: 0.8034\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2653 - accuracy: 0.8630 - val_loss: 0.8364 - val_accuracy: 0.7863\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2699 - accuracy: 0.8667 - val_loss: 0.8340 - val_accuracy: 0.7949\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 272us/step - loss: 0.2618 - accuracy: 0.8704 - val_loss: 0.8159 - val_accuracy: 0.7949\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.8019 - val_accuracy: 0.8034\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2673 - accuracy: 0.8593 - val_loss: 0.8049 - val_accuracy: 0.8120\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2637 - accuracy: 0.8630 - val_loss: 0.8219 - val_accuracy: 0.7949\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2695 - accuracy: 0.8667 - val_loss: 0.8327 - val_accuracy: 0.7949\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.8396 - val_accuracy: 0.7949\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2662 - accuracy: 0.8556 - val_loss: 0.8438 - val_accuracy: 0.7949\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.8221 - val_accuracy: 0.7949\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2602 - accuracy: 0.8704 - val_loss: 0.8057 - val_accuracy: 0.8034\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2714 - accuracy: 0.8593 - val_loss: 0.7979 - val_accuracy: 0.8034\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2614 - accuracy: 0.8593 - val_loss: 0.8080 - val_accuracy: 0.7949\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2669 - accuracy: 0.8630 - val_loss: 0.8278 - val_accuracy: 0.7949\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2709 - accuracy: 0.8630 - val_loss: 0.8148 - val_accuracy: 0.7949\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2562 - accuracy: 0.8815 - val_loss: 0.8110 - val_accuracy: 0.8034\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2650 - accuracy: 0.8630 - val_loss: 0.8061 - val_accuracy: 0.8034\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2624 - accuracy: 0.8593 - val_loss: 0.8067 - val_accuracy: 0.7863\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2609 - accuracy: 0.8630 - val_loss: 0.8056 - val_accuracy: 0.7863\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 179us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 0.8150 - val_accuracy: 0.7863\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2576 - accuracy: 0.8630 - val_loss: 0.8014 - val_accuracy: 0.8034\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2625 - accuracy: 0.8519 - val_loss: 0.7936 - val_accuracy: 0.8034\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2616 - accuracy: 0.8667 - val_loss: 0.8049 - val_accuracy: 0.8034\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2614 - accuracy: 0.8630 - val_loss: 0.8223 - val_accuracy: 0.7863\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2644 - accuracy: 0.8667 - val_loss: 0.8391 - val_accuracy: 0.7863\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2646 - accuracy: 0.8667 - val_loss: 0.8226 - val_accuracy: 0.7949\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2657 - accuracy: 0.8704 - val_loss: 0.7970 - val_accuracy: 0.8120\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.7946 - val_accuracy: 0.8034\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 294us/step - loss: 0.2601 - accuracy: 0.8630 - val_loss: 0.8101 - val_accuracy: 0.7949\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2635 - accuracy: 0.8667 - val_loss: 0.8172 - val_accuracy: 0.7949\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 0.8042 - val_accuracy: 0.7949\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.7974 - val_accuracy: 0.7949\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2609 - accuracy: 0.8667 - val_loss: 0.8029 - val_accuracy: 0.7863\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2589 - accuracy: 0.8556 - val_loss: 0.8189 - val_accuracy: 0.7863\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.8140 - val_accuracy: 0.7863\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2607 - accuracy: 0.8667 - val_loss: 0.8008 - val_accuracy: 0.7949\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2582 - accuracy: 0.8667 - val_loss: 0.8039 - val_accuracy: 0.7863\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2632 - accuracy: 0.8556 - val_loss: 0.8163 - val_accuracy: 0.7863\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2676 - accuracy: 0.8667 - val_loss: 0.7990 - val_accuracy: 0.7949\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7827 - val_accuracy: 0.7949\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2648 - accuracy: 0.8667 - val_loss: 0.7993 - val_accuracy: 0.8034\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2641 - accuracy: 0.8630 - val_loss: 0.8206 - val_accuracy: 0.7949\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2610 - accuracy: 0.8630 - val_loss: 0.8320 - val_accuracy: 0.7863\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2598 - accuracy: 0.8704 - val_loss: 0.8195 - val_accuracy: 0.7863\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2588 - accuracy: 0.8667 - val_loss: 0.8100 - val_accuracy: 0.7949\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 135us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 0.8036 - val_accuracy: 0.7949\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 225us/step - loss: 0.2658 - accuracy: 0.8667 - val_loss: 0.8130 - val_accuracy: 0.8034\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 453us/step - loss: 0.2634 - accuracy: 0.8630 - val_loss: 0.8173 - val_accuracy: 0.7863\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.8168 - val_accuracy: 0.7863\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2638 - accuracy: 0.8593 - val_loss: 0.8028 - val_accuracy: 0.8034\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2636 - accuracy: 0.8630 - val_loss: 0.8045 - val_accuracy: 0.8034\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2641 - accuracy: 0.8593 - val_loss: 0.8123 - val_accuracy: 0.7949\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2584 - accuracy: 0.8593 - val_loss: 0.8100 - val_accuracy: 0.8034\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2590 - accuracy: 0.8630 - val_loss: 0.8097 - val_accuracy: 0.8034\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2582 - accuracy: 0.8667 - val_loss: 0.8201 - val_accuracy: 0.7863\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2581 - accuracy: 0.8778 - val_loss: 0.8204 - val_accuracy: 0.7949\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.8170 - val_accuracy: 0.7863\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 243us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 0.8276 - val_accuracy: 0.7949\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2647 - accuracy: 0.8556 - val_loss: 0.8394 - val_accuracy: 0.7778\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2646 - accuracy: 0.8630 - val_loss: 0.8165 - val_accuracy: 0.8034\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2639 - accuracy: 0.8630 - val_loss: 0.8051 - val_accuracy: 0.7949\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2686 - accuracy: 0.8593 - val_loss: 0.8105 - val_accuracy: 0.8034\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.2648 - accuracy: 0.8444 - val_loss: 0.8196 - val_accuracy: 0.8034\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2584 - accuracy: 0.8593 - val_loss: 0.8213 - val_accuracy: 0.8034\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2613 - accuracy: 0.8667 - val_loss: 0.8225 - val_accuracy: 0.8034\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2618 - accuracy: 0.8630 - val_loss: 0.8225 - val_accuracy: 0.8034\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2631 - accuracy: 0.8556 - val_loss: 0.8240 - val_accuracy: 0.7949\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2606 - accuracy: 0.8667 - val_loss: 0.8616 - val_accuracy: 0.7949\n",
      "Epoch 942/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 86us/step - loss: 0.2697 - accuracy: 0.8481 - val_loss: 0.8538 - val_accuracy: 0.7863\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.8102 - val_accuracy: 0.7949\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 199us/step - loss: 0.2609 - accuracy: 0.8630 - val_loss: 0.7889 - val_accuracy: 0.8120\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2625 - accuracy: 0.8481 - val_loss: 0.7938 - val_accuracy: 0.8120\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2595 - accuracy: 0.8593 - val_loss: 0.8154 - val_accuracy: 0.7949\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2600 - accuracy: 0.8667 - val_loss: 0.8206 - val_accuracy: 0.7949\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 249us/step - loss: 0.2621 - accuracy: 0.8630 - val_loss: 0.8040 - val_accuracy: 0.8034\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2642 - accuracy: 0.8593 - val_loss: 0.8006 - val_accuracy: 0.8034\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 590us/step - loss: 0.2631 - accuracy: 0.8704 - val_loss: 0.8030 - val_accuracy: 0.8120\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2637 - accuracy: 0.8519 - val_loss: 0.7993 - val_accuracy: 0.8120\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2622 - accuracy: 0.8630 - val_loss: 0.8160 - val_accuracy: 0.7863\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2581 - accuracy: 0.8667 - val_loss: 0.8216 - val_accuracy: 0.7863\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2611 - accuracy: 0.8667 - val_loss: 0.8262 - val_accuracy: 0.7949\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2642 - accuracy: 0.8667 - val_loss: 0.8258 - val_accuracy: 0.8034\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.8240 - val_accuracy: 0.7863\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2608 - accuracy: 0.8704 - val_loss: 0.8239 - val_accuracy: 0.7949\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.8382 - val_accuracy: 0.7863\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 390us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.8452 - val_accuracy: 0.7778\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2660 - accuracy: 0.8630 - val_loss: 0.8174 - val_accuracy: 0.7778\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2637 - accuracy: 0.8704 - val_loss: 0.8057 - val_accuracy: 0.8034\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2626 - accuracy: 0.8630 - val_loss: 0.8201 - val_accuracy: 0.7949\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.8276 - val_accuracy: 0.7949\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2604 - accuracy: 0.8593 - val_loss: 0.8249 - val_accuracy: 0.7949\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 307us/step - loss: 0.2622 - accuracy: 0.8667 - val_loss: 0.8143 - val_accuracy: 0.7949\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2634 - accuracy: 0.8667 - val_loss: 0.8072 - val_accuracy: 0.8034\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2623 - accuracy: 0.8667 - val_loss: 0.8150 - val_accuracy: 0.7949\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2589 - accuracy: 0.8630 - val_loss: 0.8157 - val_accuracy: 0.7949\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 293us/step - loss: 0.2583 - accuracy: 0.8667 - val_loss: 0.8215 - val_accuracy: 0.7949\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2585 - accuracy: 0.8667 - val_loss: 0.8261 - val_accuracy: 0.7949\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2599 - accuracy: 0.8667 - val_loss: 0.8162 - val_accuracy: 0.7949\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 300us/step - loss: 0.2586 - accuracy: 0.8593 - val_loss: 0.8077 - val_accuracy: 0.8034\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2624 - accuracy: 0.8593 - val_loss: 0.8210 - val_accuracy: 0.7949\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 455us/step - loss: 0.2598 - accuracy: 0.8667 - val_loss: 0.8371 - val_accuracy: 0.7863\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 512us/step - loss: 0.2619 - accuracy: 0.8667 - val_loss: 0.8341 - val_accuracy: 0.7863\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2627 - accuracy: 0.8667 - val_loss: 0.8298 - val_accuracy: 0.7863\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2601 - accuracy: 0.8667 - val_loss: 0.8244 - val_accuracy: 0.7863\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2589 - accuracy: 0.8667 - val_loss: 0.8349 - val_accuracy: 0.7863\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2637 - accuracy: 0.8556 - val_loss: 0.8432 - val_accuracy: 0.7949\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2602 - accuracy: 0.8667 - val_loss: 0.8354 - val_accuracy: 0.7863\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 351us/step - loss: 0.2645 - accuracy: 0.8667 - val_loss: 0.8234 - val_accuracy: 0.7949\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2617 - accuracy: 0.8667 - val_loss: 0.8303 - val_accuracy: 0.7863\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2650 - accuracy: 0.8704 - val_loss: 0.8512 - val_accuracy: 0.7863\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.8426 - val_accuracy: 0.7863\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2614 - accuracy: 0.8704 - val_loss: 0.8338 - val_accuracy: 0.7863\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2624 - accuracy: 0.8667 - val_loss: 0.8266 - val_accuracy: 0.7863\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2596 - accuracy: 0.8667 - val_loss: 0.8297 - val_accuracy: 0.7778\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 164us/step - loss: 0.2641 - accuracy: 0.8593 - val_loss: 0.8373 - val_accuracy: 0.7863\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2653 - accuracy: 0.8667 - val_loss: 0.8503 - val_accuracy: 0.7863\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2613 - accuracy: 0.8741 - val_loss: 0.8556 - val_accuracy: 0.7863\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2638 - accuracy: 0.8630 - val_loss: 0.8293 - val_accuracy: 0.7949\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2601 - accuracy: 0.8630 - val_loss: 0.8104 - val_accuracy: 0.7949\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2630 - accuracy: 0.8667 - val_loss: 0.8037 - val_accuracy: 0.8034\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2663 - accuracy: 0.8667 - val_loss: 0.8237 - val_accuracy: 0.7863\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2620 - accuracy: 0.8667 - val_loss: 0.8470 - val_accuracy: 0.7863\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2625 - accuracy: 0.8667 - val_loss: 0.8447 - val_accuracy: 0.7863\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2610 - accuracy: 0.8667 - val_loss: 0.8313 - val_accuracy: 0.7778\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2614 - accuracy: 0.8556 - val_loss: 0.8417 - val_accuracy: 0.7949\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2627 - accuracy: 0.8556 - val_loss: 0.8422 - val_accuracy: 0.7863\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2604 - accuracy: 0.8667 - val_loss: 0.8274 - val_accuracy: 0.7949\n"
     ]
    }
   ],
   "source": [
    "hist2_over3 = model2_over3.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 86.29%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.132076e-01</td>\n",
       "      <td>2.812180e-01</td>\n",
       "      <td>1.055744e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.993202e-04</td>\n",
       "      <td>6.834937e-07</td>\n",
       "      <td>9.998000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>SR4035</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.589463e-01</td>\n",
       "      <td>3.982787e-01</td>\n",
       "      <td>2.427750e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.477194e-01</td>\n",
       "      <td>4.522807e-01</td>\n",
       "      <td>1.761374e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.953657e-05</td>\n",
       "      <td>9.999305e-01</td>\n",
       "      <td>3.132419e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713214e-09</td>\n",
       "      <td>6.656316e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.956684e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.441288e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.958189e-07</td>\n",
       "      <td>1.001001e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage  strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual  NRS210          0           0  6.132076e-01   \n",
       "1     p0006kpresabs_qual  NRS205          2           2  1.993202e-04   \n",
       "2     p0006kpresabs_qual     312          2           1  3.589463e-01   \n",
       "3     p0006kpresabs_qual    GA15          2           1  3.589463e-01   \n",
       "4     p0006kpresabs_qual  SR4035          0           1  3.589463e-01   \n",
       "..                   ...     ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  NRS383          1           0  5.477194e-01   \n",
       "985  p0017Skpresabs_qual  NRS218          1           1  6.953657e-05   \n",
       "986  p0017Skpresabs_qual  NRS209          2           2  2.713214e-09   \n",
       "987  p0017Skpresabs_qual  SR2852          1           1  9.956684e-12   \n",
       "988  p0017Skpresabs_qual  NRS248          0           0  9.999998e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.812180e-01  1.055744e-01  \n",
       "1    6.834937e-07  9.998000e-01  \n",
       "2    3.982787e-01  2.427750e-01  \n",
       "3    3.982787e-01  2.427750e-01  \n",
       "4    3.982787e-01  2.427750e-01  \n",
       "..            ...           ...  \n",
       "984  4.522807e-01  1.761374e-08  \n",
       "985  9.999305e-01  3.132419e-10  \n",
       "986  6.656316e-09  1.000000e+00  \n",
       "987  1.000000e+00  7.441288e-26  \n",
       "988  1.958189e-07  1.001001e-12  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.11726900e-01, 2.88259600e-01, 1.35570260e-05],\n",
       "       [8.64584450e-13, 3.12930700e-12, 1.00000000e+00],\n",
       "       [4.42078150e-07, 2.02627070e-08, 9.99999500e-01],\n",
       "       [1.05034110e-03, 8.90037600e-04, 9.98059600e-01],\n",
       "       [9.98862000e-01, 1.13794590e-03, 1.81274480e-09],\n",
       "       [1.82078290e-03, 1.85080750e-04, 9.97994200e-01],\n",
       "       [9.99999760e-01, 6.61693800e-08, 8.31988100e-08],\n",
       "       [9.55438100e-01, 4.45601600e-02, 1.73015540e-06],\n",
       "       [9.99999900e-01, 8.78319100e-08, 9.45232800e-16],\n",
       "       [9.99964830e-01, 4.30483030e-06, 3.08697930e-05],\n",
       "       [9.20596800e-04, 9.98794900e-01, 2.84447680e-04],\n",
       "       [9.99609530e-01, 3.89117660e-04, 1.47760730e-06],\n",
       "       [9.99926700e-01, 7.32737000e-05, 1.31415840e-11],\n",
       "       [9.99974700e-01, 2.20703840e-05, 3.25563630e-06],\n",
       "       [9.20596800e-04, 9.98794900e-01, 2.84447680e-04],\n",
       "       [3.35391100e-01, 6.57018500e-01, 7.59035670e-03],\n",
       "       [2.65663800e-09, 2.10090070e-05, 9.99979000e-01],\n",
       "       [9.99999170e-01, 8.43095300e-07, 2.68288810e-11],\n",
       "       [1.82078290e-03, 1.85080750e-04, 9.97994200e-01],\n",
       "       [2.41508660e-06, 2.65778870e-08, 9.99997600e-01],\n",
       "       [9.99999900e-01, 1.15692920e-07, 2.33656380e-13],\n",
       "       [9.95635330e-01, 4.34824600e-03, 1.64287400e-05],\n",
       "       [6.12200300e-04, 9.88591730e-01, 1.07961000e-02],\n",
       "       [4.34848800e-04, 7.44748540e-05, 9.99490600e-01],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [3.35391100e-01, 6.57018500e-01, 7.59035670e-03],\n",
       "       [3.25639220e-03, 7.56778800e-01, 2.39964890e-01],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [2.48317580e-07, 1.41311110e-09, 9.99999760e-01],\n",
       "       [9.99943000e-01, 3.60173470e-05, 2.09579610e-05],\n",
       "       [9.95723100e-01, 4.27688000e-03, 5.30510570e-09],\n",
       "       [9.99938700e-01, 5.23157900e-06, 5.60552140e-05],\n",
       "       [9.99964500e-01, 3.49876800e-05, 4.84113570e-07],\n",
       "       [1.24947070e-03, 9.96835530e-01, 1.91493540e-03],\n",
       "       [3.35391100e-01, 6.57018500e-01, 7.59035670e-03],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [5.38281440e-01, 4.58372740e-01, 3.34584670e-03],\n",
       "       [9.30221800e-01, 6.97782600e-02, 2.17415950e-11],\n",
       "       [4.42078150e-07, 2.02627070e-08, 9.99999500e-01],\n",
       "       [9.95304940e-01, 4.63813300e-03, 5.69409700e-05],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [1.35751500e-04, 1.35054250e-03, 9.98513760e-01],\n",
       "       [1.05034110e-03, 8.90037600e-04, 9.98059600e-01],\n",
       "       [3.25639220e-03, 7.56778800e-01, 2.39964890e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [6.48465750e-03, 9.93513700e-01, 1.62648130e-06],\n",
       "       [4.42078150e-07, 2.02627070e-08, 9.99999500e-01],\n",
       "       [9.99983200e-01, 1.68045660e-05, 2.76634130e-10],\n",
       "       [9.75046900e-01, 2.11217370e-02, 3.83144270e-03],\n",
       "       [7.11726900e-01, 2.88259600e-01, 1.35570260e-05],\n",
       "       [9.95236750e-01, 4.76316740e-03, 3.66461170e-08],\n",
       "       [9.73712150e-01, 2.62872000e-02, 7.05125560e-07],\n",
       "       [9.55438100e-01, 4.45601600e-02, 1.73015540e-06],\n",
       "       [3.35391100e-01, 6.57018500e-01, 7.59035670e-03],\n",
       "       [9.99320270e-01, 5.75956700e-09, 6.79777470e-04],\n",
       "       [1.66490850e-01, 1.31812410e-02, 8.20327900e-01],\n",
       "       [1.03150140e-09, 1.08692930e-06, 9.99998900e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [9.09880500e-04, 2.44424600e-04, 9.98845700e-01],\n",
       "       [1.82078290e-03, 1.85080750e-04, 9.97994200e-01],\n",
       "       [2.80179720e-04, 9.87836300e-01, 1.18835205e-02],\n",
       "       [2.30480300e-02, 7.21910700e-01, 2.55041360e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [2.65663800e-09, 2.10090070e-05, 9.99979000e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [1.07879770e-06, 1.19901694e-01, 8.80097200e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [1.14990020e-02, 9.83871340e-01, 4.62967800e-03],\n",
       "       [3.17459570e-09, 1.02854030e-02, 9.89714560e-01],\n",
       "       [1.43000430e-03, 9.97823830e-01, 7.46201260e-04],\n",
       "       [9.99967200e-01, 3.28153870e-05, 5.88472800e-13],\n",
       "       [2.01135330e-13, 2.57649340e-13, 1.00000000e+00],\n",
       "       [1.14990020e-02, 9.83871340e-01, 4.62967800e-03],\n",
       "       [1.03150140e-09, 1.08692930e-06, 9.99998900e-01],\n",
       "       [1.14162010e-02, 9.88569000e-01, 1.47923110e-05],\n",
       "       [1.82078290e-03, 1.85080750e-04, 9.97994200e-01],\n",
       "       [1.39739700e-03, 9.97426900e-01, 1.17565280e-03],\n",
       "       [1.80900220e-05, 6.17327700e-01, 3.82654200e-01],\n",
       "       [8.64584450e-13, 3.12930700e-12, 1.00000000e+00],\n",
       "       [1.90380010e-08, 5.91127700e-04, 9.99408840e-01],\n",
       "       [9.35324670e-01, 6.45890900e-02, 8.61367200e-05],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [9.35324670e-01, 6.45890900e-02, 8.61367200e-05],\n",
       "       [5.65150300e-04, 3.25418080e-03, 9.96180650e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [2.78119990e-05, 9.93043070e-01, 6.92911700e-03],\n",
       "       [9.99964500e-01, 3.49876800e-05, 4.84113570e-07],\n",
       "       [1.90380010e-08, 5.91127700e-04, 9.99408840e-01],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [1.76677180e-02, 9.82330800e-01, 1.53467650e-06],\n",
       "       [9.65782900e-03, 9.90332070e-01, 1.00614570e-05],\n",
       "       [3.73631540e-07, 1.52712900e-05, 9.99984400e-01],\n",
       "       [4.71373380e-04, 4.54170080e-01, 5.45358600e-01],\n",
       "       [5.82151600e-04, 5.47531600e-01, 4.51886200e-01],\n",
       "       [2.01135330e-13, 2.57649340e-13, 1.00000000e+00],\n",
       "       [3.91071500e-03, 9.96064250e-01, 2.51034900e-05],\n",
       "       [3.25639220e-03, 7.56778800e-01, 2.39964890e-01],\n",
       "       [1.01423410e-03, 9.38804500e-01, 6.01811700e-02],\n",
       "       [4.42078150e-07, 2.02627070e-08, 9.99999500e-01],\n",
       "       [9.99882000e-01, 1.18019090e-04, 9.58419700e-10],\n",
       "       [3.25639220e-03, 7.56778800e-01, 2.39964890e-01],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [9.99233250e-01, 7.66818400e-04, 2.38419480e-12],\n",
       "       [1.55826910e-01, 4.73903000e-01, 3.70270070e-01],\n",
       "       [1.82078290e-03, 1.85080750e-04, 9.97994200e-01],\n",
       "       [5.12906070e-03, 3.12596000e-06, 9.94867800e-01],\n",
       "       [6.25037600e-04, 1.76376130e-03, 9.97611170e-01],\n",
       "       [1.07879770e-06, 1.19901694e-01, 8.80097200e-01],\n",
       "       [6.25037600e-04, 1.76376130e-03, 9.97611170e-01],\n",
       "       [1.04171660e-04, 1.09993634e-04, 9.99785840e-01],\n",
       "       [1.41901280e-01, 8.72888900e-04, 8.57225840e-01],\n",
       "       [4.75978800e-06, 3.11427800e-06, 9.99992130e-01],\n",
       "       [5.93137740e-01, 3.55406250e-01, 5.14559560e-02],\n",
       "       [3.25639220e-03, 7.56778800e-01, 2.39964890e-01],\n",
       "       [3.17459570e-09, 1.02854030e-02, 9.89714560e-01],\n",
       "       [1.07879770e-06, 1.19901694e-01, 8.80097200e-01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9037913653298268"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9037913653298268"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train_over, X_sel_test_over, y_sel_train_over, y_sel_test_over = train_test_split(X_sel_over, y_sel_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test_over[:,-1])\n",
    "dat8['test'] = y_sel_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS236     1\n",
       "1      NRS113     2\n",
       "2    CFBRSa23     0\n",
       "3      NRS249     2\n",
       "4         107     1\n",
       "..        ...   ...\n",
       "112     NY439     2\n",
       "113    NRS106     0\n",
       "114       221     0\n",
       "115    NRS386     2\n",
       "116  CFBRSa03     1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train_over = X_sel_train_over[:,:-1]\n",
    "X_sel_test_over = X_sel_test_over[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 467us/step - loss: 1.0203 - accuracy: 0.4630 - val_loss: 1.0255 - val_accuracy: 0.4274\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.9843 - accuracy: 0.4444 - val_loss: 0.9999 - val_accuracy: 0.4444\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.9620 - accuracy: 0.5185 - val_loss: 0.9818 - val_accuracy: 0.5043\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.9404 - accuracy: 0.5407 - val_loss: 0.9678 - val_accuracy: 0.5726\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.9204 - accuracy: 0.5889 - val_loss: 0.9587 - val_accuracy: 0.5556\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.9033 - accuracy: 0.5889 - val_loss: 0.9492 - val_accuracy: 0.5556\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.8864 - accuracy: 0.5889 - val_loss: 0.9401 - val_accuracy: 0.5556\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.8748 - accuracy: 0.5889 - val_loss: 0.9335 - val_accuracy: 0.5556\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.8631 - accuracy: 0.5889 - val_loss: 0.9292 - val_accuracy: 0.5556\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.8525 - accuracy: 0.5926 - val_loss: 0.9293 - val_accuracy: 0.5556\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.8434 - accuracy: 0.5926 - val_loss: 0.9298 - val_accuracy: 0.5556\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.8368 - accuracy: 0.5963 - val_loss: 0.9287 - val_accuracy: 0.5556\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.8285 - accuracy: 0.6037 - val_loss: 0.9228 - val_accuracy: 0.5556\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.8225 - accuracy: 0.5963 - val_loss: 0.9160 - val_accuracy: 0.5812\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.8140 - accuracy: 0.6148 - val_loss: 0.9127 - val_accuracy: 0.5812\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.8059 - accuracy: 0.6185 - val_loss: 0.9081 - val_accuracy: 0.5812\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.7989 - accuracy: 0.6259 - val_loss: 0.9042 - val_accuracy: 0.5641\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.7925 - accuracy: 0.6259 - val_loss: 0.9021 - val_accuracy: 0.5556\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7879 - accuracy: 0.6185 - val_loss: 0.9015 - val_accuracy: 0.5470\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7807 - accuracy: 0.6296 - val_loss: 0.8951 - val_accuracy: 0.5812\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.7751 - accuracy: 0.6444 - val_loss: 0.8896 - val_accuracy: 0.5897\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.7706 - accuracy: 0.6481 - val_loss: 0.8867 - val_accuracy: 0.5897\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.7639 - accuracy: 0.6481 - val_loss: 0.8870 - val_accuracy: 0.5812\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.7599 - accuracy: 0.6519 - val_loss: 0.8848 - val_accuracy: 0.5812\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.7546 - accuracy: 0.6593 - val_loss: 0.8802 - val_accuracy: 0.5641\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7497 - accuracy: 0.6630 - val_loss: 0.8740 - val_accuracy: 0.5897\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.7444 - accuracy: 0.6704 - val_loss: 0.8701 - val_accuracy: 0.5556\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.7395 - accuracy: 0.6852 - val_loss: 0.8666 - val_accuracy: 0.5897\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.7331 - accuracy: 0.6815 - val_loss: 0.8653 - val_accuracy: 0.6068\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.7291 - accuracy: 0.6815 - val_loss: 0.8631 - val_accuracy: 0.6068\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.7240 - accuracy: 0.6926 - val_loss: 0.8604 - val_accuracy: 0.6325\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.7193 - accuracy: 0.7000 - val_loss: 0.8575 - val_accuracy: 0.6239\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.7147 - accuracy: 0.7074 - val_loss: 0.8554 - val_accuracy: 0.5897\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.7101 - accuracy: 0.7222 - val_loss: 0.8538 - val_accuracy: 0.5812\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.7066 - accuracy: 0.7222 - val_loss: 0.8517 - val_accuracy: 0.5812\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.7015 - accuracy: 0.7185 - val_loss: 0.8507 - val_accuracy: 0.5897\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.6960 - accuracy: 0.7185 - val_loss: 0.8477 - val_accuracy: 0.5897\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.6926 - accuracy: 0.7222 - val_loss: 0.8454 - val_accuracy: 0.5812\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.6875 - accuracy: 0.7222 - val_loss: 0.8407 - val_accuracy: 0.5897\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.6834 - accuracy: 0.7185 - val_loss: 0.8382 - val_accuracy: 0.5812\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.6800 - accuracy: 0.7222 - val_loss: 0.8339 - val_accuracy: 0.5812\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.6756 - accuracy: 0.7259 - val_loss: 0.8315 - val_accuracy: 0.5812\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.6726 - accuracy: 0.7296 - val_loss: 0.8304 - val_accuracy: 0.5983\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.6669 - accuracy: 0.7259 - val_loss: 0.8306 - val_accuracy: 0.6068\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.6652 - accuracy: 0.7333 - val_loss: 0.8302 - val_accuracy: 0.5983\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.6623 - accuracy: 0.7333 - val_loss: 0.8276 - val_accuracy: 0.6068\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.6563 - accuracy: 0.7259 - val_loss: 0.8294 - val_accuracy: 0.5897\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 493us/step - loss: 0.6558 - accuracy: 0.7296 - val_loss: 0.8304 - val_accuracy: 0.5897\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.6526 - accuracy: 0.7296 - val_loss: 0.8241 - val_accuracy: 0.5897\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6484 - accuracy: 0.7296 - val_loss: 0.8210 - val_accuracy: 0.5897\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.6441 - accuracy: 0.7333 - val_loss: 0.8172 - val_accuracy: 0.6068\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.6401 - accuracy: 0.7407 - val_loss: 0.8145 - val_accuracy: 0.5983\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6379 - accuracy: 0.7519 - val_loss: 0.8133 - val_accuracy: 0.6239\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.6355 - accuracy: 0.7481 - val_loss: 0.8126 - val_accuracy: 0.6325\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.6334 - accuracy: 0.7519 - val_loss: 0.8133 - val_accuracy: 0.6325\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.6292 - accuracy: 0.7519 - val_loss: 0.8102 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.6259 - accuracy: 0.7519 - val_loss: 0.8094 - val_accuracy: 0.6325\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.6230 - accuracy: 0.7481 - val_loss: 0.8087 - val_accuracy: 0.5983\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.6197 - accuracy: 0.7370 - val_loss: 0.8077 - val_accuracy: 0.6068\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.6169 - accuracy: 0.7370 - val_loss: 0.8048 - val_accuracy: 0.6410\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.6140 - accuracy: 0.7444 - val_loss: 0.8034 - val_accuracy: 0.6410\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.6112 - accuracy: 0.7519 - val_loss: 0.8020 - val_accuracy: 0.6410\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.6101 - accuracy: 0.7630 - val_loss: 0.7986 - val_accuracy: 0.6581\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.6067 - accuracy: 0.7630 - val_loss: 0.7972 - val_accuracy: 0.6325\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.6051 - accuracy: 0.7481 - val_loss: 0.7976 - val_accuracy: 0.5983\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.6028 - accuracy: 0.7481 - val_loss: 0.7945 - val_accuracy: 0.5983\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5997 - accuracy: 0.7519 - val_loss: 0.7928 - val_accuracy: 0.5983\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5972 - accuracy: 0.7630 - val_loss: 0.7891 - val_accuracy: 0.6581\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5955 - accuracy: 0.7630 - val_loss: 0.7883 - val_accuracy: 0.6581\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.5938 - accuracy: 0.7704 - val_loss: 0.7876 - val_accuracy: 0.6581\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5894 - accuracy: 0.7704 - val_loss: 0.7875 - val_accuracy: 0.6667\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.5870 - accuracy: 0.7704 - val_loss: 0.7880 - val_accuracy: 0.6496\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.5857 - accuracy: 0.7741 - val_loss: 0.7857 - val_accuracy: 0.6496\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.5830 - accuracy: 0.7741 - val_loss: 0.7847 - val_accuracy: 0.6581\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.5805 - accuracy: 0.7667 - val_loss: 0.7844 - val_accuracy: 0.6581\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.5779 - accuracy: 0.7667 - val_loss: 0.7876 - val_accuracy: 0.6667\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5773 - accuracy: 0.7741 - val_loss: 0.7901 - val_accuracy: 0.6581\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5738 - accuracy: 0.7704 - val_loss: 0.7895 - val_accuracy: 0.6581\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5712 - accuracy: 0.7741 - val_loss: 0.7891 - val_accuracy: 0.6667\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.5689 - accuracy: 0.7852 - val_loss: 0.7895 - val_accuracy: 0.6581\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.5686 - accuracy: 0.7704 - val_loss: 0.7929 - val_accuracy: 0.6496\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5676 - accuracy: 0.7704 - val_loss: 0.7905 - val_accuracy: 0.6581\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.5632 - accuracy: 0.7741 - val_loss: 0.7897 - val_accuracy: 0.6581\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.5617 - accuracy: 0.7741 - val_loss: 0.7876 - val_accuracy: 0.6581\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.5591 - accuracy: 0.7889 - val_loss: 0.7870 - val_accuracy: 0.6667\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.5611 - accuracy: 0.7852 - val_loss: 0.7864 - val_accuracy: 0.6667\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.5558 - accuracy: 0.7815 - val_loss: 0.7838 - val_accuracy: 0.6667\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.5526 - accuracy: 0.7852 - val_loss: 0.7838 - val_accuracy: 0.6667\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.5507 - accuracy: 0.7852 - val_loss: 0.7836 - val_accuracy: 0.6667\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.5489 - accuracy: 0.7926 - val_loss: 0.7819 - val_accuracy: 0.6667\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.5474 - accuracy: 0.7926 - val_loss: 0.7805 - val_accuracy: 0.6667\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.5448 - accuracy: 0.7926 - val_loss: 0.7807 - val_accuracy: 0.6667\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.5448 - accuracy: 0.7926 - val_loss: 0.7797 - val_accuracy: 0.6667\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5411 - accuracy: 0.7889 - val_loss: 0.7786 - val_accuracy: 0.6667\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.5401 - accuracy: 0.7889 - val_loss: 0.7784 - val_accuracy: 0.6752\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.5392 - accuracy: 0.7852 - val_loss: 0.7796 - val_accuracy: 0.6667\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.5372 - accuracy: 0.7815 - val_loss: 0.7791 - val_accuracy: 0.6667\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.5353 - accuracy: 0.7815 - val_loss: 0.7773 - val_accuracy: 0.6667\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5332 - accuracy: 0.7815 - val_loss: 0.7757 - val_accuracy: 0.6667\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.5307 - accuracy: 0.7815 - val_loss: 0.7726 - val_accuracy: 0.6667\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5294 - accuracy: 0.7815 - val_loss: 0.7702 - val_accuracy: 0.6752\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.5277 - accuracy: 0.7963 - val_loss: 0.7714 - val_accuracy: 0.6752\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.5263 - accuracy: 0.7963 - val_loss: 0.7741 - val_accuracy: 0.6752\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.5275 - accuracy: 0.8000 - val_loss: 0.7756 - val_accuracy: 0.6667\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.5245 - accuracy: 0.8000 - val_loss: 0.7768 - val_accuracy: 0.6667\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.5242 - accuracy: 0.8000 - val_loss: 0.7775 - val_accuracy: 0.6667\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.5210 - accuracy: 0.7852 - val_loss: 0.7760 - val_accuracy: 0.6752\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5176 - accuracy: 0.8000 - val_loss: 0.7765 - val_accuracy: 0.6752\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5202 - accuracy: 0.8000 - val_loss: 0.7790 - val_accuracy: 0.6667\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.5181 - accuracy: 0.8074 - val_loss: 0.7777 - val_accuracy: 0.6667\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.5156 - accuracy: 0.8037 - val_loss: 0.7771 - val_accuracy: 0.6667\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5124 - accuracy: 0.8000 - val_loss: 0.7774 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.5118 - accuracy: 0.7926 - val_loss: 0.7767 - val_accuracy: 0.6752\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5100 - accuracy: 0.7963 - val_loss: 0.7762 - val_accuracy: 0.6667\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.5091 - accuracy: 0.8037 - val_loss: 0.7771 - val_accuracy: 0.6667\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.5076 - accuracy: 0.8000 - val_loss: 0.7772 - val_accuracy: 0.6667\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.5062 - accuracy: 0.8000 - val_loss: 0.7755 - val_accuracy: 0.6667\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.5043 - accuracy: 0.7963 - val_loss: 0.7765 - val_accuracy: 0.6667\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.5046 - accuracy: 0.8000 - val_loss: 0.7770 - val_accuracy: 0.6667\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.5020 - accuracy: 0.8074 - val_loss: 0.7772 - val_accuracy: 0.6667\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.5000 - accuracy: 0.8074 - val_loss: 0.7746 - val_accuracy: 0.6667\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4988 - accuracy: 0.8037 - val_loss: 0.7717 - val_accuracy: 0.6667\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4998 - accuracy: 0.8074 - val_loss: 0.7732 - val_accuracy: 0.6667\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.4967 - accuracy: 0.8037 - val_loss: 0.7742 - val_accuracy: 0.6667\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.4957 - accuracy: 0.7963 - val_loss: 0.7745 - val_accuracy: 0.6667\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4944 - accuracy: 0.8000 - val_loss: 0.7745 - val_accuracy: 0.6667\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4935 - accuracy: 0.8000 - val_loss: 0.7799 - val_accuracy: 0.6667\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.4930 - accuracy: 0.7963 - val_loss: 0.7812 - val_accuracy: 0.6667\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4928 - accuracy: 0.8037 - val_loss: 0.7827 - val_accuracy: 0.6667\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4899 - accuracy: 0.8074 - val_loss: 0.7816 - val_accuracy: 0.6923\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.4912 - accuracy: 0.8111 - val_loss: 0.7813 - val_accuracy: 0.7009\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4874 - accuracy: 0.8148 - val_loss: 0.7763 - val_accuracy: 0.6923\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4912 - accuracy: 0.8000 - val_loss: 0.7774 - val_accuracy: 0.6752\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4864 - accuracy: 0.8000 - val_loss: 0.7746 - val_accuracy: 0.6923\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.4820 - accuracy: 0.8148 - val_loss: 0.7731 - val_accuracy: 0.6923\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4817 - accuracy: 0.8148 - val_loss: 0.7726 - val_accuracy: 0.6923\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.4829 - accuracy: 0.8074 - val_loss: 0.7742 - val_accuracy: 0.6923\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4804 - accuracy: 0.8074 - val_loss: 0.7728 - val_accuracy: 0.6923\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4781 - accuracy: 0.8148 - val_loss: 0.7746 - val_accuracy: 0.6923\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.4765 - accuracy: 0.8148 - val_loss: 0.7775 - val_accuracy: 0.6923\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4768 - accuracy: 0.8185 - val_loss: 0.7793 - val_accuracy: 0.6923\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4785 - accuracy: 0.8185 - val_loss: 0.7740 - val_accuracy: 0.6923\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.4748 - accuracy: 0.8222 - val_loss: 0.7681 - val_accuracy: 0.6923\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.4726 - accuracy: 0.8148 - val_loss: 0.7656 - val_accuracy: 0.6923\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4724 - accuracy: 0.8037 - val_loss: 0.7689 - val_accuracy: 0.6923\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4714 - accuracy: 0.8074 - val_loss: 0.7727 - val_accuracy: 0.6923\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4720 - accuracy: 0.8148 - val_loss: 0.7734 - val_accuracy: 0.6923\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.4700 - accuracy: 0.8111 - val_loss: 0.7689 - val_accuracy: 0.6923\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4679 - accuracy: 0.8111 - val_loss: 0.7669 - val_accuracy: 0.6923\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.4668 - accuracy: 0.8148 - val_loss: 0.7691 - val_accuracy: 0.6923\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4659 - accuracy: 0.8185 - val_loss: 0.7716 - val_accuracy: 0.6923\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4652 - accuracy: 0.8185 - val_loss: 0.7714 - val_accuracy: 0.6923\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.4641 - accuracy: 0.8185 - val_loss: 0.7730 - val_accuracy: 0.7009\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.4637 - accuracy: 0.8148 - val_loss: 0.7743 - val_accuracy: 0.6923\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.4616 - accuracy: 0.8148 - val_loss: 0.7738 - val_accuracy: 0.6923\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.4596 - accuracy: 0.8222 - val_loss: 0.7712 - val_accuracy: 0.6923\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4590 - accuracy: 0.8222 - val_loss: 0.7712 - val_accuracy: 0.6923\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.4577 - accuracy: 0.8222 - val_loss: 0.7730 - val_accuracy: 0.6923\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.4566 - accuracy: 0.8185 - val_loss: 0.7753 - val_accuracy: 0.6923\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.4564 - accuracy: 0.8148 - val_loss: 0.7776 - val_accuracy: 0.6923\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4558 - accuracy: 0.8222 - val_loss: 0.7780 - val_accuracy: 0.7009\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4566 - accuracy: 0.8185 - val_loss: 0.7794 - val_accuracy: 0.6923\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4530 - accuracy: 0.8185 - val_loss: 0.7802 - val_accuracy: 0.6923\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4580 - accuracy: 0.8074 - val_loss: 0.7855 - val_accuracy: 0.6923\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.4546 - accuracy: 0.8074 - val_loss: 0.7829 - val_accuracy: 0.6923\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4528 - accuracy: 0.8148 - val_loss: 0.7826 - val_accuracy: 0.6923\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4510 - accuracy: 0.8148 - val_loss: 0.7827 - val_accuracy: 0.6923\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4493 - accuracy: 0.8222 - val_loss: 0.7840 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.4496 - accuracy: 0.8296 - val_loss: 0.7821 - val_accuracy: 0.6838\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4509 - accuracy: 0.8296 - val_loss: 0.7831 - val_accuracy: 0.6923\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.4488 - accuracy: 0.8185 - val_loss: 0.7826 - val_accuracy: 0.7009\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4470 - accuracy: 0.8148 - val_loss: 0.7824 - val_accuracy: 0.7009\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.4469 - accuracy: 0.8185 - val_loss: 0.7854 - val_accuracy: 0.7009\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4453 - accuracy: 0.8259 - val_loss: 0.7802 - val_accuracy: 0.7009\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4447 - accuracy: 0.8222 - val_loss: 0.7741 - val_accuracy: 0.7094\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.4434 - accuracy: 0.8259 - val_loss: 0.7724 - val_accuracy: 0.7094\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4418 - accuracy: 0.8370 - val_loss: 0.7723 - val_accuracy: 0.7094\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4418 - accuracy: 0.8259 - val_loss: 0.7725 - val_accuracy: 0.7009\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4427 - accuracy: 0.8222 - val_loss: 0.7740 - val_accuracy: 0.7009\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4401 - accuracy: 0.8296 - val_loss: 0.7745 - val_accuracy: 0.7094\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4379 - accuracy: 0.8407 - val_loss: 0.7772 - val_accuracy: 0.7094\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.4394 - accuracy: 0.8333 - val_loss: 0.7819 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4386 - accuracy: 0.8222 - val_loss: 0.7807 - val_accuracy: 0.7009\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4354 - accuracy: 0.8370 - val_loss: 0.7772 - val_accuracy: 0.7009\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4400 - accuracy: 0.8259 - val_loss: 0.7767 - val_accuracy: 0.6923\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4410 - accuracy: 0.8333 - val_loss: 0.7717 - val_accuracy: 0.6923\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4360 - accuracy: 0.8296 - val_loss: 0.7700 - val_accuracy: 0.7009\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4349 - accuracy: 0.8148 - val_loss: 0.7729 - val_accuracy: 0.7009\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4335 - accuracy: 0.8222 - val_loss: 0.7718 - val_accuracy: 0.7009\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4314 - accuracy: 0.8296 - val_loss: 0.7727 - val_accuracy: 0.7009\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4296 - accuracy: 0.8296 - val_loss: 0.7770 - val_accuracy: 0.7094\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4328 - accuracy: 0.8296 - val_loss: 0.7774 - val_accuracy: 0.7094\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.4304 - accuracy: 0.8333 - val_loss: 0.7769 - val_accuracy: 0.7094\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4293 - accuracy: 0.8333 - val_loss: 0.7824 - val_accuracy: 0.7094\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4277 - accuracy: 0.8296 - val_loss: 0.7814 - val_accuracy: 0.6923\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.4286 - accuracy: 0.8370 - val_loss: 0.7820 - val_accuracy: 0.6923\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.7824 - val_accuracy: 0.7094\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4273 - accuracy: 0.8407 - val_loss: 0.7838 - val_accuracy: 0.7094\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4253 - accuracy: 0.8333 - val_loss: 0.7790 - val_accuracy: 0.7094\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4246 - accuracy: 0.8333 - val_loss: 0.7764 - val_accuracy: 0.7009\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.4231 - accuracy: 0.8296 - val_loss: 0.7767 - val_accuracy: 0.6923\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4241 - accuracy: 0.8370 - val_loss: 0.7788 - val_accuracy: 0.6923\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4236 - accuracy: 0.8370 - val_loss: 0.7817 - val_accuracy: 0.7009\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4235 - accuracy: 0.8407 - val_loss: 0.7839 - val_accuracy: 0.7094\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4205 - accuracy: 0.8407 - val_loss: 0.7818 - val_accuracy: 0.7009\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.4237 - accuracy: 0.8333 - val_loss: 0.7817 - val_accuracy: 0.6923\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.4224 - accuracy: 0.8333 - val_loss: 0.7823 - val_accuracy: 0.6923\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.4213 - accuracy: 0.8296 - val_loss: 0.7844 - val_accuracy: 0.7094\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.4193 - accuracy: 0.8370 - val_loss: 0.7882 - val_accuracy: 0.7094\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4203 - accuracy: 0.8370 - val_loss: 0.7889 - val_accuracy: 0.7094\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.4212 - accuracy: 0.8333 - val_loss: 0.7864 - val_accuracy: 0.7094\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4214 - accuracy: 0.8296 - val_loss: 0.7802 - val_accuracy: 0.7009\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4172 - accuracy: 0.8333 - val_loss: 0.7763 - val_accuracy: 0.7094\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.4149 - accuracy: 0.8407 - val_loss: 0.7771 - val_accuracy: 0.7009\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4159 - accuracy: 0.8333 - val_loss: 0.7764 - val_accuracy: 0.7009\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4139 - accuracy: 0.8407 - val_loss: 0.7781 - val_accuracy: 0.7009\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4135 - accuracy: 0.8370 - val_loss: 0.7815 - val_accuracy: 0.7009\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4121 - accuracy: 0.8370 - val_loss: 0.7858 - val_accuracy: 0.7009\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.4118 - accuracy: 0.8333 - val_loss: 0.7929 - val_accuracy: 0.7009\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.4115 - accuracy: 0.8370 - val_loss: 0.7924 - val_accuracy: 0.7009\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4103 - accuracy: 0.8370 - val_loss: 0.7901 - val_accuracy: 0.7009\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4091 - accuracy: 0.8370 - val_loss: 0.7903 - val_accuracy: 0.7009\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.4092 - accuracy: 0.8370 - val_loss: 0.7895 - val_accuracy: 0.6923\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.4111 - accuracy: 0.8370 - val_loss: 0.7878 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4096 - accuracy: 0.8296 - val_loss: 0.7859 - val_accuracy: 0.6923\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4072 - accuracy: 0.8370 - val_loss: 0.7887 - val_accuracy: 0.7009\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4064 - accuracy: 0.8407 - val_loss: 0.7922 - val_accuracy: 0.7009\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4074 - accuracy: 0.8407 - val_loss: 0.7882 - val_accuracy: 0.7009\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.4056 - accuracy: 0.8519 - val_loss: 0.7871 - val_accuracy: 0.7009\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4060 - accuracy: 0.8556 - val_loss: 0.7859 - val_accuracy: 0.7009\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.4047 - accuracy: 0.8519 - val_loss: 0.7852 - val_accuracy: 0.7009\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.4023 - accuracy: 0.8444 - val_loss: 0.7888 - val_accuracy: 0.7009\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4048 - accuracy: 0.8444 - val_loss: 0.7930 - val_accuracy: 0.7009\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.4032 - accuracy: 0.8407 - val_loss: 0.7937 - val_accuracy: 0.7009\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4009 - accuracy: 0.8407 - val_loss: 0.7926 - val_accuracy: 0.7009\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4015 - accuracy: 0.8407 - val_loss: 0.7917 - val_accuracy: 0.7009\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.4062 - accuracy: 0.8407 - val_loss: 0.7897 - val_accuracy: 0.6923\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.4014 - accuracy: 0.8407 - val_loss: 0.7960 - val_accuracy: 0.7009\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.4028 - accuracy: 0.8370 - val_loss: 0.8069 - val_accuracy: 0.7094\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.4015 - accuracy: 0.8481 - val_loss: 0.8067 - val_accuracy: 0.7094\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3987 - accuracy: 0.8481 - val_loss: 0.8008 - val_accuracy: 0.7009\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.4024 - accuracy: 0.8556 - val_loss: 0.7963 - val_accuracy: 0.7009\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3972 - accuracy: 0.8481 - val_loss: 0.7940 - val_accuracy: 0.7009\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3994 - accuracy: 0.8444 - val_loss: 0.7938 - val_accuracy: 0.7094\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3994 - accuracy: 0.8481 - val_loss: 0.7968 - val_accuracy: 0.7094\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.4000 - accuracy: 0.8556 - val_loss: 0.7997 - val_accuracy: 0.7094\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3976 - accuracy: 0.8556 - val_loss: 0.7975 - val_accuracy: 0.7094\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3945 - accuracy: 0.8481 - val_loss: 0.7955 - val_accuracy: 0.7094\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3930 - accuracy: 0.8556 - val_loss: 0.7973 - val_accuracy: 0.7009\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3928 - accuracy: 0.8556 - val_loss: 0.7986 - val_accuracy: 0.7009\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3946 - accuracy: 0.8630 - val_loss: 0.7990 - val_accuracy: 0.7009\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3934 - accuracy: 0.8519 - val_loss: 0.8005 - val_accuracy: 0.7009\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3948 - accuracy: 0.8593 - val_loss: 0.8030 - val_accuracy: 0.7094\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3921 - accuracy: 0.8593 - val_loss: 0.7952 - val_accuracy: 0.7094\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3906 - accuracy: 0.8556 - val_loss: 0.7932 - val_accuracy: 0.7094\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.3906 - accuracy: 0.8519 - val_loss: 0.7966 - val_accuracy: 0.7094\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.3908 - accuracy: 0.8519 - val_loss: 0.7988 - val_accuracy: 0.7094\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3911 - accuracy: 0.8481 - val_loss: 0.8002 - val_accuracy: 0.7094\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3919 - accuracy: 0.8519 - val_loss: 0.8025 - val_accuracy: 0.7094\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.3871 - accuracy: 0.8630 - val_loss: 0.7952 - val_accuracy: 0.7094\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3878 - accuracy: 0.8556 - val_loss: 0.7941 - val_accuracy: 0.7009\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3892 - accuracy: 0.8630 - val_loss: 0.7947 - val_accuracy: 0.7094\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3868 - accuracy: 0.8519 - val_loss: 0.7997 - val_accuracy: 0.7094\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3862 - accuracy: 0.8556 - val_loss: 0.8040 - val_accuracy: 0.7094\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3857 - accuracy: 0.8593 - val_loss: 0.8065 - val_accuracy: 0.7009\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3869 - accuracy: 0.8667 - val_loss: 0.8050 - val_accuracy: 0.7009\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3863 - accuracy: 0.8630 - val_loss: 0.8095 - val_accuracy: 0.7179\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3865 - accuracy: 0.8556 - val_loss: 0.8044 - val_accuracy: 0.7094\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3841 - accuracy: 0.8630 - val_loss: 0.7977 - val_accuracy: 0.7094\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3827 - accuracy: 0.8630 - val_loss: 0.8032 - val_accuracy: 0.7094\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3817 - accuracy: 0.8593 - val_loss: 0.8137 - val_accuracy: 0.7094\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3822 - accuracy: 0.8593 - val_loss: 0.8111 - val_accuracy: 0.7094\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3836 - accuracy: 0.8593 - val_loss: 0.8095 - val_accuracy: 0.7009\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.3815 - accuracy: 0.8630 - val_loss: 0.8167 - val_accuracy: 0.7094\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3818 - accuracy: 0.8593 - val_loss: 0.8184 - val_accuracy: 0.7094\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3813 - accuracy: 0.8593 - val_loss: 0.8100 - val_accuracy: 0.7009\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3788 - accuracy: 0.8593 - val_loss: 0.8100 - val_accuracy: 0.7009\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3795 - accuracy: 0.8630 - val_loss: 0.8116 - val_accuracy: 0.7009\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3785 - accuracy: 0.8593 - val_loss: 0.8115 - val_accuracy: 0.7094\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3790 - accuracy: 0.8556 - val_loss: 0.8133 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3776 - accuracy: 0.8630 - val_loss: 0.8165 - val_accuracy: 0.7094\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3780 - accuracy: 0.8593 - val_loss: 0.8194 - val_accuracy: 0.7094\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3777 - accuracy: 0.8630 - val_loss: 0.8161 - val_accuracy: 0.7009\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3775 - accuracy: 0.8630 - val_loss: 0.8198 - val_accuracy: 0.7094\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3760 - accuracy: 0.8667 - val_loss: 0.8219 - val_accuracy: 0.7094\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3769 - accuracy: 0.8667 - val_loss: 0.8180 - val_accuracy: 0.7009\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3766 - accuracy: 0.8667 - val_loss: 0.8178 - val_accuracy: 0.7094\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3765 - accuracy: 0.8593 - val_loss: 0.8281 - val_accuracy: 0.7094\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3760 - accuracy: 0.8593 - val_loss: 0.8275 - val_accuracy: 0.7094\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3766 - accuracy: 0.8593 - val_loss: 0.8297 - val_accuracy: 0.7094\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3754 - accuracy: 0.8593 - val_loss: 0.8261 - val_accuracy: 0.7094\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3739 - accuracy: 0.8630 - val_loss: 0.8297 - val_accuracy: 0.7094\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3726 - accuracy: 0.8667 - val_loss: 0.8304 - val_accuracy: 0.7009\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3718 - accuracy: 0.8704 - val_loss: 0.8265 - val_accuracy: 0.7009\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.3741 - accuracy: 0.8630 - val_loss: 0.8253 - val_accuracy: 0.7094\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3746 - accuracy: 0.8630 - val_loss: 0.8269 - val_accuracy: 0.7009\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3730 - accuracy: 0.8667 - val_loss: 0.8350 - val_accuracy: 0.7094\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3728 - accuracy: 0.8704 - val_loss: 0.8320 - val_accuracy: 0.7094\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3703 - accuracy: 0.8667 - val_loss: 0.8302 - val_accuracy: 0.7094\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3695 - accuracy: 0.8667 - val_loss: 0.8306 - val_accuracy: 0.7094\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3698 - accuracy: 0.8667 - val_loss: 0.8345 - val_accuracy: 0.7094\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3701 - accuracy: 0.8667 - val_loss: 0.8302 - val_accuracy: 0.7094\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3680 - accuracy: 0.8667 - val_loss: 0.8297 - val_accuracy: 0.7094\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3675 - accuracy: 0.8778 - val_loss: 0.8325 - val_accuracy: 0.7094\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3680 - accuracy: 0.8704 - val_loss: 0.8311 - val_accuracy: 0.7094\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3676 - accuracy: 0.8704 - val_loss: 0.8288 - val_accuracy: 0.7094\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3671 - accuracy: 0.8667 - val_loss: 0.8308 - val_accuracy: 0.7094\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3669 - accuracy: 0.8741 - val_loss: 0.8325 - val_accuracy: 0.7094\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.3667 - accuracy: 0.8741 - val_loss: 0.8239 - val_accuracy: 0.7009\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.3678 - accuracy: 0.8778 - val_loss: 0.8223 - val_accuracy: 0.7009\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3676 - accuracy: 0.8704 - val_loss: 0.8287 - val_accuracy: 0.7094\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3664 - accuracy: 0.8704 - val_loss: 0.8367 - val_accuracy: 0.7094\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3666 - accuracy: 0.8741 - val_loss: 0.8353 - val_accuracy: 0.7094\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3663 - accuracy: 0.8778 - val_loss: 0.8279 - val_accuracy: 0.7009\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3689 - accuracy: 0.8667 - val_loss: 0.8287 - val_accuracy: 0.7009\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3668 - accuracy: 0.8741 - val_loss: 0.8342 - val_accuracy: 0.7094\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3643 - accuracy: 0.8778 - val_loss: 0.8384 - val_accuracy: 0.7094\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 231us/step - loss: 0.3632 - accuracy: 0.8778 - val_loss: 0.8329 - val_accuracy: 0.7094\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.3620 - accuracy: 0.8667 - val_loss: 0.8309 - val_accuracy: 0.7009\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3628 - accuracy: 0.8667 - val_loss: 0.8348 - val_accuracy: 0.7009\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3631 - accuracy: 0.8778 - val_loss: 0.8349 - val_accuracy: 0.7009\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3614 - accuracy: 0.8778 - val_loss: 0.8394 - val_accuracy: 0.7009\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.3616 - accuracy: 0.8741 - val_loss: 0.8425 - val_accuracy: 0.7009\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.3599 - accuracy: 0.8741 - val_loss: 0.8483 - val_accuracy: 0.7009\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3627 - accuracy: 0.8778 - val_loss: 0.8527 - val_accuracy: 0.7009\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3628 - accuracy: 0.8778 - val_loss: 0.8480 - val_accuracy: 0.7009\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.3598 - accuracy: 0.8704 - val_loss: 0.8486 - val_accuracy: 0.7094\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3597 - accuracy: 0.8704 - val_loss: 0.8542 - val_accuracy: 0.7094\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.3627 - accuracy: 0.8630 - val_loss: 0.8573 - val_accuracy: 0.7009\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3598 - accuracy: 0.8667 - val_loss: 0.8536 - val_accuracy: 0.7009\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3599 - accuracy: 0.8778 - val_loss: 0.8431 - val_accuracy: 0.7009\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3584 - accuracy: 0.8778 - val_loss: 0.8405 - val_accuracy: 0.7009\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3574 - accuracy: 0.8815 - val_loss: 0.8428 - val_accuracy: 0.7094\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 124us/step - loss: 0.3588 - accuracy: 0.8741 - val_loss: 0.8492 - val_accuracy: 0.7094\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3591 - accuracy: 0.8667 - val_loss: 0.8493 - val_accuracy: 0.7094\n",
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3607 - accuracy: 0.8667 - val_loss: 0.8499 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3563 - accuracy: 0.8667 - val_loss: 0.8501 - val_accuracy: 0.7094\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3563 - accuracy: 0.8778 - val_loss: 0.8487 - val_accuracy: 0.7094\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3552 - accuracy: 0.8741 - val_loss: 0.8463 - val_accuracy: 0.7009\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3554 - accuracy: 0.8741 - val_loss: 0.8510 - val_accuracy: 0.7094\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3535 - accuracy: 0.8741 - val_loss: 0.8575 - val_accuracy: 0.7179\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3565 - accuracy: 0.8741 - val_loss: 0.8608 - val_accuracy: 0.7179\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3579 - accuracy: 0.8741 - val_loss: 0.8507 - val_accuracy: 0.7094\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3534 - accuracy: 0.8741 - val_loss: 0.8599 - val_accuracy: 0.7179\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3545 - accuracy: 0.8704 - val_loss: 0.8596 - val_accuracy: 0.7179\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3532 - accuracy: 0.8778 - val_loss: 0.8542 - val_accuracy: 0.7094\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3530 - accuracy: 0.8778 - val_loss: 0.8500 - val_accuracy: 0.7009\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.3522 - accuracy: 0.8778 - val_loss: 0.8513 - val_accuracy: 0.7009\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.3540 - accuracy: 0.8741 - val_loss: 0.8591 - val_accuracy: 0.7094\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3531 - accuracy: 0.8778 - val_loss: 0.8578 - val_accuracy: 0.7094\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3534 - accuracy: 0.8741 - val_loss: 0.8512 - val_accuracy: 0.7009\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.3620 - accuracy: 0.8556 - val_loss: 0.8512 - val_accuracy: 0.7094\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3574 - accuracy: 0.8630 - val_loss: 0.8507 - val_accuracy: 0.7094\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3552 - accuracy: 0.8741 - val_loss: 0.8717 - val_accuracy: 0.6581\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3560 - accuracy: 0.8593 - val_loss: 0.8639 - val_accuracy: 0.7179\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3525 - accuracy: 0.8778 - val_loss: 0.8568 - val_accuracy: 0.7094\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3499 - accuracy: 0.8778 - val_loss: 0.8559 - val_accuracy: 0.7094\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3505 - accuracy: 0.8778 - val_loss: 0.8594 - val_accuracy: 0.7094\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3523 - accuracy: 0.8778 - val_loss: 0.8584 - val_accuracy: 0.7094\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3492 - accuracy: 0.8778 - val_loss: 0.8615 - val_accuracy: 0.7094\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3482 - accuracy: 0.8778 - val_loss: 0.8652 - val_accuracy: 0.7094\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3478 - accuracy: 0.8778 - val_loss: 0.8604 - val_accuracy: 0.7009\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3495 - accuracy: 0.8667 - val_loss: 0.8609 - val_accuracy: 0.7094\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3494 - accuracy: 0.8741 - val_loss: 0.8611 - val_accuracy: 0.7094\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.3483 - accuracy: 0.8778 - val_loss: 0.8614 - val_accuracy: 0.7094\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3475 - accuracy: 0.8778 - val_loss: 0.8582 - val_accuracy: 0.7094\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3471 - accuracy: 0.8778 - val_loss: 0.8574 - val_accuracy: 0.7009\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3445 - accuracy: 0.8778 - val_loss: 0.8705 - val_accuracy: 0.7094\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.3524 - accuracy: 0.8815 - val_loss: 0.8760 - val_accuracy: 0.7094\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3483 - accuracy: 0.8778 - val_loss: 0.8590 - val_accuracy: 0.7009\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3454 - accuracy: 0.8778 - val_loss: 0.8609 - val_accuracy: 0.7009\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.8683 - val_accuracy: 0.7094\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3462 - accuracy: 0.8815 - val_loss: 0.8736 - val_accuracy: 0.7179\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3435 - accuracy: 0.8741 - val_loss: 0.8601 - val_accuracy: 0.7009\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.8563 - val_accuracy: 0.7009\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3478 - accuracy: 0.8778 - val_loss: 0.8631 - val_accuracy: 0.7179\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3453 - accuracy: 0.8778 - val_loss: 0.8621 - val_accuracy: 0.7094\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3434 - accuracy: 0.8778 - val_loss: 0.8589 - val_accuracy: 0.7094\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.8647 - val_accuracy: 0.7094\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3450 - accuracy: 0.8778 - val_loss: 0.8693 - val_accuracy: 0.7094\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3445 - accuracy: 0.8778 - val_loss: 0.8676 - val_accuracy: 0.7094\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3431 - accuracy: 0.8778 - val_loss: 0.8631 - val_accuracy: 0.7009\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3420 - accuracy: 0.8778 - val_loss: 0.8644 - val_accuracy: 0.7009\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3421 - accuracy: 0.8778 - val_loss: 0.8685 - val_accuracy: 0.7094\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3455 - accuracy: 0.8815 - val_loss: 0.8737 - val_accuracy: 0.7094\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3432 - accuracy: 0.8852 - val_loss: 0.8686 - val_accuracy: 0.7094\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3414 - accuracy: 0.8815 - val_loss: 0.8654 - val_accuracy: 0.7094\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3406 - accuracy: 0.8815 - val_loss: 0.8643 - val_accuracy: 0.7094\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3407 - accuracy: 0.8778 - val_loss: 0.8643 - val_accuracy: 0.7094\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3425 - accuracy: 0.8778 - val_loss: 0.8589 - val_accuracy: 0.7094\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3413 - accuracy: 0.8778 - val_loss: 0.8607 - val_accuracy: 0.7179\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3399 - accuracy: 0.8778 - val_loss: 0.8671 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3413 - accuracy: 0.8778 - val_loss: 0.8638 - val_accuracy: 0.7179\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3397 - accuracy: 0.8778 - val_loss: 0.8677 - val_accuracy: 0.7179\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3398 - accuracy: 0.8778 - val_loss: 0.8745 - val_accuracy: 0.7179\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3421 - accuracy: 0.8704 - val_loss: 0.8840 - val_accuracy: 0.7265\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3406 - accuracy: 0.8815 - val_loss: 0.8692 - val_accuracy: 0.7094\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3387 - accuracy: 0.8778 - val_loss: 0.8680 - val_accuracy: 0.7094\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3408 - accuracy: 0.8741 - val_loss: 0.8681 - val_accuracy: 0.7094\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3392 - accuracy: 0.8778 - val_loss: 0.8754 - val_accuracy: 0.7094\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3381 - accuracy: 0.8778 - val_loss: 0.8866 - val_accuracy: 0.6667\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3404 - accuracy: 0.8741 - val_loss: 0.8876 - val_accuracy: 0.6667\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3382 - accuracy: 0.8889 - val_loss: 0.8741 - val_accuracy: 0.7094\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3370 - accuracy: 0.8778 - val_loss: 0.8654 - val_accuracy: 0.7009\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3384 - accuracy: 0.8741 - val_loss: 0.8641 - val_accuracy: 0.7094\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3370 - accuracy: 0.8741 - val_loss: 0.8689 - val_accuracy: 0.7094\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3360 - accuracy: 0.8778 - val_loss: 0.8687 - val_accuracy: 0.7094\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3367 - accuracy: 0.8778 - val_loss: 0.8701 - val_accuracy: 0.7094\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3360 - accuracy: 0.8778 - val_loss: 0.8725 - val_accuracy: 0.7094\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3359 - accuracy: 0.8778 - val_loss: 0.8804 - val_accuracy: 0.7179\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3357 - accuracy: 0.8778 - val_loss: 0.8790 - val_accuracy: 0.7094\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3376 - accuracy: 0.8704 - val_loss: 0.8752 - val_accuracy: 0.7009\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3369 - accuracy: 0.8778 - val_loss: 0.8797 - val_accuracy: 0.7009\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3360 - accuracy: 0.8778 - val_loss: 0.8835 - val_accuracy: 0.7009\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3338 - accuracy: 0.8778 - val_loss: 0.8818 - val_accuracy: 0.7009\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3341 - accuracy: 0.8778 - val_loss: 0.8821 - val_accuracy: 0.7009\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3353 - accuracy: 0.8778 - val_loss: 0.8837 - val_accuracy: 0.7009\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3343 - accuracy: 0.8741 - val_loss: 0.8836 - val_accuracy: 0.7094\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3339 - accuracy: 0.8778 - val_loss: 0.8870 - val_accuracy: 0.7094\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3360 - accuracy: 0.8778 - val_loss: 0.9000 - val_accuracy: 0.7094\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3353 - accuracy: 0.8741 - val_loss: 0.8896 - val_accuracy: 0.7009\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3340 - accuracy: 0.8815 - val_loss: 0.8889 - val_accuracy: 0.7009\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3327 - accuracy: 0.8815 - val_loss: 0.8920 - val_accuracy: 0.7179\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3314 - accuracy: 0.8815 - val_loss: 0.8886 - val_accuracy: 0.7094\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3311 - accuracy: 0.8815 - val_loss: 0.8843 - val_accuracy: 0.7094\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3344 - accuracy: 0.8778 - val_loss: 0.8830 - val_accuracy: 0.7094\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3328 - accuracy: 0.8778 - val_loss: 0.8902 - val_accuracy: 0.7094\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3318 - accuracy: 0.8815 - val_loss: 0.8860 - val_accuracy: 0.7094\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3310 - accuracy: 0.8778 - val_loss: 0.8880 - val_accuracy: 0.7094\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3308 - accuracy: 0.8778 - val_loss: 0.8936 - val_accuracy: 0.7094\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3304 - accuracy: 0.8815 - val_loss: 0.8973 - val_accuracy: 0.7179\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3314 - accuracy: 0.8815 - val_loss: 0.9006 - val_accuracy: 0.7265\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3306 - accuracy: 0.8778 - val_loss: 0.8958 - val_accuracy: 0.7094\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3323 - accuracy: 0.8815 - val_loss: 0.8894 - val_accuracy: 0.7009\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.3342 - accuracy: 0.8815 - val_loss: 0.8949 - val_accuracy: 0.7094\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3321 - accuracy: 0.8815 - val_loss: 0.9008 - val_accuracy: 0.7094\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3319 - accuracy: 0.8815 - val_loss: 0.8981 - val_accuracy: 0.7009\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3257 - accuracy: 0.8778 - val_loss: 0.8905 - val_accuracy: 0.7009\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3323 - accuracy: 0.8741 - val_loss: 0.8912 - val_accuracy: 0.7009\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3335 - accuracy: 0.8741 - val_loss: 0.8887 - val_accuracy: 0.7009\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3301 - accuracy: 0.8778 - val_loss: 0.8840 - val_accuracy: 0.7009\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3294 - accuracy: 0.8815 - val_loss: 0.8858 - val_accuracy: 0.7094\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3299 - accuracy: 0.8815 - val_loss: 0.8884 - val_accuracy: 0.7094\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3302 - accuracy: 0.8815 - val_loss: 0.8942 - val_accuracy: 0.7094\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3277 - accuracy: 0.8815 - val_loss: 0.8858 - val_accuracy: 0.7009\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3280 - accuracy: 0.8778 - val_loss: 0.8902 - val_accuracy: 0.7009\n",
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3278 - accuracy: 0.8778 - val_loss: 0.8982 - val_accuracy: 0.7009\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3260 - accuracy: 0.8815 - val_loss: 0.8957 - val_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3270 - accuracy: 0.8815 - val_loss: 0.8928 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3283 - accuracy: 0.8778 - val_loss: 0.8916 - val_accuracy: 0.7009\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3254 - accuracy: 0.8815 - val_loss: 0.9002 - val_accuracy: 0.7009\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3273 - accuracy: 0.8815 - val_loss: 0.9018 - val_accuracy: 0.7009\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3259 - accuracy: 0.8778 - val_loss: 0.8984 - val_accuracy: 0.7179\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3270 - accuracy: 0.8778 - val_loss: 0.8951 - val_accuracy: 0.7179\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3298 - accuracy: 0.8778 - val_loss: 0.8905 - val_accuracy: 0.7094\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3257 - accuracy: 0.8815 - val_loss: 0.9028 - val_accuracy: 0.7094\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3263 - accuracy: 0.8815 - val_loss: 0.9144 - val_accuracy: 0.7265\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3276 - accuracy: 0.8815 - val_loss: 0.9170 - val_accuracy: 0.7094\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 44us/step - loss: 0.3273 - accuracy: 0.8778 - val_loss: 0.9133 - val_accuracy: 0.7179\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3270 - accuracy: 0.8778 - val_loss: 0.9106 - val_accuracy: 0.7094\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3260 - accuracy: 0.8741 - val_loss: 0.9074 - val_accuracy: 0.7009\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3252 - accuracy: 0.8815 - val_loss: 0.9151 - val_accuracy: 0.7009\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3253 - accuracy: 0.8815 - val_loss: 0.9086 - val_accuracy: 0.7009\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3238 - accuracy: 0.8815 - val_loss: 0.9115 - val_accuracy: 0.7094\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3254 - accuracy: 0.8815 - val_loss: 0.9150 - val_accuracy: 0.7094\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 42us/step - loss: 0.3233 - accuracy: 0.8815 - val_loss: 0.9049 - val_accuracy: 0.7009\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3243 - accuracy: 0.8778 - val_loss: 0.9048 - val_accuracy: 0.7009\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3244 - accuracy: 0.8778 - val_loss: 0.9083 - val_accuracy: 0.7009\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3231 - accuracy: 0.8778 - val_loss: 0.9098 - val_accuracy: 0.7009\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3237 - accuracy: 0.8815 - val_loss: 0.9231 - val_accuracy: 0.7179\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.3248 - accuracy: 0.8815 - val_loss: 0.9171 - val_accuracy: 0.7094\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3228 - accuracy: 0.8815 - val_loss: 0.9096 - val_accuracy: 0.7009\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3220 - accuracy: 0.8815 - val_loss: 0.9124 - val_accuracy: 0.7009\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3221 - accuracy: 0.8815 - val_loss: 0.9129 - val_accuracy: 0.7009\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 39us/step - loss: 0.3219 - accuracy: 0.8815 - val_loss: 0.9094 - val_accuracy: 0.7009\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3231 - accuracy: 0.8815 - val_loss: 0.9026 - val_accuracy: 0.7094\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3256 - accuracy: 0.8778 - val_loss: 0.9021 - val_accuracy: 0.7094\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3220 - accuracy: 0.8815 - val_loss: 0.9067 - val_accuracy: 0.7094\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3216 - accuracy: 0.8815 - val_loss: 0.9059 - val_accuracy: 0.7179\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3236 - accuracy: 0.8815 - val_loss: 0.9026 - val_accuracy: 0.7179\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3221 - accuracy: 0.8778 - val_loss: 0.8964 - val_accuracy: 0.7094\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3251 - accuracy: 0.8778 - val_loss: 0.8960 - val_accuracy: 0.7094\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.3224 - accuracy: 0.8815 - val_loss: 0.9058 - val_accuracy: 0.7265\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 46us/step - loss: 0.3230 - accuracy: 0.8815 - val_loss: 0.9110 - val_accuracy: 0.7265\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 43us/step - loss: 0.3247 - accuracy: 0.8778 - val_loss: 0.9074 - val_accuracy: 0.7009\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3216 - accuracy: 0.8778 - val_loss: 0.9105 - val_accuracy: 0.7009\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 41us/step - loss: 0.3212 - accuracy: 0.8815 - val_loss: 0.9204 - val_accuracy: 0.7350\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.3202 - accuracy: 0.8815 - val_loss: 0.9229 - val_accuracy: 0.7265\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.3199 - accuracy: 0.8815 - val_loss: 0.9178 - val_accuracy: 0.7265\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3189 - accuracy: 0.8815 - val_loss: 0.9230 - val_accuracy: 0.7265\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3192 - accuracy: 0.8815 - val_loss: 0.9265 - val_accuracy: 0.7179\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3195 - accuracy: 0.8815 - val_loss: 0.9178 - val_accuracy: 0.7094\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3195 - accuracy: 0.8815 - val_loss: 0.9164 - val_accuracy: 0.7094\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3184 - accuracy: 0.8815 - val_loss: 0.9178 - val_accuracy: 0.7094\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3173 - accuracy: 0.8815 - val_loss: 0.9254 - val_accuracy: 0.7094\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3192 - accuracy: 0.8852 - val_loss: 0.9265 - val_accuracy: 0.7265\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3198 - accuracy: 0.8815 - val_loss: 0.9186 - val_accuracy: 0.7265\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3180 - accuracy: 0.8815 - val_loss: 0.9146 - val_accuracy: 0.7265\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3212 - accuracy: 0.8815 - val_loss: 0.9063 - val_accuracy: 0.7265\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3211 - accuracy: 0.8815 - val_loss: 0.9064 - val_accuracy: 0.7265\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3207 - accuracy: 0.8815 - val_loss: 0.9175 - val_accuracy: 0.7265\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3171 - accuracy: 0.8815 - val_loss: 0.9131 - val_accuracy: 0.7265\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3158 - accuracy: 0.8815 - val_loss: 0.9168 - val_accuracy: 0.7265\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3164 - accuracy: 0.8815 - val_loss: 0.9213 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 0.9243 - val_accuracy: 0.7179\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3166 - accuracy: 0.8815 - val_loss: 0.9343 - val_accuracy: 0.7350\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3164 - accuracy: 0.8778 - val_loss: 0.9360 - val_accuracy: 0.7179\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3157 - accuracy: 0.8815 - val_loss: 0.9371 - val_accuracy: 0.7179\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3162 - accuracy: 0.8778 - val_loss: 0.9363 - val_accuracy: 0.7350\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3160 - accuracy: 0.8815 - val_loss: 0.9338 - val_accuracy: 0.7265\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3148 - accuracy: 0.8815 - val_loss: 0.9373 - val_accuracy: 0.7265\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 0.9335 - val_accuracy: 0.7265\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3172 - accuracy: 0.8815 - val_loss: 0.9294 - val_accuracy: 0.7265\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3163 - accuracy: 0.8778 - val_loss: 0.9239 - val_accuracy: 0.7094\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3151 - accuracy: 0.8815 - val_loss: 0.9281 - val_accuracy: 0.7179\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3160 - accuracy: 0.8815 - val_loss: 0.9230 - val_accuracy: 0.7094\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3188 - accuracy: 0.8815 - val_loss: 0.9276 - val_accuracy: 0.7094\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.3176 - accuracy: 0.8815 - val_loss: 0.9446 - val_accuracy: 0.7179\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.3151 - accuracy: 0.8815 - val_loss: 0.9449 - val_accuracy: 0.7094\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.3167 - accuracy: 0.8741 - val_loss: 0.9482 - val_accuracy: 0.7179\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.3161 - accuracy: 0.8815 - val_loss: 0.9373 - val_accuracy: 0.7179\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3143 - accuracy: 0.8778 - val_loss: 0.9306 - val_accuracy: 0.7094\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3143 - accuracy: 0.8778 - val_loss: 0.9311 - val_accuracy: 0.7179\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3148 - accuracy: 0.8815 - val_loss: 0.9396 - val_accuracy: 0.7265\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3141 - accuracy: 0.8815 - val_loss: 0.9345 - val_accuracy: 0.7265\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3153 - accuracy: 0.8778 - val_loss: 0.9264 - val_accuracy: 0.7265\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3143 - accuracy: 0.8815 - val_loss: 0.9278 - val_accuracy: 0.7179\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3141 - accuracy: 0.8815 - val_loss: 0.9416 - val_accuracy: 0.7265\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3142 - accuracy: 0.8815 - val_loss: 0.9413 - val_accuracy: 0.7265\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3123 - accuracy: 0.8815 - val_loss: 0.9352 - val_accuracy: 0.7094\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3133 - accuracy: 0.8815 - val_loss: 0.9342 - val_accuracy: 0.7179\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3111 - accuracy: 0.8815 - val_loss: 0.9455 - val_accuracy: 0.7179\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3143 - accuracy: 0.8889 - val_loss: 0.9621 - val_accuracy: 0.6667\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3159 - accuracy: 0.8704 - val_loss: 0.9516 - val_accuracy: 0.7265\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.92 - 0s 55us/step - loss: 0.3117 - accuracy: 0.8852 - val_loss: 0.9443 - val_accuracy: 0.7179\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3141 - accuracy: 0.8815 - val_loss: 0.9394 - val_accuracy: 0.7179\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3135 - accuracy: 0.8815 - val_loss: 0.9421 - val_accuracy: 0.7179\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3133 - accuracy: 0.8815 - val_loss: 0.9492 - val_accuracy: 0.7265\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3138 - accuracy: 0.8815 - val_loss: 0.9463 - val_accuracy: 0.7179\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3140 - accuracy: 0.8815 - val_loss: 0.9419 - val_accuracy: 0.7179\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3164 - accuracy: 0.8704 - val_loss: 0.9429 - val_accuracy: 0.7179\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3126 - accuracy: 0.8815 - val_loss: 0.9468 - val_accuracy: 0.7179\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3108 - accuracy: 0.8815 - val_loss: 0.9519 - val_accuracy: 0.7179\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3131 - accuracy: 0.8815 - val_loss: 0.9520 - val_accuracy: 0.7179\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3142 - accuracy: 0.8815 - val_loss: 0.9502 - val_accuracy: 0.7179\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3130 - accuracy: 0.8815 - val_loss: 0.9392 - val_accuracy: 0.7179\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3108 - accuracy: 0.8815 - val_loss: 0.9384 - val_accuracy: 0.7179\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3121 - accuracy: 0.8815 - val_loss: 0.9455 - val_accuracy: 0.7265\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3097 - accuracy: 0.8815 - val_loss: 0.9435 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3084 - accuracy: 0.8815 - val_loss: 0.9436 - val_accuracy: 0.7179\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.3093 - accuracy: 0.8815 - val_loss: 0.9443 - val_accuracy: 0.7179\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3090 - accuracy: 0.8815 - val_loss: 0.9473 - val_accuracy: 0.7179\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3087 - accuracy: 0.8815 - val_loss: 0.9499 - val_accuracy: 0.7179\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3104 - accuracy: 0.8778 - val_loss: 0.9564 - val_accuracy: 0.7265\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3116 - accuracy: 0.8815 - val_loss: 0.9628 - val_accuracy: 0.7265\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.3098 - accuracy: 0.8815 - val_loss: 0.9422 - val_accuracy: 0.7179\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.3096 - accuracy: 0.8815 - val_loss: 0.9378 - val_accuracy: 0.7265\n",
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3094 - accuracy: 0.8815 - val_loss: 0.9467 - val_accuracy: 0.7265\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3102 - accuracy: 0.8667 - val_loss: 0.9519 - val_accuracy: 0.7265\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.3106 - accuracy: 0.8815 - val_loss: 0.9422 - val_accuracy: 0.7265\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.3124 - accuracy: 0.8815 - val_loss: 0.9435 - val_accuracy: 0.7265\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.3089 - accuracy: 0.8815 - val_loss: 0.9566 - val_accuracy: 0.7265\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3094 - accuracy: 0.8815 - val_loss: 0.9623 - val_accuracy: 0.7265\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.3131 - accuracy: 0.8815 - val_loss: 0.9507 - val_accuracy: 0.7265\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3120 - accuracy: 0.8778 - val_loss: 0.9415 - val_accuracy: 0.7265\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3076 - accuracy: 0.8815 - val_loss: 0.9536 - val_accuracy: 0.7350\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.3090 - accuracy: 0.8852 - val_loss: 0.9608 - val_accuracy: 0.7265\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3098 - accuracy: 0.8852 - val_loss: 0.9499 - val_accuracy: 0.7265\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3065 - accuracy: 0.8815 - val_loss: 0.9430 - val_accuracy: 0.7265\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.3090 - accuracy: 0.8815 - val_loss: 0.9429 - val_accuracy: 0.7265\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3082 - accuracy: 0.8815 - val_loss: 0.9492 - val_accuracy: 0.7265\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3080 - accuracy: 0.8852 - val_loss: 0.9593 - val_accuracy: 0.7179\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3067 - accuracy: 0.8852 - val_loss: 0.9552 - val_accuracy: 0.7179\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.3065 - accuracy: 0.8815 - val_loss: 0.9554 - val_accuracy: 0.7179\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.9603 - val_accuracy: 0.7094\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3067 - accuracy: 0.8778 - val_loss: 0.9582 - val_accuracy: 0.7179\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.3050 - accuracy: 0.8815 - val_loss: 0.9550 - val_accuracy: 0.7179\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3062 - accuracy: 0.8815 - val_loss: 0.9558 - val_accuracy: 0.7179\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3086 - accuracy: 0.8815 - val_loss: 0.9542 - val_accuracy: 0.7094\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3080 - accuracy: 0.8778 - val_loss: 0.9647 - val_accuracy: 0.7179\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3062 - accuracy: 0.8852 - val_loss: 0.9640 - val_accuracy: 0.7094\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3058 - accuracy: 0.8815 - val_loss: 0.9608 - val_accuracy: 0.7179\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.3068 - accuracy: 0.8815 - val_loss: 0.9668 - val_accuracy: 0.7179\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.3057 - accuracy: 0.8815 - val_loss: 0.9690 - val_accuracy: 0.7179\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.3063 - accuracy: 0.8815 - val_loss: 0.9707 - val_accuracy: 0.7094\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.3064 - accuracy: 0.8815 - val_loss: 0.9671 - val_accuracy: 0.7179\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.3085 - accuracy: 0.8815 - val_loss: 0.9731 - val_accuracy: 0.7179\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.3063 - accuracy: 0.8815 - val_loss: 0.9671 - val_accuracy: 0.7179\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3055 - accuracy: 0.8815 - val_loss: 0.9678 - val_accuracy: 0.7179\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3041 - accuracy: 0.8815 - val_loss: 0.9708 - val_accuracy: 0.7179\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.3049 - accuracy: 0.8815 - val_loss: 0.9809 - val_accuracy: 0.7265\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3074 - accuracy: 0.8815 - val_loss: 0.9877 - val_accuracy: 0.7265\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3060 - accuracy: 0.8815 - val_loss: 0.9697 - val_accuracy: 0.7179\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3067 - accuracy: 0.8815 - val_loss: 0.9629 - val_accuracy: 0.7179\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3028 - accuracy: 0.8815 - val_loss: 0.9626 - val_accuracy: 0.7179\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3099 - accuracy: 0.8778 - val_loss: 0.9783 - val_accuracy: 0.7350\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3073 - accuracy: 0.8852 - val_loss: 0.9570 - val_accuracy: 0.7179\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.3092 - accuracy: 0.8815 - val_loss: 0.9466 - val_accuracy: 0.7179\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.3075 - accuracy: 0.8815 - val_loss: 0.9555 - val_accuracy: 0.7265\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3023 - accuracy: 0.8852 - val_loss: 0.9798 - val_accuracy: 0.7179\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.3078 - accuracy: 0.8815 - val_loss: 0.9807 - val_accuracy: 0.7179\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.3050 - accuracy: 0.8815 - val_loss: 0.9603 - val_accuracy: 0.7094\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.3047 - accuracy: 0.8815 - val_loss: 0.9592 - val_accuracy: 0.7094\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3044 - accuracy: 0.8815 - val_loss: 0.9762 - val_accuracy: 0.7179\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3051 - accuracy: 0.8852 - val_loss: 0.9834 - val_accuracy: 0.7265\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3037 - accuracy: 0.8852 - val_loss: 0.9842 - val_accuracy: 0.7265\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.3032 - accuracy: 0.8778 - val_loss: 0.9800 - val_accuracy: 0.7179\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3051 - accuracy: 0.8815 - val_loss: 0.9815 - val_accuracy: 0.7179\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3036 - accuracy: 0.8815 - val_loss: 0.9952 - val_accuracy: 0.7179\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.3022 - accuracy: 0.8815 - val_loss: 0.9856 - val_accuracy: 0.7179\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3014 - accuracy: 0.8815 - val_loss: 0.9848 - val_accuracy: 0.7179\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.3045 - accuracy: 0.8815 - val_loss: 0.9803 - val_accuracy: 0.7265\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3033 - accuracy: 0.8815 - val_loss: 0.9708 - val_accuracy: 0.7179\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.3063 - accuracy: 0.8815 - val_loss: 0.9682 - val_accuracy: 0.7179\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.3034 - accuracy: 0.8815 - val_loss: 0.9784 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.3025 - accuracy: 0.8778 - val_loss: 1.0019 - val_accuracy: 0.6838\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3074 - accuracy: 0.8815 - val_loss: 0.9866 - val_accuracy: 0.7265\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3006 - accuracy: 0.8815 - val_loss: 0.9682 - val_accuracy: 0.7179\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.3026 - accuracy: 0.8815 - val_loss: 0.9628 - val_accuracy: 0.7179\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.3001 - accuracy: 0.8778 - val_loss: 0.9722 - val_accuracy: 0.7265\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.3014 - accuracy: 0.8815 - val_loss: 0.9810 - val_accuracy: 0.7265\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.3012 - accuracy: 0.8815 - val_loss: 0.9802 - val_accuracy: 0.7265\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.3023 - accuracy: 0.8852 - val_loss: 0.9625 - val_accuracy: 0.7179\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3025 - accuracy: 0.8852 - val_loss: 0.9639 - val_accuracy: 0.7179\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.3017 - accuracy: 0.8852 - val_loss: 0.9753 - val_accuracy: 0.7179\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.3016 - accuracy: 0.8852 - val_loss: 0.9825 - val_accuracy: 0.7179\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.3000 - accuracy: 0.8852 - val_loss: 0.9815 - val_accuracy: 0.7265\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.3006 - accuracy: 0.8815 - val_loss: 0.9847 - val_accuracy: 0.7265\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.3010 - accuracy: 0.8815 - val_loss: 0.9828 - val_accuracy: 0.7179\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2996 - accuracy: 0.8815 - val_loss: 0.9909 - val_accuracy: 0.7265\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.3031 - accuracy: 0.8741 - val_loss: 0.9931 - val_accuracy: 0.6752\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.3008 - accuracy: 0.8815 - val_loss: 0.9765 - val_accuracy: 0.7265\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.3018 - accuracy: 0.8815 - val_loss: 0.9681 - val_accuracy: 0.7265\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.3013 - accuracy: 0.8852 - val_loss: 0.9725 - val_accuracy: 0.7265\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2985 - accuracy: 0.8852 - val_loss: 0.9776 - val_accuracy: 0.7265\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2983 - accuracy: 0.8852 - val_loss: 0.9822 - val_accuracy: 0.7265\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 134us/step - loss: 0.2980 - accuracy: 0.8852 - val_loss: 0.9844 - val_accuracy: 0.7265\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2983 - accuracy: 0.8852 - val_loss: 0.9771 - val_accuracy: 0.7265\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2992 - accuracy: 0.8889 - val_loss: 0.9749 - val_accuracy: 0.7179\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.3000 - accuracy: 0.8889 - val_loss: 0.9777 - val_accuracy: 0.7179\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2995 - accuracy: 0.8889 - val_loss: 0.9761 - val_accuracy: 0.7179\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.3008 - accuracy: 0.8852 - val_loss: 0.9744 - val_accuracy: 0.7179\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2999 - accuracy: 0.8852 - val_loss: 0.9754 - val_accuracy: 0.7265\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2980 - accuracy: 0.8852 - val_loss: 0.9813 - val_accuracy: 0.7265\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2997 - accuracy: 0.8852 - val_loss: 0.9971 - val_accuracy: 0.6752\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.3016 - accuracy: 0.8889 - val_loss: 0.9893 - val_accuracy: 0.7265\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2994 - accuracy: 0.8852 - val_loss: 0.9925 - val_accuracy: 0.7265\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.3001 - accuracy: 0.8852 - val_loss: 0.9936 - val_accuracy: 0.7179\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2979 - accuracy: 0.8852 - val_loss: 0.9835 - val_accuracy: 0.7179\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2981 - accuracy: 0.8889 - val_loss: 0.9823 - val_accuracy: 0.7179\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2984 - accuracy: 0.8889 - val_loss: 0.9854 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2995 - accuracy: 0.8889 - val_loss: 0.9807 - val_accuracy: 0.7179\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2995 - accuracy: 0.8852 - val_loss: 0.9796 - val_accuracy: 0.7179\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2978 - accuracy: 0.8852 - val_loss: 0.9941 - val_accuracy: 0.7179\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2966 - accuracy: 0.8852 - val_loss: 0.9982 - val_accuracy: 0.7179\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2972 - accuracy: 0.8815 - val_loss: 0.9982 - val_accuracy: 0.7094\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2973 - accuracy: 0.8852 - val_loss: 0.9926 - val_accuracy: 0.7094\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2973 - accuracy: 0.8852 - val_loss: 0.9937 - val_accuracy: 0.7094\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2963 - accuracy: 0.8852 - val_loss: 0.9931 - val_accuracy: 0.7094\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2985 - accuracy: 0.8852 - val_loss: 1.0006 - val_accuracy: 0.7179\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2983 - accuracy: 0.8852 - val_loss: 0.9929 - val_accuracy: 0.7179\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2957 - accuracy: 0.8852 - val_loss: 0.9900 - val_accuracy: 0.7094\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2958 - accuracy: 0.8852 - val_loss: 0.9883 - val_accuracy: 0.7179\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2962 - accuracy: 0.8815 - val_loss: 0.9857 - val_accuracy: 0.7179\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2959 - accuracy: 0.8815 - val_loss: 0.9860 - val_accuracy: 0.7265\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2966 - accuracy: 0.8852 - val_loss: 0.9931 - val_accuracy: 0.7265\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2983 - accuracy: 0.8852 - val_loss: 0.9947 - val_accuracy: 0.7265\n",
      "Epoch 668/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2955 - accuracy: 0.8852 - val_loss: 0.9841 - val_accuracy: 0.7265\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2985 - accuracy: 0.8889 - val_loss: 0.9781 - val_accuracy: 0.7179\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.3021 - accuracy: 0.8852 - val_loss: 0.9806 - val_accuracy: 0.7179\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2961 - accuracy: 0.8852 - val_loss: 0.9884 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2951 - accuracy: 0.8852 - val_loss: 0.9867 - val_accuracy: 0.7179\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.3000 - accuracy: 0.8852 - val_loss: 0.9935 - val_accuracy: 0.7179\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2990 - accuracy: 0.8852 - val_loss: 0.9912 - val_accuracy: 0.7265\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2949 - accuracy: 0.8852 - val_loss: 0.9966 - val_accuracy: 0.7265\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2956 - accuracy: 0.8815 - val_loss: 0.9989 - val_accuracy: 0.7265\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3002 - accuracy: 0.8815 - val_loss: 1.0037 - val_accuracy: 0.7265\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2957 - accuracy: 0.8778 - val_loss: 1.0012 - val_accuracy: 0.7179\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2946 - accuracy: 0.8852 - val_loss: 1.0071 - val_accuracy: 0.7350\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.3001 - accuracy: 0.8852 - val_loss: 1.0125 - val_accuracy: 0.7350\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2974 - accuracy: 0.8778 - val_loss: 0.9953 - val_accuracy: 0.7179\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2950 - accuracy: 0.8778 - val_loss: 0.9896 - val_accuracy: 0.7179\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2952 - accuracy: 0.8778 - val_loss: 0.9910 - val_accuracy: 0.7265\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2944 - accuracy: 0.8815 - val_loss: 0.9914 - val_accuracy: 0.7265\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2939 - accuracy: 0.8815 - val_loss: 0.9918 - val_accuracy: 0.7265\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2937 - accuracy: 0.8815 - val_loss: 1.0064 - val_accuracy: 0.7265\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2965 - accuracy: 0.8889 - val_loss: 1.0233 - val_accuracy: 0.6752\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2969 - accuracy: 0.8852 - val_loss: 1.0089 - val_accuracy: 0.7265\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2953 - accuracy: 0.8778 - val_loss: 0.9975 - val_accuracy: 0.7179\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2965 - accuracy: 0.8815 - val_loss: 0.9962 - val_accuracy: 0.7179\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2932 - accuracy: 0.8815 - val_loss: 1.0025 - val_accuracy: 0.7265\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2923 - accuracy: 0.8815 - val_loss: 1.0132 - val_accuracy: 0.7179\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2964 - accuracy: 0.8815 - val_loss: 1.0173 - val_accuracy: 0.6667\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2942 - accuracy: 0.8815 - val_loss: 1.0028 - val_accuracy: 0.7179\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2959 - accuracy: 0.8852 - val_loss: 0.9963 - val_accuracy: 0.7179\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2944 - accuracy: 0.8852 - val_loss: 1.0007 - val_accuracy: 0.7179\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2934 - accuracy: 0.8852 - val_loss: 1.0150 - val_accuracy: 0.7265\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2933 - accuracy: 0.8889 - val_loss: 1.0118 - val_accuracy: 0.7265\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2933 - accuracy: 0.8852 - val_loss: 0.9995 - val_accuracy: 0.7179\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2958 - accuracy: 0.8778 - val_loss: 1.0016 - val_accuracy: 0.7179\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2946 - accuracy: 0.8815 - val_loss: 0.9948 - val_accuracy: 0.7179\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2943 - accuracy: 0.8852 - val_loss: 1.0026 - val_accuracy: 0.7265\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2932 - accuracy: 0.8852 - val_loss: 0.9943 - val_accuracy: 0.7179\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2939 - accuracy: 0.8889 - val_loss: 0.9932 - val_accuracy: 0.7179\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2941 - accuracy: 0.8852 - val_loss: 0.9970 - val_accuracy: 0.7094\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2935 - accuracy: 0.8815 - val_loss: 1.0089 - val_accuracy: 0.7179\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2950 - accuracy: 0.8926 - val_loss: 1.0113 - val_accuracy: 0.7179\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2939 - accuracy: 0.8815 - val_loss: 0.9953 - val_accuracy: 0.7179\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2911 - accuracy: 0.8778 - val_loss: 0.9997 - val_accuracy: 0.7179\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2925 - accuracy: 0.8852 - val_loss: 0.9986 - val_accuracy: 0.7179\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2921 - accuracy: 0.8852 - val_loss: 0.9912 - val_accuracy: 0.7179\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2940 - accuracy: 0.8852 - val_loss: 0.9951 - val_accuracy: 0.7179\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2906 - accuracy: 0.8815 - val_loss: 1.0029 - val_accuracy: 0.7179\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2899 - accuracy: 0.8815 - val_loss: 1.0097 - val_accuracy: 0.7265\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2903 - accuracy: 0.8815 - val_loss: 1.0094 - val_accuracy: 0.7265\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2911 - accuracy: 0.8815 - val_loss: 1.0070 - val_accuracy: 0.7265\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2914 - accuracy: 0.8815 - val_loss: 1.0129 - val_accuracy: 0.7265\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2914 - accuracy: 0.8815 - val_loss: 1.0165 - val_accuracy: 0.7350\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2908 - accuracy: 0.8852 - val_loss: 1.0155 - val_accuracy: 0.7350\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2917 - accuracy: 0.8815 - val_loss: 1.0107 - val_accuracy: 0.7179\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2910 - accuracy: 0.8815 - val_loss: 1.0114 - val_accuracy: 0.7179\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2944 - accuracy: 0.8852 - val_loss: 1.0028 - val_accuracy: 0.7265\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2933 - accuracy: 0.8852 - val_loss: 1.0044 - val_accuracy: 0.7350\n",
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2920 - accuracy: 0.8815 - val_loss: 1.0069 - val_accuracy: 0.7265\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2906 - accuracy: 0.8815 - val_loss: 1.0096 - val_accuracy: 0.7350\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2921 - accuracy: 0.8852 - val_loss: 1.0016 - val_accuracy: 0.7265\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2911 - accuracy: 0.8852 - val_loss: 1.0015 - val_accuracy: 0.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2907 - accuracy: 0.8852 - val_loss: 1.0093 - val_accuracy: 0.7265\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2890 - accuracy: 0.8852 - val_loss: 1.0109 - val_accuracy: 0.7265\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2908 - accuracy: 0.8852 - val_loss: 1.0117 - val_accuracy: 0.7179\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2906 - accuracy: 0.8852 - val_loss: 1.0183 - val_accuracy: 0.7179\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2901 - accuracy: 0.8889 - val_loss: 1.0287 - val_accuracy: 0.6752\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2933 - accuracy: 0.8815 - val_loss: 1.0272 - val_accuracy: 0.6752\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2925 - accuracy: 0.8778 - val_loss: 1.0163 - val_accuracy: 0.7179\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2913 - accuracy: 0.8889 - val_loss: 1.0241 - val_accuracy: 0.7350\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2903 - accuracy: 0.8852 - val_loss: 1.0252 - val_accuracy: 0.7265\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2890 - accuracy: 0.8852 - val_loss: 1.0204 - val_accuracy: 0.7265\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2895 - accuracy: 0.8815 - val_loss: 1.0222 - val_accuracy: 0.7265\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2916 - accuracy: 0.8815 - val_loss: 1.0156 - val_accuracy: 0.7265\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2907 - accuracy: 0.8852 - val_loss: 1.0208 - val_accuracy: 0.7265\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2895 - accuracy: 0.8852 - val_loss: 1.0253 - val_accuracy: 0.7265\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2890 - accuracy: 0.8852 - val_loss: 1.0196 - val_accuracy: 0.7265\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2888 - accuracy: 0.8852 - val_loss: 1.0090 - val_accuracy: 0.7179\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2910 - accuracy: 0.8815 - val_loss: 1.0151 - val_accuracy: 0.7179\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2901 - accuracy: 0.8852 - val_loss: 1.0247 - val_accuracy: 0.7350\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2911 - accuracy: 0.8852 - val_loss: 1.0200 - val_accuracy: 0.7350\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2900 - accuracy: 0.8852 - val_loss: 1.0144 - val_accuracy: 0.7265\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2881 - accuracy: 0.8852 - val_loss: 1.0256 - val_accuracy: 0.7265\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2907 - accuracy: 0.8852 - val_loss: 1.0410 - val_accuracy: 0.6752\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2945 - accuracy: 0.8778 - val_loss: 1.0320 - val_accuracy: 0.7265\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2906 - accuracy: 0.8889 - val_loss: 1.0253 - val_accuracy: 0.7179\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 45us/step - loss: 0.2888 - accuracy: 0.8889 - val_loss: 1.0193 - val_accuracy: 0.7179\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2905 - accuracy: 0.8889 - val_loss: 1.0187 - val_accuracy: 0.7179\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2899 - accuracy: 0.8889 - val_loss: 1.0200 - val_accuracy: 0.7179\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2889 - accuracy: 0.8889 - val_loss: 1.0333 - val_accuracy: 0.7265\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2883 - accuracy: 0.8852 - val_loss: 1.0410 - val_accuracy: 0.7265\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2931 - accuracy: 0.8815 - val_loss: 1.0636 - val_accuracy: 0.6838\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2948 - accuracy: 0.8815 - val_loss: 1.0447 - val_accuracy: 0.7265\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2884 - accuracy: 0.8852 - val_loss: 1.0230 - val_accuracy: 0.7179\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2948 - accuracy: 0.8852 - val_loss: 1.0155 - val_accuracy: 0.7179\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2939 - accuracy: 0.8852 - val_loss: 1.0144 - val_accuracy: 0.7179\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2892 - accuracy: 0.8889 - val_loss: 1.0283 - val_accuracy: 0.7179\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2895 - accuracy: 0.8889 - val_loss: 1.0299 - val_accuracy: 0.7179\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2894 - accuracy: 0.8852 - val_loss: 1.0246 - val_accuracy: 0.7179\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2880 - accuracy: 0.8815 - val_loss: 1.0314 - val_accuracy: 0.7265\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2880 - accuracy: 0.8852 - val_loss: 1.0388 - val_accuracy: 0.7265\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2883 - accuracy: 0.8852 - val_loss: 1.0370 - val_accuracy: 0.7265\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2882 - accuracy: 0.8852 - val_loss: 1.0182 - val_accuracy: 0.7179\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2950 - accuracy: 0.8852 - val_loss: 1.0185 - val_accuracy: 0.7179\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2912 - accuracy: 0.8889 - val_loss: 1.0292 - val_accuracy: 0.7179\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2840 - accuracy: 0.8815 - val_loss: 1.0431 - val_accuracy: 0.6752\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2887 - accuracy: 0.8815 - val_loss: 1.0418 - val_accuracy: 0.6752\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2898 - accuracy: 0.8778 - val_loss: 1.0336 - val_accuracy: 0.7179\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2903 - accuracy: 0.8815 - val_loss: 1.0274 - val_accuracy: 0.7265\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2899 - accuracy: 0.8852 - val_loss: 1.0263 - val_accuracy: 0.7265\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2882 - accuracy: 0.8852 - val_loss: 1.0416 - val_accuracy: 0.7350\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2882 - accuracy: 0.8852 - val_loss: 1.0332 - val_accuracy: 0.7265\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2863 - accuracy: 0.8889 - val_loss: 1.0260 - val_accuracy: 0.7179\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2879 - accuracy: 0.8852 - val_loss: 1.0298 - val_accuracy: 0.7179\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2888 - accuracy: 0.8852 - val_loss: 1.0468 - val_accuracy: 0.7179\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2892 - accuracy: 0.8926 - val_loss: 1.0628 - val_accuracy: 0.6752\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2917 - accuracy: 0.8815 - val_loss: 1.0576 - val_accuracy: 0.6752\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2914 - accuracy: 0.8815 - val_loss: 1.0631 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2890 - accuracy: 0.8815 - val_loss: 1.0482 - val_accuracy: 0.7179\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2870 - accuracy: 0.8852 - val_loss: 1.0309 - val_accuracy: 0.7179\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2865 - accuracy: 0.8852 - val_loss: 1.0260 - val_accuracy: 0.7179\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2874 - accuracy: 0.8852 - val_loss: 1.0248 - val_accuracy: 0.7179\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2875 - accuracy: 0.8889 - val_loss: 1.0311 - val_accuracy: 0.7350\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2862 - accuracy: 0.8889 - val_loss: 1.0289 - val_accuracy: 0.7265\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2862 - accuracy: 0.8889 - val_loss: 1.0400 - val_accuracy: 0.7265\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2866 - accuracy: 0.8741 - val_loss: 1.0546 - val_accuracy: 0.6752\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2873 - accuracy: 0.8852 - val_loss: 1.0469 - val_accuracy: 0.7179\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2863 - accuracy: 0.8889 - val_loss: 1.0496 - val_accuracy: 0.7179\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2865 - accuracy: 0.8889 - val_loss: 1.0389 - val_accuracy: 0.7265\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2900 - accuracy: 0.8889 - val_loss: 1.0212 - val_accuracy: 0.7436\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2887 - accuracy: 0.8778 - val_loss: 1.0279 - val_accuracy: 0.7265\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2863 - accuracy: 0.8889 - val_loss: 1.0274 - val_accuracy: 0.7265\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2858 - accuracy: 0.8852 - val_loss: 1.0313 - val_accuracy: 0.7265\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2880 - accuracy: 0.8852 - val_loss: 1.0316 - val_accuracy: 0.7265\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2871 - accuracy: 0.8815 - val_loss: 1.0332 - val_accuracy: 0.7265\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2864 - accuracy: 0.8889 - val_loss: 1.0319 - val_accuracy: 0.7350\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2854 - accuracy: 0.8889 - val_loss: 1.0319 - val_accuracy: 0.7265\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2838 - accuracy: 0.8889 - val_loss: 1.0350 - val_accuracy: 0.7179\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2837 - accuracy: 0.8852 - val_loss: 1.0357 - val_accuracy: 0.7179\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2858 - accuracy: 0.8852 - val_loss: 1.0400 - val_accuracy: 0.7179\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2843 - accuracy: 0.8852 - val_loss: 1.0312 - val_accuracy: 0.7179\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2858 - accuracy: 0.8889 - val_loss: 1.0340 - val_accuracy: 0.7179\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2831 - accuracy: 0.8889 - val_loss: 1.0469 - val_accuracy: 0.7265\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2854 - accuracy: 0.8852 - val_loss: 1.0509 - val_accuracy: 0.7265\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2870 - accuracy: 0.8852 - val_loss: 1.0440 - val_accuracy: 0.7265\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2853 - accuracy: 0.8852 - val_loss: 1.0381 - val_accuracy: 0.7179\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2834 - accuracy: 0.8889 - val_loss: 1.0386 - val_accuracy: 0.7179\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2846 - accuracy: 0.8852 - val_loss: 1.0413 - val_accuracy: 0.7094\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2843 - accuracy: 0.8852 - val_loss: 1.0354 - val_accuracy: 0.7179\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2846 - accuracy: 0.8852 - val_loss: 1.0396 - val_accuracy: 0.7179\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2845 - accuracy: 0.8852 - val_loss: 1.0501 - val_accuracy: 0.7350\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2839 - accuracy: 0.8852 - val_loss: 1.0539 - val_accuracy: 0.6838\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2861 - accuracy: 0.8815 - val_loss: 1.0497 - val_accuracy: 0.7265\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2868 - accuracy: 0.8815 - val_loss: 1.0409 - val_accuracy: 0.7265\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2856 - accuracy: 0.8852 - val_loss: 1.0361 - val_accuracy: 0.7265\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2847 - accuracy: 0.8889 - val_loss: 1.0359 - val_accuracy: 0.7350\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2849 - accuracy: 0.8889 - val_loss: 1.0460 - val_accuracy: 0.7350\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2848 - accuracy: 0.8889 - val_loss: 1.0497 - val_accuracy: 0.7350\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2844 - accuracy: 0.8889 - val_loss: 1.0499 - val_accuracy: 0.7265\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2833 - accuracy: 0.8889 - val_loss: 1.0541 - val_accuracy: 0.7265\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2830 - accuracy: 0.8852 - val_loss: 1.0479 - val_accuracy: 0.7265\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2828 - accuracy: 0.8852 - val_loss: 1.0481 - val_accuracy: 0.7265\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2846 - accuracy: 0.8852 - val_loss: 1.0432 - val_accuracy: 0.7179\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2825 - accuracy: 0.8852 - val_loss: 1.0506 - val_accuracy: 0.7265\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2825 - accuracy: 0.8889 - val_loss: 1.0593 - val_accuracy: 0.7350\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2838 - accuracy: 0.8889 - val_loss: 1.0561 - val_accuracy: 0.7350\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2837 - accuracy: 0.8889 - val_loss: 1.0556 - val_accuracy: 0.7350\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2829 - accuracy: 0.8889 - val_loss: 1.0556 - val_accuracy: 0.7350\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2828 - accuracy: 0.8889 - val_loss: 1.0530 - val_accuracy: 0.7265\n",
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2826 - accuracy: 0.8889 - val_loss: 1.0516 - val_accuracy: 0.7179\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2852 - accuracy: 0.8852 - val_loss: 1.0451 - val_accuracy: 0.7350\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2893 - accuracy: 0.8778 - val_loss: 1.0456 - val_accuracy: 0.7265\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2838 - accuracy: 0.8889 - val_loss: 1.0666 - val_accuracy: 0.6838\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2884 - accuracy: 0.8815 - val_loss: 1.0677 - val_accuracy: 0.6838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2871 - accuracy: 0.8815 - val_loss: 1.0569 - val_accuracy: 0.6752\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2873 - accuracy: 0.8889 - val_loss: 1.0361 - val_accuracy: 0.7265\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2872 - accuracy: 0.8889 - val_loss: 1.0351 - val_accuracy: 0.7436\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2870 - accuracy: 0.8815 - val_loss: 1.0387 - val_accuracy: 0.7436\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2873 - accuracy: 0.8815 - val_loss: 1.0439 - val_accuracy: 0.7436\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2851 - accuracy: 0.8815 - val_loss: 1.0481 - val_accuracy: 0.7350\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2817 - accuracy: 0.8889 - val_loss: 1.0471 - val_accuracy: 0.7265\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2836 - accuracy: 0.8889 - val_loss: 1.0435 - val_accuracy: 0.7265\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2825 - accuracy: 0.8889 - val_loss: 1.0540 - val_accuracy: 0.7350\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2817 - accuracy: 0.8889 - val_loss: 1.0560 - val_accuracy: 0.7350\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2830 - accuracy: 0.8889 - val_loss: 1.0563 - val_accuracy: 0.7179\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2816 - accuracy: 0.8889 - val_loss: 1.0610 - val_accuracy: 0.7265\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2810 - accuracy: 0.8889 - val_loss: 1.0663 - val_accuracy: 0.7265\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2816 - accuracy: 0.8889 - val_loss: 1.0589 - val_accuracy: 0.7265\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2843 - accuracy: 0.8852 - val_loss: 1.0546 - val_accuracy: 0.7265\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2826 - accuracy: 0.8889 - val_loss: 1.0556 - val_accuracy: 0.7350\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.87 - 0s 71us/step - loss: 0.2809 - accuracy: 0.8889 - val_loss: 1.0483 - val_accuracy: 0.7179\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2819 - accuracy: 0.8889 - val_loss: 1.0540 - val_accuracy: 0.7265\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2814 - accuracy: 0.8889 - val_loss: 1.0731 - val_accuracy: 0.7350\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2851 - accuracy: 0.8889 - val_loss: 1.0718 - val_accuracy: 0.7350\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2833 - accuracy: 0.8889 - val_loss: 1.0563 - val_accuracy: 0.7350\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2813 - accuracy: 0.8889 - val_loss: 1.0470 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2823 - accuracy: 0.8889 - val_loss: 1.0483 - val_accuracy: 0.7265\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2811 - accuracy: 0.8889 - val_loss: 1.0575 - val_accuracy: 0.7265\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2806 - accuracy: 0.8889 - val_loss: 1.0642 - val_accuracy: 0.7265\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2811 - accuracy: 0.8889 - val_loss: 1.0727 - val_accuracy: 0.7265\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2818 - accuracy: 0.8889 - val_loss: 1.0668 - val_accuracy: 0.7265\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2804 - accuracy: 0.8889 - val_loss: 1.0628 - val_accuracy: 0.7265\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2810 - accuracy: 0.8889 - val_loss: 1.0622 - val_accuracy: 0.7265\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2832 - accuracy: 0.8889 - val_loss: 1.0777 - val_accuracy: 0.7265\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2813 - accuracy: 0.8889 - val_loss: 1.0706 - val_accuracy: 0.7265\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2798 - accuracy: 0.8889 - val_loss: 1.0642 - val_accuracy: 0.7179\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2806 - accuracy: 0.8889 - val_loss: 1.0633 - val_accuracy: 0.7179\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2809 - accuracy: 0.8889 - val_loss: 1.0615 - val_accuracy: 0.7179\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2819 - accuracy: 0.8852 - val_loss: 1.0633 - val_accuracy: 0.7265\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2808 - accuracy: 0.8889 - val_loss: 1.0707 - val_accuracy: 0.7265\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2811 - accuracy: 0.8889 - val_loss: 1.0676 - val_accuracy: 0.7350\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2797 - accuracy: 0.8889 - val_loss: 1.0632 - val_accuracy: 0.7265\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2814 - accuracy: 0.8889 - val_loss: 1.0589 - val_accuracy: 0.7179\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2809 - accuracy: 0.8889 - val_loss: 1.0640 - val_accuracy: 0.7179\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2802 - accuracy: 0.8889 - val_loss: 1.0684 - val_accuracy: 0.7265\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2825 - accuracy: 0.8852 - val_loss: 1.0842 - val_accuracy: 0.6752\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2816 - accuracy: 0.8815 - val_loss: 1.0669 - val_accuracy: 0.7179\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2790 - accuracy: 0.8889 - val_loss: 1.0647 - val_accuracy: 0.7179\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2802 - accuracy: 0.8889 - val_loss: 1.0718 - val_accuracy: 0.7265\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2827 - accuracy: 0.8889 - val_loss: 1.0644 - val_accuracy: 0.7265\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2801 - accuracy: 0.8889 - val_loss: 1.0639 - val_accuracy: 0.7179\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2801 - accuracy: 0.8889 - val_loss: 1.0604 - val_accuracy: 0.7179\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2791 - accuracy: 0.8852 - val_loss: 1.0667 - val_accuracy: 0.7265\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2793 - accuracy: 0.8889 - val_loss: 1.0644 - val_accuracy: 0.7265\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2806 - accuracy: 0.8889 - val_loss: 1.0536 - val_accuracy: 0.7179\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2834 - accuracy: 0.8889 - val_loss: 1.0557 - val_accuracy: 0.7265\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2797 - accuracy: 0.8889 - val_loss: 1.0719 - val_accuracy: 0.7265\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2839 - accuracy: 0.8741 - val_loss: 1.0789 - val_accuracy: 0.7350\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2802 - accuracy: 0.8889 - val_loss: 1.0548 - val_accuracy: 0.7265\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2854 - accuracy: 0.8889 - val_loss: 1.0501 - val_accuracy: 0.7179\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2944 - accuracy: 0.8889 - val_loss: 1.0462 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2832 - accuracy: 0.8889 - val_loss: 1.0562 - val_accuracy: 0.7265\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2789 - accuracy: 0.8889 - val_loss: 1.0675 - val_accuracy: 0.7350\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2808 - accuracy: 0.8889 - val_loss: 1.0569 - val_accuracy: 0.7265\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2776 - accuracy: 0.8889 - val_loss: 1.0627 - val_accuracy: 0.7265\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2773 - accuracy: 0.8889 - val_loss: 1.0678 - val_accuracy: 0.7265\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2775 - accuracy: 0.8889 - val_loss: 1.0665 - val_accuracy: 0.7265\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2784 - accuracy: 0.8889 - val_loss: 1.0653 - val_accuracy: 0.7265\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2784 - accuracy: 0.8889 - val_loss: 1.0706 - val_accuracy: 0.7265\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2787 - accuracy: 0.8889 - val_loss: 1.0681 - val_accuracy: 0.7179\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2801 - accuracy: 0.8889 - val_loss: 1.0746 - val_accuracy: 0.7265\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2778 - accuracy: 0.8889 - val_loss: 1.0850 - val_accuracy: 0.7350\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2821 - accuracy: 0.8778 - val_loss: 1.0831 - val_accuracy: 0.7350\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2827 - accuracy: 0.8889 - val_loss: 1.0661 - val_accuracy: 0.7179\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2779 - accuracy: 0.8889 - val_loss: 1.0822 - val_accuracy: 0.7350\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2796 - accuracy: 0.8889 - val_loss: 1.0815 - val_accuracy: 0.7350\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2771 - accuracy: 0.8889 - val_loss: 1.0800 - val_accuracy: 0.7179\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2788 - accuracy: 0.8889 - val_loss: 1.0768 - val_accuracy: 0.7179\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2771 - accuracy: 0.8889 - val_loss: 1.0843 - val_accuracy: 0.7265\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2774 - accuracy: 0.8889 - val_loss: 1.0772 - val_accuracy: 0.7350\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2788 - accuracy: 0.8889 - val_loss: 1.0648 - val_accuracy: 0.7265\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2794 - accuracy: 0.8889 - val_loss: 1.0662 - val_accuracy: 0.7350\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2791 - accuracy: 0.8889 - val_loss: 1.0733 - val_accuracy: 0.7350\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2781 - accuracy: 0.8889 - val_loss: 1.0810 - val_accuracy: 0.7179\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2794 - accuracy: 0.8889 - val_loss: 1.0773 - val_accuracy: 0.7094\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2833 - accuracy: 0.8852 - val_loss: 1.0711 - val_accuracy: 0.7179\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2787 - accuracy: 0.8889 - val_loss: 1.0771 - val_accuracy: 0.7179\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2778 - accuracy: 0.8852 - val_loss: 1.0834 - val_accuracy: 0.7265\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2781 - accuracy: 0.8889 - val_loss: 1.0809 - val_accuracy: 0.7265\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2776 - accuracy: 0.8889 - val_loss: 1.0773 - val_accuracy: 0.7179\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 47us/step - loss: 0.2762 - accuracy: 0.8889 - val_loss: 1.0833 - val_accuracy: 0.7179\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2767 - accuracy: 0.8889 - val_loss: 1.0846 - val_accuracy: 0.7179\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2769 - accuracy: 0.8889 - val_loss: 1.0835 - val_accuracy: 0.7179\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2769 - accuracy: 0.8852 - val_loss: 1.0823 - val_accuracy: 0.7265\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2761 - accuracy: 0.8889 - val_loss: 1.0750 - val_accuracy: 0.7179\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2780 - accuracy: 0.8889 - val_loss: 1.0786 - val_accuracy: 0.7265\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2779 - accuracy: 0.8889 - val_loss: 1.0878 - val_accuracy: 0.7350\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2776 - accuracy: 0.8889 - val_loss: 1.0821 - val_accuracy: 0.7179\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2781 - accuracy: 0.8889 - val_loss: 1.0860 - val_accuracy: 0.7265\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2797 - accuracy: 0.8741 - val_loss: 1.0982 - val_accuracy: 0.6838\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2766 - accuracy: 0.8889 - val_loss: 1.0899 - val_accuracy: 0.7179\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2759 - accuracy: 0.8889 - val_loss: 1.0863 - val_accuracy: 0.7094\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2759 - accuracy: 0.8889 - val_loss: 1.0762 - val_accuracy: 0.7179\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2746 - accuracy: 0.8889 - val_loss: 1.0763 - val_accuracy: 0.7265\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2773 - accuracy: 0.8852 - val_loss: 1.0728 - val_accuracy: 0.7350\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2805 - accuracy: 0.8889 - val_loss: 1.0743 - val_accuracy: 0.7265\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2779 - accuracy: 0.8889 - val_loss: 1.0797 - val_accuracy: 0.7179\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2761 - accuracy: 0.8889 - val_loss: 1.0861 - val_accuracy: 0.7094\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2793 - accuracy: 0.8889 - val_loss: 1.0906 - val_accuracy: 0.7094\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2792 - accuracy: 0.8889 - val_loss: 1.0872 - val_accuracy: 0.7094\n",
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2793 - accuracy: 0.8889 - val_loss: 1.0790 - val_accuracy: 0.7179\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2758 - accuracy: 0.8889 - val_loss: 1.0795 - val_accuracy: 0.7179\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2744 - accuracy: 0.8889 - val_loss: 1.0817 - val_accuracy: 0.7350\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2786 - accuracy: 0.8815 - val_loss: 1.0806 - val_accuracy: 0.7265\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2765 - accuracy: 0.8889 - val_loss: 1.0716 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2779 - accuracy: 0.8889 - val_loss: 1.0679 - val_accuracy: 0.7350\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2777 - accuracy: 0.8889 - val_loss: 1.0605 - val_accuracy: 0.7265\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2785 - accuracy: 0.8889 - val_loss: 1.0624 - val_accuracy: 0.7179\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2774 - accuracy: 0.8889 - val_loss: 1.0778 - val_accuracy: 0.7265\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2736 - accuracy: 0.8889 - val_loss: 1.0962 - val_accuracy: 0.7350\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2846 - accuracy: 0.8778 - val_loss: 1.1205 - val_accuracy: 0.6752\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2804 - accuracy: 0.8889 - val_loss: 1.0978 - val_accuracy: 0.7265\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2739 - accuracy: 0.8852 - val_loss: 1.0890 - val_accuracy: 0.7094\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2818 - accuracy: 0.8852 - val_loss: 1.0890 - val_accuracy: 0.7094\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2783 - accuracy: 0.8852 - val_loss: 1.0897 - val_accuracy: 0.7179\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2744 - accuracy: 0.8889 - val_loss: 1.0885 - val_accuracy: 0.7265\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2766 - accuracy: 0.8889 - val_loss: 1.0911 - val_accuracy: 0.7350\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2771 - accuracy: 0.8889 - val_loss: 1.0837 - val_accuracy: 0.7350\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2752 - accuracy: 0.8889 - val_loss: 1.0842 - val_accuracy: 0.7265\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2764 - accuracy: 0.8889 - val_loss: 1.0862 - val_accuracy: 0.7094\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2763 - accuracy: 0.8852 - val_loss: 1.0966 - val_accuracy: 0.7265\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2742 - accuracy: 0.8889 - val_loss: 1.0928 - val_accuracy: 0.7179\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2733 - accuracy: 0.8889 - val_loss: 1.0872 - val_accuracy: 0.7094\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2788 - accuracy: 0.8889 - val_loss: 1.0929 - val_accuracy: 0.7094\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2800 - accuracy: 0.8889 - val_loss: 1.1006 - val_accuracy: 0.7094\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2772 - accuracy: 0.8852 - val_loss: 1.1113 - val_accuracy: 0.6752\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2754 - accuracy: 0.8963 - val_loss: 1.0989 - val_accuracy: 0.7350\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2742 - accuracy: 0.8889 - val_loss: 1.0860 - val_accuracy: 0.7265\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2758 - accuracy: 0.8889 - val_loss: 1.0837 - val_accuracy: 0.7265\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2751 - accuracy: 0.8889 - val_loss: 1.0938 - val_accuracy: 0.7265\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2746 - accuracy: 0.8852 - val_loss: 1.0951 - val_accuracy: 0.7265\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2749 - accuracy: 0.8889 - val_loss: 1.0863 - val_accuracy: 0.7179\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2739 - accuracy: 0.8889 - val_loss: 1.0914 - val_accuracy: 0.7350\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2737 - accuracy: 0.8889 - val_loss: 1.0932 - val_accuracy: 0.7265\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2735 - accuracy: 0.8889 - val_loss: 1.0911 - val_accuracy: 0.7265\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2746 - accuracy: 0.8889 - val_loss: 1.0942 - val_accuracy: 0.7265\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2737 - accuracy: 0.8889 - val_loss: 1.0839 - val_accuracy: 0.7265\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2771 - accuracy: 0.8889 - val_loss: 1.0857 - val_accuracy: 0.7179\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2752 - accuracy: 0.8889 - val_loss: 1.0982 - val_accuracy: 0.7179\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2738 - accuracy: 0.8852 - val_loss: 1.1159 - val_accuracy: 0.6752\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2748 - accuracy: 0.9000 - val_loss: 1.1087 - val_accuracy: 0.7265\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2745 - accuracy: 0.8889 - val_loss: 1.1010 - val_accuracy: 0.7265\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2740 - accuracy: 0.8889 - val_loss: 1.0926 - val_accuracy: 0.7265\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2728 - accuracy: 0.8889 - val_loss: 1.0908 - val_accuracy: 0.7350\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2742 - accuracy: 0.8889 - val_loss: 1.1035 - val_accuracy: 0.7350\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2813 - accuracy: 0.8889 - val_loss: 1.1276 - val_accuracy: 0.7265\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2853 - accuracy: 0.8778 - val_loss: 1.1294 - val_accuracy: 0.6838\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2769 - accuracy: 0.8963 - val_loss: 1.1137 - val_accuracy: 0.7179\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2782 - accuracy: 0.8852 - val_loss: 1.1102 - val_accuracy: 0.7179\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2779 - accuracy: 0.8852 - val_loss: 1.1015 - val_accuracy: 0.7179\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2730 - accuracy: 0.8889 - val_loss: 1.1095 - val_accuracy: 0.7265\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2733 - accuracy: 0.8889 - val_loss: 1.1151 - val_accuracy: 0.7265\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2745 - accuracy: 0.8889 - val_loss: 1.1186 - val_accuracy: 0.7265\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2738 - accuracy: 0.8889 - val_loss: 1.1056 - val_accuracy: 0.7179\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2729 - accuracy: 0.8889 - val_loss: 1.1092 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a33f4add8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 59us/step\n",
      "over-sampling test accuracy: 71.79%\n"
     ]
    }
   ],
   "source": [
    "acc_test2_over4 = model2_over4.evaluate(X_sel_test_over, y_sel_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test2_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 1, 2, 2, 1, 2,\n",
       "       1, 2, 1, 1, 2, 0, 2, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 0, 1, 2, 2,\n",
       "       2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 2,\n",
       "       2, 1, 2, 2, 0, 1, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 0, 2, 0,\n",
       "       0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0, 2, 1, 0, 1,\n",
       "       1, 1, 2, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model2_over4.predict_classes(X_sel_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS236     1     2\n",
       "1      NRS113     2     2\n",
       "2    CFBRSa23     0     0\n",
       "3      NRS249     2     2\n",
       "4         107     1     0\n",
       "..        ...   ...   ...\n",
       "112     NY439     2     2\n",
       "113    NRS106     0     0\n",
       "114       221     0     1\n",
       "115    NRS386     2     1\n",
       "116  CFBRSa03     1     1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model2_over4.predict_proba(X_sel_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.155347e-04</td>\n",
       "      <td>0.117173</td>\n",
       "      <td>0.882712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.696634e-03</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.992666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.967662e-01</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.003217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.470928e-04</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.406378e-01</td>\n",
       "      <td>0.314578</td>\n",
       "      <td>0.044784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4.558951e-04</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.999310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.037265e-01</td>\n",
       "      <td>0.495453</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.713146e-01</td>\n",
       "      <td>0.790131</td>\n",
       "      <td>0.038555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.473031e-10</td>\n",
       "      <td>0.587913</td>\n",
       "      <td>0.412087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.713146e-01</td>\n",
       "      <td>0.790131</td>\n",
       "      <td>0.038555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2\n",
       "0    1.155347e-04  0.117173  0.882712\n",
       "1    2.696634e-03  0.004637  0.992666\n",
       "2    9.967662e-01  0.000017  0.003217\n",
       "3    4.470928e-04  0.002181  0.997372\n",
       "4    6.406378e-01  0.314578  0.044784\n",
       "..            ...       ...       ...\n",
       "112  4.558951e-04  0.000234  0.999310\n",
       "113  5.037265e-01  0.495453  0.000820\n",
       "114  1.713146e-01  0.790131  0.038555\n",
       "115  5.473031e-10  0.587913  0.412087\n",
       "116  1.713146e-01  0.790131  0.038555\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p006p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 117 samples\n",
      "Epoch 1/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2557 - accuracy: 0.8889 - val_loss: 0.8965 - val_accuracy: 0.7009\n",
      "Epoch 2/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2570 - accuracy: 0.8889 - val_loss: 0.9051 - val_accuracy: 0.7094\n",
      "Epoch 3/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.9053 - val_accuracy: 0.7009\n",
      "Epoch 4/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2556 - accuracy: 0.8889 - val_loss: 0.9030 - val_accuracy: 0.7009\n",
      "Epoch 5/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2559 - accuracy: 0.8889 - val_loss: 0.9047 - val_accuracy: 0.7009\n",
      "Epoch 6/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2556 - accuracy: 0.8889 - val_loss: 0.9122 - val_accuracy: 0.7009\n",
      "Epoch 7/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2558 - accuracy: 0.8778 - val_loss: 0.9240 - val_accuracy: 0.6581\n",
      "Epoch 8/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2559 - accuracy: 0.8852 - val_loss: 0.9278 - val_accuracy: 0.6667\n",
      "Epoch 9/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2578 - accuracy: 0.8852 - val_loss: 0.9299 - val_accuracy: 0.6667\n",
      "Epoch 10/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2550 - accuracy: 0.9000 - val_loss: 0.9070 - val_accuracy: 0.7094\n",
      "Epoch 11/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.9006 - val_accuracy: 0.7265\n",
      "Epoch 12/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2573 - accuracy: 0.8815 - val_loss: 0.8966 - val_accuracy: 0.7265\n",
      "Epoch 13/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2564 - accuracy: 0.8852 - val_loss: 0.9083 - val_accuracy: 0.7094\n",
      "Epoch 14/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2560 - accuracy: 0.8889 - val_loss: 0.9114 - val_accuracy: 0.7094\n",
      "Epoch 15/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2570 - accuracy: 0.8889 - val_loss: 0.9043 - val_accuracy: 0.7009\n",
      "Epoch 16/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2560 - accuracy: 0.8889 - val_loss: 0.9198 - val_accuracy: 0.7094\n",
      "Epoch 17/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2564 - accuracy: 0.8852 - val_loss: 0.9248 - val_accuracy: 0.6496\n",
      "Epoch 18/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2550 - accuracy: 0.8852 - val_loss: 0.9266 - val_accuracy: 0.6496\n",
      "Epoch 19/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2548 - accuracy: 0.8852 - val_loss: 0.9162 - val_accuracy: 0.7009\n",
      "Epoch 20/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.9107 - val_accuracy: 0.6923\n",
      "Epoch 21/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2589 - accuracy: 0.8889 - val_loss: 0.9074 - val_accuracy: 0.7009\n",
      "Epoch 22/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2555 - accuracy: 0.8889 - val_loss: 0.9193 - val_accuracy: 0.7179\n",
      "Epoch 23/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2560 - accuracy: 0.8926 - val_loss: 0.9347 - val_accuracy: 0.6581\n",
      "Epoch 24/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2590 - accuracy: 0.8852 - val_loss: 0.9310 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2567 - accuracy: 0.8815 - val_loss: 0.9136 - val_accuracy: 0.7094\n",
      "Epoch 26/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2547 - accuracy: 0.8889 - val_loss: 0.9116 - val_accuracy: 0.7009\n",
      "Epoch 27/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2557 - accuracy: 0.8889 - val_loss: 0.9145 - val_accuracy: 0.7009\n",
      "Epoch 28/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2558 - accuracy: 0.8889 - val_loss: 0.9099 - val_accuracy: 0.7009\n",
      "Epoch 29/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2545 - accuracy: 0.8889 - val_loss: 0.9155 - val_accuracy: 0.7094\n",
      "Epoch 30/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2552 - accuracy: 0.8889 - val_loss: 0.9242 - val_accuracy: 0.7265\n",
      "Epoch 31/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.9237 - val_accuracy: 0.7265\n",
      "Epoch 32/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2577 - accuracy: 0.8889 - val_loss: 0.9211 - val_accuracy: 0.7265\n",
      "Epoch 33/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2542 - accuracy: 0.8889 - val_loss: 0.9009 - val_accuracy: 0.7094\n",
      "Epoch 34/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2593 - accuracy: 0.8889 - val_loss: 0.8947 - val_accuracy: 0.7094\n",
      "Epoch 35/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2603 - accuracy: 0.8889 - val_loss: 0.9070 - val_accuracy: 0.7009\n",
      "Epoch 36/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2567 - accuracy: 0.8889 - val_loss: 0.9235 - val_accuracy: 0.7009\n",
      "Epoch 37/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2547 - accuracy: 0.8889 - val_loss: 0.9153 - val_accuracy: 0.7009\n",
      "Epoch 38/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2547 - accuracy: 0.8889 - val_loss: 0.9068 - val_accuracy: 0.7009\n",
      "Epoch 39/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2571 - accuracy: 0.8889 - val_loss: 0.8995 - val_accuracy: 0.7009\n",
      "Epoch 40/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2560 - accuracy: 0.8889 - val_loss: 0.9054 - val_accuracy: 0.7009\n",
      "Epoch 41/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2541 - accuracy: 0.8889 - val_loss: 0.9080 - val_accuracy: 0.7009\n",
      "Epoch 42/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2537 - accuracy: 0.8889 - val_loss: 0.9175 - val_accuracy: 0.7009\n",
      "Epoch 43/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2540 - accuracy: 0.8889 - val_loss: 0.9198 - val_accuracy: 0.7009\n",
      "Epoch 44/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2540 - accuracy: 0.8889 - val_loss: 0.9136 - val_accuracy: 0.7009\n",
      "Epoch 45/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2549 - accuracy: 0.8852 - val_loss: 0.9150 - val_accuracy: 0.7094\n",
      "Epoch 46/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2550 - accuracy: 0.8852 - val_loss: 0.9112 - val_accuracy: 0.7009\n",
      "Epoch 47/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2555 - accuracy: 0.8889 - val_loss: 0.9163 - val_accuracy: 0.7094\n",
      "Epoch 48/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2542 - accuracy: 0.8889 - val_loss: 0.9249 - val_accuracy: 0.7179\n",
      "Epoch 49/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2531 - accuracy: 0.8889 - val_loss: 0.9274 - val_accuracy: 0.6581\n",
      "Epoch 50/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2544 - accuracy: 0.8852 - val_loss: 0.9281 - val_accuracy: 0.6496\n",
      "Epoch 51/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2558 - accuracy: 0.8852 - val_loss: 0.9319 - val_accuracy: 0.6410\n",
      "Epoch 52/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2548 - accuracy: 0.8852 - val_loss: 0.9280 - val_accuracy: 0.6496\n",
      "Epoch 53/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2547 - accuracy: 0.8852 - val_loss: 0.9232 - val_accuracy: 0.6496\n",
      "Epoch 54/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2564 - accuracy: 0.8852 - val_loss: 0.9186 - val_accuracy: 0.6410\n",
      "Epoch 55/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2587 - accuracy: 0.8778 - val_loss: 0.9134 - val_accuracy: 0.7094\n",
      "Epoch 56/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2559 - accuracy: 0.8889 - val_loss: 0.9169 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2540 - accuracy: 0.8889 - val_loss: 0.9165 - val_accuracy: 0.7179\n",
      "Epoch 58/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.9296 - val_accuracy: 0.6667\n",
      "Epoch 59/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2551 - accuracy: 0.8741 - val_loss: 0.9288 - val_accuracy: 0.7094\n",
      "Epoch 60/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2547 - accuracy: 0.8889 - val_loss: 0.9195 - val_accuracy: 0.7009\n",
      "Epoch 61/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2526 - accuracy: 0.8889 - val_loss: 0.9100 - val_accuracy: 0.7009\n",
      "Epoch 62/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2562 - accuracy: 0.8889 - val_loss: 0.9152 - val_accuracy: 0.7009\n",
      "Epoch 63/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.9264 - val_accuracy: 0.7009\n",
      "Epoch 64/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.9464 - val_accuracy: 0.6410\n",
      "Epoch 65/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2568 - accuracy: 0.8852 - val_loss: 0.9537 - val_accuracy: 0.6410\n",
      "Epoch 66/1000\n",
      "270/270 [==============================] - 0s 52us/step - loss: 0.2572 - accuracy: 0.8852 - val_loss: 0.9465 - val_accuracy: 0.6496\n",
      "Epoch 67/1000\n",
      "270/270 [==============================] - 0s 50us/step - loss: 0.2569 - accuracy: 0.8852 - val_loss: 0.9327 - val_accuracy: 0.6496\n",
      "Epoch 68/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2542 - accuracy: 0.8852 - val_loss: 0.9296 - val_accuracy: 0.7009\n",
      "Epoch 69/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 0.9383 - val_accuracy: 0.7094\n",
      "Epoch 70/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2587 - accuracy: 0.8889 - val_loss: 0.9458 - val_accuracy: 0.7009\n",
      "Epoch 71/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2584 - accuracy: 0.8889 - val_loss: 0.9286 - val_accuracy: 0.6923\n",
      "Epoch 72/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2538 - accuracy: 0.8889 - val_loss: 0.9373 - val_accuracy: 0.6923\n",
      "Epoch 73/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2552 - accuracy: 0.8889 - val_loss: 0.9377 - val_accuracy: 0.7009\n",
      "Epoch 74/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2562 - accuracy: 0.8778 - val_loss: 0.9394 - val_accuracy: 0.6496\n",
      "Epoch 75/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2555 - accuracy: 0.8852 - val_loss: 0.9457 - val_accuracy: 0.6496\n",
      "Epoch 76/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2538 - accuracy: 0.8852 - val_loss: 0.9355 - val_accuracy: 0.6410\n",
      "Epoch 77/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2574 - accuracy: 0.8741 - val_loss: 0.9122 - val_accuracy: 0.7009\n",
      "Epoch 78/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2550 - accuracy: 0.8889 - val_loss: 0.9083 - val_accuracy: 0.7009\n",
      "Epoch 79/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.9268 - val_accuracy: 0.6496\n",
      "Epoch 80/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2557 - accuracy: 0.8852 - val_loss: 0.9313 - val_accuracy: 0.6496\n",
      "Epoch 81/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2572 - accuracy: 0.8852 - val_loss: 0.9302 - val_accuracy: 0.6496\n",
      "Epoch 82/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2550 - accuracy: 0.8852 - val_loss: 0.9260 - val_accuracy: 0.6496\n",
      "Epoch 83/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2549 - accuracy: 0.8778 - val_loss: 0.9282 - val_accuracy: 0.6752\n",
      "Epoch 84/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2564 - accuracy: 0.8852 - val_loss: 0.9202 - val_accuracy: 0.7265\n",
      "Epoch 85/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2578 - accuracy: 0.8815 - val_loss: 0.9116 - val_accuracy: 0.7009\n",
      "Epoch 86/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2585 - accuracy: 0.8852 - val_loss: 0.9117 - val_accuracy: 0.7179\n",
      "Epoch 87/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2577 - accuracy: 0.8889 - val_loss: 0.9191 - val_accuracy: 0.7265\n",
      "Epoch 88/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2589 - accuracy: 0.8889 - val_loss: 0.9319 - val_accuracy: 0.7179\n",
      "Epoch 89/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2578 - accuracy: 0.8889 - val_loss: 0.9341 - val_accuracy: 0.7179\n",
      "Epoch 90/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2564 - accuracy: 0.8889 - val_loss: 0.9405 - val_accuracy: 0.7179\n",
      "Epoch 91/1000\n",
      "270/270 [==============================] - 0s 51us/step - loss: 0.2578 - accuracy: 0.8889 - val_loss: 0.9480 - val_accuracy: 0.7179\n",
      "Epoch 92/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2572 - accuracy: 0.8889 - val_loss: 0.9438 - val_accuracy: 0.7009\n",
      "Epoch 93/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2521 - accuracy: 0.8778 - val_loss: 0.9361 - val_accuracy: 0.7009\n",
      "Epoch 94/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2562 - accuracy: 0.8889 - val_loss: 0.9357 - val_accuracy: 0.7094\n",
      "Epoch 95/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2605 - accuracy: 0.8778 - val_loss: 0.9420 - val_accuracy: 0.6581\n",
      "Epoch 96/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2554 - accuracy: 0.8852 - val_loss: 0.9350 - val_accuracy: 0.6496\n",
      "Epoch 97/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2528 - accuracy: 0.8889 - val_loss: 0.9252 - val_accuracy: 0.6923\n",
      "Epoch 98/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2545 - accuracy: 0.8889 - val_loss: 0.9152 - val_accuracy: 0.7094\n",
      "Epoch 99/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2566 - accuracy: 0.8889 - val_loss: 0.9132 - val_accuracy: 0.7179\n",
      "Epoch 100/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2567 - accuracy: 0.8889 - val_loss: 0.9097 - val_accuracy: 0.7179\n",
      "Epoch 101/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.9209 - val_accuracy: 0.7094\n",
      "Epoch 102/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2538 - accuracy: 0.8778 - val_loss: 0.9234 - val_accuracy: 0.6581\n",
      "Epoch 103/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2541 - accuracy: 0.8704 - val_loss: 0.9313 - val_accuracy: 0.7009\n",
      "Epoch 104/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 0.9406 - val_accuracy: 0.6581\n",
      "Epoch 105/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2538 - accuracy: 0.8852 - val_loss: 0.9349 - val_accuracy: 0.6581\n",
      "Epoch 106/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2538 - accuracy: 0.9000 - val_loss: 0.9235 - val_accuracy: 0.7009\n",
      "Epoch 107/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2526 - accuracy: 0.8889 - val_loss: 0.9226 - val_accuracy: 0.7009\n",
      "Epoch 108/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2549 - accuracy: 0.8889 - val_loss: 0.9269 - val_accuracy: 0.7009\n",
      "Epoch 109/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9441 - val_accuracy: 0.6496\n",
      "Epoch 110/1000\n",
      "270/270 [==============================] - 0s 53us/step - loss: 0.2541 - accuracy: 0.8852 - val_loss: 0.9697 - val_accuracy: 0.6410\n",
      "Epoch 111/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2604 - accuracy: 0.8852 - val_loss: 0.9605 - val_accuracy: 0.6496\n",
      "Epoch 112/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2580 - accuracy: 0.8815 - val_loss: 0.9336 - val_accuracy: 0.6667\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 76us/step - loss: 0.2575 - accuracy: 0.8778 - val_loss: 0.9277 - val_accuracy: 0.6496\n",
      "Epoch 114/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2542 - accuracy: 0.8852 - val_loss: 0.9274 - val_accuracy: 0.6496\n",
      "Epoch 115/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2530 - accuracy: 0.8852 - val_loss: 0.9340 - val_accuracy: 0.6581\n",
      "Epoch 116/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2536 - accuracy: 0.8852 - val_loss: 0.9326 - val_accuracy: 0.7094\n",
      "Epoch 117/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2567 - accuracy: 0.8852 - val_loss: 0.9460 - val_accuracy: 0.6667\n",
      "Epoch 118/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2551 - accuracy: 0.8815 - val_loss: 0.9372 - val_accuracy: 0.7009\n",
      "Epoch 119/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.9305 - val_accuracy: 0.7009\n",
      "Epoch 120/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 0.9260 - val_accuracy: 0.7009\n",
      "Epoch 121/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2538 - accuracy: 0.8889 - val_loss: 0.9248 - val_accuracy: 0.7009\n",
      "Epoch 122/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2555 - accuracy: 0.8889 - val_loss: 0.9276 - val_accuracy: 0.7094\n",
      "Epoch 123/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9420 - val_accuracy: 0.6581\n",
      "Epoch 124/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2533 - accuracy: 0.8815 - val_loss: 0.9462 - val_accuracy: 0.6496\n",
      "Epoch 125/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2543 - accuracy: 0.8815 - val_loss: 0.9503 - val_accuracy: 0.6581\n",
      "Epoch 126/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2544 - accuracy: 0.8852 - val_loss: 0.9431 - val_accuracy: 0.6581\n",
      "Epoch 127/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2528 - accuracy: 0.8852 - val_loss: 0.9335 - val_accuracy: 0.7179\n",
      "Epoch 128/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2531 - accuracy: 0.8889 - val_loss: 0.9281 - val_accuracy: 0.7094\n",
      "Epoch 129/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9269 - val_accuracy: 0.7094\n",
      "Epoch 130/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2529 - accuracy: 0.8889 - val_loss: 0.9222 - val_accuracy: 0.7179\n",
      "Epoch 131/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2524 - accuracy: 0.8889 - val_loss: 0.9257 - val_accuracy: 0.7094\n",
      "Epoch 132/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2529 - accuracy: 0.8889 - val_loss: 0.9303 - val_accuracy: 0.7179\n",
      "Epoch 133/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2525 - accuracy: 0.8889 - val_loss: 0.9367 - val_accuracy: 0.7179\n",
      "Epoch 134/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9404 - val_accuracy: 0.7094\n",
      "Epoch 135/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2545 - accuracy: 0.8778 - val_loss: 0.9523 - val_accuracy: 0.6581\n",
      "Epoch 136/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2543 - accuracy: 0.8852 - val_loss: 0.9522 - val_accuracy: 0.6581\n",
      "Epoch 137/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2536 - accuracy: 0.8815 - val_loss: 0.9466 - val_accuracy: 0.7009\n",
      "Epoch 138/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2529 - accuracy: 0.8778 - val_loss: 0.9480 - val_accuracy: 0.6581\n",
      "Epoch 139/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.9384 - val_accuracy: 0.7094\n",
      "Epoch 140/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2554 - accuracy: 0.8815 - val_loss: 0.9378 - val_accuracy: 0.7094\n",
      "Epoch 141/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.9342 - val_accuracy: 0.7179\n",
      "Epoch 142/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2509 - accuracy: 0.8815 - val_loss: 0.9306 - val_accuracy: 0.7265\n",
      "Epoch 143/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2561 - accuracy: 0.8889 - val_loss: 0.9315 - val_accuracy: 0.7094\n",
      "Epoch 144/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2570 - accuracy: 0.8889 - val_loss: 0.9355 - val_accuracy: 0.7179\n",
      "Epoch 145/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2543 - accuracy: 0.8852 - val_loss: 0.9424 - val_accuracy: 0.6581\n",
      "Epoch 146/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2527 - accuracy: 0.8815 - val_loss: 0.9406 - val_accuracy: 0.7009\n",
      "Epoch 147/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2520 - accuracy: 0.8852 - val_loss: 0.9360 - val_accuracy: 0.7009\n",
      "Epoch 148/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9310 - val_accuracy: 0.7094\n",
      "Epoch 149/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2530 - accuracy: 0.8852 - val_loss: 0.9318 - val_accuracy: 0.7179\n",
      "Epoch 150/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2521 - accuracy: 0.8815 - val_loss: 0.9403 - val_accuracy: 0.7179\n",
      "Epoch 151/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2577 - accuracy: 0.8778 - val_loss: 0.9511 - val_accuracy: 0.6667\n",
      "Epoch 152/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2572 - accuracy: 0.8852 - val_loss: 0.9408 - val_accuracy: 0.6667\n",
      "Epoch 153/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2532 - accuracy: 0.8889 - val_loss: 0.9268 - val_accuracy: 0.7265\n",
      "Epoch 154/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2548 - accuracy: 0.8778 - val_loss: 0.9177 - val_accuracy: 0.7265\n",
      "Epoch 155/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2576 - accuracy: 0.8815 - val_loss: 0.9153 - val_accuracy: 0.7179\n",
      "Epoch 156/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2543 - accuracy: 0.8852 - val_loss: 0.9205 - val_accuracy: 0.7009\n",
      "Epoch 157/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2529 - accuracy: 0.8852 - val_loss: 0.9407 - val_accuracy: 0.7094\n",
      "Epoch 158/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2546 - accuracy: 0.8889 - val_loss: 0.9419 - val_accuracy: 0.7094\n",
      "Epoch 159/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2530 - accuracy: 0.8889 - val_loss: 0.9308 - val_accuracy: 0.7009\n",
      "Epoch 160/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9229 - val_accuracy: 0.7009\n",
      "Epoch 161/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9268 - val_accuracy: 0.7009\n",
      "Epoch 162/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 0.9469 - val_accuracy: 0.7094\n",
      "Epoch 163/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9584 - val_accuracy: 0.6581\n",
      "Epoch 164/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2550 - accuracy: 0.8852 - val_loss: 0.9478 - val_accuracy: 0.6581\n",
      "Epoch 165/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2535 - accuracy: 0.8963 - val_loss: 0.9356 - val_accuracy: 0.7009\n",
      "Epoch 166/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2551 - accuracy: 0.8889 - val_loss: 0.9285 - val_accuracy: 0.7265\n",
      "Epoch 167/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2544 - accuracy: 0.8778 - val_loss: 0.9417 - val_accuracy: 0.6496\n",
      "Epoch 168/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2520 - accuracy: 0.8852 - val_loss: 0.9610 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2555 - accuracy: 0.8852 - val_loss: 0.9756 - val_accuracy: 0.6581\n",
      "Epoch 170/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2581 - accuracy: 0.8741 - val_loss: 0.9543 - val_accuracy: 0.7094\n",
      "Epoch 171/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2535 - accuracy: 0.8889 - val_loss: 0.9404 - val_accuracy: 0.7009\n",
      "Epoch 172/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2522 - accuracy: 0.8889 - val_loss: 0.9375 - val_accuracy: 0.7009\n",
      "Epoch 173/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2512 - accuracy: 0.8889 - val_loss: 0.9473 - val_accuracy: 0.7009\n",
      "Epoch 174/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2546 - accuracy: 0.8852 - val_loss: 0.9714 - val_accuracy: 0.6581\n",
      "Epoch 175/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2558 - accuracy: 0.8852 - val_loss: 0.9510 - val_accuracy: 0.6496\n",
      "Epoch 176/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2526 - accuracy: 0.8778 - val_loss: 0.9467 - val_accuracy: 0.7009\n",
      "Epoch 177/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2526 - accuracy: 0.8889 - val_loss: 0.9605 - val_accuracy: 0.7009\n",
      "Epoch 178/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2528 - accuracy: 0.8852 - val_loss: 0.9701 - val_accuracy: 0.6496\n",
      "Epoch 179/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2541 - accuracy: 0.8852 - val_loss: 0.9570 - val_accuracy: 0.6496\n",
      "Epoch 180/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2525 - accuracy: 0.8815 - val_loss: 0.9417 - val_accuracy: 0.7009\n",
      "Epoch 181/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9330 - val_accuracy: 0.7094\n",
      "Epoch 182/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2527 - accuracy: 0.8889 - val_loss: 0.9367 - val_accuracy: 0.7094\n",
      "Epoch 183/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2527 - accuracy: 0.8889 - val_loss: 0.9372 - val_accuracy: 0.7094\n",
      "Epoch 184/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9335 - val_accuracy: 0.7179\n",
      "Epoch 185/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2531 - accuracy: 0.8889 - val_loss: 0.9333 - val_accuracy: 0.7265\n",
      "Epoch 186/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2537 - accuracy: 0.8889 - val_loss: 0.9293 - val_accuracy: 0.7179\n",
      "Epoch 187/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9353 - val_accuracy: 0.7094\n",
      "Epoch 188/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9456 - val_accuracy: 0.7094\n",
      "Epoch 189/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 0.9584 - val_accuracy: 0.7094\n",
      "Epoch 190/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.9410 - val_accuracy: 0.7009\n",
      "Epoch 191/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9416 - val_accuracy: 0.6923\n",
      "Epoch 192/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 0.9529 - val_accuracy: 0.7094\n",
      "Epoch 193/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9558 - val_accuracy: 0.7094\n",
      "Epoch 194/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9508 - val_accuracy: 0.7094\n",
      "Epoch 195/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2510 - accuracy: 0.8889 - val_loss: 0.9420 - val_accuracy: 0.7094\n",
      "Epoch 196/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2525 - accuracy: 0.8889 - val_loss: 0.9371 - val_accuracy: 0.7094\n",
      "Epoch 197/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9244 - val_accuracy: 0.7179\n",
      "Epoch 198/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2528 - accuracy: 0.8889 - val_loss: 0.9305 - val_accuracy: 0.7094\n",
      "Epoch 199/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2512 - accuracy: 0.8889 - val_loss: 0.9487 - val_accuracy: 0.7179\n",
      "Epoch 200/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 0.9569 - val_accuracy: 0.7179\n",
      "Epoch 201/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2532 - accuracy: 0.8889 - val_loss: 0.9552 - val_accuracy: 0.6581\n",
      "Epoch 202/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2535 - accuracy: 0.8852 - val_loss: 0.9502 - val_accuracy: 0.6581\n",
      "Epoch 203/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2513 - accuracy: 0.8815 - val_loss: 0.9446 - val_accuracy: 0.6496\n",
      "Epoch 204/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2512 - accuracy: 0.8926 - val_loss: 0.9385 - val_accuracy: 0.7009\n",
      "Epoch 205/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2499 - accuracy: 0.8889 - val_loss: 0.9421 - val_accuracy: 0.7009\n",
      "Epoch 206/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9505 - val_accuracy: 0.7009\n",
      "Epoch 207/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9341 - val_accuracy: 0.7009\n",
      "Epoch 208/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2524 - accuracy: 0.8889 - val_loss: 0.9312 - val_accuracy: 0.7094\n",
      "Epoch 209/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2527 - accuracy: 0.8889 - val_loss: 0.9333 - val_accuracy: 0.7094\n",
      "Epoch 210/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9447 - val_accuracy: 0.7009\n",
      "Epoch 211/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9496 - val_accuracy: 0.7009\n",
      "Epoch 212/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2522 - accuracy: 0.8889 - val_loss: 0.9599 - val_accuracy: 0.7009\n",
      "Epoch 213/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9610 - val_accuracy: 0.7009\n",
      "Epoch 214/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2534 - accuracy: 0.8889 - val_loss: 0.9501 - val_accuracy: 0.7009\n",
      "Epoch 215/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2533 - accuracy: 0.8926 - val_loss: 0.9394 - val_accuracy: 0.7179\n",
      "Epoch 216/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2559 - accuracy: 0.8889 - val_loss: 0.9280 - val_accuracy: 0.7179\n",
      "Epoch 217/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2541 - accuracy: 0.8852 - val_loss: 0.9312 - val_accuracy: 0.7009\n",
      "Epoch 218/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9514 - val_accuracy: 0.7094\n",
      "Epoch 219/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2513 - accuracy: 0.8926 - val_loss: 0.9671 - val_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2546 - accuracy: 0.8852 - val_loss: 0.9653 - val_accuracy: 0.6667\n",
      "Epoch 221/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2540 - accuracy: 0.8852 - val_loss: 0.9569 - val_accuracy: 0.6581\n",
      "Epoch 222/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2516 - accuracy: 0.8926 - val_loss: 0.9410 - val_accuracy: 0.7094\n",
      "Epoch 223/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9311 - val_accuracy: 0.7094\n",
      "Epoch 224/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2520 - accuracy: 0.8852 - val_loss: 0.9265 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2538 - accuracy: 0.8889 - val_loss: 0.9227 - val_accuracy: 0.7094\n",
      "Epoch 226/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 0.9339 - val_accuracy: 0.7094\n",
      "Epoch 227/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2535 - accuracy: 0.8889 - val_loss: 0.9386 - val_accuracy: 0.7094\n",
      "Epoch 228/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9435 - val_accuracy: 0.7094\n",
      "Epoch 229/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2516 - accuracy: 0.8852 - val_loss: 0.9528 - val_accuracy: 0.7094\n",
      "Epoch 230/1000\n",
      "270/270 [==============================] - 0s 220us/step - loss: 0.2504 - accuracy: 0.8852 - val_loss: 0.9506 - val_accuracy: 0.6581\n",
      "Epoch 231/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 0.9381 - val_accuracy: 0.7265\n",
      "Epoch 232/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2527 - accuracy: 0.8889 - val_loss: 0.9206 - val_accuracy: 0.7265\n",
      "Epoch 233/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 0.9160 - val_accuracy: 0.7094\n",
      "Epoch 234/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 0.9213 - val_accuracy: 0.7094\n",
      "Epoch 235/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9315 - val_accuracy: 0.7179\n",
      "Epoch 236/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2505 - accuracy: 0.8852 - val_loss: 0.9338 - val_accuracy: 0.7094\n",
      "Epoch 237/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9331 - val_accuracy: 0.7094\n",
      "Epoch 238/1000\n",
      "270/270 [==============================] - 0s 155us/step - loss: 0.2501 - accuracy: 0.8889 - val_loss: 0.9280 - val_accuracy: 0.7094\n",
      "Epoch 239/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2536 - accuracy: 0.8778 - val_loss: 0.9238 - val_accuracy: 0.7350\n",
      "Epoch 240/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 0.9337 - val_accuracy: 0.7179\n",
      "Epoch 241/1000\n",
      "270/270 [==============================] - 0s 119us/step - loss: 0.2526 - accuracy: 0.8963 - val_loss: 0.9428 - val_accuracy: 0.6581\n",
      "Epoch 242/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2513 - accuracy: 0.8852 - val_loss: 0.9530 - val_accuracy: 0.6496\n",
      "Epoch 243/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2513 - accuracy: 0.8852 - val_loss: 0.9505 - val_accuracy: 0.6496\n",
      "Epoch 244/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2501 - accuracy: 0.8852 - val_loss: 0.9455 - val_accuracy: 0.7009\n",
      "Epoch 245/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.90 - 0s 611us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9366 - val_accuracy: 0.7094\n",
      "Epoch 246/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9344 - val_accuracy: 0.7094\n",
      "Epoch 247/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2535 - accuracy: 0.8852 - val_loss: 0.9431 - val_accuracy: 0.7094\n",
      "Epoch 248/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2538 - accuracy: 0.8889 - val_loss: 0.9517 - val_accuracy: 0.7179\n",
      "Epoch 249/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2548 - accuracy: 0.8852 - val_loss: 0.9656 - val_accuracy: 0.6667\n",
      "Epoch 250/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2515 - accuracy: 0.8852 - val_loss: 0.9495 - val_accuracy: 0.6581\n",
      "Epoch 251/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2503 - accuracy: 0.8815 - val_loss: 0.9314 - val_accuracy: 0.7094\n",
      "Epoch 252/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2526 - accuracy: 0.8815 - val_loss: 0.9255 - val_accuracy: 0.7179\n",
      "Epoch 253/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2524 - accuracy: 0.8889 - val_loss: 0.9352 - val_accuracy: 0.7265\n",
      "Epoch 254/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2504 - accuracy: 0.8889 - val_loss: 0.9497 - val_accuracy: 0.6667\n",
      "Epoch 255/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2525 - accuracy: 0.8889 - val_loss: 0.9527 - val_accuracy: 0.7265\n",
      "Epoch 256/1000\n",
      "270/270 [==============================] - 0s 487us/step - loss: 0.2524 - accuracy: 0.8889 - val_loss: 0.9389 - val_accuracy: 0.7179\n",
      "Epoch 257/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2545 - accuracy: 0.8889 - val_loss: 0.9342 - val_accuracy: 0.7094\n",
      "Epoch 258/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2579 - accuracy: 0.8889 - val_loss: 0.9359 - val_accuracy: 0.7094\n",
      "Epoch 259/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2555 - accuracy: 0.8889 - val_loss: 0.9571 - val_accuracy: 0.7009\n",
      "Epoch 260/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9617 - val_accuracy: 0.7094\n",
      "Epoch 261/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2529 - accuracy: 0.8741 - val_loss: 0.9716 - val_accuracy: 0.6667\n",
      "Epoch 262/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2538 - accuracy: 0.8815 - val_loss: 0.9668 - val_accuracy: 0.6752\n",
      "Epoch 263/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2544 - accuracy: 0.8852 - val_loss: 0.9619 - val_accuracy: 0.7265\n",
      "Epoch 264/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2532 - accuracy: 0.8889 - val_loss: 0.9430 - val_accuracy: 0.7265\n",
      "Epoch 265/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2525 - accuracy: 0.8926 - val_loss: 0.9338 - val_accuracy: 0.7179\n",
      "Epoch 266/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.9476 - val_accuracy: 0.6581\n",
      "Epoch 267/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2515 - accuracy: 0.8889 - val_loss: 0.9399 - val_accuracy: 0.7094\n",
      "Epoch 268/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9404 - val_accuracy: 0.7094\n",
      "Epoch 269/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9471 - val_accuracy: 0.6581\n",
      "Epoch 270/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2516 - accuracy: 0.8852 - val_loss: 0.9632 - val_accuracy: 0.6581\n",
      "Epoch 271/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2523 - accuracy: 0.8815 - val_loss: 0.9579 - val_accuracy: 0.6581\n",
      "Epoch 272/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2510 - accuracy: 0.8852 - val_loss: 0.9526 - val_accuracy: 0.7094\n",
      "Epoch 273/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9553 - val_accuracy: 0.7094\n",
      "Epoch 274/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2504 - accuracy: 0.8778 - val_loss: 0.9703 - val_accuracy: 0.6581\n",
      "Epoch 275/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2511 - accuracy: 0.8852 - val_loss: 0.9755 - val_accuracy: 0.6667\n",
      "Epoch 276/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2518 - accuracy: 0.8852 - val_loss: 0.9752 - val_accuracy: 0.6581\n",
      "Epoch 277/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2509 - accuracy: 0.8852 - val_loss: 0.9690 - val_accuracy: 0.6667\n",
      "Epoch 278/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2499 - accuracy: 0.8926 - val_loss: 0.9573 - val_accuracy: 0.7179\n",
      "Epoch 279/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2507 - accuracy: 0.8889 - val_loss: 0.9556 - val_accuracy: 0.7265\n",
      "Epoch 280/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2512 - accuracy: 0.8852 - val_loss: 0.9621 - val_accuracy: 0.7265\n",
      "Epoch 281/1000\n",
      "270/270 [==============================] - 0s 48us/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 0.9807 - val_accuracy: 0.6581\n",
      "Epoch 282/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2518 - accuracy: 0.8852 - val_loss: 0.9922 - val_accuracy: 0.6667\n",
      "Epoch 283/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2547 - accuracy: 0.8852 - val_loss: 1.0108 - val_accuracy: 0.6581\n",
      "Epoch 284/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2583 - accuracy: 0.8852 - val_loss: 1.0098 - val_accuracy: 0.6581\n",
      "Epoch 285/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2551 - accuracy: 0.8852 - val_loss: 0.9866 - val_accuracy: 0.6667\n",
      "Epoch 286/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2509 - accuracy: 0.8852 - val_loss: 0.9736 - val_accuracy: 0.6581\n",
      "Epoch 287/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2512 - accuracy: 0.8778 - val_loss: 0.9566 - val_accuracy: 0.7094\n",
      "Epoch 288/1000\n",
      "270/270 [==============================] - 0s 308us/step - loss: 0.2507 - accuracy: 0.8852 - val_loss: 0.9539 - val_accuracy: 0.7094\n",
      "Epoch 289/1000\n",
      "270/270 [==============================] - 0s 193us/step - loss: 0.2510 - accuracy: 0.8889 - val_loss: 0.9447 - val_accuracy: 0.7094\n",
      "Epoch 290/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2512 - accuracy: 0.8889 - val_loss: 0.9350 - val_accuracy: 0.7009\n",
      "Epoch 291/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9350 - val_accuracy: 0.7179\n",
      "Epoch 292/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9429 - val_accuracy: 0.7265\n",
      "Epoch 293/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9575 - val_accuracy: 0.6752\n",
      "Epoch 294/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.9716 - val_accuracy: 0.6752\n",
      "Epoch 295/1000\n",
      "270/270 [==============================] - 0s 320us/step - loss: 0.2530 - accuracy: 0.8815 - val_loss: 0.9738 - val_accuracy: 0.6667\n",
      "Epoch 296/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2517 - accuracy: 0.8815 - val_loss: 0.9718 - val_accuracy: 0.7265\n",
      "Epoch 297/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2511 - accuracy: 0.8889 - val_loss: 0.9722 - val_accuracy: 0.7179\n",
      "Epoch 298/1000\n",
      "270/270 [==============================] - 0s 191us/step - loss: 0.2490 - accuracy: 0.8926 - val_loss: 0.9681 - val_accuracy: 0.7094\n",
      "Epoch 299/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 0.9663 - val_accuracy: 0.7009\n",
      "Epoch 300/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.2521 - accuracy: 0.8852 - val_loss: 0.9672 - val_accuracy: 0.7009\n",
      "Epoch 301/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2502 - accuracy: 0.8889 - val_loss: 0.9813 - val_accuracy: 0.7094\n",
      "Epoch 302/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2495 - accuracy: 0.8852 - val_loss: 0.9940 - val_accuracy: 0.6496\n",
      "Epoch 303/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2514 - accuracy: 0.8852 - val_loss: 1.0016 - val_accuracy: 0.6496\n",
      "Epoch 304/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2538 - accuracy: 0.8852 - val_loss: 1.0119 - val_accuracy: 0.6496\n",
      "Epoch 305/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2552 - accuracy: 0.8852 - val_loss: 1.0088 - val_accuracy: 0.6496\n",
      "Epoch 306/1000\n",
      "270/270 [==============================] - 0s 337us/step - loss: 0.2558 - accuracy: 0.8852 - val_loss: 0.9801 - val_accuracy: 0.7009\n",
      "Epoch 307/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2532 - accuracy: 0.8889 - val_loss: 0.9669 - val_accuracy: 0.7094\n",
      "Epoch 308/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 0.9546 - val_accuracy: 0.7094\n",
      "Epoch 309/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2530 - accuracy: 0.8926 - val_loss: 0.9533 - val_accuracy: 0.7094\n",
      "Epoch 310/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9672 - val_accuracy: 0.7265\n",
      "Epoch 311/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9758 - val_accuracy: 0.7265\n",
      "Epoch 312/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9744 - val_accuracy: 0.7179\n",
      "Epoch 313/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9649 - val_accuracy: 0.7094\n",
      "Epoch 314/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2507 - accuracy: 0.8889 - val_loss: 0.9647 - val_accuracy: 0.7094\n",
      "Epoch 315/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2509 - accuracy: 0.8852 - val_loss: 0.9777 - val_accuracy: 0.7094\n",
      "Epoch 316/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 0.9949 - val_accuracy: 0.6581\n",
      "Epoch 317/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2526 - accuracy: 0.8852 - val_loss: 1.0046 - val_accuracy: 0.6667\n",
      "Epoch 318/1000\n",
      "270/270 [==============================] - 0s 236us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.9934 - val_accuracy: 0.6667\n",
      "Epoch 319/1000\n",
      "270/270 [==============================] - 0s 215us/step - loss: 0.2522 - accuracy: 0.8889 - val_loss: 0.9818 - val_accuracy: 0.7094\n",
      "Epoch 320/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2507 - accuracy: 0.8815 - val_loss: 0.9838 - val_accuracy: 0.6496\n",
      "Epoch 321/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2503 - accuracy: 0.8852 - val_loss: 0.9885 - val_accuracy: 0.6581\n",
      "Epoch 322/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2535 - accuracy: 0.8852 - val_loss: 0.9957 - val_accuracy: 0.6496\n",
      "Epoch 323/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2532 - accuracy: 0.8852 - val_loss: 0.9844 - val_accuracy: 0.6496\n",
      "Epoch 324/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2540 - accuracy: 0.8815 - val_loss: 0.9577 - val_accuracy: 0.7094\n",
      "Epoch 325/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2612 - accuracy: 0.8778 - val_loss: 0.9515 - val_accuracy: 0.7094\n",
      "Epoch 326/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2559 - accuracy: 0.8889 - val_loss: 0.9604 - val_accuracy: 0.7094\n",
      "Epoch 327/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 0.9809 - val_accuracy: 0.6667\n",
      "Epoch 328/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2560 - accuracy: 0.8852 - val_loss: 0.9882 - val_accuracy: 0.7179\n",
      "Epoch 329/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2577 - accuracy: 0.8889 - val_loss: 0.9729 - val_accuracy: 0.7009\n",
      "Epoch 330/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2519 - accuracy: 0.8852 - val_loss: 0.9704 - val_accuracy: 0.6923\n",
      "Epoch 331/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2513 - accuracy: 0.8926 - val_loss: 0.9618 - val_accuracy: 0.7094\n",
      "Epoch 332/1000\n",
      "270/270 [==============================] - 0s 375us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9602 - val_accuracy: 0.7094\n",
      "Epoch 333/1000\n",
      "270/270 [==============================] - 0s 167us/step - loss: 0.2526 - accuracy: 0.8852 - val_loss: 0.9694 - val_accuracy: 0.7009\n",
      "Epoch 334/1000\n",
      "270/270 [==============================] - 0s 175us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 0.9784 - val_accuracy: 0.6581\n",
      "Epoch 335/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2505 - accuracy: 0.8852 - val_loss: 0.9753 - val_accuracy: 0.6581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2520 - accuracy: 0.8741 - val_loss: 0.9674 - val_accuracy: 0.7265\n",
      "Epoch 337/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2512 - accuracy: 0.8852 - val_loss: 0.9676 - val_accuracy: 0.6667\n",
      "Epoch 338/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 0.9764 - val_accuracy: 0.6581\n",
      "Epoch 339/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2498 - accuracy: 0.8852 - val_loss: 0.9721 - val_accuracy: 0.6581\n",
      "Epoch 340/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2508 - accuracy: 0.8778 - val_loss: 0.9619 - val_accuracy: 0.7094\n",
      "Epoch 341/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9624 - val_accuracy: 0.7094\n",
      "Epoch 342/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2529 - accuracy: 0.8889 - val_loss: 0.9787 - val_accuracy: 0.6581\n",
      "Epoch 343/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2534 - accuracy: 0.8852 - val_loss: 0.9692 - val_accuracy: 0.7179\n",
      "Epoch 344/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9602 - val_accuracy: 0.7179\n",
      "Epoch 345/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2521 - accuracy: 0.8889 - val_loss: 0.9464 - val_accuracy: 0.7009\n",
      "Epoch 346/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9498 - val_accuracy: 0.7094\n",
      "Epoch 347/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9512 - val_accuracy: 0.7179\n",
      "Epoch 348/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2511 - accuracy: 0.8889 - val_loss: 0.9575 - val_accuracy: 0.7265\n",
      "Epoch 349/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 0.9495 - val_accuracy: 0.7179\n",
      "Epoch 350/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9432 - val_accuracy: 0.7179\n",
      "Epoch 351/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2512 - accuracy: 0.8889 - val_loss: 0.9432 - val_accuracy: 0.7179\n",
      "Epoch 352/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 0.9448 - val_accuracy: 0.7179\n",
      "Epoch 353/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9489 - val_accuracy: 0.7179\n",
      "Epoch 354/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9604 - val_accuracy: 0.7009\n",
      "Epoch 355/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2497 - accuracy: 0.8889 - val_loss: 0.9673 - val_accuracy: 0.7009\n",
      "Epoch 356/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9724 - val_accuracy: 0.7009\n",
      "Epoch 357/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9751 - val_accuracy: 0.7009\n",
      "Epoch 358/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9700 - val_accuracy: 0.7094\n",
      "Epoch 359/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 0.9663 - val_accuracy: 0.7094\n",
      "Epoch 360/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 0.9684 - val_accuracy: 0.7094\n",
      "Epoch 361/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9692 - val_accuracy: 0.7094\n",
      "Epoch 362/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2499 - accuracy: 0.8926 - val_loss: 0.9728 - val_accuracy: 0.7179\n",
      "Epoch 363/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9714 - val_accuracy: 0.7179\n",
      "Epoch 364/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 0.9737 - val_accuracy: 0.7265\n",
      "Epoch 365/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2528 - accuracy: 0.8889 - val_loss: 0.9800 - val_accuracy: 0.7350\n",
      "Epoch 366/1000\n",
      "270/270 [==============================] - 0s 128us/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 0.9722 - val_accuracy: 0.7179\n",
      "Epoch 367/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2500 - accuracy: 0.8815 - val_loss: 0.9732 - val_accuracy: 0.6667\n",
      "Epoch 368/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2512 - accuracy: 0.8852 - val_loss: 0.9682 - val_accuracy: 0.6581\n",
      "Epoch 369/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2522 - accuracy: 0.8889 - val_loss: 0.9674 - val_accuracy: 0.7094\n",
      "Epoch 370/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9553 - val_accuracy: 0.7094\n",
      "Epoch 371/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 0.9501 - val_accuracy: 0.7179\n",
      "Epoch 372/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2504 - accuracy: 0.8852 - val_loss: 0.9531 - val_accuracy: 0.7179\n",
      "Epoch 373/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 0.9479 - val_accuracy: 0.7179\n",
      "Epoch 374/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2524 - accuracy: 0.8889 - val_loss: 0.9458 - val_accuracy: 0.7009\n",
      "Epoch 375/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2502 - accuracy: 0.8889 - val_loss: 0.9442 - val_accuracy: 0.7094\n",
      "Epoch 376/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.9541 - val_accuracy: 0.7265\n",
      "Epoch 377/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2539 - accuracy: 0.8778 - val_loss: 0.9787 - val_accuracy: 0.7094\n",
      "Epoch 378/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 0.9859 - val_accuracy: 0.7094\n",
      "Epoch 379/1000\n",
      "270/270 [==============================] - 0s 162us/step - loss: 0.2496 - accuracy: 0.8852 - val_loss: 0.9814 - val_accuracy: 0.7094\n",
      "Epoch 380/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 0.9736 - val_accuracy: 0.7009\n",
      "Epoch 381/1000\n",
      "270/270 [==============================] - 0s 221us/step - loss: 0.2504 - accuracy: 0.8889 - val_loss: 0.9799 - val_accuracy: 0.7009\n",
      "Epoch 382/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 0.9664 - val_accuracy: 0.7094\n",
      "Epoch 383/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2511 - accuracy: 0.8889 - val_loss: 0.9538 - val_accuracy: 0.7094\n",
      "Epoch 384/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 0.9632 - val_accuracy: 0.7179\n",
      "Epoch 385/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2516 - accuracy: 0.8889 - val_loss: 0.9721 - val_accuracy: 0.7179\n",
      "Epoch 386/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2531 - accuracy: 0.8889 - val_loss: 0.9685 - val_accuracy: 0.7179\n",
      "Epoch 387/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2522 - accuracy: 0.8889 - val_loss: 0.9627 - val_accuracy: 0.7179\n",
      "Epoch 388/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9537 - val_accuracy: 0.7094\n",
      "Epoch 389/1000\n",
      "270/270 [==============================] - 0s 170us/step - loss: 0.2546 - accuracy: 0.8778 - val_loss: 0.9459 - val_accuracy: 0.7265\n",
      "Epoch 390/1000\n",
      "270/270 [==============================] - 0s 153us/step - loss: 0.2564 - accuracy: 0.8815 - val_loss: 0.9525 - val_accuracy: 0.7094\n",
      "Epoch 391/1000\n",
      "270/270 [==============================] - 0s 331us/step - loss: 0.2513 - accuracy: 0.8926 - val_loss: 0.9626 - val_accuracy: 0.7179\n",
      "Epoch 392/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2514 - accuracy: 0.8889 - val_loss: 0.9789 - val_accuracy: 0.7179\n",
      "Epoch 393/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 0.9816 - val_accuracy: 0.7179\n",
      "Epoch 394/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2515 - accuracy: 0.8889 - val_loss: 0.9779 - val_accuracy: 0.7179\n",
      "Epoch 395/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.9719 - val_accuracy: 0.7179\n",
      "Epoch 396/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 0.9665 - val_accuracy: 0.7265\n",
      "Epoch 397/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9598 - val_accuracy: 0.7179\n",
      "Epoch 398/1000\n",
      "270/270 [==============================] - 0s 123us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9622 - val_accuracy: 0.7094\n",
      "Epoch 399/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9650 - val_accuracy: 0.7179\n",
      "Epoch 400/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 0.9646 - val_accuracy: 0.7179\n",
      "Epoch 401/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2483 - accuracy: 0.8852 - val_loss: 0.9727 - val_accuracy: 0.7179\n",
      "Epoch 402/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 0.9736 - val_accuracy: 0.7265\n",
      "Epoch 403/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9775 - val_accuracy: 0.7265\n",
      "Epoch 404/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2497 - accuracy: 0.8889 - val_loss: 0.9733 - val_accuracy: 0.7179\n",
      "Epoch 405/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9792 - val_accuracy: 0.7179\n",
      "Epoch 406/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 0.9833 - val_accuracy: 0.7179\n",
      "Epoch 407/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9923 - val_accuracy: 0.7094\n",
      "Epoch 408/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2486 - accuracy: 0.9000 - val_loss: 0.9955 - val_accuracy: 0.6667\n",
      "Epoch 409/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2521 - accuracy: 0.8852 - val_loss: 1.0012 - val_accuracy: 0.6752\n",
      "Epoch 410/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2532 - accuracy: 0.8852 - val_loss: 0.9885 - val_accuracy: 0.6581\n",
      "Epoch 411/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2517 - accuracy: 0.8926 - val_loss: 0.9642 - val_accuracy: 0.7265\n",
      "Epoch 412/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2555 - accuracy: 0.8815 - val_loss: 0.9527 - val_accuracy: 0.7265\n",
      "Epoch 413/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2541 - accuracy: 0.8815 - val_loss: 0.9610 - val_accuracy: 0.7265\n",
      "Epoch 414/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2495 - accuracy: 0.8852 - val_loss: 0.9956 - val_accuracy: 0.6667\n",
      "Epoch 415/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2533 - accuracy: 0.8852 - val_loss: 1.0055 - val_accuracy: 0.6667\n",
      "Epoch 416/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2527 - accuracy: 0.8852 - val_loss: 0.9913 - val_accuracy: 0.6667\n",
      "Epoch 417/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2502 - accuracy: 0.8852 - val_loss: 0.9760 - val_accuracy: 0.7094\n",
      "Epoch 418/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.9772 - val_accuracy: 0.7179\n",
      "Epoch 419/1000\n",
      "270/270 [==============================] - 0s 152us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9743 - val_accuracy: 0.7094\n",
      "Epoch 420/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 0.9693 - val_accuracy: 0.7094\n",
      "Epoch 421/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2507 - accuracy: 0.8889 - val_loss: 0.9718 - val_accuracy: 0.7094\n",
      "Epoch 422/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 0.9682 - val_accuracy: 0.7094\n",
      "Epoch 423/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 0.9768 - val_accuracy: 0.7094\n",
      "Epoch 424/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9798 - val_accuracy: 0.7179\n",
      "Epoch 425/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2490 - accuracy: 0.8889 - val_loss: 0.9719 - val_accuracy: 0.7094\n",
      "Epoch 426/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2498 - accuracy: 0.8852 - val_loss: 0.9701 - val_accuracy: 0.7009\n",
      "Epoch 427/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2508 - accuracy: 0.8889 - val_loss: 0.9715 - val_accuracy: 0.7009\n",
      "Epoch 428/1000\n",
      "270/270 [==============================] - 0s 227us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 0.9790 - val_accuracy: 0.7094\n",
      "Epoch 429/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.9942 - val_accuracy: 0.7094\n",
      "Epoch 430/1000\n",
      "270/270 [==============================] - 0s 163us/step - loss: 0.2498 - accuracy: 0.8741 - val_loss: 0.9971 - val_accuracy: 0.6581\n",
      "Epoch 431/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 0.9919 - val_accuracy: 0.7094\n",
      "Epoch 432/1000\n",
      "270/270 [==============================] - 0s 121us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 0.9797 - val_accuracy: 0.7094\n",
      "Epoch 433/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 0.9764 - val_accuracy: 0.7094\n",
      "Epoch 434/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9755 - val_accuracy: 0.7094\n",
      "Epoch 435/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 0.9750 - val_accuracy: 0.7094\n",
      "Epoch 436/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2504 - accuracy: 0.8889 - val_loss: 0.9717 - val_accuracy: 0.7094\n",
      "Epoch 437/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 0.9743 - val_accuracy: 0.7094\n",
      "Epoch 438/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2491 - accuracy: 0.8852 - val_loss: 0.9764 - val_accuracy: 0.6667\n",
      "Epoch 439/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2489 - accuracy: 0.8778 - val_loss: 0.9774 - val_accuracy: 0.7179\n",
      "Epoch 440/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 0.9735 - val_accuracy: 0.7179\n",
      "Epoch 441/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 0.9721 - val_accuracy: 0.7179\n",
      "Epoch 442/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 0.9821 - val_accuracy: 0.7179\n",
      "Epoch 443/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9740 - val_accuracy: 0.7265\n",
      "Epoch 444/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9703 - val_accuracy: 0.7265\n",
      "Epoch 445/1000\n",
      "270/270 [==============================] - 0s 180us/step - loss: 0.2497 - accuracy: 0.8889 - val_loss: 0.9753 - val_accuracy: 0.7265\n",
      "Epoch 446/1000\n",
      "270/270 [==============================] - 0s 284us/step - loss: 0.2501 - accuracy: 0.8889 - val_loss: 0.9779 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9788 - val_accuracy: 0.7094\n",
      "Epoch 448/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.9824 - val_accuracy: 0.7094\n",
      "Epoch 449/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 0.9758 - val_accuracy: 0.7009\n",
      "Epoch 450/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2515 - accuracy: 0.8889 - val_loss: 0.9721 - val_accuracy: 0.7009\n",
      "Epoch 451/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2544 - accuracy: 0.8889 - val_loss: 0.9744 - val_accuracy: 0.7009\n",
      "Epoch 452/1000\n",
      "270/270 [==============================] - 0s 207us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9745 - val_accuracy: 0.7094\n",
      "Epoch 453/1000\n",
      "270/270 [==============================] - 0s 239us/step - loss: 0.2499 - accuracy: 0.8889 - val_loss: 0.9797 - val_accuracy: 0.7094\n",
      "Epoch 454/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9674 - val_accuracy: 0.7094\n",
      "Epoch 455/1000\n",
      "270/270 [==============================] - 0s 177us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 0.9767 - val_accuracy: 0.7179\n",
      "Epoch 456/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 0.9798 - val_accuracy: 0.7179\n",
      "Epoch 457/1000\n",
      "270/270 [==============================] - 0s 250us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9944 - val_accuracy: 0.7265\n",
      "Epoch 458/1000\n",
      "270/270 [==============================] - 0s 192us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9735 - val_accuracy: 0.7179\n",
      "Epoch 459/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 0.9699 - val_accuracy: 0.7179\n",
      "Epoch 460/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2490 - accuracy: 0.8889 - val_loss: 0.9718 - val_accuracy: 0.7179\n",
      "Epoch 461/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9765 - val_accuracy: 0.7179\n",
      "Epoch 462/1000\n",
      "270/270 [==============================] - 0s 130us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 0.9604 - val_accuracy: 0.7094\n",
      "Epoch 463/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.9611 - val_accuracy: 0.7009\n",
      "Epoch 464/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 0.9710 - val_accuracy: 0.7094\n",
      "Epoch 465/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 0.9812 - val_accuracy: 0.7094\n",
      "Epoch 466/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 0.9917 - val_accuracy: 0.6581\n",
      "Epoch 467/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2481 - accuracy: 0.8852 - val_loss: 0.9963 - val_accuracy: 0.6581\n",
      "Epoch 468/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 0.9993 - val_accuracy: 0.6581\n",
      "Epoch 469/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 0.9936 - val_accuracy: 0.7009\n",
      "Epoch 470/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 0.9987 - val_accuracy: 0.7179\n",
      "Epoch 471/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 0.9933 - val_accuracy: 0.7179\n",
      "Epoch 472/1000\n",
      "270/270 [==============================] - 0s 183us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9903 - val_accuracy: 0.7265\n",
      "Epoch 473/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 0.9837 - val_accuracy: 0.7265\n",
      "Epoch 474/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 0.9831 - val_accuracy: 0.7265\n",
      "Epoch 475/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9890 - val_accuracy: 0.7265\n",
      "Epoch 476/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 0.9989 - val_accuracy: 0.7265\n",
      "Epoch 477/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9974 - val_accuracy: 0.7179\n",
      "Epoch 478/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.9952 - val_accuracy: 0.7094\n",
      "Epoch 479/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 0.9788 - val_accuracy: 0.7094\n",
      "Epoch 480/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 0.9763 - val_accuracy: 0.7094\n",
      "Epoch 481/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9867 - val_accuracy: 0.7179\n",
      "Epoch 482/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2495 - accuracy: 0.8889 - val_loss: 1.0033 - val_accuracy: 0.7265\n",
      "Epoch 483/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2529 - accuracy: 0.8889 - val_loss: 1.0176 - val_accuracy: 0.6752\n",
      "Epoch 484/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2511 - accuracy: 0.8778 - val_loss: 1.0010 - val_accuracy: 0.7179\n",
      "Epoch 485/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2484 - accuracy: 0.8852 - val_loss: 0.9942 - val_accuracy: 0.7094\n",
      "Epoch 486/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 0.9956 - val_accuracy: 0.7009\n",
      "Epoch 487/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 0.9950 - val_accuracy: 0.7094\n",
      "Epoch 488/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.9940 - val_accuracy: 0.7094\n",
      "Epoch 489/1000\n",
      "270/270 [==============================] - 0s 150us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9888 - val_accuracy: 0.7094\n",
      "Epoch 490/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2480 - accuracy: 0.8889 - val_loss: 0.9909 - val_accuracy: 0.7094\n",
      "Epoch 491/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 0.9825 - val_accuracy: 0.7094\n",
      "Epoch 492/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2510 - accuracy: 0.8926 - val_loss: 0.9718 - val_accuracy: 0.7094\n",
      "Epoch 493/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2547 - accuracy: 0.8815 - val_loss: 0.9669 - val_accuracy: 0.7521\n",
      "Epoch 494/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2552 - accuracy: 0.8815 - val_loss: 0.9593 - val_accuracy: 0.7179\n",
      "Epoch 495/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 0.9768 - val_accuracy: 0.7265\n",
      "Epoch 496/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2485 - accuracy: 0.8815 - val_loss: 0.9979 - val_accuracy: 0.6752\n",
      "Epoch 497/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2502 - accuracy: 0.8852 - val_loss: 0.9979 - val_accuracy: 0.6752\n",
      "Epoch 498/1000\n",
      "270/270 [==============================] - 0s 325us/step - loss: 0.2493 - accuracy: 0.8852 - val_loss: 0.9951 - val_accuracy: 0.6667\n",
      "Epoch 499/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2477 - accuracy: 0.8741 - val_loss: 0.9876 - val_accuracy: 0.7094\n",
      "Epoch 500/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 0.9929 - val_accuracy: 0.7094\n",
      "Epoch 501/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2490 - accuracy: 0.8889 - val_loss: 0.9913 - val_accuracy: 0.7009\n",
      "Epoch 502/1000\n",
      "270/270 [==============================] - 0s 147us/step - loss: 0.2495 - accuracy: 0.8889 - val_loss: 1.0004 - val_accuracy: 0.7094\n",
      "Epoch 503/1000\n",
      "270/270 [==============================] - 0s 631us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 1.0040 - val_accuracy: 0.7094\n",
      "Epoch 504/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 0.9935 - val_accuracy: 0.7009\n",
      "Epoch 505/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 0.9898 - val_accuracy: 0.7094\n",
      "Epoch 506/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 0.9772 - val_accuracy: 0.7009\n",
      "Epoch 507/1000\n",
      "270/270 [==============================] - 0s 290us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 0.9813 - val_accuracy: 0.7094\n",
      "Epoch 508/1000\n",
      "270/270 [==============================] - 0s 145us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 0.9892 - val_accuracy: 0.7094\n",
      "Epoch 509/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 0.9974 - val_accuracy: 0.7094\n",
      "Epoch 510/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2501 - accuracy: 0.8741 - val_loss: 1.0036 - val_accuracy: 0.7094\n",
      "Epoch 511/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2488 - accuracy: 0.8741 - val_loss: 1.0012 - val_accuracy: 0.7009\n",
      "Epoch 512/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2495 - accuracy: 0.8889 - val_loss: 0.9996 - val_accuracy: 0.7009\n",
      "Epoch 513/1000\n",
      "270/270 [==============================] - 0s 314us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 1.0038 - val_accuracy: 0.7265\n",
      "Epoch 514/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2524 - accuracy: 0.8852 - val_loss: 1.0042 - val_accuracy: 0.6667\n",
      "Epoch 515/1000\n",
      "270/270 [==============================] - 0s 98us/step - loss: 0.2488 - accuracy: 0.8963 - val_loss: 0.9880 - val_accuracy: 0.7009\n",
      "Epoch 516/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 0.9823 - val_accuracy: 0.7094\n",
      "Epoch 517/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 0.9766 - val_accuracy: 0.7094\n",
      "Epoch 518/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2505 - accuracy: 0.8889 - val_loss: 0.9816 - val_accuracy: 0.7179\n",
      "Epoch 519/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2493 - accuracy: 0.8926 - val_loss: 0.9942 - val_accuracy: 0.6667\n",
      "Epoch 520/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 1.0033 - val_accuracy: 0.6752\n",
      "Epoch 521/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 1.0041 - val_accuracy: 0.6838\n",
      "Epoch 522/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2496 - accuracy: 0.8815 - val_loss: 0.9949 - val_accuracy: 0.7350\n",
      "Epoch 523/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 0.9914 - val_accuracy: 0.7265\n",
      "Epoch 524/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 0.9937 - val_accuracy: 0.7179\n",
      "Epoch 525/1000\n",
      "270/270 [==============================] - 0s 201us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 0.9966 - val_accuracy: 0.7179\n",
      "Epoch 526/1000\n",
      "270/270 [==============================] - 0s 258us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0029 - val_accuracy: 0.7265\n",
      "Epoch 527/1000\n",
      "270/270 [==============================] - 0s 283us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0049 - val_accuracy: 0.7179\n",
      "Epoch 528/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0021 - val_accuracy: 0.7179\n",
      "Epoch 529/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0031 - val_accuracy: 0.7094\n",
      "Epoch 530/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 0.9963 - val_accuracy: 0.7009\n",
      "Epoch 531/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 0.9866 - val_accuracy: 0.7094\n",
      "Epoch 532/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2523 - accuracy: 0.8889 - val_loss: 0.9757 - val_accuracy: 0.7094\n",
      "Epoch 533/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2501 - accuracy: 0.8889 - val_loss: 0.9719 - val_accuracy: 0.7265\n",
      "Epoch 534/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2475 - accuracy: 0.8926 - val_loss: 0.9905 - val_accuracy: 0.6838\n",
      "Epoch 535/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2560 - accuracy: 0.8815 - val_loss: 1.0140 - val_accuracy: 0.6838\n",
      "Epoch 536/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2573 - accuracy: 0.8815 - val_loss: 1.0021 - val_accuracy: 0.6752\n",
      "Epoch 537/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2552 - accuracy: 0.8815 - val_loss: 0.9805 - val_accuracy: 0.7265\n",
      "Epoch 538/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2508 - accuracy: 0.8815 - val_loss: 0.9720 - val_accuracy: 0.7265\n",
      "Epoch 539/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 0.9741 - val_accuracy: 0.7179\n",
      "Epoch 540/1000\n",
      "270/270 [==============================] - 0s 287us/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 0.9926 - val_accuracy: 0.7094\n",
      "Epoch 541/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0115 - val_accuracy: 0.6581\n",
      "Epoch 542/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2518 - accuracy: 0.8852 - val_loss: 1.0252 - val_accuracy: 0.6496\n",
      "Epoch 543/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2509 - accuracy: 0.8963 - val_loss: 1.0084 - val_accuracy: 0.7179\n",
      "Epoch 544/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 0.9919 - val_accuracy: 0.7094\n",
      "Epoch 545/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 0.9870 - val_accuracy: 0.7179\n",
      "Epoch 546/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 0.9847 - val_accuracy: 0.7179\n",
      "Epoch 547/1000\n",
      "270/270 [==============================] - 0s 138us/step - loss: 0.2525 - accuracy: 0.8889 - val_loss: 0.9964 - val_accuracy: 0.7179\n",
      "Epoch 548/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2498 - accuracy: 0.8889 - val_loss: 1.0051 - val_accuracy: 0.7179\n",
      "Epoch 549/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2495 - accuracy: 0.8889 - val_loss: 0.9966 - val_accuracy: 0.7179\n",
      "Epoch 550/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 0.9996 - val_accuracy: 0.7179\n",
      "Epoch 551/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 1.0013 - val_accuracy: 0.7179\n",
      "Epoch 552/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0041 - val_accuracy: 0.6581\n",
      "Epoch 553/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2530 - accuracy: 0.8852 - val_loss: 1.0012 - val_accuracy: 0.6667\n",
      "Epoch 554/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2505 - accuracy: 0.8852 - val_loss: 1.0006 - val_accuracy: 0.6581\n",
      "Epoch 555/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 0.9969 - val_accuracy: 0.7179\n",
      "Epoch 556/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2469 - accuracy: 0.8741 - val_loss: 1.0041 - val_accuracy: 0.6667\n",
      "Epoch 557/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2477 - accuracy: 0.8852 - val_loss: 1.0114 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 1.0032 - val_accuracy: 0.7179\n",
      "Epoch 559/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 0.9990 - val_accuracy: 0.7094\n",
      "Epoch 560/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 0.9928 - val_accuracy: 0.7094\n",
      "Epoch 561/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 0.9895 - val_accuracy: 0.7179\n",
      "Epoch 562/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 0.9982 - val_accuracy: 0.7265\n",
      "Epoch 563/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0079 - val_accuracy: 0.7265\n",
      "Epoch 564/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 1.0111 - val_accuracy: 0.6667\n",
      "Epoch 565/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 1.0113 - val_accuracy: 0.6667\n",
      "Epoch 566/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2479 - accuracy: 0.8926 - val_loss: 1.0006 - val_accuracy: 0.7179\n",
      "Epoch 567/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 0.9983 - val_accuracy: 0.7179\n",
      "Epoch 568/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0069 - val_accuracy: 0.7179\n",
      "Epoch 569/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 0.9988 - val_accuracy: 0.7094\n",
      "Epoch 570/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9935 - val_accuracy: 0.7179\n",
      "Epoch 571/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0059 - val_accuracy: 0.7179\n",
      "Epoch 572/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0032 - val_accuracy: 0.7094\n",
      "Epoch 573/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0063 - val_accuracy: 0.7094\n",
      "Epoch 574/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9953 - val_accuracy: 0.7094\n",
      "Epoch 575/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0033 - val_accuracy: 0.7094\n",
      "Epoch 576/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2470 - accuracy: 0.8852 - val_loss: 1.0025 - val_accuracy: 0.7094\n",
      "Epoch 577/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0047 - val_accuracy: 0.7179\n",
      "Epoch 578/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2507 - accuracy: 0.8889 - val_loss: 0.9909 - val_accuracy: 0.7179\n",
      "Epoch 579/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 0.9926 - val_accuracy: 0.7094\n",
      "Epoch 580/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 0.9938 - val_accuracy: 0.7094\n",
      "Epoch 581/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2480 - accuracy: 0.8815 - val_loss: 0.9943 - val_accuracy: 0.7265\n",
      "Epoch 582/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9967 - val_accuracy: 0.7265\n",
      "Epoch 583/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2476 - accuracy: 0.8852 - val_loss: 1.0126 - val_accuracy: 0.7179\n",
      "Epoch 584/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2491 - accuracy: 0.8741 - val_loss: 1.0207 - val_accuracy: 0.6752\n",
      "Epoch 585/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 1.0089 - val_accuracy: 0.7094\n",
      "Epoch 586/1000\n",
      "270/270 [==============================] - 0s 139us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0025 - val_accuracy: 0.7094\n",
      "Epoch 587/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0024 - val_accuracy: 0.7179\n",
      "Epoch 588/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0030 - val_accuracy: 0.7265\n",
      "Epoch 589/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 1.0073 - val_accuracy: 0.7265\n",
      "Epoch 590/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0036 - val_accuracy: 0.7265\n",
      "Epoch 591/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0038 - val_accuracy: 0.7350\n",
      "Epoch 592/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2465 - accuracy: 0.8963 - val_loss: 1.0255 - val_accuracy: 0.6838\n",
      "Epoch 593/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2503 - accuracy: 0.8852 - val_loss: 1.0259 - val_accuracy: 0.6752\n",
      "Epoch 594/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2501 - accuracy: 0.8704 - val_loss: 1.0078 - val_accuracy: 0.7265\n",
      "Epoch 595/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0096 - val_accuracy: 0.7179\n",
      "Epoch 596/1000\n",
      "270/270 [==============================] - 0s 115us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.0209 - val_accuracy: 0.6667\n",
      "Epoch 597/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2491 - accuracy: 0.8852 - val_loss: 1.0256 - val_accuracy: 0.6667\n",
      "Epoch 598/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 1.0220 - val_accuracy: 0.6581\n",
      "Epoch 599/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 1.0070 - val_accuracy: 0.7094\n",
      "Epoch 600/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0025 - val_accuracy: 0.7179\n",
      "Epoch 601/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9974 - val_accuracy: 0.7265\n",
      "Epoch 602/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 1.0100 - val_accuracy: 0.7265\n",
      "Epoch 603/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2485 - accuracy: 0.8815 - val_loss: 1.0153 - val_accuracy: 0.6752\n",
      "Epoch 604/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2490 - accuracy: 0.8778 - val_loss: 1.0138 - val_accuracy: 0.7179\n",
      "Epoch 605/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 1.0108 - val_accuracy: 0.7179\n",
      "Epoch 606/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 1.0097 - val_accuracy: 0.7094\n",
      "Epoch 607/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2491 - accuracy: 0.8704 - val_loss: 1.0191 - val_accuracy: 0.6581\n",
      "Epoch 608/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 1.0164 - val_accuracy: 0.7094\n",
      "Epoch 609/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0033 - val_accuracy: 0.7265\n",
      "Epoch 610/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.0044 - val_accuracy: 0.7094\n",
      "Epoch 611/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 1.0090 - val_accuracy: 0.7094\n",
      "Epoch 612/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0217 - val_accuracy: 0.7179\n",
      "Epoch 613/1000\n",
      "270/270 [==============================] - 0s 149us/step - loss: 0.2483 - accuracy: 0.8815 - val_loss: 1.0302 - val_accuracy: 0.6667\n",
      "Epoch 614/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2504 - accuracy: 0.8852 - val_loss: 1.0280 - val_accuracy: 0.6667\n",
      "Epoch 615/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 1.0208 - val_accuracy: 0.7179\n",
      "Epoch 616/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0116 - val_accuracy: 0.7179\n",
      "Epoch 617/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0045 - val_accuracy: 0.7179\n",
      "Epoch 618/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 0.9978 - val_accuracy: 0.7179\n",
      "Epoch 619/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 0.9915 - val_accuracy: 0.7094\n",
      "Epoch 620/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0003 - val_accuracy: 0.7094\n",
      "Epoch 621/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 1.0134 - val_accuracy: 0.6752\n",
      "Epoch 622/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 1.0241 - val_accuracy: 0.6667\n",
      "Epoch 623/1000\n",
      "270/270 [==============================] - 0s 100us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 1.0139 - val_accuracy: 0.6752\n",
      "Epoch 624/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2493 - accuracy: 0.8778 - val_loss: 1.0017 - val_accuracy: 0.7179\n",
      "Epoch 625/1000\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.90 - 0s 87us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0069 - val_accuracy: 0.7179\n",
      "Epoch 626/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0077 - val_accuracy: 0.7179\n",
      "Epoch 627/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 1.0110 - val_accuracy: 0.7179\n",
      "Epoch 628/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0168 - val_accuracy: 0.7179\n",
      "Epoch 629/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0182 - val_accuracy: 0.7179\n",
      "Epoch 630/1000\n",
      "270/270 [==============================] - 0s 336us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0172 - val_accuracy: 0.7179\n",
      "Epoch 631/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2456 - accuracy: 0.8926 - val_loss: 1.0040 - val_accuracy: 0.7094\n",
      "Epoch 632/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 0.9987 - val_accuracy: 0.7094\n",
      "Epoch 633/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 0.9945 - val_accuracy: 0.7094\n",
      "Epoch 634/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 0.9995 - val_accuracy: 0.7094\n",
      "Epoch 635/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0039 - val_accuracy: 0.7094\n",
      "Epoch 636/1000\n",
      "270/270 [==============================] - 0s 422us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0004 - val_accuracy: 0.7094\n",
      "Epoch 637/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2480 - accuracy: 0.8889 - val_loss: 0.9931 - val_accuracy: 0.7179\n",
      "Epoch 638/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.9895 - val_accuracy: 0.7179\n",
      "Epoch 639/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.9971 - val_accuracy: 0.7094\n",
      "Epoch 640/1000\n",
      "270/270 [==============================] - 0s 148us/step - loss: 0.2494 - accuracy: 0.8889 - val_loss: 1.0243 - val_accuracy: 0.7179\n",
      "Epoch 641/1000\n",
      "270/270 [==============================] - 0s 158us/step - loss: 0.2502 - accuracy: 0.8778 - val_loss: 1.0397 - val_accuracy: 0.6581\n",
      "Epoch 642/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2503 - accuracy: 0.8852 - val_loss: 1.0356 - val_accuracy: 0.6581\n",
      "Epoch 643/1000\n",
      "270/270 [==============================] - 0s 217us/step - loss: 0.2482 - accuracy: 0.8926 - val_loss: 1.0193 - val_accuracy: 0.7265\n",
      "Epoch 644/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0054 - val_accuracy: 0.7094\n",
      "Epoch 645/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0102 - val_accuracy: 0.7094\n",
      "Epoch 646/1000\n",
      "270/270 [==============================] - 0s 144us/step - loss: 0.2503 - accuracy: 0.8889 - val_loss: 1.0132 - val_accuracy: 0.7265\n",
      "Epoch 647/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 1.0076 - val_accuracy: 0.7094\n",
      "Epoch 648/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0191 - val_accuracy: 0.6581\n",
      "Epoch 649/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 1.0363 - val_accuracy: 0.6667\n",
      "Epoch 650/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 1.0339 - val_accuracy: 0.6581\n",
      "Epoch 651/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2477 - accuracy: 0.8852 - val_loss: 1.0222 - val_accuracy: 0.7179\n",
      "Epoch 652/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0228 - val_accuracy: 0.7094\n",
      "Epoch 653/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0293 - val_accuracy: 0.7094\n",
      "Epoch 654/1000\n",
      "270/270 [==============================] - 0s 213us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0336 - val_accuracy: 0.7094\n",
      "Epoch 655/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.0314 - val_accuracy: 0.6752\n",
      "Epoch 656/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2478 - accuracy: 0.8778 - val_loss: 1.0249 - val_accuracy: 0.7265\n",
      "Epoch 657/1000\n",
      "270/270 [==============================] - 0s 60us/step - loss: 0.2481 - accuracy: 0.8815 - val_loss: 1.0266 - val_accuracy: 0.6752\n",
      "Epoch 658/1000\n",
      "270/270 [==============================] - 0s 143us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 1.0247 - val_accuracy: 0.6667\n",
      "Epoch 659/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 1.0259 - val_accuracy: 0.6667\n",
      "Epoch 660/1000\n",
      "270/270 [==============================] - 0s 173us/step - loss: 0.2500 - accuracy: 0.8852 - val_loss: 1.0302 - val_accuracy: 0.6667\n",
      "Epoch 661/1000\n",
      "270/270 [==============================] - 0s 238us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.0278 - val_accuracy: 0.6667\n",
      "Epoch 662/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 1.0198 - val_accuracy: 0.6667\n",
      "Epoch 663/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 1.0269 - val_accuracy: 0.6581\n",
      "Epoch 664/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2487 - accuracy: 0.8815 - val_loss: 1.0193 - val_accuracy: 0.7094\n",
      "Epoch 665/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2480 - accuracy: 0.8889 - val_loss: 1.0063 - val_accuracy: 0.7094\n",
      "Epoch 666/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0108 - val_accuracy: 0.7094\n",
      "Epoch 667/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2452 - accuracy: 0.8889 - val_loss: 1.0138 - val_accuracy: 0.7094\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 68us/step - loss: 0.2490 - accuracy: 0.8889 - val_loss: 1.0229 - val_accuracy: 0.7094\n",
      "Epoch 669/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2523 - accuracy: 0.8778 - val_loss: 1.0334 - val_accuracy: 0.6667\n",
      "Epoch 670/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2488 - accuracy: 0.8852 - val_loss: 1.0336 - val_accuracy: 0.6581\n",
      "Epoch 671/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2467 - accuracy: 0.8963 - val_loss: 1.0305 - val_accuracy: 0.7094\n",
      "Epoch 672/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0181 - val_accuracy: 0.7179\n",
      "Epoch 673/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0159 - val_accuracy: 0.7179\n",
      "Epoch 674/1000\n",
      "270/270 [==============================] - 0s 223us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0159 - val_accuracy: 0.7179\n",
      "Epoch 675/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0235 - val_accuracy: 0.7179\n",
      "Epoch 676/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0293 - val_accuracy: 0.7179\n",
      "Epoch 677/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0228 - val_accuracy: 0.7179\n",
      "Epoch 678/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 1.0228 - val_accuracy: 0.7179\n",
      "Epoch 679/1000\n",
      "270/270 [==============================] - 0s 107us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0193 - val_accuracy: 0.7094\n",
      "Epoch 680/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0276 - val_accuracy: 0.7094\n",
      "Epoch 681/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2495 - accuracy: 0.8889 - val_loss: 1.0347 - val_accuracy: 0.7094\n",
      "Epoch 682/1000\n",
      "270/270 [==============================] - 0s 246us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 1.0381 - val_accuracy: 0.7094\n",
      "Epoch 683/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0414 - val_accuracy: 0.6581\n",
      "Epoch 684/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2461 - accuracy: 0.8852 - val_loss: 1.0364 - val_accuracy: 0.6667\n",
      "Epoch 685/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2491 - accuracy: 0.8815 - val_loss: 1.0307 - val_accuracy: 0.7179\n",
      "Epoch 686/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 1.0230 - val_accuracy: 0.7265\n",
      "Epoch 687/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 1.0200 - val_accuracy: 0.7179\n",
      "Epoch 688/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0166 - val_accuracy: 0.7179\n",
      "Epoch 689/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0153 - val_accuracy: 0.7179\n",
      "Epoch 690/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0203 - val_accuracy: 0.7094\n",
      "Epoch 691/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0226 - val_accuracy: 0.7094\n",
      "Epoch 692/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0274 - val_accuracy: 0.7094\n",
      "Epoch 693/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0299 - val_accuracy: 0.7179\n",
      "Epoch 694/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0305 - val_accuracy: 0.7179\n",
      "Epoch 695/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0279 - val_accuracy: 0.7179\n",
      "Epoch 696/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 1.0342 - val_accuracy: 0.7179\n",
      "Epoch 697/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0286 - val_accuracy: 0.7179\n",
      "Epoch 698/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.0343 - val_accuracy: 0.6667\n",
      "Epoch 699/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2484 - accuracy: 0.8630 - val_loss: 1.0205 - val_accuracy: 0.7179\n",
      "Epoch 700/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2480 - accuracy: 0.8889 - val_loss: 1.0163 - val_accuracy: 0.7094\n",
      "Epoch 701/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2475 - accuracy: 0.8852 - val_loss: 1.0159 - val_accuracy: 0.7094\n",
      "Epoch 702/1000\n",
      "270/270 [==============================] - 0s 240us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0138 - val_accuracy: 0.7094\n",
      "Epoch 703/1000\n",
      "270/270 [==============================] - 0s 190us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0153 - val_accuracy: 0.7094\n",
      "Epoch 704/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0224 - val_accuracy: 0.7094\n",
      "Epoch 705/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2482 - accuracy: 0.8704 - val_loss: 1.0363 - val_accuracy: 0.6581\n",
      "Epoch 706/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 1.0397 - val_accuracy: 0.6581\n",
      "Epoch 707/1000\n",
      "270/270 [==============================] - 0s 127us/step - loss: 0.2473 - accuracy: 0.8852 - val_loss: 1.0394 - val_accuracy: 0.7094\n",
      "Epoch 708/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2485 - accuracy: 0.8778 - val_loss: 1.0397 - val_accuracy: 0.7094\n",
      "Epoch 709/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0234 - val_accuracy: 0.7094\n",
      "Epoch 710/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0140 - val_accuracy: 0.7094\n",
      "Epoch 711/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0096 - val_accuracy: 0.7009\n",
      "Epoch 712/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2499 - accuracy: 0.8889 - val_loss: 1.0257 - val_accuracy: 0.7094\n",
      "Epoch 713/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 1.0376 - val_accuracy: 0.7094\n",
      "Epoch 714/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2501 - accuracy: 0.8852 - val_loss: 1.0513 - val_accuracy: 0.6581\n",
      "Epoch 715/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.0381 - val_accuracy: 0.6581\n",
      "Epoch 716/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 1.0314 - val_accuracy: 0.7094\n",
      "Epoch 717/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 1.0271 - val_accuracy: 0.7094\n",
      "Epoch 718/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0382 - val_accuracy: 0.6581\n",
      "Epoch 719/1000\n",
      "270/270 [==============================] - 0s 151us/step - loss: 0.2469 - accuracy: 0.8852 - val_loss: 1.0425 - val_accuracy: 0.6581\n",
      "Epoch 720/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 1.0418 - val_accuracy: 0.6581\n",
      "Epoch 721/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2464 - accuracy: 0.8815 - val_loss: 1.0337 - val_accuracy: 0.7094\n",
      "Epoch 722/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2461 - accuracy: 0.8889 - val_loss: 1.0289 - val_accuracy: 0.7094\n",
      "Epoch 723/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0236 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0224 - val_accuracy: 0.7179\n",
      "Epoch 725/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2490 - accuracy: 0.8889 - val_loss: 1.0227 - val_accuracy: 0.7179\n",
      "Epoch 726/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0146 - val_accuracy: 0.7179\n",
      "Epoch 727/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0179 - val_accuracy: 0.7094\n",
      "Epoch 728/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0279 - val_accuracy: 0.7094\n",
      "Epoch 729/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0261 - val_accuracy: 0.7094\n",
      "Epoch 730/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0239 - val_accuracy: 0.7094\n",
      "Epoch 731/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0158 - val_accuracy: 0.7094\n",
      "Epoch 732/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 1.0113 - val_accuracy: 0.7094\n",
      "Epoch 733/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 1.0285 - val_accuracy: 0.7094\n",
      "Epoch 734/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0267 - val_accuracy: 0.7094\n",
      "Epoch 735/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0257 - val_accuracy: 0.7094\n",
      "Epoch 736/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0313 - val_accuracy: 0.7179\n",
      "Epoch 737/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2450 - accuracy: 0.8889 - val_loss: 1.0148 - val_accuracy: 0.7094\n",
      "Epoch 738/1000\n",
      "270/270 [==============================] - 0s 116us/step - loss: 0.2501 - accuracy: 0.8852 - val_loss: 1.0044 - val_accuracy: 0.7265\n",
      "Epoch 739/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2581 - accuracy: 0.8815 - val_loss: 1.0050 - val_accuracy: 0.7350\n",
      "Epoch 740/1000\n",
      "270/270 [==============================] - 0s 161us/step - loss: 0.2542 - accuracy: 0.8815 - val_loss: 1.0117 - val_accuracy: 0.7265\n",
      "Epoch 741/1000\n",
      "270/270 [==============================] - 0s 125us/step - loss: 0.2491 - accuracy: 0.8889 - val_loss: 1.0328 - val_accuracy: 0.7179\n",
      "Epoch 742/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0265 - val_accuracy: 0.7265\n",
      "Epoch 743/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0158 - val_accuracy: 0.7265\n",
      "Epoch 744/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0224 - val_accuracy: 0.7265\n",
      "Epoch 745/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0261 - val_accuracy: 0.7179\n",
      "Epoch 746/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0356 - val_accuracy: 0.7179\n",
      "Epoch 747/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2473 - accuracy: 0.8815 - val_loss: 1.0366 - val_accuracy: 0.7094\n",
      "Epoch 748/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0255 - val_accuracy: 0.7094\n",
      "Epoch 749/1000\n",
      "270/270 [==============================] - 0s 235us/step - loss: 0.2516 - accuracy: 0.8852 - val_loss: 1.0184 - val_accuracy: 0.7179\n",
      "Epoch 750/1000\n",
      "270/270 [==============================] - 0s 131us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 1.0162 - val_accuracy: 0.7265\n",
      "Epoch 751/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2524 - accuracy: 0.8852 - val_loss: 1.0253 - val_accuracy: 0.7094\n",
      "Epoch 752/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2508 - accuracy: 0.8852 - val_loss: 1.0305 - val_accuracy: 0.6581\n",
      "Epoch 753/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2481 - accuracy: 0.8852 - val_loss: 1.0258 - val_accuracy: 0.7094\n",
      "Epoch 754/1000\n",
      "270/270 [==============================] - 0s 86us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0270 - val_accuracy: 0.7094\n",
      "Epoch 755/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2461 - accuracy: 0.8889 - val_loss: 1.0278 - val_accuracy: 0.7094\n",
      "Epoch 756/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0320 - val_accuracy: 0.6667\n",
      "Epoch 757/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2470 - accuracy: 0.8852 - val_loss: 1.0224 - val_accuracy: 0.7094\n",
      "Epoch 758/1000\n",
      "270/270 [==============================] - 0s 172us/step - loss: 0.2492 - accuracy: 0.8815 - val_loss: 1.0212 - val_accuracy: 0.7094\n",
      "Epoch 759/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2492 - accuracy: 0.8889 - val_loss: 1.0148 - val_accuracy: 0.7094\n",
      "Epoch 760/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 1.0152 - val_accuracy: 0.7094\n",
      "Epoch 761/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 1.0144 - val_accuracy: 0.7094\n",
      "Epoch 762/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0166 - val_accuracy: 0.7094\n",
      "Epoch 763/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0222 - val_accuracy: 0.7094\n",
      "Epoch 764/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0243 - val_accuracy: 0.7094\n",
      "Epoch 765/1000\n",
      "270/270 [==============================] - 0s 108us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0237 - val_accuracy: 0.7094\n",
      "Epoch 766/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0283 - val_accuracy: 0.7094\n",
      "Epoch 767/1000\n",
      "270/270 [==============================] - 0s 59us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0325 - val_accuracy: 0.7350\n",
      "Epoch 768/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0265 - val_accuracy: 0.7179\n",
      "Epoch 769/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0332 - val_accuracy: 0.7265\n",
      "Epoch 770/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 1.0295 - val_accuracy: 0.7265\n",
      "Epoch 771/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2490 - accuracy: 0.8815 - val_loss: 1.0252 - val_accuracy: 0.7179\n",
      "Epoch 772/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2478 - accuracy: 0.8852 - val_loss: 1.0312 - val_accuracy: 0.7179\n",
      "Epoch 773/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0281 - val_accuracy: 0.7179\n",
      "Epoch 774/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 1.0231 - val_accuracy: 0.7179\n",
      "Epoch 775/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0302 - val_accuracy: 0.7094\n",
      "Epoch 776/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0302 - val_accuracy: 0.7094\n",
      "Epoch 777/1000\n",
      "270/270 [==============================] - 0s 102us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0328 - val_accuracy: 0.7094\n",
      "Epoch 778/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0295 - val_accuracy: 0.7265\n",
      "Epoch 779/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0325 - val_accuracy: 0.7179\n",
      "Epoch 780/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2456 - accuracy: 0.8889 - val_loss: 1.0221 - val_accuracy: 0.7179\n",
      "Epoch 781/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0185 - val_accuracy: 0.7179\n",
      "Epoch 782/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2487 - accuracy: 0.8889 - val_loss: 1.0222 - val_accuracy: 0.7179\n",
      "Epoch 783/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0226 - val_accuracy: 0.7179\n",
      "Epoch 784/1000\n",
      "270/270 [==============================] - 0s 200us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0262 - val_accuracy: 0.7179\n",
      "Epoch 785/1000\n",
      "270/270 [==============================] - 0s 133us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0238 - val_accuracy: 0.7265\n",
      "Epoch 786/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2502 - accuracy: 0.8889 - val_loss: 1.0118 - val_accuracy: 0.7179\n",
      "Epoch 787/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0151 - val_accuracy: 0.7179\n",
      "Epoch 788/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2461 - accuracy: 0.8889 - val_loss: 1.0288 - val_accuracy: 0.7179\n",
      "Epoch 789/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0325 - val_accuracy: 0.7179\n",
      "Epoch 790/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 1.0173 - val_accuracy: 0.7094\n",
      "Epoch 791/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0195 - val_accuracy: 0.7009\n",
      "Epoch 792/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0240 - val_accuracy: 0.7094\n",
      "Epoch 793/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2497 - accuracy: 0.8852 - val_loss: 1.0422 - val_accuracy: 0.7179\n",
      "Epoch 794/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0431 - val_accuracy: 0.7179\n",
      "Epoch 795/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0436 - val_accuracy: 0.7179\n",
      "Epoch 796/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0389 - val_accuracy: 0.7179\n",
      "Epoch 797/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2466 - accuracy: 0.8852 - val_loss: 1.0345 - val_accuracy: 0.7094\n",
      "Epoch 798/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0361 - val_accuracy: 0.7094\n",
      "Epoch 799/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0373 - val_accuracy: 0.7094\n",
      "Epoch 800/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0276 - val_accuracy: 0.7094\n",
      "Epoch 801/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0249 - val_accuracy: 0.7179\n",
      "Epoch 802/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0247 - val_accuracy: 0.7179\n",
      "Epoch 803/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0369 - val_accuracy: 0.7094\n",
      "Epoch 804/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2459 - accuracy: 0.8889 - val_loss: 1.0429 - val_accuracy: 0.7179\n",
      "Epoch 805/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0464 - val_accuracy: 0.7179\n",
      "Epoch 806/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0342 - val_accuracy: 0.7179\n",
      "Epoch 807/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0225 - val_accuracy: 0.7265\n",
      "Epoch 808/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 1.0195 - val_accuracy: 0.7179\n",
      "Epoch 809/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0287 - val_accuracy: 0.7265\n",
      "Epoch 810/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2467 - accuracy: 0.8852 - val_loss: 1.0284 - val_accuracy: 0.7094\n",
      "Epoch 811/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0204 - val_accuracy: 0.7094\n",
      "Epoch 812/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 1.0265 - val_accuracy: 0.7094\n",
      "Epoch 813/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2489 - accuracy: 0.8815 - val_loss: 1.0384 - val_accuracy: 0.7094\n",
      "Epoch 814/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 1.0519 - val_accuracy: 0.7094\n",
      "Epoch 815/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2529 - accuracy: 0.8889 - val_loss: 1.0627 - val_accuracy: 0.7179\n",
      "Epoch 816/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 1.0521 - val_accuracy: 0.7179\n",
      "Epoch 817/1000\n",
      "270/270 [==============================] - 0s 85us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0366 - val_accuracy: 0.7009\n",
      "Epoch 818/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0482 - val_accuracy: 0.7009\n",
      "Epoch 819/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2475 - accuracy: 0.8926 - val_loss: 1.0620 - val_accuracy: 0.6496\n",
      "Epoch 820/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2492 - accuracy: 0.8852 - val_loss: 1.0625 - val_accuracy: 0.6496\n",
      "Epoch 821/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 1.0411 - val_accuracy: 0.7094\n",
      "Epoch 822/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0226 - val_accuracy: 0.7094\n",
      "Epoch 823/1000\n",
      "270/270 [==============================] - 0s 176us/step - loss: 0.2497 - accuracy: 0.8815 - val_loss: 1.0194 - val_accuracy: 0.7179\n",
      "Epoch 824/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2481 - accuracy: 0.8741 - val_loss: 1.0258 - val_accuracy: 0.7094\n",
      "Epoch 825/1000\n",
      "270/270 [==============================] - 0s 142us/step - loss: 0.2441 - accuracy: 0.8926 - val_loss: 1.0480 - val_accuracy: 0.7350\n",
      "Epoch 826/1000\n",
      "270/270 [==============================] - 0s 136us/step - loss: 0.2497 - accuracy: 0.8852 - val_loss: 1.0577 - val_accuracy: 0.7350\n",
      "Epoch 827/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 1.0428 - val_accuracy: 0.7179\n",
      "Epoch 828/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0177 - val_accuracy: 0.7179\n",
      "Epoch 829/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2507 - accuracy: 0.8778 - val_loss: 1.0110 - val_accuracy: 0.7350\n",
      "Epoch 830/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2511 - accuracy: 0.8815 - val_loss: 1.0392 - val_accuracy: 0.7179\n",
      "Epoch 831/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0303 - val_accuracy: 0.7179\n",
      "Epoch 832/1000\n",
      "270/270 [==============================] - 0s 129us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0354 - val_accuracy: 0.7179\n",
      "Epoch 833/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0349 - val_accuracy: 0.7179\n",
      "Epoch 834/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0330 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 1.0286 - val_accuracy: 0.7094\n",
      "Epoch 836/1000\n",
      "270/270 [==============================] - 0s 185us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0379 - val_accuracy: 0.7094\n",
      "Epoch 837/1000\n",
      "270/270 [==============================] - 0s 182us/step - loss: 0.2483 - accuracy: 0.8852 - val_loss: 1.0398 - val_accuracy: 0.6581\n",
      "Epoch 838/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2486 - accuracy: 0.8852 - val_loss: 1.0312 - val_accuracy: 0.7094\n",
      "Epoch 839/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0192 - val_accuracy: 0.7350\n",
      "Epoch 840/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2482 - accuracy: 0.8778 - val_loss: 1.0221 - val_accuracy: 0.7179\n",
      "Epoch 841/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2474 - accuracy: 0.8889 - val_loss: 1.0213 - val_accuracy: 0.7179\n",
      "Epoch 842/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0248 - val_accuracy: 0.7265\n",
      "Epoch 843/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2463 - accuracy: 0.8852 - val_loss: 1.0246 - val_accuracy: 0.7179\n",
      "Epoch 844/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2473 - accuracy: 0.8889 - val_loss: 1.0199 - val_accuracy: 0.7265\n",
      "Epoch 845/1000\n",
      "270/270 [==============================] - 0s 104us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0152 - val_accuracy: 0.7265\n",
      "Epoch 846/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2480 - accuracy: 0.8852 - val_loss: 1.0095 - val_accuracy: 0.7179\n",
      "Epoch 847/1000\n",
      "270/270 [==============================] - 0s 165us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0182 - val_accuracy: 0.7265\n",
      "Epoch 848/1000\n",
      "270/270 [==============================] - 0s 189us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0317 - val_accuracy: 0.7350\n",
      "Epoch 849/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0376 - val_accuracy: 0.7350\n",
      "Epoch 850/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0250 - val_accuracy: 0.7265\n",
      "Epoch 851/1000\n",
      "270/270 [==============================] - 0s 184us/step - loss: 0.2482 - accuracy: 0.8889 - val_loss: 1.0256 - val_accuracy: 0.7265\n",
      "Epoch 852/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2451 - accuracy: 0.8889 - val_loss: 1.0340 - val_accuracy: 0.7179\n",
      "Epoch 853/1000\n",
      "270/270 [==============================] - 0s 97us/step - loss: 0.2453 - accuracy: 0.8889 - val_loss: 1.0417 - val_accuracy: 0.7179\n",
      "Epoch 854/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2447 - accuracy: 0.8926 - val_loss: 1.0566 - val_accuracy: 0.6667\n",
      "Epoch 855/1000\n",
      "270/270 [==============================] - 0s 109us/step - loss: 0.2479 - accuracy: 0.8852 - val_loss: 1.0684 - val_accuracy: 0.6667\n",
      "Epoch 856/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2481 - accuracy: 0.8852 - val_loss: 1.0589 - val_accuracy: 0.6667\n",
      "Epoch 857/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2463 - accuracy: 0.8815 - val_loss: 1.0507 - val_accuracy: 0.7094\n",
      "Epoch 858/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2444 - accuracy: 0.8889 - val_loss: 1.0519 - val_accuracy: 0.7094\n",
      "Epoch 859/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0497 - val_accuracy: 0.7094\n",
      "Epoch 860/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2446 - accuracy: 0.8889 - val_loss: 1.0339 - val_accuracy: 0.7094\n",
      "Epoch 861/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2514 - accuracy: 0.8778 - val_loss: 1.0219 - val_accuracy: 0.7265\n",
      "Epoch 862/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2486 - accuracy: 0.8815 - val_loss: 1.0280 - val_accuracy: 0.7094\n",
      "Epoch 863/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2429 - accuracy: 0.8889 - val_loss: 1.0521 - val_accuracy: 0.6838\n",
      "Epoch 864/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2542 - accuracy: 0.8852 - val_loss: 1.0818 - val_accuracy: 0.6838\n",
      "Epoch 865/1000\n",
      "270/270 [==============================] - 0s 187us/step - loss: 0.2603 - accuracy: 0.8852 - val_loss: 1.0766 - val_accuracy: 0.6838\n",
      "Epoch 866/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2546 - accuracy: 0.8852 - val_loss: 1.0500 - val_accuracy: 0.7094\n",
      "Epoch 867/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0361 - val_accuracy: 0.7009\n",
      "Epoch 868/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0379 - val_accuracy: 0.7094\n",
      "Epoch 869/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0367 - val_accuracy: 0.7094\n",
      "Epoch 870/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 1.0351 - val_accuracy: 0.7179\n",
      "Epoch 871/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2475 - accuracy: 0.8889 - val_loss: 1.0347 - val_accuracy: 0.7179\n",
      "Epoch 872/1000\n",
      "270/270 [==============================] - 0s 64us/step - loss: 0.2456 - accuracy: 0.8889 - val_loss: 1.0228 - val_accuracy: 0.7179\n",
      "Epoch 873/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0208 - val_accuracy: 0.7265\n",
      "Epoch 874/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2497 - accuracy: 0.8926 - val_loss: 1.0340 - val_accuracy: 0.6752\n",
      "Epoch 875/1000\n",
      "270/270 [==============================] - 0s 141us/step - loss: 0.2485 - accuracy: 0.8852 - val_loss: 1.0331 - val_accuracy: 0.6667\n",
      "Epoch 876/1000\n",
      "270/270 [==============================] - 0s 157us/step - loss: 0.2478 - accuracy: 0.8815 - val_loss: 1.0274 - val_accuracy: 0.7179\n",
      "Epoch 877/1000\n",
      "270/270 [==============================] - 0s 169us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0318 - val_accuracy: 0.7179\n",
      "Epoch 878/1000\n",
      "270/270 [==============================] - 0s 226us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0339 - val_accuracy: 0.7265\n",
      "Epoch 879/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0447 - val_accuracy: 0.7265\n",
      "Epoch 880/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0491 - val_accuracy: 0.6667\n",
      "Epoch 881/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2473 - accuracy: 0.8852 - val_loss: 1.0475 - val_accuracy: 0.7179\n",
      "Epoch 882/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 1.0418 - val_accuracy: 0.7094\n",
      "Epoch 883/1000\n",
      "270/270 [==============================] - 0s 62us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0460 - val_accuracy: 0.7094\n",
      "Epoch 884/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2465 - accuracy: 0.8889 - val_loss: 1.0459 - val_accuracy: 0.7094\n",
      "Epoch 885/1000\n",
      "270/270 [==============================] - 0s 222us/step - loss: 0.2460 - accuracy: 0.8926 - val_loss: 1.0535 - val_accuracy: 0.6581\n",
      "Epoch 886/1000\n",
      "270/270 [==============================] - 0s 245us/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 1.0460 - val_accuracy: 0.7094\n",
      "Epoch 887/1000\n",
      "270/270 [==============================] - 0s 106us/step - loss: 0.2499 - accuracy: 0.8889 - val_loss: 1.0433 - val_accuracy: 0.7094\n",
      "Epoch 888/1000\n",
      "270/270 [==============================] - 0s 88us/step - loss: 0.2486 - accuracy: 0.9000 - val_loss: 1.0544 - val_accuracy: 0.6581\n",
      "Epoch 889/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 1.0543 - val_accuracy: 0.6581\n",
      "Epoch 890/1000\n",
      "270/270 [==============================] - 0s 73us/step - loss: 0.2474 - accuracy: 0.8852 - val_loss: 1.0445 - val_accuracy: 0.7094\n",
      "Epoch 891/1000\n",
      "270/270 [==============================] - 0s 55us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0432 - val_accuracy: 0.7094\n",
      "Epoch 892/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2460 - accuracy: 0.8852 - val_loss: 1.0545 - val_accuracy: 0.7179\n",
      "Epoch 893/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0568 - val_accuracy: 0.7179\n",
      "Epoch 894/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2454 - accuracy: 0.8926 - val_loss: 1.0442 - val_accuracy: 0.7179\n",
      "Epoch 895/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0381 - val_accuracy: 0.7179\n",
      "Epoch 896/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0539 - val_accuracy: 0.7265\n",
      "Epoch 897/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2448 - accuracy: 0.8852 - val_loss: 1.0581 - val_accuracy: 0.7179\n",
      "Epoch 898/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0495 - val_accuracy: 0.7179\n",
      "Epoch 899/1000\n",
      "270/270 [==============================] - 0s 118us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0379 - val_accuracy: 0.7094\n",
      "Epoch 900/1000\n",
      "270/270 [==============================] - 0s 137us/step - loss: 0.2476 - accuracy: 0.8815 - val_loss: 1.0422 - val_accuracy: 0.7265\n",
      "Epoch 901/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2494 - accuracy: 0.8852 - val_loss: 1.0353 - val_accuracy: 0.7265\n",
      "Epoch 902/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2509 - accuracy: 0.8778 - val_loss: 1.0447 - val_accuracy: 0.6667\n",
      "Epoch 903/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2468 - accuracy: 0.8852 - val_loss: 1.0461 - val_accuracy: 0.6581\n",
      "Epoch 904/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2482 - accuracy: 0.8852 - val_loss: 1.0501 - val_accuracy: 0.6581\n",
      "Epoch 905/1000\n",
      "270/270 [==============================] - 0s 146us/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 1.0648 - val_accuracy: 0.6667\n",
      "Epoch 906/1000\n",
      "270/270 [==============================] - 0s 117us/step - loss: 0.2498 - accuracy: 0.8852 - val_loss: 1.0501 - val_accuracy: 0.6667\n",
      "Epoch 907/1000\n",
      "270/270 [==============================] - 0s 114us/step - loss: 0.2468 - accuracy: 0.8815 - val_loss: 1.0368 - val_accuracy: 0.7094\n",
      "Epoch 908/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 1.0324 - val_accuracy: 0.7094\n",
      "Epoch 909/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0273 - val_accuracy: 0.7094\n",
      "Epoch 910/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0297 - val_accuracy: 0.7265\n",
      "Epoch 911/1000\n",
      "270/270 [==============================] - 0s 112us/step - loss: 0.2493 - accuracy: 0.8815 - val_loss: 1.0370 - val_accuracy: 0.7265\n",
      "Epoch 912/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2475 - accuracy: 0.8704 - val_loss: 1.0486 - val_accuracy: 0.6752\n",
      "Epoch 913/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2460 - accuracy: 0.8852 - val_loss: 1.0547 - val_accuracy: 0.6838\n",
      "Epoch 914/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2464 - accuracy: 0.8852 - val_loss: 1.0600 - val_accuracy: 0.6752\n",
      "Epoch 915/1000\n",
      "270/270 [==============================] - 0s 126us/step - loss: 0.2457 - accuracy: 0.8852 - val_loss: 1.0562 - val_accuracy: 0.6752\n",
      "Epoch 916/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2444 - accuracy: 0.8852 - val_loss: 1.0549 - val_accuracy: 0.6752\n",
      "Epoch 917/1000\n",
      "270/270 [==============================] - 0s 132us/step - loss: 0.2499 - accuracy: 0.8704 - val_loss: 1.0482 - val_accuracy: 0.7607\n",
      "Epoch 918/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2520 - accuracy: 0.8815 - val_loss: 1.0483 - val_accuracy: 0.7179\n",
      "Epoch 919/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0482 - val_accuracy: 0.7179\n",
      "Epoch 920/1000\n",
      "270/270 [==============================] - 0s 99us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0444 - val_accuracy: 0.7179\n",
      "Epoch 921/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0367 - val_accuracy: 0.7179\n",
      "Epoch 922/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2454 - accuracy: 0.8889 - val_loss: 1.0432 - val_accuracy: 0.7350\n",
      "Epoch 923/1000\n",
      "270/270 [==============================] - 0s 398us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0457 - val_accuracy: 0.7265\n",
      "Epoch 924/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0486 - val_accuracy: 0.7265\n",
      "Epoch 925/1000\n",
      "270/270 [==============================] - 0s 105us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0499 - val_accuracy: 0.7265\n",
      "Epoch 926/1000\n",
      "270/270 [==============================] - 0s 113us/step - loss: 0.2450 - accuracy: 0.8889 - val_loss: 1.0555 - val_accuracy: 0.7265\n",
      "Epoch 927/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2450 - accuracy: 0.8889 - val_loss: 1.0490 - val_accuracy: 0.7265\n",
      "Epoch 928/1000\n",
      "270/270 [==============================] - 0s 95us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0472 - val_accuracy: 0.7179\n",
      "Epoch 929/1000\n",
      "270/270 [==============================] - 0s 93us/step - loss: 0.2459 - accuracy: 0.8889 - val_loss: 1.0508 - val_accuracy: 0.7094\n",
      "Epoch 930/1000\n",
      "270/270 [==============================] - 0s 87us/step - loss: 0.2452 - accuracy: 0.8889 - val_loss: 1.0471 - val_accuracy: 0.7094\n",
      "Epoch 931/1000\n",
      "270/270 [==============================] - 0s 110us/step - loss: 0.2464 - accuracy: 0.8889 - val_loss: 1.0422 - val_accuracy: 0.7265\n",
      "Epoch 932/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2450 - accuracy: 0.8889 - val_loss: 1.0482 - val_accuracy: 0.7179\n",
      "Epoch 933/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2456 - accuracy: 0.8926 - val_loss: 1.0646 - val_accuracy: 0.6667\n",
      "Epoch 934/1000\n",
      "270/270 [==============================] - 0s 103us/step - loss: 0.2471 - accuracy: 0.8852 - val_loss: 1.0653 - val_accuracy: 0.6667\n",
      "Epoch 935/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2455 - accuracy: 0.8889 - val_loss: 1.0504 - val_accuracy: 0.7094\n",
      "Epoch 936/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2443 - accuracy: 0.8889 - val_loss: 1.0400 - val_accuracy: 0.7094\n",
      "Epoch 937/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0401 - val_accuracy: 0.7094\n",
      "Epoch 938/1000\n",
      "270/270 [==============================] - 0s 94us/step - loss: 0.2510 - accuracy: 0.8815 - val_loss: 1.0461 - val_accuracy: 0.7265\n",
      "Epoch 939/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2501 - accuracy: 0.8889 - val_loss: 1.0790 - val_accuracy: 0.7265\n",
      "Epoch 940/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2531 - accuracy: 0.8815 - val_loss: 1.0962 - val_accuracy: 0.6752\n",
      "Epoch 941/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2542 - accuracy: 0.8852 - val_loss: 1.0892 - val_accuracy: 0.6752\n",
      "Epoch 942/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2488 - accuracy: 0.8889 - val_loss: 1.0750 - val_accuracy: 0.7179\n",
      "Epoch 943/1000\n",
      "270/270 [==============================] - 0s 61us/step - loss: 0.2483 - accuracy: 0.8889 - val_loss: 1.0645 - val_accuracy: 0.7179\n",
      "Epoch 944/1000\n",
      "270/270 [==============================] - 0s 77us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0732 - val_accuracy: 0.7179\n",
      "Epoch 945/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0662 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2472 - accuracy: 0.8889 - val_loss: 1.0573 - val_accuracy: 0.7179\n",
      "Epoch 947/1000\n",
      "270/270 [==============================] - 0s 49us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0373 - val_accuracy: 0.7179\n",
      "Epoch 948/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0388 - val_accuracy: 0.7179\n",
      "Epoch 949/1000\n",
      "270/270 [==============================] - 0s 78us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0442 - val_accuracy: 0.7265\n",
      "Epoch 950/1000\n",
      "270/270 [==============================] - 0s 197us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0534 - val_accuracy: 0.7265\n",
      "Epoch 951/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2454 - accuracy: 0.8852 - val_loss: 1.0498 - val_accuracy: 0.7179\n",
      "Epoch 952/1000\n",
      "270/270 [==============================] - 0s 72us/step - loss: 0.2462 - accuracy: 0.8889 - val_loss: 1.0449 - val_accuracy: 0.7179\n",
      "Epoch 953/1000\n",
      "270/270 [==============================] - 0s 83us/step - loss: 0.2528 - accuracy: 0.8889 - val_loss: 1.0269 - val_accuracy: 0.7179\n",
      "Epoch 954/1000\n",
      "270/270 [==============================] - 0s 90us/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 1.0281 - val_accuracy: 0.7265\n",
      "Epoch 955/1000\n",
      "270/270 [==============================] - 0s 120us/step - loss: 0.2478 - accuracy: 0.8889 - val_loss: 1.0418 - val_accuracy: 0.7350\n",
      "Epoch 956/1000\n",
      "270/270 [==============================] - 0s 178us/step - loss: 0.2493 - accuracy: 0.8889 - val_loss: 1.0446 - val_accuracy: 0.7265\n",
      "Epoch 957/1000\n",
      "270/270 [==============================] - 0s 211us/step - loss: 0.2484 - accuracy: 0.8889 - val_loss: 1.0457 - val_accuracy: 0.7179\n",
      "Epoch 958/1000\n",
      "270/270 [==============================] - 0s 80us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0598 - val_accuracy: 0.7179\n",
      "Epoch 959/1000\n",
      "270/270 [==============================] - 0s 81us/step - loss: 0.2462 - accuracy: 0.8741 - val_loss: 1.0663 - val_accuracy: 0.6581\n",
      "Epoch 960/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2457 - accuracy: 0.8815 - val_loss: 1.0634 - val_accuracy: 0.7094\n",
      "Epoch 961/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2453 - accuracy: 0.8889 - val_loss: 1.0595 - val_accuracy: 0.7094\n",
      "Epoch 962/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2450 - accuracy: 0.8889 - val_loss: 1.0548 - val_accuracy: 0.7179\n",
      "Epoch 963/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2456 - accuracy: 0.8889 - val_loss: 1.0549 - val_accuracy: 0.7179\n",
      "Epoch 964/1000\n",
      "270/270 [==============================] - 0s 63us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0501 - val_accuracy: 0.7179\n",
      "Epoch 965/1000\n",
      "270/270 [==============================] - 0s 89us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0541 - val_accuracy: 0.7179\n",
      "Epoch 966/1000\n",
      "270/270 [==============================] - 0s 96us/step - loss: 0.2465 - accuracy: 0.8926 - val_loss: 1.0663 - val_accuracy: 0.7094\n",
      "Epoch 967/1000\n",
      "270/270 [==============================] - 0s 111us/step - loss: 0.2495 - accuracy: 0.8815 - val_loss: 1.0751 - val_accuracy: 0.6667\n",
      "Epoch 968/1000\n",
      "270/270 [==============================] - 0s 278us/step - loss: 0.2469 - accuracy: 0.9000 - val_loss: 1.0545 - val_accuracy: 0.7094\n",
      "Epoch 969/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2469 - accuracy: 0.8926 - val_loss: 1.0536 - val_accuracy: 0.7179\n",
      "Epoch 970/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2473 - accuracy: 0.8852 - val_loss: 1.0594 - val_accuracy: 0.7179\n",
      "Epoch 971/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0603 - val_accuracy: 0.7265\n",
      "Epoch 972/1000\n",
      "270/270 [==============================] - 0s 76us/step - loss: 0.2467 - accuracy: 0.8889 - val_loss: 1.0605 - val_accuracy: 0.7094\n",
      "Epoch 973/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0657 - val_accuracy: 0.7094\n",
      "Epoch 974/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2457 - accuracy: 0.8889 - val_loss: 1.0673 - val_accuracy: 0.7094\n",
      "Epoch 975/1000\n",
      "270/270 [==============================] - 0s 91us/step - loss: 0.2448 - accuracy: 0.8889 - val_loss: 1.0643 - val_accuracy: 0.7094\n",
      "Epoch 976/1000\n",
      "270/270 [==============================] - 0s 186us/step - loss: 0.2455 - accuracy: 0.8889 - val_loss: 1.0572 - val_accuracy: 0.7179\n",
      "Epoch 977/1000\n",
      "270/270 [==============================] - 0s 79us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0575 - val_accuracy: 0.7179\n",
      "Epoch 978/1000\n",
      "270/270 [==============================] - 0s 84us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 1.0598 - val_accuracy: 0.7094\n",
      "Epoch 979/1000\n",
      "270/270 [==============================] - 0s 82us/step - loss: 0.2468 - accuracy: 0.8889 - val_loss: 1.0673 - val_accuracy: 0.7094\n",
      "Epoch 980/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2451 - accuracy: 0.8889 - val_loss: 1.0693 - val_accuracy: 0.7094\n",
      "Epoch 981/1000\n",
      "270/270 [==============================] - 0s 65us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0754 - val_accuracy: 0.7265\n",
      "Epoch 982/1000\n",
      "270/270 [==============================] - 0s 69us/step - loss: 0.2463 - accuracy: 0.8889 - val_loss: 1.0829 - val_accuracy: 0.6752\n",
      "Epoch 983/1000\n",
      "270/270 [==============================] - 0s 68us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0696 - val_accuracy: 0.7179\n",
      "Epoch 984/1000\n",
      "270/270 [==============================] - 0s 57us/step - loss: 0.2458 - accuracy: 0.8889 - val_loss: 1.0500 - val_accuracy: 0.7094\n",
      "Epoch 985/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 1.0494 - val_accuracy: 0.7094\n",
      "Epoch 986/1000\n",
      "270/270 [==============================] - 0s 54us/step - loss: 0.2466 - accuracy: 0.8889 - val_loss: 1.0551 - val_accuracy: 0.7094\n",
      "Epoch 987/1000\n",
      "270/270 [==============================] - 0s 254us/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 1.0752 - val_accuracy: 0.7094\n",
      "Epoch 988/1000\n",
      "270/270 [==============================] - 0s 56us/step - loss: 0.2454 - accuracy: 0.8889 - val_loss: 1.0785 - val_accuracy: 0.7179\n",
      "Epoch 989/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 1.0730 - val_accuracy: 0.7179\n",
      "Epoch 990/1000\n",
      "270/270 [==============================] - 0s 58us/step - loss: 0.2481 - accuracy: 0.8889 - val_loss: 1.0662 - val_accuracy: 0.7265\n",
      "Epoch 991/1000\n",
      "270/270 [==============================] - 0s 101us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 1.0632 - val_accuracy: 0.7265\n",
      "Epoch 992/1000\n",
      "270/270 [==============================] - 0s 71us/step - loss: 0.2469 - accuracy: 0.8889 - val_loss: 1.0493 - val_accuracy: 0.7265\n",
      "Epoch 993/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2460 - accuracy: 0.8889 - val_loss: 1.0597 - val_accuracy: 0.7179\n",
      "Epoch 994/1000\n",
      "270/270 [==============================] - 0s 92us/step - loss: 0.2487 - accuracy: 0.8926 - val_loss: 1.0760 - val_accuracy: 0.7179\n",
      "Epoch 995/1000\n",
      "270/270 [==============================] - 0s 70us/step - loss: 0.2496 - accuracy: 0.8889 - val_loss: 1.0842 - val_accuracy: 0.6581\n",
      "Epoch 996/1000\n",
      "270/270 [==============================] - 0s 74us/step - loss: 0.2470 - accuracy: 0.8815 - val_loss: 1.0850 - val_accuracy: 0.6667\n",
      "Epoch 997/1000\n",
      "270/270 [==============================] - 0s 67us/step - loss: 0.2487 - accuracy: 0.8852 - val_loss: 1.0832 - val_accuracy: 0.7179\n",
      "Epoch 998/1000\n",
      "270/270 [==============================] - 0s 75us/step - loss: 0.2506 - accuracy: 0.8889 - val_loss: 1.0677 - val_accuracy: 0.7179\n",
      "Epoch 999/1000\n",
      "270/270 [==============================] - 0s 66us/step - loss: 0.2485 - accuracy: 0.8889 - val_loss: 1.0626 - val_accuracy: 0.7179\n",
      "Epoch 1000/1000\n",
      "270/270 [==============================] - 0s 122us/step - loss: 0.2505 - accuracy: 0.8815 - val_loss: 1.0819 - val_accuracy: 0.6838\n"
     ]
    }
   ],
   "source": [
    "hist2_over4 = model2_over4.fit(X_sel_train_over, y_sel_train_over,\n",
    "          batch_size=64, epochs=1000,\n",
    "          validation_data=(X_sel_test_over, y_sel_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 88.70%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist2_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.321970e-02</td>\n",
       "      <td>2.446264e-01</td>\n",
       "      <td>7.421539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.478230e-02</td>\n",
       "      <td>2.806685e-01</td>\n",
       "      <td>6.845492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.987907e-01</td>\n",
       "      <td>5.331044e-01</td>\n",
       "      <td>2.681049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0006kpresabs_qual</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090251e-01</td>\n",
       "      <td>3.405008e-01</td>\n",
       "      <td>2.504741e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129044e-01</td>\n",
       "      <td>3.870795e-01</td>\n",
       "      <td>1.601290e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.260306e-07</td>\n",
       "      <td>7.910664e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.604249e-12</td>\n",
       "      <td>2.698129e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>p0017Skpresabs_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.207667e-01</td>\n",
       "      <td>2.792331e-01</td>\n",
       "      <td>2.571588e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phage    strain  phenotype  prediction             0  \\\n",
       "0     p0006kpresabs_qual    NRS236          1           2  1.321970e-02   \n",
       "1     p0006kpresabs_qual    NRS113          2           2  3.478230e-02   \n",
       "2     p0006kpresabs_qual  CFBRSa23          0           0  4.090251e-01   \n",
       "3     p0006kpresabs_qual    NRS249          2           1  1.987907e-01   \n",
       "4     p0006kpresabs_qual       107          1           0  4.090251e-01   \n",
       "..                   ...       ...        ...         ...           ...   \n",
       "984  p0017Skpresabs_qual  CFBRSa30          0           0  7.207667e-01   \n",
       "985  p0017Skpresabs_qual    NRS383          1           0  6.129044e-01   \n",
       "986  p0017Skpresabs_qual    NRS110          2           2  3.260306e-07   \n",
       "987  p0017Skpresabs_qual    NRS209          2           2  3.604249e-12   \n",
       "988  p0017Skpresabs_qual     NY439          0           0  7.207667e-01   \n",
       "\n",
       "                1             2  \n",
       "0    2.446264e-01  7.421539e-01  \n",
       "1    2.806685e-01  6.845492e-01  \n",
       "2    3.405008e-01  2.504741e-01  \n",
       "3    5.331044e-01  2.681049e-01  \n",
       "4    3.405008e-01  2.504741e-01  \n",
       "..            ...           ...  \n",
       "984  2.792331e-01  2.571588e-07  \n",
       "985  3.870795e-01  1.601290e-05  \n",
       "986  7.910664e-07  9.999989e-01  \n",
       "987  2.698129e-07  9.999998e-01  \n",
       "988  2.792331e-01  2.571588e-07  \n",
       "\n",
       "[989 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.15534710e-04, 1.17172600e-01, 8.82711900e-01],\n",
       "       [2.69663380e-03, 4.63731350e-03, 9.92666070e-01],\n",
       "       [9.96766200e-01, 1.70009880e-05, 3.21681200e-03],\n",
       "       [4.47092750e-04, 2.18084270e-03, 9.97372030e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [8.74220600e-05, 7.78390700e-04, 9.99134240e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [8.07282270e-01, 1.87858800e-01, 4.85888900e-03],\n",
       "       [9.99445260e-01, 5.21134000e-04, 3.36222840e-05],\n",
       "       [9.88914430e-01, 1.10523130e-02, 3.32677000e-05],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [1.11698620e-05, 9.83830900e-01, 1.61578600e-02],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [3.46699200e-01, 5.35712360e-01, 1.17588505e-01],\n",
       "       [9.95891000e-01, 3.70014830e-03, 4.08814730e-04],\n",
       "       [2.70234360e-08, 1.19652910e-10, 1.00000000e+00],\n",
       "       [1.93955090e-04, 1.48521110e-02, 9.84953900e-01],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [4.19717030e-06, 1.22764690e-05, 9.99983550e-01],\n",
       "       [4.55895060e-04, 2.34422560e-04, 9.99309660e-01],\n",
       "       [3.11164200e-02, 9.67644930e-01, 1.23862550e-03],\n",
       "       [7.03974000e-03, 1.87261050e-02, 9.74234160e-01],\n",
       "       [4.93034240e-01, 4.99143100e-01, 7.82263500e-03],\n",
       "       [3.48558950e-02, 1.51784940e-01, 8.13359140e-01],\n",
       "       [4.71680940e-03, 9.95206400e-01, 7.67905700e-05],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [4.25742100e-04, 7.20983140e-04, 9.98853300e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [1.54129580e-04, 2.05335280e-03, 9.97792500e-01],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [4.47092750e-04, 2.18084270e-03, 9.97372030e-01],\n",
       "       [8.54492260e-02, 8.44197700e-02, 8.30131000e-01],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [9.96538400e-01, 3.46158540e-03, 1.88174120e-09],\n",
       "       [9.99922900e-01, 6.34091800e-05, 1.37233610e-05],\n",
       "       [1.02503360e-01, 8.84675150e-01, 1.28215320e-02],\n",
       "       [4.62984640e-08, 8.70962200e-08, 9.99999900e-01],\n",
       "       [9.29159100e-01, 6.26110300e-02, 8.22994600e-03],\n",
       "       [1.05070585e-05, 1.03846170e-01, 8.96143400e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [1.11698620e-05, 9.83830900e-01, 1.61578600e-02],\n",
       "       [4.47092750e-04, 2.18084270e-03, 9.97372030e-01],\n",
       "       [5.40956300e-06, 1.77533610e-03, 9.98219200e-01],\n",
       "       [1.15534710e-04, 1.17172600e-01, 8.82711900e-01],\n",
       "       [1.82924150e-03, 9.57510300e-01, 4.06604330e-02],\n",
       "       [4.02959650e-04, 5.16180020e-02, 9.47979100e-01],\n",
       "       [5.93147400e-09, 9.99329000e-01, 6.71049800e-04],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [2.15194600e-01, 6.76332500e-01, 1.08472960e-01],\n",
       "       [4.19717030e-06, 1.22764690e-05, 9.99983550e-01],\n",
       "       [3.02118340e-06, 2.90662980e-06, 9.99994040e-01],\n",
       "       [3.31400570e-04, 3.22394670e-01, 6.77273900e-01],\n",
       "       [1.05070585e-05, 1.03846170e-01, 8.96143400e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [5.72973530e-02, 7.15289200e-01, 2.27413450e-01],\n",
       "       [1.20982425e-02, 9.87901700e-01, 1.23328750e-07],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [9.99990460e-01, 2.03710100e-06, 7.48113300e-06],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [7.92077060e-01, 2.06402500e-01, 1.52041870e-03],\n",
       "       [9.98975900e-01, 1.37889820e-04, 8.86229740e-04],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [9.85144730e-01, 6.73256900e-04, 1.41819910e-02],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [5.76554330e-04, 1.63523460e-02, 9.83071150e-01],\n",
       "       [5.68509600e-06, 5.06356700e-03, 9.94930700e-01],\n",
       "       [1.71314630e-01, 7.90130560e-01, 3.85548400e-02],\n",
       "       [3.31400570e-04, 3.22394670e-01, 6.77273900e-01],\n",
       "       [4.47092750e-04, 2.18084270e-03, 9.97372030e-01],\n",
       "       [9.78532500e-01, 2.14651860e-02, 2.38589180e-06],\n",
       "       [1.84344760e-02, 9.74357370e-01, 7.20824000e-03],\n",
       "       [1.05832150e-02, 4.31300460e-04, 9.88985400e-01],\n",
       "       [8.80125600e-01, 1.19653980e-01, 2.20402360e-04],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [6.81030000e-01, 3.18914150e-01, 5.58717770e-05],\n",
       "       [5.76554330e-04, 1.63523460e-02, 9.83071150e-01],\n",
       "       [5.76554330e-04, 1.63523460e-02, 9.83071150e-01],\n",
       "       [1.05070585e-05, 1.03846170e-01, 8.96143400e-01],\n",
       "       [8.07282270e-01, 1.87858800e-01, 4.85888900e-03],\n",
       "       [8.07282270e-01, 1.87858800e-01, 4.85888900e-03],\n",
       "       [9.99990000e-01, 1.98697670e-06, 7.95039300e-06],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [8.07282270e-01, 1.87858800e-01, 4.85888900e-03],\n",
       "       [1.71314630e-01, 7.90130560e-01, 3.85548400e-02],\n",
       "       [9.29159100e-01, 6.26110300e-02, 8.22994600e-03],\n",
       "       [1.93955090e-04, 1.48521110e-02, 9.84953900e-01],\n",
       "       [9.99827500e-01, 1.72470390e-04, 2.79872800e-10],\n",
       "       [9.99922300e-01, 2.22679140e-05, 5.54333240e-05],\n",
       "       [9.99970200e-01, 1.05949950e-05, 1.91340040e-05],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [2.92519300e-01, 6.91300330e-01, 1.61803220e-02],\n",
       "       [9.91603200e-01, 2.13329450e-04, 8.18345700e-03],\n",
       "       [3.39017750e-01, 6.55360300e-01, 5.62195100e-03],\n",
       "       [3.31622230e-10, 2.07268600e-02, 9.79273100e-01],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [4.55895060e-04, 2.34422560e-04, 9.99309660e-01],\n",
       "       [9.99899000e-01, 1.00957460e-04, 2.31488390e-11],\n",
       "       [1.37195630e-02, 6.59906900e-02, 9.20289800e-01],\n",
       "       [3.80644080e-01, 6.03716800e-01, 1.56391470e-02],\n",
       "       [4.62984640e-08, 8.70962200e-08, 9.99999900e-01],\n",
       "       [3.17796440e-03, 9.85766650e-01, 1.10553070e-02],\n",
       "       [1.05070585e-05, 1.03846170e-01, 8.96143400e-01],\n",
       "       [9.83234640e-01, 9.65283000e-03, 7.11241740e-03],\n",
       "       [9.73807900e-01, 2.61921660e-02, 4.35185470e-10],\n",
       "       [3.84533130e-06, 2.91487370e-03, 9.97081200e-01],\n",
       "       [1.40875800e-04, 9.40709400e-01, 5.91496940e-02],\n",
       "       [6.40637760e-01, 3.14578120e-01, 4.47840900e-02],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [6.53663400e-02, 8.30385860e-01, 1.04247770e-01],\n",
       "       [1.23514020e-01, 4.96119680e-01, 3.80366300e-01],\n",
       "       [4.55895060e-04, 2.34422560e-04, 9.99309660e-01],\n",
       "       [5.03726500e-01, 4.95453180e-01, 8.20388200e-04],\n",
       "       [1.71314630e-01, 7.90130560e-01, 3.85548400e-02],\n",
       "       [5.47303150e-10, 5.87912860e-01, 4.12087170e-01],\n",
       "       [1.71314630e-01, 7.90130560e-01, 3.85548400e-02]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0006presabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668639053254438"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668639053254438"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620973044049968"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02947260633480655"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620973044049968"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02947260633480655"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l_over = [acc_test2_over, acc_test2_over2, acc_test2_over3, acc_test2_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean after lasso: 74.57%\n"
     ]
    }
   ],
   "source": [
    "mean_l_over = np.mean(accs_l_over)\n",
    "print('over-sampling test accuracy mean after lasso: %.2f%%' % (mean_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation after lasso: 0.026602347982728397\n"
     ]
    }
   ],
   "source": [
    "std_l_over = np.std(accs_l_over)\n",
    "print('over-sampling test accuracy standard deviation after lasso:', std_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l_over = [np.mean(hist2_over.history['accuracy']), np.mean(hist2_over2.history['accuracy']), np.mean(hist2_over3.history['accuracy']),\n",
    "             np.mean(hist2_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean after lasso: 87.38%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l_over = np.mean(accs_train_l_over)\n",
    "print('over-sampling train accuracy mean after lasso: %.2f%%' % (mean_train_l_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation after lasso: 0.009234734\n"
     ]
    }
   ],
   "source": [
    "std_train_l_over = np.std(accs_train_l_over)\n",
    "print('over-sampling train accuracy standard deviation after lasso:', std_train_l_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
