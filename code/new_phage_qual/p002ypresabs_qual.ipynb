{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p002ypresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 2033)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p002ypresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8177</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2033 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  ...  group_8177  group_8643  group_8644  \\\n",
       "0              1                1  ...           0           0           0   \n",
       "1              1                1  ...           0           0           0   \n",
       "2              1                1  ...           0           0           0   \n",
       "3              1                1  ...           0           0           0   \n",
       "4              1                1  ...           0           0           0   \n",
       "\n",
       "   group_8645  group_8646  group_8815  group_8892  group_9007  group_9104  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 2033 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    220\n",
       "1     30\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 2032)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA</th>\n",
       "      <th>TTTTTTTATGAAT</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCATTAGT</th>\n",
       "      <th>TTTTTTCATTAGTAA</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8177</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9007</th>\n",
       "      <th>group_9104</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2032 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGAAT  \\\n",
       "0              1   \n",
       "1              1   \n",
       "2              1   \n",
       "3              1   \n",
       "4              1   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTGACTAAAATTAATGAAAAGTGAAAATAGTATTGGAACTCAATATCTTTAATGATTTAATGAATAATTTTTATTGAAAGCGATAATTCGTATTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCATTAGT  TTTTTTCATTAGTAA  \\\n",
       "0              1                1   \n",
       "1              1                1   \n",
       "2              1                1   \n",
       "3              1                1   \n",
       "4              1                1   \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_8177  group_8643  group_8644  group_8645  group_8646  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_8815  group_8892  group_9007  group_9104  pheno  \n",
       "0           0           0           0           0      0  \n",
       "1           0           0           0           0      0  \n",
       "2           0           0           0           0      1  \n",
       "3           0           0           0           0      0  \n",
       "4           0           0           0           0      0  \n",
       "\n",
       "[5 rows x 2032 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 2032) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 220), (1, 220), (2, 220)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0       CFBRSa26     0\n",
       "1         NRS109     2\n",
       "2         NRS112     0\n",
       "3         NRS216     1\n",
       "4         NRS021     0\n",
       "..           ...   ...\n",
       "193  CFBREBSa133     0\n",
       "194       NRS209     2\n",
       "195       NRS109     2\n",
       "196       NRS209     2\n",
       "197       NRS035     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 561us/step - loss: 0.9054 - accuracy: 0.6255 - val_loss: 0.5772 - val_accuracy: 0.7525\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.5107 - accuracy: 0.8052 - val_loss: 0.4735 - val_accuracy: 0.7929\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.4337 - accuracy: 0.8182 - val_loss: 0.4013 - val_accuracy: 0.8131\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.4144 - accuracy: 0.8268 - val_loss: 0.3411 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.3856 - accuracy: 0.8247 - val_loss: 0.5292 - val_accuracy: 0.7374\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.4188 - accuracy: 0.8074 - val_loss: 0.2980 - val_accuracy: 0.8788\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.3238 - accuracy: 0.8636 - val_loss: 0.2833 - val_accuracy: 0.8838\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.2813 - accuracy: 0.8853 - val_loss: 0.2681 - val_accuracy: 0.8838\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.2777 - accuracy: 0.8918 - val_loss: 0.2557 - val_accuracy: 0.9192\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.2592 - accuracy: 0.9091 - val_loss: 0.2378 - val_accuracy: 0.8939\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 170us/step - loss: 0.2412 - accuracy: 0.8983 - val_loss: 0.2191 - val_accuracy: 0.9091\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.2303 - accuracy: 0.8983 - val_loss: 0.2516 - val_accuracy: 0.9091\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.2581 - accuracy: 0.8896 - val_loss: 0.1931 - val_accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.1975 - accuracy: 0.9372 - val_loss: 0.1867 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1902 - accuracy: 0.9242 - val_loss: 0.2287 - val_accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.1967 - accuracy: 0.9286 - val_loss: 0.1951 - val_accuracy: 0.9293\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 0.1612 - accuracy: 0.9502 - val_loss: 0.1820 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.1576 - accuracy: 0.9589 - val_loss: 0.1692 - val_accuracy: 0.9343\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1316 - accuracy: 0.9654 - val_loss: 0.1338 - val_accuracy: 0.9747\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.1292 - accuracy: 0.9762 - val_loss: 0.1464 - val_accuracy: 0.9495\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 0.1317 - accuracy: 0.9675 - val_loss: 0.1990 - val_accuracy: 0.9293\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.1220 - accuracy: 0.9740 - val_loss: 0.1131 - val_accuracy: 0.9747\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.1098 - accuracy: 0.9740 - val_loss: 0.1238 - val_accuracy: 0.9848\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.1082 - accuracy: 0.9784 - val_loss: 0.1140 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0988 - accuracy: 0.9870 - val_loss: 0.1161 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0919 - accuracy: 0.9870 - val_loss: 0.1549 - val_accuracy: 0.9394\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 428us/step - loss: 0.1007 - accuracy: 0.9762 - val_loss: 0.1067 - val_accuracy: 0.9646\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 0.1056 - accuracy: 0.9632 - val_loss: 0.0938 - val_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.0943 - accuracy: 0.9762 - val_loss: 0.2225 - val_accuracy: 0.9040\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.0997 - accuracy: 0.9719 - val_loss: 0.0964 - val_accuracy: 0.9646\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0776 - accuracy: 0.9805 - val_loss: 0.0980 - val_accuracy: 0.9646\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0734 - accuracy: 0.9827 - val_loss: 0.0861 - val_accuracy: 0.9747\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0682 - accuracy: 0.9892 - val_loss: 0.0870 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0703 - accuracy: 0.9848 - val_loss: 0.0842 - val_accuracy: 0.9848\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0673 - accuracy: 0.9892 - val_loss: 0.0824 - val_accuracy: 0.9899\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0663 - accuracy: 0.9870 - val_loss: 0.0720 - val_accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0730 - accuracy: 0.9827 - val_loss: 0.1464 - val_accuracy: 0.9343\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0881 - accuracy: 0.9654 - val_loss: 0.1223 - val_accuracy: 0.9545\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0621 - accuracy: 0.9870 - val_loss: 0.0761 - val_accuracy: 0.9798\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0531 - accuracy: 0.9892 - val_loss: 0.0716 - val_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0520 - accuracy: 0.9913 - val_loss: 0.0701 - val_accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0521 - accuracy: 0.9935 - val_loss: 0.0637 - val_accuracy: 0.9848\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0464 - accuracy: 0.9913 - val_loss: 0.0724 - val_accuracy: 0.9848\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 160us/step - loss: 0.0497 - accuracy: 0.9935 - val_loss: 0.0919 - val_accuracy: 0.9646\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0468 - accuracy: 0.9913 - val_loss: 0.0622 - val_accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0473 - accuracy: 0.9913 - val_loss: 0.0619 - val_accuracy: 0.9848\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0470 - accuracy: 0.9913 - val_loss: 0.1456 - val_accuracy: 0.9394\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0546 - accuracy: 0.9870 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0422 - accuracy: 0.9913 - val_loss: 0.0645 - val_accuracy: 0.9899\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0389 - accuracy: 0.9935 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0387 - accuracy: 0.9957 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0437 - accuracy: 0.9892 - val_loss: 0.1015 - val_accuracy: 0.9495\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0447 - accuracy: 0.9935 - val_loss: 0.0612 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0416 - accuracy: 0.9913 - val_loss: 0.0543 - val_accuracy: 0.9899\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0478 - accuracy: 0.9913 - val_loss: 0.0758 - val_accuracy: 0.9747\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 0.0367 - accuracy: 0.9935 - val_loss: 0.0915 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0344 - accuracy: 0.9957 - val_loss: 0.0679 - val_accuracy: 0.9697\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 0.0337 - accuracy: 0.9913 - val_loss: 0.0513 - val_accuracy: 0.9899\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 0.0299 - accuracy: 0.9957 - val_loss: 0.0467 - val_accuracy: 0.9899\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0374 - accuracy: 0.9935 - val_loss: 0.0533 - val_accuracy: 0.9949\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.0310 - accuracy: 0.9935 - val_loss: 0.0492 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0299 - accuracy: 0.9957 - val_loss: 0.0549 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.0742 - val_accuracy: 0.9646\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.0478 - val_accuracy: 0.9848\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 0.0239 - accuracy: 0.9957 - val_loss: 0.0606 - val_accuracy: 0.9798\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.0258 - accuracy: 0.9935 - val_loss: 0.0515 - val_accuracy: 0.9798\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.0447 - val_accuracy: 0.9798\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0435 - val_accuracy: 0.9899\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.0507 - val_accuracy: 0.9798\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0558 - val_accuracy: 0.9798\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 557us/step - loss: 0.0207 - accuracy: 0.9978 - val_loss: 0.0502 - val_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.0449 - val_accuracy: 0.9848\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0208 - accuracy: 0.9978 - val_loss: 0.0395 - val_accuracy: 0.9949\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0250 - accuracy: 0.9957 - val_loss: 0.0565 - val_accuracy: 0.9798\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9697\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.0640 - val_accuracy: 0.9747\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0184 - accuracy: 0.9978 - val_loss: 0.0610 - val_accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0166 - accuracy: 0.9978 - val_loss: 0.0849 - val_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0168 - accuracy: 0.9978 - val_loss: 0.0352 - val_accuracy: 0.9899\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.0373 - val_accuracy: 0.9949\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.0205 - accuracy: 0.9978 - val_loss: 0.0369 - val_accuracy: 0.9899\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 0.0423 - val_accuracy: 0.9848\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0154 - accuracy: 0.9978 - val_loss: 0.0377 - val_accuracy: 0.9848\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0309 - val_accuracy: 0.9899\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9949\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0351 - val_accuracy: 0.9949\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.0285 - val_accuracy: 0.9949\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0138 - accuracy: 0.9978 - val_loss: 0.0329 - val_accuracy: 0.9949\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.0387 - val_accuracy: 0.9899\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0551 - val_accuracy: 0.9798\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0153 - accuracy: 0.9978 - val_loss: 0.0339 - val_accuracy: 0.9848\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.0415 - val_accuracy: 0.9899\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9848\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0165 - accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.9949\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0906 - accuracy: 0.9632 - val_loss: 0.2994 - val_accuracy: 0.9141\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 0.0791 - accuracy: 0.9784 - val_loss: 0.1738 - val_accuracy: 0.9394\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0612 - val_accuracy: 0.9848\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.0367 - val_accuracy: 0.9848\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.0769 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3f7b8208>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 150us/step\n",
      "over-sampling test accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 2, 2, 1, 0, 0, 2, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 0, 1,\n",
       "       0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 0, 0, 2, 1, 1, 0,\n",
       "       0, 2, 0, 0, 2, 0, 1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0,\n",
       "       2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 1, 2, 1,\n",
       "       0, 2, 0, 2, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 2, 1, 2, 2,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 1, 2, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBREBSa133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0       CFBRSa26     0     0\n",
       "1         NRS109     2     2\n",
       "2         NRS112     0     0\n",
       "3         NRS216     1     1\n",
       "4         NRS021     0     0\n",
       "..           ...   ...   ...\n",
       "193  CFBREBSa133     0     0\n",
       "194       NRS209     2     2\n",
       "195       NRS109     2     2\n",
       "196       NRS209     2     2\n",
       "197       NRS035     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999852</td>\n",
       "      <td>1.476760e-04</td>\n",
       "      <td>5.399214e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>3.009203e-03</td>\n",
       "      <td>9.967352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998466</td>\n",
       "      <td>1.533670e-03</td>\n",
       "      <td>9.995098e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007553</td>\n",
       "      <td>9.924409e-01</td>\n",
       "      <td>5.932516e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999889</td>\n",
       "      <td>1.113699e-04</td>\n",
       "      <td>2.815641e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>5.957744e-07</td>\n",
       "      <td>4.386633e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.933857e-05</td>\n",
       "      <td>9.999559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>3.009205e-03</td>\n",
       "      <td>9.967352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.933857e-05</td>\n",
       "      <td>9.999559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.000449</td>\n",
       "      <td>9.995371e-01</td>\n",
       "      <td>1.442270e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    0.999852  1.476760e-04  5.399214e-12\n",
       "1    0.000256  3.009203e-03  9.967352e-01\n",
       "2    0.998466  1.533670e-03  9.995098e-10\n",
       "3    0.007553  9.924409e-01  5.932516e-06\n",
       "4    0.999889  1.113699e-04  2.815641e-11\n",
       "..        ...           ...           ...\n",
       "193  0.999995  5.957744e-07  4.386633e-06\n",
       "194  0.000005  3.933857e-05  9.999559e-01\n",
       "195  0.000256  3.009205e-03  9.967352e-01\n",
       "196  0.000005  3.933857e-05  9.999559e-01\n",
       "197  0.000449  9.995371e-01  1.442270e-05\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.0327 - val_accuracy: 0.9848\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0364 - val_accuracy: 0.9899\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9848\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9899\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9899\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9798\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9899\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9798\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9848\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9798\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9798\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9798\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9798\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9899\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9899\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 386us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9798\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 592us/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9798\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9899\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9899\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 564us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9899\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9798\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 486us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9798\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9798\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 416us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9848\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9899\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 464us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9899\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9848\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 489us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9899\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 453us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9899\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 556us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9899\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9697\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9848\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9899\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9848\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9848\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9899\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9899\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9848\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9798\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9848\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9899\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9848\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 752us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9848\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 726us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9848\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9848\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9899\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9798\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9899\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9798\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9798\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9899\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9848\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9848\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9899\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9798\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9848\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9899\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9848\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9848\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9798\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9899\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9848\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9798\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9899\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9899\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9899\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 516us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9899\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9848\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9848\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9848\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9899\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9798\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9899\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9848\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9899\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9899\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9798\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9848\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9899\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9899\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.99%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99852300e-01, 1.47676020e-04, 5.39921360e-12],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [9.98466400e-01, 1.53366980e-03, 9.99509800e-10],\n",
       "       [7.55309500e-03, 9.92440940e-01, 5.93251570e-06],\n",
       "       [9.99888660e-01, 1.11369925e-04, 2.81564110e-11],\n",
       "       [9.99773800e-01, 2.26175000e-04, 7.29222850e-12],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [1.00000000e+00, 2.96427060e-09, 5.35099860e-17],\n",
       "       [3.38997300e-03, 9.96609450e-01, 5.71683800e-07],\n",
       "       [1.00000000e+00, 2.86100080e-09, 1.50830130e-15],\n",
       "       [5.45560430e-03, 9.94544400e-01, 2.63903830e-08],\n",
       "       [8.71244400e-03, 9.88195060e-01, 3.09258330e-03],\n",
       "       [9.99698640e-01, 3.01340920e-04, 5.24773700e-11],\n",
       "       [3.69098700e-03, 9.96309000e-01, 2.36460100e-08],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [4.69896070e-04, 9.99529100e-01, 9.22393900e-07],\n",
       "       [2.63437660e-04, 9.99736500e-01, 6.55442100e-08],\n",
       "       [4.69231530e-05, 9.99953030e-01, 1.56085950e-08],\n",
       "       [9.99779160e-01, 2.20860380e-04, 6.42092370e-12],\n",
       "       [9.99961730e-01, 3.82507750e-05, 3.61328200e-11],\n",
       "       [1.36405140e-03, 9.98635950e-01, 5.89819960e-08],\n",
       "       [2.48099340e-01, 7.51878500e-01, 2.21004830e-05],\n",
       "       [1.03219815e-01, 8.96777900e-01, 2.24945850e-06],\n",
       "       [9.99984860e-01, 1.51268400e-05, 7.75305760e-13],\n",
       "       [1.09960790e-04, 9.93862300e-01, 6.02776300e-03],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [9.53468550e-04, 9.99046500e-01, 6.29875500e-09],\n",
       "       [8.96006460e-01, 1.03993520e-01, 1.04092430e-09],\n",
       "       [9.99999900e-01, 1.04097865e-07, 8.50777300e-14],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [2.63437660e-04, 9.99736500e-01, 6.55442100e-08],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [2.63905430e-03, 9.97360770e-01, 1.62151750e-07],\n",
       "       [9.99136750e-01, 8.63261460e-04, 1.13588264e-10],\n",
       "       [1.55445990e-04, 9.99487500e-01, 3.56954230e-04],\n",
       "       [6.09097500e-07, 9.99999400e-01, 2.43166690e-09],\n",
       "       [9.95740900e-01, 4.25918350e-03, 8.01496850e-11],\n",
       "       [9.99996900e-01, 3.09845270e-06, 2.63274100e-12],\n",
       "       [9.98380540e-01, 1.61943760e-03, 3.46113750e-10],\n",
       "       [9.99541760e-01, 4.58238650e-04, 1.81998600e-11],\n",
       "       [7.50221800e-01, 2.49778200e-01, 1.30811400e-08],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [5.70049740e-05, 9.99943000e-01, 5.48630340e-09],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [1.76013600e-04, 9.99816600e-01, 7.44280940e-06],\n",
       "       [9.99996200e-01, 3.80153200e-06, 5.08646770e-14],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [9.83211460e-01, 1.67885590e-02, 1.10276270e-08],\n",
       "       [9.97151850e-01, 2.84810220e-03, 6.93920060e-11],\n",
       "       [9.96644260e-01, 3.35578570e-03, 3.79799970e-10],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [9.99796330e-01, 2.03734470e-04, 5.87804930e-12],\n",
       "       [9.44852350e-01, 5.51475960e-02, 3.77478500e-09],\n",
       "       [6.95518730e-03, 9.93044800e-01, 1.86095010e-08],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [9.98272300e-01, 1.72773420e-03, 7.90972700e-11],\n",
       "       [6.67801800e-01, 3.32198140e-01, 1.73240340e-08],\n",
       "       [3.69098700e-03, 9.96309000e-01, 2.36460100e-08],\n",
       "       [9.97480700e-01, 2.51936840e-03, 5.50630650e-10],\n",
       "       [5.06602340e-04, 9.99493360e-01, 7.84502150e-09],\n",
       "       [9.99917600e-01, 8.24118540e-05, 4.34087730e-11],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [2.63437660e-04, 9.99736500e-01, 6.55442100e-08],\n",
       "       [9.89322500e-01, 1.06774240e-02, 6.81217860e-08],\n",
       "       [1.09960790e-04, 9.93862300e-01, 6.02776300e-03],\n",
       "       [5.45560430e-03, 9.94544400e-01, 2.63903830e-08],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [6.09097500e-07, 9.99999400e-01, 2.43166690e-09],\n",
       "       [2.63905430e-03, 9.97360770e-01, 1.62151750e-07],\n",
       "       [4.69231530e-05, 9.99953030e-01, 1.56085950e-08],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [2.63437660e-04, 9.99736500e-01, 6.55442100e-08],\n",
       "       [9.47400900e-03, 9.90493000e-01, 3.29610740e-05],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [8.80886550e-01, 1.19113460e-01, 5.51736900e-09],\n",
       "       [9.99627230e-01, 3.72794020e-04, 1.25052250e-11],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [1.09690010e-03, 9.98899460e-01, 3.55554740e-06],\n",
       "       [5.06602340e-04, 9.99493360e-01, 7.84502150e-09],\n",
       "       [9.95020150e-01, 4.97980230e-03, 3.11777380e-10],\n",
       "       [9.88613600e-01, 1.13864110e-02, 5.26607900e-10],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [9.98120500e-01, 1.87946630e-03, 1.03031830e-09],\n",
       "       [9.99580100e-01, 4.19930440e-04, 3.55064620e-11],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [9.60118350e-01, 3.98815760e-02, 4.67143920e-09],\n",
       "       [9.47400900e-03, 9.90493000e-01, 3.29610740e-05],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [1.55445990e-04, 9.99487500e-01, 3.56954230e-04],\n",
       "       [1.55445990e-04, 9.99487500e-01, 3.56954230e-04],\n",
       "       [3.69098700e-03, 9.96309000e-01, 2.36460100e-08],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [9.99562900e-01, 4.37018700e-04, 2.24492950e-10],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [9.99829770e-01, 1.70210140e-04, 4.65716100e-11],\n",
       "       [9.99675300e-01, 3.24796740e-04, 6.55993700e-11],\n",
       "       [7.97650500e-01, 2.02347340e-01, 2.18236820e-06],\n",
       "       [9.99937060e-01, 6.29732200e-05, 5.79135520e-12],\n",
       "       [9.99993900e-01, 6.13682000e-06, 7.42995000e-12],\n",
       "       [6.95518730e-03, 9.93044800e-01, 1.86095010e-08],\n",
       "       [1.55445990e-04, 9.99487500e-01, 3.56954230e-04],\n",
       "       [4.69896070e-04, 9.99529100e-01, 9.22393900e-07],\n",
       "       [9.99990460e-01, 9.54901600e-06, 1.53980970e-13],\n",
       "       [6.71312100e-01, 3.28687460e-01, 4.09981420e-07],\n",
       "       [1.00000000e+00, 4.96725000e-09, 3.72912500e-15],\n",
       "       [3.44084650e-02, 9.64704930e-01, 8.86674330e-04],\n",
       "       [9.98322800e-01, 1.67722340e-03, 4.36468900e-11],\n",
       "       [2.79987670e-03, 9.97199800e-01, 3.23373630e-07],\n",
       "       [9.99999640e-01, 3.08726580e-07, 2.69494930e-13],\n",
       "       [3.69098700e-03, 9.96309000e-01, 2.36460100e-08],\n",
       "       [2.79987670e-03, 9.97199800e-01, 3.23373630e-07],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [2.63905430e-03, 9.97360770e-01, 1.62151750e-07],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.69098700e-03, 9.96309000e-01, 2.36460100e-08],\n",
       "       [2.01173220e-02, 9.79882660e-01, 1.23359465e-08],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [9.99956600e-01, 4.33899840e-05, 9.72615300e-12],\n",
       "       [9.99737300e-01, 2.62702260e-04, 3.79328200e-11],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [5.70049740e-05, 9.99943000e-01, 5.48630340e-09],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [1.09960790e-04, 9.93862300e-01, 6.02776300e-03],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.48512820e-04, 9.99537100e-01, 1.44227020e-05],\n",
       "       [9.97224450e-01, 2.77559180e-03, 7.12157800e-10],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [6.95518730e-03, 9.93044800e-01, 1.86095010e-08],\n",
       "       [3.28414680e-03, 9.96715800e-01, 7.66990500e-08],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [5.37383560e-01, 4.62616440e-01, 5.26958340e-09],\n",
       "       [9.99977350e-01, 2.26989850e-05, 2.26018940e-12],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [3.17319840e-01, 6.82680250e-01, 3.08857100e-08],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [2.86110370e-01, 7.13889300e-01, 3.11115170e-07],\n",
       "       [1.00000000e+00, 3.69300880e-09, 4.94637850e-15],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [9.96108000e-01, 3.89197260e-03, 8.55972100e-10],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.38997300e-03, 9.96609450e-01, 5.71683800e-07],\n",
       "       [9.99998000e-01, 2.02490200e-06, 2.40350450e-12],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.35246560e-03, 9.93794560e-01, 2.85296860e-03],\n",
       "       [7.55309500e-03, 9.92440940e-01, 5.93251570e-06],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [6.35081800e-01, 3.64918170e-01, 2.14342320e-08],\n",
       "       [2.79987670e-03, 9.97199800e-01, 3.23373630e-07],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.44084650e-02, 9.64704930e-01, 8.86674330e-04],\n",
       "       [8.22732000e-01, 1.77267500e-01, 4.85894360e-07],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [8.71244400e-03, 9.88195060e-01, 3.09258330e-03],\n",
       "       [2.55562340e-04, 3.00920340e-03, 9.96735160e-01],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [1.26712260e-03, 9.98730960e-01, 1.90215140e-06],\n",
       "       [9.91926430e-01, 8.07349200e-03, 3.23502450e-10],\n",
       "       [9.53468550e-04, 9.99046500e-01, 6.29875500e-09],\n",
       "       [1.55445990e-04, 9.99487500e-01, 3.56954230e-04],\n",
       "       [2.63905430e-03, 9.97360770e-01, 1.62151750e-07],\n",
       "       [6.95518730e-03, 9.93044800e-01, 1.86095010e-08],\n",
       "       [1.36405140e-03, 9.98635950e-01, 5.89819960e-08],\n",
       "       [1.36405140e-03, 9.98635950e-01, 5.89819960e-08],\n",
       "       [3.44084650e-02, 9.64704930e-01, 8.86674330e-04],\n",
       "       [1.09690010e-03, 9.98899460e-01, 3.55554740e-06],\n",
       "       [9.99990460e-01, 9.52030900e-06, 6.71204400e-12],\n",
       "       [1.09690010e-03, 9.98899460e-01, 3.55554740e-06],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [9.85672350e-01, 1.43276880e-02, 5.83770600e-10],\n",
       "       [3.02992940e-08, 2.11305330e-03, 9.97886960e-01],\n",
       "       [1.09960790e-04, 9.93862300e-01, 6.02776300e-03],\n",
       "       [3.02992370e-08, 2.11305640e-03, 9.97886960e-01],\n",
       "       [9.99995000e-01, 5.95774400e-07, 4.38663300e-06],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [2.55562340e-04, 3.00920500e-03, 9.96735160e-01],\n",
       "       [4.72409400e-06, 3.93385700e-05, 9.99955900e-01],\n",
       "       [4.48513250e-04, 9.99537100e-01, 1.44227020e-05]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980104071013162"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980104071013162"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS109     2\n",
       "1     NRS109     2\n",
       "2     NRS222     0\n",
       "3     NRS109     2\n",
       "4    GA50245     0\n",
       "..       ...   ...\n",
       "193   NRS148     2\n",
       "194   NRS266     1\n",
       "195   NRS109     2\n",
       "196   NRS149     0\n",
       "197   NRS109     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 425us/step - loss: 0.6430 - accuracy: 0.7078 - val_loss: 0.5176 - val_accuracy: 0.7677\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.4556 - accuracy: 0.8052 - val_loss: 0.4375 - val_accuracy: 0.8283\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.3673 - accuracy: 0.8398 - val_loss: 0.3551 - val_accuracy: 0.8384\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.3258 - accuracy: 0.8485 - val_loss: 0.3388 - val_accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.2725 - accuracy: 0.9004 - val_loss: 0.3140 - val_accuracy: 0.8535\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.2586 - accuracy: 0.8939 - val_loss: 0.2765 - val_accuracy: 0.8939\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.2216 - accuracy: 0.9177 - val_loss: 0.2742 - val_accuracy: 0.9293\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.1988 - accuracy: 0.9242 - val_loss: 0.2325 - val_accuracy: 0.8939\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.1779 - accuracy: 0.9437 - val_loss: 0.2184 - val_accuracy: 0.9293\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.1734 - accuracy: 0.9394 - val_loss: 0.2039 - val_accuracy: 0.9293\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.1617 - accuracy: 0.9524 - val_loss: 0.1973 - val_accuracy: 0.9343\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.1479 - accuracy: 0.9589 - val_loss: 0.1761 - val_accuracy: 0.9545\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.1552 - accuracy: 0.9524 - val_loss: 0.1660 - val_accuracy: 0.9495\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.1506 - accuracy: 0.9502 - val_loss: 0.1495 - val_accuracy: 0.9394\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.1156 - accuracy: 0.9697 - val_loss: 0.1551 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 511us/step - loss: 0.1086 - accuracy: 0.9762 - val_loss: 0.1361 - val_accuracy: 0.9596\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.1086 - accuracy: 0.9719 - val_loss: 0.1354 - val_accuracy: 0.9495\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.1078 - accuracy: 0.9697 - val_loss: 0.1746 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.1108 - accuracy: 0.9632 - val_loss: 0.1403 - val_accuracy: 0.9545\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 654us/step - loss: 0.1036 - accuracy: 0.9697 - val_loss: 0.1092 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 405us/step - loss: 0.1036 - accuracy: 0.9697 - val_loss: 0.1302 - val_accuracy: 0.9545\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 553us/step - loss: 0.0951 - accuracy: 0.9762 - val_loss: 0.1123 - val_accuracy: 0.9646\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 403us/step - loss: 0.0737 - accuracy: 0.9848 - val_loss: 0.1308 - val_accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0774 - accuracy: 0.9848 - val_loss: 0.0961 - val_accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0693 - accuracy: 0.9827 - val_loss: 0.1016 - val_accuracy: 0.9646\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.0642 - accuracy: 0.9935 - val_loss: 0.1008 - val_accuracy: 0.9646\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 478us/step - loss: 0.0589 - accuracy: 0.9913 - val_loss: 0.0917 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 0.0778 - accuracy: 0.9719 - val_loss: 0.1024 - val_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 0.0574 - accuracy: 0.9870 - val_loss: 0.0950 - val_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.0612 - accuracy: 0.9870 - val_loss: 0.1002 - val_accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.0683 - accuracy: 0.9848 - val_loss: 0.0864 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 478us/step - loss: 0.0627 - accuracy: 0.9848 - val_loss: 0.1139 - val_accuracy: 0.9545\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0597 - accuracy: 0.9848 - val_loss: 0.0907 - val_accuracy: 0.9798\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0516 - accuracy: 0.9913 - val_loss: 0.0755 - val_accuracy: 0.9747\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0512 - accuracy: 0.9913 - val_loss: 0.0758 - val_accuracy: 0.9646\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.0447 - accuracy: 0.9913 - val_loss: 0.0778 - val_accuracy: 0.9798\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0419 - accuracy: 0.9913 - val_loss: 0.0708 - val_accuracy: 0.9747\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0987 - val_accuracy: 0.9646\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0954 - val_accuracy: 0.9596\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 0.0417 - accuracy: 0.9935 - val_loss: 0.0703 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.0361 - accuracy: 0.9935 - val_loss: 0.1100 - val_accuracy: 0.9646\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0383 - accuracy: 0.9935 - val_loss: 0.1219 - val_accuracy: 0.9545\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0365 - accuracy: 0.9913 - val_loss: 0.0828 - val_accuracy: 0.9646\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0321 - accuracy: 0.9957 - val_loss: 0.1136 - val_accuracy: 0.9596\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.0365 - accuracy: 0.9892 - val_loss: 0.0672 - val_accuracy: 0.9646\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.0734 - val_accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.0934 - val_accuracy: 0.9646\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.0299 - accuracy: 0.9935 - val_loss: 0.1120 - val_accuracy: 0.9596\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0307 - accuracy: 0.9935 - val_loss: 0.0750 - val_accuracy: 0.9747\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 0.0809 - val_accuracy: 0.9747\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0252 - accuracy: 0.9957 - val_loss: 0.0782 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.1033 - val_accuracy: 0.9646\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.0315 - accuracy: 0.9957 - val_loss: 0.1355 - val_accuracy: 0.9596\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0623 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.0353 - accuracy: 0.9935 - val_loss: 0.0706 - val_accuracy: 0.9848\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0314 - accuracy: 0.9935 - val_loss: 0.0861 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0337 - accuracy: 0.9892 - val_loss: 0.0814 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.0578 - val_accuracy: 0.9697\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.0187 - accuracy: 0.9978 - val_loss: 0.0946 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0206 - accuracy: 0.9978 - val_loss: 0.0801 - val_accuracy: 0.9646\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 178us/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.0612 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9646\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 0.0836 - val_accuracy: 0.9646\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.0167 - accuracy: 0.9978 - val_loss: 0.0904 - val_accuracy: 0.9646\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9646\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9646\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0160 - accuracy: 0.9978 - val_loss: 0.1043 - val_accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0175 - accuracy: 0.9978 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0268 - accuracy: 0.9935 - val_loss: 0.0673 - val_accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0892 - val_accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0190 - accuracy: 0.9978 - val_loss: 0.0770 - val_accuracy: 0.9646\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 173us/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.1196 - val_accuracy: 0.9596\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0635 - val_accuracy: 0.9697\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0524 - val_accuracy: 0.9848\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 0.0593 - val_accuracy: 0.9848\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9646\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0125 - accuracy: 0.9978 - val_loss: 0.1095 - val_accuracy: 0.9596\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0862 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 509us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9646\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9747\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9747\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9747\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9798\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9848\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9697\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9646\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9798\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9697\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3f4410f0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 178us/step\n",
      "over-sampling test accuracy: 96.97%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 0, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1,\n",
       "       2, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 2, 2, 0, 2, 0, 0, 1, 1, 2, 0, 2,\n",
       "       1, 1, 0, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 1, 0,\n",
       "       2, 0, 2, 1, 1, 1, 2, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1,\n",
       "       0, 2, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 1, 1,\n",
       "       1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 0, 2, 1, 0,\n",
       "       0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "       0, 1, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS109     2     2\n",
       "1     NRS109     2     2\n",
       "2     NRS222     0     0\n",
       "3     NRS109     2     2\n",
       "4    GA50245     0     0\n",
       "..       ...   ...   ...\n",
       "193   NRS148     2     2\n",
       "194   NRS266     1     1\n",
       "195   NRS109     2     2\n",
       "196   NRS149     0     0\n",
       "197   NRS109     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.544798e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>9.992802e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.544798e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>9.992802e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.981701e-01</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>9.083791e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.544798e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>9.992802e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.991456e-01</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>6.293267e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>8.168285e-08</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>9.992730e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.343134e-04</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>4.523713e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2.544798e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>9.992802e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.229113e-01</td>\n",
       "      <td>0.477087</td>\n",
       "      <td>1.622369e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.544798e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>9.992802e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    2.544798e-04  0.000465  9.992802e-01\n",
       "1    2.544798e-04  0.000465  9.992802e-01\n",
       "2    9.981701e-01  0.001830  9.083791e-10\n",
       "3    2.544798e-04  0.000465  9.992802e-01\n",
       "4    9.991456e-01  0.000854  6.293267e-09\n",
       "..            ...       ...           ...\n",
       "193  8.168285e-08  0.000727  9.992730e-01\n",
       "194  2.343134e-04  0.999761  4.523713e-06\n",
       "195  2.544798e-04  0.000465  9.992802e-01\n",
       "196  5.229113e-01  0.477087  1.622369e-06\n",
       "197  2.544798e-04  0.000465  9.992802e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9697\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9747\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0660 - val_accuracy: 0.9747\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9697\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9596\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9848\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9848\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0565 - val_accuracy: 0.9899\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9697\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9697\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9798\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9697\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9697\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9697\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9697\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9697\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9697\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9697\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9697\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9697\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 401us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9697\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 484us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9697\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 412us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9697\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 417us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 402us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9697\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9697\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 432us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 511us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9697\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 341us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9697\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 517us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9798\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9747\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9697\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9697\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9798\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9697\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9798\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 335us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9747\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9747\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9798\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9747\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9697\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 182us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9747\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9747\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9697\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9747\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 424us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9747\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9798\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9798\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9798\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9798\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9798\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9697\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9798\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 459us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 366us/step - loss: 9.8024e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9747\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 676us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 9.8999e-04 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 9.8163e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 9.7159e-04 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9747\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 8.6462e-04 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 8.8381e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 8.6601e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9697\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 8.4502e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 8.7271e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9798\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 8.2791e-04 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 8.4038e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 8.3759e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 588us/step - loss: 7.9150e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 515us/step - loss: 8.0535e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.98170140e-01, 1.82982660e-03, 9.08379100e-10],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99145600e-01, 8.54330400e-04, 6.29326700e-09],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.96754940e-01, 3.24509390e-03, 3.90328230e-08],\n",
       "       [2.86995750e-04, 9.99712900e-01, 8.05633600e-08],\n",
       "       [1.00000000e+00, 4.73811100e-09, 1.06927760e-13],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99763200e-01, 2.36815600e-04, 2.30747400e-10],\n",
       "       [2.82478230e-04, 9.99717060e-01, 4.84786000e-07],\n",
       "       [9.98798850e-01, 1.20102940e-03, 6.36851000e-08],\n",
       "       [2.84632390e-05, 9.94989450e-01, 4.98202600e-03],\n",
       "       [2.11131560e-04, 9.99770000e-01, 1.88034560e-05],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [5.20176600e-04, 9.99479500e-01, 3.98754280e-07],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [9.08466250e-05, 9.99719100e-01, 1.90041070e-04],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99972340e-01, 2.77043980e-05, 2.39644280e-09],\n",
       "       [1.07738260e-02, 9.89225900e-01, 2.72224980e-07],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [2.84632390e-05, 9.94989450e-01, 4.98202600e-03],\n",
       "       [2.91435700e-03, 9.96953000e-01, 1.32663820e-04],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [2.82478230e-04, 9.99717060e-01, 4.84786000e-07],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.17484070e-02, 9.78249850e-01, 1.69415310e-06],\n",
       "       [9.99361600e-01, 6.38390540e-04, 2.87737160e-08],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99998200e-01, 1.75286820e-06, 9.68540940e-11],\n",
       "       [1.43546390e-01, 8.56448800e-01, 4.79933500e-06],\n",
       "       [2.26073640e-05, 9.99950650e-01, 2.67117830e-05],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [5.20176600e-04, 9.99479500e-01, 3.98754280e-07],\n",
       "       [9.99651550e-01, 3.48410860e-04, 3.24331170e-10],\n",
       "       [5.25173640e-03, 9.93828360e-01, 9.19932300e-04],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [4.36421400e-03, 9.95623050e-01, 1.27585770e-05],\n",
       "       [1.00000000e+00, 2.19387620e-10, 5.81994020e-18],\n",
       "       [9.99961600e-01, 3.83739000e-05, 1.50110400e-10],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [4.02486200e-04, 9.99593700e-01, 3.79368000e-06],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99999640e-01, 3.68345070e-07, 2.05968890e-11],\n",
       "       [9.84444000e-01, 1.55560070e-02, 6.43830900e-09],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [4.82372330e-03, 9.95176300e-01, 2.17447710e-08],\n",
       "       [2.34313410e-04, 9.99761160e-01, 4.52370840e-06],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.93090570e-01, 6.90946400e-03, 7.10595200e-09],\n",
       "       [1.36120970e-04, 9.99852660e-01, 1.11581340e-05],\n",
       "       [2.50612500e-01, 7.49387500e-01, 4.04599130e-08],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.99659400e-01, 3.40636470e-04, 1.55052180e-08],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.98244170e-01, 1.75572550e-03, 1.43940200e-07],\n",
       "       [9.99999900e-01, 1.30102850e-07, 5.00302400e-15],\n",
       "       [1.07738260e-02, 9.89225900e-01, 2.72224980e-07],\n",
       "       [1.48282150e-02, 9.85170900e-01, 9.54348600e-07],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99980450e-01, 1.95884400e-05, 6.21645700e-10],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [3.73969760e-03, 9.96252800e-01, 7.53751700e-06],\n",
       "       [4.91095050e-03, 9.95042100e-01, 4.70155000e-05],\n",
       "       [9.97541070e-01, 2.45898640e-03, 1.02908290e-11],\n",
       "       [9.99989030e-01, 1.10196750e-05, 2.31812150e-09],\n",
       "       [3.14367240e-05, 9.99968400e-01, 1.30437670e-07],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [2.34313410e-04, 9.99761160e-01, 4.52370840e-06],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99802400e-01, 1.97617930e-04, 3.12599560e-10],\n",
       "       [9.99772500e-01, 2.27541170e-04, 2.64136630e-10],\n",
       "       [9.97521100e-01, 2.47884540e-03, 6.04083200e-11],\n",
       "       [8.59121000e-01, 1.40878920e-01, 1.03434010e-07],\n",
       "       [5.00545200e-03, 9.94989800e-01, 4.76149700e-06],\n",
       "       [1.99348340e-03, 9.94755740e-01, 3.25071160e-03],\n",
       "       [9.99981400e-01, 1.85810700e-05, 1.72307400e-11],\n",
       "       [4.02486200e-04, 9.99593700e-01, 3.79368000e-06],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [9.96066870e-01, 3.93289650e-03, 2.08225770e-07],\n",
       "       [3.73969760e-03, 9.96252800e-01, 7.53751700e-06],\n",
       "       [9.98132170e-01, 1.86770790e-03, 8.28774500e-08],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.00000000e+00, 1.14396060e-08, 2.95616350e-16],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.82478230e-04, 9.99717060e-01, 4.84786000e-07],\n",
       "       [2.86995750e-04, 9.99712900e-01, 8.05633600e-08],\n",
       "       [4.36421400e-03, 9.95623050e-01, 1.27585770e-05],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [1.72230000e-05, 9.99977230e-01, 5.58314470e-06],\n",
       "       [9.99980450e-01, 1.95524570e-05, 2.72835160e-08],\n",
       "       [9.99807540e-01, 1.92503180e-04, 1.25631840e-08],\n",
       "       [9.08466250e-05, 9.99719100e-01, 1.90041070e-04],\n",
       "       [9.99666700e-01, 3.33301980e-04, 1.35700090e-08],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [9.99730770e-01, 2.69179200e-04, 9.21808600e-09],\n",
       "       [2.82478230e-04, 9.99717060e-01, 4.84786000e-07],\n",
       "       [9.27846250e-01, 7.21536700e-02, 4.81110760e-08],\n",
       "       [2.17484070e-02, 9.78249850e-01, 1.69415310e-06],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.00000000e+00, 2.03179720e-09, 1.09705050e-14],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [5.00545200e-03, 9.94989800e-01, 4.76149700e-06],\n",
       "       [9.99104900e-01, 8.95023200e-04, 2.72027560e-08],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [2.08228350e-01, 7.91771200e-01, 4.89978450e-07],\n",
       "       [1.07738260e-02, 9.89225900e-01, 2.72224980e-07],\n",
       "       [3.57426600e-02, 9.64257000e-01, 3.81023970e-07],\n",
       "       [1.99348340e-03, 9.94755740e-01, 3.25071160e-03],\n",
       "       [9.99488600e-01, 5.11408000e-04, 1.91455990e-08],\n",
       "       [9.99999900e-01, 6.52568100e-08, 1.30352580e-13],\n",
       "       [9.99998800e-01, 1.18582450e-06, 1.75184200e-11],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.88224740e-01, 1.17751000e-02, 1.40894460e-07],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.84897040e-03, 9.98150900e-01, 1.68191050e-07],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [4.46778700e-03, 9.95531560e-01, 5.92635100e-07],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [3.14367240e-05, 9.99968400e-01, 1.30437670e-07],\n",
       "       [1.00000000e+00, 1.62993230e-08, 2.67144560e-16],\n",
       "       [9.08466250e-05, 9.99719100e-01, 1.90041070e-04],\n",
       "       [4.46778700e-03, 9.95531560e-01, 5.92635100e-07],\n",
       "       [2.17484070e-02, 9.78249850e-01, 1.69415310e-06],\n",
       "       [2.86995750e-04, 9.99712900e-01, 8.05633600e-08],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.40748700e-01, 5.92512700e-02, 1.13664600e-08],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [9.99893070e-01, 1.06894800e-04, 7.25995570e-12],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.99999900e-01, 1.57612690e-07, 6.64044500e-11],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.69967070e-01, 3.00328280e-02, 1.06883800e-07],\n",
       "       [9.99989400e-01, 1.05501380e-05, 2.69078060e-14],\n",
       "       [7.33927650e-04, 9.99265000e-01, 1.08951770e-06],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [9.99304900e-01, 6.95077400e-04, 5.65007630e-08],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [4.46778700e-03, 9.95531560e-01, 5.92635100e-07],\n",
       "       [9.99989750e-01, 1.02837160e-05, 1.04254765e-11],\n",
       "       [9.99991900e-01, 8.12765500e-06, 2.31059560e-14],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [1.72230000e-05, 9.99977230e-01, 5.58314470e-06],\n",
       "       [1.99348340e-03, 9.94755740e-01, 3.25071160e-03],\n",
       "       [9.98570200e-01, 1.42952520e-03, 2.35044280e-07],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [2.84632390e-05, 9.94989450e-01, 4.98202600e-03],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [9.99124700e-01, 8.75313400e-04, 5.33588200e-10],\n",
       "       [9.99250000e-01, 7.49927540e-04, 3.48036120e-08],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [9.99923000e-01, 7.70465600e-05, 2.91570810e-09],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [5.25173640e-03, 9.93828360e-01, 9.19932300e-04],\n",
       "       [4.46778700e-03, 9.95531560e-01, 5.92635100e-07],\n",
       "       [3.14367240e-05, 9.99968400e-01, 1.30437670e-07],\n",
       "       [1.26163780e-07, 3.97753900e-05, 9.99960060e-01],\n",
       "       [2.08720210e-02, 9.79112000e-01, 1.59706250e-05],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [9.99978300e-01, 2.17076230e-05, 6.18514840e-14],\n",
       "       [4.36421400e-03, 9.95623050e-01, 1.27585770e-05],\n",
       "       [8.27021900e-01, 1.72978100e-01, 1.18238070e-08],\n",
       "       [5.00545200e-03, 9.94989800e-01, 4.76149700e-06],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [1.91396580e-01, 8.08600250e-01, 3.19248370e-06],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [4.91095050e-03, 9.95042100e-01, 4.70155000e-05],\n",
       "       [9.99013900e-01, 9.86127600e-04, 4.19677450e-11],\n",
       "       [9.99999300e-01, 6.60739700e-07, 1.79420090e-15],\n",
       "       [9.99999760e-01, 2.47673340e-07, 4.00210900e-15],\n",
       "       [9.99953270e-01, 4.67506140e-05, 1.27433450e-13],\n",
       "       [1.48282150e-02, 9.85170900e-01, 9.54348600e-07],\n",
       "       [8.16828500e-08, 7.26874200e-04, 9.99273000e-01],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [1.99348340e-03, 9.94755740e-01, 3.25071160e-03],\n",
       "       [2.27006040e-03, 9.97729960e-01, 1.96731340e-08],\n",
       "       [8.16828500e-08, 7.26874570e-04, 9.99273000e-01],\n",
       "       [2.34313410e-04, 9.99761160e-01, 4.52371250e-06],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01],\n",
       "       [5.22911300e-01, 4.77087020e-01, 1.62236860e-06],\n",
       "       [2.54479800e-04, 4.65349440e-04, 9.99280150e-01]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972834404652587"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972834404652587"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa110     0\n",
       "1    CFBREBSa131     1\n",
       "2         NRS148     2\n",
       "3         NRS169     1\n",
       "4         NRS073     0\n",
       "..           ...   ...\n",
       "193       NRS001     1\n",
       "194       NRS191     0\n",
       "195       NRS207     0\n",
       "196         CA26     0\n",
       "197     CFBRSa48     0\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 422us/step - loss: 0.7285 - accuracy: 0.6840 - val_loss: 0.5866 - val_accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.4820 - accuracy: 0.8009 - val_loss: 0.4873 - val_accuracy: 0.7929\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.4218 - val_accuracy: 0.8182\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.3403 - accuracy: 0.8723 - val_loss: 0.3843 - val_accuracy: 0.8434\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.3200 - accuracy: 0.8701 - val_loss: 0.3812 - val_accuracy: 0.8131\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.3418 - accuracy: 0.8636 - val_loss: 0.3595 - val_accuracy: 0.8232\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.2584 - accuracy: 0.9069 - val_loss: 0.3017 - val_accuracy: 0.8889\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.2476 - accuracy: 0.9004 - val_loss: 0.2921 - val_accuracy: 0.8990\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.2236 - accuracy: 0.9221 - val_loss: 0.2698 - val_accuracy: 0.8687\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.2078 - accuracy: 0.9264 - val_loss: 0.2522 - val_accuracy: 0.8889\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.1949 - accuracy: 0.9286 - val_loss: 0.2404 - val_accuracy: 0.9343\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.1947 - accuracy: 0.9372 - val_loss: 0.2295 - val_accuracy: 0.9242\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.1558 - accuracy: 0.9610 - val_loss: 0.2140 - val_accuracy: 0.9444\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.1513 - accuracy: 0.9610 - val_loss: 0.2008 - val_accuracy: 0.9343\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.1503 - accuracy: 0.9545 - val_loss: 0.2744 - val_accuracy: 0.9091\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 489us/step - loss: 0.1470 - accuracy: 0.9589 - val_loss: 0.1969 - val_accuracy: 0.9495\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.1387 - accuracy: 0.9610 - val_loss: 0.1893 - val_accuracy: 0.9343\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.1238 - accuracy: 0.9697 - val_loss: 0.1670 - val_accuracy: 0.9596\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.1127 - accuracy: 0.9719 - val_loss: 0.1592 - val_accuracy: 0.9545\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 708us/step - loss: 0.1052 - accuracy: 0.9762 - val_loss: 0.1593 - val_accuracy: 0.9596\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.1014 - accuracy: 0.9762 - val_loss: 0.1473 - val_accuracy: 0.9545\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0970 - accuracy: 0.9805 - val_loss: 0.1433 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0823 - accuracy: 0.9870 - val_loss: 0.1516 - val_accuracy: 0.9545\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0887 - accuracy: 0.9762 - val_loss: 0.1323 - val_accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0782 - accuracy: 0.9827 - val_loss: 0.1569 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0930 - accuracy: 0.9762 - val_loss: 0.1311 - val_accuracy: 0.9697\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0785 - accuracy: 0.9848 - val_loss: 0.1301 - val_accuracy: 0.9646\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0665 - accuracy: 0.9870 - val_loss: 0.1426 - val_accuracy: 0.9495\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0751 - accuracy: 0.9784 - val_loss: 0.1216 - val_accuracy: 0.9646\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 458us/step - loss: 0.0723 - accuracy: 0.9805 - val_loss: 0.1173 - val_accuracy: 0.9646\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.1370 - val_accuracy: 0.9747\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 171us/step - loss: 0.0653 - accuracy: 0.9784 - val_loss: 0.1153 - val_accuracy: 0.9646\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0558 - accuracy: 0.9892 - val_loss: 0.1570 - val_accuracy: 0.9495\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0546 - accuracy: 0.9913 - val_loss: 0.1443 - val_accuracy: 0.9495\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.0517 - accuracy: 0.9870 - val_loss: 0.1056 - val_accuracy: 0.9798\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 0.0481 - accuracy: 0.9913 - val_loss: 0.1021 - val_accuracy: 0.9747\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.0458 - accuracy: 0.9935 - val_loss: 0.1143 - val_accuracy: 0.9596\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0435 - accuracy: 0.9892 - val_loss: 0.1115 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 0.1184 - val_accuracy: 0.9596\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.1033 - val_accuracy: 0.9747\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0416 - accuracy: 0.9892 - val_loss: 0.1050 - val_accuracy: 0.9747\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0459 - accuracy: 0.9827 - val_loss: 0.1092 - val_accuracy: 0.9697\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0451 - accuracy: 0.9913 - val_loss: 0.1099 - val_accuracy: 0.9697\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 0.1084 - val_accuracy: 0.9697\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0336 - accuracy: 0.9957 - val_loss: 0.1086 - val_accuracy: 0.9747\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0333 - accuracy: 0.9913 - val_loss: 0.0978 - val_accuracy: 0.9747\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.0918 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.0361 - accuracy: 0.9957 - val_loss: 0.0941 - val_accuracy: 0.9697\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.0379 - accuracy: 0.9913 - val_loss: 0.1555 - val_accuracy: 0.9495\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.0453 - accuracy: 0.9892 - val_loss: 0.1218 - val_accuracy: 0.9697\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 177us/step - loss: 0.0350 - accuracy: 0.9913 - val_loss: 0.0968 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0674 - accuracy: 0.9805 - val_loss: 0.0862 - val_accuracy: 0.9899\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.0521 - accuracy: 0.9870 - val_loss: 0.1100 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.1014 - val_accuracy: 0.9697\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.0277 - accuracy: 0.9957 - val_loss: 0.1192 - val_accuracy: 0.9646\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.1327 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0266 - accuracy: 0.9978 - val_loss: 0.1498 - val_accuracy: 0.9545\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0228 - accuracy: 0.9978 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 0.0184 - accuracy: 0.9978 - val_loss: 0.0995 - val_accuracy: 0.9697\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.0181 - accuracy: 0.9978 - val_loss: 0.0896 - val_accuracy: 0.9747\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.0865 - val_accuracy: 0.9697\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0857 - val_accuracy: 0.9798\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.0838 - val_accuracy: 0.9848\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 0.0889 - val_accuracy: 0.9697\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.1057 - val_accuracy: 0.9646\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0193 - accuracy: 0.9978 - val_loss: 0.0911 - val_accuracy: 0.9798\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9646\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9495\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 492us/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 0.1316 - val_accuracy: 0.9596\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0165 - accuracy: 0.9978 - val_loss: 0.1796 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.1787 - val_accuracy: 0.9495\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.1705 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0310 - accuracy: 0.9935 - val_loss: 0.1609 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0968 - val_accuracy: 0.9646\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9747\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9646\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.1191 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9899\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9697\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9798\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a40850080>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 198us/step\n",
      "over-sampling test accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 1, 0, 2, 0, 2, 0, 2, 0, 2,\n",
       "       1, 0, 1, 2, 2, 2, 0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2, 2, 1, 0, 0,\n",
       "       1, 1, 0, 1, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 2, 1,\n",
       "       0, 1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 2, 0, 2, 0, 0, 1, 0, 2,\n",
       "       2, 1, 2, 1, 2, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 2, 0, 2, 0, 1,\n",
       "       2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 0, 0, 2, 1, 1, 1, 2,\n",
       "       1, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1, 1, 0, 2, 0, 1, 2, 0, 0, 0, 1,\n",
       "       1, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CA26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CFBRSa48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa110     0     0\n",
       "1    CFBREBSa131     1     1\n",
       "2         NRS148     2     2\n",
       "3         NRS169     1     1\n",
       "4         NRS073     0     0\n",
       "..           ...   ...   ...\n",
       "193       NRS001     1     1\n",
       "194       NRS191     0     0\n",
       "195       NRS207     0     0\n",
       "196         CA26     0     0\n",
       "197     CFBRSa48     0     0\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.995762e-01</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>1.239028e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.607985e-02</td>\n",
       "      <td>0.973920</td>\n",
       "      <td>4.181065e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.483531e-10</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>9.993107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.207318e-03</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>2.792645e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.998268e-01</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>1.205728e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.822547e-03</td>\n",
       "      <td>0.996177</td>\n",
       "      <td>1.056541e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.188336e-01</td>\n",
       "      <td>0.081166</td>\n",
       "      <td>3.952307e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>9.996057e-01</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>1.105371e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.999986e-01</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.736989e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.995962e-01</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>4.492323e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    9.995762e-01  0.000424  1.239028e-10\n",
       "1    2.607985e-02  0.973920  4.181065e-10\n",
       "2    3.483531e-10  0.000689  9.993107e-01\n",
       "3    2.207318e-03  0.995000  2.792645e-03\n",
       "4    9.998268e-01  0.000173  1.205728e-14\n",
       "..            ...       ...           ...\n",
       "193  3.822547e-03  0.996177  1.056541e-07\n",
       "194  9.188336e-01  0.081166  3.952307e-08\n",
       "195  9.996057e-01  0.000394  1.105371e-10\n",
       "196  9.999986e-01  0.000001  9.736989e-13\n",
       "197  9.995962e-01  0.000404  4.492323e-10\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9848\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9848\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9848\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9848\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9848\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9848\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9848\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9798\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9848\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9848\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9899\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9848\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9848\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9848\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9848\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9848\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 555us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9798\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9848\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9545\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 546us/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1317 - val_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9697\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 466us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9899\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 503us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9899\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 435us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 352us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9848\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9848\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9747\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9848\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 531us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9848\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9848\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9747\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9798\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9848\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 541us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9848\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9848\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9848\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9848\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9848\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9848\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9848\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9899\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9747\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9848\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9848\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9848\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9848\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9848\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9747\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9848\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9899\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9848\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 172us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9848\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9848\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9747\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9848\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 181us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9848\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 371us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9848\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9848\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9848\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9848\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9848\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9848\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9848\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9848\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9848\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9848\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9848\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 445us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9848\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9747\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9848\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9848\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9848\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9848\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9848\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9798\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 366us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9848\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9848\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 417us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9848\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9848\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 428us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9848\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9848\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 9.5043e-04 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9848\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 9.7321e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9848\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9747\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9848\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 9.1840e-04 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9848\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 9.2326e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 8.6291e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9848\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 8.9689e-04 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9848\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 9.5996e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99576150e-01, 4.23892840e-04, 1.23902780e-10],\n",
       "       [2.60798520e-02, 9.73920170e-01, 4.18106470e-10],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.20731760e-03, 9.95000100e-01, 2.79264450e-03],\n",
       "       [9.99826850e-01, 1.73138690e-04, 1.20572760e-14],\n",
       "       [1.33726550e-05, 9.99986650e-01, 1.79746240e-08],\n",
       "       [2.89208330e-06, 9.93311400e-01, 6.68580830e-03],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.24777940e-03, 9.97752000e-01, 1.84453800e-07],\n",
       "       [5.43817340e-01, 4.56182630e-01, 1.28422650e-08],\n",
       "       [9.99985200e-01, 1.48233200e-05, 1.13038530e-16],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [1.76153390e-02, 9.82384400e-01, 2.00859550e-07],\n",
       "       [3.82255060e-03, 9.96177300e-01, 1.05654110e-07],\n",
       "       [9.99992000e-01, 7.95952900e-06, 4.14285670e-09],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [9.99087200e-01, 9.12809450e-04, 3.87899700e-10],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [9.93488800e-01, 6.51118100e-03, 6.01880270e-10],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.98028700e-01, 1.97123100e-03, 2.52061120e-13],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.89208330e-06, 9.93311400e-01, 6.68580830e-03],\n",
       "       [9.99998570e-01, 1.37958850e-06, 8.30646400e-14],\n",
       "       [6.98977060e-03, 9.93010100e-01, 8.31608200e-08],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99994750e-01, 5.27162400e-06, 1.01652500e-12],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [8.88242400e-03, 9.89578660e-01, 1.53891030e-03],\n",
       "       [7.29763900e-03, 9.92701300e-01, 1.03235120e-06],\n",
       "       [9.97810900e-01, 2.18915540e-03, 3.85815070e-10],\n",
       "       [2.96392500e-03, 9.97036100e-01, 4.55613640e-08],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [5.14509740e-05, 9.99858500e-01, 8.99359950e-05],\n",
       "       [9.99576150e-01, 4.23892840e-04, 1.23902780e-10],\n",
       "       [5.82351450e-01, 4.17648580e-01, 6.68753000e-11],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [4.50306540e-04, 9.99549700e-01, 4.15560070e-08],\n",
       "       [9.99999640e-01, 3.17529380e-07, 2.78450980e-12],\n",
       "       [9.99997500e-01, 2.46587110e-06, 5.67283600e-10],\n",
       "       [5.56014000e-03, 9.94439840e-01, 4.25864620e-11],\n",
       "       [2.02752770e-04, 9.99737440e-01, 5.97872900e-05],\n",
       "       [9.99997260e-01, 2.74508580e-06, 1.81888460e-12],\n",
       "       [2.20731760e-03, 9.95000100e-01, 2.79264450e-03],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [8.88242400e-03, 9.89578660e-01, 1.53891030e-03],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.49426720e-04, 9.99750440e-01, 1.56834400e-07],\n",
       "       [9.99950900e-01, 4.91513060e-05, 5.27392900e-11],\n",
       "       [9.99309060e-01, 6.90988500e-04, 1.75505460e-10],\n",
       "       [4.35380100e-05, 9.99954800e-01, 1.71632180e-06],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [3.25799880e-01, 6.74198700e-01, 1.46922820e-06],\n",
       "       [4.35380100e-05, 9.99954800e-01, 1.71632180e-06],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [1.43210280e-03, 9.98567800e-01, 1.25761910e-08],\n",
       "       [9.90477560e-01, 9.52248650e-03, 7.54911860e-10],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [3.50014240e-03, 9.96499900e-01, 3.79638200e-08],\n",
       "       [7.49174240e-01, 2.50825760e-01, 2.57549710e-09],\n",
       "       [1.64660600e-03, 9.98353360e-01, 5.55964300e-08],\n",
       "       [6.99800300e-03, 9.93001900e-01, 7.11607600e-08],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [2.89208330e-06, 9.93311400e-01, 6.68580830e-03],\n",
       "       [2.96392500e-03, 9.97036100e-01, 4.55613640e-08],\n",
       "       [9.99999500e-01, 4.97615700e-07, 3.77602900e-13],\n",
       "       [9.13301370e-04, 9.99086740e-01, 7.24946460e-09],\n",
       "       [7.58283600e-04, 9.99241100e-01, 6.20324440e-07],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [1.21681400e-02, 9.87831800e-01, 1.01455950e-07],\n",
       "       [3.50014240e-03, 9.96499900e-01, 3.79638200e-08],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.98467000e-01, 1.53294470e-03, 2.07177750e-10],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99576150e-01, 4.23892840e-04, 1.23902780e-10],\n",
       "       [9.99122200e-01, 8.77757500e-04, 3.65742200e-10],\n",
       "       [6.99800300e-03, 9.93001900e-01, 7.11607600e-08],\n",
       "       [9.99822560e-01, 1.77496170e-04, 1.01707046e-10],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [2.89208330e-06, 9.93311400e-01, 6.68580830e-03],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.24777940e-03, 9.97752000e-01, 1.84453800e-07],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.98617770e-01, 1.38223920e-03, 3.26877300e-09],\n",
       "       [2.02752770e-04, 9.99737440e-01, 5.97872900e-05],\n",
       "       [8.83779170e-01, 1.16220890e-01, 1.54728340e-08],\n",
       "       [9.95883200e-01, 4.11675270e-03, 2.77803450e-12],\n",
       "       [2.20731760e-03, 9.95000100e-01, 2.79264450e-03],\n",
       "       [4.13907650e-03, 9.95860760e-01, 2.07655030e-07],\n",
       "       [9.98470500e-01, 1.52950440e-03, 7.09014300e-10],\n",
       "       [9.99888540e-01, 1.11389025e-04, 1.04723750e-10],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [1.08477570e-04, 9.99891500e-01, 1.15464080e-08],\n",
       "       [7.16627600e-05, 9.99927300e-01, 1.08497280e-06],\n",
       "       [9.99740660e-01, 2.59356500e-04, 3.55668830e-14],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.99978400e-01, 2.16175940e-05, 2.29724730e-16],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99991540e-01, 8.46900100e-06, 5.88263260e-11],\n",
       "       [9.13301370e-04, 9.99086740e-01, 7.24946460e-09],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [9.99576150e-01, 4.23892840e-04, 1.23902780e-10],\n",
       "       [1.63724480e-01, 8.36275500e-01, 2.30624390e-08],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [7.58283600e-04, 9.99241100e-01, 6.20324440e-07],\n",
       "       [9.99966000e-01, 3.39742360e-05, 8.39062700e-12],\n",
       "       [2.60798520e-02, 9.73920170e-01, 4.18106470e-10],\n",
       "       [1.14584540e-02, 9.88392530e-01, 1.49065700e-04],\n",
       "       [9.99996070e-01, 3.92621720e-06, 1.15705640e-12],\n",
       "       [1.51219630e-02, 9.84875740e-01, 2.34105780e-06],\n",
       "       [2.20731760e-03, 9.95000100e-01, 2.79264450e-03],\n",
       "       [1.08852335e-04, 9.99888900e-01, 2.21012100e-06],\n",
       "       [9.99625440e-01, 3.74558440e-04, 8.04126400e-15],\n",
       "       [9.99995700e-01, 4.31992900e-06, 1.28190830e-11],\n",
       "       [2.24777940e-03, 9.97752000e-01, 1.84453800e-07],\n",
       "       [9.98415230e-01, 1.58481500e-03, 2.37964310e-10],\n",
       "       [9.99892000e-01, 1.07962835e-04, 1.37310770e-11],\n",
       "       [7.29763900e-03, 9.92701300e-01, 1.03235120e-06],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99994040e-01, 5.96430160e-06, 3.48057480e-12],\n",
       "       [2.89208330e-06, 9.93311400e-01, 6.68580830e-03],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [2.18934760e-01, 7.81065050e-01, 1.74064040e-07],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.28378180e-04, 9.99771650e-01, 4.93463400e-10],\n",
       "       [4.50306540e-04, 9.99549700e-01, 4.15560070e-08],\n",
       "       [1.64660600e-03, 9.98353360e-01, 5.55964300e-08],\n",
       "       [2.97798200e-01, 6.99604630e-01, 2.59714970e-03],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [1.14584540e-02, 9.88392530e-01, 1.49065700e-04],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [9.99998450e-01, 1.49667950e-06, 3.33078620e-13],\n",
       "       [9.70280500e-01, 2.97194780e-02, 5.61846850e-08],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.02752770e-04, 9.99737440e-01, 5.97872900e-05],\n",
       "       [7.58283600e-04, 9.99241100e-01, 6.20324440e-07],\n",
       "       [1.51219630e-02, 9.84875740e-01, 2.34105780e-06],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [1.21681400e-02, 9.87831800e-01, 1.01455950e-07],\n",
       "       [9.99987240e-01, 1.26958050e-05, 6.68605900e-12],\n",
       "       [9.99949700e-01, 5.02583800e-05, 7.28270930e-16],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.93541240e-01, 6.45874500e-03, 8.25569600e-13],\n",
       "       [1.43210280e-03, 9.98567800e-01, 1.25761910e-08],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [7.29763900e-03, 9.92701300e-01, 1.03235120e-06],\n",
       "       [3.50014240e-03, 9.96499900e-01, 3.79638200e-08],\n",
       "       [9.99918000e-01, 8.19923950e-05, 6.13157650e-11],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [9.99985700e-01, 1.43021890e-05, 2.32643700e-16],\n",
       "       [1.21681400e-02, 9.87831800e-01, 1.01455950e-07],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99323840e-01, 6.76229130e-04, 7.34296860e-14],\n",
       "       [5.11209130e-01, 4.88790800e-01, 6.61183700e-08],\n",
       "       [9.99966860e-01, 3.30881500e-05, 1.16198820e-11],\n",
       "       [5.56014000e-03, 9.94439840e-01, 4.25864620e-11],\n",
       "       [7.16627600e-05, 9.99927300e-01, 1.08497280e-06],\n",
       "       [4.13907650e-03, 9.95860760e-01, 2.07655030e-07],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99950200e-01, 4.98826050e-05, 2.47399930e-11],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [2.84649430e-04, 3.68349300e-04, 9.99347030e-01],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [9.75037460e-01, 2.49625280e-02, 3.78733070e-12],\n",
       "       [9.92564500e-01, 7.43551000e-03, 1.71420580e-08],\n",
       "       [4.13907650e-03, 9.95860760e-01, 2.07655030e-07],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99999500e-01, 4.53147320e-07, 1.49138470e-12],\n",
       "       [4.13907650e-03, 9.95860760e-01, 2.07655030e-07],\n",
       "       [2.66158380e-08, 5.74012200e-05, 9.99942540e-01],\n",
       "       [9.99940300e-01, 5.97660100e-05, 4.25626600e-15],\n",
       "       [3.48353120e-10, 6.89307050e-04, 9.99310730e-01],\n",
       "       [3.82254700e-03, 9.96177300e-01, 1.05654110e-07],\n",
       "       [3.82254700e-03, 9.96177300e-01, 1.05654110e-07],\n",
       "       [9.18833600e-01, 8.11664240e-02, 3.95230730e-08],\n",
       "       [9.99605700e-01, 3.94314300e-04, 1.10537070e-10],\n",
       "       [9.99998570e-01, 1.47372440e-06, 9.73698900e-13],\n",
       "       [9.99596200e-01, 4.03850020e-04, 4.49232320e-10]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934955616773798"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934955616773798"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS110     1\n",
       "1         NRS216     1\n",
       "2         NRS386     1\n",
       "3       CFBRSa25     0\n",
       "4      BCH-SA-03     1\n",
       "..           ...   ...\n",
       "193       NRS216     1\n",
       "194  CFBREBSa110     0\n",
       "195       NRS148     2\n",
       "196         GA27     0\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 538us/step - loss: 0.7588 - accuracy: 0.6039 - val_loss: 0.5309 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.5450 - accuracy: 0.7727 - val_loss: 0.4666 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4562 - accuracy: 0.8052 - val_loss: 0.4063 - val_accuracy: 0.8081\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 0.3847 - accuracy: 0.8095 - val_loss: 0.3772 - val_accuracy: 0.8232\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.3681 - accuracy: 0.8182 - val_loss: 0.3798 - val_accuracy: 0.8687\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.3498 - accuracy: 0.8658 - val_loss: 0.3725 - val_accuracy: 0.8788\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.3569 - accuracy: 0.8593 - val_loss: 0.3267 - val_accuracy: 0.8687\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.2743 - accuracy: 0.8983 - val_loss: 0.2883 - val_accuracy: 0.8990\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.2542 - accuracy: 0.9026 - val_loss: 0.2909 - val_accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.2634 - accuracy: 0.8896 - val_loss: 0.2736 - val_accuracy: 0.8788\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 428us/step - loss: 0.2221 - accuracy: 0.9134 - val_loss: 0.2620 - val_accuracy: 0.9091\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 393us/step - loss: 0.1983 - accuracy: 0.9416 - val_loss: 0.2467 - val_accuracy: 0.9141\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 0.1844 - accuracy: 0.9524 - val_loss: 0.2221 - val_accuracy: 0.9343\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.1700 - accuracy: 0.9502 - val_loss: 0.2147 - val_accuracy: 0.9343\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.1607 - accuracy: 0.9545 - val_loss: 0.2117 - val_accuracy: 0.9040\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 0.1520 - accuracy: 0.9524 - val_loss: 0.1923 - val_accuracy: 0.9343\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.1473 - accuracy: 0.9675 - val_loss: 0.1794 - val_accuracy: 0.9293\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.1312 - accuracy: 0.9654 - val_loss: 0.1731 - val_accuracy: 0.9343\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 174us/step - loss: 0.1215 - accuracy: 0.9697 - val_loss: 0.1639 - val_accuracy: 0.9545\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.1155 - accuracy: 0.9675 - val_loss: 0.1535 - val_accuracy: 0.9545\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 530us/step - loss: 0.1072 - accuracy: 0.9784 - val_loss: 0.1484 - val_accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.1031 - accuracy: 0.9740 - val_loss: 0.1450 - val_accuracy: 0.9343\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.1020 - accuracy: 0.9784 - val_loss: 0.1447 - val_accuracy: 0.9646\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 175us/step - loss: 0.0998 - accuracy: 0.9762 - val_loss: 0.1338 - val_accuracy: 0.9545\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0992 - accuracy: 0.9719 - val_loss: 0.1436 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.1256 - val_accuracy: 0.9646\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0803 - accuracy: 0.9827 - val_loss: 0.1183 - val_accuracy: 0.9646\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0800 - accuracy: 0.9805 - val_loss: 0.1620 - val_accuracy: 0.9343\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 508us/step - loss: 0.0893 - accuracy: 0.9827 - val_loss: 0.1114 - val_accuracy: 0.9646\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 0.0693 - accuracy: 0.9870 - val_loss: 0.1071 - val_accuracy: 0.9646\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 179us/step - loss: 0.0662 - accuracy: 0.9892 - val_loss: 0.1111 - val_accuracy: 0.9646\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.0652 - accuracy: 0.9848 - val_loss: 0.1274 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0630 - accuracy: 0.9848 - val_loss: 0.0970 - val_accuracy: 0.9697\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.0579 - accuracy: 0.9892 - val_loss: 0.0988 - val_accuracy: 0.9697\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0546 - accuracy: 0.9892 - val_loss: 0.0946 - val_accuracy: 0.9798\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 0.0522 - accuracy: 0.9913 - val_loss: 0.1110 - val_accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0584 - accuracy: 0.9892 - val_loss: 0.0943 - val_accuracy: 0.9798\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0489 - accuracy: 0.9913 - val_loss: 0.0938 - val_accuracy: 0.9899\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0520 - accuracy: 0.9935 - val_loss: 0.0893 - val_accuracy: 0.9747\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0457 - accuracy: 0.9935 - val_loss: 0.0933 - val_accuracy: 0.9596\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0438 - accuracy: 0.9913 - val_loss: 0.0941 - val_accuracy: 0.9697\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.0455 - accuracy: 0.9913 - val_loss: 0.0855 - val_accuracy: 0.9747\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0453 - accuracy: 0.9913 - val_loss: 0.0961 - val_accuracy: 0.9646\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0387 - accuracy: 0.9935 - val_loss: 0.0750 - val_accuracy: 0.9899\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.0465 - accuracy: 0.9957 - val_loss: 0.0857 - val_accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0773 - val_accuracy: 0.9798\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0362 - accuracy: 0.9957 - val_loss: 0.0732 - val_accuracy: 0.9798\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0405 - accuracy: 0.9848 - val_loss: 0.0820 - val_accuracy: 0.9899\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0371 - accuracy: 0.9935 - val_loss: 0.0762 - val_accuracy: 0.9899\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0372 - accuracy: 0.9957 - val_loss: 0.0754 - val_accuracy: 0.9949\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.0438 - accuracy: 0.9935 - val_loss: 0.0804 - val_accuracy: 0.9949\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 0.0414 - accuracy: 0.9913 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0305 - accuracy: 0.9935 - val_loss: 0.0776 - val_accuracy: 0.9899\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 0.0340 - accuracy: 0.9935 - val_loss: 0.0675 - val_accuracy: 0.9899\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.0271 - accuracy: 0.9957 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.0681 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0742 - val_accuracy: 0.9899\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 237us/step - loss: 0.0265 - accuracy: 0.9957 - val_loss: 0.0776 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.0230 - accuracy: 0.9978 - val_loss: 0.0814 - val_accuracy: 0.9697\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 176us/step - loss: 0.0216 - accuracy: 0.9978 - val_loss: 0.0744 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.0252 - accuracy: 0.9957 - val_loss: 0.0682 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0233 - accuracy: 0.9957 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.0200 - accuracy: 0.9978 - val_loss: 0.0623 - val_accuracy: 0.9899\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.0672 - val_accuracy: 0.9899\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.0661 - val_accuracy: 0.9798\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.0998 - val_accuracy: 0.9596\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.0746 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 0.0177 - accuracy: 0.9978 - val_loss: 0.0605 - val_accuracy: 0.9848\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 482us/step - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.0623 - val_accuracy: 0.9798\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.0629 - val_accuracy: 0.9848\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.0189 - accuracy: 0.9978 - val_loss: 0.0751 - val_accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0613 - val_accuracy: 0.9899\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0179 - accuracy: 0.9978 - val_loss: 0.0695 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.0812 - val_accuracy: 0.9646\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 236us/step - loss: 0.0158 - accuracy: 0.9978 - val_loss: 0.0768 - val_accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.0735 - val_accuracy: 0.9697\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0148 - accuracy: 0.9978 - val_loss: 0.0641 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.0785 - val_accuracy: 0.9697\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0661 - val_accuracy: 0.9747\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9697\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0790 - val_accuracy: 0.9646\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0751 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 0.0804 - val_accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0755 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0600 - val_accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9646\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0740 - val_accuracy: 0.9697\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9646\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9697\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9747\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9747\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9646\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9798\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3e8bf438>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 162us/step\n",
      "over-sampling test accuracy: 96.46%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 2, 1,\n",
       "       1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 0, 1, 1, 2, 1, 2, 2,\n",
       "       0, 0, 1, 2, 2, 0, 0, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 1, 2, 0, 0, 1,\n",
       "       0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 1, 2, 0,\n",
       "       1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 1, 2, 0, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 2,\n",
       "       2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GA27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS110     1     1\n",
       "1         NRS216     1     1\n",
       "2         NRS386     1     1\n",
       "3       CFBRSa25     0     0\n",
       "4      BCH-SA-03     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS216     1     1\n",
       "194  CFBREBSa110     0     0\n",
       "195       NRS148     2     2\n",
       "196         GA27     0     0\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.220611e-03</td>\n",
       "      <td>0.997779</td>\n",
       "      <td>1.605854e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.468139e-03</td>\n",
       "      <td>0.993532</td>\n",
       "      <td>1.171246e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.556950e-02</td>\n",
       "      <td>0.974430</td>\n",
       "      <td>4.912491e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.998289e-01</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>1.743965e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.377019e-03</td>\n",
       "      <td>0.993623</td>\n",
       "      <td>6.990759e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>6.468146e-03</td>\n",
       "      <td>0.993532</td>\n",
       "      <td>1.171247e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>9.994338e-01</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>2.796447e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.941034e-07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>9.991261e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.970651e-01</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>9.256775e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.941034e-07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>9.991261e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    2.220611e-03  0.997779  1.605854e-09\n",
       "1    6.468139e-03  0.993532  1.171246e-07\n",
       "2    2.556950e-02  0.974430  4.912491e-07\n",
       "3    9.998289e-01  0.000171  1.743965e-10\n",
       "4    6.377019e-03  0.993623  6.990759e-08\n",
       "..            ...       ...           ...\n",
       "193  6.468146e-03  0.993532  1.171247e-07\n",
       "194  9.994338e-01  0.000566  2.796447e-10\n",
       "195  1.941034e-07  0.000874  9.991261e-01\n",
       "196  9.970651e-01  0.002935  9.256775e-14\n",
       "197  1.941034e-07  0.000874  9.991261e-01\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9646\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9646\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9646\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9747\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9697\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9646\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9747\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9747\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9646\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9646\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9646\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9747\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9646\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9646\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9646\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9646\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9646\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9747\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9646\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9697\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 207us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9646\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9747\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 369us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9646\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9747\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 337us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9697\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 581us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9697\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9646\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9646\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 714us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9646\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9646\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9646\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9646\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9646\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9646\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 716us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9747\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 628us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9697\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9697\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 294us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9747\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9697\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9697\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9646\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 304us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9646\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 548us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9697\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 409us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9646\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 757us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 470us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9646\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9697\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9697\n",
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9747\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9646\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9646\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9747\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9646\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 407us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9697\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 341us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9697\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9697\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9646\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9697\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9646\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9646\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 9.9364e-04 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9697\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 9.8511e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9646\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 9.9830e-04 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 9.4259e-04 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9697\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 9.2159e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9697\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 9.2536e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9697\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 9.1048e-04 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9697\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 9.0085e-04 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9646\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 9.1114e-04 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9747\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 8.6140e-04 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9646\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 8.8454e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9697\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 8.5867e-04 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9697\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 8.6651e-04 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9646\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 8.9222e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 8.2562e-04 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 9.4224e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 7.6609e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9697\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22061090e-03, 9.97779400e-01, 1.60585430e-09],\n",
       "       [6.46813900e-03, 9.93531760e-01, 1.17124640e-07],\n",
       "       [2.55695020e-02, 9.74430000e-01, 4.91249070e-07],\n",
       "       [9.99828930e-01, 1.71014570e-04, 1.74396480e-10],\n",
       "       [6.37701900e-03, 9.93622840e-01, 6.99075850e-08],\n",
       "       [2.22061090e-03, 9.97779400e-01, 1.60585430e-09],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99816000e-01, 1.81194740e-04, 2.90974530e-06],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.88741800e-01, 1.12580920e-02, 1.38097720e-07],\n",
       "       [9.97488600e-01, 2.51024980e-03, 1.09917700e-06],\n",
       "       [9.89710750e-01, 1.02892240e-02, 7.03940060e-09],\n",
       "       [9.99883060e-01, 1.16935730e-04, 1.54633320e-10],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99993900e-01, 6.09301300e-06, 2.94204860e-09],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.22061090e-03, 9.97779400e-01, 1.60585430e-09],\n",
       "       [9.99201950e-01, 7.98092800e-04, 4.48166140e-10],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [8.42817070e-04, 9.99156830e-01, 3.13717800e-07],\n",
       "       [8.39046900e-04, 9.99161000e-01, 4.86217250e-08],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [6.34329850e-06, 9.99993700e-01, 3.35203300e-12],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.91570300e-05, 9.99679100e-01, 2.21765430e-04],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [3.02213150e-02, 9.69761100e-01, 1.76203500e-05],\n",
       "       [9.05533160e-05, 9.99908900e-01, 5.11296500e-07],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [3.02213150e-02, 9.69761100e-01, 1.76203500e-05],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [6.37701900e-03, 9.93622840e-01, 6.99075850e-08],\n",
       "       [4.36574870e-03, 9.95634260e-01, 2.82759000e-08],\n",
       "       [8.39046900e-04, 9.99161000e-01, 4.86217250e-08],\n",
       "       [9.98675900e-01, 1.32407930e-03, 6.41408800e-14],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.99999900e-01, 9.49171400e-08, 1.39658870e-10],\n",
       "       [9.97004700e-01, 2.99535270e-03, 2.80800470e-09],\n",
       "       [1.08974230e-04, 9.95581000e-01, 4.31011300e-03],\n",
       "       [7.61729600e-03, 9.89514230e-01, 2.86844020e-03],\n",
       "       [6.46813900e-03, 9.93531760e-01, 1.17124640e-07],\n",
       "       [9.84857800e-01, 1.51422590e-02, 2.31785680e-09],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [1.00388825e-02, 9.89961150e-01, 1.63106400e-09],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [9.97756200e-01, 2.24381570e-03, 7.82331200e-12],\n",
       "       [9.94077200e-01, 5.92280920e-03, 3.95939440e-13],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [3.02213150e-02, 9.69761100e-01, 1.76203500e-05],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [2.47834700e-04, 9.99752100e-01, 1.34355655e-08],\n",
       "       [7.27003600e-02, 9.27299560e-01, 6.63262300e-09],\n",
       "       [9.99989150e-01, 1.08135360e-05, 4.81089200e-09],\n",
       "       [9.99965670e-01, 3.43769640e-05, 1.16029760e-10],\n",
       "       [9.99785000e-01, 2.14951050e-04, 1.40602170e-10],\n",
       "       [1.73991320e-03, 9.98260100e-01, 5.20429300e-09],\n",
       "       [3.90365170e-04, 9.99609400e-01, 2.72701800e-07],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [2.86941170e-02, 9.71305850e-01, 1.76058260e-12],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.99979600e-01, 2.03870260e-05, 7.46295460e-11],\n",
       "       [9.90195600e-01, 9.80443200e-03, 9.97204300e-09],\n",
       "       [3.90365170e-04, 9.99609400e-01, 2.72701800e-07],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.87827900e-01, 1.21721210e-02, 5.13706400e-13],\n",
       "       [5.08186300e-01, 4.91813500e-01, 1.09857910e-07],\n",
       "       [9.05533160e-05, 9.99908900e-01, 5.11296500e-07],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99984500e-01, 1.54456900e-05, 7.08080700e-11],\n",
       "       [1.00388825e-02, 9.89961150e-01, 1.63106400e-09],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.91570300e-05, 9.99679100e-01, 2.21765430e-04],\n",
       "       [9.75127800e-03, 9.90248740e-01, 2.38509830e-08],\n",
       "       [9.98776500e-01, 1.22354440e-03, 5.30595100e-08],\n",
       "       [2.07899400e-01, 7.92092740e-01, 7.80094600e-06],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [2.90798220e-01, 7.09192160e-01, 9.58793500e-06],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [9.99056640e-01, 9.43382850e-04, 4.38924800e-09],\n",
       "       [9.99997260e-01, 2.70977380e-06, 4.24789810e-10],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [9.99992700e-01, 7.30555670e-06, 3.59948870e-09],\n",
       "       [9.97260800e-01, 2.73918430e-03, 2.17144200e-13],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [4.36574870e-03, 9.95634260e-01, 2.82759000e-08],\n",
       "       [4.36574870e-03, 9.95634260e-01, 2.82759000e-08],\n",
       "       [2.22061090e-03, 9.97779400e-01, 1.60585430e-09],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [9.96418830e-01, 3.58122500e-03, 9.71327000e-15],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99967700e-01, 3.23036600e-05, 9.65234350e-11],\n",
       "       [9.99866370e-01, 1.33611230e-04, 1.76916480e-10],\n",
       "       [2.22061090e-03, 9.97779400e-01, 1.60585430e-09],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [7.61729600e-03, 9.89514230e-01, 2.86844020e-03],\n",
       "       [1.00388825e-02, 9.89961150e-01, 1.63106400e-09],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.99990600e-01, 9.42183100e-06, 2.02626110e-11],\n",
       "       [3.90365170e-04, 9.99609400e-01, 2.72701800e-07],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [4.88586280e-01, 5.11413750e-01, 1.35585890e-12],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [6.37701900e-03, 9.93622840e-01, 6.99075850e-08],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [6.37701900e-03, 9.93622840e-01, 6.99075850e-08],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99993560e-01, 6.45778200e-06, 8.65642400e-11],\n",
       "       [9.74467800e-01, 2.55322140e-02, 2.46732080e-12],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [4.59250450e-01, 5.40747640e-01, 1.93997020e-06],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [9.15133240e-01, 8.48613460e-02, 5.50085630e-06],\n",
       "       [8.44594100e-06, 9.99991540e-01, 1.32690110e-10],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99999500e-01, 4.23138540e-07, 6.59927700e-12],\n",
       "       [9.81955900e-03, 9.90180500e-01, 5.13951600e-09],\n",
       "       [9.99325160e-01, 6.74845600e-04, 4.56012480e-10],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.36574870e-03, 9.95634260e-01, 2.82759000e-08],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [9.99572460e-01, 4.27485680e-04, 5.67952040e-09],\n",
       "       [9.99433800e-01, 5.66189700e-04, 2.79644170e-10],\n",
       "       [9.75127800e-03, 9.90248740e-01, 2.38509830e-08],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [2.31427480e-02, 9.76849400e-01, 7.96584600e-06],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99972460e-01, 2.75835250e-05, 7.02673800e-09],\n",
       "       [9.83159300e-01, 1.68407700e-02, 1.57395090e-12],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99899600e-01, 1.00393460e-04, 1.49909110e-10],\n",
       "       [2.49343200e-03, 9.97506560e-01, 1.00456100e-12],\n",
       "       [2.55695020e-02, 9.74430000e-01, 4.91249070e-07],\n",
       "       [9.98355700e-01, 1.64425680e-03, 3.36031040e-10],\n",
       "       [9.99989030e-01, 1.09114090e-05, 4.73771300e-10],\n",
       "       [9.97138600e-01, 2.86133380e-03, 6.64564650e-08],\n",
       "       [1.36946110e-02, 9.85878100e-01, 4.27347500e-04],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [6.93078150e-04, 9.99306900e-01, 1.71147170e-09],\n",
       "       [1.08974230e-04, 9.95581000e-01, 4.31011300e-03],\n",
       "       [6.37701900e-03, 9.93622840e-01, 6.99075850e-08],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.92573300e-04, 8.61414300e-04, 9.98646100e-01],\n",
       "       [8.97325100e-01, 1.01648300e-01, 1.02661970e-03],\n",
       "       [8.39046900e-04, 9.99161000e-01, 4.86217250e-08],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [8.42817070e-04, 9.99156830e-01, 3.13717800e-07],\n",
       "       [9.97166930e-01, 2.83301970e-03, 6.45595700e-14],\n",
       "       [1.38873320e-02, 9.86112650e-01, 2.54098940e-09],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [9.95857800e-01, 4.14226860e-03, 4.44941780e-10],\n",
       "       [1.36946110e-02, 9.85878100e-01, 4.27347500e-04],\n",
       "       [1.43715570e-04, 9.99855040e-01, 1.24890580e-06],\n",
       "       [6.56366470e-01, 3.43633100e-01, 5.03698630e-07],\n",
       "       [9.91570300e-05, 9.99679100e-01, 2.21765430e-04],\n",
       "       [8.42817070e-04, 9.99156830e-01, 3.13717800e-07],\n",
       "       [1.00388825e-02, 9.89961150e-01, 1.63106400e-09],\n",
       "       [9.99973060e-01, 2.68899440e-05, 2.81759400e-10],\n",
       "       [9.99518040e-01, 4.81941330e-04, 2.99183750e-13],\n",
       "       [9.93735250e-01, 6.26463350e-03, 8.99393400e-08],\n",
       "       [9.99999050e-01, 1.00299030e-06, 9.16440900e-11],\n",
       "       [1.94103050e-07, 8.73678360e-04, 9.99126140e-01],\n",
       "       [4.36574870e-03, 9.95634260e-01, 2.82759000e-08],\n",
       "       [2.86941170e-02, 9.71305850e-01, 1.76058260e-12],\n",
       "       [8.42817070e-04, 9.99156830e-01, 3.13717800e-07],\n",
       "       [9.99228500e-01, 7.71492000e-04, 4.02275000e-09],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99974250e-01, 2.57455120e-05, 3.16631080e-09],\n",
       "       [9.99981050e-01, 1.89891100e-05, 7.16029900e-15],\n",
       "       [9.99045670e-01, 9.54359300e-04, 1.92492360e-09],\n",
       "       [9.99900340e-01, 9.95989600e-05, 1.29760100e-10],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [9.99433800e-01, 5.66189700e-04, 2.79644170e-10],\n",
       "       [2.61737020e-05, 2.23427410e-05, 9.99951500e-01],\n",
       "       [4.92572400e-04, 8.61413500e-04, 9.98646100e-01],\n",
       "       [6.46814560e-03, 9.93531760e-01, 1.17124750e-07],\n",
       "       [9.99433800e-01, 5.66189400e-04, 2.79644700e-10],\n",
       "       [1.94103420e-07, 8.73678800e-04, 9.99126140e-01],\n",
       "       [9.97065100e-01, 2.93489870e-03, 9.25677500e-14],\n",
       "       [1.94103420e-07, 8.73678800e-04, 9.99126140e-01]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970156106519742"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970156106519742"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964512549739822"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017448573181583576"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964512549739822"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017448573181583576"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 97.60%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.009698407745857654\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 100.00%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 3.201843e-05\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0      NRS241     1\n",
       "1      NRS148     2\n",
       "2      NRS255     1\n",
       "3      NRS214     0\n",
       "4      NRS148     2\n",
       "..        ...   ...\n",
       "193  CFBRSa30     0\n",
       "194    NRS266     1\n",
       "195    SR4152     0\n",
       "196    NRS109     2\n",
       "197       115     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 1ms/step - loss: 4.1172 - accuracy: 0.4545 - val_loss: 0.9910 - val_accuracy: 0.6970\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 336us/step - loss: 3.3673 - accuracy: 0.5801 - val_loss: 0.9944 - val_accuracy: 0.7172\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 3.4016 - accuracy: 0.6061 - val_loss: 0.8445 - val_accuracy: 0.7071\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 3.6975 - accuracy: 0.5801 - val_loss: 0.8747 - val_accuracy: 0.7121\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 3.1697 - accuracy: 0.6061 - val_loss: 0.8867 - val_accuracy: 0.6717\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 3.3122 - accuracy: 0.5996 - val_loss: 0.9408 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 332us/step - loss: 3.3610 - accuracy: 0.5714 - val_loss: 1.0616 - val_accuracy: 0.7121\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 3.1438 - accuracy: 0.6472 - val_loss: 1.0579 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 3.0341 - accuracy: 0.6147 - val_loss: 0.9402 - val_accuracy: 0.7576\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 2.8640 - accuracy: 0.6212 - val_loss: 1.1904 - val_accuracy: 0.7121\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 558us/step - loss: 2.5323 - accuracy: 0.6450 - val_loss: 1.0270 - val_accuracy: 0.6818\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 2.7654 - accuracy: 0.6190 - val_loss: 0.9797 - val_accuracy: 0.7424\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 2.4618 - accuracy: 0.6970 - val_loss: 0.9189 - val_accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 2.7291 - accuracy: 0.6926 - val_loss: 1.0031 - val_accuracy: 0.7626\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 3.1022 - accuracy: 0.6385 - val_loss: 0.8716 - val_accuracy: 0.8636\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 2.5186 - accuracy: 0.6883 - val_loss: 0.9018 - val_accuracy: 0.8030\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 2.8843 - accuracy: 0.6494 - val_loss: 0.9637 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 2.5136 - accuracy: 0.7251 - val_loss: 0.9091 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 2.6859 - accuracy: 0.6818 - val_loss: 0.9117 - val_accuracy: 0.7929\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 2.5076 - accuracy: 0.6840 - val_loss: 0.8120 - val_accuracy: 0.8636\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 446us/step - loss: 2.4700 - accuracy: 0.6861 - val_loss: 0.8597 - val_accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 518us/step - loss: 2.2017 - accuracy: 0.7229 - val_loss: 0.8304 - val_accuracy: 0.8535\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 2.3942 - accuracy: 0.7078 - val_loss: 0.8314 - val_accuracy: 0.8485\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 426us/step - loss: 2.3407 - accuracy: 0.7035 - val_loss: 0.8758 - val_accuracy: 0.8636\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 418us/step - loss: 2.3225 - accuracy: 0.7229 - val_loss: 0.7098 - val_accuracy: 0.8384\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 463us/step - loss: 1.9866 - accuracy: 0.7251 - val_loss: 0.5820 - val_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 501us/step - loss: 1.9262 - accuracy: 0.7554 - val_loss: 0.6110 - val_accuracy: 0.8485\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 260us/step - loss: 1.8783 - accuracy: 0.7273 - val_loss: 0.7190 - val_accuracy: 0.8838\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 1.9865 - accuracy: 0.7316 - val_loss: 0.5990 - val_accuracy: 0.8788\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 2.1120 - accuracy: 0.7056 - val_loss: 0.7553 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 2.2210 - accuracy: 0.7273 - val_loss: 0.5655 - val_accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 1.7700 - accuracy: 0.7338 - val_loss: 0.4701 - val_accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 1.7795 - accuracy: 0.6861 - val_loss: 0.6624 - val_accuracy: 0.8737\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 1.3848 - accuracy: 0.7662 - val_loss: 0.5199 - val_accuracy: 0.8990\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 1.8862 - accuracy: 0.7446 - val_loss: 0.5636 - val_accuracy: 0.8838\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 344us/step - loss: 1.8132 - accuracy: 0.7035 - val_loss: 0.6175 - val_accuracy: 0.8990\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 2.0522 - accuracy: 0.7251 - val_loss: 0.7278 - val_accuracy: 0.8737\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 1.7415 - accuracy: 0.7078 - val_loss: 0.5068 - val_accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 460us/step - loss: 1.6298 - accuracy: 0.7727 - val_loss: 0.5549 - val_accuracy: 0.9242\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 302us/step - loss: 1.5854 - accuracy: 0.7273 - val_loss: 0.5802 - val_accuracy: 0.9192\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 1.3974 - accuracy: 0.7641 - val_loss: 0.6421 - val_accuracy: 0.9040\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 195us/step - loss: 1.4469 - accuracy: 0.7749 - val_loss: 0.5765 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 183us/step - loss: 1.6027 - accuracy: 0.7532 - val_loss: 0.5741 - val_accuracy: 0.9293\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 1.4460 - accuracy: 0.7446 - val_loss: 0.6673 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 180us/step - loss: 1.4764 - accuracy: 0.7381 - val_loss: 0.6223 - val_accuracy: 0.8939\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 1.4127 - accuracy: 0.7338 - val_loss: 0.6740 - val_accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 1.2759 - accuracy: 0.7814 - val_loss: 0.6704 - val_accuracy: 0.9293\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 1.2268 - accuracy: 0.7576 - val_loss: 0.6153 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 1.3998 - accuracy: 0.7554 - val_loss: 0.7094 - val_accuracy: 0.9242\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 1.1163 - accuracy: 0.8095 - val_loss: 0.7907 - val_accuracy: 0.9343\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.0559 - accuracy: 0.8139 - val_loss: 0.5998 - val_accuracy: 0.9495\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 1.0233 - accuracy: 0.7965 - val_loss: 0.6561 - val_accuracy: 0.9545\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.2274 - accuracy: 0.7749 - val_loss: 0.9255 - val_accuracy: 0.9192\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 1.2860 - accuracy: 0.7316 - val_loss: 0.7114 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 1.1220 - accuracy: 0.7554 - val_loss: 0.6604 - val_accuracy: 0.9394\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 1.0261 - accuracy: 0.7684 - val_loss: 0.6571 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 202us/step - loss: 0.9570 - accuracy: 0.8182 - val_loss: 0.6222 - val_accuracy: 0.9545\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.9745 - accuracy: 0.7792 - val_loss: 0.8407 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 184us/step - loss: 0.9554 - accuracy: 0.7597 - val_loss: 0.7853 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 1.0205 - accuracy: 0.7771 - val_loss: 0.6290 - val_accuracy: 0.9545\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 1.0046 - accuracy: 0.7792 - val_loss: 0.8076 - val_accuracy: 0.8838\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.9394 - accuracy: 0.7792 - val_loss: 0.7223 - val_accuracy: 0.9495\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.9490 - accuracy: 0.7749 - val_loss: 0.6824 - val_accuracy: 0.9545\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.8743 - accuracy: 0.7532 - val_loss: 0.8902 - val_accuracy: 0.9293\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.9525 - accuracy: 0.7771 - val_loss: 0.6238 - val_accuracy: 0.9040\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 1.0121 - accuracy: 0.7273 - val_loss: 0.6182 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.7526 - accuracy: 0.7792 - val_loss: 0.6292 - val_accuracy: 0.9646\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 0.8120 - accuracy: 0.7835 - val_loss: 0.8918 - val_accuracy: 0.9343\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 452us/step - loss: 1.1797 - accuracy: 0.7316 - val_loss: 0.9663 - val_accuracy: 0.9293\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.7927 - accuracy: 0.7792 - val_loss: 0.7151 - val_accuracy: 0.9293\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.9539 - accuracy: 0.7792 - val_loss: 0.8658 - val_accuracy: 0.9394\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.8604 - accuracy: 0.7619 - val_loss: 0.7966 - val_accuracy: 0.9394\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.7349 - accuracy: 0.7749 - val_loss: 0.7000 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.8079 - accuracy: 0.7835 - val_loss: 0.6745 - val_accuracy: 0.9545\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.6675 - accuracy: 0.8030 - val_loss: 0.6572 - val_accuracy: 0.9596\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.7727 - accuracy: 0.7749 - val_loss: 0.7122 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.7556 - accuracy: 0.7944 - val_loss: 1.0384 - val_accuracy: 0.9242\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.8663 - accuracy: 0.7749 - val_loss: 0.5526 - val_accuracy: 0.9697\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.7017 - accuracy: 0.7965 - val_loss: 0.8299 - val_accuracy: 0.9343\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.6150 - accuracy: 0.7900 - val_loss: 0.6299 - val_accuracy: 0.9697\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.7369 - accuracy: 0.7727 - val_loss: 0.6143 - val_accuracy: 0.9394\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.7505 - accuracy: 0.8030 - val_loss: 0.6067 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.7616 - accuracy: 0.7987 - val_loss: 0.7856 - val_accuracy: 0.9495\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.6616 - accuracy: 0.7706 - val_loss: 0.8080 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.7835 - accuracy: 0.7619 - val_loss: 0.8684 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 349us/step - loss: 0.6735 - accuracy: 0.7684 - val_loss: 0.5480 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 459us/step - loss: 0.6263 - accuracy: 0.7965 - val_loss: 0.6701 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.6417 - accuracy: 0.7814 - val_loss: 0.6600 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.5989 - accuracy: 0.7987 - val_loss: 0.4781 - val_accuracy: 0.9343\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.7718 - accuracy: 0.7727 - val_loss: 0.4228 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.6199 - accuracy: 0.7922 - val_loss: 0.7193 - val_accuracy: 0.9495\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.5031 - accuracy: 0.8182 - val_loss: 0.8452 - val_accuracy: 0.9394\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.6583 - accuracy: 0.7576 - val_loss: 0.7045 - val_accuracy: 0.9545\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.5965 - accuracy: 0.7879 - val_loss: 0.6954 - val_accuracy: 0.9545\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.6188 - accuracy: 0.7922 - val_loss: 0.7048 - val_accuracy: 0.9495\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.5732 - accuracy: 0.7532 - val_loss: 0.8440 - val_accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.6583 - accuracy: 0.7576 - val_loss: 0.7665 - val_accuracy: 0.9495\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.5159 - accuracy: 0.7922 - val_loss: 0.6217 - val_accuracy: 0.9545\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.5845 - accuracy: 0.7619 - val_loss: 0.5372 - val_accuracy: 0.9596\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.5796 - accuracy: 0.7771 - val_loss: 0.6500 - val_accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3da6dc18>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 268us/step\n",
      "over-sampling test accuracy: 96.46%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 1,\n",
       "       2, 2, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 2,\n",
       "       0, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2, 0, 1,\n",
       "       2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 2, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 0, 1, 0, 2, 1,\n",
       "       1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2,\n",
       "       0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 1, 1, 2,\n",
       "       2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CFBRSa30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0      NRS241     1     1\n",
       "1      NRS148     2     2\n",
       "2      NRS255     1     1\n",
       "3      NRS214     0     0\n",
       "4      NRS148     2     2\n",
       "..        ...   ...   ...\n",
       "193  CFBRSa30     0     0\n",
       "194    NRS266     1     1\n",
       "195    SR4152     0     0\n",
       "196    NRS109     2     2\n",
       "197       115     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.643635e-04</td>\n",
       "      <td>9.998355e-01</td>\n",
       "      <td>1.573355e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.189490e-08</td>\n",
       "      <td>7.780775e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.533502e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.759057e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.952921e-10</td>\n",
       "      <td>1.368696e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.189490e-08</td>\n",
       "      <td>7.780775e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.333206e-14</td>\n",
       "      <td>7.526777e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.031151e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.025762e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.780141e-11</td>\n",
       "      <td>3.428157e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.000139e-09</td>\n",
       "      <td>5.614254e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.068928e-03</td>\n",
       "      <td>9.921145e-01</td>\n",
       "      <td>5.816648e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.643635e-04  9.998355e-01  1.573355e-07\n",
       "1    1.189490e-08  7.780775e-09  1.000000e+00\n",
       "2    4.533502e-09  1.000000e+00  2.759057e-11\n",
       "3    1.000000e+00  2.952921e-10  1.368696e-10\n",
       "4    1.189490e-08  7.780775e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "193  1.000000e+00  1.333206e-14  7.526777e-15\n",
       "194  2.031151e-08  1.000000e+00  3.025762e-10\n",
       "195  1.000000e+00  1.780141e-11  3.428157e-12\n",
       "196  9.000139e-09  5.614254e-09  1.000000e+00\n",
       "197  2.068928e-03  9.921145e-01  5.816648e-03\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.4620 - accuracy: 0.7857 - val_loss: 0.5468 - val_accuracy: 0.9697\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.4935 - accuracy: 0.7792 - val_loss: 0.6729 - val_accuracy: 0.9596\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.5128 - accuracy: 0.8052 - val_loss: 0.6165 - val_accuracy: 0.9596\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.4904 - accuracy: 0.7987 - val_loss: 0.6004 - val_accuracy: 0.9596\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.6076 - accuracy: 0.7597 - val_loss: 0.6550 - val_accuracy: 0.9646\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.4876 - accuracy: 0.7857 - val_loss: 0.6224 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.4549 - accuracy: 0.8009 - val_loss: 0.5626 - val_accuracy: 0.9646\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.5644 - accuracy: 0.7857 - val_loss: 0.5559 - val_accuracy: 0.9697\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.4205 - accuracy: 0.8095 - val_loss: 0.6840 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.4595 - accuracy: 0.8268 - val_loss: 0.8172 - val_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.6270 - accuracy: 0.7944 - val_loss: 0.7475 - val_accuracy: 0.9495\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.5400 - accuracy: 0.8095 - val_loss: 0.5060 - val_accuracy: 0.9697\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4885 - accuracy: 0.8074 - val_loss: 0.5433 - val_accuracy: 0.9495\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.7727 - accuracy: 0.7706 - val_loss: 0.6322 - val_accuracy: 0.9646\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.5213 - accuracy: 0.7944 - val_loss: 0.8847 - val_accuracy: 0.9394\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.5876 - accuracy: 0.8030 - val_loss: 0.5929 - val_accuracy: 0.9697\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.5286 - accuracy: 0.7641 - val_loss: 0.6592 - val_accuracy: 0.9545\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.4723 - accuracy: 0.8247 - val_loss: 0.5816 - val_accuracy: 0.9697\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5779 - accuracy: 0.7944 - val_loss: 0.5094 - val_accuracy: 0.9697\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.4220 - accuracy: 0.8203 - val_loss: 0.5796 - val_accuracy: 0.9697\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.4536 - accuracy: 0.7835 - val_loss: 0.6237 - val_accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.4451 - accuracy: 0.7835 - val_loss: 0.6641 - val_accuracy: 0.9495\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.4173 - accuracy: 0.7922 - val_loss: 0.5615 - val_accuracy: 0.9697\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4692 - accuracy: 0.8009 - val_loss: 0.6480 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4144 - accuracy: 0.8074 - val_loss: 0.5415 - val_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.6099 - accuracy: 0.7727 - val_loss: 1.2056 - val_accuracy: 0.9192\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5901 - accuracy: 0.7900 - val_loss: 0.6708 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.6348 - accuracy: 0.7944 - val_loss: 0.5595 - val_accuracy: 0.9697\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.5015 - accuracy: 0.8333 - val_loss: 0.6682 - val_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 246us/step - loss: 0.4371 - accuracy: 0.8095 - val_loss: 0.6370 - val_accuracy: 0.9596\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.4462 - accuracy: 0.8030 - val_loss: 0.4456 - val_accuracy: 0.9646\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.3866 - accuracy: 0.7987 - val_loss: 0.5458 - val_accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.4556 - accuracy: 0.8052 - val_loss: 0.5150 - val_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4715 - accuracy: 0.8030 - val_loss: 0.6861 - val_accuracy: 0.9545\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.4546 - accuracy: 0.7576 - val_loss: 0.6307 - val_accuracy: 0.9596\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5512 - accuracy: 0.7900 - val_loss: 0.4355 - val_accuracy: 0.9798\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4155 - accuracy: 0.8117 - val_loss: 0.5458 - val_accuracy: 0.9596\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.4860 - accuracy: 0.7944 - val_loss: 0.5583 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4709 - accuracy: 0.8052 - val_loss: 0.6053 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.4240 - accuracy: 0.7771 - val_loss: 0.5447 - val_accuracy: 0.9697\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4217 - accuracy: 0.8052 - val_loss: 0.5695 - val_accuracy: 0.9646\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.4302 - accuracy: 0.7857 - val_loss: 0.4359 - val_accuracy: 0.9596\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.4652 - accuracy: 0.8182 - val_loss: 0.7756 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.4204 - accuracy: 0.7835 - val_loss: 0.5257 - val_accuracy: 0.9747\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.4614 - accuracy: 0.7944 - val_loss: 0.5821 - val_accuracy: 0.9596\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.3569 - accuracy: 0.8160 - val_loss: 0.4941 - val_accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.3865 - accuracy: 0.8074 - val_loss: 0.4960 - val_accuracy: 0.9697\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4022 - accuracy: 0.8052 - val_loss: 0.5645 - val_accuracy: 0.9697\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.4658 - accuracy: 0.7944 - val_loss: 0.8633 - val_accuracy: 0.9394\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 231us/step - loss: 0.3978 - accuracy: 0.8009 - val_loss: 0.4695 - val_accuracy: 0.9697\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.3744 - accuracy: 0.8268 - val_loss: 0.6376 - val_accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.4938 - accuracy: 0.7814 - val_loss: 0.8105 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.4843 - accuracy: 0.7749 - val_loss: 0.6090 - val_accuracy: 0.9697\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.3975 - accuracy: 0.8203 - val_loss: 0.6065 - val_accuracy: 0.9646\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4041 - accuracy: 0.8225 - val_loss: 0.6792 - val_accuracy: 0.9545\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.4605 - accuracy: 0.7965 - val_loss: 0.5711 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.5319 - accuracy: 0.7965 - val_loss: 0.6154 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.5877 - accuracy: 0.8160 - val_loss: 0.9649 - val_accuracy: 0.9394\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5307 - accuracy: 0.7965 - val_loss: 0.6239 - val_accuracy: 0.9545\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.4545 - accuracy: 0.7879 - val_loss: 0.4494 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.4582 - accuracy: 0.7900 - val_loss: 0.6009 - val_accuracy: 0.9646\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.4126 - accuracy: 0.7965 - val_loss: 0.5013 - val_accuracy: 0.9646\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.3210 - accuracy: 0.8355 - val_loss: 0.4409 - val_accuracy: 0.9697\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.4071 - accuracy: 0.7944 - val_loss: 0.5198 - val_accuracy: 0.9747\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4253 - accuracy: 0.7662 - val_loss: 0.5307 - val_accuracy: 0.9646\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.4447 - accuracy: 0.7792 - val_loss: 0.4671 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.3768 - accuracy: 0.8074 - val_loss: 0.5721 - val_accuracy: 0.9545\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.3971 - accuracy: 0.8268 - val_loss: 0.5829 - val_accuracy: 0.9646\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.3619 - accuracy: 0.7965 - val_loss: 0.6403 - val_accuracy: 0.9596\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.4139 - accuracy: 0.7987 - val_loss: 0.5686 - val_accuracy: 0.9646\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 287us/step - loss: 0.3512 - accuracy: 0.8095 - val_loss: 0.5914 - val_accuracy: 0.9646\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.4430 - accuracy: 0.7965 - val_loss: 0.4677 - val_accuracy: 0.9747\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.4809 - accuracy: 0.8095 - val_loss: 0.8405 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.4236 - accuracy: 0.7684 - val_loss: 0.6063 - val_accuracy: 0.9596\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.4315 - accuracy: 0.8139 - val_loss: 0.4453 - val_accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 0.4188 - accuracy: 0.7749 - val_loss: 0.5163 - val_accuracy: 0.9596\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.3632 - accuracy: 0.8030 - val_loss: 0.4773 - val_accuracy: 0.9646\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4670 - accuracy: 0.7987 - val_loss: 0.4563 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.3568 - accuracy: 0.8160 - val_loss: 0.7772 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.5793 - accuracy: 0.7641 - val_loss: 0.7363 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.5419 - accuracy: 0.7922 - val_loss: 0.6162 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.3718 - accuracy: 0.8139 - val_loss: 0.5784 - val_accuracy: 0.9596\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.4585 - accuracy: 0.7771 - val_loss: 0.8667 - val_accuracy: 0.9394\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.75 - 0s 212us/step - loss: 0.5643 - accuracy: 0.7576 - val_loss: 0.5757 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4730 - accuracy: 0.7879 - val_loss: 0.6335 - val_accuracy: 0.9596\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.4220 - accuracy: 0.7684 - val_loss: 0.6044 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.4431 - accuracy: 0.8117 - val_loss: 0.4829 - val_accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.3480 - accuracy: 0.8117 - val_loss: 0.6939 - val_accuracy: 0.9495\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4224 - accuracy: 0.7684 - val_loss: 0.3831 - val_accuracy: 0.9798\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.5629 - accuracy: 0.7684 - val_loss: 0.3962 - val_accuracy: 0.9747\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 523us/step - loss: 0.5019 - accuracy: 0.8074 - val_loss: 0.7236 - val_accuracy: 0.9646\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 314us/step - loss: 0.5431 - accuracy: 0.8009 - val_loss: 0.7010 - val_accuracy: 0.9646\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.4913 - accuracy: 0.7900 - val_loss: 0.7617 - val_accuracy: 0.9495\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.5107 - accuracy: 0.7965 - val_loss: 0.7138 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.5958 - accuracy: 0.7706 - val_loss: 0.7547 - val_accuracy: 0.9495\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.4856 - accuracy: 0.7965 - val_loss: 0.5662 - val_accuracy: 0.9646\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.4569 - accuracy: 0.8139 - val_loss: 0.6754 - val_accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.3965 - accuracy: 0.8074 - val_loss: 0.7603 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.4287 - accuracy: 0.8009 - val_loss: 0.5443 - val_accuracy: 0.9596\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.4438 - accuracy: 0.8290 - val_loss: 0.6332 - val_accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.68%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.64363530e-04, 9.99835500e-01, 1.57335550e-07],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [4.53350250e-09, 1.00000000e+00, 2.75905690e-11],\n",
       "       [1.00000000e+00, 2.95292100e-10, 1.36869630e-10],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [8.61057800e-09, 1.00000000e+00, 3.41442740e-12],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.12303155e-07, 9.99999900e-01, 4.11950300e-09],\n",
       "       [2.32923520e-05, 9.99976750e-01, 3.82343800e-11],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.78272530e-07, 9.99999900e-01, 8.30041500e-09],\n",
       "       [1.00000000e+00, 1.82837600e-22, 1.54079860e-22],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [2.35751900e-07, 9.99999760e-01, 1.25028200e-08],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [2.35751900e-07, 9.99999760e-01, 1.25028200e-08],\n",
       "       [8.61057800e-09, 1.00000000e+00, 3.41442740e-12],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [6.56439100e-09, 1.00000000e+00, 5.03330850e-11],\n",
       "       [2.54499090e-09, 1.00000000e+00, 1.08023350e-11],\n",
       "       [9.99999760e-01, 2.26834350e-07, 5.13637050e-11],\n",
       "       [1.09292150e-06, 9.99998800e-01, 1.18051390e-07],\n",
       "       [1.00000000e+00, 6.36814000e-14, 3.30448940e-15],\n",
       "       [1.00000000e+00, 1.87248360e-23, 1.66217170e-23],\n",
       "       [1.00000000e+00, 2.74826360e-11, 1.33487230e-11],\n",
       "       [1.00000000e+00, 2.77890570e-10, 1.36501960e-11],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.68366400e-12, 2.21550380e-13],\n",
       "       [1.00000000e+00, 1.48303580e-14, 1.12103250e-15],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.13647500e-24, 4.69615720e-24],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.94713770e-13, 1.56533840e-13],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.64729300e-19, 1.08168410e-20],\n",
       "       [5.47472300e-08, 1.00000000e+00, 1.38007660e-09],\n",
       "       [1.09292150e-06, 9.99998800e-01, 1.18051390e-07],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.48303580e-14, 1.12103250e-15],\n",
       "       [1.00000000e+00, 1.44887000e-09, 2.30217930e-12],\n",
       "       [5.47472300e-08, 1.00000000e+00, 1.38007660e-09],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.91976540e-18, 4.58476060e-18],\n",
       "       [1.00000000e+00, 4.92379340e-09, 1.28667150e-10],\n",
       "       [1.58464960e-06, 9.99998200e-01, 1.99171050e-07],\n",
       "       [1.06704775e-07, 9.99999900e-01, 3.81102170e-09],\n",
       "       [1.00000000e+00, 2.47494450e-18, 5.68013240e-19],\n",
       "       [2.28636040e-08, 1.00000000e+00, 3.63713920e-10],\n",
       "       [1.00000000e+00, 6.60337350e-23, 5.69559150e-23],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.42367200e-12, 2.07783940e-12],\n",
       "       [6.56439100e-09, 1.00000000e+00, 5.03330850e-11],\n",
       "       [4.76698430e-08, 1.00000000e+00, 1.11788010e-09],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.37280500e-16, 3.23148760e-16],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.48303580e-14, 1.12103250e-15],\n",
       "       [4.53350250e-09, 1.00000000e+00, 2.75905690e-11],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.27624780e-09, 1.00000000e+00, 3.52116700e-12],\n",
       "       [1.00000000e+00, 6.89789750e-16, 1.03836040e-16],\n",
       "       [1.00000000e+00, 1.03770760e-15, 2.54568800e-18],\n",
       "       [9.99869470e-01, 1.30468000e-04, 2.04534600e-09],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 9.10655800e-17, 2.62836240e-17],\n",
       "       [4.76698430e-08, 1.00000000e+00, 1.11788010e-09],\n",
       "       [5.12065020e-08, 1.00000000e+00, 1.24653840e-09],\n",
       "       [1.00000000e+00, 4.45495400e-11, 4.56398300e-12],\n",
       "       [1.00000000e+00, 8.67078400e-20, 2.80449800e-20],\n",
       "       [7.68005750e-07, 9.99999170e-01, 7.06063760e-08],\n",
       "       [1.00000000e+00, 1.66962280e-27, 1.47835680e-28],\n",
       "       [1.28400880e-06, 9.99998700e-01, 5.20529150e-08],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.14458780e-14, 8.89204700e-16],\n",
       "       [2.06892840e-03, 9.92114540e-01, 5.81664820e-03],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.64363530e-04, 9.99835500e-01, 1.57335550e-07],\n",
       "       [1.00000000e+00, 2.33217960e-12, 3.36361570e-15],\n",
       "       [2.06892840e-03, 9.92114540e-01, 5.81664820e-03],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.10136140e-18, 2.20570550e-20],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.12303155e-07, 9.99999900e-01, 4.11950300e-09],\n",
       "       [2.65263800e-09, 1.00000000e+00, 1.15541420e-11],\n",
       "       [1.00000000e+00, 1.32530710e-20, 1.01286640e-20],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [9.99995230e-01, 4.16931330e-06, 5.55604700e-07],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.60838680e-14, 2.40956900e-15],\n",
       "       [2.06892840e-03, 9.92114540e-01, 5.81664820e-03],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [9.99855500e-01, 1.44424060e-04, 2.61367400e-11],\n",
       "       [9.70135500e-09, 1.00000000e+00, 9.37453700e-11],\n",
       "       [1.35399090e-08, 1.00000000e+00, 1.59149320e-10],\n",
       "       [4.19836800e-06, 9.99995100e-01, 7.30477600e-07],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [1.64363530e-04, 9.99835500e-01, 1.57335550e-07],\n",
       "       [3.40877900e-01, 6.59120860e-01, 1.28868290e-06],\n",
       "       [2.28636040e-08, 1.00000000e+00, 3.63713920e-10],\n",
       "       [2.20173430e-08, 1.00000000e+00, 3.42996580e-10],\n",
       "       [1.00000000e+00, 3.11675130e-15, 1.81073160e-15],\n",
       "       [4.76698430e-08, 1.00000000e+00, 1.11788010e-09],\n",
       "       [2.90347880e-09, 1.00000000e+00, 1.33804090e-11],\n",
       "       [2.65263800e-09, 1.00000000e+00, 1.15541420e-11],\n",
       "       [1.12303155e-07, 9.99999900e-01, 4.11950300e-09],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [3.31136210e-03, 9.96688300e-01, 3.46164200e-07],\n",
       "       [9.70135500e-09, 1.00000000e+00, 9.37453700e-11],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [2.03115870e-08, 1.00000000e+00, 3.02576820e-10],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.42481800e-12, 9.03976800e-15],\n",
       "       [2.65263800e-09, 1.00000000e+00, 1.15541420e-11],\n",
       "       [1.00000000e+00, 8.49139650e-11, 2.02186360e-11],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.58464960e-06, 9.99998200e-01, 1.99171050e-07],\n",
       "       [4.53350250e-09, 1.00000000e+00, 2.75905690e-11],\n",
       "       [8.61057800e-09, 1.00000000e+00, 3.41442740e-12],\n",
       "       [2.90347880e-09, 1.00000000e+00, 1.33804090e-11],\n",
       "       [9.99967100e-01, 2.44042620e-05, 8.51264100e-06],\n",
       "       [6.07512300e-09, 1.00000000e+00, 4.43834760e-11],\n",
       "       [1.00000000e+00, 9.10655800e-17, 2.62836240e-17],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [9.99979600e-01, 2.03855290e-05, 4.37683700e-08],\n",
       "       [1.00000000e+00, 3.17511740e-10, 1.46958200e-10],\n",
       "       [5.47472300e-08, 1.00000000e+00, 1.38007660e-09],\n",
       "       [2.54499090e-09, 1.00000000e+00, 1.08023350e-11],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [9.99999900e-01, 1.37920680e-07, 5.66327680e-08],\n",
       "       [2.32923520e-05, 9.99976750e-01, 3.82343800e-11],\n",
       "       [1.00000000e+00, 1.09793970e-11, 2.18821550e-12],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [2.28636040e-08, 1.00000000e+00, 3.63713920e-10],\n",
       "       [8.61057800e-09, 1.00000000e+00, 3.41442740e-12],\n",
       "       [1.28400880e-06, 9.99998700e-01, 5.20529150e-08],\n",
       "       [6.07512300e-09, 1.00000000e+00, 4.43834760e-11],\n",
       "       [1.00000000e+00, 7.06080300e-16, 7.50460360e-18],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.09915400e-14, 2.80365080e-14],\n",
       "       [2.50669530e-05, 9.99967200e-01, 7.71555300e-06],\n",
       "       [1.00000000e+00, 2.10801700e-09, 9.39946500e-10],\n",
       "       [1.00000000e+00, 1.00319520e-13, 1.28374204e-14],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [5.83197100e-08, 1.00000000e+00, 1.51945730e-09],\n",
       "       [6.07512300e-09, 1.00000000e+00, 4.43834760e-11],\n",
       "       [5.47472300e-08, 1.00000000e+00, 1.38007660e-09],\n",
       "       [1.12303155e-07, 9.99999900e-01, 4.11950300e-09],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.70357600e-05, 9.99982950e-01, 1.92086700e-08],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.92266460e-16, 8.58341750e-18],\n",
       "       [2.20173430e-08, 1.00000000e+00, 3.42996580e-10],\n",
       "       [1.00000000e+00, 2.20127240e-08, 9.37177500e-09],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [4.76698430e-08, 1.00000000e+00, 1.11788010e-09],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.72360190e-08, 1.00000000e+00, 2.33463860e-10],\n",
       "       [4.26599400e-09, 1.00000000e+00, 2.49955580e-11],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.31489230e-03, 9.98685060e-01, 3.27284100e-10],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.13933070e-13, 3.23516320e-16],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [9.99999500e-01, 4.21619940e-07, 3.30689980e-13],\n",
       "       [3.85139740e-08, 3.12501850e-08, 9.99999900e-01],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [9.00012200e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [6.56439100e-09, 1.00000000e+00, 5.03330850e-11],\n",
       "       [6.56439100e-09, 1.00000000e+00, 5.03330850e-11],\n",
       "       [1.00000000e+00, 1.80202340e-13, 6.45705500e-15],\n",
       "       [1.18948990e-08, 7.78077500e-09, 1.00000000e+00],\n",
       "       [2.20173430e-08, 1.00000000e+00, 3.42996580e-10],\n",
       "       [1.00000000e+00, 1.18385230e-11, 3.85879240e-13],\n",
       "       [2.03115100e-08, 1.00000000e+00, 3.02576240e-10],\n",
       "       [1.00000000e+00, 1.33320620e-14, 7.52677700e-15],\n",
       "       [2.03115100e-08, 1.00000000e+00, 3.02576240e-10],\n",
       "       [1.00000000e+00, 1.78014130e-11, 3.42815730e-12],\n",
       "       [9.00013900e-09, 5.61425350e-09, 1.00000000e+00],\n",
       "       [2.06892840e-03, 9.92114540e-01, 5.81664820e-03]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908363942454853"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908363942454853"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS209     2\n",
       "1       NRS386     1\n",
       "2       NRS148     2\n",
       "3       NRS178     0\n",
       "4       NRS237     0\n",
       "..         ...   ...\n",
       "193     NRS209     2\n",
       "194     NRS002     0\n",
       "195     NRS109     2\n",
       "196  BCH-SA-03     1\n",
       "197  BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 828us/step - loss: 3.7536 - accuracy: 0.3918 - val_loss: 0.9904 - val_accuracy: 0.5152\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 3.6162 - accuracy: 0.5281 - val_loss: 0.9305 - val_accuracy: 0.6869\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 3.8724 - accuracy: 0.5974 - val_loss: 0.9222 - val_accuracy: 0.6919\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 3.8182 - accuracy: 0.6082 - val_loss: 0.8911 - val_accuracy: 0.6768\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 343us/step - loss: 3.2671 - accuracy: 0.6255 - val_loss: 0.8770 - val_accuracy: 0.7323\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 3.4186 - accuracy: 0.6558 - val_loss: 0.7635 - val_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 3.5538 - accuracy: 0.6450 - val_loss: 0.7460 - val_accuracy: 0.8081\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 459us/step - loss: 3.5903 - accuracy: 0.6580 - val_loss: 0.7450 - val_accuracy: 0.8232\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 506us/step - loss: 3.0367 - accuracy: 0.6926 - val_loss: 0.8440 - val_accuracy: 0.8081\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 3.0603 - accuracy: 0.6948 - val_loss: 0.8562 - val_accuracy: 0.8384\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 3.1444 - accuracy: 0.6775 - val_loss: 1.0523 - val_accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 3.0798 - accuracy: 0.6688 - val_loss: 1.0281 - val_accuracy: 0.8535\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 2.6248 - accuracy: 0.7165 - val_loss: 0.9860 - val_accuracy: 0.8384\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 2.8673 - accuracy: 0.6797 - val_loss: 0.9867 - val_accuracy: 0.8485\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 520us/step - loss: 2.3234 - accuracy: 0.7143 - val_loss: 1.0456 - val_accuracy: 0.8434\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 2.3756 - accuracy: 0.7078 - val_loss: 1.1325 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 2.3702 - accuracy: 0.6926 - val_loss: 1.2307 - val_accuracy: 0.8182\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 2.2765 - accuracy: 0.7208 - val_loss: 1.0048 - val_accuracy: 0.8889\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 2.2839 - accuracy: 0.7186 - val_loss: 1.1749 - val_accuracy: 0.8737\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 2.3106 - accuracy: 0.6991 - val_loss: 1.4558 - val_accuracy: 0.7879\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 2.2292 - accuracy: 0.7186 - val_loss: 1.3437 - val_accuracy: 0.8485\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 2.0036 - accuracy: 0.7186 - val_loss: 1.3092 - val_accuracy: 0.8838\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 2.0025 - accuracy: 0.7229 - val_loss: 1.1172 - val_accuracy: 0.8788\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 424us/step - loss: 1.7329 - accuracy: 0.7489 - val_loss: 1.0772 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 1.9066 - accuracy: 0.7100 - val_loss: 1.3278 - val_accuracy: 0.8384\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.8523 - accuracy: 0.7229 - val_loss: 1.0336 - val_accuracy: 0.8384\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.7548 - accuracy: 0.7186 - val_loss: 1.1054 - val_accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 1.7737 - accuracy: 0.7403 - val_loss: 0.9793 - val_accuracy: 0.8535\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 1.5752 - accuracy: 0.7489 - val_loss: 1.0313 - val_accuracy: 0.8485\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 488us/step - loss: 2.0059 - accuracy: 0.7056 - val_loss: 1.0841 - val_accuracy: 0.8636\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.5417 - accuracy: 0.7338 - val_loss: 0.9909 - val_accuracy: 0.8788\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 1.3677 - accuracy: 0.7727 - val_loss: 0.9799 - val_accuracy: 0.8737\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 1.3891 - accuracy: 0.7424 - val_loss: 1.0214 - val_accuracy: 0.8889\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 1.4836 - accuracy: 0.7186 - val_loss: 1.0180 - val_accuracy: 0.8939\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 1.3009 - accuracy: 0.7446 - val_loss: 0.8338 - val_accuracy: 0.8939\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 1.4199 - accuracy: 0.7424 - val_loss: 1.0124 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 1.3024 - accuracy: 0.7338 - val_loss: 0.9565 - val_accuracy: 0.9040\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 1.3529 - accuracy: 0.7597 - val_loss: 0.8823 - val_accuracy: 0.8687\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 1.0034 - accuracy: 0.8117 - val_loss: 0.8134 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 1.4073 - accuracy: 0.7706 - val_loss: 0.9298 - val_accuracy: 0.8838\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.1260 - accuracy: 0.7576 - val_loss: 0.7522 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 1.0886 - accuracy: 0.7814 - val_loss: 0.7434 - val_accuracy: 0.8535\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 1.2370 - accuracy: 0.7446 - val_loss: 0.7897 - val_accuracy: 0.8939\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 1.2962 - accuracy: 0.7424 - val_loss: 0.8415 - val_accuracy: 0.9343\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 1.1013 - accuracy: 0.7771 - val_loss: 0.8157 - val_accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 1.0513 - accuracy: 0.7641 - val_loss: 0.7153 - val_accuracy: 0.8939\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.1713 - accuracy: 0.7684 - val_loss: 0.7762 - val_accuracy: 0.8838\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 1.0461 - accuracy: 0.7706 - val_loss: 0.7577 - val_accuracy: 0.9394\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 221us/step - loss: 0.9928 - accuracy: 0.7554 - val_loss: 0.7748 - val_accuracy: 0.9343\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 1.0934 - accuracy: 0.7706 - val_loss: 0.7225 - val_accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 1.1707 - accuracy: 0.7532 - val_loss: 0.6849 - val_accuracy: 0.9293\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 346us/step - loss: 0.9286 - accuracy: 0.7944 - val_loss: 0.6140 - val_accuracy: 0.9495\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 373us/step - loss: 0.7907 - accuracy: 0.8052 - val_loss: 0.6171 - val_accuracy: 0.9242\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.8536 - accuracy: 0.7662 - val_loss: 0.6054 - val_accuracy: 0.9293\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.7381 - accuracy: 0.8117 - val_loss: 0.5233 - val_accuracy: 0.9293\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.7824 - accuracy: 0.7792 - val_loss: 0.6687 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.7730 - accuracy: 0.7706 - val_loss: 0.4431 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.8811 - accuracy: 0.7597 - val_loss: 0.7746 - val_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.8798 - accuracy: 0.7489 - val_loss: 0.5748 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.8909 - accuracy: 0.7792 - val_loss: 0.6253 - val_accuracy: 0.9495\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.7932 - accuracy: 0.7879 - val_loss: 0.8435 - val_accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 419us/step - loss: 1.2250 - accuracy: 0.7662 - val_loss: 0.8024 - val_accuracy: 0.8687\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 1.0406 - accuracy: 0.7554 - val_loss: 0.4022 - val_accuracy: 0.8990\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 415us/step - loss: 0.9160 - accuracy: 0.7641 - val_loss: 0.8013 - val_accuracy: 0.9394\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 506us/step - loss: 0.7552 - accuracy: 0.7835 - val_loss: 0.4830 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.7081 - accuracy: 0.7922 - val_loss: 0.6536 - val_accuracy: 0.9495\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.7170 - accuracy: 0.7381 - val_loss: 0.5731 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 446us/step - loss: 0.6626 - accuracy: 0.8182 - val_loss: 0.5316 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 475us/step - loss: 0.6229 - accuracy: 0.8052 - val_loss: 0.4833 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 450us/step - loss: 0.5784 - accuracy: 0.8030 - val_loss: 0.5647 - val_accuracy: 0.9495\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 700us/step - loss: 0.6386 - accuracy: 0.7749 - val_loss: 0.5068 - val_accuracy: 0.9495\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 624us/step - loss: 0.6864 - accuracy: 0.7879 - val_loss: 0.4873 - val_accuracy: 0.9495\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.7293 - accuracy: 0.7749 - val_loss: 0.8182 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.6991 - accuracy: 0.8074 - val_loss: 0.5637 - val_accuracy: 0.9495\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 495us/step - loss: 0.7658 - accuracy: 0.7684 - val_loss: 0.5034 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.5745 - accuracy: 0.7879 - val_loss: 0.4872 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 316us/step - loss: 0.7469 - accuracy: 0.7576 - val_loss: 0.5804 - val_accuracy: 0.8990\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 0.8822 - accuracy: 0.7987 - val_loss: 0.8282 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 0.7533 - accuracy: 0.8139 - val_loss: 0.4962 - val_accuracy: 0.9495\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 542us/step - loss: 0.7505 - accuracy: 0.7662 - val_loss: 0.5684 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.5855 - accuracy: 0.8030 - val_loss: 0.4421 - val_accuracy: 0.9495\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.5535 - accuracy: 0.8052 - val_loss: 0.7361 - val_accuracy: 0.9495\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.6673 - accuracy: 0.7771 - val_loss: 0.3396 - val_accuracy: 0.9596\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 364us/step - loss: 0.4792 - accuracy: 0.8420 - val_loss: 0.7387 - val_accuracy: 0.9495\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.6999 - accuracy: 0.7771 - val_loss: 0.4645 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.6132 - accuracy: 0.7727 - val_loss: 0.3096 - val_accuracy: 0.9697\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 293us/step - loss: 0.5472 - accuracy: 0.8247 - val_loss: 0.5405 - val_accuracy: 0.9495\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.5483 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.5384 - accuracy: 0.7771 - val_loss: 0.6231 - val_accuracy: 0.9495\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5314 - accuracy: 0.7900 - val_loss: 0.5267 - val_accuracy: 0.9495\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.5095 - accuracy: 0.7944 - val_loss: 0.6073 - val_accuracy: 0.9495\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.5102 - accuracy: 0.7987 - val_loss: 0.4841 - val_accuracy: 0.9495\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4388 - accuracy: 0.8095 - val_loss: 0.3303 - val_accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5570 - accuracy: 0.8203 - val_loss: 0.5275 - val_accuracy: 0.9495\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.4234 - accuracy: 0.8203 - val_loss: 0.3291 - val_accuracy: 0.9596\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.6077 - accuracy: 0.7835 - val_loss: 0.5471 - val_accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.4942 - accuracy: 0.8052 - val_loss: 0.5037 - val_accuracy: 0.9495\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.4791 - accuracy: 0.8030 - val_loss: 0.4643 - val_accuracy: 0.9545\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 213us/step - loss: 0.5395 - accuracy: 0.7814 - val_loss: 0.3759 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.5794 - accuracy: 0.7511 - val_loss: 0.3072 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a42d3eba8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 171us/step\n",
      "over-sampling test accuracy: 92.42%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0,\n",
       "       0, 0, 1, 2, 1, 2, 2, 0, 1, 0, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1, 2, 2,\n",
       "       0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 2, 2, 1, 0, 2, 0, 1, 0, 0,\n",
       "       0, 2, 2, 0, 1, 0, 2, 0, 0, 1, 2, 1, 0, 1, 2, 0, 1, 2, 2, 1, 0, 0,\n",
       "       2, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0,\n",
       "       1, 1, 2, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2,\n",
       "       1, 2, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1,\n",
       "       0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS209     2     2\n",
       "1       NRS386     1     1\n",
       "2       NRS148     2     2\n",
       "3       NRS178     0     1\n",
       "4       NRS237     0     0\n",
       "..         ...   ...   ...\n",
       "193     NRS209     2     2\n",
       "194     NRS002     0     1\n",
       "195     NRS109     2     2\n",
       "196  BCH-SA-03     1     1\n",
       "197  BCH-SA-03     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.033055e-08</td>\n",
       "      <td>2.077004e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.341317e-02</td>\n",
       "      <td>9.765866e-01</td>\n",
       "      <td>1.195465e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.534076e-09</td>\n",
       "      <td>8.725181e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.741061e-19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.490597e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.908509e-11</td>\n",
       "      <td>5.167130e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.033055e-08</td>\n",
       "      <td>2.077004e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.456927e-02</td>\n",
       "      <td>9.854306e-01</td>\n",
       "      <td>9.453345e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.542550e-09</td>\n",
       "      <td>1.027252e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.916769e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.587334e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.916769e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.587334e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.033055e-08  2.077004e-08  1.000000e+00\n",
       "1    2.341317e-02  9.765866e-01  1.195465e-07\n",
       "2    1.534076e-09  8.725181e-09  1.000000e+00\n",
       "3    4.741061e-19  1.000000e+00  1.490597e-17\n",
       "4    1.000000e+00  2.908509e-11  5.167130e-14\n",
       "..            ...           ...           ...\n",
       "193  1.033055e-08  2.077004e-08  1.000000e+00\n",
       "194  1.456927e-02  9.854306e-01  9.453345e-08\n",
       "195  1.542550e-09  1.027252e-08  1.000000e+00\n",
       "196  9.916769e-08  9.999999e-01  7.587334e-10\n",
       "197  9.916769e-08  9.999999e-01  7.587334e-10\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 483us/step - loss: 0.5355 - accuracy: 0.8268 - val_loss: 0.6524 - val_accuracy: 0.9495\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 445us/step - loss: 0.4881 - accuracy: 0.8268 - val_loss: 0.6525 - val_accuracy: 0.9495\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.5805 - accuracy: 0.7792 - val_loss: 0.7863 - val_accuracy: 0.9495\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5213 - accuracy: 0.7922 - val_loss: 0.7767 - val_accuracy: 0.9495\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.5295 - accuracy: 0.8095 - val_loss: 0.4984 - val_accuracy: 0.9495\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.4479 - accuracy: 0.8030 - val_loss: 0.5573 - val_accuracy: 0.9495\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5694 - accuracy: 0.7944 - val_loss: 0.8041 - val_accuracy: 0.9495\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.5017 - accuracy: 0.8074 - val_loss: 0.7365 - val_accuracy: 0.9444\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 0.4918 - accuracy: 0.8095 - val_loss: 0.8101 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.6208 - accuracy: 0.7619 - val_loss: 0.6316 - val_accuracy: 0.9495\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.4932 - accuracy: 0.7684 - val_loss: 0.6799 - val_accuracy: 0.9495\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.6368 - accuracy: 0.7857 - val_loss: 0.7487 - val_accuracy: 0.9495\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.4797 - accuracy: 0.7922 - val_loss: 0.7131 - val_accuracy: 0.9495\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.5520 - accuracy: 0.8030 - val_loss: 0.5438 - val_accuracy: 0.9242\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.6876 - accuracy: 0.7727 - val_loss: 0.7139 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.6512 - accuracy: 0.7814 - val_loss: 0.5232 - val_accuracy: 0.9495\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 462us/step - loss: 0.4901 - accuracy: 0.8160 - val_loss: 0.6091 - val_accuracy: 0.9495\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 423us/step - loss: 0.3634 - accuracy: 0.8160 - val_loss: 0.7094 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.4090 - accuracy: 0.8095 - val_loss: 0.4342 - val_accuracy: 0.9646\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 821us/step - loss: 0.4854 - accuracy: 0.7835 - val_loss: 0.7281 - val_accuracy: 0.9495\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 512us/step - loss: 0.6181 - accuracy: 0.7944 - val_loss: 0.6820 - val_accuracy: 0.9596\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 475us/step - loss: 0.6533 - accuracy: 0.7879 - val_loss: 0.5513 - val_accuracy: 0.9596\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 356us/step - loss: 0.5399 - accuracy: 0.8009 - val_loss: 0.6714 - val_accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 0.5010 - accuracy: 0.8182 - val_loss: 0.4638 - val_accuracy: 0.9596\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.5744 - accuracy: 0.7792 - val_loss: 0.7457 - val_accuracy: 0.9495\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.3943 - accuracy: 0.8247 - val_loss: 0.4937 - val_accuracy: 0.9495\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 376us/step - loss: 0.4994 - accuracy: 0.7922 - val_loss: 0.7897 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.4335 - accuracy: 0.7944 - val_loss: 0.5201 - val_accuracy: 0.9394\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.4988 - accuracy: 0.7900 - val_loss: 0.6802 - val_accuracy: 0.9495\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 738us/step - loss: 0.5014 - accuracy: 0.7857 - val_loss: 0.5739 - val_accuracy: 0.9495\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.3945 - accuracy: 0.8506 - val_loss: 0.6989 - val_accuracy: 0.9495\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 542us/step - loss: 0.4509 - accuracy: 0.8052 - val_loss: 0.4859 - val_accuracy: 0.9495\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 606us/step - loss: 0.5138 - accuracy: 0.7619 - val_loss: 0.7163 - val_accuracy: 0.9495\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 353us/step - loss: 0.4968 - accuracy: 0.7641 - val_loss: 0.4750 - val_accuracy: 0.9545\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 486us/step - loss: 0.5248 - accuracy: 0.7792 - val_loss: 0.7139 - val_accuracy: 0.9495\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 429us/step - loss: 0.5040 - accuracy: 0.7706 - val_loss: 0.6844 - val_accuracy: 0.9495\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 503us/step - loss: 0.4365 - accuracy: 0.8290 - val_loss: 0.5681 - val_accuracy: 0.9495\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 0.6181 - accuracy: 0.7727 - val_loss: 0.7397 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 0.4816 - accuracy: 0.7835 - val_loss: 0.5412 - val_accuracy: 0.9495\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 481us/step - loss: 0.4676 - accuracy: 0.7922 - val_loss: 0.5246 - val_accuracy: 0.9495\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 442us/step - loss: 0.5238 - accuracy: 0.7965 - val_loss: 0.5967 - val_accuracy: 0.9495\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.74 - 0s 428us/step - loss: 0.5375 - accuracy: 0.7662 - val_loss: 0.4547 - val_accuracy: 0.9545\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 342us/step - loss: 0.5206 - accuracy: 0.7792 - val_loss: 0.7456 - val_accuracy: 0.9495\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 625us/step - loss: 0.4851 - accuracy: 0.7662 - val_loss: 0.6451 - val_accuracy: 0.9495\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 350us/step - loss: 0.4682 - accuracy: 0.7965 - val_loss: 0.5837 - val_accuracy: 0.9495\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.4512 - accuracy: 0.8009 - val_loss: 0.7142 - val_accuracy: 0.9495\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.5765 - accuracy: 0.7727 - val_loss: 0.6259 - val_accuracy: 0.9444\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 292us/step - loss: 0.4731 - accuracy: 0.7835 - val_loss: 0.5455 - val_accuracy: 0.9545\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.4122 - accuracy: 0.7987 - val_loss: 0.4445 - val_accuracy: 0.9545\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.4601 - accuracy: 0.8009 - val_loss: 0.6323 - val_accuracy: 0.9495\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 299us/step - loss: 0.3975 - accuracy: 0.8095 - val_loss: 0.3670 - val_accuracy: 0.9646\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 814us/step - loss: 0.5185 - accuracy: 0.8030 - val_loss: 0.3921 - val_accuracy: 0.9394\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 444us/step - loss: 0.5996 - accuracy: 0.8247 - val_loss: 0.4260 - val_accuracy: 0.9495\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 0.6925 - accuracy: 0.7641 - val_loss: 0.4393 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 354us/step - loss: 0.5294 - accuracy: 0.7749 - val_loss: 0.6464 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 0.5253 - accuracy: 0.7965 - val_loss: 0.4838 - val_accuracy: 0.9545\n",
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 377us/step - loss: 0.5378 - accuracy: 0.7792 - val_loss: 0.3680 - val_accuracy: 0.9697\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 0.5234 - accuracy: 0.8117 - val_loss: 0.5928 - val_accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 468us/step - loss: 0.5142 - accuracy: 0.7706 - val_loss: 0.5270 - val_accuracy: 0.9545\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 358us/step - loss: 0.4375 - accuracy: 0.7879 - val_loss: 0.4126 - val_accuracy: 0.9596\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.5522 - accuracy: 0.8030 - val_loss: 0.4025 - val_accuracy: 0.9596\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 489us/step - loss: 0.4963 - accuracy: 0.7706 - val_loss: 0.6740 - val_accuracy: 0.9545\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.4786 - accuracy: 0.8052 - val_loss: 0.7243 - val_accuracy: 0.9495\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 0.5179 - accuracy: 0.7814 - val_loss: 0.5168 - val_accuracy: 0.9545\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 0.4830 - accuracy: 0.8117 - val_loss: 0.4836 - val_accuracy: 0.9545\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.4353 - accuracy: 0.8117 - val_loss: 0.5601 - val_accuracy: 0.9495\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 347us/step - loss: 0.4290 - accuracy: 0.8052 - val_loss: 0.7709 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.5393 - accuracy: 0.7706 - val_loss: 0.3150 - val_accuracy: 0.9596\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.5415 - accuracy: 0.7857 - val_loss: 0.4286 - val_accuracy: 0.9596\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 291us/step - loss: 0.5627 - accuracy: 0.7857 - val_loss: 0.5905 - val_accuracy: 0.9545\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.4635 - accuracy: 0.7879 - val_loss: 0.5569 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 0.4019 - accuracy: 0.8074 - val_loss: 0.3977 - val_accuracy: 0.9646\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.4194 - accuracy: 0.8009 - val_loss: 0.5084 - val_accuracy: 0.9545\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 0.4404 - accuracy: 0.7965 - val_loss: 0.5850 - val_accuracy: 0.9495\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 317us/step - loss: 0.4057 - accuracy: 0.8139 - val_loss: 0.5955 - val_accuracy: 0.9596\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 506us/step - loss: 0.4265 - accuracy: 0.8117 - val_loss: 0.6497 - val_accuracy: 0.9545\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 544us/step - loss: 0.4851 - accuracy: 0.7489 - val_loss: 0.5627 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 422us/step - loss: 0.3697 - accuracy: 0.8182 - val_loss: 0.5564 - val_accuracy: 0.9596\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.4878 - accuracy: 0.7771 - val_loss: 0.5767 - val_accuracy: 0.9596\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.3960 - accuracy: 0.8052 - val_loss: 0.6123 - val_accuracy: 0.9545\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 411us/step - loss: 0.4377 - accuracy: 0.7835 - val_loss: 0.6032 - val_accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 481us/step - loss: 0.3700 - accuracy: 0.8095 - val_loss: 0.6071 - val_accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.4262 - accuracy: 0.7987 - val_loss: 0.6512 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.4454 - accuracy: 0.7771 - val_loss: 0.5304 - val_accuracy: 0.9596\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 398us/step - loss: 0.4091 - accuracy: 0.8030 - val_loss: 0.6252 - val_accuracy: 0.9545\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 409us/step - loss: 0.4155 - accuracy: 0.7922 - val_loss: 0.4954 - val_accuracy: 0.9596\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 464us/step - loss: 0.4419 - accuracy: 0.7965 - val_loss: 0.5997 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 268us/step - loss: 0.3638 - accuracy: 0.8117 - val_loss: 0.5662 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 383us/step - loss: 0.3863 - accuracy: 0.7987 - val_loss: 0.5032 - val_accuracy: 0.9596\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 360us/step - loss: 0.3643 - accuracy: 0.8268 - val_loss: 0.5781 - val_accuracy: 0.9545\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 372us/step - loss: 0.4005 - accuracy: 0.7987 - val_loss: 0.5065 - val_accuracy: 0.9495\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 362us/step - loss: 0.4267 - accuracy: 0.7684 - val_loss: 0.6413 - val_accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 0.4111 - accuracy: 0.8074 - val_loss: 0.5690 - val_accuracy: 0.9596\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 0.4752 - accuracy: 0.7857 - val_loss: 0.3564 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5648 - accuracy: 0.8182 - val_loss: 0.5898 - val_accuracy: 0.9596\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.6264 - accuracy: 0.7944 - val_loss: 0.6724 - val_accuracy: 0.9545\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.5426 - accuracy: 0.8009 - val_loss: 0.9424 - val_accuracy: 0.9242\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.6486 - accuracy: 0.7727 - val_loss: 0.3790 - val_accuracy: 0.9646\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.5389 - accuracy: 0.7727 - val_loss: 0.6979 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.4065 - accuracy: 0.8247 - val_loss: 0.4583 - val_accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.44%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [2.34131740e-02, 9.76586640e-01, 1.19546480e-07],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [4.74106100e-19, 1.00000000e+00, 1.49059670e-17],\n",
       "       [1.00000000e+00, 2.90850850e-11, 5.16712970e-14],\n",
       "       [1.53128040e-10, 1.00000000e+00, 5.85402500e-12],\n",
       "       [9.91675100e-08, 9.99999900e-01, 7.58733350e-10],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.53128040e-10, 1.00000000e+00, 5.85402500e-12],\n",
       "       [3.27097680e-01, 6.54188330e-01, 1.87139640e-02],\n",
       "       [2.34131740e-02, 9.76586640e-01, 1.19546480e-07],\n",
       "       [1.94771740e-01, 8.05226300e-01, 1.90955700e-06],\n",
       "       [7.69961800e-07, 9.99998450e-01, 8.56489900e-07],\n",
       "       [4.04378950e-04, 9.99595600e-01, 1.09082540e-08],\n",
       "       [1.00000000e+00, 1.33622100e-13, 6.24817600e-17],\n",
       "       [9.91675100e-08, 9.99999900e-01, 7.58733350e-10],\n",
       "       [1.00000000e+00, 2.36278970e-10, 7.05662700e-13],\n",
       "       [1.02297610e-06, 9.99997850e-01, 1.10048850e-06],\n",
       "       [1.00000000e+00, 8.70953800e-12, 1.14741190e-14],\n",
       "       [4.33649630e-17, 1.00000000e+00, 7.95565160e-16],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.53636340e-09, 2.06599270e-11],\n",
       "       [1.00000000e+00, 1.08833040e-14, 2.73254170e-18],\n",
       "       [1.00000000e+00, 1.49678710e-10, 3.99180720e-13],\n",
       "       [1.44670030e-06, 9.99997000e-01, 1.49407190e-06],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.74729130e-16, 1.00000000e+00, 5.24128200e-16],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.56433330e-15, 6.78535200e-19],\n",
       "       [3.27664830e-04, 9.99672200e-01, 6.72849200e-08],\n",
       "       [1.00000000e+00, 3.12591250e-12, 3.19409700e-15],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [2.84972340e-06, 9.99997140e-01, 1.89231400e-09],\n",
       "       [1.00000000e+00, 2.29073950e-11, 3.83567550e-14],\n",
       "       [1.00000000e+00, 1.26131030e-11, 1.82148460e-14],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.10342550e-11, 1.57474750e-13],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.02297610e-06, 9.99997850e-01, 1.10048850e-06],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [2.65621400e-08, 1.00000000e+00, 3.50775250e-09],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.44386280e-13, 6.88249140e-17],\n",
       "       [1.00000000e+00, 4.22538540e-19, 8.54862400e-24],\n",
       "       [6.68773600e-09, 1.00000000e+00, 1.30102800e-08],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.91089770e-16, 7.20692000e-20],\n",
       "       [1.61674920e-01, 8.13483830e-01, 2.48412960e-02],\n",
       "       [2.88858670e-09, 1.00000000e+00, 8.07676000e-12],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [2.84972340e-06, 9.99997140e-01, 1.89231400e-09],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [3.04731640e-08, 1.00000000e+00, 4.16095940e-10],\n",
       "       [2.88858670e-09, 1.00000000e+00, 8.07676000e-12],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.10238830e-07, 9.99999900e-01, 2.18064180e-11],\n",
       "       [1.00000000e+00, 1.41662970e-10, 3.72681050e-13],\n",
       "       [4.06578740e-04, 9.99593440e-01, 4.98647100e-09],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.68148140e-13, 2.21330410e-16],\n",
       "       [1.00000000e+00, 1.00800230e-12, 7.77951600e-16],\n",
       "       [1.61674920e-01, 8.13483830e-01, 2.48412960e-02],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [4.04378950e-04, 9.99595600e-01, 1.09082540e-08],\n",
       "       [1.00000000e+00, 2.80007960e-15, 5.02079450e-19],\n",
       "       [9.91675100e-08, 9.99999900e-01, 7.58733350e-10],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.23692000e-13, 5.14467300e-16],\n",
       "       [2.42181340e-17, 1.00000000e+00, 3.55355000e-17],\n",
       "       [1.00000000e+00, 2.10752860e-11, 3.45670200e-14],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [2.12351230e-10, 1.00000000e+00, 6.21171900e-10],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.74729130e-16, 1.00000000e+00, 5.24128200e-16],\n",
       "       [1.00000000e+00, 9.25212700e-15, 2.23130800e-18],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.29369190e-10, 6.80003900e-13],\n",
       "       [3.04731640e-08, 1.00000000e+00, 4.16095940e-10],\n",
       "       [9.75307170e-01, 2.46922490e-02, 5.38053030e-07],\n",
       "       [1.00000000e+00, 3.16501030e-16, 3.30522470e-20],\n",
       "       [1.00000000e+00, 7.35593000e-14, 2.96638500e-17],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.34878600e-12, 2.23581000e-15],\n",
       "       [5.38836620e-15, 1.00000000e+00, 6.39205800e-16],\n",
       "       [1.00000000e+00, 3.07852560e-11, 5.54677830e-14],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.79006290e-11, 2.81953500e-14],\n",
       "       [1.00000000e+00, 4.73250800e-14, 1.71074520e-17],\n",
       "       [1.61674920e-01, 8.13483830e-01, 2.48412960e-02],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [4.04378950e-04, 9.99595600e-01, 1.09082540e-08],\n",
       "       [7.58154750e-01, 2.41844830e-01, 3.49474730e-07],\n",
       "       [4.33649630e-17, 1.00000000e+00, 7.95565160e-16],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00800230e-12, 7.77951600e-16],\n",
       "       [5.38836620e-15, 1.00000000e+00, 6.39205800e-16],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [2.65621400e-08, 1.00000000e+00, 3.50775250e-09],\n",
       "       [1.00000000e+00, 3.13749580e-15, 5.78684100e-19],\n",
       "       [9.34342270e-01, 6.56574500e-02, 2.79267340e-07],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [3.27664830e-04, 9.99672200e-01, 6.72849200e-08],\n",
       "       [1.00000000e+00, 4.89412160e-09, 3.09912820e-11],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [3.27664830e-04, 9.99672200e-01, 6.72849200e-08],\n",
       "       [2.65621400e-08, 1.00000000e+00, 3.50775250e-09],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [4.04378950e-04, 9.99595600e-01, 1.09082540e-08],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [3.04731640e-08, 1.00000000e+00, 4.16095940e-10],\n",
       "       [7.69961800e-07, 9.99998450e-01, 8.56489900e-07],\n",
       "       [2.65621400e-08, 1.00000000e+00, 3.50775250e-09],\n",
       "       [1.00000000e+00, 5.31719950e-10, 1.94181200e-12],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [2.84972340e-06, 9.99997140e-01, 1.89231400e-09],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.54777100e-11, 1.15675800e-13],\n",
       "       [4.06578740e-04, 9.99593440e-01, 4.98647100e-09],\n",
       "       [1.00000000e+00, 2.50087900e-13, 1.36605530e-16],\n",
       "       [1.29594955e-05, 9.99987000e-01, 9.53325300e-11],\n",
       "       [1.00000000e+00, 3.19549140e-12, 3.28307920e-15],\n",
       "       [1.31305430e-06, 9.99997260e-01, 1.37162100e-06],\n",
       "       [1.36433760e-11, 1.00000000e+00, 3.86701900e-11],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.39224880e-13, 6.57679600e-17],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.75460170e-12, 2.72780710e-15],\n",
       "       [4.33649630e-17, 1.00000000e+00, 7.95565160e-16],\n",
       "       [1.00000000e+00, 3.36874860e-17, 2.01856260e-21],\n",
       "       [7.73970400e-08, 9.99999900e-01, 8.66873100e-09],\n",
       "       [1.36433760e-11, 1.00000000e+00, 3.86701900e-11],\n",
       "       [1.00000000e+00, 1.43080260e-09, 6.67889200e-12],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.48247030e-10, 3.94421770e-13],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [2.84972340e-06, 9.99997140e-01, 1.89231400e-09],\n",
       "       [1.00000000e+00, 2.06312960e-15, 3.42955750e-19],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.49434520e-14, 4.05880600e-18],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.10238830e-07, 9.99999900e-01, 2.18064180e-11],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.57894690e-12, 1.00000000e+00, 8.27599450e-12],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [6.68773600e-09, 1.00000000e+00, 1.30102800e-08],\n",
       "       [1.00000000e+00, 5.40195870e-08, 6.20468500e-10],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.92107100e-14, 3.77382720e-17],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.49662100e-12, 7.95869100e-15],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.07898170e-11, 1.03607900e-13],\n",
       "       [1.00000000e+00, 1.11857010e-11, 1.56795520e-14],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [2.12351230e-10, 1.00000000e+00, 6.21171900e-10],\n",
       "       [1.00000000e+00, 1.33917390e-08, 1.08844270e-10],\n",
       "       [1.00000000e+00, 7.39129400e-12, 9.34909100e-15],\n",
       "       [1.00000000e+00, 7.43293300e-11, 1.66642440e-13],\n",
       "       [2.34131740e-02, 9.76586640e-01, 1.19546480e-07],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.55643150e-01, 8.44356700e-01, 5.96584260e-08],\n",
       "       [1.00000000e+00, 5.58030600e-12, 6.58322860e-15],\n",
       "       [9.91675100e-08, 9.99999900e-01, 7.58733350e-10],\n",
       "       [7.73970400e-08, 9.99999900e-01, 8.66873100e-09],\n",
       "       [1.00000000e+00, 3.07852560e-11, 5.54677830e-14],\n",
       "       [1.00000000e+00, 6.22466400e-12, 7.54511800e-15],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [3.04731640e-08, 1.00000000e+00, 4.16095940e-10],\n",
       "       [1.00000000e+00, 1.02570760e-08, 7.80322400e-11],\n",
       "       [1.31305430e-06, 9.99997260e-01, 1.37162100e-06],\n",
       "       [2.12351230e-10, 1.00000000e+00, 6.21171900e-10],\n",
       "       [2.12351230e-10, 1.00000000e+00, 6.21171900e-10],\n",
       "       [1.00000000e+00, 1.01023460e-09, 4.32576800e-12],\n",
       "       [1.53407590e-09, 8.72518150e-09, 1.00000000e+00],\n",
       "       [1.53128040e-10, 1.00000000e+00, 5.85402500e-12],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [1.31305930e-06, 9.99997260e-01, 1.37162230e-06],\n",
       "       [1.03305460e-08, 2.07700360e-08, 1.00000000e+00],\n",
       "       [1.45692695e-02, 9.85430600e-01, 9.45334500e-08],\n",
       "       [1.54254950e-09, 1.02725240e-08, 1.00000000e+00],\n",
       "       [9.91676900e-08, 9.99999900e-01, 7.58733350e-10],\n",
       "       [9.91676900e-08, 9.99999900e-01, 7.58733350e-10]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923094582185491"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923094582185491"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS209     2\n",
       "1      BCH-SA-09     1\n",
       "2         NRS224     0\n",
       "3         NRS209     2\n",
       "4         NRS235     1\n",
       "..           ...   ...\n",
       "193       NRS209     2\n",
       "194  CFBREBSa131     1\n",
       "195  CFBREBSa103     0\n",
       "196       NRS188     1\n",
       "197       NRS148     2\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 741us/step - loss: 3.8863 - accuracy: 0.5195 - val_loss: 0.9374 - val_accuracy: 0.7525\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 359us/step - loss: 3.4163 - accuracy: 0.6710 - val_loss: 0.8999 - val_accuracy: 0.7626\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 464us/step - loss: 3.2407 - accuracy: 0.6797 - val_loss: 0.8612 - val_accuracy: 0.7828\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 3.1458 - accuracy: 0.6710 - val_loss: 1.0645 - val_accuracy: 0.7828\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 417us/step - loss: 2.7088 - accuracy: 0.7273 - val_loss: 0.9697 - val_accuracy: 0.6970\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 392us/step - loss: 3.5323 - accuracy: 0.6818 - val_loss: 1.0858 - val_accuracy: 0.8131\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 338us/step - loss: 3.2311 - accuracy: 0.6515 - val_loss: 1.2186 - val_accuracy: 0.8030\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 2.8957 - accuracy: 0.6991 - val_loss: 1.2948 - val_accuracy: 0.7929\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 2.7220 - accuracy: 0.7013 - val_loss: 1.7153 - val_accuracy: 0.7778\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 726us/step - loss: 3.1982 - accuracy: 0.6429 - val_loss: 1.6411 - val_accuracy: 0.8232\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 378us/step - loss: 2.0144 - accuracy: 0.7381 - val_loss: 1.4181 - val_accuracy: 0.8232\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 2.3812 - accuracy: 0.7186 - val_loss: 1.6037 - val_accuracy: 0.8030\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 367us/step - loss: 2.3942 - accuracy: 0.7208 - val_loss: 1.2734 - val_accuracy: 0.8232\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 467us/step - loss: 2.2941 - accuracy: 0.7511 - val_loss: 1.1508 - val_accuracy: 0.8081\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 501us/step - loss: 2.0128 - accuracy: 0.7381 - val_loss: 1.2840 - val_accuracy: 0.8586\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 2.1031 - accuracy: 0.7359 - val_loss: 1.4668 - val_accuracy: 0.8232\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 185us/step - loss: 2.0692 - accuracy: 0.7684 - val_loss: 1.2295 - val_accuracy: 0.8535\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 1.9614 - accuracy: 0.7468 - val_loss: 1.4172 - val_accuracy: 0.8687\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 2.0571 - accuracy: 0.7186 - val_loss: 2.0498 - val_accuracy: 0.7525\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 499us/step - loss: 1.9609 - accuracy: 0.7229 - val_loss: 1.5711 - val_accuracy: 0.8030\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 1.9677 - accuracy: 0.7035 - val_loss: 1.6922 - val_accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 188us/step - loss: 1.9334 - accuracy: 0.7294 - val_loss: 1.3659 - val_accuracy: 0.8687\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 1.9056 - accuracy: 0.7273 - val_loss: 1.7590 - val_accuracy: 0.8283\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 1.5846 - accuracy: 0.7359 - val_loss: 1.4441 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 1.4949 - accuracy: 0.7403 - val_loss: 2.0384 - val_accuracy: 0.8182\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 1.8024 - accuracy: 0.7143 - val_loss: 1.6776 - val_accuracy: 0.8283\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 1.4756 - accuracy: 0.7662 - val_loss: 1.1430 - val_accuracy: 0.8788\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 451us/step - loss: 1.3225 - accuracy: 0.7857 - val_loss: 1.1962 - val_accuracy: 0.8939\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 1.4576 - accuracy: 0.7597 - val_loss: 1.0680 - val_accuracy: 0.9040\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 679us/step - loss: 1.2336 - accuracy: 0.7792 - val_loss: 1.0757 - val_accuracy: 0.8636\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 1.5209 - accuracy: 0.7489 - val_loss: 0.9529 - val_accuracy: 0.8838\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 326us/step - loss: 1.2870 - accuracy: 0.7835 - val_loss: 1.0868 - val_accuracy: 0.8838\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 1.0492 - accuracy: 0.7489 - val_loss: 0.8601 - val_accuracy: 0.9141\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 950us/step - loss: 1.1367 - accuracy: 0.7641 - val_loss: 1.1429 - val_accuracy: 0.8990\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 893us/step - loss: 1.4355 - accuracy: 0.7641 - val_loss: 0.9440 - val_accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 468us/step - loss: 1.2097 - accuracy: 0.7468 - val_loss: 1.3250 - val_accuracy: 0.8485\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 1.2113 - accuracy: 0.7597 - val_loss: 1.3034 - val_accuracy: 0.8788\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.9904 - accuracy: 0.7814 - val_loss: 1.1395 - val_accuracy: 0.8737\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 1.0886 - accuracy: 0.7468 - val_loss: 0.8873 - val_accuracy: 0.9040\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 1.0194 - accuracy: 0.7922 - val_loss: 1.0432 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.9237 - accuracy: 0.7835 - val_loss: 0.6647 - val_accuracy: 0.9141\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 186us/step - loss: 0.9359 - accuracy: 0.7749 - val_loss: 0.9561 - val_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.9154 - accuracy: 0.7771 - val_loss: 1.2164 - val_accuracy: 0.8586\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 1.1037 - accuracy: 0.7879 - val_loss: 0.9024 - val_accuracy: 0.8939\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 191us/step - loss: 0.9809 - accuracy: 0.7706 - val_loss: 1.1797 - val_accuracy: 0.9040\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 252us/step - loss: 1.3207 - accuracy: 0.7641 - val_loss: 0.8278 - val_accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 217us/step - loss: 1.0065 - accuracy: 0.7511 - val_loss: 0.7769 - val_accuracy: 0.9596\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.9218 - accuracy: 0.7900 - val_loss: 0.7939 - val_accuracy: 0.9293\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 187us/step - loss: 0.8855 - accuracy: 0.8030 - val_loss: 1.0403 - val_accuracy: 0.9141\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.8831 - accuracy: 0.7597 - val_loss: 0.8719 - val_accuracy: 0.9394\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.7768 - accuracy: 0.7814 - val_loss: 0.7368 - val_accuracy: 0.9596\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.8668 - accuracy: 0.7857 - val_loss: 0.6790 - val_accuracy: 0.9495\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.7513 - accuracy: 0.7706 - val_loss: 0.7046 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.7357 - accuracy: 0.7944 - val_loss: 0.5987 - val_accuracy: 0.9596\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 493us/step - loss: 0.8989 - accuracy: 0.7835 - val_loss: 0.7122 - val_accuracy: 0.9596\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.7172 - accuracy: 0.7857 - val_loss: 0.6109 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.7658 - accuracy: 0.7727 - val_loss: 0.9558 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.7744 - accuracy: 0.7814 - val_loss: 0.6605 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.7919 - accuracy: 0.7965 - val_loss: 1.1242 - val_accuracy: 0.8939\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.9563 - accuracy: 0.7684 - val_loss: 0.8282 - val_accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.7563 - accuracy: 0.7749 - val_loss: 0.8894 - val_accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 503us/step - loss: 0.6029 - accuracy: 0.7900 - val_loss: 0.6624 - val_accuracy: 0.9394\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.7238 - accuracy: 0.7987 - val_loss: 0.8330 - val_accuracy: 0.9394\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.8170 - accuracy: 0.7814 - val_loss: 0.5744 - val_accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 388us/step - loss: 0.5911 - accuracy: 0.8182 - val_loss: 0.6867 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.7179 - accuracy: 0.7814 - val_loss: 0.8482 - val_accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.5763 - accuracy: 0.8030 - val_loss: 0.6934 - val_accuracy: 0.9545\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6790 - accuracy: 0.7922 - val_loss: 0.5411 - val_accuracy: 0.9697\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.6056 - accuracy: 0.8052 - val_loss: 0.5761 - val_accuracy: 0.9596\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 0.6464 - accuracy: 0.8030 - val_loss: 0.5541 - val_accuracy: 0.9596\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 233us/step - loss: 0.5807 - accuracy: 0.8095 - val_loss: 0.7548 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 615us/step - loss: 0.7062 - accuracy: 0.7597 - val_loss: 0.9529 - val_accuracy: 0.9495\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.5726 - accuracy: 0.8247 - val_loss: 0.7612 - val_accuracy: 0.9394\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.7522 - accuracy: 0.7532 - val_loss: 0.6458 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 333us/step - loss: 0.6394 - accuracy: 0.7879 - val_loss: 0.6919 - val_accuracy: 0.9495\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.5980 - accuracy: 0.7792 - val_loss: 0.6309 - val_accuracy: 0.9545\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.6418 - accuracy: 0.7965 - val_loss: 0.5374 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 296us/step - loss: 0.6750 - accuracy: 0.7814 - val_loss: 0.5534 - val_accuracy: 0.9596\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.7165 - accuracy: 0.7922 - val_loss: 0.4882 - val_accuracy: 0.9697\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6609 - accuracy: 0.7684 - val_loss: 0.7663 - val_accuracy: 0.9495\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.8556 - accuracy: 0.7576 - val_loss: 0.6780 - val_accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.5773 - accuracy: 0.7944 - val_loss: 0.4612 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.5851 - accuracy: 0.7900 - val_loss: 0.7732 - val_accuracy: 0.9495\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.6051 - accuracy: 0.7684 - val_loss: 0.4976 - val_accuracy: 0.9697\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5151 - accuracy: 0.8203 - val_loss: 0.5184 - val_accuracy: 0.9697\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.5779 - accuracy: 0.8182 - val_loss: 0.6485 - val_accuracy: 0.9545\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.5304 - accuracy: 0.8095 - val_loss: 0.6460 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5320 - accuracy: 0.8074 - val_loss: 0.4784 - val_accuracy: 0.9646\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5302 - accuracy: 0.8268 - val_loss: 0.4633 - val_accuracy: 0.9646\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.5819 - accuracy: 0.7944 - val_loss: 0.8541 - val_accuracy: 0.9495\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.5677 - accuracy: 0.8074 - val_loss: 0.5453 - val_accuracy: 0.9646\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.6014 - accuracy: 0.8117 - val_loss: 0.5440 - val_accuracy: 0.9697\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.5380 - accuracy: 0.8095 - val_loss: 0.8886 - val_accuracy: 0.9495\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.6760 - accuracy: 0.7771 - val_loss: 0.9796 - val_accuracy: 0.9242\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 330us/step - loss: 0.5639 - accuracy: 0.7900 - val_loss: 0.4225 - val_accuracy: 0.9747\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 363us/step - loss: 0.5039 - accuracy: 0.7879 - val_loss: 0.4314 - val_accuracy: 0.9697\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.5614 - accuracy: 0.7835 - val_loss: 0.4165 - val_accuracy: 0.9646\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5232 - accuracy: 0.7965 - val_loss: 0.4853 - val_accuracy: 0.9747\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.4296 - accuracy: 0.8139 - val_loss: 0.6265 - val_accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 284us/step - loss: 0.5431 - accuracy: 0.7727 - val_loss: 0.4912 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a44194630>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 340us/step\n",
      "over-sampling test accuracy: 94.44%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2, 1,\n",
       "       2, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 1, 1,\n",
       "       2, 1, 1, 2, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 2, 0, 2, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 0,\n",
       "       2, 2, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 0, 1, 2,\n",
       "       0, 2, 2, 0, 0, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2,\n",
       "       0, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CFBREBSa103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS188</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS209     2     2\n",
       "1      BCH-SA-09     1     1\n",
       "2         NRS224     0     0\n",
       "3         NRS209     2     2\n",
       "4         NRS235     1     1\n",
       "..           ...   ...   ...\n",
       "193       NRS209     2     2\n",
       "194  CFBREBSa131     1     1\n",
       "195  CFBREBSa103     0     0\n",
       "196       NRS188     1     1\n",
       "197       NRS148     2     2\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.618598e-08</td>\n",
       "      <td>3.613115e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.141211e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.190622e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.118812e-13</td>\n",
       "      <td>2.544858e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.618598e-08</td>\n",
       "      <td>3.613115e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.248625e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>1.258703e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.618598e-08</td>\n",
       "      <td>3.613115e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3.175916e-02</td>\n",
       "      <td>9.307808e-01</td>\n",
       "      <td>3.745997e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.680168e-13</td>\n",
       "      <td>5.076824e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.261245e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.079788e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.076633e-09</td>\n",
       "      <td>3.887265e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    3.618598e-08  3.613115e-08  9.999999e-01\n",
       "1    2.141211e-08  1.000000e+00  4.190622e-09\n",
       "2    1.000000e+00  3.118812e-13  2.544858e-14\n",
       "3    3.618598e-08  3.613115e-08  9.999999e-01\n",
       "4    1.248625e-06  9.999988e-01  1.258703e-09\n",
       "..            ...           ...           ...\n",
       "193  3.618598e-08  3.613115e-08  9.999999e-01\n",
       "194  3.175916e-02  9.307808e-01  3.745997e-02\n",
       "195  1.000000e+00  3.680168e-13  5.076824e-14\n",
       "196  5.261245e-12  1.000000e+00  4.079788e-13\n",
       "197  3.076633e-09  3.887265e-08  1.000000e+00\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.6228 - accuracy: 0.7944 - val_loss: 0.7755 - val_accuracy: 0.9394\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.5683 - accuracy: 0.8074 - val_loss: 1.1025 - val_accuracy: 0.9242\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.5511 - accuracy: 0.8117 - val_loss: 0.9267 - val_accuracy: 0.9394\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.6326 - accuracy: 0.7706 - val_loss: 0.7069 - val_accuracy: 0.9394\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 329us/step - loss: 0.5060 - accuracy: 0.8052 - val_loss: 0.8987 - val_accuracy: 0.9343\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 301us/step - loss: 0.5383 - accuracy: 0.8117 - val_loss: 0.7937 - val_accuracy: 0.9394\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 263us/step - loss: 0.5536 - accuracy: 0.8009 - val_loss: 0.9154 - val_accuracy: 0.9343\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.6086 - accuracy: 0.7857 - val_loss: 0.6770 - val_accuracy: 0.9444\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.4113 - accuracy: 0.8268 - val_loss: 0.8323 - val_accuracy: 0.9394\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 400us/step - loss: 0.4892 - accuracy: 0.7944 - val_loss: 0.7562 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 368us/step - loss: 0.5500 - accuracy: 0.7727 - val_loss: 1.0439 - val_accuracy: 0.9293\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 258us/step - loss: 0.5368 - accuracy: 0.7706 - val_loss: 0.7762 - val_accuracy: 0.9394\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.5237 - accuracy: 0.7879 - val_loss: 0.7088 - val_accuracy: 0.9444\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.4927 - accuracy: 0.7987 - val_loss: 0.9379 - val_accuracy: 0.9343\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 322us/step - loss: 0.4046 - accuracy: 0.8095 - val_loss: 0.8688 - val_accuracy: 0.9394\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 279us/step - loss: 0.5118 - accuracy: 0.7879 - val_loss: 0.7235 - val_accuracy: 0.9343\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.5335 - accuracy: 0.7684 - val_loss: 0.7768 - val_accuracy: 0.9394\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 0.4611 - accuracy: 0.8074 - val_loss: 0.7587 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.5212 - accuracy: 0.7641 - val_loss: 0.7269 - val_accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.5076 - accuracy: 0.7900 - val_loss: 0.7696 - val_accuracy: 0.9293\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.4876 - accuracy: 0.7944 - val_loss: 0.8758 - val_accuracy: 0.9343\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 370us/step - loss: 0.4661 - accuracy: 0.7944 - val_loss: 0.8331 - val_accuracy: 0.9394\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 384us/step - loss: 0.5292 - accuracy: 0.8030 - val_loss: 0.7800 - val_accuracy: 0.9343\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.4989 - accuracy: 0.8009 - val_loss: 0.5610 - val_accuracy: 0.9646\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 0.5118 - accuracy: 0.7749 - val_loss: 0.6432 - val_accuracy: 0.9545\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.5873 - accuracy: 0.7727 - val_loss: 1.1585 - val_accuracy: 0.9192\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.5574 - accuracy: 0.7965 - val_loss: 0.7450 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 394us/step - loss: 0.5791 - accuracy: 0.7857 - val_loss: 0.6273 - val_accuracy: 0.9596\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 220us/step - loss: 0.4718 - accuracy: 0.7900 - val_loss: 0.8447 - val_accuracy: 0.9343\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 194us/step - loss: 0.4584 - accuracy: 0.7900 - val_loss: 0.8244 - val_accuracy: 0.9394\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 365us/step - loss: 0.5202 - accuracy: 0.8009 - val_loss: 1.0338 - val_accuracy: 0.9293\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 285us/step - loss: 0.5580 - accuracy: 0.7532 - val_loss: 0.9361 - val_accuracy: 0.9343\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 484us/step - loss: 0.5283 - accuracy: 0.7857 - val_loss: 0.5818 - val_accuracy: 0.9596\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 670us/step - loss: 0.6703 - accuracy: 0.7792 - val_loss: 1.0015 - val_accuracy: 0.9343\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 510us/step - loss: 0.4985 - accuracy: 0.8225 - val_loss: 0.6867 - val_accuracy: 0.9495\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 344us/step - loss: 0.4875 - accuracy: 0.8182 - val_loss: 0.6475 - val_accuracy: 0.9495\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.5386 - accuracy: 0.7814 - val_loss: 0.9436 - val_accuracy: 0.9394\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.5358 - accuracy: 0.7944 - val_loss: 0.9269 - val_accuracy: 0.9343\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 514us/step - loss: 0.4572 - accuracy: 0.8160 - val_loss: 0.5876 - val_accuracy: 0.9596\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.4097 - accuracy: 0.8095 - val_loss: 0.7792 - val_accuracy: 0.9444\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 282us/step - loss: 0.5041 - accuracy: 0.7987 - val_loss: 0.7504 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.4167 - accuracy: 0.7944 - val_loss: 0.6671 - val_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.4755 - accuracy: 0.7900 - val_loss: 0.6314 - val_accuracy: 0.9495\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.4222 - accuracy: 0.8182 - val_loss: 0.7777 - val_accuracy: 0.9343\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.4389 - accuracy: 0.8095 - val_loss: 0.8454 - val_accuracy: 0.9343\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.4002 - accuracy: 0.7944 - val_loss: 0.7827 - val_accuracy: 0.9394\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.5336 - accuracy: 0.7835 - val_loss: 0.6398 - val_accuracy: 0.9495\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.3903 - accuracy: 0.8290 - val_loss: 0.5649 - val_accuracy: 0.9596\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 427us/step - loss: 0.4752 - accuracy: 0.8052 - val_loss: 1.0371 - val_accuracy: 0.9343\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 844us/step - loss: 0.4704 - accuracy: 0.7749 - val_loss: 0.5472 - val_accuracy: 0.9646\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 319us/step - loss: 0.4155 - accuracy: 0.7987 - val_loss: 0.8121 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.5393 - accuracy: 0.7532 - val_loss: 1.0061 - val_accuracy: 0.9293\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 0.4612 - accuracy: 0.7835 - val_loss: 0.5600 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 391us/step - loss: 0.4147 - accuracy: 0.7965 - val_loss: 0.9226 - val_accuracy: 0.9293\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 257us/step - loss: 0.4593 - accuracy: 0.8052 - val_loss: 1.0446 - val_accuracy: 0.9343\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.5473 - accuracy: 0.7944 - val_loss: 1.2722 - val_accuracy: 0.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.4510 - accuracy: 0.7965 - val_loss: 0.5794 - val_accuracy: 0.9646\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 496us/step - loss: 0.4428 - accuracy: 0.8009 - val_loss: 0.8526 - val_accuracy: 0.9343\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 380us/step - loss: 0.4729 - accuracy: 0.7792 - val_loss: 0.7002 - val_accuracy: 0.9495\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 471us/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.7377 - val_accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 0.4446 - accuracy: 0.7900 - val_loss: 0.7849 - val_accuracy: 0.9343\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.4475 - accuracy: 0.8247 - val_loss: 1.1224 - val_accuracy: 0.9141\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 251us/step - loss: 0.4427 - accuracy: 0.7835 - val_loss: 0.7286 - val_accuracy: 0.9444\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.4100 - accuracy: 0.8290 - val_loss: 0.6457 - val_accuracy: 0.9495\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.4348 - accuracy: 0.7857 - val_loss: 0.6532 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.3975 - accuracy: 0.7554 - val_loss: 0.8278 - val_accuracy: 0.9343\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.4364 - accuracy: 0.8009 - val_loss: 0.7894 - val_accuracy: 0.9394\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 0.3902 - accuracy: 0.8268 - val_loss: 0.7635 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.4279 - accuracy: 0.7922 - val_loss: 0.6595 - val_accuracy: 0.9495\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 0.4491 - accuracy: 0.7987 - val_loss: 0.9496 - val_accuracy: 0.9394\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.4878 - accuracy: 0.8203 - val_loss: 0.6375 - val_accuracy: 0.9596\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.5268 - accuracy: 0.7987 - val_loss: 0.7453 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 422us/step - loss: 0.5203 - accuracy: 0.7814 - val_loss: 1.0030 - val_accuracy: 0.9242\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 553us/step - loss: 0.5568 - accuracy: 0.7727 - val_loss: 0.7917 - val_accuracy: 0.9394\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 0.4335 - accuracy: 0.7987 - val_loss: 0.8950 - val_accuracy: 0.9293\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 446us/step - loss: 0.4282 - accuracy: 0.8009 - val_loss: 0.6174 - val_accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 408us/step - loss: 0.4503 - accuracy: 0.7922 - val_loss: 0.8841 - val_accuracy: 0.9394\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 644us/step - loss: 0.4270 - accuracy: 0.7987 - val_loss: 0.6776 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 474us/step - loss: 0.4317 - accuracy: 0.7835 - val_loss: 0.7586 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 323us/step - loss: 0.4609 - accuracy: 0.7771 - val_loss: 0.5350 - val_accuracy: 0.9596\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 454us/step - loss: 0.3850 - accuracy: 0.8160 - val_loss: 0.9558 - val_accuracy: 0.9293\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 339us/step - loss: 0.4177 - accuracy: 0.8095 - val_loss: 0.9483 - val_accuracy: 0.9192\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.4587 - accuracy: 0.7922 - val_loss: 0.6301 - val_accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 0.4666 - accuracy: 0.8052 - val_loss: 0.7481 - val_accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.6006 - accuracy: 0.7706 - val_loss: 0.8193 - val_accuracy: 0.9394\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 379us/step - loss: 0.4894 - accuracy: 0.7965 - val_loss: 0.6784 - val_accuracy: 0.9545\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 387us/step - loss: 0.5622 - accuracy: 0.7771 - val_loss: 1.0025 - val_accuracy: 0.9293\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.4783 - accuracy: 0.7857 - val_loss: 0.6214 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.4638 - accuracy: 0.8160 - val_loss: 0.9511 - val_accuracy: 0.9242\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 298us/step - loss: 0.4443 - accuracy: 0.7792 - val_loss: 0.6836 - val_accuracy: 0.9545\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.4213 - accuracy: 0.7944 - val_loss: 0.7447 - val_accuracy: 0.9394\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.4402 - accuracy: 0.7922 - val_loss: 0.9166 - val_accuracy: 0.9343\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.3656 - accuracy: 0.7814 - val_loss: 0.7541 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 192us/step - loss: 0.3932 - accuracy: 0.7987 - val_loss: 0.7335 - val_accuracy: 0.9495\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.4098 - accuracy: 0.7879 - val_loss: 0.8295 - val_accuracy: 0.9343\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.4435 - accuracy: 0.7814 - val_loss: 0.7911 - val_accuracy: 0.9343\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.4146 - accuracy: 0.8203 - val_loss: 0.7375 - val_accuracy: 0.9495\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 0.4058 - accuracy: 0.7965 - val_loss: 0.7912 - val_accuracy: 0.9343\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 0.4298 - accuracy: 0.7835 - val_loss: 0.6898 - val_accuracy: 0.9596\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 190us/step - loss: 0.4233 - accuracy: 0.7922 - val_loss: 0.9167 - val_accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.45%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [2.14121060e-08, 1.00000000e+00, 4.19062160e-09],\n",
       "       [1.00000000e+00, 3.11881220e-13, 2.54485810e-14],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.24862460e-06, 9.99998800e-01, 1.25870260e-09],\n",
       "       [5.89275330e-08, 1.00000000e+00, 1.16629400e-08],\n",
       "       [7.93851700e-10, 1.00000000e+00, 4.46804200e-11],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [1.24862460e-06, 9.99998800e-01, 1.25870260e-09],\n",
       "       [4.61083830e-08, 1.00000000e+00, 9.74188900e-09],\n",
       "       [1.00000000e+00, 7.10465000e-17, 3.45499450e-18],\n",
       "       [1.00000000e+00, 1.83221940e-11, 2.10740700e-12],\n",
       "       [1.00000000e+00, 3.96622180e-10, 5.42163470e-11],\n",
       "       [7.93851700e-10, 1.00000000e+00, 4.46804200e-11],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.21688700e-12, 5.59174600e-13],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.63974990e-10, 1.00000000e+00, 1.97347950e-11],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.56132450e-21, 1.14395460e-22],\n",
       "       [7.23787100e-01, 2.76058550e-01, 1.54340470e-04],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.33531085e-14, 1.00000000e+00, 6.27972070e-16],\n",
       "       [1.00000000e+00, 3.31455970e-10, 4.48542660e-11],\n",
       "       [3.01720200e-07, 9.99999640e-01, 3.05706070e-08],\n",
       "       [1.00000000e+00, 1.36551660e-19, 1.20470050e-20],\n",
       "       [2.48102450e-09, 1.00000000e+00, 3.91594120e-10],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.12917650e-07, 9.99999640e-01, 3.12162200e-08],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.29302510e-08, 1.00000000e+00, 2.40637980e-09],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.08717390e-12, 1.46360190e-13],\n",
       "       [1.00000000e+00, 4.08397650e-13, 3.79401240e-14],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.77148530e-15, 1.00000000e+00, 1.56342050e-16],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [2.17922530e-04, 9.99781400e-01, 7.27158640e-07],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [2.29822670e-08, 1.00000000e+00, 4.52981160e-09],\n",
       "       [2.14121060e-08, 1.00000000e+00, 4.19062160e-09],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [9.72311300e-01, 2.76882240e-02, 5.17735770e-07],\n",
       "       [6.55417170e-12, 1.00000000e+00, 5.72044300e-13],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.15596640e-09, 2.56529000e-12],\n",
       "       [1.00000000e+00, 4.16849300e-16, 4.34172680e-17],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.77953700e-12, 6.23055200e-13],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [9.99999900e-01, 5.96149800e-08, 2.23072200e-09],\n",
       "       [1.00000000e+00, 1.13199776e-10, 8.34268150e-13],\n",
       "       [1.00000000e+00, 1.08847320e-11, 1.58755640e-12],\n",
       "       [1.00000000e+00, 2.10700400e-13, 2.71023290e-14],\n",
       "       [9.98995000e-01, 8.03144530e-04, 2.01905700e-04],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.26060740e-11, 3.87367570e-12],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.38750930e-15, 1.36957220e-16],\n",
       "       [1.32769780e-09, 1.00000000e+00, 1.96881480e-10],\n",
       "       [1.00000000e+00, 5.86023360e-13, 7.92881600e-14],\n",
       "       [2.48102450e-09, 1.00000000e+00, 3.91594120e-10],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.33531085e-14, 1.00000000e+00, 6.27972070e-16],\n",
       "       [1.00000000e+00, 2.39906500e-17, 2.30159280e-18],\n",
       "       [1.00000000e+00, 4.70653620e-11, 8.50377500e-12],\n",
       "       [6.11958350e-09, 1.00000000e+00, 1.05695330e-09],\n",
       "       [2.42671500e-07, 9.99999640e-01, 6.05148600e-08],\n",
       "       [3.07088270e-12, 1.00000000e+00, 2.02216620e-13],\n",
       "       [1.33531085e-14, 1.00000000e+00, 6.27972070e-16],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [4.04007140e-09, 1.00000000e+00, 6.69462430e-10],\n",
       "       [2.14121060e-08, 1.00000000e+00, 4.19062160e-09],\n",
       "       [6.17897850e-07, 9.99999050e-01, 3.31889500e-07],\n",
       "       [1.00000000e+00, 3.03334860e-18, 3.00902970e-19],\n",
       "       [1.00000000e+00, 2.41218900e-16, 2.88117960e-17],\n",
       "       [5.89275330e-08, 1.00000000e+00, 1.16629400e-08],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [1.00000000e+00, 3.62602200e-10, 3.86044530e-11],\n",
       "       [1.00000000e+00, 1.08717390e-12, 1.46360190e-13],\n",
       "       [1.00000000e+00, 1.12199750e-11, 1.84073370e-12],\n",
       "       [1.00000000e+00, 1.56306670e-11, 1.37257710e-12],\n",
       "       [1.00000000e+00, 6.24105400e-17, 2.25474380e-18],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [6.11958350e-09, 1.00000000e+00, 1.05695330e-09],\n",
       "       [1.00000000e+00, 7.48364700e-11, 9.31535700e-12],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [1.24862460e-06, 9.99998800e-01, 1.25870260e-09],\n",
       "       [9.99999900e-01, 8.01944200e-08, 2.10951820e-08],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.64199180e-10, 6.40168800e-11],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.77148530e-15, 1.00000000e+00, 1.56342050e-16],\n",
       "       [1.00000000e+00, 5.20446440e-08, 9.35532700e-09],\n",
       "       [3.07088270e-12, 1.00000000e+00, 2.02216620e-13],\n",
       "       [4.04007140e-09, 1.00000000e+00, 6.69462430e-10],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [7.93851700e-10, 1.00000000e+00, 4.46804200e-11],\n",
       "       [3.91159530e-06, 9.99994750e-01, 1.25749240e-06],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.17292740e-10, 1.00000000e+00, 1.36523310e-11],\n",
       "       [3.12917650e-07, 9.99999640e-01, 3.12162200e-08],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [4.61083830e-08, 1.00000000e+00, 9.74188900e-09],\n",
       "       [2.29822670e-08, 1.00000000e+00, 4.52981160e-09],\n",
       "       [1.00000000e+00, 6.89068640e-10, 4.98117280e-11],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.08717390e-12, 1.46360190e-13],\n",
       "       [1.61152470e-01, 8.38847500e-01, 3.00169670e-08],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [4.54602700e-06, 9.99995470e-01, 5.38893100e-10],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.82737100e-10, 1.77553880e-12],\n",
       "       [9.99998700e-01, 1.25740620e-06, 1.35889190e-08],\n",
       "       [1.00000000e+00, 3.43783020e-11, 5.11739830e-12],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.32769780e-09, 1.00000000e+00, 1.96881480e-10],\n",
       "       [2.48102450e-09, 1.00000000e+00, 3.91594120e-10],\n",
       "       [1.00000000e+00, 3.90344660e-12, 4.31961300e-14],\n",
       "       [7.81243800e-12, 1.00000000e+00, 6.93918560e-13],\n",
       "       [9.99999900e-01, 8.82811900e-08, 8.48451900e-10],\n",
       "       [3.12917650e-07, 9.99999640e-01, 3.12162200e-08],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.31141750e-11, 5.14464430e-12],\n",
       "       [1.00000000e+00, 8.90012150e-09, 3.69929530e-10],\n",
       "       [3.01720200e-07, 9.99999640e-01, 3.05706070e-08],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.75602950e-15, 1.02882330e-15],\n",
       "       [5.24208800e-10, 1.00000000e+00, 7.08486100e-11],\n",
       "       [1.00000000e+00, 8.67200500e-13, 1.70776480e-14],\n",
       "       [5.26126450e-12, 1.00000000e+00, 4.07980340e-13],\n",
       "       [1.00000000e+00, 3.97791340e-13, 5.97342100e-14],\n",
       "       [4.04007140e-09, 1.00000000e+00, 6.69462430e-10],\n",
       "       [9.92967100e-01, 5.89167500e-03, 1.14124080e-03],\n",
       "       [3.77148530e-15, 1.00000000e+00, 1.56342050e-16],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.19565380e-17, 3.30021390e-18],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.07662100e-09, 3.88725000e-08, 1.00000000e+00],\n",
       "       [9.98536600e-01, 1.46293300e-03, 4.54698350e-07],\n",
       "       [1.00000000e+00, 3.24242370e-11, 3.85088300e-12],\n",
       "       [7.81243800e-12, 1.00000000e+00, 6.93918560e-13],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [2.48102450e-09, 1.00000000e+00, 3.91594120e-10],\n",
       "       [1.00000000e+00, 3.41888000e-11, 2.18327840e-13],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.32769780e-09, 1.00000000e+00, 1.96881480e-10],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [5.89275330e-08, 1.00000000e+00, 1.16629400e-08],\n",
       "       [3.77148530e-15, 1.00000000e+00, 1.56342050e-16],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [7.02423450e-10, 1.00000000e+00, 9.77486100e-11],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [9.99999900e-01, 8.99671000e-08, 1.64547450e-09],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.83106200e-09, 1.43693970e-09],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.17531200e-15, 2.23935100e-16],\n",
       "       [1.00000000e+00, 1.14647010e-16, 1.15893550e-17],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.44846440e-17, 1.97508040e-18],\n",
       "       [7.81243800e-12, 1.00000000e+00, 6.93918560e-13],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.70175770e-12, 2.75845940e-13],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [7.77428840e-10, 1.11817710e-08, 1.00000000e+00],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [4.04007140e-09, 1.00000000e+00, 6.69462430e-10],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [2.14121060e-08, 1.00000000e+00, 4.19062160e-09],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [2.14121060e-08, 1.00000000e+00, 4.19062160e-09],\n",
       "       [3.61859800e-08, 3.61311500e-08, 9.99999900e-01],\n",
       "       [3.17591580e-02, 9.30780800e-01, 3.74599730e-02],\n",
       "       [1.00000000e+00, 3.68016840e-13, 5.07682380e-14],\n",
       "       [5.26124460e-12, 1.00000000e+00, 4.07978800e-13],\n",
       "       [3.07663270e-09, 3.88726500e-08, 1.00000000e+00]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906450872359963"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906450872359963"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0    CFBREBSa116     0\n",
       "1         NRS214     0\n",
       "2         NRS148     2\n",
       "3         NRS148     2\n",
       "4         NRS148     2\n",
       "..           ...   ...\n",
       "193       NRS148     2\n",
       "194       NRS054     0\n",
       "195       NRS109     2\n",
       "196       NRS216     1\n",
       "197    BCH-SA-03     1\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 841us/step - loss: 4.0770 - accuracy: 0.5779 - val_loss: 0.9237 - val_accuracy: 0.7020\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 234us/step - loss: 3.4172 - accuracy: 0.6602 - val_loss: 0.8772 - val_accuracy: 0.7323\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 404us/step - loss: 3.1248 - accuracy: 0.6775 - val_loss: 0.8833 - val_accuracy: 0.7576\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 396us/step - loss: 3.3125 - accuracy: 0.6472 - val_loss: 1.2084 - val_accuracy: 0.7576\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 255us/step - loss: 3.0191 - accuracy: 0.6732 - val_loss: 1.1903 - val_accuracy: 0.7626\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 2.7613 - accuracy: 0.6948 - val_loss: 1.9376 - val_accuracy: 0.7778\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 665us/step - loss: 2.8846 - accuracy: 0.6818 - val_loss: 1.6932 - val_accuracy: 0.7778\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 455us/step - loss: 2.8019 - accuracy: 0.7013 - val_loss: 1.5670 - val_accuracy: 0.7475\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 880us/step - loss: 2.8096 - accuracy: 0.6861 - val_loss: 1.2590 - val_accuracy: 0.7980\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 533us/step - loss: 2.5449 - accuracy: 0.6797 - val_loss: 1.5417 - val_accuracy: 0.8131\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 2.4816 - accuracy: 0.7013 - val_loss: 1.5794 - val_accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 608us/step - loss: 2.3357 - accuracy: 0.7489 - val_loss: 1.2081 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 494us/step - loss: 2.1602 - accuracy: 0.7381 - val_loss: 1.4737 - val_accuracy: 0.8384\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 444us/step - loss: 2.1489 - accuracy: 0.7359 - val_loss: 1.3067 - val_accuracy: 0.8384\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 2.1408 - accuracy: 0.7316 - val_loss: 1.2775 - val_accuracy: 0.8535\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 2.1445 - accuracy: 0.7229 - val_loss: 1.5310 - val_accuracy: 0.8434\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 355us/step - loss: 2.1302 - accuracy: 0.6710 - val_loss: 1.6810 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 606us/step - loss: 1.9276 - accuracy: 0.7294 - val_loss: 1.5581 - val_accuracy: 0.8283\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 1.8451 - accuracy: 0.7338 - val_loss: 1.4886 - val_accuracy: 0.8131\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 1.6681 - accuracy: 0.7424 - val_loss: 1.5321 - val_accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 351us/step - loss: 1.7777 - accuracy: 0.7100 - val_loss: 1.1289 - val_accuracy: 0.8636\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.4310 - accuracy: 0.7511 - val_loss: 1.5651 - val_accuracy: 0.8384\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 277us/step - loss: 1.6496 - accuracy: 0.7511 - val_loss: 1.4854 - val_accuracy: 0.8535\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 288us/step - loss: 1.5470 - accuracy: 0.7446 - val_loss: 1.3104 - val_accuracy: 0.8687\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 1.3364 - accuracy: 0.7554 - val_loss: 1.1009 - val_accuracy: 0.8687\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.1738 - accuracy: 0.7792 - val_loss: 1.4057 - val_accuracy: 0.8636\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 206us/step - loss: 1.2916 - accuracy: 0.7944 - val_loss: 1.1682 - val_accuracy: 0.8788\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 198us/step - loss: 1.3385 - accuracy: 0.7554 - val_loss: 0.9188 - val_accuracy: 0.8939\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.3160 - accuracy: 0.7468 - val_loss: 1.2471 - val_accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 189us/step - loss: 1.2512 - accuracy: 0.7597 - val_loss: 0.9621 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 197us/step - loss: 1.1544 - accuracy: 0.7619 - val_loss: 1.2504 - val_accuracy: 0.8939\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 225us/step - loss: 1.1364 - accuracy: 0.7771 - val_loss: 1.0298 - val_accuracy: 0.8636\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 244us/step - loss: 1.0534 - accuracy: 0.7771 - val_loss: 0.8261 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 1.2354 - accuracy: 0.7727 - val_loss: 1.1136 - val_accuracy: 0.8232\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 1.1818 - accuracy: 0.7489 - val_loss: 2.1433 - val_accuracy: 0.7980\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 1.2675 - accuracy: 0.7684 - val_loss: 1.2972 - val_accuracy: 0.8737\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 196us/step - loss: 0.9536 - accuracy: 0.7944 - val_loss: 0.7523 - val_accuracy: 0.8788\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.0432 - accuracy: 0.7814 - val_loss: 0.9025 - val_accuracy: 0.8687\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 199us/step - loss: 1.1086 - accuracy: 0.7554 - val_loss: 0.9042 - val_accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 193us/step - loss: 1.1759 - accuracy: 0.7316 - val_loss: 1.0671 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 1.1407 - accuracy: 0.7403 - val_loss: 0.8360 - val_accuracy: 0.8990\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 348us/step - loss: 0.9664 - accuracy: 0.7792 - val_loss: 1.0412 - val_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 375us/step - loss: 0.8938 - accuracy: 0.7727 - val_loss: 0.9215 - val_accuracy: 0.8939\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.8429 - accuracy: 0.7987 - val_loss: 0.8172 - val_accuracy: 0.9343\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.9292 - accuracy: 0.7641 - val_loss: 1.0318 - val_accuracy: 0.8535\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 230us/step - loss: 0.9421 - accuracy: 0.7814 - val_loss: 0.8705 - val_accuracy: 0.8990\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.8510 - accuracy: 0.7511 - val_loss: 0.6122 - val_accuracy: 0.9444\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 399us/step - loss: 0.8592 - accuracy: 0.7792 - val_loss: 0.5166 - val_accuracy: 0.9192\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.8121 - accuracy: 0.7641 - val_loss: 0.8011 - val_accuracy: 0.8535\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.6629 - accuracy: 0.8377 - val_loss: 0.5892 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.9554 - accuracy: 0.7684 - val_loss: 0.9651 - val_accuracy: 0.9293\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 1.0207 - accuracy: 0.7771 - val_loss: 0.5212 - val_accuracy: 0.9495\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 261us/step - loss: 0.8444 - accuracy: 0.7857 - val_loss: 0.6388 - val_accuracy: 0.9394\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 334us/step - loss: 0.8186 - accuracy: 0.7662 - val_loss: 0.7806 - val_accuracy: 0.9394\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 310us/step - loss: 0.7727 - accuracy: 0.7944 - val_loss: 0.5016 - val_accuracy: 0.9495\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 572us/step - loss: 0.7200 - accuracy: 0.7922 - val_loss: 0.6532 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 381us/step - loss: 0.6941 - accuracy: 0.7944 - val_loss: 0.6686 - val_accuracy: 0.9293\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 422us/step - loss: 0.8144 - accuracy: 0.7554 - val_loss: 0.4744 - val_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 267us/step - loss: 0.6599 - accuracy: 0.8182 - val_loss: 0.5971 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.6926 - accuracy: 0.8074 - val_loss: 0.5227 - val_accuracy: 0.9394\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 229us/step - loss: 0.7958 - accuracy: 0.7792 - val_loss: 0.5680 - val_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 571us/step - loss: 0.5803 - accuracy: 0.7987 - val_loss: 0.4787 - val_accuracy: 0.9394\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.7285 - accuracy: 0.7771 - val_loss: 0.8289 - val_accuracy: 0.9394\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.6752 - accuracy: 0.7965 - val_loss: 0.9087 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.6893 - accuracy: 0.8160 - val_loss: 0.7149 - val_accuracy: 0.9394\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 270us/step - loss: 0.7168 - accuracy: 0.7900 - val_loss: 0.4997 - val_accuracy: 0.9343\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.6610 - accuracy: 0.7857 - val_loss: 0.7071 - val_accuracy: 0.9394\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 512us/step - loss: 0.6910 - accuracy: 0.7814 - val_loss: 1.0845 - val_accuracy: 0.9293\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.7310 - accuracy: 0.7922 - val_loss: 0.5604 - val_accuracy: 0.9192\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 204us/step - loss: 0.6325 - accuracy: 0.7987 - val_loss: 0.4290 - val_accuracy: 0.9646\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.6612 - accuracy: 0.7814 - val_loss: 0.7749 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.7019 - accuracy: 0.8225 - val_loss: 0.5168 - val_accuracy: 0.9495\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 208us/step - loss: 0.6016 - accuracy: 0.8095 - val_loss: 0.4671 - val_accuracy: 0.9495\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 201us/step - loss: 0.7765 - accuracy: 0.7792 - val_loss: 0.4750 - val_accuracy: 0.9545\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.6542 - accuracy: 0.8052 - val_loss: 0.7111 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 254us/step - loss: 0.7164 - accuracy: 0.7771 - val_loss: 0.4636 - val_accuracy: 0.9141\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 207us/step - loss: 0.6579 - accuracy: 0.7879 - val_loss: 0.7680 - val_accuracy: 0.9394\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 210us/step - loss: 0.6332 - accuracy: 0.7879 - val_loss: 0.4034 - val_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.6133 - accuracy: 0.7879 - val_loss: 0.5703 - val_accuracy: 0.9495\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 209us/step - loss: 0.6390 - accuracy: 0.8009 - val_loss: 0.4014 - val_accuracy: 0.9596\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 290us/step - loss: 0.5396 - accuracy: 0.7944 - val_loss: 0.4807 - val_accuracy: 0.9495\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 253us/step - loss: 0.5739 - accuracy: 0.7684 - val_loss: 0.3654 - val_accuracy: 0.9646\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 235us/step - loss: 0.6414 - accuracy: 0.8074 - val_loss: 0.6424 - val_accuracy: 0.9091\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.4603 - accuracy: 0.8030 - val_loss: 0.4341 - val_accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 216us/step - loss: 0.6396 - accuracy: 0.7965 - val_loss: 0.3557 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 200us/step - loss: 0.6376 - accuracy: 0.7706 - val_loss: 0.5429 - val_accuracy: 0.9495\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.6109 - accuracy: 0.7771 - val_loss: 0.7543 - val_accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.5522 - accuracy: 0.7879 - val_loss: 0.3258 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.6141 - accuracy: 0.8052 - val_loss: 0.8055 - val_accuracy: 0.9394\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.5065 - accuracy: 0.7554 - val_loss: 0.4045 - val_accuracy: 0.9596\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4994 - accuracy: 0.7965 - val_loss: 0.3676 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.5473 - accuracy: 0.7965 - val_loss: 0.6561 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 212us/step - loss: 0.5799 - accuracy: 0.8074 - val_loss: 0.5914 - val_accuracy: 0.9394\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 205us/step - loss: 0.3923 - accuracy: 0.8377 - val_loss: 0.2910 - val_accuracy: 0.9394\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 247us/step - loss: 0.5384 - accuracy: 0.8139 - val_loss: 0.5837 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 211us/step - loss: 0.5929 - accuracy: 0.7749 - val_loss: 0.5010 - val_accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 271us/step - loss: 0.5241 - accuracy: 0.8312 - val_loss: 0.5940 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 295us/step - loss: 0.4668 - accuracy: 0.8139 - val_loss: 0.5981 - val_accuracy: 0.9343\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.5629 - accuracy: 0.8009 - val_loss: 0.7197 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 223us/step - loss: 0.5526 - accuracy: 0.7814 - val_loss: 0.8035 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4468b5f8>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s 164us/step\n",
      "over-sampling test accuracy: 95.96%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 2, 1, 0, 2, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 2,\n",
       "       2, 2, 2, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 2, 2,\n",
       "       1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0,\n",
       "       2, 1, 1, 2, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 2, 1, 1, 2, 2, 2, 2, 0,\n",
       "       0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 0, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
       "       2, 0, 2, 1, 0, 0, 1, 2, 1, 0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NRS054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0    CFBREBSa116     0     0\n",
       "1         NRS214     0     0\n",
       "2         NRS148     2     2\n",
       "3         NRS148     2     2\n",
       "4         NRS148     2     2\n",
       "..           ...   ...   ...\n",
       "193       NRS148     2     2\n",
       "194       NRS054     0     1\n",
       "195       NRS109     2     2\n",
       "196       NRS216     1     1\n",
       "197    BCH-SA-03     1     1\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.325985e-11</td>\n",
       "      <td>6.464015e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.727631e-07</td>\n",
       "      <td>2.922883e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.915769e-09</td>\n",
       "      <td>1.829717e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.915769e-09</td>\n",
       "      <td>1.829717e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.915769e-09</td>\n",
       "      <td>1.829717e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.915772e-09</td>\n",
       "      <td>1.829721e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.625608e-01</td>\n",
       "      <td>5.088866e-01</td>\n",
       "      <td>2.855253e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>6.087012e-09</td>\n",
       "      <td>6.090844e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>7.759023e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.633419e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.571714e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.872320e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.000000e+00  4.325985e-11  6.464015e-12\n",
       "1    9.999999e-01  1.727631e-07  2.922883e-08\n",
       "2    1.915769e-09  1.829717e-09  1.000000e+00\n",
       "3    1.915769e-09  1.829717e-09  1.000000e+00\n",
       "4    1.915769e-09  1.829717e-09  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "193  1.915772e-09  1.829721e-09  1.000000e+00\n",
       "194  4.625608e-01  5.088866e-01  2.855253e-02\n",
       "195  6.087012e-09  6.090844e-09  1.000000e+00\n",
       "196  7.759023e-12  1.000000e+00  1.633419e-11\n",
       "197  2.571714e-15  1.000000e+00  6.872320e-15\n",
       "\n",
       "[198 rows x 3 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p002yp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 462 samples, validate on 198 samples\n",
      "Epoch 1/100\n",
      "462/462 [==============================] - 0s 313us/step - loss: 0.5796 - accuracy: 0.7771 - val_loss: 0.4017 - val_accuracy: 0.9596\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.6698 - accuracy: 0.7987 - val_loss: 0.8864 - val_accuracy: 0.9242\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - 0s 245us/step - loss: 0.6863 - accuracy: 0.7835 - val_loss: 0.5297 - val_accuracy: 0.9242\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.5979 - accuracy: 0.7857 - val_loss: 0.7192 - val_accuracy: 0.9394\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.5544 - accuracy: 0.7965 - val_loss: 0.8611 - val_accuracy: 0.9343\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.6128 - accuracy: 0.7987 - val_loss: 0.4887 - val_accuracy: 0.9343\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - 0s 324us/step - loss: 0.8326 - accuracy: 0.7749 - val_loss: 0.7987 - val_accuracy: 0.8990\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.6569 - accuracy: 0.8247 - val_loss: 0.8271 - val_accuracy: 0.9343\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - 0s 297us/step - loss: 0.5392 - accuracy: 0.8095 - val_loss: 0.4209 - val_accuracy: 0.9545\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - 0s 239us/step - loss: 0.7034 - accuracy: 0.7532 - val_loss: 0.5019 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - 0s 259us/step - loss: 0.6642 - accuracy: 0.7771 - val_loss: 0.5820 - val_accuracy: 0.9394\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - 0s 272us/step - loss: 0.4601 - accuracy: 0.8247 - val_loss: 0.4053 - val_accuracy: 0.9545\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - 0s 303us/step - loss: 0.5169 - accuracy: 0.7987 - val_loss: 0.6140 - val_accuracy: 0.9394\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - 0s 262us/step - loss: 0.4980 - accuracy: 0.8074 - val_loss: 0.3725 - val_accuracy: 0.9596\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.5877 - accuracy: 0.7900 - val_loss: 0.8530 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.6382 - accuracy: 0.7944 - val_loss: 0.3457 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - 0s 308us/step - loss: 0.5232 - accuracy: 0.8074 - val_loss: 0.8266 - val_accuracy: 0.9343\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - 0s 264us/step - loss: 0.5868 - accuracy: 0.7749 - val_loss: 0.5281 - val_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - 0s 266us/step - loss: 0.5601 - accuracy: 0.7922 - val_loss: 0.5544 - val_accuracy: 0.9495\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.5260 - accuracy: 0.7900 - val_loss: 0.6203 - val_accuracy: 0.9495\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.5865 - accuracy: 0.7944 - val_loss: 0.5051 - val_accuracy: 0.9495\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - 0s 327us/step - loss: 0.4448 - accuracy: 0.8030 - val_loss: 0.4145 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 0s 273us/step - loss: 0.6011 - accuracy: 0.7771 - val_loss: 0.3581 - val_accuracy: 0.9545\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - 0s 265us/step - loss: 0.5467 - accuracy: 0.8117 - val_loss: 0.8941 - val_accuracy: 0.9293\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 0s 241us/step - loss: 0.5357 - accuracy: 0.7965 - val_loss: 0.6481 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 0s 248us/step - loss: 0.5323 - accuracy: 0.8095 - val_loss: 0.3751 - val_accuracy: 0.9646\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - 0s 242us/step - loss: 0.5440 - accuracy: 0.7792 - val_loss: 0.4819 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.4873 - accuracy: 0.8095 - val_loss: 0.4309 - val_accuracy: 0.9596\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 0s 320us/step - loss: 0.5174 - accuracy: 0.8139 - val_loss: 0.8143 - val_accuracy: 0.9394\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.5106 - accuracy: 0.8074 - val_loss: 0.4027 - val_accuracy: 0.9596\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 0s 238us/step - loss: 0.5502 - accuracy: 0.7879 - val_loss: 0.4767 - val_accuracy: 0.9545\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - 0s 232us/step - loss: 0.5267 - accuracy: 0.7987 - val_loss: 0.8947 - val_accuracy: 0.9343\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - 0s 307us/step - loss: 0.5053 - accuracy: 0.7900 - val_loss: 0.4250 - val_accuracy: 0.9596\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 0s 278us/step - loss: 0.5436 - accuracy: 0.8030 - val_loss: 0.8134 - val_accuracy: 0.9394\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 0s 219us/step - loss: 0.5432 - accuracy: 0.7749 - val_loss: 0.5402 - val_accuracy: 0.9545\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.5321 - accuracy: 0.8030 - val_loss: 0.3272 - val_accuracy: 0.9646\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - 0s 228us/step - loss: 0.5644 - accuracy: 0.7792 - val_loss: 0.3814 - val_accuracy: 0.9596\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 0s 215us/step - loss: 0.4013 - accuracy: 0.8030 - val_loss: 0.8734 - val_accuracy: 0.9394\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 0s 280us/step - loss: 0.5139 - accuracy: 0.7835 - val_loss: 0.3187 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - 0s 283us/step - loss: 0.5100 - accuracy: 0.7706 - val_loss: 0.7547 - val_accuracy: 0.9343\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 0s 306us/step - loss: 0.5816 - accuracy: 0.7944 - val_loss: 0.6102 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - 0s 256us/step - loss: 0.6059 - accuracy: 0.7749 - val_loss: 0.6725 - val_accuracy: 0.9495\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4789 - accuracy: 0.7879 - val_loss: 0.6969 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 0s 289us/step - loss: 0.4871 - accuracy: 0.8355 - val_loss: 0.8052 - val_accuracy: 0.9444\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 0s 309us/step - loss: 0.6013 - accuracy: 0.7944 - val_loss: 0.3418 - val_accuracy: 0.9495\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 0s 240us/step - loss: 0.4843 - accuracy: 0.7879 - val_loss: 0.5527 - val_accuracy: 0.9495\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.8040 - accuracy: 0.7619 - val_loss: 1.0755 - val_accuracy: 0.9242\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 0s 218us/step - loss: 0.5342 - accuracy: 0.8009 - val_loss: 0.9076 - val_accuracy: 0.9394\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.6324 - accuracy: 0.7922 - val_loss: 0.3763 - val_accuracy: 0.9545\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.5301 - accuracy: 0.7922 - val_loss: 0.9939 - val_accuracy: 0.9293\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.6528 - accuracy: 0.7922 - val_loss: 0.7758 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - 0s 222us/step - loss: 0.6912 - accuracy: 0.7511 - val_loss: 0.5744 - val_accuracy: 0.9545\n",
      "Epoch 53/100\n",
      "462/462 [==============================] - 0s 226us/step - loss: 0.6443 - accuracy: 0.7857 - val_loss: 0.6501 - val_accuracy: 0.9545\n",
      "Epoch 54/100\n",
      "462/462 [==============================] - 0s 227us/step - loss: 0.5337 - accuracy: 0.7814 - val_loss: 0.7160 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "462/462 [==============================] - 0s 243us/step - loss: 0.4489 - accuracy: 0.7965 - val_loss: 0.5536 - val_accuracy: 0.9545\n",
      "Epoch 56/100\n",
      "462/462 [==============================] - 0s 315us/step - loss: 0.4408 - accuracy: 0.8225 - val_loss: 0.7482 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "462/462 [==============================] - 0s 250us/step - loss: 0.4498 - accuracy: 0.8182 - val_loss: 0.4518 - val_accuracy: 0.9596\n",
      "Epoch 58/100\n",
      "462/462 [==============================] - 0s 331us/step - loss: 0.4961 - accuracy: 0.7792 - val_loss: 0.7045 - val_accuracy: 0.9495\n",
      "Epoch 59/100\n",
      "462/462 [==============================] - 0s 501us/step - loss: 0.4649 - accuracy: 0.7965 - val_loss: 0.5898 - val_accuracy: 0.9545\n",
      "Epoch 60/100\n",
      "462/462 [==============================] - 0s 321us/step - loss: 0.5044 - accuracy: 0.7662 - val_loss: 0.7685 - val_accuracy: 0.9444\n",
      "Epoch 61/100\n",
      "462/462 [==============================] - 0s 203us/step - loss: 0.4076 - accuracy: 0.8074 - val_loss: 0.5753 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "462/462 [==============================] - 0s 274us/step - loss: 0.4119 - accuracy: 0.8052 - val_loss: 0.3661 - val_accuracy: 0.9697\n",
      "Epoch 63/100\n",
      "462/462 [==============================] - 0s 453us/step - loss: 0.4403 - accuracy: 0.8117 - val_loss: 1.0949 - val_accuracy: 0.9242\n",
      "Epoch 64/100\n",
      "462/462 [==============================] - 0s 656us/step - loss: 0.4709 - accuracy: 0.8225 - val_loss: 0.4058 - val_accuracy: 0.9596\n",
      "Epoch 65/100\n",
      "462/462 [==============================] - 0s 276us/step - loss: 0.4889 - accuracy: 0.7792 - val_loss: 0.5603 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.4026 - accuracy: 0.8225 - val_loss: 0.5019 - val_accuracy: 0.9545\n",
      "Epoch 67/100\n",
      "462/462 [==============================] - 0s 563us/step - loss: 0.4247 - accuracy: 0.8030 - val_loss: 0.8269 - val_accuracy: 0.9495\n",
      "Epoch 68/100\n",
      "462/462 [==============================] - 0s 755us/step - loss: 0.4907 - accuracy: 0.7835 - val_loss: 0.6946 - val_accuracy: 0.9545\n",
      "Epoch 69/100\n",
      "462/462 [==============================] - 0s 421us/step - loss: 0.4605 - accuracy: 0.7641 - val_loss: 0.6379 - val_accuracy: 0.9495\n",
      "Epoch 70/100\n",
      "462/462 [==============================] - 0s 269us/step - loss: 0.4534 - accuracy: 0.8182 - val_loss: 0.6787 - val_accuracy: 0.9495\n",
      "Epoch 71/100\n",
      "462/462 [==============================] - 0s 224us/step - loss: 0.4482 - accuracy: 0.7965 - val_loss: 0.4074 - val_accuracy: 0.9646\n",
      "Epoch 72/100\n",
      "462/462 [==============================] - 0s 214us/step - loss: 0.5054 - accuracy: 0.7900 - val_loss: 0.6301 - val_accuracy: 0.9495\n",
      "Epoch 73/100\n",
      "462/462 [==============================] - 0s 382us/step - loss: 0.4692 - accuracy: 0.8117 - val_loss: 0.7314 - val_accuracy: 0.9495\n",
      "Epoch 74/100\n",
      "462/462 [==============================] - 0s 499us/step - loss: 0.4984 - accuracy: 0.7857 - val_loss: 0.7854 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "462/462 [==============================] - 0s 932us/step - loss: 0.3990 - accuracy: 0.8333 - val_loss: 0.9090 - val_accuracy: 0.9242\n",
      "Epoch 76/100\n",
      "462/462 [==============================] - 0s 569us/step - loss: 0.4809 - accuracy: 0.7857 - val_loss: 0.4520 - val_accuracy: 0.9646\n",
      "Epoch 77/100\n",
      "462/462 [==============================] - 0s 427us/step - loss: 0.4452 - accuracy: 0.7922 - val_loss: 0.5729 - val_accuracy: 0.9596\n",
      "Epoch 78/100\n",
      "462/462 [==============================] - 0s 311us/step - loss: 0.4401 - accuracy: 0.7879 - val_loss: 0.9254 - val_accuracy: 0.9242\n",
      "Epoch 79/100\n",
      "462/462 [==============================] - 0s 281us/step - loss: 0.4409 - accuracy: 0.8052 - val_loss: 0.4724 - val_accuracy: 0.9646\n",
      "Epoch 80/100\n",
      "462/462 [==============================] - 0s 571us/step - loss: 0.4221 - accuracy: 0.8095 - val_loss: 0.9959 - val_accuracy: 0.9242\n",
      "Epoch 81/100\n",
      "462/462 [==============================] - 0s 412us/step - loss: 0.4867 - accuracy: 0.8052 - val_loss: 0.5527 - val_accuracy: 0.9596\n",
      "Epoch 82/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 0.5143 - accuracy: 0.7944 - val_loss: 0.8697 - val_accuracy: 0.9394\n",
      "Epoch 83/100\n",
      "462/462 [==============================] - 0s 305us/step - loss: 0.4444 - accuracy: 0.7944 - val_loss: 0.9527 - val_accuracy: 0.9394\n",
      "Epoch 84/100\n",
      "462/462 [==============================] - 0s 275us/step - loss: 0.4046 - accuracy: 0.8117 - val_loss: 0.8985 - val_accuracy: 0.9394\n",
      "Epoch 85/100\n",
      "462/462 [==============================] - 0s 324us/step - loss: 0.4185 - accuracy: 0.7922 - val_loss: 0.7392 - val_accuracy: 0.9495\n",
      "Epoch 86/100\n",
      "462/462 [==============================] - 0s 437us/step - loss: 0.4567 - accuracy: 0.7662 - val_loss: 0.8043 - val_accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "462/462 [==============================] - 0s 345us/step - loss: 0.3880 - accuracy: 0.7987 - val_loss: 0.6656 - val_accuracy: 0.9545\n",
      "Epoch 88/100\n",
      "462/462 [==============================] - 0s 328us/step - loss: 0.4541 - accuracy: 0.7965 - val_loss: 0.8212 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "462/462 [==============================] - 0s 300us/step - loss: 0.4189 - accuracy: 0.7987 - val_loss: 0.5359 - val_accuracy: 0.9545\n",
      "Epoch 90/100\n",
      "462/462 [==============================] - 0s 249us/step - loss: 0.6486 - accuracy: 0.7511 - val_loss: 0.4478 - val_accuracy: 0.9596\n",
      "Epoch 91/100\n",
      "462/462 [==============================] - 0s 286us/step - loss: 0.4786 - accuracy: 0.8095 - val_loss: 0.9995 - val_accuracy: 0.9343\n",
      "Epoch 92/100\n",
      "462/462 [==============================] - 0s 735us/step - loss: 0.4717 - accuracy: 0.8290 - val_loss: 0.6514 - val_accuracy: 0.9495\n",
      "Epoch 93/100\n",
      "462/462 [==============================] - 0s 532us/step - loss: 0.4512 - accuracy: 0.8139 - val_loss: 0.5467 - val_accuracy: 0.9646\n",
      "Epoch 94/100\n",
      "462/462 [==============================] - 0s 551us/step - loss: 0.4012 - accuracy: 0.8117 - val_loss: 0.6274 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "462/462 [==============================] - 0s 431us/step - loss: 0.4199 - accuracy: 0.7727 - val_loss: 0.8737 - val_accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "462/462 [==============================] - 0s 385us/step - loss: 0.3917 - accuracy: 0.8009 - val_loss: 0.4995 - val_accuracy: 0.9545\n",
      "Epoch 97/100\n",
      "462/462 [==============================] - 0s 410us/step - loss: 0.4049 - accuracy: 0.8052 - val_loss: 0.5091 - val_accuracy: 0.9596\n",
      "Epoch 98/100\n",
      "462/462 [==============================] - 0s 395us/step - loss: 0.4076 - accuracy: 0.7922 - val_loss: 0.7673 - val_accuracy: 0.9495\n",
      "Epoch 99/100\n",
      "462/462 [==============================] - 0s 414us/step - loss: 0.4823 - accuracy: 0.7857 - val_loss: 0.7515 - val_accuracy: 0.9495\n",
      "Epoch 100/100\n",
      "462/462 [==============================] - 0s 491us/step - loss: 0.4192 - accuracy: 0.8009 - val_loss: 0.4420 - val_accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.51%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.32598470e-11, 6.46401470e-12],\n",
       "       [9.99999900e-01, 1.72763110e-07, 2.92288300e-08],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [7.75903700e-12, 1.00000000e+00, 1.63342480e-11],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.17938640e-11, 3.22324570e-12],\n",
       "       [9.99999900e-01, 1.26572430e-07, 5.35242870e-09],\n",
       "       [8.39436960e-08, 9.99999900e-01, 2.54192580e-08],\n",
       "       [1.00000000e+00, 3.93525350e-09, 6.29118900e-10],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [8.39436960e-08, 9.99999900e-01, 2.54192580e-08],\n",
       "       [9.99998200e-01, 1.51068930e-06, 2.62199700e-07],\n",
       "       [3.28353660e-11, 1.00000000e+00, 3.15474080e-12],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [4.02108620e-11, 1.00000000e+00, 8.64265460e-11],\n",
       "       [9.82808350e-15, 1.00000000e+00, 2.56772520e-14],\n",
       "       [9.99998900e-01, 1.05711100e-06, 1.63448200e-08],\n",
       "       [1.00000000e+00, 2.61718250e-09, 4.15853160e-10],\n",
       "       [5.97272800e-17, 1.00000000e+00, 1.29530550e-16],\n",
       "       [3.97458330e-17, 1.00000000e+00, 6.33426000e-17],\n",
       "       [9.99999400e-01, 6.18102000e-07, 1.54960920e-08],\n",
       "       [2.64823050e-16, 1.00000000e+00, 7.19575400e-16],\n",
       "       [1.00000000e+00, 7.21221560e-16, 9.13948000e-17],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.29763490e-16, 1.00000000e+00, 1.73344830e-17],\n",
       "       [1.00000000e+00, 1.65014360e-11, 2.43036200e-12],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [3.42456990e-07, 9.99999500e-01, 1.09752060e-07],\n",
       "       [1.00000000e+00, 4.84600540e-09, 7.77138240e-10],\n",
       "       [3.02524250e-14, 1.00000000e+00, 5.33683900e-14],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [9.59585100e-01, 4.02329560e-02, 1.81988200e-04],\n",
       "       [9.99999640e-01, 2.98240340e-07, 1.00956250e-08],\n",
       "       [9.99999900e-01, 1.17360486e-07, 1.97409600e-08],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.77051360e-19, 3.89939760e-20],\n",
       "       [3.28353660e-11, 1.00000000e+00, 3.15474080e-12],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [5.97272800e-17, 1.00000000e+00, 1.29530550e-16],\n",
       "       [2.43121060e-08, 1.00000000e+00, 7.00306170e-09],\n",
       "       [3.24349350e-15, 1.00000000e+00, 6.77450340e-15],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [4.83385800e-16, 1.00000000e+00, 1.25118910e-15],\n",
       "       [1.00000000e+00, 1.70228930e-09, 2.68746030e-10],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.11868414e-13, 1.00000000e+00, 2.14275770e-13],\n",
       "       [2.57172330e-15, 1.00000000e+00, 6.87234600e-15],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.52332760e-10, 1.00000000e+00, 1.28828740e-10],\n",
       "       [9.99999900e-01, 9.02579100e-08, 1.51833890e-09],\n",
       "       [1.00000000e+00, 1.11118340e-10, 1.68399630e-11],\n",
       "       [2.80569250e-06, 9.99996200e-01, 9.78798700e-07],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.50131120e-09, 2.36571180e-10],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [2.57172330e-15, 1.00000000e+00, 6.87234600e-15],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [5.97272800e-17, 1.00000000e+00, 1.29530550e-16],\n",
       "       [1.00000000e+00, 7.42597900e-10, 1.15788344e-10],\n",
       "       [1.00000000e+00, 2.13662180e-11, 3.15905800e-12],\n",
       "       [1.53015420e-09, 1.00000000e+00, 3.94231310e-10],\n",
       "       [1.53015420e-09, 1.00000000e+00, 3.94231310e-10],\n",
       "       [1.29763490e-16, 1.00000000e+00, 1.73344830e-17],\n",
       "       [1.00000000e+00, 3.66120400e-12, 5.27205070e-13],\n",
       "       [1.00000000e+00, 1.32831400e-08, 1.84485950e-09],\n",
       "       [1.11868414e-13, 1.00000000e+00, 2.14275770e-13],\n",
       "       [9.99999900e-01, 8.80165500e-08, 1.10326910e-08],\n",
       "       [1.00000000e+00, 1.64157270e-08, 2.68108740e-09],\n",
       "       [4.02108620e-11, 1.00000000e+00, 8.64265460e-11],\n",
       "       [1.68945360e-10, 1.00000000e+00, 3.13447700e-10],\n",
       "       [1.00000000e+00, 2.20144450e-08, 3.61132920e-09],\n",
       "       [6.30824500e-08, 9.99999900e-01, 1.91761120e-09],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.11868414e-13, 1.00000000e+00, 2.14275770e-13],\n",
       "       [9.98716350e-01, 1.28282050e-03, 8.03524800e-07],\n",
       "       [2.64823050e-16, 1.00000000e+00, 7.19575400e-16],\n",
       "       [2.27249330e-14, 1.00000000e+00, 5.86984000e-14],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [1.00000000e+00, 4.53583800e-09, 7.26676600e-10],\n",
       "       [1.00000000e+00, 4.18175260e-12, 6.03363100e-13],\n",
       "       [3.28353660e-11, 1.00000000e+00, 3.15474080e-12],\n",
       "       [9.59634800e-02, 4.74946680e-01, 4.29089870e-01],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.40449730e-08, 1.25091140e-09],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [9.99608700e-01, 3.90774420e-04, 6.53925200e-07],\n",
       "       [6.47858600e-10, 1.00000000e+00, 8.73593400e-10],\n",
       "       [3.42456990e-07, 9.99999500e-01, 1.09752060e-07],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.68945360e-10, 1.00000000e+00, 3.13447700e-10],\n",
       "       [2.25796700e-06, 9.99994750e-01, 2.96129860e-06],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [5.19732650e-10, 1.00000000e+00, 2.33733870e-10],\n",
       "       [2.21538510e-07, 9.99999640e-01, 1.75576100e-07],\n",
       "       [5.97272800e-17, 1.00000000e+00, 1.29530550e-16],\n",
       "       [1.00000000e+00, 2.01779070e-08, 3.00630300e-09],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [8.39436960e-08, 9.99999900e-01, 2.54192580e-08],\n",
       "       [1.09897775e-13, 1.00000000e+00, 2.79912130e-13],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.80044200e-09, 1.09611210e-09],\n",
       "       [6.17168500e-17, 1.00000000e+00, 1.47104130e-16],\n",
       "       [1.12165220e-06, 9.99998700e-01, 2.09240580e-07],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [9.82808350e-15, 1.00000000e+00, 2.56772520e-14],\n",
       "       [1.00000000e+00, 7.03930970e-10, 3.37223700e-11],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [3.02524250e-14, 1.00000000e+00, 5.33683900e-14],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [9.99558400e-01, 4.39629950e-04, 1.93387270e-06],\n",
       "       [1.00000000e+00, 9.72169400e-09, 5.12999100e-10],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [3.28353660e-11, 1.00000000e+00, 3.15474080e-12],\n",
       "       [1.00000000e+00, 5.81882600e-12, 8.43732040e-13],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [4.83385800e-16, 1.00000000e+00, 1.25118910e-15],\n",
       "       [9.99969360e-01, 3.05133400e-05, 1.18725550e-07],\n",
       "       [1.00000000e+00, 3.92199730e-13, 5.46175200e-14],\n",
       "       [4.79882100e-16, 1.00000000e+00, 9.07597400e-16],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.41812610e-09, 2.04459770e-10],\n",
       "       [1.00000000e+00, 4.06763430e-10, 6.28547700e-11],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [8.39436960e-08, 9.99999900e-01, 2.54192580e-08],\n",
       "       [1.00000000e+00, 5.89810000e-10, 8.29825400e-11],\n",
       "       [1.00000000e+00, 2.50379200e-08, 2.24188910e-09],\n",
       "       [9.01559950e-01, 9.80998800e-02, 3.40126540e-04],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [4.02108620e-11, 1.00000000e+00, 8.64265460e-11],\n",
       "       [1.11868414e-13, 1.00000000e+00, 2.14275770e-13],\n",
       "       [7.75903700e-12, 1.00000000e+00, 1.63342480e-11],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [9.99999170e-01, 7.34739600e-07, 1.27031260e-07],\n",
       "       [1.00000000e+00, 1.31346540e-11, 1.92789900e-12],\n",
       "       [8.75570450e-13, 1.00000000e+00, 2.53936110e-13],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [3.24349350e-15, 1.00000000e+00, 6.77450340e-15],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [2.91288870e-07, 9.99999760e-01, 1.87242420e-10],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.77823560e-01, 8.16181700e-01, 5.99468360e-03],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.11868414e-13, 1.00000000e+00, 2.14275770e-13],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [9.99994300e-01, 4.88639670e-06, 8.22231500e-07],\n",
       "       [5.40744030e-09, 5.52454570e-09, 1.00000000e+00],\n",
       "       [1.68945360e-10, 1.00000000e+00, 3.13447700e-10],\n",
       "       [1.00000000e+00, 2.67552900e-13, 3.70464000e-14],\n",
       "       [1.00000000e+00, 4.32302150e-12, 6.24056630e-13],\n",
       "       [2.57172330e-15, 1.00000000e+00, 6.87234600e-15],\n",
       "       [1.91576890e-09, 1.82971730e-09, 1.00000000e+00],\n",
       "       [8.76563200e-09, 1.00000000e+00, 2.42313100e-09],\n",
       "       [9.35645040e-01, 6.43127800e-02, 4.21796180e-05],\n",
       "       [9.99993700e-01, 6.25821440e-06, 1.33140590e-07],\n",
       "       [6.24773300e-14, 1.00000000e+00, 1.21067540e-13],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.78865260e-08, 2.81557090e-09],\n",
       "       [9.93080100e-02, 8.49688900e-01, 5.10030950e-02],\n",
       "       [6.08697700e-09, 6.09082100e-09, 1.00000000e+00],\n",
       "       [9.99999760e-01, 2.90749880e-07, 4.14715800e-09],\n",
       "       [1.91577240e-09, 1.82972070e-09, 1.00000000e+00],\n",
       "       [4.62560830e-01, 5.08886600e-01, 2.85525300e-02],\n",
       "       [6.08701200e-09, 6.09084430e-09, 1.00000000e+00],\n",
       "       [7.75902300e-12, 1.00000000e+00, 1.63341860e-11],\n",
       "       [2.57171360e-15, 1.00000000e+00, 6.87231970e-15]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p002ypresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788988368533823"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788988368533823"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881724441383533"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005392709700076941"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9881724441383533"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005392709700076941"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 94.82%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.01571956877289432\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 79.52%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.00096449774\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
