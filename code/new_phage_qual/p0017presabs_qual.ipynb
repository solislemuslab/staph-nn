{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0017presabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7157)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0017presabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    0\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_1598</th>\n",
       "      <th>group_1744</th>\n",
       "      <th>group_4749</th>\n",
       "      <th>group_6727</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9205</th>\n",
       "      <th>group_9474</th>\n",
       "      <th>group_9475</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_1598  group_1744  group_4749  group_6727  group_8892  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           1           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_9205  group_9474  group_9475  group_9858  pheno  \n",
       "0           0           0           0           0      2  \n",
       "1           0           0           0           0      0  \n",
       "2           0           0           0           0      2  \n",
       "3           0           0           0           0      2  \n",
       "4           0           0           0           0      2  \n",
       "\n",
       "[5 rows x 7157 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 7156)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG</th>\n",
       "      <th>TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA</th>\n",
       "      <th>TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT</th>\n",
       "      <th>TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA</th>\n",
       "      <th>TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC</th>\n",
       "      <th>TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT</th>\n",
       "      <th>TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC</th>\n",
       "      <th>TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA</th>\n",
       "      <th>TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA</th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_1598</th>\n",
       "      <th>group_1744</th>\n",
       "      <th>group_4749</th>\n",
       "      <th>group_6727</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9205</th>\n",
       "      <th>group_9474</th>\n",
       "      <th>group_9475</th>\n",
       "      <th>group_9858</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAG  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCTCGCTACAATTTACAAATGGACTTGTTATCAACGTTAGGGCAATAAATGAAAGTAGTATAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCTTATTATACGAAATTTTCATATCATAGTAAAGTTTTTTACGAAAAAAACGTATTTAATGTTGACAATACGAAAATTTCGTATTATATTAGGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTCGTAAAAAACTTTACTATGATATGAAAATTTCGTATAATAAGAAAAAAAGGAGGTAAGTAATATGAACAAAGAAAGAAATATTATTATAGCCA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTGCAATTTTTTATTTTCATTATAAACTTCCTTTCAAACACTGCTGAAATAGACGTCTTTTTCAAATAAGCATGATTAATACTTCAATTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATTTTACTCACCTCTAAAGCATAATTCCATATAAACTTGTTATTATCCGAAATTTTTGTATAATAGATTATTTTTGTTGGAGTAATTATTAGT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATTATAATTAAAGTTTTCCATTGTTTTCCTCCTATAATAGCTTATCTGCAATCATCACAGCTAATAAATCGTTTTGTCTTATTGCTTC  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTATGTTATAATCTTTCTAGACGTATTCAAAGGACGTCTTTTTAGATTGTATGTTATAGCTAGCCTTCCGGTTAATTTTTTGTTATGATGTGTTA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTTATAACATTCAAAGTCTCACCATTGTCATTTGAATGATCATCAATAATAATTAATTCGTAATCAGTACTCTTCATTGTTTGATTTAATACAGAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_1598  group_1744  group_4749  group_6727  group_8892  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           1           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_9205  group_9474  group_9475  group_9858  pheno  \n",
       "0           0           0           0           0      2  \n",
       "1           0           0           0           0      0  \n",
       "2           0           0           0           0      2  \n",
       "3           0           0           0           0      2  \n",
       "4           0           0           0           0      2  \n",
       "\n",
       "[5 rows x 7156 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 7156) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "112       NRS027     1\n",
       "207       NRS246     1\n",
       "186       NRS218     2\n",
       "88      CFBRSa70     2\n",
       "156       NRS177     1\n",
       "..           ...   ...\n",
       "244       SR3585     0\n",
       "99       GA50819     2\n",
       "147       NRS161     2\n",
       "49   CFBREBSa114     1\n",
       "140       NRS114     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.2350 - accuracy: 0.3672 - val_loss: 1.1179 - val_accuracy: 0.3553\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 540us/step - loss: 1.0526 - accuracy: 0.4689 - val_loss: 1.0122 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 1.0044 - accuracy: 0.5141 - val_loss: 0.9859 - val_accuracy: 0.5395\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 697us/step - loss: 0.9736 - accuracy: 0.5424 - val_loss: 0.9690 - val_accuracy: 0.5658\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 609us/step - loss: 0.9297 - accuracy: 0.5763 - val_loss: 0.9857 - val_accuracy: 0.5526\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.8880 - accuracy: 0.6045 - val_loss: 0.9637 - val_accuracy: 0.5132\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.8694 - accuracy: 0.6610 - val_loss: 0.9661 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.8728 - accuracy: 0.6441 - val_loss: 0.9654 - val_accuracy: 0.5395\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 594us/step - loss: 0.8417 - accuracy: 0.6667 - val_loss: 0.9865 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.8071 - accuracy: 0.7062 - val_loss: 1.0061 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.7776 - accuracy: 0.6610 - val_loss: 0.9917 - val_accuracy: 0.5132\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.7585 - accuracy: 0.6949 - val_loss: 0.9299 - val_accuracy: 0.5395\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.7495 - accuracy: 0.7288 - val_loss: 0.9822 - val_accuracy: 0.5395\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 530us/step - loss: 0.7313 - accuracy: 0.7458 - val_loss: 0.9858 - val_accuracy: 0.5526\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 624us/step - loss: 0.7003 - accuracy: 0.7232 - val_loss: 1.0030 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.6974 - accuracy: 0.6949 - val_loss: 1.0076 - val_accuracy: 0.4868\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.6770 - accuracy: 0.7401 - val_loss: 0.9814 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.6753 - accuracy: 0.7514 - val_loss: 0.9971 - val_accuracy: 0.5658\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.6544 - accuracy: 0.7345 - val_loss: 0.9711 - val_accuracy: 0.5395\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.6587 - accuracy: 0.7514 - val_loss: 1.0234 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 700us/step - loss: 0.6089 - accuracy: 0.7740 - val_loss: 1.0658 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.6114 - accuracy: 0.7401 - val_loss: 1.0201 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.6071 - accuracy: 0.7740 - val_loss: 1.0550 - val_accuracy: 0.5263\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 598us/step - loss: 0.5663 - accuracy: 0.7910 - val_loss: 1.0286 - val_accuracy: 0.5132\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 508us/step - loss: 0.6020 - accuracy: 0.7458 - val_loss: 1.0111 - val_accuracy: 0.5263\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 719us/step - loss: 0.5723 - accuracy: 0.8079 - val_loss: 1.0702 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 680us/step - loss: 0.5331 - accuracy: 0.8305 - val_loss: 1.1188 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 678us/step - loss: 0.5645 - accuracy: 0.7853 - val_loss: 1.0230 - val_accuracy: 0.5395\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.5321 - accuracy: 0.7627 - val_loss: 1.1330 - val_accuracy: 0.4737\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 618us/step - loss: 0.4888 - accuracy: 0.8305 - val_loss: 1.0360 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.4951 - accuracy: 0.8249 - val_loss: 1.0362 - val_accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.4520 - accuracy: 0.8531 - val_loss: 1.1823 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 671us/step - loss: 0.5042 - accuracy: 0.8475 - val_loss: 1.0596 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.4907 - accuracy: 0.8362 - val_loss: 1.0414 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 593us/step - loss: 0.4264 - accuracy: 0.8475 - val_loss: 1.1579 - val_accuracy: 0.5263\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 582us/step - loss: 0.4892 - accuracy: 0.8362 - val_loss: 1.0873 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.4197 - accuracy: 0.8814 - val_loss: 1.1071 - val_accuracy: 0.5132\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.4208 - accuracy: 0.8757 - val_loss: 1.1069 - val_accuracy: 0.5132\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 613us/step - loss: 0.4345 - accuracy: 0.8588 - val_loss: 1.0331 - val_accuracy: 0.5395\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 620us/step - loss: 0.4390 - accuracy: 0.8701 - val_loss: 1.0829 - val_accuracy: 0.5132\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.3870 - accuracy: 0.8757 - val_loss: 1.2179 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 611us/step - loss: 0.4048 - accuracy: 0.8757 - val_loss: 1.1064 - val_accuracy: 0.4868\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.3978 - accuracy: 0.8757 - val_loss: 1.0913 - val_accuracy: 0.4868\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.3606 - accuracy: 0.8983 - val_loss: 1.1332 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 671us/step - loss: 0.3277 - accuracy: 0.9096 - val_loss: 1.1647 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.3226 - accuracy: 0.9153 - val_loss: 1.1280 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8927 - val_loss: 1.1848 - val_accuracy: 0.5263\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.3142 - accuracy: 0.8983 - val_loss: 1.1688 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.2863 - accuracy: 0.9209 - val_loss: 1.1834 - val_accuracy: 0.4868\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.2808 - accuracy: 0.9266 - val_loss: 1.1849 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 592us/step - loss: 0.2785 - accuracy: 0.9209 - val_loss: 1.1977 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 716us/step - loss: 0.2652 - accuracy: 0.9266 - val_loss: 1.1533 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.2913 - accuracy: 0.9153 - val_loss: 1.2122 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 678us/step - loss: 0.2564 - accuracy: 0.9266 - val_loss: 1.2773 - val_accuracy: 0.4474\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 669us/step - loss: 0.2968 - accuracy: 0.8927 - val_loss: 1.2243 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.3010 - accuracy: 0.9096 - val_loss: 1.2071 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.2680 - accuracy: 0.9040 - val_loss: 1.3290 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 597us/step - loss: 0.2475 - accuracy: 0.9040 - val_loss: 1.2715 - val_accuracy: 0.4737\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 696us/step - loss: 0.2265 - accuracy: 0.9435 - val_loss: 1.2210 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 476us/step - loss: 0.2300 - accuracy: 0.9266 - val_loss: 1.2874 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.2266 - accuracy: 0.9322 - val_loss: 1.2809 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.2238 - accuracy: 0.9435 - val_loss: 1.2494 - val_accuracy: 0.4605\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.2404 - accuracy: 0.9096 - val_loss: 1.2892 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.2404 - accuracy: 0.9153 - val_loss: 1.3282 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.2236 - accuracy: 0.9379 - val_loss: 1.2793 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.2015 - accuracy: 0.9379 - val_loss: 1.3711 - val_accuracy: 0.5132\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1935 - accuracy: 0.9379 - val_loss: 1.4033 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.1829 - accuracy: 0.9605 - val_loss: 1.3150 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.2008 - accuracy: 0.9435 - val_loss: 1.3638 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.2048 - accuracy: 0.9379 - val_loss: 1.3936 - val_accuracy: 0.4868\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.1740 - accuracy: 0.9661 - val_loss: 1.3404 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1816 - accuracy: 0.9266 - val_loss: 1.3775 - val_accuracy: 0.5132\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.1690 - accuracy: 0.9605 - val_loss: 1.4068 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 347us/step - loss: 0.1705 - accuracy: 0.9605 - val_loss: 1.4089 - val_accuracy: 0.4868\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.1698 - accuracy: 0.9492 - val_loss: 1.4205 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1543 - accuracy: 0.9605 - val_loss: 1.4751 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1597 - accuracy: 0.9605 - val_loss: 1.4523 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1679 - accuracy: 0.9605 - val_loss: 1.4058 - val_accuracy: 0.4868\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1523 - accuracy: 0.9548 - val_loss: 1.4556 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.1525 - accuracy: 0.9605 - val_loss: 1.4836 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.1569 - accuracy: 0.9435 - val_loss: 1.4866 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.1564 - accuracy: 0.9492 - val_loss: 1.5377 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.1468 - accuracy: 0.9605 - val_loss: 1.5708 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1480 - accuracy: 0.9379 - val_loss: 1.5080 - val_accuracy: 0.4737\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.1452 - accuracy: 0.9492 - val_loss: 1.5906 - val_accuracy: 0.4868\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.1418 - accuracy: 0.9435 - val_loss: 1.5640 - val_accuracy: 0.5395\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1400 - accuracy: 0.9661 - val_loss: 1.5527 - val_accuracy: 0.4868\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.1465 - accuracy: 0.9435 - val_loss: 1.5586 - val_accuracy: 0.5263\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.1376 - accuracy: 0.9492 - val_loss: 1.6112 - val_accuracy: 0.5132\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.1521 - accuracy: 0.9435 - val_loss: 1.6210 - val_accuracy: 0.4868\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.1552 - accuracy: 0.9209 - val_loss: 1.7499 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 407us/step - loss: 0.1354 - accuracy: 0.9435 - val_loss: 1.6171 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.1334 - accuracy: 0.9379 - val_loss: 1.6452 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1332 - accuracy: 0.9548 - val_loss: 1.6591 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.1232 - accuracy: 0.9548 - val_loss: 1.5971 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 459us/step - loss: 0.1314 - accuracy: 0.9718 - val_loss: 1.7262 - val_accuracy: 0.5132\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 579us/step - loss: 0.1426 - accuracy: 0.9492 - val_loss: 1.6745 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.1258 - accuracy: 0.9774 - val_loss: 1.6069 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.1267 - accuracy: 0.9605 - val_loss: 1.7103 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.1189 - accuracy: 0.9661 - val_loss: 1.7862 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36fca198>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 174us/step\n",
      "test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test1 = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0,\n",
       "       1, 1, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 1,\n",
       "       2, 2, 1, 0, 2, 2, 2, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 2,\n",
       "       0, 2, 1, 1, 0, 0, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GA50819</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NRS161</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "112       NRS027     1     0\n",
       "207       NRS246     1     0\n",
       "186       NRS218     2     2\n",
       "88      CFBRSa70     2     0\n",
       "156       NRS177     1     1\n",
       "..           ...   ...   ...\n",
       "244       SR3585     0     0\n",
       "99       GA50819     2     0\n",
       "147       NRS161     2     1\n",
       "49   CFBREBSa114     1     0\n",
       "140       NRS114     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1.predict_proba(X_test)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897785</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.063568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.849721</td>\n",
       "      <td>0.078949</td>\n",
       "      <td>0.071330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.987734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.728429</td>\n",
       "      <td>0.046807</td>\n",
       "      <td>0.224764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.928673</td>\n",
       "      <td>0.060271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.426559</td>\n",
       "      <td>0.176919</td>\n",
       "      <td>0.396522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.010921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.360253</td>\n",
       "      <td>0.636501</td>\n",
       "      <td>0.003246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.997986</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.001724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.152902</td>\n",
       "      <td>0.351779</td>\n",
       "      <td>0.495319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.897785  0.038647  0.063568\n",
       "1   0.849721  0.078949  0.071330\n",
       "2   0.003935  0.008331  0.987734\n",
       "3   0.728429  0.046807  0.224764\n",
       "4   0.011056  0.928673  0.060271\n",
       "..       ...       ...       ...\n",
       "71  0.426559  0.176919  0.396522\n",
       "72  0.984176  0.004903  0.010921\n",
       "73  0.360253  0.636501  0.003246\n",
       "74  0.997986  0.000290  0.001724\n",
       "75  0.152902  0.351779  0.495319\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.0872 - accuracy: 0.9605 - val_loss: 2.1276 - val_accuracy: 0.5395\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0717 - accuracy: 0.9887 - val_loss: 2.0578 - val_accuracy: 0.5526\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 367us/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 2.1070 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.0746 - accuracy: 0.9831 - val_loss: 2.1571 - val_accuracy: 0.4868\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.0857 - accuracy: 0.9661 - val_loss: 2.1716 - val_accuracy: 0.5132\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.0979 - accuracy: 0.9605 - val_loss: 2.1281 - val_accuracy: 0.5395\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.1263 - accuracy: 0.9548 - val_loss: 2.1190 - val_accuracy: 0.5395\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.1957 - accuracy: 0.9605 - val_loss: 2.1834 - val_accuracy: 0.5263\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.1525 - accuracy: 0.9548 - val_loss: 2.2077 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.1092 - accuracy: 0.9548 - val_loss: 2.1683 - val_accuracy: 0.5263\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 375us/step - loss: 0.0821 - accuracy: 0.9661 - val_loss: 2.1326 - val_accuracy: 0.5263\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.0947 - accuracy: 0.9605 - val_loss: 2.1672 - val_accuracy: 0.5395\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.1055 - accuracy: 0.9605 - val_loss: 2.2029 - val_accuracy: 0.5395\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.1014 - accuracy: 0.9661 - val_loss: 2.2847 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.1007 - accuracy: 0.9548 - val_loss: 2.2112 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1175 - accuracy: 0.9492 - val_loss: 2.1684 - val_accuracy: 0.5526\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1002 - accuracy: 0.9605 - val_loss: 2.3176 - val_accuracy: 0.5263\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.2711 - accuracy: 0.9661 - val_loss: 2.2414 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0748 - accuracy: 0.9718 - val_loss: 2.3479 - val_accuracy: 0.4737\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.0880 - accuracy: 0.9774 - val_loss: 2.3167 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 606us/step - loss: 0.1061 - accuracy: 0.9435 - val_loss: 2.3213 - val_accuracy: 0.4737\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 2.3293 - val_accuracy: 0.5263\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 561us/step - loss: 0.1045 - accuracy: 0.9492 - val_loss: 2.3465 - val_accuracy: 0.5263\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.1018 - accuracy: 0.9661 - val_loss: 2.3419 - val_accuracy: 0.5132\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.1034 - accuracy: 0.9548 - val_loss: 2.4241 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.0870 - accuracy: 0.9605 - val_loss: 2.3867 - val_accuracy: 0.5263\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.0834 - accuracy: 0.9661 - val_loss: 2.3972 - val_accuracy: 0.5132\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 406us/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 2.3765 - val_accuracy: 0.5263\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.0745 - accuracy: 0.9718 - val_loss: 2.3595 - val_accuracy: 0.5526\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 578us/step - loss: 0.0766 - accuracy: 0.9718 - val_loss: 2.3869 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.0744 - accuracy: 0.9774 - val_loss: 2.4029 - val_accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 2.3784 - val_accuracy: 0.5526\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 553us/step - loss: 0.0716 - accuracy: 0.9718 - val_loss: 2.3971 - val_accuracy: 0.5132\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.0830 - accuracy: 0.9548 - val_loss: 2.3855 - val_accuracy: 0.5526\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.0718 - accuracy: 0.9661 - val_loss: 2.4107 - val_accuracy: 0.5526\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.0794 - accuracy: 0.9661 - val_loss: 2.3897 - val_accuracy: 0.5395\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.0857 - accuracy: 0.9718 - val_loss: 2.3901 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.0801 - accuracy: 0.9605 - val_loss: 2.4562 - val_accuracy: 0.5263\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 2.4456 - val_accuracy: 0.5132\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 541us/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 2.4407 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 417us/step - loss: 0.0726 - accuracy: 0.9774 - val_loss: 2.4567 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.0721 - accuracy: 0.9605 - val_loss: 2.4609 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0683 - accuracy: 0.9774 - val_loss: 2.5147 - val_accuracy: 0.5263\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.0614 - accuracy: 0.9718 - val_loss: 2.5208 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.0652 - accuracy: 0.9718 - val_loss: 2.5206 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0696 - accuracy: 0.9718 - val_loss: 2.5169 - val_accuracy: 0.5132\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.0793 - accuracy: 0.9661 - val_loss: 2.5007 - val_accuracy: 0.5132\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 2.5364 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.0869 - accuracy: 0.9718 - val_loss: 2.5150 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.0880 - accuracy: 0.9605 - val_loss: 2.5472 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0741 - accuracy: 0.9661 - val_loss: 2.5299 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 2.5301 - val_accuracy: 0.5132\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.0580 - accuracy: 0.9831 - val_loss: 2.5376 - val_accuracy: 0.5263\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 2.5929 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.0679 - accuracy: 0.9718 - val_loss: 2.5856 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.0634 - accuracy: 0.9831 - val_loss: 2.5588 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.0634 - accuracy: 0.9718 - val_loss: 2.5443 - val_accuracy: 0.5263\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 654us/step - loss: 0.0587 - accuracy: 0.9774 - val_loss: 2.5746 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 716us/step - loss: 0.0630 - accuracy: 0.9718 - val_loss: 2.5923 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 704us/step - loss: 0.0552 - accuracy: 0.9774 - val_loss: 2.5751 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 581us/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 2.5963 - val_accuracy: 0.4868\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 725us/step - loss: 0.1026 - accuracy: 0.9548 - val_loss: 2.6196 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.0960 - accuracy: 0.9605 - val_loss: 2.6310 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.1976 - accuracy: 0.9661 - val_loss: 2.5986 - val_accuracy: 0.5526\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.1676 - accuracy: 0.9661 - val_loss: 2.6147 - val_accuracy: 0.5132\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.0994 - accuracy: 0.9661 - val_loss: 2.6153 - val_accuracy: 0.5526\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.0686 - accuracy: 0.9661 - val_loss: 2.6648 - val_accuracy: 0.5395\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0723 - accuracy: 0.9661 - val_loss: 2.7271 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.0718 - accuracy: 0.9605 - val_loss: 2.6837 - val_accuracy: 0.5526\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0703 - accuracy: 0.9661 - val_loss: 2.6998 - val_accuracy: 0.5526\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.0720 - accuracy: 0.9605 - val_loss: 2.6881 - val_accuracy: 0.5658\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 845us/step - loss: 0.0658 - accuracy: 0.9774 - val_loss: 2.6943 - val_accuracy: 0.5395\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 744us/step - loss: 0.0651 - accuracy: 0.9774 - val_loss: 2.6693 - val_accuracy: 0.5789\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 785us/step - loss: 0.0609 - accuracy: 0.9718 - val_loss: 2.6982 - val_accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.0652 - accuracy: 0.9718 - val_loss: 2.6908 - val_accuracy: 0.5132\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.0605 - accuracy: 0.9774 - val_loss: 2.6840 - val_accuracy: 0.5395\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.0605 - accuracy: 0.9718 - val_loss: 2.6943 - val_accuracy: 0.5263\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.0554 - accuracy: 0.9774 - val_loss: 2.6969 - val_accuracy: 0.5526\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 2.7141 - val_accuracy: 0.5658\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 0.0615 - accuracy: 0.9661 - val_loss: 2.7159 - val_accuracy: 0.5526\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.0628 - accuracy: 0.9718 - val_loss: 2.7330 - val_accuracy: 0.5395\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 783us/step - loss: 0.0584 - accuracy: 0.9718 - val_loss: 2.7721 - val_accuracy: 0.5526\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 601us/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 2.7493 - val_accuracy: 0.5526\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.0559 - accuracy: 0.9718 - val_loss: 2.6913 - val_accuracy: 0.5263\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.0726 - accuracy: 0.9661 - val_loss: 2.6885 - val_accuracy: 0.5789\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 459us/step - loss: 0.0552 - accuracy: 0.9774 - val_loss: 2.7877 - val_accuracy: 0.5263\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0676 - accuracy: 0.9718 - val_loss: 2.7178 - val_accuracy: 0.5526\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 2.6791 - val_accuracy: 0.5395\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.0819 - accuracy: 0.9661 - val_loss: 2.7559 - val_accuracy: 0.5263\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.0782 - accuracy: 0.9661 - val_loss: 2.7428 - val_accuracy: 0.5395\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.0719 - accuracy: 0.9661 - val_loss: 2.7491 - val_accuracy: 0.5263\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.0735 - accuracy: 0.9605 - val_loss: 2.7992 - val_accuracy: 0.5263\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.0707 - accuracy: 0.9718 - val_loss: 2.7997 - val_accuracy: 0.5395\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.0705 - accuracy: 0.9661 - val_loss: 2.7804 - val_accuracy: 0.5395\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.0690 - accuracy: 0.9661 - val_loss: 2.7826 - val_accuracy: 0.5526\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.0681 - accuracy: 0.9605 - val_loss: 2.7676 - val_accuracy: 0.5132\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0693 - accuracy: 0.9605 - val_loss: 2.7699 - val_accuracy: 0.5526\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.0686 - accuracy: 0.9661 - val_loss: 2.7976 - val_accuracy: 0.5658\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.0675 - accuracy: 0.9661 - val_loss: 2.8048 - val_accuracy: 0.5132\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.0667 - accuracy: 0.9661 - val_loss: 2.7851 - val_accuracy: 0.5658\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.82%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist1.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947819</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.042591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.184744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS027          1           0  0.759813   \n",
       "1       p0017kpresabs_qual    NRS246          1           0  0.947819   \n",
       "2       p0017kpresabs_qual    NRS218          2           1  0.008693   \n",
       "3       p0017kpresabs_qual  CFBRSa70          2           0  0.813774   \n",
       "4       p0017kpresabs_qual    NRS177          1           1  0.000916   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS187          1           1  0.216843   \n",
       "604  p0040presabsSTCC_qual    SR1287          0           1  0.418802   \n",
       "605  p0040presabsSTCC_qual  CFBRSa50          0           0  0.948100   \n",
       "606  p0040presabsSTCC_qual    NRS196          2           2  0.000964   \n",
       "607  p0040presabsSTCC_qual    NRS072          0           0  0.795570   \n",
       "\n",
       "            1         2  \n",
       "0    0.001304  0.238883  \n",
       "1    0.009591  0.042591  \n",
       "2    0.989390  0.001916  \n",
       "3    0.001482  0.184744  \n",
       "4    0.998926  0.000157  \n",
       "..        ...       ...  \n",
       "603  0.568123  0.215034  \n",
       "604  0.553160  0.028038  \n",
       "605  0.035031  0.016869  \n",
       "606  0.039095  0.959940  \n",
       "607  0.187358  0.017072  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.97785100e-01, 3.86468000e-02, 6.35680300e-02],\n",
       "       [8.49721100e-01, 7.89486300e-02, 7.13302940e-02],\n",
       "       [3.93458040e-03, 8.33102900e-03, 9.87734400e-01],\n",
       "       [7.28428800e-01, 4.68073000e-02, 2.24763910e-01],\n",
       "       [1.10560880e-02, 9.28673150e-01, 6.02708270e-02],\n",
       "       [9.81330100e-01, 1.86365640e-02, 3.33018580e-05],\n",
       "       [9.44645000e-01, 6.40717600e-03, 4.89478200e-02],\n",
       "       [9.91395300e-01, 5.01880400e-04, 8.10279900e-03],\n",
       "       [8.46692860e-01, 1.15866980e-01, 3.74401730e-02],\n",
       "       [7.69999600e-05, 1.09815836e-01, 8.90107200e-01],\n",
       "       [7.31703800e-01, 1.78511430e-01, 8.97847640e-02],\n",
       "       [5.19315600e-01, 2.03730730e-01, 2.76953670e-01],\n",
       "       [5.20993700e-04, 1.60449580e-03, 9.97874500e-01],\n",
       "       [1.79342220e-03, 2.59388720e-02, 9.72267700e-01],\n",
       "       [5.59380700e-01, 3.26150800e-01, 1.14468470e-01],\n",
       "       [9.45620600e-01, 5.31242530e-02, 1.25512150e-03],\n",
       "       [1.44026980e-03, 9.93514200e-01, 5.04555550e-03],\n",
       "       [1.55329510e-01, 5.10880760e-02, 7.93582400e-01],\n",
       "       [5.70674660e-01, 3.20500900e-01, 1.08824340e-01],\n",
       "       [5.30182200e-01, 1.84369500e-01, 2.85448280e-01],\n",
       "       [5.95542200e-01, 2.43103430e-01, 1.61354360e-01],\n",
       "       [9.62110000e-01, 1.41226040e-02, 2.37674140e-02],\n",
       "       [1.94084060e-03, 9.35328700e-01, 6.27304400e-02],\n",
       "       [3.03222860e-01, 3.77403860e-01, 3.19373280e-01],\n",
       "       [2.54208130e-02, 2.26269850e-02, 9.51952160e-01],\n",
       "       [8.31005700e-01, 6.90047100e-02, 9.99895300e-02],\n",
       "       [8.84589700e-01, 5.06092570e-02, 6.48010600e-02],\n",
       "       [7.55833900e-02, 8.41183900e-01, 8.32328050e-02],\n",
       "       [2.68809600e-02, 9.37740400e-01, 3.53787300e-02],\n",
       "       [1.35041770e-01, 1.00823980e-01, 7.64134300e-01],\n",
       "       [1.96989720e-02, 7.40528800e-01, 2.39772220e-01],\n",
       "       [9.16066800e-05, 3.16676500e-03, 9.96741600e-01],\n",
       "       [9.27418200e-03, 1.91690850e-02, 9.71556660e-01],\n",
       "       [3.67915200e-01, 5.92406400e-01, 3.96783950e-02],\n",
       "       [5.10447100e-01, 6.72822800e-02, 4.22270630e-01],\n",
       "       [2.84019600e-02, 8.38168300e-03, 9.63216360e-01],\n",
       "       [9.97986100e-01, 2.90259500e-04, 1.72359900e-03],\n",
       "       [1.62849620e-01, 1.87516000e-02, 8.18398800e-01],\n",
       "       [1.67763050e-01, 8.67274000e-02, 7.45509560e-01],\n",
       "       [8.72326500e-01, 3.54409200e-02, 9.22325600e-02],\n",
       "       [6.38707460e-01, 9.53788400e-02, 2.65913720e-01],\n",
       "       [9.55729500e-01, 3.21790870e-02, 1.20913730e-02],\n",
       "       [4.29456500e-01, 2.09578630e-01, 3.60964860e-01],\n",
       "       [3.24551250e-01, 5.42420570e-01, 1.33028100e-01],\n",
       "       [1.33798950e-02, 1.67230800e-01, 8.19389340e-01],\n",
       "       [5.55226700e-06, 2.39757310e-04, 9.99754700e-01],\n",
       "       [1.65908380e-03, 9.90138770e-01, 8.20218400e-03],\n",
       "       [9.50759200e-01, 6.77267930e-03, 4.24680970e-02],\n",
       "       [1.77966900e-01, 2.83958350e-01, 5.38074850e-01],\n",
       "       [1.93398680e-04, 2.61246880e-03, 9.97194050e-01],\n",
       "       [4.68435660e-06, 1.82043300e-04, 9.99813260e-01],\n",
       "       [7.59846700e-01, 2.33419480e-01, 6.73384270e-03],\n",
       "       [9.40116400e-01, 4.52455730e-02, 1.46380310e-02],\n",
       "       [5.35574500e-01, 7.45959060e-02, 3.89829600e-01],\n",
       "       [1.83722480e-01, 7.06515200e-01, 1.09762300e-01],\n",
       "       [4.99336650e-02, 8.31978540e-02, 8.66868440e-01],\n",
       "       [1.29533990e-01, 8.66510800e-01, 3.95520400e-03],\n",
       "       [4.76704150e-01, 4.45510500e-01, 7.77853600e-02],\n",
       "       [3.78031400e-02, 7.77188540e-02, 8.84478030e-01],\n",
       "       [7.68647130e-01, 1.35712880e-01, 9.56400860e-02],\n",
       "       [3.78747200e-01, 5.78215800e-01, 4.30370980e-02],\n",
       "       [9.31272950e-02, 9.02405100e-01, 4.46759960e-03],\n",
       "       [9.96965800e-01, 1.34606980e-08, 3.03412580e-03],\n",
       "       [3.29896960e-01, 2.22277680e-02, 6.47875200e-01],\n",
       "       [7.54498200e-07, 9.98950400e-01, 1.04885510e-03],\n",
       "       [6.72572100e-05, 3.86614400e-02, 9.61271300e-01],\n",
       "       [5.31617700e-01, 8.46146100e-02, 3.83767720e-01],\n",
       "       [5.57940450e-02, 4.29288600e-01, 5.14917300e-01],\n",
       "       [7.09920300e-05, 9.99083300e-01, 8.45708240e-04],\n",
       "       [1.69855970e-01, 6.36578800e-01, 1.93565260e-01],\n",
       "       [7.08326160e-01, 1.30753110e-01, 1.60920720e-01],\n",
       "       [4.26559100e-01, 1.76919180e-01, 3.96521700e-01],\n",
       "       [9.84176000e-01, 4.90344600e-03, 1.09206615e-02],\n",
       "       [3.60253190e-01, 6.36501100e-01, 3.24571880e-03],\n",
       "       [9.97986100e-01, 2.90259500e-04, 1.72359900e-03],\n",
       "       [1.52901590e-01, 3.51779220e-01, 4.95319200e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214383059621155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214383059621155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat2['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "178     NRS210     2\n",
       "104     Grady1     0\n",
       "79    CFBRSa29     2\n",
       "66    CFBRSa03     0\n",
       "9          217     1\n",
       "..         ...   ...\n",
       "25   BCH-SA-10     1\n",
       "94        GA15     2\n",
       "244     SR3585     0\n",
       "227     NRS387     2\n",
       "185     NRS217     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.1250 - accuracy: 0.3672 - val_loss: 1.0530 - val_accuracy: 0.4342\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 640us/step - loss: 1.0484 - accuracy: 0.5367 - val_loss: 1.0734 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 582us/step - loss: 1.0396 - accuracy: 0.5706 - val_loss: 1.1293 - val_accuracy: 0.5263\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 668us/step - loss: 1.0606 - accuracy: 0.6102 - val_loss: 1.0775 - val_accuracy: 0.5263\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 538us/step - loss: 0.8868 - accuracy: 0.6328 - val_loss: 1.0715 - val_accuracy: 0.5132\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.8385 - accuracy: 0.6158 - val_loss: 1.0881 - val_accuracy: 0.4211\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 656us/step - loss: 0.8350 - accuracy: 0.6497 - val_loss: 1.0888 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.7822 - accuracy: 0.6554 - val_loss: 1.1165 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 469us/step - loss: 0.7758 - accuracy: 0.6554 - val_loss: 1.1166 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 441us/step - loss: 0.7155 - accuracy: 0.7062 - val_loss: 1.1351 - val_accuracy: 0.4079\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 724us/step - loss: 0.7667 - accuracy: 0.6497 - val_loss: 1.1148 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.7491 - accuracy: 0.7006 - val_loss: 1.1408 - val_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 580us/step - loss: 0.6917 - accuracy: 0.7288 - val_loss: 1.1472 - val_accuracy: 0.4868\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.6681 - accuracy: 0.7175 - val_loss: 1.1804 - val_accuracy: 0.4211\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 662us/step - loss: 0.6555 - accuracy: 0.7232 - val_loss: 1.1556 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 530us/step - loss: 0.6183 - accuracy: 0.7627 - val_loss: 1.1342 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.6035 - accuracy: 0.7401 - val_loss: 1.1819 - val_accuracy: 0.4605\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.5806 - accuracy: 0.7684 - val_loss: 1.1835 - val_accuracy: 0.4605\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.5779 - accuracy: 0.7740 - val_loss: 1.2297 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.5553 - accuracy: 0.7910 - val_loss: 1.2382 - val_accuracy: 0.4737\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.5454 - accuracy: 0.7853 - val_loss: 1.2362 - val_accuracy: 0.4342\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 601us/step - loss: 0.5278 - accuracy: 0.7797 - val_loss: 1.3478 - val_accuracy: 0.3684\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 920us/step - loss: 0.5483 - accuracy: 0.7684 - val_loss: 1.2738 - val_accuracy: 0.3947\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 769us/step - loss: 0.5488 - accuracy: 0.7853 - val_loss: 1.2453 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 760us/step - loss: 0.5160 - accuracy: 0.7966 - val_loss: 1.3405 - val_accuracy: 0.3816\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 698us/step - loss: 0.5110 - accuracy: 0.8023 - val_loss: 1.3355 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 604us/step - loss: 0.5036 - accuracy: 0.8023 - val_loss: 1.3768 - val_accuracy: 0.4079\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.4637 - accuracy: 0.8023 - val_loss: 1.3791 - val_accuracy: 0.4079\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 725us/step - loss: 0.4648 - accuracy: 0.8079 - val_loss: 1.3636 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.4343 - accuracy: 0.8192 - val_loss: 1.3747 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.4127 - accuracy: 0.8362 - val_loss: 1.3979 - val_accuracy: 0.4079\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.4226 - accuracy: 0.8305 - val_loss: 1.3819 - val_accuracy: 0.4474\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.4156 - accuracy: 0.8418 - val_loss: 1.4540 - val_accuracy: 0.3684\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8644 - val_loss: 1.4203 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 728us/step - loss: 0.3762 - accuracy: 0.8757 - val_loss: 1.5096 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 777us/step - loss: 0.3912 - accuracy: 0.8701 - val_loss: 1.4829 - val_accuracy: 0.4342\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.3701 - accuracy: 0.8644 - val_loss: 1.5463 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 519us/step - loss: 0.4691 - accuracy: 0.8475 - val_loss: 1.5823 - val_accuracy: 0.4211\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 711us/step - loss: 0.3541 - accuracy: 0.8757 - val_loss: 1.4974 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 552us/step - loss: 0.3496 - accuracy: 0.8701 - val_loss: 1.5322 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 800us/step - loss: 0.3455 - accuracy: 0.8870 - val_loss: 1.5754 - val_accuracy: 0.4079\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 766us/step - loss: 0.3383 - accuracy: 0.8418 - val_loss: 1.5271 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 727us/step - loss: 0.3287 - accuracy: 0.8983 - val_loss: 1.6385 - val_accuracy: 0.3816\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.3546 - accuracy: 0.8927 - val_loss: 1.6374 - val_accuracy: 0.4474\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.3204 - accuracy: 0.8983 - val_loss: 1.6763 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.3513 - accuracy: 0.8531 - val_loss: 1.5669 - val_accuracy: 0.4868\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.3133 - accuracy: 0.8701 - val_loss: 1.6609 - val_accuracy: 0.4079\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.2700 - accuracy: 0.9153 - val_loss: 1.6741 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 547us/step - loss: 0.2768 - accuracy: 0.9209 - val_loss: 1.6774 - val_accuracy: 0.4079\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.2738 - accuracy: 0.9096 - val_loss: 1.6708 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.2602 - accuracy: 0.9096 - val_loss: 1.7246 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.2592 - accuracy: 0.9040 - val_loss: 1.7687 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.2467 - accuracy: 0.9435 - val_loss: 1.7374 - val_accuracy: 0.5395\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.2657 - accuracy: 0.9096 - val_loss: 1.8676 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.2599 - accuracy: 0.9040 - val_loss: 1.7864 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.2672 - accuracy: 0.8983 - val_loss: 1.8297 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.2612 - accuracy: 0.9040 - val_loss: 1.7804 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.2319 - accuracy: 0.9153 - val_loss: 1.9355 - val_accuracy: 0.3947\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.2228 - accuracy: 0.9266 - val_loss: 1.8557 - val_accuracy: 0.5526\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 476us/step - loss: 0.2634 - accuracy: 0.9209 - val_loss: 1.8534 - val_accuracy: 0.5132\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.2380 - accuracy: 0.9266 - val_loss: 2.0633 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 593us/step - loss: 0.2341 - accuracy: 0.9040 - val_loss: 1.8609 - val_accuracy: 0.4605\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 436us/step - loss: 0.2048 - accuracy: 0.9548 - val_loss: 1.9169 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.2137 - accuracy: 0.9266 - val_loss: 1.9172 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1909 - accuracy: 0.9492 - val_loss: 1.9096 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.1856 - accuracy: 0.9435 - val_loss: 1.8706 - val_accuracy: 0.5526\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.1947 - accuracy: 0.9266 - val_loss: 1.9665 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1753 - accuracy: 0.9548 - val_loss: 1.9352 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1863 - accuracy: 0.9322 - val_loss: 1.9371 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.1950 - accuracy: 0.9266 - val_loss: 2.0136 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.1777 - accuracy: 0.9548 - val_loss: 1.9492 - val_accuracy: 0.5395\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.1610 - accuracy: 0.9435 - val_loss: 2.1103 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.1799 - accuracy: 0.9435 - val_loss: 2.0542 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.1897 - accuracy: 0.9435 - val_loss: 2.0101 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1596 - accuracy: 0.9435 - val_loss: 2.0955 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1766 - accuracy: 0.9379 - val_loss: 2.0899 - val_accuracy: 0.4079\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.1760 - accuracy: 0.9266 - val_loss: 2.0244 - val_accuracy: 0.5263\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1535 - accuracy: 0.9492 - val_loss: 2.0545 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.1531 - accuracy: 0.9435 - val_loss: 2.1175 - val_accuracy: 0.4211\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.1457 - accuracy: 0.9548 - val_loss: 2.0915 - val_accuracy: 0.4474\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 442us/step - loss: 0.1638 - accuracy: 0.9209 - val_loss: 2.0876 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.1539 - accuracy: 0.9435 - val_loss: 2.1377 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1419 - accuracy: 0.9605 - val_loss: 2.1355 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 387us/step - loss: 0.1589 - accuracy: 0.9435 - val_loss: 2.2320 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.1506 - accuracy: 0.9548 - val_loss: 2.2068 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1395 - accuracy: 0.9492 - val_loss: 2.1032 - val_accuracy: 0.4868\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.1644 - accuracy: 0.9435 - val_loss: 2.2238 - val_accuracy: 0.4079\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1397 - accuracy: 0.9661 - val_loss: 2.1592 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1497 - accuracy: 0.9379 - val_loss: 2.1457 - val_accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.1412 - accuracy: 0.9435 - val_loss: 2.1976 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1389 - accuracy: 0.9548 - val_loss: 2.1525 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1232 - accuracy: 0.9661 - val_loss: 2.1482 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 601us/step - loss: 0.1314 - accuracy: 0.9492 - val_loss: 2.2025 - val_accuracy: 0.4737\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.1377 - accuracy: 0.9548 - val_loss: 2.2432 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.1245 - accuracy: 0.9492 - val_loss: 2.1939 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1491 - accuracy: 0.9322 - val_loss: 2.2182 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.1127 - accuracy: 0.9605 - val_loss: 2.2429 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 543us/step - loss: 0.1296 - accuracy: 0.9435 - val_loss: 2.1805 - val_accuracy: 0.4868\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 502us/step - loss: 0.1316 - accuracy: 0.9548 - val_loss: 2.2805 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.1264 - accuracy: 0.9718 - val_loss: 2.2605 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a353b71d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 198us/step\n",
      "test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2,\n",
       "       0, 1, 1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 2, 0,\n",
       "       0, 0, 0, 2, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1,\n",
       "       0, 2, 2, 2, 0, 1, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict_classes(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BCH-SA-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GA15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>NRS217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "178     NRS210     2     0\n",
       "104     Grady1     0     1\n",
       "79    CFBRSa29     2     0\n",
       "66    CFBRSa03     0     1\n",
       "9          217     1     0\n",
       "..         ...   ...   ...\n",
       "25   BCH-SA-10     1     1\n",
       "94        GA15     2     1\n",
       "244     SR3585     0     0\n",
       "227     NRS387     2     2\n",
       "185     NRS217     0     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model2.predict_proba(X_test)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950409</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136295</td>\n",
       "      <td>0.810181</td>\n",
       "      <td>0.053525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.989155</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.005414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192855</td>\n",
       "      <td>0.635855</td>\n",
       "      <td>0.171290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567618</td>\n",
       "      <td>0.301551</td>\n",
       "      <td>0.130831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.995850</td>\n",
       "      <td>0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.133443</td>\n",
       "      <td>0.770544</td>\n",
       "      <td>0.096013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.740730</td>\n",
       "      <td>0.085304</td>\n",
       "      <td>0.173965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.034299</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.961546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.907964</td>\n",
       "      <td>0.090689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.950409  0.048540  0.001051\n",
       "1   0.136295  0.810181  0.053525\n",
       "2   0.989155  0.005430  0.005414\n",
       "3   0.192855  0.635855  0.171290\n",
       "4   0.567618  0.301551  0.130831\n",
       "..       ...       ...       ...\n",
       "71  0.000615  0.995850  0.003535\n",
       "72  0.133443  0.770544  0.096013\n",
       "73  0.740730  0.085304  0.173965\n",
       "74  0.034299  0.004155  0.961546\n",
       "75  0.001348  0.907964  0.090689\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.1164 - accuracy: 0.9605 - val_loss: 2.6647 - val_accuracy: 0.4342\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1091 - accuracy: 0.9492 - val_loss: 2.6360 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.1017 - accuracy: 0.9548 - val_loss: 2.6782 - val_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1029 - accuracy: 0.9435 - val_loss: 2.6764 - val_accuracy: 0.4342\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.0954 - accuracy: 0.9661 - val_loss: 2.7293 - val_accuracy: 0.4474\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 390us/step - loss: 0.1169 - accuracy: 0.9492 - val_loss: 2.7168 - val_accuracy: 0.4868\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 386us/step - loss: 0.1012 - accuracy: 0.9548 - val_loss: 2.6588 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0918 - accuracy: 0.9661 - val_loss: 2.6558 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1019 - accuracy: 0.9661 - val_loss: 2.6109 - val_accuracy: 0.4605\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.0891 - accuracy: 0.9605 - val_loss: 2.7158 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.1290 - accuracy: 0.9661 - val_loss: 2.6948 - val_accuracy: 0.4474\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 535us/step - loss: 0.0937 - accuracy: 0.9605 - val_loss: 2.5750 - val_accuracy: 0.5132\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.1026 - accuracy: 0.9435 - val_loss: 2.5663 - val_accuracy: 0.4737\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.0931 - accuracy: 0.9661 - val_loss: 2.6000 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 441us/step - loss: 0.1035 - accuracy: 0.9605 - val_loss: 2.7058 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.0992 - accuracy: 0.9605 - val_loss: 2.7269 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 2.6649 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.0898 - accuracy: 0.9492 - val_loss: 2.6653 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 484us/step - loss: 0.0783 - accuracy: 0.9718 - val_loss: 2.6614 - val_accuracy: 0.4605\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.0822 - accuracy: 0.9661 - val_loss: 2.6799 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 579us/step - loss: 0.0782 - accuracy: 0.9718 - val_loss: 2.6778 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 752us/step - loss: 0.0781 - accuracy: 0.9774 - val_loss: 2.7386 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 909us/step - loss: 0.0799 - accuracy: 0.9661 - val_loss: 2.7491 - val_accuracy: 0.4605\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 786us/step - loss: 0.0738 - accuracy: 0.9718 - val_loss: 2.7300 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 625us/step - loss: 0.0832 - accuracy: 0.9718 - val_loss: 2.7414 - val_accuracy: 0.4868\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9605 - val_loss: 2.7492 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 437us/step - loss: 0.0812 - accuracy: 0.9774 - val_loss: 2.7386 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.0919 - accuracy: 0.9605 - val_loss: 2.8208 - val_accuracy: 0.4474\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 703us/step - loss: 0.0820 - accuracy: 0.9774 - val_loss: 2.7428 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9718 - val_loss: 2.7754 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 938us/step - loss: 0.0769 - accuracy: 0.9605 - val_loss: 2.8124 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 456us/step - loss: 0.0943 - accuracy: 0.9718 - val_loss: 2.8220 - val_accuracy: 0.4605\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.0836 - accuracy: 0.9548 - val_loss: 2.8368 - val_accuracy: 0.4737\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 602us/step - loss: 0.0857 - accuracy: 0.9605 - val_loss: 2.8349 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.0796 - accuracy: 0.9661 - val_loss: 2.8285 - val_accuracy: 0.4868\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 522us/step - loss: 0.0773 - accuracy: 0.9605 - val_loss: 2.8602 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.0727 - accuracy: 0.9661 - val_loss: 2.9055 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.0712 - accuracy: 0.9661 - val_loss: 2.8971 - val_accuracy: 0.4737\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 389us/step - loss: 0.0703 - accuracy: 0.9661 - val_loss: 2.9242 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 457us/step - loss: 0.0723 - accuracy: 0.9718 - val_loss: 2.9796 - val_accuracy: 0.4474\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 831us/step - loss: 0.0716 - accuracy: 0.9661 - val_loss: 2.9420 - val_accuracy: 0.4868\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 694us/step - loss: 0.0610 - accuracy: 0.9887 - val_loss: 2.9815 - val_accuracy: 0.4868\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9661 - val_loss: 2.9906 - val_accuracy: 0.4474\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 957us/step - loss: 0.0679 - accuracy: 0.9661 - val_loss: 3.0220 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 755us/step - loss: 0.0681 - accuracy: 0.9661 - val_loss: 3.0267 - val_accuracy: 0.4342\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.0737 - accuracy: 0.9605 - val_loss: 3.0158 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 763us/step - loss: 0.0716 - accuracy: 0.9718 - val_loss: 3.0230 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.0629 - accuracy: 0.9831 - val_loss: 3.0747 - val_accuracy: 0.4868\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.0693 - accuracy: 0.9661 - val_loss: 3.0310 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 3.0299 - val_accuracy: 0.4605\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 444us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 3.0709 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.0622 - accuracy: 0.9831 - val_loss: 3.0434 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.0606 - accuracy: 0.9831 - val_loss: 3.0701 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 448us/step - loss: 0.0664 - accuracy: 0.9718 - val_loss: 3.0892 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 520us/step - loss: 0.0805 - accuracy: 0.9548 - val_loss: 3.0530 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 646us/step - loss: 0.0824 - accuracy: 0.9435 - val_loss: 3.1508 - val_accuracy: 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.0964 - accuracy: 0.9435 - val_loss: 3.1253 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.0795 - accuracy: 0.9492 - val_loss: 3.0717 - val_accuracy: 0.5263\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.0667 - accuracy: 0.9718 - val_loss: 3.1390 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.0725 - accuracy: 0.9661 - val_loss: 3.1591 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.0630 - accuracy: 0.9661 - val_loss: 3.0914 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.0636 - accuracy: 0.9718 - val_loss: 3.0995 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: 3.1670 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.0524 - accuracy: 0.9774 - val_loss: 3.1177 - val_accuracy: 0.4474\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 475us/step - loss: 0.0587 - accuracy: 0.9831 - val_loss: 3.1172 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.0566 - accuracy: 0.9831 - val_loss: 3.2567 - val_accuracy: 0.4737\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 3.1521 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 801us/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 3.2014 - val_accuracy: 0.4868\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 479us/step - loss: 0.0583 - accuracy: 0.9831 - val_loss: 3.2067 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 495us/step - loss: 0.0597 - accuracy: 0.9774 - val_loss: 3.2186 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.0520 - accuracy: 0.9774 - val_loss: 3.1840 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 3.2107 - val_accuracy: 0.4605\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 453us/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 3.2111 - val_accuracy: 0.4605\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 765us/step - loss: 0.0504 - accuracy: 0.9774 - val_loss: 3.2281 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 638us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 3.2481 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 551us/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 3.2430 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 488us/step - loss: 0.0497 - accuracy: 0.9831 - val_loss: 3.2859 - val_accuracy: 0.4605\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 3.3047 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 571us/step - loss: 0.0453 - accuracy: 0.9831 - val_loss: 3.2905 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 693us/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 3.3127 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.0432 - accuracy: 0.9831 - val_loss: 3.3264 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 3.3322 - val_accuracy: 0.4605\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 528us/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 3.3429 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 3.3574 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.0438 - accuracy: 0.9774 - val_loss: 3.3561 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 3.3619 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.0444 - accuracy: 0.9831 - val_loss: 3.3688 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 3.3631 - val_accuracy: 0.4474\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 438us/step - loss: 0.0441 - accuracy: 0.9774 - val_loss: 3.3827 - val_accuracy: 0.4474\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 3.3781 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.0417 - accuracy: 0.9831 - val_loss: 3.3626 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 444us/step - loss: 0.0443 - accuracy: 0.9718 - val_loss: 3.3995 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.0391 - accuracy: 0.9774 - val_loss: 3.3852 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 468us/step - loss: 0.0555 - accuracy: 0.9605 - val_loss: 3.4038 - val_accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.0571 - accuracy: 0.9718 - val_loss: 3.3712 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.0496 - accuracy: 0.9718 - val_loss: 3.4507 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 3.4162 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 413us/step - loss: 0.0396 - accuracy: 0.9718 - val_loss: 3.3759 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 501us/step - loss: 0.0443 - accuracy: 0.9718 - val_loss: 3.4210 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.0764 - accuracy: 0.9718 - val_loss: 3.5117 - val_accuracy: 0.4474\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.07%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.851192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625329</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.889404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>6.335156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>2.086646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>4.754707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>2.864372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>5.715521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>9.284494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>9.653131e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>3.775318e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS210          2           0  0.999887   \n",
       "1       p0017kpresabs_qual    Grady1          0           0  0.625329   \n",
       "2       p0017kpresabs_qual  CFBRSa29          2           0  0.999098   \n",
       "3       p0017kpresabs_qual  CFBRSa03          0           0  0.647338   \n",
       "4       p0017kpresabs_qual       217          1           0  0.613342   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS265          1           1  0.025601   \n",
       "604  p0040presabsSTCC_qual     NY439          2           2  0.161947   \n",
       "605  p0040presabsSTCC_qual  CFBRSa05          0           0  0.652983   \n",
       "606  p0040presabsSTCC_qual    NRS205          2           2  0.000927   \n",
       "607  p0040presabsSTCC_qual     CA105          1           0  0.736115   \n",
       "\n",
       "            1             2  \n",
       "0    0.000112  8.851192e-07  \n",
       "1    0.369782  4.889404e-03  \n",
       "2    0.000269  6.335156e-04  \n",
       "3    0.331796  2.086646e-02  \n",
       "4    0.381903  4.754707e-03  \n",
       "..        ...           ...  \n",
       "603  0.687962  2.864372e-01  \n",
       "604  0.266501  5.715521e-01  \n",
       "605  0.254172  9.284494e-02  \n",
       "606  0.033760  9.653131e-01  \n",
       "607  0.260109  3.775318e-03  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.50409050e-01, 4.85404660e-02, 1.05052760e-03],\n",
       "       [1.36294920e-01, 8.10180540e-01, 5.35245400e-02],\n",
       "       [9.89155500e-01, 5.43018240e-03, 5.41440020e-03],\n",
       "       [1.92855300e-01, 6.35854540e-01, 1.71290160e-01],\n",
       "       [5.67618000e-01, 3.01551130e-01, 1.30830870e-01],\n",
       "       [3.03387110e-05, 1.05399430e-04, 9.99864200e-01],\n",
       "       [6.19640230e-01, 1.07306690e-01, 2.73053020e-01],\n",
       "       [7.17105500e-03, 3.68505830e-02, 9.55978400e-01],\n",
       "       [4.64002650e-07, 1.63578280e-05, 9.99983200e-01],\n",
       "       [8.06335360e-02, 5.02502100e-03, 9.14341450e-01],\n",
       "       [7.73711900e-01, 1.02803670e-01, 1.23484425e-01],\n",
       "       [1.04009920e-02, 9.61994700e-03, 9.79979040e-01],\n",
       "       [7.53824000e-01, 2.34950910e-01, 1.12250590e-02],\n",
       "       [7.94750030e-01, 1.89111950e-01, 1.61380100e-02],\n",
       "       [9.71428600e-01, 3.03582270e-03, 2.55356150e-02],\n",
       "       [7.51547040e-01, 1.87612900e-01, 6.08401080e-02],\n",
       "       [2.56840890e-05, 9.99973650e-01, 7.62742500e-07],\n",
       "       [2.97899370e-01, 6.97555960e-01, 4.54465950e-03],\n",
       "       [1.44763410e-05, 4.45295030e-03, 9.95532500e-01],\n",
       "       [9.51802970e-01, 1.73905360e-02, 3.08064130e-02],\n",
       "       [5.16486580e-05, 1.44603270e-01, 8.55345100e-01],\n",
       "       [1.28547370e-01, 1.90822780e-01, 6.80629850e-01],\n",
       "       [9.99647500e-01, 3.43639950e-05, 3.18211240e-04],\n",
       "       [6.61608530e-03, 6.90613500e-01, 3.02770400e-01],\n",
       "       [2.02681570e-02, 9.69650900e-01, 1.00809220e-02],\n",
       "       [9.43924900e-01, 2.88202760e-02, 2.72548650e-02],\n",
       "       [8.03678630e-01, 1.33723130e-02, 1.82948990e-01],\n",
       "       [8.37826000e-01, 1.58492200e-01, 3.68174900e-03],\n",
       "       [1.22659970e-01, 2.35537040e-01, 6.41803000e-01],\n",
       "       [1.22346480e-04, 2.32231080e-04, 9.99645500e-01],\n",
       "       [2.20836880e-04, 9.99678500e-01, 1.00700025e-04],\n",
       "       [2.48069230e-04, 7.31536050e-03, 9.92436600e-01],\n",
       "       [1.20354000e-02, 6.31422880e-03, 9.81650400e-01],\n",
       "       [9.93239300e-01, 3.52338280e-03, 3.23739400e-03],\n",
       "       [7.10143740e-02, 8.45232400e-03, 9.20533300e-01],\n",
       "       [1.43902210e-01, 4.08099000e-03, 8.52016800e-01],\n",
       "       [1.08756830e-02, 1.99211250e-03, 9.87132200e-01],\n",
       "       [7.87231100e-01, 1.94009020e-04, 2.12574880e-01],\n",
       "       [5.44306900e-02, 9.37246700e-01, 8.32266300e-03],\n",
       "       [9.90280500e-01, 7.18440200e-03, 2.53497620e-03],\n",
       "       [6.12384550e-03, 5.73525300e-02, 9.36523600e-01],\n",
       "       [5.15464070e-01, 4.22751250e-01, 6.17846000e-02],\n",
       "       [2.14180020e-02, 2.60507080e-03, 9.75977000e-01],\n",
       "       [5.14279400e-01, 3.58786820e-01, 1.26933710e-01],\n",
       "       [7.51601800e-01, 3.18417850e-02, 2.16556440e-01],\n",
       "       [6.03620600e-01, 3.31460480e-01, 6.49190000e-02],\n",
       "       [4.16742100e-01, 3.10538920e-01, 2.72719060e-01],\n",
       "       [6.76219100e-02, 3.24179640e-02, 8.99960160e-01],\n",
       "       [7.11187960e-01, 6.55321550e-02, 2.23279880e-01],\n",
       "       [1.82911960e-02, 1.57685070e-01, 8.24023800e-01],\n",
       "       [7.15237700e-02, 7.75650100e-06, 9.28468500e-01],\n",
       "       [7.61761140e-03, 9.92381400e-01, 9.27255900e-07],\n",
       "       [1.84618460e-01, 7.65538100e-02, 7.38827650e-01],\n",
       "       [2.64297370e-02, 8.96835450e-01, 7.67347960e-02],\n",
       "       [6.28735960e-01, 3.64176500e-01, 7.08749660e-03],\n",
       "       [7.40648450e-01, 2.47987400e-01, 1.13641390e-02],\n",
       "       [6.46713400e-02, 3.35373200e-02, 9.01791330e-01],\n",
       "       [9.97689700e-01, 1.76906110e-03, 5.41229440e-04],\n",
       "       [7.66363260e-01, 5.89366500e-02, 1.74700040e-01],\n",
       "       [4.98876300e-02, 9.69058400e-03, 9.40421760e-01],\n",
       "       [1.29505510e-02, 5.68422560e-02, 9.30207250e-01],\n",
       "       [1.86276490e-04, 6.61165250e-05, 9.99747600e-01],\n",
       "       [4.55928040e-03, 9.46879100e-02, 9.00752800e-01],\n",
       "       [5.94310300e-02, 8.60377100e-03, 9.31965230e-01],\n",
       "       [6.03215200e-02, 5.50385950e-01, 3.89292540e-01],\n",
       "       [2.20467840e-02, 8.40697050e-01, 1.37256200e-01],\n",
       "       [8.39460430e-01, 6.26692300e-02, 9.78703100e-02],\n",
       "       [1.60109220e-01, 3.35067450e-01, 5.04823300e-01],\n",
       "       [7.85477300e-03, 4.91692780e-01, 5.00452460e-01],\n",
       "       [6.60319750e-04, 5.15255330e-03, 9.94187100e-01],\n",
       "       [9.98418100e-01, 5.72981600e-04, 1.00889700e-03],\n",
       "       [6.14801600e-04, 9.95850440e-01, 3.53476000e-03],\n",
       "       [1.33442970e-01, 7.70543930e-01, 9.60130800e-02],\n",
       "       [7.40730350e-01, 8.53044840e-02, 1.73965200e-01],\n",
       "       [3.42988400e-02, 4.15466870e-03, 9.61546400e-01],\n",
       "       [1.34758830e-03, 9.07963750e-01, 9.06887200e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642089832566023"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642089832566023"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat3['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "231      NY360     2\n",
       "92       EUH25     2\n",
       "91       EUH15     2\n",
       "203     NRS241     0\n",
       "242     SR2852     2\n",
       "..         ...   ...\n",
       "26   BCH-SA-11     0\n",
       "111     NRS022     1\n",
       "96        GA27     2\n",
       "129     NRS102     1\n",
       "166     NRS192     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.2870 - accuracy: 0.4068 - val_loss: 1.2340 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 779us/step - loss: 1.0673 - accuracy: 0.5593 - val_loss: 1.3186 - val_accuracy: 0.4079\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 762us/step - loss: 1.0118 - accuracy: 0.5763 - val_loss: 1.3027 - val_accuracy: 0.4211\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 788us/step - loss: 0.9361 - accuracy: 0.6384 - val_loss: 1.3377 - val_accuracy: 0.3816\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 644us/step - loss: 0.8932 - accuracy: 0.6158 - val_loss: 1.4061 - val_accuracy: 0.3947\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 591us/step - loss: 0.8460 - accuracy: 0.6667 - val_loss: 1.3154 - val_accuracy: 0.4079\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 944us/step - loss: 0.7988 - accuracy: 0.6384 - val_loss: 1.3097 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 530us/step - loss: 0.7427 - accuracy: 0.6554 - val_loss: 1.4660 - val_accuracy: 0.3684\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.8210 - accuracy: 0.7345 - val_loss: 1.3565 - val_accuracy: 0.4474\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 878us/step - loss: 0.7516 - accuracy: 0.6667 - val_loss: 1.4480 - val_accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 854us/step - loss: 0.6952 - accuracy: 0.6723 - val_loss: 1.5109 - val_accuracy: 0.4211\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.7315 - accuracy: 0.7345 - val_loss: 1.4089 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 454us/step - loss: 0.7237 - accuracy: 0.7006 - val_loss: 1.3643 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.7684 - val_loss: 1.3955 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.7627 - val_loss: 1.4590 - val_accuracy: 0.3553\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.7910 - val_loss: 1.4855 - val_accuracy: 0.4079\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 914us/step - loss: 0.5481 - accuracy: 0.7797 - val_loss: 1.5073 - val_accuracy: 0.4211\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 643us/step - loss: 0.5845 - accuracy: 0.7345 - val_loss: 1.6006 - val_accuracy: 0.3553\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7910 - val_loss: 1.5222 - val_accuracy: 0.4211\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 887us/step - loss: 0.5563 - accuracy: 0.7853 - val_loss: 1.5523 - val_accuracy: 0.3947\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 959us/step - loss: 0.4801 - accuracy: 0.8192 - val_loss: 1.4032 - val_accuracy: 0.4211\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 729us/step - loss: 0.4873 - accuracy: 0.7571 - val_loss: 1.6198 - val_accuracy: 0.3553\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 788us/step - loss: 0.4710 - accuracy: 0.8136 - val_loss: 1.5134 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 807us/step - loss: 0.5605 - accuracy: 0.8249 - val_loss: 1.5778 - val_accuracy: 0.3684\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.4760 - accuracy: 0.7966 - val_loss: 1.4701 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 485us/step - loss: 0.4443 - accuracy: 0.8531 - val_loss: 1.5833 - val_accuracy: 0.4079\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 492us/step - loss: 0.4921 - accuracy: 0.8192 - val_loss: 1.6752 - val_accuracy: 0.4079\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 481us/step - loss: 0.4196 - accuracy: 0.8701 - val_loss: 1.5361 - val_accuracy: 0.4079\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 577us/step - loss: 0.5211 - accuracy: 0.7797 - val_loss: 1.6966 - val_accuracy: 0.3947\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 982us/step - loss: 0.4286 - accuracy: 0.8701 - val_loss: 1.7016 - val_accuracy: 0.4079\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.4727 - accuracy: 0.8475 - val_loss: 1.7074 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 610us/step - loss: 0.5471 - accuracy: 0.7684 - val_loss: 1.5086 - val_accuracy: 0.4342\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 457us/step - loss: 0.5023 - accuracy: 0.7853 - val_loss: 1.5765 - val_accuracy: 0.4474\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.4085 - accuracy: 0.8192 - val_loss: 1.5209 - val_accuracy: 0.4079\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.4214 - accuracy: 0.8814 - val_loss: 1.6687 - val_accuracy: 0.4211\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 649us/step - loss: 0.4056 - accuracy: 0.8644 - val_loss: 1.6635 - val_accuracy: 0.4211\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 747us/step - loss: 0.5031 - accuracy: 0.8475 - val_loss: 1.5928 - val_accuracy: 0.4211\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.4859 - accuracy: 0.8249 - val_loss: 1.6389 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 588us/step - loss: 0.4773 - accuracy: 0.8531 - val_loss: 1.9011 - val_accuracy: 0.3947\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 504us/step - loss: 0.4793 - accuracy: 0.8588 - val_loss: 1.9086 - val_accuracy: 0.4079\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.3729 - accuracy: 0.8644 - val_loss: 1.6536 - val_accuracy: 0.3816\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.4332 - accuracy: 0.8305 - val_loss: 1.6465 - val_accuracy: 0.3816\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.3366 - accuracy: 0.8927 - val_loss: 1.7229 - val_accuracy: 0.4079\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 493us/step - loss: 0.3078 - accuracy: 0.8870 - val_loss: 1.7552 - val_accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 470us/step - loss: 0.2884 - accuracy: 0.9096 - val_loss: 1.8592 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.2977 - accuracy: 0.9096 - val_loss: 1.7845 - val_accuracy: 0.3816\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.3561 - accuracy: 0.8870 - val_loss: 1.7245 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.3293 - accuracy: 0.9040 - val_loss: 1.7463 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 590us/step - loss: 0.9676 - accuracy: 0.8757 - val_loss: 2.5970 - val_accuracy: 0.4079\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 1.1482 - accuracy: 0.8418 - val_loss: 2.0624 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 464us/step - loss: 0.4188 - accuracy: 0.9096 - val_loss: 1.9990 - val_accuracy: 0.4079\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.4664 - accuracy: 0.8588 - val_loss: 2.0301 - val_accuracy: 0.3816\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 461us/step - loss: 0.5475 - accuracy: 0.8475 - val_loss: 1.8814 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.3459 - accuracy: 0.8870 - val_loss: 2.0799 - val_accuracy: 0.3553\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.9392 - accuracy: 0.8870 - val_loss: 3.1098 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 707us/step - loss: 1.6847 - accuracy: 0.8814 - val_loss: 3.0724 - val_accuracy: 0.3553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 589us/step - loss: 1.5373 - accuracy: 0.8362 - val_loss: 2.5570 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 474us/step - loss: 1.2971 - accuracy: 0.8023 - val_loss: 2.2600 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.8201 - accuracy: 0.8644 - val_loss: 2.3750 - val_accuracy: 0.3684\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 724us/step - loss: 0.5617 - accuracy: 0.8870 - val_loss: 1.9658 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 591us/step - loss: 0.3823 - accuracy: 0.8983 - val_loss: 1.8755 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 499us/step - loss: 0.2939 - accuracy: 0.9266 - val_loss: 1.8897 - val_accuracy: 0.4079\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 609us/step - loss: 0.2697 - accuracy: 0.9096 - val_loss: 1.8971 - val_accuracy: 0.4079\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 616us/step - loss: 0.2550 - accuracy: 0.9266 - val_loss: 1.8592 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 627us/step - loss: 0.2803 - accuracy: 0.9096 - val_loss: 1.8812 - val_accuracy: 0.4079\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.3250 - accuracy: 0.8983 - val_loss: 2.1553 - val_accuracy: 0.4211\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 489us/step - loss: 0.2767 - accuracy: 0.8870 - val_loss: 1.8567 - val_accuracy: 0.4211\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 907us/step - loss: 0.2480 - accuracy: 0.9266 - val_loss: 1.8863 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 691us/step - loss: 0.2270 - accuracy: 0.9322 - val_loss: 1.9233 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 690us/step - loss: 0.2154 - accuracy: 0.9435 - val_loss: 1.9791 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 669us/step - loss: 0.2229 - accuracy: 0.9266 - val_loss: 1.9414 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 665us/step - loss: 0.2152 - accuracy: 0.9605 - val_loss: 1.9777 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 541us/step - loss: 0.2224 - accuracy: 0.9322 - val_loss: 1.9607 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 573us/step - loss: 0.2122 - accuracy: 0.9266 - val_loss: 2.0006 - val_accuracy: 0.4474\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9266 - val_loss: 2.0227 - val_accuracy: 0.4211\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 794us/step - loss: 0.2165 - accuracy: 0.9435 - val_loss: 2.0908 - val_accuracy: 0.4211\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 547us/step - loss: 0.2939 - accuracy: 0.8983 - val_loss: 1.9737 - val_accuracy: 0.4079\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.2136 - accuracy: 0.9322 - val_loss: 2.1399 - val_accuracy: 0.3684\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.1997 - accuracy: 0.9379 - val_loss: 1.9994 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 528us/step - loss: 0.1948 - accuracy: 0.9379 - val_loss: 2.0465 - val_accuracy: 0.4211\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.1998 - accuracy: 0.9322 - val_loss: 2.0889 - val_accuracy: 0.4211\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 563us/step - loss: 0.1891 - accuracy: 0.9492 - val_loss: 2.0568 - val_accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 615us/step - loss: 0.1889 - accuracy: 0.9322 - val_loss: 2.1000 - val_accuracy: 0.4211\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 510us/step - loss: 0.2384 - accuracy: 0.9209 - val_loss: 2.1106 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.3404 - accuracy: 0.8814 - val_loss: 2.1752 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 493us/step - loss: 0.2470 - accuracy: 0.8983 - val_loss: 2.1735 - val_accuracy: 0.4079\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.2493 - accuracy: 0.9153 - val_loss: 2.3095 - val_accuracy: 0.3947\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 521us/step - loss: 0.2215 - accuracy: 0.9322 - val_loss: 2.1684 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 537us/step - loss: 0.1835 - accuracy: 0.9322 - val_loss: 2.0992 - val_accuracy: 0.4342\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.2115 - accuracy: 0.9322 - val_loss: 2.2636 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 507us/step - loss: 0.2093 - accuracy: 0.9548 - val_loss: 2.2027 - val_accuracy: 0.4342\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 485us/step - loss: 0.2287 - accuracy: 0.9379 - val_loss: 2.2048 - val_accuracy: 0.4211\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.2060 - accuracy: 0.9266 - val_loss: 2.1835 - val_accuracy: 0.4211\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 564us/step - loss: 0.1947 - accuracy: 0.9379 - val_loss: 2.1903 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.1765 - accuracy: 0.9322 - val_loss: 2.1853 - val_accuracy: 0.4474\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 467us/step - loss: 0.1679 - accuracy: 0.9548 - val_loss: 2.1514 - val_accuracy: 0.4079\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 462us/step - loss: 0.2749 - accuracy: 0.8927 - val_loss: 2.1814 - val_accuracy: 0.4211\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 506us/step - loss: 0.2142 - accuracy: 0.9153 - val_loss: 2.2083 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 466us/step - loss: 0.1766 - accuracy: 0.9379 - val_loss: 2.1919 - val_accuracy: 0.4342\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 456us/step - loss: 0.1697 - accuracy: 0.9435 - val_loss: 2.2294 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3596ff98>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 191us/step\n",
      "test accuracy: 47.37%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 1, 2, 1, 1, 2, 2, 0, 1, 1, 1, 0, 2,\n",
       "       0, 0, 2, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 2,\n",
       "       2, 0, 2, 1, 1, 1, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict_classes(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NRS022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>NRS102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "231      NY360     2     1\n",
       "92       EUH25     2     0\n",
       "91       EUH15     2     2\n",
       "203     NRS241     0     1\n",
       "242     SR2852     2     2\n",
       "..         ...   ...   ...\n",
       "26   BCH-SA-11     0     1\n",
       "111     NRS022     1     0\n",
       "96        GA27     2     2\n",
       "129     NRS102     1     0\n",
       "166     NRS192     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model3.predict_proba(X_test)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300197</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>1.058516e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>2.497419e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148422</td>\n",
       "      <td>0.143526</td>\n",
       "      <td>7.080525e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020322</td>\n",
       "      <td>0.979353</td>\n",
       "      <td>3.254849e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9.995253e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.825816</td>\n",
       "      <td>2.182598e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.554053</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>4.401001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>9.988418e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.960267</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>3.508106e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.854277</td>\n",
       "      <td>0.106694</td>\n",
       "      <td>3.902893e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1             2\n",
       "0   0.300197  0.593951  1.058516e-01\n",
       "1   0.999966  0.000034  2.497419e-13\n",
       "2   0.148422  0.143526  7.080525e-01\n",
       "3   0.020322  0.979353  3.254849e-04\n",
       "4   0.000189  0.000286  9.995253e-01\n",
       "..       ...       ...           ...\n",
       "71  0.152358  0.825816  2.182598e-02\n",
       "72  0.554053  0.005847  4.401001e-01\n",
       "73  0.000068  0.001090  9.988418e-01\n",
       "74  0.960267  0.036225  3.508106e-03\n",
       "75  0.854277  0.106694  3.902893e-02\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 0.1709 - accuracy: 0.9379 - val_loss: 1.8307 - val_accuracy: 0.4737\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.1685 - accuracy: 0.9548 - val_loss: 1.8430 - val_accuracy: 0.5132\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.2115 - accuracy: 0.9096 - val_loss: 1.7845 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 526us/step - loss: 0.2423 - accuracy: 0.8927 - val_loss: 1.9230 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 510us/step - loss: 0.2811 - accuracy: 0.9040 - val_loss: 1.8493 - val_accuracy: 0.4737\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 527us/step - loss: 0.2603 - accuracy: 0.9209 - val_loss: 1.8055 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.2364 - accuracy: 0.9153 - val_loss: 1.8639 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.1760 - accuracy: 0.9322 - val_loss: 1.9630 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.90 - 0s 575us/step - loss: 0.2292 - accuracy: 0.9096 - val_loss: 1.9568 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 627us/step - loss: 0.1798 - accuracy: 0.9266 - val_loss: 1.8552 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 524us/step - loss: 0.1963 - accuracy: 0.9548 - val_loss: 1.8700 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.1857 - accuracy: 0.9379 - val_loss: 1.8357 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.1817 - accuracy: 0.9492 - val_loss: 1.8710 - val_accuracy: 0.4737\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 511us/step - loss: 0.1768 - accuracy: 0.9605 - val_loss: 1.8645 - val_accuracy: 0.4605\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 616us/step - loss: 0.1850 - accuracy: 0.9435 - val_loss: 1.8484 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 564us/step - loss: 0.2192 - accuracy: 0.9322 - val_loss: 1.8391 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 639us/step - loss: 0.1841 - accuracy: 0.9379 - val_loss: 1.8342 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 726us/step - loss: 0.1650 - accuracy: 0.9548 - val_loss: 1.8653 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 931us/step - loss: 0.1911 - accuracy: 0.9322 - val_loss: 1.8245 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 438us/step - loss: 0.1883 - accuracy: 0.9435 - val_loss: 1.8698 - val_accuracy: 0.4737\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 936us/step - loss: 0.1640 - accuracy: 0.9379 - val_loss: 1.8709 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9435 - val_loss: 1.9125 - val_accuracy: 0.4474\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9153 - val_loss: 2.0878 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 846us/step - loss: 0.1851 - accuracy: 0.9322 - val_loss: 1.8576 - val_accuracy: 0.4605\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9379 - val_loss: 1.9017 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9605 - val_loss: 1.9628 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 661us/step - loss: 0.1505 - accuracy: 0.9435 - val_loss: 1.8779 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 728us/step - loss: 0.1455 - accuracy: 0.9548 - val_loss: 1.9946 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 747us/step - loss: 0.1873 - accuracy: 0.9153 - val_loss: 1.8982 - val_accuracy: 0.4605\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 744us/step - loss: 0.1810 - accuracy: 0.9379 - val_loss: 1.9033 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.1907 - accuracy: 0.9153 - val_loss: 2.0068 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9322 - val_loss: 1.8834 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9322 - val_loss: 2.0739 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.9379 - val_loss: 2.0262 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 733us/step - loss: 0.2042 - accuracy: 0.9379 - val_loss: 1.9979 - val_accuracy: 0.4605\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 904us/step - loss: 0.1730 - accuracy: 0.9435 - val_loss: 1.9746 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.1702 - accuracy: 0.9379 - val_loss: 2.0179 - val_accuracy: 0.4342\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9266 - val_loss: 1.9497 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 588us/step - loss: 0.1601 - accuracy: 0.9605 - val_loss: 1.9643 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 543us/step - loss: 0.1619 - accuracy: 0.9322 - val_loss: 1.9992 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 493us/step - loss: 0.1581 - accuracy: 0.9492 - val_loss: 1.9805 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 582us/step - loss: 0.1509 - accuracy: 0.9718 - val_loss: 1.9949 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 635us/step - loss: 0.1728 - accuracy: 0.9492 - val_loss: 2.0043 - val_accuracy: 0.4868\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 586us/step - loss: 0.1583 - accuracy: 0.9605 - val_loss: 2.0186 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 748us/step - loss: 0.1723 - accuracy: 0.9605 - val_loss: 2.0026 - val_accuracy: 0.4868\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 546us/step - loss: 0.3323 - accuracy: 0.9492 - val_loss: 2.0747 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 499us/step - loss: 0.2316 - accuracy: 0.9435 - val_loss: 2.0070 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.1753 - accuracy: 0.9435 - val_loss: 1.9958 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 612us/step - loss: 0.1506 - accuracy: 0.9661 - val_loss: 2.0721 - val_accuracy: 0.4474\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9605 - val_loss: 2.0088 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 910us/step - loss: 0.1411 - accuracy: 0.9718 - val_loss: 2.0347 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 509us/step - loss: 0.1673 - accuracy: 0.9209 - val_loss: 2.1341 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 710us/step - loss: 0.1474 - accuracy: 0.9266 - val_loss: 2.1058 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9322 - val_loss: 2.1224 - val_accuracy: 0.4474\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 809us/step - loss: 0.1428 - accuracy: 0.9435 - val_loss: 2.1789 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 793us/step - loss: 0.1396 - accuracy: 0.9266 - val_loss: 2.1409 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 952us/step - loss: 0.1407 - accuracy: 0.9322 - val_loss: 2.1878 - val_accuracy: 0.4211\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 762us/step - loss: 0.1333 - accuracy: 0.9379 - val_loss: 2.2043 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 678us/step - loss: 0.1335 - accuracy: 0.9492 - val_loss: 2.1604 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 588us/step - loss: 0.1278 - accuracy: 0.9661 - val_loss: 2.1623 - val_accuracy: 0.4605\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 663us/step - loss: 0.1230 - accuracy: 0.9718 - val_loss: 2.1666 - val_accuracy: 0.4474\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 2.0941 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 791us/step - loss: 0.1287 - accuracy: 0.9548 - val_loss: 2.2203 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 556us/step - loss: 0.1317 - accuracy: 0.9548 - val_loss: 2.3007 - val_accuracy: 0.4474\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 675us/step - loss: 0.1785 - accuracy: 0.9379 - val_loss: 2.1819 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.1344 - accuracy: 0.9435 - val_loss: 2.2165 - val_accuracy: 0.4737\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 708us/step - loss: 0.1292 - accuracy: 0.9435 - val_loss: 2.2879 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 581us/step - loss: 0.1192 - accuracy: 0.9605 - val_loss: 2.2271 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 701us/step - loss: 0.1237 - accuracy: 0.9605 - val_loss: 2.2904 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 651us/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 2.2727 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 660us/step - loss: 0.1250 - accuracy: 0.9548 - val_loss: 2.3217 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 704us/step - loss: 0.1142 - accuracy: 0.9605 - val_loss: 2.2895 - val_accuracy: 0.4605\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 617us/step - loss: 0.1309 - accuracy: 0.9605 - val_loss: 2.2913 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.1169 - accuracy: 0.9718 - val_loss: 2.2067 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 632us/step - loss: 0.1107 - accuracy: 0.9661 - val_loss: 2.4834 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 572us/step - loss: 0.1563 - accuracy: 0.9661 - val_loss: 2.3327 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 587us/step - loss: 0.1098 - accuracy: 0.9718 - val_loss: 2.2845 - val_accuracy: 0.4605\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.1896 - accuracy: 0.9209 - val_loss: 2.2124 - val_accuracy: 0.4605\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 529us/step - loss: 0.1175 - accuracy: 0.9548 - val_loss: 2.3323 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.1273 - accuracy: 0.9605 - val_loss: 2.4703 - val_accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 545us/step - loss: 0.1191 - accuracy: 0.9605 - val_loss: 2.3013 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.1114 - accuracy: 0.9718 - val_loss: 2.3211 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 600us/step - loss: 0.1113 - accuracy: 0.9661 - val_loss: 2.2966 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 718us/step - loss: 0.1058 - accuracy: 0.9661 - val_loss: 2.3137 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 752us/step - loss: 0.1702 - accuracy: 0.9605 - val_loss: 2.3828 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 684us/step - loss: 0.1349 - accuracy: 0.9492 - val_loss: 2.4485 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 505us/step - loss: 0.1081 - accuracy: 0.9661 - val_loss: 2.3735 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 559us/step - loss: 0.1193 - accuracy: 0.9661 - val_loss: 2.4090 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 569us/step - loss: 0.1042 - accuracy: 0.9718 - val_loss: 2.3734 - val_accuracy: 0.4737\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 640us/step - loss: 0.1111 - accuracy: 0.9605 - val_loss: 2.3674 - val_accuracy: 0.4868\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 591us/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 2.4175 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 597us/step - loss: 0.1070 - accuracy: 0.9718 - val_loss: 2.3998 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 632us/step - loss: 0.1538 - accuracy: 0.9492 - val_loss: 2.6275 - val_accuracy: 0.4737\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 621us/step - loss: 0.1131 - accuracy: 0.9605 - val_loss: 2.4517 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 668us/step - loss: 0.1194 - accuracy: 0.9548 - val_loss: 2.4463 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 787us/step - loss: 0.1020 - accuracy: 0.9718 - val_loss: 2.4566 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9661 - val_loss: 2.4410 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9661 - val_loss: 2.4580 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 940us/step - loss: 0.1045 - accuracy: 0.9718 - val_loss: 2.3958 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 685us/step - loss: 0.1006 - accuracy: 0.9718 - val_loss: 2.4210 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 94.76%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.165526e-02</td>\n",
       "      <td>4.848140e-01</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.986388e-01</td>\n",
       "      <td>1.245148e-03</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.227520e-04</td>\n",
       "      <td>1.424882e-02</td>\n",
       "      <td>0.984828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.374333e-01</td>\n",
       "      <td>1.614128e-01</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.976981e-09</td>\n",
       "      <td>5.145955e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305407e-01</td>\n",
       "      <td>6.356251e-02</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.476389e-02</td>\n",
       "      <td>8.577548e-01</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779456e-01</td>\n",
       "      <td>5.384378e-01</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.210180e-01</td>\n",
       "      <td>3.559393e-01</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.484084e-03</td>\n",
       "      <td>9.944786e-01</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage     strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual      NY360          2           2  2.165526e-02   \n",
       "1       p0017kpresabs_qual      EUH25          2           0  9.986388e-01   \n",
       "2       p0017kpresabs_qual      EUH15          2           2  9.227520e-04   \n",
       "3       p0017kpresabs_qual     NRS241          0           0  8.374333e-01   \n",
       "4       p0017kpresabs_qual     SR2852          2           2  3.976981e-09   \n",
       "..                     ...        ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  BCH-SA-01          0           0  9.305407e-01   \n",
       "604  p0040presabsSTCC_qual        504          0           1  4.476389e-02   \n",
       "605  p0040presabsSTCC_qual       GA27          2           1  2.779456e-01   \n",
       "606  p0040presabsSTCC_qual     NRS209          1           0  4.210180e-01   \n",
       "607  p0040presabsSTCC_qual  BCH-SA-13          1           1  5.484084e-03   \n",
       "\n",
       "                1         2  \n",
       "0    4.848140e-01  0.493531  \n",
       "1    1.245148e-03  0.000116  \n",
       "2    1.424882e-02  0.984828  \n",
       "3    1.614128e-01  0.001154  \n",
       "4    5.145955e-10  1.000000  \n",
       "..            ...       ...  \n",
       "603  6.356251e-02  0.005897  \n",
       "604  8.577548e-01  0.097481  \n",
       "605  5.384378e-01  0.183617  \n",
       "606  3.559393e-01  0.223043  \n",
       "607  9.944786e-01  0.000037  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00197060e-01, 5.93951300e-01, 1.05851580e-01],\n",
       "       [9.99965800e-01, 3.42531680e-05, 2.49741880e-13],\n",
       "       [1.48421930e-01, 1.43525560e-01, 7.08052500e-01],\n",
       "       [2.03219410e-02, 9.79352530e-01, 3.25484930e-04],\n",
       "       [1.89209700e-04, 2.85522460e-04, 9.99525300e-01],\n",
       "       [4.90020550e-02, 1.02699620e-01, 8.48298300e-01],\n",
       "       [3.81876600e-02, 7.07397460e-01, 2.54414900e-01],\n",
       "       [2.70405400e-03, 1.07550910e-03, 9.96220400e-01],\n",
       "       [2.51256260e-01, 6.89154100e-02, 6.79828300e-01],\n",
       "       [5.39077600e-01, 1.24853805e-01, 3.36068630e-01],\n",
       "       [6.10260670e-01, 2.87556350e-01, 1.02182920e-01],\n",
       "       [1.00000000e+00, 4.18953700e-08, 1.25978170e-14],\n",
       "       [9.29220500e-01, 6.17651600e-02, 9.01423600e-03],\n",
       "       [9.48855340e-01, 3.34729140e-02, 1.76718090e-02],\n",
       "       [7.98825260e-01, 2.09601710e-03, 1.99078660e-01],\n",
       "       [2.05057020e-01, 7.63409000e-01, 3.15339500e-02],\n",
       "       [1.75715680e-01, 8.14795550e-01, 9.48872800e-03],\n",
       "       [1.87083240e-01, 5.02405400e-01, 3.10511320e-01],\n",
       "       [3.90562500e-03, 9.85322240e-01, 1.07721150e-02],\n",
       "       [9.19755500e-01, 5.95872240e-03, 7.42858100e-02],\n",
       "       [8.96619600e-01, 9.02624350e-02, 1.31178970e-02],\n",
       "       [5.65804840e-01, 7.29260800e-04, 4.33465870e-01],\n",
       "       [8.61937000e-01, 7.75652450e-02, 6.04977700e-02],\n",
       "       [1.29793020e-01, 2.20428750e-01, 6.49778200e-01],\n",
       "       [4.82952800e-01, 4.72848030e-01, 4.41992130e-02],\n",
       "       [8.03388200e-01, 1.62816730e-01, 3.37951670e-02],\n",
       "       [1.16899340e-01, 1.81910040e-01, 7.01190600e-01],\n",
       "       [4.53048300e-01, 5.41498960e-01, 5.45279300e-03],\n",
       "       [6.43137160e-01, 1.93461220e-01, 1.63401600e-01],\n",
       "       [5.29904960e-01, 4.20702460e-01, 4.93926200e-02],\n",
       "       [4.42910160e-02, 6.65085800e-02, 8.89200400e-01],\n",
       "       [7.86779900e-01, 1.05298140e-01, 1.07921920e-01],\n",
       "       [4.08603140e-02, 8.43926550e-01, 1.15213156e-01],\n",
       "       [3.25859870e-01, 1.12732230e-02, 6.62866900e-01],\n",
       "       [9.24217600e-02, 5.96021060e-01, 3.11557100e-01],\n",
       "       [6.51696320e-03, 7.40453540e-01, 2.53029440e-01],\n",
       "       [4.73556700e-02, 1.57167150e-01, 7.95477200e-01],\n",
       "       [5.21774230e-04, 4.90458450e-03, 9.94573650e-01],\n",
       "       [6.92890300e-01, 2.27918330e-01, 7.91914400e-02],\n",
       "       [1.93473040e-02, 9.80614070e-01, 3.86423530e-05],\n",
       "       [9.30748600e-03, 9.90550500e-01, 1.41973710e-04],\n",
       "       [5.00751030e-02, 9.39924200e-01, 1.00007470e-02],\n",
       "       [7.76409450e-01, 7.12520200e-03, 2.16465400e-01],\n",
       "       [3.43633630e-03, 9.64083150e-02, 9.00155370e-01],\n",
       "       [8.68723150e-01, 1.07248850e-01, 2.40279730e-02],\n",
       "       [9.84957340e-01, 1.20470220e-02, 2.99566360e-03],\n",
       "       [1.30141350e-01, 2.20715240e-01, 6.49143460e-01],\n",
       "       [6.48827800e-03, 9.92716500e-01, 7.95216360e-04],\n",
       "       [9.04789400e-01, 5.39115330e-02, 4.12991050e-02],\n",
       "       [5.50196800e-01, 4.48331100e-01, 1.47206940e-03],\n",
       "       [9.84957340e-01, 1.20470220e-02, 2.99566360e-03],\n",
       "       [5.69417930e-03, 9.91202950e-01, 3.10284130e-03],\n",
       "       [1.33122500e-01, 1.95049190e-03, 8.64927000e-01],\n",
       "       [6.74761160e-02, 7.48925000e-01, 1.83598920e-01],\n",
       "       [9.99998700e-01, 2.22327440e-08, 1.31750160e-06],\n",
       "       [6.05380260e-03, 9.89656300e-01, 4.28983800e-03],\n",
       "       [9.33420700e-02, 8.92333150e-01, 1.43248120e-02],\n",
       "       [1.15904110e-01, 8.83341900e-01, 7.53983400e-04],\n",
       "       [3.79304050e-01, 5.09655830e-01, 1.11040130e-01],\n",
       "       [9.60206300e-01, 1.59002860e-02, 2.38934070e-02],\n",
       "       [1.32065145e-02, 9.85438470e-01, 1.35505990e-03],\n",
       "       [1.91215770e-01, 1.97717100e-03, 8.06807000e-01],\n",
       "       [6.45132360e-01, 6.46123960e-02, 2.90255300e-01],\n",
       "       [2.82716160e-01, 6.44605100e-01, 7.26787150e-02],\n",
       "       [3.04504910e-02, 9.67045840e-01, 2.50362370e-03],\n",
       "       [2.50518970e-03, 2.27503340e-03, 9.95219770e-01],\n",
       "       [6.77187700e-03, 1.25518070e-01, 8.67710050e-01],\n",
       "       [9.78640600e-01, 1.87319460e-02, 2.62732220e-03],\n",
       "       [6.69723100e-05, 2.49992120e-04, 9.99683000e-01],\n",
       "       [3.31730050e-03, 7.45455800e-01, 2.51226870e-01],\n",
       "       [1.36615510e-01, 7.63583600e-01, 9.98009500e-02],\n",
       "       [1.52358220e-01, 8.25815860e-01, 2.18259770e-02],\n",
       "       [5.54053250e-01, 5.84667130e-03, 4.40100070e-01],\n",
       "       [6.77040950e-05, 1.09049380e-03, 9.98841800e-01],\n",
       "       [9.60266770e-01, 3.62251070e-02, 3.50810560e-03],\n",
       "       [8.54277000e-01, 1.06694080e-01, 3.90289300e-02]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6114460935889507"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6114460935889507"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat4['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test\n",
       "236     SR1129     2\n",
       "31       CA105     2\n",
       "155     NRS175     1\n",
       "92       EUH25     2\n",
       "122     NRS070     2\n",
       "..         ...   ...\n",
       "235     SR1065     0\n",
       "24   BCH-SA-09     0\n",
       "104     Grady1     0\n",
       "213     NRS254     2\n",
       "87   CFBRSa66B     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.2188 - accuracy: 0.3333 - val_loss: 1.4709 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 1.0848 - accuracy: 0.5141 - val_loss: 1.1454 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.9350 - accuracy: 0.5819 - val_loss: 1.1533 - val_accuracy: 0.3684\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 464us/step - loss: 0.8964 - accuracy: 0.5932 - val_loss: 1.2069 - val_accuracy: 0.3553\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 493us/step - loss: 0.8521 - accuracy: 0.6158 - val_loss: 1.2739 - val_accuracy: 0.3289\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.8225 - accuracy: 0.6102 - val_loss: 1.3142 - val_accuracy: 0.3816\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.7911 - accuracy: 0.6780 - val_loss: 1.3132 - val_accuracy: 0.4079\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.7646 - accuracy: 0.6554 - val_loss: 1.3358 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.7451 - accuracy: 0.6610 - val_loss: 1.3468 - val_accuracy: 0.4211\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.7227 - accuracy: 0.6723 - val_loss: 1.3646 - val_accuracy: 0.4211\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.7011 - accuracy: 0.6893 - val_loss: 1.3686 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.6813 - accuracy: 0.6893 - val_loss: 1.4028 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.6682 - accuracy: 0.7175 - val_loss: 1.3833 - val_accuracy: 0.4342\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.6489 - accuracy: 0.7401 - val_loss: 1.3894 - val_accuracy: 0.4211\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.6338 - accuracy: 0.7458 - val_loss: 1.4100 - val_accuracy: 0.4211\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.6255 - accuracy: 0.7401 - val_loss: 1.4430 - val_accuracy: 0.4079\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.6065 - accuracy: 0.7401 - val_loss: 1.4841 - val_accuracy: 0.4474\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.5949 - accuracy: 0.7345 - val_loss: 1.4957 - val_accuracy: 0.4474\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.5879 - accuracy: 0.7514 - val_loss: 1.4946 - val_accuracy: 0.4211\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.5666 - accuracy: 0.7740 - val_loss: 1.4916 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.5620 - accuracy: 0.8079 - val_loss: 1.5185 - val_accuracy: 0.3947\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.5509 - accuracy: 0.7627 - val_loss: 1.5556 - val_accuracy: 0.4211\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.5395 - accuracy: 0.7910 - val_loss: 1.5886 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.5258 - accuracy: 0.8023 - val_loss: 1.5756 - val_accuracy: 0.4474\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.5164 - accuracy: 0.8192 - val_loss: 1.5731 - val_accuracy: 0.4474\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.5157 - accuracy: 0.7910 - val_loss: 1.5955 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.4916 - accuracy: 0.8079 - val_loss: 1.6214 - val_accuracy: 0.4342\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 427us/step - loss: 0.5130 - accuracy: 0.8531 - val_loss: 1.6700 - val_accuracy: 0.4211\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.4815 - accuracy: 0.8418 - val_loss: 1.6470 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.4886 - accuracy: 0.8249 - val_loss: 1.6931 - val_accuracy: 0.4079\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.4751 - accuracy: 0.8136 - val_loss: 1.6862 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.4626 - accuracy: 0.8418 - val_loss: 1.7270 - val_accuracy: 0.4211\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.4543 - accuracy: 0.8701 - val_loss: 1.6917 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 426us/step - loss: 0.4537 - accuracy: 0.8531 - val_loss: 1.6747 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.4448 - accuracy: 0.8531 - val_loss: 1.7026 - val_accuracy: 0.4474\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.4261 - accuracy: 0.8757 - val_loss: 1.7572 - val_accuracy: 0.4079\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.4192 - accuracy: 0.8814 - val_loss: 1.7682 - val_accuracy: 0.4211\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.4104 - accuracy: 0.8814 - val_loss: 1.7677 - val_accuracy: 0.4211\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.4066 - accuracy: 0.8757 - val_loss: 1.7785 - val_accuracy: 0.4211\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.4044 - accuracy: 0.8927 - val_loss: 1.7971 - val_accuracy: 0.4211\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.3954 - accuracy: 0.8701 - val_loss: 1.8370 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 421us/step - loss: 0.3892 - accuracy: 0.8757 - val_loss: 1.8156 - val_accuracy: 0.4342\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.3807 - accuracy: 0.8927 - val_loss: 1.8010 - val_accuracy: 0.4211\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 398us/step - loss: 0.3780 - accuracy: 0.8870 - val_loss: 1.8394 - val_accuracy: 0.4079\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.3634 - accuracy: 0.8983 - val_loss: 1.8917 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 555us/step - loss: 0.3694 - accuracy: 0.8757 - val_loss: 1.9056 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 648us/step - loss: 0.3623 - accuracy: 0.8927 - val_loss: 1.8964 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 585us/step - loss: 0.3477 - accuracy: 0.9209 - val_loss: 1.9055 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 395us/step - loss: 0.3419 - accuracy: 0.9040 - val_loss: 1.9107 - val_accuracy: 0.4211\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 471us/step - loss: 0.3388 - accuracy: 0.9040 - val_loss: 1.9327 - val_accuracy: 0.4342\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.3350 - accuracy: 0.9153 - val_loss: 1.9648 - val_accuracy: 0.4211\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 539us/step - loss: 0.3343 - accuracy: 0.9266 - val_loss: 1.9718 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.3222 - accuracy: 0.9209 - val_loss: 1.9991 - val_accuracy: 0.3947\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.3199 - accuracy: 0.9209 - val_loss: 1.9928 - val_accuracy: 0.3816\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.3127 - accuracy: 0.9209 - val_loss: 1.9977 - val_accuracy: 0.4079\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.3089 - accuracy: 0.9096 - val_loss: 2.0083 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 472us/step - loss: 0.3007 - accuracy: 0.9209 - val_loss: 1.9965 - val_accuracy: 0.4211\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.2984 - accuracy: 0.9209 - val_loss: 2.0469 - val_accuracy: 0.4079\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.2983 - accuracy: 0.9153 - val_loss: 2.0762 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.2872 - accuracy: 0.9209 - val_loss: 2.0837 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.2829 - accuracy: 0.9322 - val_loss: 2.0854 - val_accuracy: 0.4079\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 368us/step - loss: 0.2854 - accuracy: 0.9153 - val_loss: 2.0943 - val_accuracy: 0.3947\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.2843 - accuracy: 0.9040 - val_loss: 2.1305 - val_accuracy: 0.4211\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.2758 - accuracy: 0.9209 - val_loss: 2.0996 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.2675 - accuracy: 0.9322 - val_loss: 2.0904 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.2718 - accuracy: 0.9209 - val_loss: 2.1370 - val_accuracy: 0.4079\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 528us/step - loss: 0.2614 - accuracy: 0.9209 - val_loss: 2.0973 - val_accuracy: 0.4342\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.2578 - accuracy: 0.9435 - val_loss: 2.0979 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.2516 - accuracy: 0.9435 - val_loss: 2.1189 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 391us/step - loss: 0.2487 - accuracy: 0.9209 - val_loss: 2.1424 - val_accuracy: 0.4211\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.2475 - accuracy: 0.9153 - val_loss: 2.1391 - val_accuracy: 0.4211\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.2426 - accuracy: 0.9266 - val_loss: 2.1210 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.2463 - accuracy: 0.9435 - val_loss: 2.1489 - val_accuracy: 0.4342\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.2332 - accuracy: 0.9492 - val_loss: 2.1606 - val_accuracy: 0.4342\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.2318 - accuracy: 0.9322 - val_loss: 2.1441 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.2314 - accuracy: 0.9209 - val_loss: 2.1422 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.2276 - accuracy: 0.9266 - val_loss: 2.1607 - val_accuracy: 0.4605\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.2329 - accuracy: 0.9379 - val_loss: 2.1718 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.2279 - accuracy: 0.9322 - val_loss: 2.2022 - val_accuracy: 0.4079\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.2321 - accuracy: 0.9266 - val_loss: 2.2100 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.2337 - accuracy: 0.9153 - val_loss: 2.1905 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.2160 - accuracy: 0.9435 - val_loss: 2.1845 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.2184 - accuracy: 0.9492 - val_loss: 2.2098 - val_accuracy: 0.4605\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 706us/step - loss: 0.2094 - accuracy: 0.9209 - val_loss: 2.2641 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.2152 - accuracy: 0.9209 - val_loss: 2.2487 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.2137 - accuracy: 0.9322 - val_loss: 2.2005 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 379us/step - loss: 0.2018 - accuracy: 0.9435 - val_loss: 2.2344 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.2086 - accuracy: 0.9266 - val_loss: 2.2942 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.1972 - accuracy: 0.9492 - val_loss: 2.2457 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1940 - accuracy: 0.9435 - val_loss: 2.2507 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1887 - accuracy: 0.9492 - val_loss: 2.2970 - val_accuracy: 0.4474\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 393us/step - loss: 0.1904 - accuracy: 0.9435 - val_loss: 2.3128 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1870 - accuracy: 0.9492 - val_loss: 2.2613 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.1938 - accuracy: 0.9492 - val_loss: 2.2822 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.1852 - accuracy: 0.9379 - val_loss: 2.3424 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1817 - accuracy: 0.9379 - val_loss: 2.2946 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 329us/step - loss: 0.1785 - accuracy: 0.9492 - val_loss: 2.3094 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1816 - accuracy: 0.9435 - val_loss: 2.3559 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.1727 - accuracy: 0.9548 - val_loss: 2.3384 - val_accuracy: 0.4474\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1777 - accuracy: 0.9492 - val_loss: 2.3465 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3824ada0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 157us/step\n",
      "test accuracy: 44.74%\n"
     ]
    }
   ],
   "source": [
    "acc_test4 = model4.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 2,\n",
       "       2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0,\n",
       "       1, 2, 0, 1, 1, 2, 2, 1, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2,\n",
       "       2, 0, 2, 2, 0, 0, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model4.predict_classes(X_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NRS254</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CFBRSa66B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  test  pred\n",
       "236     SR1129     2     2\n",
       "31       CA105     2     2\n",
       "155     NRS175     1     0\n",
       "92       EUH25     2     1\n",
       "122     NRS070     2     2\n",
       "..         ...   ...   ...\n",
       "235     SR1065     0     0\n",
       "24   BCH-SA-09     0     2\n",
       "104     Grady1     0     0\n",
       "213     NRS254     2     2\n",
       "87   CFBRSa66B     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model4.predict_proba(X_test)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>0.943907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345262</td>\n",
       "      <td>0.032067</td>\n",
       "      <td>0.622672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913798</td>\n",
       "      <td>0.084018</td>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.919924</td>\n",
       "      <td>0.045514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010381</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.979896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.548255</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.451695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.057002</td>\n",
       "      <td>0.385987</td>\n",
       "      <td>0.557011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.440886</td>\n",
       "      <td>0.434378</td>\n",
       "      <td>0.124736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.042826</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>0.910731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.753929</td>\n",
       "      <td>0.152790</td>\n",
       "      <td>0.093281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.024262  0.031831  0.943907\n",
       "1   0.345262  0.032067  0.622672\n",
       "2   0.913798  0.084018  0.002183\n",
       "3   0.034562  0.919924  0.045514\n",
       "4   0.010381  0.009723  0.979896\n",
       "..       ...       ...       ...\n",
       "71  0.548255  0.000050  0.451695\n",
       "72  0.057002  0.385987  0.557011\n",
       "73  0.440886  0.434378  0.124736\n",
       "74  0.042826  0.046443  0.910731\n",
       "75  0.753929  0.152790  0.093281\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.1800 - accuracy: 0.9379 - val_loss: 2.1268 - val_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 425us/step - loss: 0.1743 - accuracy: 0.9548 - val_loss: 2.1648 - val_accuracy: 0.4474\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.1796 - accuracy: 0.9492 - val_loss: 2.1813 - val_accuracy: 0.4474\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1761 - accuracy: 0.9492 - val_loss: 2.1424 - val_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 383us/step - loss: 0.1707 - accuracy: 0.9492 - val_loss: 2.1463 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.1735 - accuracy: 0.9492 - val_loss: 2.1738 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 372us/step - loss: 0.1722 - accuracy: 0.9605 - val_loss: 2.1719 - val_accuracy: 0.4474\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1713 - accuracy: 0.9548 - val_loss: 2.1675 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1647 - accuracy: 0.9492 - val_loss: 2.2215 - val_accuracy: 0.4474\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1738 - accuracy: 0.9492 - val_loss: 2.2259 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.1575 - accuracy: 0.9605 - val_loss: 2.1809 - val_accuracy: 0.4474\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.1660 - accuracy: 0.9605 - val_loss: 2.2062 - val_accuracy: 0.4474\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.1689 - accuracy: 0.9379 - val_loss: 2.2180 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 477us/step - loss: 0.1666 - accuracy: 0.9548 - val_loss: 2.2266 - val_accuracy: 0.4474\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 419us/step - loss: 0.1649 - accuracy: 0.9548 - val_loss: 2.2490 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 397us/step - loss: 0.1570 - accuracy: 0.9492 - val_loss: 2.3110 - val_accuracy: 0.4474\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.1776 - accuracy: 0.9435 - val_loss: 2.2915 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.1608 - accuracy: 0.9661 - val_loss: 2.2203 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.1628 - accuracy: 0.9492 - val_loss: 2.2476 - val_accuracy: 0.4474\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1634 - accuracy: 0.9548 - val_loss: 2.5441 - val_accuracy: 0.3947\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 432us/step - loss: 0.2030 - accuracy: 0.9379 - val_loss: 2.2441 - val_accuracy: 0.4474\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1566 - accuracy: 0.9492 - val_loss: 2.1770 - val_accuracy: 0.4342\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 399us/step - loss: 0.1447 - accuracy: 0.9661 - val_loss: 2.2062 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 402us/step - loss: 0.1675 - accuracy: 0.9548 - val_loss: 2.1993 - val_accuracy: 0.4474\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.1613 - accuracy: 0.9661 - val_loss: 2.1270 - val_accuracy: 0.4605\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 430us/step - loss: 0.1485 - accuracy: 0.9548 - val_loss: 2.1696 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 374us/step - loss: 0.1521 - accuracy: 0.9492 - val_loss: 2.1739 - val_accuracy: 0.4474\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 463us/step - loss: 0.1519 - accuracy: 0.9548 - val_loss: 2.1778 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.1527 - accuracy: 0.9605 - val_loss: 2.1745 - val_accuracy: 0.4474\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1471 - accuracy: 0.9605 - val_loss: 2.1826 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.1485 - accuracy: 0.9492 - val_loss: 2.2019 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.1526 - accuracy: 0.9492 - val_loss: 2.2037 - val_accuracy: 0.4474\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.1383 - accuracy: 0.9605 - val_loss: 2.1792 - val_accuracy: 0.4474\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 365us/step - loss: 0.1370 - accuracy: 0.9605 - val_loss: 2.2299 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 411us/step - loss: 0.1425 - accuracy: 0.9548 - val_loss: 2.2650 - val_accuracy: 0.4342\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.1425 - accuracy: 0.9548 - val_loss: 2.2379 - val_accuracy: 0.4342\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1357 - accuracy: 0.9718 - val_loss: 2.2343 - val_accuracy: 0.4342\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.1368 - accuracy: 0.9605 - val_loss: 2.2638 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.1328 - accuracy: 0.9492 - val_loss: 2.2935 - val_accuracy: 0.4211\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.1310 - accuracy: 0.9605 - val_loss: 2.2784 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.1315 - accuracy: 0.9718 - val_loss: 2.2893 - val_accuracy: 0.4342\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 353us/step - loss: 0.1313 - accuracy: 0.9718 - val_loss: 2.3390 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1287 - accuracy: 0.9605 - val_loss: 2.3312 - val_accuracy: 0.4474\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.1288 - accuracy: 0.9661 - val_loss: 2.3229 - val_accuracy: 0.4342\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.1270 - accuracy: 0.9605 - val_loss: 2.3490 - val_accuracy: 0.4342\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.1283 - accuracy: 0.9548 - val_loss: 2.3857 - val_accuracy: 0.4211\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.1259 - accuracy: 0.9718 - val_loss: 2.3683 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 400us/step - loss: 0.1258 - accuracy: 0.9661 - val_loss: 2.3720 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 384us/step - loss: 0.1238 - accuracy: 0.9661 - val_loss: 2.3915 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.1234 - accuracy: 0.9548 - val_loss: 2.3994 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.1218 - accuracy: 0.9605 - val_loss: 2.3858 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.1205 - accuracy: 0.9661 - val_loss: 2.3907 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.1257 - accuracy: 0.9718 - val_loss: 2.4259 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 378us/step - loss: 0.1186 - accuracy: 0.9718 - val_loss: 2.4372 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1242 - accuracy: 0.9548 - val_loss: 2.4262 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.1237 - accuracy: 0.9435 - val_loss: 2.4323 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.1236 - accuracy: 0.9718 - val_loss: 2.4421 - val_accuracy: 0.4342\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.1260 - accuracy: 0.9718 - val_loss: 2.4330 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 394us/step - loss: 0.1183 - accuracy: 0.9661 - val_loss: 2.4426 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1144 - accuracy: 0.9605 - val_loss: 2.4756 - val_accuracy: 0.4211\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.1144 - accuracy: 0.9661 - val_loss: 2.4587 - val_accuracy: 0.4211\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.1134 - accuracy: 0.9661 - val_loss: 2.4452 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.1137 - accuracy: 0.9718 - val_loss: 2.4589 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.1123 - accuracy: 0.9718 - val_loss: 2.4766 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.1143 - accuracy: 0.9605 - val_loss: 2.4855 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.1112 - accuracy: 0.9661 - val_loss: 2.4841 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 595us/step - loss: 0.1088 - accuracy: 0.9774 - val_loss: 2.5043 - val_accuracy: 0.4342\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 0.1090 - accuracy: 0.9774 - val_loss: 2.5134 - val_accuracy: 0.4211\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 513us/step - loss: 0.1117 - accuracy: 0.9718 - val_loss: 2.4931 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 412us/step - loss: 0.1083 - accuracy: 0.9718 - val_loss: 2.5032 - val_accuracy: 0.4342\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 441us/step - loss: 0.1083 - accuracy: 0.9661 - val_loss: 2.4977 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.1081 - accuracy: 0.9718 - val_loss: 2.4996 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.1108 - accuracy: 0.9774 - val_loss: 2.5086 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9774 - val_loss: 2.5246 - val_accuracy: 0.4342\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 542us/step - loss: 0.1047 - accuracy: 0.9661 - val_loss: 2.5453 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 549us/step - loss: 0.1055 - accuracy: 0.9718 - val_loss: 2.5294 - val_accuracy: 0.4342\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 629us/step - loss: 0.1055 - accuracy: 0.9718 - val_loss: 2.5272 - val_accuracy: 0.4342\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 821us/step - loss: 0.1071 - accuracy: 0.9774 - val_loss: 2.5417 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 529us/step - loss: 0.1049 - accuracy: 0.9774 - val_loss: 2.5686 - val_accuracy: 0.4211\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 523us/step - loss: 0.1048 - accuracy: 0.9718 - val_loss: 2.5556 - val_accuracy: 0.4211\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 500us/step - loss: 0.1125 - accuracy: 0.9718 - val_loss: 2.5515 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1105 - accuracy: 0.9718 - val_loss: 2.5209 - val_accuracy: 0.4342\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1126 - accuracy: 0.9605 - val_loss: 2.5532 - val_accuracy: 0.4211\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.1139 - accuracy: 0.9661 - val_loss: 2.5856 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 373us/step - loss: 0.1121 - accuracy: 0.9661 - val_loss: 2.5649 - val_accuracy: 0.4211\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 359us/step - loss: 0.1102 - accuracy: 0.9718 - val_loss: 2.5613 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1080 - accuracy: 0.9774 - val_loss: 2.5732 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.0990 - accuracy: 0.9774 - val_loss: 2.6358 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 502us/step - loss: 0.1228 - accuracy: 0.9661 - val_loss: 2.6517 - val_accuracy: 0.4342\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 494us/step - loss: 0.1097 - accuracy: 0.9774 - val_loss: 2.5762 - val_accuracy: 0.4342\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.1109 - accuracy: 0.9718 - val_loss: 2.5896 - val_accuracy: 0.4079\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 428us/step - loss: 0.1120 - accuracy: 0.9718 - val_loss: 2.6169 - val_accuracy: 0.4079\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9718 - val_loss: 2.6367 - val_accuracy: 0.4342\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 702us/step - loss: 0.1090 - accuracy: 0.9718 - val_loss: 2.5998 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 482us/step - loss: 0.1054 - accuracy: 0.9661 - val_loss: 2.6190 - val_accuracy: 0.4342\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 433us/step - loss: 0.0998 - accuracy: 0.9774 - val_loss: 2.6909 - val_accuracy: 0.4211\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.1020 - accuracy: 0.9774 - val_loss: 2.6334 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 403us/step - loss: 0.0937 - accuracy: 0.9774 - val_loss: 2.6081 - val_accuracy: 0.4342\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1004 - accuracy: 0.9661 - val_loss: 2.6069 - val_accuracy: 0.4474\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 424us/step - loss: 0.0970 - accuracy: 0.9774 - val_loss: 2.6420 - val_accuracy: 0.4342\n"
     ]
    }
   ],
   "source": [
    "hist4 = model4.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.31%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.821690e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.652370e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>9.972990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198157e-02</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>5.232074e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.388957e-01</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>1.251503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231966e-03</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>1.824512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.957360e-02</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>5.846961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.196635e-03</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>5.517461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.319404e-02</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>9.278219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.902312e-03</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>3.146706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.566210e-04</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>9.439281e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage  strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  SR1129          2           2  4.821690e-07   \n",
       "1       p0017kpresabs_qual   CA105          2           2  2.652370e-03   \n",
       "2       p0017kpresabs_qual  NRS175          1           1  1.198157e-02   \n",
       "3       p0017kpresabs_qual   EUH25          2           1  1.388957e-01   \n",
       "4       p0017kpresabs_qual  NRS070          2           1  7.231966e-03   \n",
       "..                     ...     ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  NRS247          1           2  2.957360e-02   \n",
       "604  p0040presabsSTCC_qual  NRS215          1           2  3.196635e-03   \n",
       "605  p0040presabsSTCC_qual  SR4152          2           2  4.319404e-02   \n",
       "606  p0040presabsSTCC_qual  NRS035          1           1  4.902312e-03   \n",
       "607  p0040presabsSTCC_qual  SR4187          2           2  2.566210e-04   \n",
       "\n",
       "            1             2  \n",
       "0    0.000001  9.999983e-01  \n",
       "1    0.000049  9.972990e-01  \n",
       "2    0.988018  5.232074e-09  \n",
       "3    0.735954  1.251503e-01  \n",
       "4    0.810317  1.824512e-01  \n",
       "..        ...           ...  \n",
       "603  0.385730  5.846961e-01  \n",
       "604  0.445057  5.517461e-01  \n",
       "605  0.028984  9.278219e-01  \n",
       "606  0.680427  3.146706e-01  \n",
       "607  0.055815  9.439281e-01  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.42624990e-02, 3.18308360e-02, 9.43906660e-01],\n",
       "       [3.45261500e-01, 3.20665700e-02, 6.22671840e-01],\n",
       "       [9.13798400e-01, 8.40183500e-02, 2.18328300e-03],\n",
       "       [3.45619100e-02, 9.19923700e-01, 4.55143640e-02],\n",
       "       [1.03811610e-02, 9.72315500e-03, 9.79895700e-01],\n",
       "       [6.84882370e-03, 8.28253600e-02, 9.10325800e-01],\n",
       "       [1.53362200e-01, 7.86886750e-01, 5.97510800e-02],\n",
       "       [8.80036500e-01, 5.11755840e-03, 1.14846006e-01],\n",
       "       [1.57277000e-01, 6.39489200e-01, 2.03233760e-01],\n",
       "       [3.35859840e-13, 9.99999640e-01, 3.50026970e-07],\n",
       "       [1.08816310e-01, 8.69485500e-01, 2.16982250e-02],\n",
       "       [1.64301760e-05, 9.99952200e-01, 3.12962800e-05],\n",
       "       [4.94104860e-01, 2.19399100e-01, 2.86496040e-01],\n",
       "       [1.66820120e-01, 5.34168400e-01, 2.99011440e-01],\n",
       "       [8.74798660e-01, 1.23340200e-01, 1.86113760e-03],\n",
       "       [1.54968590e-01, 7.07158600e-01, 1.37872740e-01],\n",
       "       [5.14315500e-06, 9.99715030e-01, 2.79777330e-04],\n",
       "       [5.62075300e-01, 8.09830100e-03, 4.29826350e-01],\n",
       "       [2.07743270e-01, 2.75153030e-02, 7.64741400e-01],\n",
       "       [3.21426720e-01, 6.54929460e-01, 2.36437940e-02],\n",
       "       [2.77684000e-01, 6.08744100e-01, 1.13571880e-01],\n",
       "       [2.90040500e-01, 4.27447300e-02, 6.67214800e-01],\n",
       "       [2.58774160e-01, 2.28584040e-01, 5.12641800e-01],\n",
       "       [7.91436730e-01, 1.39245510e-01, 6.93178200e-02],\n",
       "       [2.05699090e-01, 2.89008810e-03, 7.91410800e-01],\n",
       "       [6.29420040e-04, 5.19496460e-02, 9.47420950e-01],\n",
       "       [1.45132290e-01, 2.83734100e-03, 8.52030400e-01],\n",
       "       [8.04979100e-01, 1.16686660e-02, 1.83352300e-01],\n",
       "       [1.87258410e-03, 5.74865560e-02, 9.40640870e-01],\n",
       "       [1.51480850e-01, 1.48168620e-01, 7.00350500e-01],\n",
       "       [9.68390700e-01, 2.33827380e-02, 8.22656400e-03],\n",
       "       [7.96423100e-03, 2.11546570e-02, 9.70881100e-01],\n",
       "       [2.30352770e-01, 3.34641960e-01, 4.35005340e-01],\n",
       "       [8.11445000e-01, 1.54650960e-01, 3.39041000e-02],\n",
       "       [1.40501830e-01, 3.73364150e-03, 8.55764570e-01],\n",
       "       [1.55935060e-01, 8.31367000e-01, 1.26979340e-02],\n",
       "       [2.58966950e-01, 5.15551870e-01, 2.25481270e-01],\n",
       "       [4.07257620e-01, 5.62552700e-01, 3.01896860e-02],\n",
       "       [3.80600270e-01, 3.58998450e-01, 2.60401340e-01],\n",
       "       [9.48752300e-01, 2.81672500e-03, 4.84309350e-02],\n",
       "       [1.39175730e-01, 5.36569440e-03, 8.55458560e-01],\n",
       "       [8.50948000e-01, 1.18768040e-01, 3.02839840e-02],\n",
       "       [2.06127520e-02, 3.48442470e-01, 6.30944800e-01],\n",
       "       [9.82411200e-01, 8.64649200e-03, 8.94221300e-03],\n",
       "       [2.42326340e-09, 9.99907730e-01, 9.22576150e-05],\n",
       "       [2.09540960e-01, 3.06459270e-02, 7.59813130e-01],\n",
       "       [8.47798650e-01, 6.75596600e-02, 8.46417200e-02],\n",
       "       [3.50468200e-09, 9.99997850e-01, 2.14919920e-06],\n",
       "       [9.59110100e-02, 8.88377550e-01, 1.57114800e-02],\n",
       "       [1.81929300e-07, 6.19316000e-05, 9.99937900e-01],\n",
       "       [1.18997390e-01, 2.40773340e-02, 8.56925300e-01],\n",
       "       [5.09050340e-02, 6.75939860e-01, 2.73155060e-01],\n",
       "       [6.43680630e-01, 3.25968100e-01, 3.03512890e-02],\n",
       "       [3.54176040e-01, 1.96408260e-02, 6.26183100e-01],\n",
       "       [6.11004600e-01, 7.91887900e-03, 3.81076500e-01],\n",
       "       [6.28321250e-02, 9.36816000e-01, 3.51859200e-04],\n",
       "       [9.60906400e-01, 3.45770430e-03, 3.56359900e-02],\n",
       "       [1.13152110e-04, 3.66752200e-03, 9.96219340e-01],\n",
       "       [3.14359500e-06, 9.98528240e-01, 1.46861080e-03],\n",
       "       [5.49896500e-01, 2.38283740e-01, 2.11819830e-01],\n",
       "       [5.43978400e-01, 3.57621900e-02, 4.20259480e-01],\n",
       "       [6.50599660e-01, 6.17805600e-03, 3.43222320e-01],\n",
       "       [6.89006700e-01, 1.61694300e-02, 2.94823860e-01],\n",
       "       [7.88301050e-01, 1.40939660e-03, 2.10289510e-01],\n",
       "       [2.70636200e-03, 1.91356960e-03, 9.95380040e-01],\n",
       "       [7.26885160e-04, 1.78258870e-01, 8.21014200e-01],\n",
       "       [1.97017950e-01, 3.06472180e-01, 4.96509880e-01],\n",
       "       [6.99229300e-01, 1.87410700e-03, 2.98896500e-01],\n",
       "       [3.21437270e-01, 5.09997360e-03, 6.73462750e-01],\n",
       "       [6.65398870e-03, 8.36410300e-04, 9.92509600e-01],\n",
       "       [5.24902800e-01, 5.23831140e-03, 4.69858900e-01],\n",
       "       [5.48254900e-01, 5.04988860e-05, 4.51694520e-01],\n",
       "       [5.70021350e-02, 3.85986600e-01, 5.57011250e-01],\n",
       "       [4.40886350e-01, 4.34378000e-01, 1.24735616e-01],\n",
       "       [4.28263660e-02, 4.64430670e-02, 9.10730540e-01],\n",
       "       [7.53928800e-01, 1.52790010e-01, 9.32812540e-02]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6109507776174444"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6109507776174444"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214812524336334"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012612600171702732"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214812524336334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012612600171702732"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test1, acc_test2, acc_test3, acc_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean: 48.03%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation: 0.021819902064750783\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1.history['accuracy']), np.mean(hist2.history['accuracy']), np.mean(hist3.history['accuracy']),\n",
    "             np.mean(hist4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean: 96.24%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation: 0.009000052\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X.loc[:, X.columns != 'id'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X.loc[:, X.columns != 'id']))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 7155\n",
      "selected features: 319\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,   11,   38,   40,  107,  130,  211,  225,  227,  235,  267,\n",
       "         270,  297,  310,  313,  345,  362,  391,  422,  459,  490,  498,\n",
       "         527,  533,  540,  551,  626,  690,  745,  760,  785,  805,  881,\n",
       "         899,  975,  982,  983, 1047, 1064, 1066, 1114, 1135, 1162, 1181,\n",
       "        1201, 1202, 1208, 1221, 1255, 1278, 1287, 1288, 1309, 1321, 1322,\n",
       "        1328, 1391, 1400, 1403, 1407, 1414, 1427, 1442, 1461, 1481, 1484,\n",
       "        1501, 1519, 1545, 1598, 1600, 1619, 1650, 1653, 1654, 1700, 1738,\n",
       "        1739, 1746, 1801, 1803, 1815, 1830, 1851, 1853, 1859, 1885, 1921,\n",
       "        1946, 1995, 2014, 2098, 2138, 2165, 2171, 2193, 2200, 2218, 2249,\n",
       "        2258, 2303, 2311, 2348, 2350, 2372, 2393, 2418, 2461, 2481, 2492,\n",
       "        2555, 2563, 2572, 2612, 2622, 2625, 2627, 2709, 2732, 2734, 2738,\n",
       "        2746, 2754, 2794, 2805, 2851, 2895, 2898, 2934, 2962, 3010, 3022,\n",
       "        3053, 3072, 3083, 3114, 3131, 3150, 3184, 3209, 3221, 3230, 3266,\n",
       "        3311, 3372, 3409, 3426, 3513, 3576, 3580, 3597, 3610, 3629, 3658,\n",
       "        3713, 3725, 3770, 3776, 3828, 3861, 3872, 3929, 3964, 3971, 4048,\n",
       "        4049, 4051, 4115, 4151, 4169, 4195, 4208, 4218, 4236, 4300, 4333,\n",
       "        4390, 4403, 4438, 4481, 4543, 4547, 4577, 4580, 4631, 4681, 4694,\n",
       "        4711, 4754, 4760, 4790, 4847, 4848, 4859, 4884, 4930, 4955, 5020,\n",
       "        5024, 5026, 5048, 5061, 5063, 5065, 5076, 5088, 5093, 5132, 5157,\n",
       "        5231, 5233, 5302, 5320, 5339, 5341, 5351, 5359, 5396, 5397, 5406,\n",
       "        5459, 5493, 5556, 5579, 5603, 5623, 5625, 5654, 5673, 5742, 5832,\n",
       "        5833, 5855, 5868, 5875, 5897, 5918, 6008, 6035, 6039, 6050, 6065,\n",
       "        6078, 6134, 6142, 6168, 6213, 6241, 6275, 6285, 6332, 6360, 6370,\n",
       "        6408, 6410, 6421, 6458, 6487, 6488, 6534, 6536, 6550, 6559, 6591,\n",
       "        6597, 6659, 6676, 6686, 6748, 6751, 6803, 6808, 6840, 6854, 6877,\n",
       "        7022, 7030, 7040, 7078, 7079, 7080, 7084, 7085, 7086, 7087, 7088,\n",
       "        7089, 7092, 7097, 7099, 7100, 7103, 7106, 7108, 7116, 7117, 7119,\n",
       "        7120, 7122, 7124, 7125, 7128, 7129, 7130, 7131, 7132, 7133, 7134,\n",
       "        7135, 7136, 7137, 7138, 7139, 7140, 7142, 7143, 7144, 7146, 7150]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA',\n",
       "       'TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT',\n",
       "       'TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG',\n",
       "       'TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA',\n",
       "       'TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA',\n",
       "       'TTTTGTTGGAGTA', 'TTTTCATTTTCATTT',\n",
       "       'TTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTA',\n",
       "       'TTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGG',\n",
       "       'TTTTATTGTATAAT',\n",
       "       'TTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGAT',\n",
       "       'TTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATA',\n",
       "       'TTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAA',\n",
       "       'TTTTAAACAATTAA',\n",
       "       'TTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAAC',\n",
       "       'TTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTT',\n",
       "       'TTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGAC',\n",
       "       'TTTGATAATTTCATT',\n",
       "       'TTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAA',\n",
       "       'TTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAAT',\n",
       "       'TTTCCTGTACTTTT', 'TTTCCATTTATTTC',\n",
       "       'TTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATC',\n",
       "       'TTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTAT',\n",
       "       'TTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTA',\n",
       "       'TTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCA',\n",
       "       'TTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATG',\n",
       "       'TTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAAT',\n",
       "       'TTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCA',\n",
       "       'TTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAG',\n",
       "       'TTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCT',\n",
       "       'TTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAGCA',\n",
       "       'TTGGAGTAATT',\n",
       "       'TTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGACA',\n",
       "       'TTGATAGTAAAGG', 'TTGATAACGCTGC', 'TTGATAACGCTGCA',\n",
       "       'TTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAAC',\n",
       "       'TTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTT',\n",
       "       'TTCTTGATTTTTAA', 'TTCGTTTTAAACA',\n",
       "       'TTCGGGCTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'TTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATA',\n",
       "       'TTCCATTTATTTC', 'TTCATTTTACTATT',\n",
       "       'TTCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCAT',\n",
       "       'TTCATTGATGTAT',\n",
       "       'TTCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTT',\n",
       "       'TTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCA',\n",
       "       'TTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGA',\n",
       "       'TTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGTAG',\n",
       "       'TTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGA',\n",
       "       'TTCAAAACATTC',\n",
       "       'TTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCAT',\n",
       "       'TTATTTTATTACTA', 'TTATTTGCGACT', 'TTATCTTCATATTTC',\n",
       "       'TTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGC',\n",
       "       'TTATCGAGTAATT', 'TTATCCGAAATTT', 'TTATCAATAGGT',\n",
       "       'TTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGA',\n",
       "       'TTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTC',\n",
       "       'TTATAAGGTGCT', 'TTAGTTCTGTA',\n",
       "       'TTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGA',\n",
       "       'TTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAAC',\n",
       "       'TTAGCAGTCGCATTTACAATTGCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'TTAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAAC',\n",
       "       'TTACATTCTTCGTC', 'TTACATTATGCA',\n",
       "       'TTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGTAATG',\n",
       "       'TTAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTCTCCTC',\n",
       "       'TTAATCTCCGC', 'TTAATCTCCGCTT',\n",
       "       'TTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCA',\n",
       "       'TTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCAC',\n",
       "       'TTAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACA',\n",
       "       'TTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAAC',\n",
       "       'TGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGT',\n",
       "       'TGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACAT',\n",
       "       'TGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTA',\n",
       "       'TGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAG',\n",
       "       'TGTTCCCTCCTC',\n",
       "       'TGTTCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTC',\n",
       "       'TGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTA',\n",
       "       'TGTTAAAACAAGATGCGAATGATATTGGCTTTGCTAAATTACTACAAAATGAGAATAATCGTATGAGTTATAACGAGTTAATGA',\n",
       "       'TGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCAT',\n",
       "       'TGTATTGCTCCT', 'TGTAATAGACGACC',\n",
       "       'TGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCT',\n",
       "       'TGGATTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCA',\n",
       "       'TGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGT',\n",
       "       'TGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATA',\n",
       "       'TGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTT',\n",
       "       'TGCCGAGGCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCAC',\n",
       "       'TGCCAGGATA',\n",
       "       'TGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGA',\n",
       "       'TGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGT',\n",
       "       'TGATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACT',\n",
       "       'TGATAAGTTTAG',\n",
       "       'TGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATT',\n",
       "       'TGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACAT',\n",
       "       'TGACCGTGTCT',\n",
       "       'TGAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGA',\n",
       "       'TGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATGAAC',\n",
       "       'TGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTG',\n",
       "       'TCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATACTTAGAAAGTAAACT',\n",
       "       'TCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTC',\n",
       "       'TCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTT',\n",
       "       'TCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTT',\n",
       "       'TCTCCTCTGA', 'TCTATTATACAT',\n",
       "       'TCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTA',\n",
       "       'TCTAAACGAAAAT', 'TCTAAACATTCT', 'TCTAAAAGAAC', 'TCGAGTTAATGA',\n",
       "       'TCCTGTACTTT', 'TCCTGTACTTTTATTT', 'TCCTGGCAATTG',\n",
       "       'TCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATAT',\n",
       "       'TCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGATCAGCAAAT',\n",
       "       'TCCAAGATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGG',\n",
       "       'TCATTTGTTATTCCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATT',\n",
       "       'TCATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTC',\n",
       "       'TCAGAGGAGAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCAT',\n",
       "       'TCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCAC',\n",
       "       'TCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTT',\n",
       "       'TCAACTTAGTTA', 'TATTTTGTCACT',\n",
       "       'TATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATT',\n",
       "       'TATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTA',\n",
       "       'TATTGCTCCTTTT', 'TATTGAACTTGGCG',\n",
       "       'TATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGC',\n",
       "       'TATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCAT',\n",
       "       'TATGTTATAATTAAT',\n",
       "       'TATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTT',\n",
       "       'TATCTGAGTCTCT',\n",
       "       'TATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCT',\n",
       "       'TATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGG',\n",
       "       'TATATTAAAGCGCCACATAG',\n",
       "       'TATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCG',\n",
       "       'TATAAATATATATC', 'TAGTGTTCTTTTA', 'TAGTCTTGTGATT',\n",
       "       'TAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGAT',\n",
       "       'TAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACC',\n",
       "       'TACTTTCTAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATC',\n",
       "       'TACTTCCCGGC',\n",
       "       'TACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATC',\n",
       "       'TACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTG',\n",
       "       'TACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATC',\n",
       "       'TACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGC',\n",
       "       'TAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATTTTTCTAAAT',\n",
       "       'TAATGATTGTGCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTCTCCTCT',\n",
       "       'TAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGAATAACAAATG',\n",
       "       'TAATAATTACTC',\n",
       "       'TAAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATT',\n",
       "       'TAAGCGGTTTTG', 'TAACATCTTCATT',\n",
       "       'TAAATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACAT',\n",
       "       'TAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATT',\n",
       "       'TAAAATCGGAAATG', 'TAAAATCGAATG',\n",
       "       'TAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATATAC',\n",
       "       'GTTTTATTATCTC', 'GTTGTTTAACC', 'GTTGCGCCACT', 'GTTCCCTCTTT',\n",
       "       'GTTATGATTTATTT', 'GTTATAATTAATT', 'GTTAATTTTTTGT',\n",
       "       'GTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTG',\n",
       "       'GTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAG',\n",
       "       'GTATTTTTTGTG',\n",
       "       'GTATTTATATCATCGACTTACAAAAAACAGTGAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGT',\n",
       "       'GTATATAAATATATAT', 'GTACGATTTTAT', 'GGTTTTTATAAATTGG',\n",
       "       'GGTTTTCGATTG',\n",
       "       'GGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGC',\n",
       "       'GGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAATC',\n",
       "       'GGGTCAAAAAAATCAAAAGCGATCAAAATACTTGGGGAACGGGGAGGGGCTCGACTTCGCGATAATTTTAAAAATCCATGTATAACCCCCC',\n",
       "       'GGCATCTATTT',\n",
       "       'GGATTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCG',\n",
       "       'GGAGTAATTATT',\n",
       "       'GGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAG',\n",
       "       'GCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATTGAAGCTAAAAAACAACTAGTTGATGAAATTGC',\n",
       "       'GCTTATAAGAAATCTGAAACATTTAGAAATTTTGTTAATGG',\n",
       "       'GCTAAAATTGACTTGAACGTGATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAAT',\n",
       "       'GCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCATAT',\n",
       "       'GCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTC',\n",
       "       'GCGAAGAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTAT',\n",
       "       'GCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAAT',\n",
       "       'GCATCAAACGTATACATAATACCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTCTCCTCTGAAAATCACT',\n",
       "       'GATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTTTTGAAATATGACACATATGCATATCTTCTGGATATT',\n",
       "       'GATTTGCTGATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGG',\n",
       "       'GATTTAGCATAGGTACTATGTGGAAAGATATTAAATCCGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGG',\n",
       "       'GATTATGAAGTTG',\n",
       "       'GATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATT',\n",
       "       'GATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTC',\n",
       "       'GATGGTTGGTGTCGCATTTATTGGAACAATCATAATGAGTGGATATGGCATGAGAGATTGATTGTGAAAGAAGTGTTTTAAT',\n",
       "       'GATGATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAAT',\n",
       "       'GATCGACATGCATACGAAGACTTTAAGCAATCTGATGCCTTTAATGACCATTTTTCAAAAGACGCATTAAGTCATTACTTTGGTTCAAGCGGACAACATT',\n",
       "       'GATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGG',\n",
       "       'GAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTT',\n",
       "       'GAGAATAGATGTT',\n",
       "       'GAATGTTGTCCGCTTGAACCAAAGTAATGACTTAATGCGTCTTTTGAAAAATGGTCATTAAAGGCATCAGATTGCTTAAAGTCTTCGTATGCATGTCGAT',\n",
       "       'GAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCTTGAAAGACATCCGCATT',\n",
       "       'GAACAAGTTTTT',\n",
       "       'GAAATAAATGGAAAAGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTG',\n",
       "       'GAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTTGATGCACAATCATTAACTG',\n",
       "       'GAAAATAAAAAATTG',\n",
       "       'GAAAAAAGTAGACGAGGCATACAACTTCTTGAAACAAGTTTCAGAAGATGGTGGACAAGTCTTATTCGTAGGAACTAAAAAACAAGCACAAGAATCAGTT',\n",
       "       'CTTTTTTAATTGTT',\n",
       "       'CTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCTTCGTCATAGT',\n",
       "       'CTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCTGCTATCATT',\n",
       "       'CTTTATAAATTTCGT',\n",
       "       'CTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTTCT',\n",
       "       'CTTAATCGTTTT',\n",
       "       'CTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTT',\n",
       "       'CTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGT',\n",
       "       'CTATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACG',\n",
       "       'CTATAACACTTT',\n",
       "       'CTAGTTTATTAAATTTATTTTTGCGCTTTCCAAATCAATGTATATGTGTTATATTGT',\n",
       "       'CTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGATGATATAAAT',\n",
       "       'CTAAGAATTAAAAT',\n",
       "       'CGGTGCATCATCGGCATTTAACTGGACAAAAGATCAAATAGGTAAAGGTACCAAATGGCTTGGCGATAAAGTTGGCGATGTTTTAGATTTTATTGAAAAT',\n",
       "       'CCTTTATATTTTTT', 'CCTTTATATTTTTTT', 'CCTGTACTTTT',\n",
       "       'CCTCCTATTAAGATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAAT',\n",
       "       'CCTACCTCTTTTCTTAGTATATCTAGGTATTTCTCCGATTTTGGTTAATTTAAACATCTATTTTCCTCTGAAAATCACTTGTATTTATTTAGCAAATCTT',\n",
       "       'CCGCCAATATAT', 'CCCGGCAAGT',\n",
       "       'CATTTAGAAAAATATCCAGAAGATATGCATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATT',\n",
       "       'CATTAACTCGT', 'CATGTGTTCCCTCCT', 'CATCTATTCT',\n",
       "       'CATCAACTAGTTGTTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCT',\n",
       "       'CATAGTTCTGT',\n",
       "       'CACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTTTT',\n",
       "       'CACTCGATAAAT', 'CACACTTATTT',\n",
       "       'CAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCT',\n",
       "       'CAAATCTTCAAAAAT', 'ATTTTTGAAGATT', 'ATTTTCGTTTAGAT',\n",
       "       'ATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAAT',\n",
       "       'ATTGATACCCTT',\n",
       "       'ATTCTTGTGCTTGTTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGT',\n",
       "       'ATTATCAATAGGT',\n",
       "       'ATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTT',\n",
       "       'ATTACTACTATGACGAAGAATGTAATAGACGACCCGTTAATATTCAATACAACGATGGCTACGACTTAATGATAGACCAGCGTTTTATTGAAATGACGCT',\n",
       "       'ATGTTTGTTTTTCTTTAAATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTT',\n",
       "       'ATGCTAAAATAATTGATTTCTTTTTATCGTTCGTAAATACGAAATTTTCGTATTCATTACCTAAAAAAATATCATCATATTTAACATTAAAAGCACTCAT',\n",
       "       'ATGCGGATGTCTTTCAAGCGTCATTTCAATAAAACGCTGGTCTATCATTAAGTCGTAGCCATCGTTGTATTGAATATTAACGGGTCGTCTATTACATTCT',\n",
       "       'ATCTCCGCTTT',\n",
       "       'ATCTATGATCTTTCAAGCACTTTTTGCCGTGGGTAGAAAGTGCTTTTTTATTAATTTTAAAAAAAGCACCAAAAATTTAAATGGAGGTGTCTGAATGTCT',\n",
       "       'ATCGAGTAATT',\n",
       "       'ATCATTACTCTCTTTATTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGT',\n",
       "       'ATATGTGTCATATTTCAAAAGATTTGCTAAATAAATACAAGTGATTTTCAGAGGAAAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATAT',\n",
       "       'ATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCT',\n",
       "       'ATACAAGTGATTTTCAGAGGAGAATAGATGTTTAAATTAACCAAAATCGGAGAAATACCTAGATATACTAAGAAAAGAGGTAGGTATTATGTATACGTTT',\n",
       "       'ATAAGCGGTTTT', 'ATAAATTTACCTGTT', 'AGTATTCATAGT',\n",
       "       'AGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTT',\n",
       "       'AGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTATTTCTTCGCTT',\n",
       "       'AGATTTACAAAAAAAGTCTGAATTGCAGGGAACTGCTTTAAGCAATCTTAGACAAACCTATTATCATAATGGAAGTGCTATAATTGAAAATAAAGAGAGT',\n",
       "       'AGAATAGATGTT', 'AGAAAAGTTGTTT', 'ACTCTTCATTGT', 'AATAAGCGGTT',\n",
       "       'AAGTATATGAGTGCTTTTAATGTTAAATATGATGATATTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTT',\n",
       "       'AAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGGATTTAATATCTTTCCACATAGTACCTATGCTAAATCTT',\n",
       "       'X1_56029_A_G', 'oxyR', 'pckA', 'flr', 'group_4265', 'group_3683',\n",
       "       'group_1177', 'ribD', 'group_1505', 'group_1454', 'coaBC_2',\n",
       "       'gdmA', 'group_6081', 'group_8506', 'group_8543', 'group_8541',\n",
       "       'group_6857', 'group_1087', 'group_1405', 'lpl8_2', 'group_7991',\n",
       "       'group_6719', 'yezG_6', 'group_6920', 'group_1779', 'lpl2_3',\n",
       "       'group_8664', 'group_6180', 'group_5384', 'group_6934',\n",
       "       'group_8569', 'group_7728', 'group_6924', 'group_2498',\n",
       "       'group_7793', 'group_4054', 'group_276', 'group_178', 'group_64',\n",
       "       'group_1598', 'group_8892'], dtype='<U100')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA</th>\n",
       "      <th>TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT</th>\n",
       "      <th>TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG</th>\n",
       "      <th>TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA</th>\n",
       "      <th>TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA</th>\n",
       "      <th>TTTTGTTGGAGTA</th>\n",
       "      <th>TTTTCATTTTCATTT</th>\n",
       "      <th>TTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTA</th>\n",
       "      <th>TTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGG</th>\n",
       "      <th>TTTTATTGTATAAT</th>\n",
       "      <th>...</th>\n",
       "      <th>group_2498</th>\n",
       "      <th>group_7793</th>\n",
       "      <th>group_4054</th>\n",
       "      <th>group_276</th>\n",
       "      <th>group_178</th>\n",
       "      <th>group_64</th>\n",
       "      <th>group_1598</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTTTAGGTAATGAATACGAAAATTTCGTATTTACGAACGATAAAAAGAAATCAATTATTTTAGCATTTAAAGAAAAACAAACATCTTAATAGGAGGA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAAAGTGCTTGAAAGATCATAGATCATCACGTTCAAGTCAATTTTAGCCTCGGCAGGAT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTTTAGCTTCAATGATAGCAGACATTCAGACACCTCCATTTAAATTTTTGGTGCTTTTTTTAAAATTAATAAAAAAGCACTTTCTACCCACGGCAAAA  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTTTAGTTCCTACGAATAAGACTTGTCCACCATCTTCTGAAACTTGTTTCAAGAAGTTGTATGCCTCGTCTACTTTTTTCACTGTTTTTTGTAAGTCGA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTGTTGGAGTA  TTTTCATTTTCATTT  \\\n",
       "0                1                1   \n",
       "1                0                0   \n",
       "2                0                1   \n",
       "3                0                0   \n",
       "4                0                0   \n",
       "..             ...              ...   \n",
       "248              1                1   \n",
       "249              1                1   \n",
       "250              0                0   \n",
       "251              1                1   \n",
       "252              1                1   \n",
       "\n",
       "     TTTTCAATTATAGCACTTCCATTATGATAATAGGTTTGTCTAAGATTGCTTAAAGCAGTTCCCTGCAATTCAGACTTTTTTTGTAAATCTTTTCCATTTA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTCAATAAAATCTAAAACATCGCCAACTTTATCGCCAAGCCATTTGGTACCTTTACCTATTTGATCTTTTGTCCAGTTAAATGCCGATGATGCACCGG  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTTATTGTATAAT  ...  group_2498  group_7793  group_4054  group_276  \\\n",
       "0                 1  ...           0           0           0          0   \n",
       "1                 0  ...           0           0           0          0   \n",
       "2                 1  ...           0           0           0          0   \n",
       "3                 0  ...           0           0           0          0   \n",
       "4                 0  ...           0           0           0          0   \n",
       "..              ...  ...         ...         ...         ...        ...   \n",
       "248               1  ...           0           0           0          0   \n",
       "249               1  ...           0           0           0          0   \n",
       "250               0  ...           0           0           0          0   \n",
       "251               1  ...           0           0           0          0   \n",
       "252               1  ...           0           0           0          0   \n",
       "\n",
       "     group_178  group_64  group_1598  group_8892  pheno  strain  \n",
       "0            0         0           0           0      2     107  \n",
       "1            0         0           0           0      0     109  \n",
       "2            0         0           0           0      2     115  \n",
       "3            0         0           0           0      2  120335  \n",
       "4            0         0           0           0      2  120337  \n",
       "..         ...       ...         ...         ...    ...     ...  \n",
       "248          0         0           0           0      2  SR4152  \n",
       "249          0         0           0           0      1  SR4153  \n",
       "250          0         0           0           0      0  SR4155  \n",
       "251          0         0           0           0      2  SR4156  \n",
       "252          0         0           0           0      2  SR4187  \n",
       "\n",
       "[253 rows x 321 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 320) (253,) (253, 321)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91\n",
       "0    88\n",
       "1    74\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat5['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "231        NY360     2\n",
       "139       NRS113     0\n",
       "4         120337     2\n",
       "59   CFBREBSa127     1\n",
       "96          GA27     2\n",
       "..           ...   ...\n",
       "236       SR1129     2\n",
       "145       NRS152     2\n",
       "86     CFBRSa66A     0\n",
       "28     BCH-SA-13     1\n",
       "249       SR4153     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model_sel = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 867us/step - loss: 1.0777 - accuracy: 0.3842 - val_loss: 1.2104 - val_accuracy: 0.4079\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.9825 - accuracy: 0.5085 - val_loss: 1.2137 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.9385 - accuracy: 0.5254 - val_loss: 1.1150 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.8887 - accuracy: 0.5876 - val_loss: 1.1137 - val_accuracy: 0.5132\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.8661 - accuracy: 0.5819 - val_loss: 1.1015 - val_accuracy: 0.5132\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.8406 - accuracy: 0.5989 - val_loss: 1.0997 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.8694 - accuracy: 0.6497 - val_loss: 1.1613 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.8341 - accuracy: 0.6497 - val_loss: 1.1190 - val_accuracy: 0.5263\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7892 - accuracy: 0.6554 - val_loss: 1.0864 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 334us/step - loss: 0.7632 - accuracy: 0.6780 - val_loss: 1.0730 - val_accuracy: 0.5526\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.7436 - accuracy: 0.7175 - val_loss: 1.0744 - val_accuracy: 0.5658\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.7247 - accuracy: 0.6893 - val_loss: 1.0680 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.7107 - accuracy: 0.6780 - val_loss: 1.0632 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.6866 - accuracy: 0.7288 - val_loss: 1.0645 - val_accuracy: 0.5395\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.6812 - accuracy: 0.7006 - val_loss: 1.1020 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6654 - accuracy: 0.7232 - val_loss: 1.0793 - val_accuracy: 0.5395\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6693 - accuracy: 0.7232 - val_loss: 1.1278 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6500 - accuracy: 0.7345 - val_loss: 1.0691 - val_accuracy: 0.5395\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6295 - accuracy: 0.7458 - val_loss: 1.0558 - val_accuracy: 0.5263\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.6270 - accuracy: 0.7853 - val_loss: 1.0548 - val_accuracy: 0.5132\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.6153 - accuracy: 0.7853 - val_loss: 1.0591 - val_accuracy: 0.5658\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.5761 - accuracy: 0.7797 - val_loss: 1.0622 - val_accuracy: 0.5395\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.5701 - accuracy: 0.7853 - val_loss: 1.0664 - val_accuracy: 0.5395\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.5810 - accuracy: 0.7571 - val_loss: 1.0772 - val_accuracy: 0.5395\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.5559 - accuracy: 0.7853 - val_loss: 1.0458 - val_accuracy: 0.5526\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.5448 - accuracy: 0.7966 - val_loss: 1.0445 - val_accuracy: 0.5921\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5757 - accuracy: 0.7797 - val_loss: 1.0475 - val_accuracy: 0.5263\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5375 - accuracy: 0.7853 - val_loss: 1.0696 - val_accuracy: 0.5526\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.5087 - accuracy: 0.8362 - val_loss: 1.0582 - val_accuracy: 0.5789\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.5235 - accuracy: 0.7910 - val_loss: 1.0699 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.5051 - accuracy: 0.8305 - val_loss: 1.0355 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.4806 - accuracy: 0.8305 - val_loss: 1.0666 - val_accuracy: 0.6316\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.4783 - accuracy: 0.8249 - val_loss: 1.0375 - val_accuracy: 0.5395\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.4826 - accuracy: 0.8362 - val_loss: 1.0954 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 404us/step - loss: 0.4521 - accuracy: 0.8362 - val_loss: 1.0438 - val_accuracy: 0.6184\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 448us/step - loss: 0.4458 - accuracy: 0.8588 - val_loss: 1.0303 - val_accuracy: 0.6184\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.4327 - accuracy: 0.8588 - val_loss: 1.0583 - val_accuracy: 0.5921\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.4375 - accuracy: 0.8418 - val_loss: 1.0860 - val_accuracy: 0.5526\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.4511 - accuracy: 0.8531 - val_loss: 1.0754 - val_accuracy: 0.5526\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.4465 - accuracy: 0.8870 - val_loss: 1.0804 - val_accuracy: 0.5658\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.4104 - accuracy: 0.8814 - val_loss: 1.0969 - val_accuracy: 0.6053\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.4065 - accuracy: 0.8475 - val_loss: 1.1073 - val_accuracy: 0.5789\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.4027 - accuracy: 0.8531 - val_loss: 1.0748 - val_accuracy: 0.6053\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.3801 - accuracy: 0.8983 - val_loss: 1.1069 - val_accuracy: 0.5658\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.68 - 0s 200us/step - loss: 0.3805 - accuracy: 0.8757 - val_loss: 1.0909 - val_accuracy: 0.5658\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.3791 - accuracy: 0.8701 - val_loss: 1.1357 - val_accuracy: 0.5526\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.3640 - accuracy: 0.8701 - val_loss: 1.0977 - val_accuracy: 0.6053\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.3629 - accuracy: 0.8757 - val_loss: 1.1571 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.3487 - accuracy: 0.8870 - val_loss: 1.1148 - val_accuracy: 0.6184\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.3435 - accuracy: 0.9153 - val_loss: 1.1011 - val_accuracy: 0.6053\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.3438 - accuracy: 0.8701 - val_loss: 1.1277 - val_accuracy: 0.6184\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.3351 - accuracy: 0.8927 - val_loss: 1.1321 - val_accuracy: 0.6053\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.3267 - accuracy: 0.9040 - val_loss: 1.1468 - val_accuracy: 0.5789\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.3320 - accuracy: 0.8870 - val_loss: 1.1592 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.6689 - accuracy: 0.7797 - val_loss: 1.2454 - val_accuracy: 0.5921\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.5318 - accuracy: 0.8192 - val_loss: 1.2068 - val_accuracy: 0.5263\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.3436 - accuracy: 0.8588 - val_loss: 1.1442 - val_accuracy: 0.6053\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.3205 - accuracy: 0.9209 - val_loss: 1.1566 - val_accuracy: 0.5921\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.3195 - accuracy: 0.9040 - val_loss: 1.1739 - val_accuracy: 0.6053\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.3014 - accuracy: 0.9040 - val_loss: 1.1536 - val_accuracy: 0.5921\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.3053 - accuracy: 0.9153 - val_loss: 1.1677 - val_accuracy: 0.6053\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.3043 - accuracy: 0.9153 - val_loss: 1.1854 - val_accuracy: 0.6184\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.2988 - accuracy: 0.9096 - val_loss: 1.2097 - val_accuracy: 0.5789\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 308us/step - loss: 0.2797 - accuracy: 0.8983 - val_loss: 1.2056 - val_accuracy: 0.5921\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.2786 - accuracy: 0.9096 - val_loss: 1.2327 - val_accuracy: 0.5921\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.2694 - accuracy: 0.9209 - val_loss: 1.2267 - val_accuracy: 0.5789\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.3099 - accuracy: 0.8814 - val_loss: 1.2352 - val_accuracy: 0.5789\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.2726 - accuracy: 0.9040 - val_loss: 1.1997 - val_accuracy: 0.5658\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.2662 - accuracy: 0.9040 - val_loss: 1.2425 - val_accuracy: 0.6316\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.2642 - accuracy: 0.9096 - val_loss: 1.2609 - val_accuracy: 0.5789\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.2497 - accuracy: 0.9209 - val_loss: 1.2436 - val_accuracy: 0.5658\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.3219 - accuracy: 0.8814 - val_loss: 1.2681 - val_accuracy: 0.6053\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.2829 - accuracy: 0.9096 - val_loss: 1.2508 - val_accuracy: 0.6053\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.2656 - accuracy: 0.9153 - val_loss: 1.2803 - val_accuracy: 0.5921\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.2520 - accuracy: 0.9209 - val_loss: 1.2533 - val_accuracy: 0.6184\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.2341 - accuracy: 0.9379 - val_loss: 1.3014 - val_accuracy: 0.5921\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 289us/step - loss: 0.2488 - accuracy: 0.9153 - val_loss: 1.2904 - val_accuracy: 0.6053\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.2688 - accuracy: 0.9379 - val_loss: 1.2767 - val_accuracy: 0.5658\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.2555 - accuracy: 0.9209 - val_loss: 1.3080 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.2315 - accuracy: 0.9266 - val_loss: 1.3146 - val_accuracy: 0.5921\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.2270 - accuracy: 0.9322 - val_loss: 1.3203 - val_accuracy: 0.6184\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.2497 - accuracy: 0.9266 - val_loss: 1.3348 - val_accuracy: 0.5921\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.2259 - accuracy: 0.9322 - val_loss: 1.2815 - val_accuracy: 0.6184\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.2185 - accuracy: 0.9379 - val_loss: 1.3303 - val_accuracy: 0.6053\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.2646 - accuracy: 0.9153 - val_loss: 1.3237 - val_accuracy: 0.6053\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.2180 - accuracy: 0.9379 - val_loss: 1.3050 - val_accuracy: 0.6053\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.2135 - accuracy: 0.9435 - val_loss: 1.3494 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.2911 - accuracy: 0.8983 - val_loss: 1.3999 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.2218 - accuracy: 0.9096 - val_loss: 1.2608 - val_accuracy: 0.5921\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.2196 - accuracy: 0.9379 - val_loss: 1.3356 - val_accuracy: 0.6184\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1978 - accuracy: 0.9492 - val_loss: 1.3674 - val_accuracy: 0.6053\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.1994 - accuracy: 0.9435 - val_loss: 1.3249 - val_accuracy: 0.5921\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.2028 - accuracy: 0.9435 - val_loss: 1.3364 - val_accuracy: 0.6316\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.1943 - accuracy: 0.9492 - val_loss: 1.3435 - val_accuracy: 0.6053\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.1919 - accuracy: 0.9379 - val_loss: 1.3619 - val_accuracy: 0.5921\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.1905 - accuracy: 0.9435 - val_loss: 1.3711 - val_accuracy: 0.5921\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.1916 - accuracy: 0.9548 - val_loss: 1.3598 - val_accuracy: 0.5921\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.1920 - accuracy: 0.9379 - val_loss: 1.3848 - val_accuracy: 0.5789\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.1805 - accuracy: 0.9435 - val_loss: 1.3841 - val_accuracy: 0.5789\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.1957 - accuracy: 0.9492 - val_loss: 1.3603 - val_accuracy: 0.6184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3b887128>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 64us/step\n",
      "over-sampling test accuracy: 61.84%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel = model_sel.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 2, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1,\n",
       "       2, 0, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 1, 2, 0, 1, 0, 0, 2,\n",
       "       2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 1, 2,\n",
       "       1, 2, 0, 0, 0, 2, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model_sel.predict_classes(X_sel_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NRS152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>CFBRSa66A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "231        NY360     2     0\n",
       "139       NRS113     0     0\n",
       "4         120337     2     2\n",
       "59   CFBREBSa127     1     2\n",
       "96          GA27     2     2\n",
       "..           ...   ...   ...\n",
       "236       SR1129     2     2\n",
       "145       NRS152     2     2\n",
       "86     CFBRSa66A     0     0\n",
       "28     BCH-SA-13     1     2\n",
       "249       SR4153     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model_sel.predict_proba(X_sel_test)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547793</td>\n",
       "      <td>0.451841</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.964647</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.009885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.985219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.236063</td>\n",
       "      <td>0.694147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.993606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.027655</td>\n",
       "      <td>0.141378</td>\n",
       "      <td>0.830968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.986493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.936168</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.015564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.005631</td>\n",
       "      <td>0.110510</td>\n",
       "      <td>0.883859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.998698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.547793  0.451841  0.000366\n",
       "1   0.964647  0.025468  0.009885\n",
       "2   0.011376  0.003404  0.985219\n",
       "3   0.069790  0.236063  0.694147\n",
       "4   0.000054  0.006340  0.993606\n",
       "..       ...       ...       ...\n",
       "71  0.027655  0.141378  0.830968\n",
       "72  0.003434  0.010073  0.986493\n",
       "73  0.936168  0.048268  0.015564\n",
       "74  0.005631  0.110510  0.883859\n",
       "75  0.001301  0.000001  0.998698\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.2121 - accuracy: 0.9492 - val_loss: 1.3316 - val_accuracy: 0.5921\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.2564 - accuracy: 0.9096 - val_loss: 1.4493 - val_accuracy: 0.5658\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1995 - accuracy: 0.9548 - val_loss: 1.3716 - val_accuracy: 0.5658\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.1865 - accuracy: 0.9492 - val_loss: 1.3109 - val_accuracy: 0.5658\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1802 - accuracy: 0.9492 - val_loss: 1.3788 - val_accuracy: 0.5921\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1710 - accuracy: 0.9548 - val_loss: 1.4030 - val_accuracy: 0.5921\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1812 - accuracy: 0.9435 - val_loss: 1.4073 - val_accuracy: 0.5789\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1614 - accuracy: 0.9605 - val_loss: 1.4045 - val_accuracy: 0.5789\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.2345 - accuracy: 0.9209 - val_loss: 1.3577 - val_accuracy: 0.5921\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1802 - accuracy: 0.9435 - val_loss: 1.3508 - val_accuracy: 0.5789\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.1584 - accuracy: 0.9548 - val_loss: 1.3763 - val_accuracy: 0.6053\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.1545 - accuracy: 0.9661 - val_loss: 1.3474 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1606 - accuracy: 0.9661 - val_loss: 1.3769 - val_accuracy: 0.6184\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1787 - accuracy: 0.9435 - val_loss: 1.3986 - val_accuracy: 0.5658\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.1499 - accuracy: 0.9661 - val_loss: 1.3717 - val_accuracy: 0.6053\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1622 - accuracy: 0.9492 - val_loss: 1.3947 - val_accuracy: 0.6184\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1552 - accuracy: 0.9661 - val_loss: 1.3903 - val_accuracy: 0.5921\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1572 - accuracy: 0.9718 - val_loss: 1.4186 - val_accuracy: 0.6184\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.1456 - accuracy: 0.9718 - val_loss: 1.3866 - val_accuracy: 0.6053\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1426 - accuracy: 0.9718 - val_loss: 1.4109 - val_accuracy: 0.6184\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1485 - accuracy: 0.9605 - val_loss: 1.4057 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1446 - accuracy: 0.9605 - val_loss: 1.3893 - val_accuracy: 0.6184\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1515 - accuracy: 0.9548 - val_loss: 1.3860 - val_accuracy: 0.5921\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.1408 - accuracy: 0.9661 - val_loss: 1.3960 - val_accuracy: 0.6053\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1397 - accuracy: 0.9718 - val_loss: 1.3974 - val_accuracy: 0.6053\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1406 - accuracy: 0.9718 - val_loss: 1.4161 - val_accuracy: 0.6184\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.1384 - accuracy: 0.9718 - val_loss: 1.4241 - val_accuracy: 0.6053\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1466 - accuracy: 0.9718 - val_loss: 1.4329 - val_accuracy: 0.6053\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1271 - accuracy: 0.9718 - val_loss: 1.3992 - val_accuracy: 0.5921\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1299 - accuracy: 0.9718 - val_loss: 1.4240 - val_accuracy: 0.6316\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1473 - accuracy: 0.9605 - val_loss: 1.4104 - val_accuracy: 0.6053\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1361 - accuracy: 0.9661 - val_loss: 1.4222 - val_accuracy: 0.6184\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.1601 - accuracy: 0.9435 - val_loss: 1.4446 - val_accuracy: 0.6184\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1389 - accuracy: 0.9548 - val_loss: 1.4951 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1336 - accuracy: 0.9718 - val_loss: 1.4501 - val_accuracy: 0.6053\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.1258 - accuracy: 0.9661 - val_loss: 1.4690 - val_accuracy: 0.6053\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.1212 - accuracy: 0.9718 - val_loss: 1.4409 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1335 - accuracy: 0.9605 - val_loss: 1.4418 - val_accuracy: 0.6316\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1246 - accuracy: 0.9605 - val_loss: 1.5028 - val_accuracy: 0.6053\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.1226 - accuracy: 0.9661 - val_loss: 1.4676 - val_accuracy: 0.6184\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.1234 - accuracy: 0.9661 - val_loss: 1.4918 - val_accuracy: 0.6316\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1226 - accuracy: 0.9774 - val_loss: 1.4747 - val_accuracy: 0.6184\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.1133 - accuracy: 0.9661 - val_loss: 1.4892 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1188 - accuracy: 0.9661 - val_loss: 1.4997 - val_accuracy: 0.6184\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1213 - accuracy: 0.9661 - val_loss: 1.5199 - val_accuracy: 0.6184\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.1301 - accuracy: 0.9661 - val_loss: 1.5068 - val_accuracy: 0.6184\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.1107 - accuracy: 0.9774 - val_loss: 1.5203 - val_accuracy: 0.6184\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.1301 - accuracy: 0.9605 - val_loss: 1.5420 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1471 - accuracy: 0.9661 - val_loss: 1.5898 - val_accuracy: 0.6184\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.3021 - accuracy: 0.8814 - val_loss: 1.6730 - val_accuracy: 0.5658\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.2395 - accuracy: 0.9209 - val_loss: 1.4646 - val_accuracy: 0.6184\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1453 - accuracy: 0.9661 - val_loss: 1.5674 - val_accuracy: 0.5789\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1533 - accuracy: 0.9605 - val_loss: 1.5408 - val_accuracy: 0.6184\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.1208 - accuracy: 0.9718 - val_loss: 1.5656 - val_accuracy: 0.6316\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1167 - accuracy: 0.9605 - val_loss: 1.5372 - val_accuracy: 0.6184\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.1118 - accuracy: 0.9605 - val_loss: 1.5620 - val_accuracy: 0.6316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.1101 - accuracy: 0.9831 - val_loss: 1.5576 - val_accuracy: 0.6184\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.1141 - accuracy: 0.9605 - val_loss: 1.6472 - val_accuracy: 0.6053\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.4902 - accuracy: 0.8983 - val_loss: 2.1112 - val_accuracy: 0.5789\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.4876 - accuracy: 0.9492 - val_loss: 1.8792 - val_accuracy: 0.6184\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.3805 - accuracy: 0.9548 - val_loss: 1.7504 - val_accuracy: 0.5921\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.2678 - accuracy: 0.9605 - val_loss: 1.6064 - val_accuracy: 0.6053\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1535 - accuracy: 0.9605 - val_loss: 1.4836 - val_accuracy: 0.6053\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1178 - accuracy: 0.9718 - val_loss: 1.4672 - val_accuracy: 0.6316\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.1132 - accuracy: 0.9661 - val_loss: 1.4728 - val_accuracy: 0.5921\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.1053 - accuracy: 0.9718 - val_loss: 1.4840 - val_accuracy: 0.6053\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.1016 - accuracy: 0.9774 - val_loss: 1.4850 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 956us/step - loss: 0.0986 - accuracy: 0.9774 - val_loss: 1.4975 - val_accuracy: 0.6053\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.0966 - accuracy: 0.9718 - val_loss: 1.4862 - val_accuracy: 0.6184\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.0947 - accuracy: 0.9774 - val_loss: 1.4935 - val_accuracy: 0.6184\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.0947 - accuracy: 0.9831 - val_loss: 1.5187 - val_accuracy: 0.6184\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.0934 - accuracy: 0.9887 - val_loss: 1.5124 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 491us/step - loss: 0.0972 - accuracy: 0.9661 - val_loss: 1.5188 - val_accuracy: 0.6053\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0957 - accuracy: 0.9718 - val_loss: 1.5191 - val_accuracy: 0.6053\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.1138 - accuracy: 0.9718 - val_loss: 1.5807 - val_accuracy: 0.6184\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1036 - accuracy: 0.9661 - val_loss: 1.5875 - val_accuracy: 0.6053\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.1003 - accuracy: 0.9718 - val_loss: 1.5419 - val_accuracy: 0.6184\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.0928 - accuracy: 0.9774 - val_loss: 1.5336 - val_accuracy: 0.6316\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1037 - accuracy: 0.9831 - val_loss: 1.5971 - val_accuracy: 0.5789\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 1.5572 - val_accuracy: 0.6053\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.0922 - accuracy: 0.9887 - val_loss: 1.5725 - val_accuracy: 0.6053\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 719us/step - loss: 0.0889 - accuracy: 0.9831 - val_loss: 1.5573 - val_accuracy: 0.6316\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.0863 - accuracy: 0.9774 - val_loss: 1.5483 - val_accuracy: 0.6184\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0863 - accuracy: 0.9774 - val_loss: 1.5509 - val_accuracy: 0.6053\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0830 - accuracy: 0.9774 - val_loss: 1.5672 - val_accuracy: 0.6184\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0846 - accuracy: 0.9718 - val_loss: 1.5846 - val_accuracy: 0.6184\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0858 - accuracy: 0.9774 - val_loss: 1.5911 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.0903 - accuracy: 0.9718 - val_loss: 1.5742 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0892 - accuracy: 0.9661 - val_loss: 1.5857 - val_accuracy: 0.6184\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0776 - accuracy: 0.9774 - val_loss: 1.5896 - val_accuracy: 0.6053\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0854 - accuracy: 0.9661 - val_loss: 1.5964 - val_accuracy: 0.6184\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.0850 - accuracy: 0.9887 - val_loss: 1.5911 - val_accuracy: 0.6184\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0829 - accuracy: 0.9774 - val_loss: 1.6090 - val_accuracy: 0.6053\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 1.6246 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1465 - accuracy: 0.9548 - val_loss: 1.6948 - val_accuracy: 0.6053\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0941 - accuracy: 0.9774 - val_loss: 1.6479 - val_accuracy: 0.6053\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0874 - accuracy: 0.9774 - val_loss: 1.6382 - val_accuracy: 0.5921\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0761 - accuracy: 0.9831 - val_loss: 1.6332 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0779 - accuracy: 0.9887 - val_loss: 1.6148 - val_accuracy: 0.6184\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.0782 - accuracy: 0.9774 - val_loss: 1.6261 - val_accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "hist_sel = model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.45%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848032e-03</td>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.441349e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.155850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466081e-02</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.979626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985392e-01</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.665667e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.617341e-03</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.055758e-03</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.747076e-01</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.593112e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.838999e-01</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual        NY360          2           1  3.848032e-03   \n",
       "1       p0017kpresabs_qual       NRS113          0           0  8.441349e-01   \n",
       "2       p0017kpresabs_qual       120337          2           2  1.466081e-02   \n",
       "3       p0017kpresabs_qual  CFBREBSa127          1           0  9.985392e-01   \n",
       "4       p0017kpresabs_qual         GA27          2           2  1.665667e-08   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa131          2           1  6.617341e-03   \n",
       "604  p0040presabsSTCC_qual       NRS112          2           2  1.055758e-03   \n",
       "605  p0040presabsSTCC_qual    BCH-SA-06          0           0  8.747076e-01   \n",
       "606  p0040presabsSTCC_qual         834N          2           2  2.593112e-06   \n",
       "607  p0040presabsSTCC_qual          CA9          1           2  3.838999e-01   \n",
       "\n",
       "            1         2  \n",
       "0    0.996096  0.000056  \n",
       "1    0.000015  0.155850  \n",
       "2    0.005713  0.979626  \n",
       "3    0.000350  0.001111  \n",
       "4    0.000005  0.999995  \n",
       "..        ...       ...  \n",
       "603  0.565843  0.427540  \n",
       "604  0.045611  0.953333  \n",
       "605  0.071162  0.054130  \n",
       "606  0.000013  0.999985  \n",
       "607  0.142659  0.473441  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.47793270e-01, 4.51840800e-01, 3.65946270e-04],\n",
       "       [9.64646700e-01, 2.54682450e-02, 9.88508200e-03],\n",
       "       [1.13764815e-02, 3.40412560e-03, 9.85219360e-01],\n",
       "       [6.97899460e-02, 2.36062910e-01, 6.94147170e-01],\n",
       "       [5.38612150e-05, 6.34027400e-03, 9.93605850e-01],\n",
       "       [1.91742500e-01, 6.82658140e-01, 1.25599460e-01],\n",
       "       [2.53399200e-01, 3.08578130e-01, 4.38022670e-01],\n",
       "       [6.27517550e-02, 9.31558430e-01, 5.68989340e-03],\n",
       "       [4.05248720e-05, 7.15595050e-08, 9.99959350e-01],\n",
       "       [9.60366370e-01, 3.89166000e-02, 7.17021350e-04],\n",
       "       [8.36825800e-01, 1.57177480e-01, 5.99673500e-03],\n",
       "       [2.02666860e-01, 2.36815260e-04, 7.97096300e-01],\n",
       "       [2.18478680e-01, 5.00190500e-01, 2.81330760e-01],\n",
       "       [9.92467800e-01, 5.59619700e-03, 1.93596030e-03],\n",
       "       [1.22960415e-02, 8.44317100e-03, 9.79260740e-01],\n",
       "       [7.93340060e-02, 9.20149270e-01, 5.16795030e-04],\n",
       "       [3.21384430e-01, 5.03609900e-01, 1.75005690e-01],\n",
       "       [9.80847200e-01, 1.45017190e-02, 4.65107240e-03],\n",
       "       [1.97359170e-01, 7.20814100e-01, 8.18267600e-02],\n",
       "       [4.30030900e-02, 1.58786400e-01, 7.98210500e-01],\n",
       "       [7.94086750e-02, 8.60673800e-01, 5.99175240e-02],\n",
       "       [3.30013300e-02, 5.60951050e-01, 4.06047600e-01],\n",
       "       [1.27893950e-02, 2.29353250e-03, 9.84917100e-01],\n",
       "       [5.66264300e-01, 1.45407070e-01, 2.88328740e-01],\n",
       "       [9.99637250e-01, 1.09213680e-04, 2.53601230e-04],\n",
       "       [2.44677490e-03, 7.55851600e-02, 9.21968100e-01],\n",
       "       [9.91257900e-01, 5.33670100e-03, 3.40543180e-03],\n",
       "       [2.06398140e-01, 7.77819750e-01, 1.57820270e-02],\n",
       "       [9.60366370e-01, 3.89166000e-02, 7.17021350e-04],\n",
       "       [4.19493400e-01, 5.79953970e-01, 5.52582150e-04],\n",
       "       [4.94055450e-03, 9.93962700e-01, 1.09677660e-03],\n",
       "       [2.54473670e-03, 1.05544820e-03, 9.96399760e-01],\n",
       "       [3.31454500e-02, 7.85116000e-01, 1.81738510e-01],\n",
       "       [6.94032970e-01, 2.00874420e-01, 1.05092600e-01],\n",
       "       [2.20784500e-01, 7.52218070e-01, 2.69974950e-02],\n",
       "       [2.56010800e-01, 7.04422060e-01, 3.95671350e-02],\n",
       "       [9.60366370e-01, 3.89166000e-02, 7.17021350e-04],\n",
       "       [7.14206900e-02, 8.03248600e-01, 1.25330760e-01],\n",
       "       [1.27967770e-04, 2.08401970e-07, 9.99871850e-01],\n",
       "       [8.57224700e-01, 1.25083220e-01, 1.76921000e-02],\n",
       "       [2.85026600e-01, 7.14234300e-01, 7.39147800e-04],\n",
       "       [7.69293100e-01, 6.29797950e-02, 1.67727050e-01],\n",
       "       [8.66101150e-01, 7.84216600e-02, 5.54771400e-02],\n",
       "       [1.05153640e-02, 6.72976160e-03, 9.82754900e-01],\n",
       "       [6.47131770e-03, 1.56033970e-02, 9.77925300e-01],\n",
       "       [2.58450540e-01, 6.64991440e-01, 7.65580500e-02],\n",
       "       [3.09284260e-03, 3.46644480e-03, 9.93440700e-01],\n",
       "       [8.47258150e-01, 1.52313260e-01, 4.28625500e-04],\n",
       "       [2.02395410e-01, 1.95247270e-04, 7.97409300e-01],\n",
       "       [8.06958400e-04, 4.59074000e-03, 9.94602260e-01],\n",
       "       [4.51533900e-03, 8.59087600e-03, 9.86893800e-01],\n",
       "       [1.02107690e-02, 4.67715230e-01, 5.22074040e-01],\n",
       "       [8.54825260e-01, 1.17413620e-01, 2.77611520e-02],\n",
       "       [2.41692740e-03, 2.85491780e-02, 9.69033960e-01],\n",
       "       [6.03741600e-01, 3.96001460e-01, 2.57013700e-04],\n",
       "       [5.95033500e-01, 9.45766000e-02, 3.10389820e-01],\n",
       "       [3.71376650e-02, 9.13833260e-01, 4.90291160e-02],\n",
       "       [7.68362460e-01, 6.07385750e-02, 1.70898960e-01],\n",
       "       [3.38166470e-02, 2.35903470e-04, 9.65947400e-01],\n",
       "       [7.40398930e-03, 5.64178700e-01, 4.28417300e-01],\n",
       "       [9.60366370e-01, 3.89166000e-02, 7.17021350e-04],\n",
       "       [6.51899600e-01, 3.45029060e-01, 3.07138080e-03],\n",
       "       [8.91324900e-01, 1.04896410e-01, 3.77875290e-03],\n",
       "       [1.25021840e-03, 9.98481200e-01, 2.68542470e-04],\n",
       "       [1.76965400e-02, 9.78045940e-01, 4.25747600e-03],\n",
       "       [2.19396350e-02, 4.66270180e-01, 5.11790200e-01],\n",
       "       [4.30332870e-01, 4.32009600e-01, 1.37657500e-01],\n",
       "       [3.26187160e-01, 2.57673650e-03, 6.71236100e-01],\n",
       "       [7.45687200e-01, 3.58926240e-02, 2.18420200e-01],\n",
       "       [8.59154160e-01, 6.53803900e-02, 7.54653800e-02],\n",
       "       [4.81648900e-01, 2.60256650e-01, 2.58094500e-01],\n",
       "       [2.76546890e-02, 1.41377730e-01, 8.30967600e-01],\n",
       "       [3.43359560e-03, 1.00730530e-02, 9.86493400e-01],\n",
       "       [9.36168200e-01, 4.82680700e-02, 1.55636960e-02],\n",
       "       [5.63128900e-03, 1.10509690e-01, 8.83859040e-01],\n",
       "       [1.30054630e-03, 1.13680360e-06, 9.98698230e-01]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808727868251677"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808727868251677"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat6['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "44   CFBREBSa104     1\n",
       "170       NRS199     2\n",
       "197       NRS233     1\n",
       "238       SR1746     0\n",
       "172       NRS202     2\n",
       "..           ...   ...\n",
       "92         EUH25     2\n",
       "217       NRS260     0\n",
       "75      CFBRSa25     0\n",
       "156       NRS177     1\n",
       "105        MN055     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 658us/step - loss: 1.1542 - accuracy: 0.4011 - val_loss: 1.0861 - val_accuracy: 0.4342\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 1.0443 - accuracy: 0.4633 - val_loss: 1.0538 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 1.0133 - accuracy: 0.5367 - val_loss: 1.0260 - val_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.9923 - accuracy: 0.5424 - val_loss: 0.9969 - val_accuracy: 0.4868\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.9630 - accuracy: 0.5537 - val_loss: 0.9733 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9397 - accuracy: 0.5876 - val_loss: 0.9607 - val_accuracy: 0.5132\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.9182 - accuracy: 0.5932 - val_loss: 0.9521 - val_accuracy: 0.5395\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.8977 - accuracy: 0.5989 - val_loss: 0.9418 - val_accuracy: 0.5526\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.8765 - accuracy: 0.6215 - val_loss: 0.9378 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8590 - accuracy: 0.6328 - val_loss: 0.9418 - val_accuracy: 0.5395\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.8432 - accuracy: 0.6158 - val_loss: 0.9412 - val_accuracy: 0.5395\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.8254 - accuracy: 0.6328 - val_loss: 0.9336 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.8074 - accuracy: 0.6610 - val_loss: 0.9272 - val_accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.7966 - accuracy: 0.6667 - val_loss: 0.9217 - val_accuracy: 0.5395\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.7806 - accuracy: 0.6949 - val_loss: 0.9191 - val_accuracy: 0.5526\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7686 - accuracy: 0.7006 - val_loss: 0.9221 - val_accuracy: 0.5658\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.7531 - accuracy: 0.6949 - val_loss: 0.9168 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.7411 - accuracy: 0.7119 - val_loss: 0.9058 - val_accuracy: 0.5789\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.7278 - accuracy: 0.7401 - val_loss: 0.9036 - val_accuracy: 0.5789\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.7185 - accuracy: 0.7288 - val_loss: 0.9091 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.7067 - accuracy: 0.7119 - val_loss: 0.9034 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6918 - accuracy: 0.7401 - val_loss: 0.9012 - val_accuracy: 0.5921\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6817 - accuracy: 0.7401 - val_loss: 0.9015 - val_accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.6746 - accuracy: 0.7458 - val_loss: 0.9039 - val_accuracy: 0.6184\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.6598 - accuracy: 0.7571 - val_loss: 0.9094 - val_accuracy: 0.6053\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.6506 - accuracy: 0.7684 - val_loss: 0.9049 - val_accuracy: 0.6184\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6395 - accuracy: 0.7627 - val_loss: 0.8960 - val_accuracy: 0.6316\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6304 - accuracy: 0.7966 - val_loss: 0.8920 - val_accuracy: 0.6053\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.6220 - accuracy: 0.7966 - val_loss: 0.8941 - val_accuracy: 0.6316\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.6104 - accuracy: 0.8136 - val_loss: 0.8919 - val_accuracy: 0.6184\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.5995 - accuracy: 0.8192 - val_loss: 0.8964 - val_accuracy: 0.5921\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.5921 - accuracy: 0.7966 - val_loss: 0.8999 - val_accuracy: 0.5921\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.5814 - accuracy: 0.8079 - val_loss: 0.8950 - val_accuracy: 0.6184\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.5710 - accuracy: 0.8362 - val_loss: 0.8888 - val_accuracy: 0.6184\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.5640 - accuracy: 0.8362 - val_loss: 0.8814 - val_accuracy: 0.6184\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.5539 - accuracy: 0.8475 - val_loss: 0.8839 - val_accuracy: 0.6447\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.5482 - accuracy: 0.8531 - val_loss: 0.8821 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.5349 - accuracy: 0.8588 - val_loss: 0.8806 - val_accuracy: 0.6447\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.5290 - accuracy: 0.8588 - val_loss: 0.8851 - val_accuracy: 0.6316\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.5201 - accuracy: 0.8588 - val_loss: 0.8840 - val_accuracy: 0.6053\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5086 - accuracy: 0.8644 - val_loss: 0.8810 - val_accuracy: 0.6184\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.5061 - accuracy: 0.8644 - val_loss: 0.8752 - val_accuracy: 0.6184\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.4964 - accuracy: 0.8814 - val_loss: 0.8694 - val_accuracy: 0.6447\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.4879 - accuracy: 0.8983 - val_loss: 0.8747 - val_accuracy: 0.6316\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.4832 - accuracy: 0.8757 - val_loss: 0.8920 - val_accuracy: 0.6053\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.4756 - accuracy: 0.8701 - val_loss: 0.8860 - val_accuracy: 0.5921\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.4670 - accuracy: 0.8757 - val_loss: 0.8790 - val_accuracy: 0.6053\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.4597 - accuracy: 0.8927 - val_loss: 0.8804 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.4561 - accuracy: 0.8983 - val_loss: 0.8709 - val_accuracy: 0.6184\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.4467 - accuracy: 0.8870 - val_loss: 0.8802 - val_accuracy: 0.5789\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.4390 - accuracy: 0.8757 - val_loss: 0.8804 - val_accuracy: 0.5789\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4331 - accuracy: 0.8757 - val_loss: 0.8809 - val_accuracy: 0.5789\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.4288 - accuracy: 0.8814 - val_loss: 0.8828 - val_accuracy: 0.6053\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.4243 - accuracy: 0.9153 - val_loss: 0.8772 - val_accuracy: 0.6316\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.4189 - accuracy: 0.9040 - val_loss: 0.8767 - val_accuracy: 0.5921\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.4098 - accuracy: 0.8983 - val_loss: 0.8846 - val_accuracy: 0.5789\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 92us/step - loss: 0.4023 - accuracy: 0.8983 - val_loss: 0.8803 - val_accuracy: 0.5921\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.3984 - accuracy: 0.9040 - val_loss: 0.8762 - val_accuracy: 0.6184\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3929 - accuracy: 0.9153 - val_loss: 0.8826 - val_accuracy: 0.5921\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.3881 - accuracy: 0.9209 - val_loss: 0.8918 - val_accuracy: 0.5789\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.3789 - accuracy: 0.9096 - val_loss: 0.8887 - val_accuracy: 0.5789\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.3749 - accuracy: 0.9153 - val_loss: 0.8781 - val_accuracy: 0.6316\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.3737 - accuracy: 0.9209 - val_loss: 0.8753 - val_accuracy: 0.6053\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.3668 - accuracy: 0.9209 - val_loss: 0.8822 - val_accuracy: 0.6053\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.3623 - accuracy: 0.9040 - val_loss: 0.8952 - val_accuracy: 0.6053\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.3563 - accuracy: 0.9096 - val_loss: 0.8905 - val_accuracy: 0.5921\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.3508 - accuracy: 0.9209 - val_loss: 0.8847 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.3464 - accuracy: 0.9153 - val_loss: 0.8829 - val_accuracy: 0.6184\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.3404 - accuracy: 0.9209 - val_loss: 0.8815 - val_accuracy: 0.6184\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.3372 - accuracy: 0.9266 - val_loss: 0.8942 - val_accuracy: 0.5921\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.3333 - accuracy: 0.9266 - val_loss: 0.9009 - val_accuracy: 0.6184\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.3272 - accuracy: 0.9266 - val_loss: 0.8990 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.3243 - accuracy: 0.9322 - val_loss: 0.8983 - val_accuracy: 0.6184\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.3202 - accuracy: 0.9379 - val_loss: 0.8963 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.3169 - accuracy: 0.9266 - val_loss: 0.8962 - val_accuracy: 0.6053\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.3112 - accuracy: 0.9266 - val_loss: 0.8966 - val_accuracy: 0.5921\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.3087 - accuracy: 0.9435 - val_loss: 0.8974 - val_accuracy: 0.5921\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.3038 - accuracy: 0.9379 - val_loss: 0.8994 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.2991 - accuracy: 0.9322 - val_loss: 0.9074 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.2971 - accuracy: 0.9322 - val_loss: 0.9130 - val_accuracy: 0.6184\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2975 - accuracy: 0.9492 - val_loss: 0.9113 - val_accuracy: 0.5921\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.2900 - accuracy: 0.9435 - val_loss: 0.9101 - val_accuracy: 0.6053\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2855 - accuracy: 0.9379 - val_loss: 0.9110 - val_accuracy: 0.6184\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2847 - accuracy: 0.9322 - val_loss: 0.9142 - val_accuracy: 0.6053\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2806 - accuracy: 0.9492 - val_loss: 0.9161 - val_accuracy: 0.5921\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2756 - accuracy: 0.9435 - val_loss: 0.9106 - val_accuracy: 0.5921\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.2705 - accuracy: 0.9435 - val_loss: 0.9089 - val_accuracy: 0.6053\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.2698 - accuracy: 0.9379 - val_loss: 0.9085 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.2684 - accuracy: 0.9322 - val_loss: 0.9177 - val_accuracy: 0.6053\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.2603 - accuracy: 0.9379 - val_loss: 0.9158 - val_accuracy: 0.6184\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.2580 - accuracy: 0.9435 - val_loss: 0.9230 - val_accuracy: 0.6184\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2568 - accuracy: 0.9435 - val_loss: 0.9256 - val_accuracy: 0.6184\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.2548 - accuracy: 0.9379 - val_loss: 0.9231 - val_accuracy: 0.5921\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.2486 - accuracy: 0.9435 - val_loss: 0.9159 - val_accuracy: 0.6053\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.2476 - accuracy: 0.9661 - val_loss: 0.9178 - val_accuracy: 0.6053\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2422 - accuracy: 0.9492 - val_loss: 0.9292 - val_accuracy: 0.6053\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.2444 - accuracy: 0.9548 - val_loss: 0.9415 - val_accuracy: 0.6184\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2391 - accuracy: 0.9548 - val_loss: 0.9272 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.2357 - accuracy: 0.9548 - val_loss: 0.9306 - val_accuracy: 0.6316\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2342 - accuracy: 0.9605 - val_loss: 0.9308 - val_accuracy: 0.6184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a4ff898>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 142us/step\n",
      "test accuracy: 63.16%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 0, 1, 2, 0, 1, 2, 1, 2,\n",
       "       1, 1, 1, 1, 0, 1, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 2,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model_sel2.predict_classes(X_sel_test)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "44   CFBREBSa104     1     2\n",
       "170       NRS199     2     2\n",
       "197       NRS233     1     0\n",
       "238       SR1746     0     2\n",
       "172       NRS202     2     2\n",
       "..           ...   ...   ...\n",
       "92         EUH25     2     0\n",
       "217       NRS260     0     0\n",
       "75      CFBRSa25     0     0\n",
       "156       NRS177     1     1\n",
       "105        MN055     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model_sel2.predict_proba(X_sel_test)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222783</td>\n",
       "      <td>0.039238</td>\n",
       "      <td>0.737979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.190075</td>\n",
       "      <td>0.206699</td>\n",
       "      <td>0.603226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500600</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>0.292469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350031</td>\n",
       "      <td>0.016853</td>\n",
       "      <td>0.633117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.043573</td>\n",
       "      <td>0.946814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.837619</td>\n",
       "      <td>0.137569</td>\n",
       "      <td>0.024812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.980481</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.613046</td>\n",
       "      <td>0.172551</td>\n",
       "      <td>0.214402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.985286</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.050863</td>\n",
       "      <td>0.033736</td>\n",
       "      <td>0.915401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.222783  0.039238  0.737979\n",
       "1   0.190075  0.206699  0.603226\n",
       "2   0.500600  0.206930  0.292469\n",
       "3   0.350031  0.016853  0.633117\n",
       "4   0.009613  0.043573  0.946814\n",
       "..       ...       ...       ...\n",
       "71  0.837619  0.137569  0.024812\n",
       "72  0.980481  0.016112  0.003407\n",
       "73  0.613046  0.172551  0.214402\n",
       "74  0.008814  0.985286  0.005900\n",
       "75  0.050863  0.033736  0.915401\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.2492 - accuracy: 0.9266 - val_loss: 0.8825 - val_accuracy: 0.6053\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.2445 - accuracy: 0.9379 - val_loss: 0.8834 - val_accuracy: 0.6184\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.2415 - accuracy: 0.9435 - val_loss: 0.8892 - val_accuracy: 0.6184\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2386 - accuracy: 0.9492 - val_loss: 0.8905 - val_accuracy: 0.6184\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.2358 - accuracy: 0.9379 - val_loss: 0.8889 - val_accuracy: 0.6184\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.2373 - accuracy: 0.9435 - val_loss: 0.8886 - val_accuracy: 0.6184\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.2317 - accuracy: 0.9435 - val_loss: 0.8962 - val_accuracy: 0.6184\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2289 - accuracy: 0.9548 - val_loss: 0.9014 - val_accuracy: 0.6184\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.2281 - accuracy: 0.9548 - val_loss: 0.8977 - val_accuracy: 0.6184\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.2238 - accuracy: 0.9605 - val_loss: 0.8948 - val_accuracy: 0.6184\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.2227 - accuracy: 0.9661 - val_loss: 0.8985 - val_accuracy: 0.6184\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2210 - accuracy: 0.9605 - val_loss: 0.8981 - val_accuracy: 0.6184\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.2194 - accuracy: 0.9605 - val_loss: 0.9158 - val_accuracy: 0.6184\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.2174 - accuracy: 0.9548 - val_loss: 0.9212 - val_accuracy: 0.6184\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.2143 - accuracy: 0.9492 - val_loss: 0.9166 - val_accuracy: 0.6053\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.2148 - accuracy: 0.9605 - val_loss: 0.9032 - val_accuracy: 0.6184\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.2107 - accuracy: 0.9661 - val_loss: 0.9101 - val_accuracy: 0.6184\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2067 - accuracy: 0.9548 - val_loss: 0.9170 - val_accuracy: 0.6184\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.2054 - accuracy: 0.9605 - val_loss: 0.9245 - val_accuracy: 0.6184\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.2027 - accuracy: 0.9605 - val_loss: 0.9206 - val_accuracy: 0.6184\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.2017 - accuracy: 0.9661 - val_loss: 0.9214 - val_accuracy: 0.6184\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.2024 - accuracy: 0.9661 - val_loss: 0.9185 - val_accuracy: 0.6184\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1967 - accuracy: 0.9661 - val_loss: 0.9281 - val_accuracy: 0.6184\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1982 - accuracy: 0.9605 - val_loss: 0.9378 - val_accuracy: 0.6184\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1943 - accuracy: 0.9605 - val_loss: 0.9233 - val_accuracy: 0.6184\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1945 - accuracy: 0.9718 - val_loss: 0.9215 - val_accuracy: 0.6184\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1901 - accuracy: 0.9718 - val_loss: 0.9283 - val_accuracy: 0.6184\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1910 - accuracy: 0.9605 - val_loss: 0.9429 - val_accuracy: 0.6184\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1864 - accuracy: 0.9605 - val_loss: 0.9423 - val_accuracy: 0.6184\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1873 - accuracy: 0.9605 - val_loss: 0.9364 - val_accuracy: 0.6184\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.1837 - accuracy: 0.9605 - val_loss: 0.9367 - val_accuracy: 0.6184\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.1808 - accuracy: 0.9548 - val_loss: 0.9446 - val_accuracy: 0.6184\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1784 - accuracy: 0.9605 - val_loss: 0.9451 - val_accuracy: 0.6184\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1763 - accuracy: 0.9605 - val_loss: 0.9500 - val_accuracy: 0.6184\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1752 - accuracy: 0.9774 - val_loss: 0.9505 - val_accuracy: 0.6184\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.1749 - accuracy: 0.9718 - val_loss: 0.9480 - val_accuracy: 0.6184\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1753 - accuracy: 0.9605 - val_loss: 0.9646 - val_accuracy: 0.6184\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1725 - accuracy: 0.9548 - val_loss: 0.9572 - val_accuracy: 0.6184\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1688 - accuracy: 0.9661 - val_loss: 0.9567 - val_accuracy: 0.6184\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.1674 - accuracy: 0.9718 - val_loss: 0.9580 - val_accuracy: 0.6184\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1664 - accuracy: 0.9661 - val_loss: 0.9639 - val_accuracy: 0.6184\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1649 - accuracy: 0.9718 - val_loss: 0.9592 - val_accuracy: 0.6184\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1641 - accuracy: 0.9661 - val_loss: 0.9598 - val_accuracy: 0.6184\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.1637 - accuracy: 0.9774 - val_loss: 0.9694 - val_accuracy: 0.6184\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 58us/step - loss: 0.1608 - accuracy: 0.9661 - val_loss: 0.9697 - val_accuracy: 0.6184\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 63us/step - loss: 0.1606 - accuracy: 0.9661 - val_loss: 0.9798 - val_accuracy: 0.6184\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1589 - accuracy: 0.9605 - val_loss: 0.9759 - val_accuracy: 0.6184\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.1561 - accuracy: 0.9718 - val_loss: 0.9704 - val_accuracy: 0.6184\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.1582 - accuracy: 0.9718 - val_loss: 0.9744 - val_accuracy: 0.6053\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1541 - accuracy: 0.9774 - val_loss: 0.9761 - val_accuracy: 0.6184\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.1552 - accuracy: 0.9718 - val_loss: 0.9856 - val_accuracy: 0.6184\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.1536 - accuracy: 0.9718 - val_loss: 0.9879 - val_accuracy: 0.6184\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1500 - accuracy: 0.9718 - val_loss: 0.9847 - val_accuracy: 0.6184\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1484 - accuracy: 0.9774 - val_loss: 0.9801 - val_accuracy: 0.6184\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.1503 - accuracy: 0.9774 - val_loss: 0.9855 - val_accuracy: 0.6184\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1472 - accuracy: 0.9774 - val_loss: 0.9907 - val_accuracy: 0.6184\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1466 - accuracy: 0.9774 - val_loss: 0.9983 - val_accuracy: 0.6184\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.1434 - accuracy: 0.9774 - val_loss: 1.0019 - val_accuracy: 0.6184\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1428 - accuracy: 0.9718 - val_loss: 1.0019 - val_accuracy: 0.6184\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1440 - accuracy: 0.9661 - val_loss: 0.9968 - val_accuracy: 0.6184\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1420 - accuracy: 0.9774 - val_loss: 1.0013 - val_accuracy: 0.6184\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.1414 - accuracy: 0.9718 - val_loss: 1.0077 - val_accuracy: 0.6184\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.1380 - accuracy: 0.9774 - val_loss: 1.0030 - val_accuracy: 0.6053\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1384 - accuracy: 0.9774 - val_loss: 1.0033 - val_accuracy: 0.6184\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1364 - accuracy: 0.9774 - val_loss: 1.0069 - val_accuracy: 0.6184\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1353 - accuracy: 0.9774 - val_loss: 1.0144 - val_accuracy: 0.6184\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.1338 - accuracy: 0.9718 - val_loss: 1.0232 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.1338 - accuracy: 0.9661 - val_loss: 1.0316 - val_accuracy: 0.6184\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.1331 - accuracy: 0.9774 - val_loss: 1.0281 - val_accuracy: 0.6053\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.1323 - accuracy: 0.9831 - val_loss: 1.0094 - val_accuracy: 0.6184\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1320 - accuracy: 0.9831 - val_loss: 1.0127 - val_accuracy: 0.6184\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1312 - accuracy: 0.9718 - val_loss: 1.0265 - val_accuracy: 0.6184\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1279 - accuracy: 0.9831 - val_loss: 1.0309 - val_accuracy: 0.6053\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.1302 - accuracy: 0.9774 - val_loss: 1.0232 - val_accuracy: 0.6184\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1273 - accuracy: 0.9774 - val_loss: 1.0253 - val_accuracy: 0.6184\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.1254 - accuracy: 0.9774 - val_loss: 1.0437 - val_accuracy: 0.6053\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.1274 - accuracy: 0.9718 - val_loss: 1.0512 - val_accuracy: 0.6184\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.1232 - accuracy: 0.9774 - val_loss: 1.0386 - val_accuracy: 0.6184\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1245 - accuracy: 0.9831 - val_loss: 1.0302 - val_accuracy: 0.6184\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.1239 - accuracy: 0.9831 - val_loss: 1.0369 - val_accuracy: 0.6184\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.1223 - accuracy: 0.9831 - val_loss: 1.0606 - val_accuracy: 0.6184\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.1210 - accuracy: 0.9774 - val_loss: 1.0705 - val_accuracy: 0.6053\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.1198 - accuracy: 0.9831 - val_loss: 1.0601 - val_accuracy: 0.6053\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.1195 - accuracy: 0.9831 - val_loss: 1.0436 - val_accuracy: 0.6053\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.1186 - accuracy: 0.9774 - val_loss: 1.0488 - val_accuracy: 0.6316\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.1162 - accuracy: 0.9887 - val_loss: 1.0618 - val_accuracy: 0.6184\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1151 - accuracy: 0.9774 - val_loss: 1.0714 - val_accuracy: 0.6184\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.1166 - accuracy: 0.9831 - val_loss: 1.0678 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1148 - accuracy: 0.9887 - val_loss: 1.0544 - val_accuracy: 0.6184\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.1135 - accuracy: 0.9887 - val_loss: 1.0615 - val_accuracy: 0.6184\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.1134 - accuracy: 0.9887 - val_loss: 1.0740 - val_accuracy: 0.6053\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.1120 - accuracy: 0.9831 - val_loss: 1.0728 - val_accuracy: 0.6053\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1115 - accuracy: 0.9831 - val_loss: 1.0788 - val_accuracy: 0.6184\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.1105 - accuracy: 0.9774 - val_loss: 1.0783 - val_accuracy: 0.6184\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.1088 - accuracy: 0.9831 - val_loss: 1.0764 - val_accuracy: 0.6184\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.1090 - accuracy: 0.9831 - val_loss: 1.0764 - val_accuracy: 0.6184\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.1075 - accuracy: 0.9831 - val_loss: 1.0861 - val_accuracy: 0.6053\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.1072 - accuracy: 0.9831 - val_loss: 1.0908 - val_accuracy: 0.6053\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.1058 - accuracy: 0.9774 - val_loss: 1.0933 - val_accuracy: 0.6053\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.1078 - accuracy: 0.9774 - val_loss: 1.0949 - val_accuracy: 0.6316\n"
     ]
    }
   ],
   "source": [
    "hist_sel2 = model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.95%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.290039e-09</td>\n",
       "      <td>1.567630e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.856965e-05</td>\n",
       "      <td>2.843749e-03</td>\n",
       "      <td>9.971277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999446e-01</td>\n",
       "      <td>4.541289e-06</td>\n",
       "      <td>5.090974e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.282367e-02</td>\n",
       "      <td>7.075194e-04</td>\n",
       "      <td>9.364688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.229589e-03</td>\n",
       "      <td>2.163908e-05</td>\n",
       "      <td>9.917488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>9.959286e-01</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>9.996691e-01</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>9.999915e-01</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>1.480882e-02</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>9.994158e-01</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  CFBREBSa104          1           2  1.290039e-09   \n",
       "1       p0017kpresabs_qual       NRS199          2           2  2.856965e-05   \n",
       "2       p0017kpresabs_qual       NRS233          1           0  9.999446e-01   \n",
       "3       p0017kpresabs_qual       SR1746          0           2  6.282367e-02   \n",
       "4       p0017kpresabs_qual       NRS202          2           2  8.229589e-03   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual         GA27          2           1  3.964591e-03   \n",
       "604  p0040presabsSTCC_qual        GA231          2           1  3.309226e-04   \n",
       "605  p0040presabsSTCC_qual       SR1287          0           1  8.445997e-06   \n",
       "606  p0040presabsSTCC_qual          506          2           0  6.516150e-01   \n",
       "607  p0040presabsSTCC_qual       NRS001          1           1  5.841915e-04   \n",
       "\n",
       "                1             2  \n",
       "0    1.567630e-07  9.999999e-01  \n",
       "1    2.843749e-03  9.971277e-01  \n",
       "2    4.541289e-06  5.090974e-05  \n",
       "3    7.075194e-04  9.364688e-01  \n",
       "4    2.163908e-05  9.917488e-01  \n",
       "..            ...           ...  \n",
       "603  9.959286e-01  1.068284e-04  \n",
       "604  9.996691e-01  6.232397e-10  \n",
       "605  9.999915e-01  1.182947e-13  \n",
       "606  1.480882e-02  3.335762e-01  \n",
       "607  9.994158e-01  6.525528e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22783210e-01, 3.92377700e-02, 7.37979050e-01],\n",
       "       [1.90074920e-01, 2.06699490e-01, 6.03225600e-01],\n",
       "       [5.00600460e-01, 2.06930040e-01, 2.92469470e-01],\n",
       "       [3.50030750e-01, 1.68527270e-02, 6.33116540e-01],\n",
       "       [9.61318500e-03, 4.35730600e-02, 9.46813760e-01],\n",
       "       [1.96084900e-02, 3.02962480e-01, 6.77429100e-01],\n",
       "       [5.31811030e-03, 2.47340170e-02, 9.69947900e-01],\n",
       "       [6.63762000e-01, 2.74558340e-01, 6.16796580e-02],\n",
       "       [2.40310800e-02, 9.45180240e-01, 3.07886770e-02],\n",
       "       [5.51100500e-01, 3.27758400e-01, 1.21141030e-01],\n",
       "       [2.69468930e-01, 5.62479850e-01, 1.68051230e-01],\n",
       "       [2.92012730e-02, 6.46264300e-01, 3.24534420e-01],\n",
       "       [6.47047940e-01, 3.19830360e-01, 3.31217800e-02],\n",
       "       [1.46860880e-02, 4.71504480e-02, 9.38163400e-01],\n",
       "       [6.98584260e-01, 2.82217030e-01, 1.91987300e-02],\n",
       "       [1.21431640e-01, 4.56085000e-01, 4.22483350e-01],\n",
       "       [4.79260620e-01, 3.67251800e-01, 1.53487560e-01],\n",
       "       [7.86176150e-01, 1.16117930e-01, 9.77059450e-02],\n",
       "       [9.58233200e-03, 9.48255300e-01, 4.21623140e-02],\n",
       "       [8.14013100e-01, 8.58856800e-02, 1.00101190e-01],\n",
       "       [3.80161500e-02, 5.57380600e-01, 4.04603240e-01],\n",
       "       [7.03866500e-01, 2.08972510e-01, 8.71609800e-02],\n",
       "       [8.24009600e-01, 1.73887070e-01, 2.10335340e-03],\n",
       "       [6.38716500e-01, 1.93452310e-01, 1.67831140e-01],\n",
       "       [5.31149500e-01, 3.43176050e-02, 4.34532900e-01],\n",
       "       [6.81126060e-01, 2.63987240e-01, 5.48867840e-02],\n",
       "       [9.16844070e-01, 8.19183800e-02, 1.23760550e-03],\n",
       "       [8.07109900e-03, 1.34246600e-01, 8.57682300e-01],\n",
       "       [1.61302870e-02, 2.09773470e-01, 7.74096200e-01],\n",
       "       [9.03544660e-01, 9.26339850e-02, 3.82141470e-03],\n",
       "       [4.72264950e-01, 3.59481500e-01, 1.68253560e-01],\n",
       "       [3.81689200e-02, 3.05947500e-01, 6.55883550e-01],\n",
       "       [8.58777200e-01, 6.86325300e-02, 7.25902400e-02],\n",
       "       [3.16018030e-03, 1.01367250e-02, 9.86703040e-01],\n",
       "       [1.72386590e-01, 5.06378050e-01, 3.21235400e-01],\n",
       "       [1.01896270e-01, 2.85577000e-01, 6.12526800e-01],\n",
       "       [6.83367130e-01, 2.25574050e-01, 9.10587600e-02],\n",
       "       [9.14572300e-02, 6.68195900e-01, 2.40346830e-01],\n",
       "       [9.09494760e-04, 5.36183730e-03, 9.93728640e-01],\n",
       "       [8.29495200e-01, 1.45340500e-01, 2.51642730e-02],\n",
       "       [8.07357800e-02, 7.79299300e-01, 1.39964860e-01],\n",
       "       [5.65545300e-04, 5.58687600e-04, 9.98875800e-01],\n",
       "       [6.49767150e-02, 6.84529600e-01, 2.50493650e-01],\n",
       "       [7.78175200e-04, 9.30330950e-06, 9.99212500e-01],\n",
       "       [1.15461715e-01, 8.48660900e-01, 3.58773620e-02],\n",
       "       [9.79636500e-02, 6.09556140e-01, 2.92480200e-01],\n",
       "       [6.50695100e-02, 8.24633240e-01, 1.10297270e-01],\n",
       "       [2.42699130e-01, 7.36717800e-01, 2.05830190e-02],\n",
       "       [8.28480840e-01, 1.41811770e-01, 2.97073800e-02],\n",
       "       [2.32342900e-01, 5.62624000e-01, 2.05033050e-01],\n",
       "       [5.01635000e-03, 1.84405670e-01, 8.10577900e-01],\n",
       "       [9.38059700e-01, 5.82535600e-02, 3.68676780e-03],\n",
       "       [6.76285740e-01, 2.35848720e-01, 8.78654350e-02],\n",
       "       [5.25303300e-01, 4.33010100e-01, 4.16866430e-02],\n",
       "       [8.29220050e-04, 2.66600540e-03, 9.96504800e-01],\n",
       "       [5.14786960e-01, 4.30766460e-01, 5.44465670e-02],\n",
       "       [4.93446440e-01, 3.12503500e-01, 1.94050060e-01],\n",
       "       [3.29227200e-04, 1.78436470e-02, 9.81827100e-01],\n",
       "       [9.45596300e-01, 4.13118940e-02, 1.30916955e-02],\n",
       "       [7.21198260e-01, 2.05236610e-01, 7.35651600e-02],\n",
       "       [5.16741630e-01, 8.90716240e-02, 3.94186760e-01],\n",
       "       [2.20242920e-02, 9.19765060e-01, 5.82106000e-02],\n",
       "       [1.88835810e-01, 2.88941520e-02, 7.82270100e-01],\n",
       "       [9.05265200e-03, 1.62343590e-02, 9.74712970e-01],\n",
       "       [8.92753540e-01, 8.64531500e-02, 2.07933280e-02],\n",
       "       [2.71200800e-02, 2.82940060e-01, 6.89939860e-01],\n",
       "       [6.87768600e-01, 2.66245900e-01, 4.59855420e-02],\n",
       "       [7.31253560e-01, 2.41182580e-01, 2.75638480e-02],\n",
       "       [9.99129950e-01, 6.57900940e-04, 2.12093070e-04],\n",
       "       [1.57376350e-01, 1.11389820e-04, 8.42512250e-01],\n",
       "       [4.38124300e-04, 5.73511120e-06, 9.99556100e-01],\n",
       "       [8.37619100e-01, 1.37568730e-01, 2.48122600e-02],\n",
       "       [9.80481200e-01, 1.61121250e-02, 3.40663900e-03],\n",
       "       [6.13046200e-01, 1.72551300e-01, 2.14402400e-01],\n",
       "       [8.81391300e-03, 9.85285940e-01, 5.90009300e-03],\n",
       "       [5.08633070e-02, 3.37359800e-02, 9.15400740e-01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905185643280882"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905185643280882"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat7['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test\n",
       "222    NRS271     1\n",
       "242    SR2852     2\n",
       "34       CA39     2\n",
       "221    NRS266     1\n",
       "230     NY356     2\n",
       "..        ...   ...\n",
       "105     MN055     2\n",
       "67   CFBRSa04     0\n",
       "235    SR1065     0\n",
       "190    NRS224     1\n",
       "178    NRS210     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 889us/step - loss: 1.0886 - accuracy: 0.4520 - val_loss: 1.0580 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.9605 - accuracy: 0.5424 - val_loss: 1.0466 - val_accuracy: 0.4868\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.9203 - accuracy: 0.5537 - val_loss: 1.0472 - val_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.8863 - accuracy: 0.6045 - val_loss: 1.0410 - val_accuracy: 0.5395\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.8428 - accuracy: 0.6497 - val_loss: 1.0127 - val_accuracy: 0.4737\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.8386 - accuracy: 0.6610 - val_loss: 1.0035 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.7976 - accuracy: 0.6667 - val_loss: 1.0048 - val_accuracy: 0.5658\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.7822 - accuracy: 0.6667 - val_loss: 1.0368 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.7456 - accuracy: 0.7119 - val_loss: 1.0185 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.7438 - accuracy: 0.6723 - val_loss: 0.9966 - val_accuracy: 0.4868\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.6885 - accuracy: 0.7627 - val_loss: 1.0271 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.6628 - accuracy: 0.7345 - val_loss: 0.9998 - val_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.6433 - accuracy: 0.7853 - val_loss: 0.9671 - val_accuracy: 0.5132\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6106 - accuracy: 0.7966 - val_loss: 1.0085 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6017 - accuracy: 0.7571 - val_loss: 1.0464 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.5617 - accuracy: 0.8079 - val_loss: 0.9974 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.5608 - accuracy: 0.7966 - val_loss: 1.0805 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.5342 - accuracy: 0.7853 - val_loss: 1.0528 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.5412 - accuracy: 0.7853 - val_loss: 1.0330 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.5085 - accuracy: 0.7966 - val_loss: 1.1348 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.4948 - accuracy: 0.8362 - val_loss: 1.1216 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.4457 - accuracy: 0.8757 - val_loss: 1.0906 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.4436 - accuracy: 0.8475 - val_loss: 1.1505 - val_accuracy: 0.5132\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.4263 - accuracy: 0.8418 - val_loss: 1.1371 - val_accuracy: 0.4737\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.4030 - accuracy: 0.8588 - val_loss: 1.0901 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.3886 - accuracy: 0.8531 - val_loss: 1.1272 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.3901 - accuracy: 0.8362 - val_loss: 1.1223 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.3650 - accuracy: 0.8983 - val_loss: 1.1070 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.4002 - accuracy: 0.8588 - val_loss: 1.1430 - val_accuracy: 0.5395\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.4556 - accuracy: 0.8475 - val_loss: 1.1572 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.3515 - accuracy: 0.8588 - val_loss: 1.1373 - val_accuracy: 0.4868\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.3186 - accuracy: 0.8870 - val_loss: 1.1062 - val_accuracy: 0.5263\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2897 - accuracy: 0.9266 - val_loss: 1.1116 - val_accuracy: 0.5395\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.2997 - accuracy: 0.9153 - val_loss: 1.1889 - val_accuracy: 0.5263\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.2896 - accuracy: 0.9040 - val_loss: 1.1324 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.3148 - accuracy: 0.8927 - val_loss: 1.1782 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.2572 - accuracy: 0.9322 - val_loss: 1.1345 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.2476 - accuracy: 0.9153 - val_loss: 1.2043 - val_accuracy: 0.5526\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 544us/step - loss: 0.2333 - accuracy: 0.9379 - val_loss: 1.1722 - val_accuracy: 0.5526\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.2324 - accuracy: 0.9435 - val_loss: 1.2357 - val_accuracy: 0.5263\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.2296 - accuracy: 0.9153 - val_loss: 1.2076 - val_accuracy: 0.5132\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.2303 - accuracy: 0.9266 - val_loss: 1.2402 - val_accuracy: 0.5526\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.2273 - accuracy: 0.9435 - val_loss: 1.4383 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.2961 - accuracy: 0.9040 - val_loss: 1.4768 - val_accuracy: 0.5395\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.3755 - accuracy: 0.8814 - val_loss: 1.4381 - val_accuracy: 0.5132\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.2437 - accuracy: 0.9153 - val_loss: 1.3621 - val_accuracy: 0.5263\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.2371 - accuracy: 0.8927 - val_loss: 1.3331 - val_accuracy: 0.5132\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.2085 - accuracy: 0.9096 - val_loss: 1.2928 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.2148 - accuracy: 0.9266 - val_loss: 1.3844 - val_accuracy: 0.5263\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.1787 - accuracy: 0.9548 - val_loss: 1.3139 - val_accuracy: 0.5658\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 380us/step - loss: 0.1781 - accuracy: 0.9605 - val_loss: 1.3517 - val_accuracy: 0.5395\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.1739 - accuracy: 0.9548 - val_loss: 1.3353 - val_accuracy: 0.5395\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.1928 - accuracy: 0.9379 - val_loss: 1.3243 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.1753 - accuracy: 0.9435 - val_loss: 1.3223 - val_accuracy: 0.5789\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.1597 - accuracy: 0.9605 - val_loss: 1.3632 - val_accuracy: 0.5395\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.1821 - accuracy: 0.9266 - val_loss: 1.3286 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.1618 - accuracy: 0.9435 - val_loss: 1.4755 - val_accuracy: 0.5132\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.1824 - accuracy: 0.9379 - val_loss: 1.4936 - val_accuracy: 0.5132\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 371us/step - loss: 0.1665 - accuracy: 0.9548 - val_loss: 1.4787 - val_accuracy: 0.5263\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.1541 - accuracy: 0.9548 - val_loss: 1.4259 - val_accuracy: 0.5395\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 278us/step - loss: 0.1432 - accuracy: 0.9661 - val_loss: 1.4613 - val_accuracy: 0.5395\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.1726 - accuracy: 0.9435 - val_loss: 1.4678 - val_accuracy: 0.5395\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.1333 - accuracy: 0.9605 - val_loss: 1.5058 - val_accuracy: 0.5395\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.2154 - accuracy: 0.9322 - val_loss: 1.5598 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.1830 - accuracy: 0.9266 - val_loss: 1.4363 - val_accuracy: 0.5526\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.1508 - accuracy: 0.9605 - val_loss: 1.4716 - val_accuracy: 0.5395\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.1335 - accuracy: 0.9605 - val_loss: 1.4949 - val_accuracy: 0.5526\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1363 - accuracy: 0.9548 - val_loss: 1.4827 - val_accuracy: 0.5526\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.1242 - accuracy: 0.9661 - val_loss: 1.4503 - val_accuracy: 0.5789\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.1421 - accuracy: 0.9605 - val_loss: 1.6104 - val_accuracy: 0.5526\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1490 - accuracy: 0.9548 - val_loss: 1.5689 - val_accuracy: 0.5395\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.2835 - accuracy: 0.8870 - val_loss: 1.7814 - val_accuracy: 0.5658\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.3002 - accuracy: 0.8983 - val_loss: 1.6185 - val_accuracy: 0.5658\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.3158 - accuracy: 0.8870 - val_loss: 1.4946 - val_accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.2409 - accuracy: 0.9266 - val_loss: 1.5832 - val_accuracy: 0.5526\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1813 - accuracy: 0.9266 - val_loss: 1.5115 - val_accuracy: 0.5526\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.1323 - accuracy: 0.9661 - val_loss: 1.4957 - val_accuracy: 0.5658\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.1161 - accuracy: 0.9774 - val_loss: 1.5683 - val_accuracy: 0.5789\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1134 - accuracy: 0.9661 - val_loss: 1.5508 - val_accuracy: 0.5658\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.2160 - accuracy: 0.9096 - val_loss: 1.5790 - val_accuracy: 0.5789\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.1442 - accuracy: 0.9492 - val_loss: 1.6193 - val_accuracy: 0.5526\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.1139 - accuracy: 0.9718 - val_loss: 1.5879 - val_accuracy: 0.5526\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 349us/step - loss: 0.1374 - accuracy: 0.9661 - val_loss: 1.6103 - val_accuracy: 0.5395\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.1781 - accuracy: 0.9492 - val_loss: 1.6741 - val_accuracy: 0.5395\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 377us/step - loss: 0.1174 - accuracy: 0.9661 - val_loss: 1.5684 - val_accuracy: 0.5526\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.1012 - accuracy: 0.9661 - val_loss: 1.6098 - val_accuracy: 0.5526\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1027 - accuracy: 0.9718 - val_loss: 1.6964 - val_accuracy: 0.5263\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.0959 - accuracy: 0.9718 - val_loss: 1.6541 - val_accuracy: 0.5263\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.1015 - accuracy: 0.9831 - val_loss: 1.6806 - val_accuracy: 0.5395\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 1.6167 - val_accuracy: 0.5658\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.0971 - accuracy: 0.9661 - val_loss: 1.7668 - val_accuracy: 0.5263\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1457 - accuracy: 0.9605 - val_loss: 1.5783 - val_accuracy: 0.5526\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1239 - accuracy: 0.9548 - val_loss: 1.6547 - val_accuracy: 0.5526\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1305 - accuracy: 0.9605 - val_loss: 1.7388 - val_accuracy: 0.5263\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.0985 - accuracy: 0.9661 - val_loss: 1.6893 - val_accuracy: 0.5658\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 1.7182 - val_accuracy: 0.5658\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.0855 - accuracy: 0.9774 - val_loss: 1.7102 - val_accuracy: 0.5789\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0820 - accuracy: 0.9774 - val_loss: 1.6838 - val_accuracy: 0.5789\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 1.7255 - val_accuracy: 0.5658\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.0974 - accuracy: 0.9661 - val_loss: 1.7069 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3aca7160>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 69us/step\n",
      "test accuracy: 59.21%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel3 = model_sel3.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 2, 2, 2, 0,\n",
       "       1, 0, 1, 1, 0, 2, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 2, 0, 2,\n",
       "       1, 0, 1, 0, 0, 2, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model_sel3.predict_classes(X_sel_test)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MN055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NRS224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       strain  test  pred\n",
       "222    NRS271     1     1\n",
       "242    SR2852     2     2\n",
       "34       CA39     2     1\n",
       "221    NRS266     1     0\n",
       "230     NY356     2     1\n",
       "..        ...   ...   ...\n",
       "105     MN055     2     2\n",
       "67   CFBRSa04     0     0\n",
       "235    SR1065     0     0\n",
       "190    NRS224     1     2\n",
       "178    NRS210     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model_sel3.predict_proba(X_sel_test)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103515</td>\n",
       "      <td>0.896367</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.999287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.789370</td>\n",
       "      <td>0.188953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782633</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.210245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041063</td>\n",
       "      <td>0.812126</td>\n",
       "      <td>0.146811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.997263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.997899</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.155618</td>\n",
       "      <td>0.223443</td>\n",
       "      <td>0.620939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.333316</td>\n",
       "      <td>0.666021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.103515  0.896367  0.000118\n",
       "1   0.000002  0.000711  0.999287\n",
       "2   0.021677  0.789370  0.188953\n",
       "3   0.782633  0.007122  0.210245\n",
       "4   0.041063  0.812126  0.146811\n",
       "..       ...       ...       ...\n",
       "71  0.002503  0.000234  0.997263\n",
       "72  0.997899  0.002089  0.000012\n",
       "73  0.999928  0.000020  0.000052\n",
       "74  0.155618  0.223443  0.620939\n",
       "75  0.000663  0.333316  0.666021\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.1839 - accuracy: 0.9379 - val_loss: 1.5561 - val_accuracy: 0.5789\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.1330 - accuracy: 0.9548 - val_loss: 1.4493 - val_accuracy: 0.5658\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.0947 - accuracy: 0.9718 - val_loss: 1.5021 - val_accuracy: 0.6053\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.1296 - accuracy: 0.9548 - val_loss: 1.5023 - val_accuracy: 0.6053\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.2210 - accuracy: 0.9209 - val_loss: 1.5517 - val_accuracy: 0.5921\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1125 - accuracy: 0.9661 - val_loss: 1.6257 - val_accuracy: 0.6053\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 293us/step - loss: 0.1927 - accuracy: 0.9379 - val_loss: 1.4683 - val_accuracy: 0.6053\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.0966 - accuracy: 0.9661 - val_loss: 1.4669 - val_accuracy: 0.5921\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.0937 - accuracy: 0.9718 - val_loss: 1.4883 - val_accuracy: 0.5921\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0804 - accuracy: 0.9831 - val_loss: 1.4746 - val_accuracy: 0.5789\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.0779 - accuracy: 0.9718 - val_loss: 1.4883 - val_accuracy: 0.5789\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0744 - accuracy: 0.9831 - val_loss: 1.5220 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 1.5207 - val_accuracy: 0.5658\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.0693 - accuracy: 0.9774 - val_loss: 1.5346 - val_accuracy: 0.5789\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 1.5381 - val_accuracy: 0.6053\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0662 - accuracy: 0.9831 - val_loss: 1.5384 - val_accuracy: 0.5789\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.0639 - accuracy: 0.9774 - val_loss: 1.5574 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.2674 - accuracy: 0.9209 - val_loss: 2.0694 - val_accuracy: 0.5789\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.2468 - accuracy: 0.9548 - val_loss: 1.5466 - val_accuracy: 0.5789\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.1372 - accuracy: 0.9548 - val_loss: 1.5858 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.5743 - accuracy: 0.8644 - val_loss: 1.9339 - val_accuracy: 0.5658\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6881 - accuracy: 0.8136 - val_loss: 1.6774 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.2941 - accuracy: 0.8814 - val_loss: 1.3810 - val_accuracy: 0.5658\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.1592 - accuracy: 0.9379 - val_loss: 1.3075 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.1209 - accuracy: 0.9661 - val_loss: 1.3911 - val_accuracy: 0.5921\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.0979 - accuracy: 0.9718 - val_loss: 1.3587 - val_accuracy: 0.5921\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.0829 - accuracy: 0.9774 - val_loss: 1.3720 - val_accuracy: 0.5921\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.0996 - accuracy: 0.9718 - val_loss: 1.4050 - val_accuracy: 0.5789\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.0885 - accuracy: 0.9774 - val_loss: 1.4113 - val_accuracy: 0.5921\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 281us/step - loss: 0.1030 - accuracy: 0.9661 - val_loss: 1.4469 - val_accuracy: 0.5789\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.0856 - accuracy: 0.9718 - val_loss: 1.4535 - val_accuracy: 0.6053\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 1.4579 - val_accuracy: 0.5921\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.0684 - accuracy: 0.9831 - val_loss: 1.4631 - val_accuracy: 0.5921\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.0659 - accuracy: 0.9831 - val_loss: 1.4682 - val_accuracy: 0.5789\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.0636 - accuracy: 0.9831 - val_loss: 1.4651 - val_accuracy: 0.5789\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 1.4792 - val_accuracy: 0.5921\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.0631 - accuracy: 0.9774 - val_loss: 1.4945 - val_accuracy: 0.5921\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.0606 - accuracy: 0.9774 - val_loss: 1.4985 - val_accuracy: 0.5789\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 958us/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 1.5284 - val_accuracy: 0.5789\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 1.5325 - val_accuracy: 0.5921\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 550us/step - loss: 0.0599 - accuracy: 0.9831 - val_loss: 1.5168 - val_accuracy: 0.5789\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 641us/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 1.5204 - val_accuracy: 0.5921\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 607us/step - loss: 0.0581 - accuracy: 0.9831 - val_loss: 1.5422 - val_accuracy: 0.5789\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9831 - val_loss: 1.5503 - val_accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 483us/step - loss: 0.0584 - accuracy: 0.9774 - val_loss: 1.5559 - val_accuracy: 0.5658\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9435 - val_loss: 1.6245 - val_accuracy: 0.5658\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.2419 - accuracy: 0.9209 - val_loss: 1.5706 - val_accuracy: 0.5658\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 363us/step - loss: 0.0941 - accuracy: 0.9661 - val_loss: 1.5820 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.0951 - accuracy: 0.9605 - val_loss: 1.4606 - val_accuracy: 0.5921\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 444us/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 1.5102 - val_accuracy: 0.5921\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.0723 - accuracy: 0.9774 - val_loss: 1.5341 - val_accuracy: 0.5921\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 361us/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 1.5282 - val_accuracy: 0.5789\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.0616 - accuracy: 0.9718 - val_loss: 1.5556 - val_accuracy: 0.5921\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 1.5793 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 0.0587 - accuracy: 0.9718 - val_loss: 1.5763 - val_accuracy: 0.5789\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 286us/step - loss: 0.0554 - accuracy: 0.9774 - val_loss: 1.5920 - val_accuracy: 0.5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 1.6361 - val_accuracy: 0.5789\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0627 - accuracy: 0.9831 - val_loss: 1.6318 - val_accuracy: 0.5921\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0551 - accuracy: 0.9831 - val_loss: 1.6241 - val_accuracy: 0.5789\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.0543 - accuracy: 0.9831 - val_loss: 1.6179 - val_accuracy: 0.5789\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 1.6259 - val_accuracy: 0.5921\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 381us/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 1.6594 - val_accuracy: 0.5921\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 692us/step - loss: 0.0671 - accuracy: 0.9774 - val_loss: 1.6172 - val_accuracy: 0.5921\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.0661 - accuracy: 0.9774 - val_loss: 1.6250 - val_accuracy: 0.5921\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9887 - val_loss: 1.6550 - val_accuracy: 0.5658\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 415us/step - loss: 0.0556 - accuracy: 0.9774 - val_loss: 1.6567 - val_accuracy: 0.5658\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.0535 - accuracy: 0.9718 - val_loss: 1.6458 - val_accuracy: 0.5658\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.0545 - accuracy: 0.9718 - val_loss: 1.6279 - val_accuracy: 0.5921\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 1.6809 - val_accuracy: 0.5789\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.0495 - accuracy: 0.9831 - val_loss: 1.6905 - val_accuracy: 0.5921\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 1.6762 - val_accuracy: 0.5921\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 383us/step - loss: 0.0466 - accuracy: 0.9887 - val_loss: 1.6843 - val_accuracy: 0.5789\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.0482 - accuracy: 0.9774 - val_loss: 1.6772 - val_accuracy: 0.5789\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 1.6598 - val_accuracy: 0.5658\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 1.7101 - val_accuracy: 0.5921\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 295us/step - loss: 0.0471 - accuracy: 0.9887 - val_loss: 1.7125 - val_accuracy: 0.5789\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.0479 - accuracy: 0.9774 - val_loss: 1.7187 - val_accuracy: 0.5789\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 1.7160 - val_accuracy: 0.5921\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.0475 - accuracy: 0.9774 - val_loss: 1.7074 - val_accuracy: 0.5921\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 552us/step - loss: 0.0472 - accuracy: 0.9887 - val_loss: 1.7277 - val_accuracy: 0.5921\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 682us/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 1.7263 - val_accuracy: 0.5789\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.0442 - accuracy: 0.9831 - val_loss: 1.7324 - val_accuracy: 0.5658\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 1.7430 - val_accuracy: 0.5921\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.0428 - accuracy: 0.9831 - val_loss: 1.7272 - val_accuracy: 0.5658\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.0435 - accuracy: 0.9831 - val_loss: 1.7413 - val_accuracy: 0.5658\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.0437 - accuracy: 0.9831 - val_loss: 1.7727 - val_accuracy: 0.5921\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.0455 - accuracy: 0.9831 - val_loss: 1.7585 - val_accuracy: 0.5921\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.0451 - accuracy: 0.9887 - val_loss: 1.7467 - val_accuracy: 0.5789\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.1371 - accuracy: 0.9322 - val_loss: 1.7358 - val_accuracy: 0.5921\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 1.7533 - val_accuracy: 0.5789\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.0765 - accuracy: 0.9605 - val_loss: 1.7652 - val_accuracy: 0.5921\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.0536 - accuracy: 0.9887 - val_loss: 1.7693 - val_accuracy: 0.5921\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.1197 - accuracy: 0.9718 - val_loss: 1.8911 - val_accuracy: 0.5658\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 1.7711 - val_accuracy: 0.5921\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 1.7574 - val_accuracy: 0.5921\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 1.7689 - val_accuracy: 0.6053\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 449us/step - loss: 0.0736 - accuracy: 0.9831 - val_loss: 1.8902 - val_accuracy: 0.5921\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 327us/step - loss: 0.0749 - accuracy: 0.9831 - val_loss: 1.8107 - val_accuracy: 0.5921\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.0591 - accuracy: 0.9831 - val_loss: 1.7904 - val_accuracy: 0.5921\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.0539 - accuracy: 0.9718 - val_loss: 1.7845 - val_accuracy: 0.5921\n"
     ]
    }
   ],
   "source": [
    "hist_sel3 = model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.03%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.411991</td>\n",
       "      <td>0.578852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual       NRS271          1           0  0.854929   \n",
       "1       p0017kpresabs_qual       SR2852          2           2  0.000001   \n",
       "2       p0017kpresabs_qual         CA39          2           0  0.959992   \n",
       "3       p0017kpresabs_qual       NRS266          1           2  0.000018   \n",
       "4       p0017kpresabs_qual        NY356          2           2  0.009156   \n",
       "..                     ...          ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa110          2           2  0.044135   \n",
       "604  p0040presabsSTCC_qual     CFBRSa05          0           2  0.145032   \n",
       "605  p0040presabsSTCC_qual  CFBREBSa123          0           0  0.994623   \n",
       "606  p0040presabsSTCC_qual        NY360          1           1  0.000795   \n",
       "607  p0040presabsSTCC_qual  CFBREBSa118          2           1  0.000029   \n",
       "\n",
       "            1         2  \n",
       "0    0.144940  0.000130  \n",
       "1    0.000075  0.999923  \n",
       "2    0.013406  0.026602  \n",
       "3    0.000003  0.999980  \n",
       "4    0.411991  0.578852  \n",
       "..        ...       ...  \n",
       "603  0.010244  0.945621  \n",
       "604  0.408530  0.446439  \n",
       "605  0.004152  0.001224  \n",
       "606  0.948566  0.050639  \n",
       "607  0.999037  0.000934  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.03515126e-01, 8.96367100e-01, 1.17821620e-04],\n",
       "       [1.92032260e-06, 7.11404900e-04, 9.99286700e-01],\n",
       "       [2.16771510e-02, 7.89370360e-01, 1.88952500e-01],\n",
       "       [7.82633240e-01, 7.12198800e-03, 2.10244760e-01],\n",
       "       [4.10627300e-02, 8.12126160e-01, 1.46811050e-01],\n",
       "       [9.92544700e-01, 7.42333100e-03, 3.19968460e-05],\n",
       "       [4.82616350e-02, 4.15503300e-02, 9.10188100e-01],\n",
       "       [5.30144700e-03, 7.94538000e-02, 9.15244760e-01],\n",
       "       [1.07479210e-02, 1.62570200e-01, 8.26681850e-01],\n",
       "       [9.96360600e-01, 3.62630070e-03, 1.30336460e-05],\n",
       "       [1.22501300e-01, 7.35098750e-07, 8.77498030e-01],\n",
       "       [6.23069600e-04, 9.99066650e-01, 3.10273750e-04],\n",
       "       [2.84500910e-05, 1.10161440e-03, 9.98869960e-01],\n",
       "       [6.97613200e-01, 2.44939420e-03, 2.99937500e-01],\n",
       "       [3.51189200e-01, 1.03502360e-01, 5.45308400e-01],\n",
       "       [5.65149300e-02, 5.60856940e-01, 3.82628100e-01],\n",
       "       [9.45280700e-02, 7.40330600e-03, 8.98068670e-01],\n",
       "       [2.35872130e-01, 6.82258500e-01, 8.18693600e-02],\n",
       "       [1.74087770e-02, 9.78147200e-02, 8.84776500e-01],\n",
       "       [1.22623870e-05, 1.11900230e-02, 9.88797700e-01],\n",
       "       [9.28490000e-03, 1.55925660e-02, 9.75122600e-01],\n",
       "       [1.72641440e-01, 8.27242260e-01, 1.16249140e-04],\n",
       "       [2.18713860e-01, 6.34420160e-01, 1.46865900e-01],\n",
       "       [2.43273140e-01, 7.01076600e-01, 5.56502700e-02],\n",
       "       [5.78355100e-02, 7.48796050e-01, 1.93368400e-01],\n",
       "       [9.98892600e-01, 1.37691850e-06, 1.10594100e-03],\n",
       "       [9.95957300e-01, 3.79356630e-03, 2.49047150e-04],\n",
       "       [9.93238800e-01, 2.09228550e-03, 4.66885230e-03],\n",
       "       [7.00331100e-01, 2.79922630e-01, 1.97462940e-02],\n",
       "       [5.54222660e-03, 5.22918000e-05, 9.94405500e-01],\n",
       "       [9.92488600e-02, 8.99971660e-01, 7.79460500e-04],\n",
       "       [9.95750200e-01, 4.12158160e-03, 1.28212270e-04],\n",
       "       [7.12193550e-01, 2.77510230e-01, 1.02963000e-02],\n",
       "       [6.00412550e-01, 5.42091600e-04, 3.99045350e-01],\n",
       "       [1.13173340e-03, 7.44897500e-01, 2.53970770e-01],\n",
       "       [1.38725410e-02, 3.32021100e-02, 9.52925400e-01],\n",
       "       [2.57650260e-01, 7.20678270e-01, 2.16714800e-02],\n",
       "       [1.14379750e-03, 9.97971100e-01, 8.85071600e-04],\n",
       "       [9.96473400e-01, 3.51547260e-03, 1.11750250e-05],\n",
       "       [3.87349750e-06, 8.41106460e-04, 9.99155040e-01],\n",
       "       [3.52351500e-03, 2.18770830e-04, 9.96257800e-01],\n",
       "       [5.23252230e-08, 3.24380820e-04, 9.99675630e-01],\n",
       "       [1.16551670e-05, 1.11724960e-01, 8.88263340e-01],\n",
       "       [6.65216200e-01, 3.07118420e-01, 2.76653380e-02],\n",
       "       [3.39856950e-01, 6.31216300e-01, 2.89267600e-02],\n",
       "       [9.99404670e-01, 4.84620540e-04, 1.10628640e-04],\n",
       "       [9.43618600e-02, 8.12088600e-01, 9.35495400e-02],\n",
       "       [6.21679900e-02, 9.37757550e-01, 7.44340100e-05],\n",
       "       [8.94773660e-01, 4.95087730e-02, 5.57174420e-02],\n",
       "       [1.22501300e-01, 7.35098750e-07, 8.77498030e-01],\n",
       "       [1.83020870e-01, 7.36258030e-01, 8.07211600e-02],\n",
       "       [2.29958460e-06, 4.98982400e-04, 9.99498700e-01],\n",
       "       [6.89447600e-01, 3.81186000e-04, 3.10171250e-01],\n",
       "       [9.55172800e-01, 4.48152500e-02, 1.20103430e-05],\n",
       "       [9.93634600e-01, 6.24991670e-03, 1.15482350e-04],\n",
       "       [9.11715900e-01, 8.81568640e-02, 1.27130130e-04],\n",
       "       [9.88069600e-01, 1.12067310e-03, 1.08098430e-02],\n",
       "       [8.70311800e-02, 9.12943100e-01, 2.56566360e-05],\n",
       "       [3.14200040e-04, 5.16816700e-01, 4.82869100e-01],\n",
       "       [2.05560900e-03, 9.29014400e-01, 6.89300150e-02],\n",
       "       [4.56708340e-03, 1.18327565e-01, 8.77105400e-01],\n",
       "       [1.55339420e-03, 8.53210300e-03, 9.89914540e-01],\n",
       "       [9.90202800e-01, 9.60942200e-03, 1.87750350e-04],\n",
       "       [9.36384550e-04, 4.97146550e-01, 5.01917060e-01],\n",
       "       [9.43766200e-01, 5.59049470e-02, 3.28851780e-04],\n",
       "       [8.60633200e-05, 5.60118800e-02, 9.43902100e-01],\n",
       "       [2.05847000e-01, 7.91893600e-01, 2.25936550e-03],\n",
       "       [9.98684940e-01, 1.31284660e-03, 2.30713200e-06],\n",
       "       [2.65335140e-02, 9.73405360e-01, 6.12058900e-05],\n",
       "       [8.48503300e-01, 1.51495320e-01, 1.44637700e-06],\n",
       "       [9.98124200e-01, 1.33708350e-03, 5.38786300e-04],\n",
       "       [2.50296800e-03, 2.34423200e-04, 9.97262600e-01],\n",
       "       [9.97898700e-01, 2.08909950e-03, 1.21839130e-05],\n",
       "       [9.99928000e-01, 1.98845260e-05, 5.20610340e-05],\n",
       "       [1.55618130e-01, 2.23442850e-01, 6.20938960e-01],\n",
       "       [6.63439860e-04, 3.33315600e-01, 6.66021000e-01]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7470624613481757"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7470624613481757"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat8['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "131       NRS104     0\n",
       "123       NRS071     0\n",
       "124       NRS072     1\n",
       "27     BCH-SA-12     0\n",
       "57   CFBREBSa125     2\n",
       "..           ...   ...\n",
       "170       NRS199     2\n",
       "32          CA11     2\n",
       "212       NRS253     1\n",
       "141       NRS119     2\n",
       "126       NRS074     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 783us/step - loss: 1.1477 - accuracy: 0.4294 - val_loss: 1.0194 - val_accuracy: 0.5263\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.9896 - accuracy: 0.5424 - val_loss: 0.9884 - val_accuracy: 0.5395\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.9581 - accuracy: 0.5593 - val_loss: 1.0095 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.9183 - accuracy: 0.5876 - val_loss: 0.9838 - val_accuracy: 0.4868\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.8800 - accuracy: 0.6271 - val_loss: 0.9852 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.8550 - accuracy: 0.6215 - val_loss: 0.9867 - val_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 290us/step - loss: 0.8620 - accuracy: 0.6215 - val_loss: 1.0095 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.8562 - accuracy: 0.5989 - val_loss: 0.9878 - val_accuracy: 0.4868\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.8101 - accuracy: 0.6497 - val_loss: 0.9884 - val_accuracy: 0.4737\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.7852 - accuracy: 0.6836 - val_loss: 0.9762 - val_accuracy: 0.5132\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.7608 - accuracy: 0.6836 - val_loss: 0.9614 - val_accuracy: 0.5132\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7383 - accuracy: 0.6667 - val_loss: 0.9999 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.7150 - accuracy: 0.7006 - val_loss: 0.9550 - val_accuracy: 0.5526\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.7085 - accuracy: 0.7119 - val_loss: 0.9411 - val_accuracy: 0.5658\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6864 - accuracy: 0.6893 - val_loss: 0.9487 - val_accuracy: 0.5263\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.6737 - accuracy: 0.7345 - val_loss: 1.0220 - val_accuracy: 0.5132\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6615 - accuracy: 0.7288 - val_loss: 0.9583 - val_accuracy: 0.5395\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6424 - accuracy: 0.7910 - val_loss: 1.0033 - val_accuracy: 0.5526\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6084 - accuracy: 0.7740 - val_loss: 0.9778 - val_accuracy: 0.5263\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.6016 - accuracy: 0.7853 - val_loss: 0.9858 - val_accuracy: 0.5395\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.5875 - accuracy: 0.7966 - val_loss: 0.9723 - val_accuracy: 0.5526\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.5740 - accuracy: 0.7910 - val_loss: 0.9700 - val_accuracy: 0.5395\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.5580 - accuracy: 0.8079 - val_loss: 0.9859 - val_accuracy: 0.5789\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.5568 - accuracy: 0.8192 - val_loss: 0.9767 - val_accuracy: 0.5526\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.5544 - accuracy: 0.7853 - val_loss: 1.0004 - val_accuracy: 0.5789\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.5271 - accuracy: 0.8192 - val_loss: 1.0381 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.5954 - accuracy: 0.7740 - val_loss: 1.1028 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.5320 - accuracy: 0.8079 - val_loss: 1.0051 - val_accuracy: 0.5526\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.4915 - accuracy: 0.8192 - val_loss: 1.0061 - val_accuracy: 0.5526\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.4746 - accuracy: 0.8588 - val_loss: 1.0276 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.4964 - accuracy: 0.8418 - val_loss: 1.0099 - val_accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4897 - accuracy: 0.8136 - val_loss: 1.0116 - val_accuracy: 0.5132\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.4613 - accuracy: 0.8701 - val_loss: 1.0203 - val_accuracy: 0.5526\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.4549 - accuracy: 0.8418 - val_loss: 1.0144 - val_accuracy: 0.5921\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.4680 - accuracy: 0.8531 - val_loss: 1.0070 - val_accuracy: 0.5658\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.4236 - accuracy: 0.8644 - val_loss: 1.0337 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.4197 - accuracy: 0.8757 - val_loss: 1.0899 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.4780 - accuracy: 0.8305 - val_loss: 1.0727 - val_accuracy: 0.5263\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 655us/step - loss: 0.3939 - accuracy: 0.8927 - val_loss: 1.0724 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 452us/step - loss: 0.4247 - accuracy: 0.8814 - val_loss: 1.0423 - val_accuracy: 0.5526\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.4162 - accuracy: 0.8475 - val_loss: 1.0128 - val_accuracy: 0.5789\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.3916 - accuracy: 0.8757 - val_loss: 1.0200 - val_accuracy: 0.5395\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.3835 - accuracy: 0.9096 - val_loss: 1.0059 - val_accuracy: 0.6053\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.3671 - accuracy: 0.8983 - val_loss: 1.0205 - val_accuracy: 0.5789\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.3836 - accuracy: 0.8814 - val_loss: 1.0382 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.3771 - accuracy: 0.8814 - val_loss: 0.9923 - val_accuracy: 0.5658\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.3519 - accuracy: 0.9096 - val_loss: 1.0129 - val_accuracy: 0.5789\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.3551 - accuracy: 0.8870 - val_loss: 0.9912 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.3502 - accuracy: 0.9040 - val_loss: 0.9761 - val_accuracy: 0.5658\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.3401 - accuracy: 0.8983 - val_loss: 1.0326 - val_accuracy: 0.5263\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.3372 - accuracy: 0.9096 - val_loss: 0.9974 - val_accuracy: 0.5395\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.3206 - accuracy: 0.9209 - val_loss: 1.0159 - val_accuracy: 0.5921\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.3199 - accuracy: 0.9153 - val_loss: 1.0382 - val_accuracy: 0.5526\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.3148 - accuracy: 0.9040 - val_loss: 1.0252 - val_accuracy: 0.5526\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.3151 - accuracy: 0.8927 - val_loss: 1.0463 - val_accuracy: 0.5658\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.3094 - accuracy: 0.9040 - val_loss: 1.0186 - val_accuracy: 0.5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.2918 - accuracy: 0.9153 - val_loss: 1.0445 - val_accuracy: 0.5789\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.2913 - accuracy: 0.9040 - val_loss: 1.0532 - val_accuracy: 0.5658\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.2976 - accuracy: 0.9096 - val_loss: 1.0494 - val_accuracy: 0.5526\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.3004 - accuracy: 0.8983 - val_loss: 1.0485 - val_accuracy: 0.5658\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.2757 - accuracy: 0.9266 - val_loss: 1.0701 - val_accuracy: 0.5658\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.3231 - accuracy: 0.9096 - val_loss: 1.1498 - val_accuracy: 0.5526\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.2967 - accuracy: 0.8927 - val_loss: 1.0881 - val_accuracy: 0.5658\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.2651 - accuracy: 0.9209 - val_loss: 1.0943 - val_accuracy: 0.5789\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.2711 - accuracy: 0.9153 - val_loss: 1.0471 - val_accuracy: 0.5526\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 321us/step - loss: 0.2643 - accuracy: 0.9209 - val_loss: 1.0493 - val_accuracy: 0.5395\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.3486 - accuracy: 0.8927 - val_loss: 1.2811 - val_accuracy: 0.5132\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.3464 - accuracy: 0.8870 - val_loss: 1.0764 - val_accuracy: 0.5526\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.2623 - accuracy: 0.9266 - val_loss: 1.0810 - val_accuracy: 0.5789\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.2585 - accuracy: 0.9153 - val_loss: 1.0736 - val_accuracy: 0.5526\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.2513 - accuracy: 0.9153 - val_loss: 1.0967 - val_accuracy: 0.5526\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.2837 - accuracy: 0.8983 - val_loss: 1.1324 - val_accuracy: 0.5526\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.2439 - accuracy: 0.9153 - val_loss: 1.0699 - val_accuracy: 0.5526\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.2451 - accuracy: 0.9209 - val_loss: 1.0706 - val_accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.2400 - accuracy: 0.9266 - val_loss: 1.1004 - val_accuracy: 0.5658\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2297 - accuracy: 0.9322 - val_loss: 1.1056 - val_accuracy: 0.5395\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.2889 - accuracy: 0.9153 - val_loss: 1.2168 - val_accuracy: 0.5658\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.2586 - accuracy: 0.8983 - val_loss: 1.1181 - val_accuracy: 0.5658\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.2380 - accuracy: 0.9435 - val_loss: 1.1145 - val_accuracy: 0.5526\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.2216 - accuracy: 0.9266 - val_loss: 1.1510 - val_accuracy: 0.5789\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.2195 - accuracy: 0.9379 - val_loss: 1.1246 - val_accuracy: 0.5526\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.2136 - accuracy: 0.9379 - val_loss: 1.1314 - val_accuracy: 0.5658\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 343us/step - loss: 0.2115 - accuracy: 0.9435 - val_loss: 1.1587 - val_accuracy: 0.5658\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.2191 - accuracy: 0.9266 - val_loss: 1.1926 - val_accuracy: 0.5658\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.2191 - accuracy: 0.9379 - val_loss: 1.1560 - val_accuracy: 0.5526\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.2489 - accuracy: 0.9040 - val_loss: 1.2192 - val_accuracy: 0.5658\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.2235 - accuracy: 0.9266 - val_loss: 1.1942 - val_accuracy: 0.5658\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.2611 - accuracy: 0.8983 - val_loss: 1.1926 - val_accuracy: 0.5658\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.2506 - accuracy: 0.9153 - val_loss: 1.1417 - val_accuracy: 0.5526\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.2005 - accuracy: 0.9379 - val_loss: 1.1205 - val_accuracy: 0.5658\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.2034 - accuracy: 0.9322 - val_loss: 1.1784 - val_accuracy: 0.5658\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.1981 - accuracy: 0.9209 - val_loss: 1.2014 - val_accuracy: 0.5395\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.2012 - accuracy: 0.9548 - val_loss: 1.2121 - val_accuracy: 0.5526\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.2106 - accuracy: 0.9379 - val_loss: 1.2335 - val_accuracy: 0.5526\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.1959 - accuracy: 0.9492 - val_loss: 1.2779 - val_accuracy: 0.5789\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.1857 - accuracy: 0.9379 - val_loss: 1.2280 - val_accuracy: 0.5395\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.1796 - accuracy: 0.9661 - val_loss: 1.1991 - val_accuracy: 0.5395\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.1730 - accuracy: 0.9548 - val_loss: 1.2127 - val_accuracy: 0.5526\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.1691 - accuracy: 0.9548 - val_loss: 1.2222 - val_accuracy: 0.5395\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.1672 - accuracy: 0.9661 - val_loss: 1.2204 - val_accuracy: 0.5395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39af0f98>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 128us/step\n",
      "over-sampling test accuracy: 59.21%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel4 = model_sel4.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 2, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 2, 1, 1, 0, 1, 2, 2,\n",
       "       2, 1, 0, 2, 2, 0, 2, 1, 2, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 0, 2,\n",
       "       0, 2, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 2, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model_sel4.predict_classes(X_sel_test)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CA11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NRS074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "131       NRS104     0     1\n",
       "123       NRS071     0     2\n",
       "124       NRS072     1     0\n",
       "27     BCH-SA-12     0     1\n",
       "57   CFBREBSa125     2     2\n",
       "..           ...   ...   ...\n",
       "170       NRS199     2     0\n",
       "32          CA11     2     0\n",
       "212       NRS253     1     1\n",
       "141       NRS119     2     2\n",
       "126       NRS074     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model_sel4.predict_proba(X_sel_test)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158166</td>\n",
       "      <td>0.745738</td>\n",
       "      <td>0.096096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.463862</td>\n",
       "      <td>0.497409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.532130</td>\n",
       "      <td>0.070925</td>\n",
       "      <td>0.396945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198760</td>\n",
       "      <td>0.657271</td>\n",
       "      <td>0.143969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.248682</td>\n",
       "      <td>0.734616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.456327</td>\n",
       "      <td>0.103251</td>\n",
       "      <td>0.440421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.898749</td>\n",
       "      <td>0.093794</td>\n",
       "      <td>0.007457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.044462</td>\n",
       "      <td>0.917985</td>\n",
       "      <td>0.037553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.055589</td>\n",
       "      <td>0.944397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.638687</td>\n",
       "      <td>0.318243</td>\n",
       "      <td>0.043071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.158166  0.745738  0.096096\n",
       "1   0.038728  0.463862  0.497409\n",
       "2   0.532130  0.070925  0.396945\n",
       "3   0.198760  0.657271  0.143969\n",
       "4   0.016703  0.248682  0.734616\n",
       "..       ...       ...       ...\n",
       "71  0.456327  0.103251  0.440421\n",
       "72  0.898749  0.093794  0.007457\n",
       "73  0.044462  0.917985  0.037553\n",
       "74  0.000014  0.055589  0.944397\n",
       "75  0.638687  0.318243  0.043071\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p17p.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1575 - accuracy: 0.9548 - val_loss: 1.2473 - val_accuracy: 0.5789\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.1468 - accuracy: 0.9718 - val_loss: 1.2577 - val_accuracy: 0.5658\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.1457 - accuracy: 0.9718 - val_loss: 1.2536 - val_accuracy: 0.5789\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.1483 - accuracy: 0.9718 - val_loss: 1.2536 - val_accuracy: 0.5658\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1472 - accuracy: 0.9605 - val_loss: 1.2810 - val_accuracy: 0.5789\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1456 - accuracy: 0.9605 - val_loss: 1.3070 - val_accuracy: 0.5658\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.1374 - accuracy: 0.9718 - val_loss: 1.3205 - val_accuracy: 0.5789\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1754 - accuracy: 0.9492 - val_loss: 1.3427 - val_accuracy: 0.5526\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.1754 - accuracy: 0.9435 - val_loss: 1.4236 - val_accuracy: 0.5658\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.1657 - accuracy: 0.9322 - val_loss: 1.3977 - val_accuracy: 0.5789\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1351 - accuracy: 0.9661 - val_loss: 1.3689 - val_accuracy: 0.5789\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1425 - accuracy: 0.9605 - val_loss: 1.3749 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.1292 - accuracy: 0.9718 - val_loss: 1.3883 - val_accuracy: 0.5789\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1277 - accuracy: 0.9887 - val_loss: 1.3893 - val_accuracy: 0.5789\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1242 - accuracy: 0.9718 - val_loss: 1.3817 - val_accuracy: 0.5789\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.1246 - accuracy: 0.9774 - val_loss: 1.3968 - val_accuracy: 0.5789\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.1240 - accuracy: 0.9718 - val_loss: 1.3918 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.1240 - accuracy: 0.9661 - val_loss: 1.3900 - val_accuracy: 0.5789\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.1220 - accuracy: 0.9774 - val_loss: 1.4044 - val_accuracy: 0.5789\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1177 - accuracy: 0.9831 - val_loss: 1.4095 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.1229 - accuracy: 0.9605 - val_loss: 1.3903 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.1302 - accuracy: 0.9605 - val_loss: 1.3986 - val_accuracy: 0.5789\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.1304 - accuracy: 0.9605 - val_loss: 1.4055 - val_accuracy: 0.5789\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.1199 - accuracy: 0.9548 - val_loss: 1.4319 - val_accuracy: 0.5658\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.1159 - accuracy: 0.9661 - val_loss: 1.4516 - val_accuracy: 0.5658\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1284 - accuracy: 0.9718 - val_loss: 1.3989 - val_accuracy: 0.5526\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.1490 - accuracy: 0.9492 - val_loss: 1.4142 - val_accuracy: 0.6184\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.1798 - accuracy: 0.9435 - val_loss: 1.4236 - val_accuracy: 0.6053\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.1362 - accuracy: 0.9774 - val_loss: 1.4494 - val_accuracy: 0.5658\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.1112 - accuracy: 0.9887 - val_loss: 1.4991 - val_accuracy: 0.5789\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.1109 - accuracy: 0.9774 - val_loss: 1.4626 - val_accuracy: 0.5658\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.1052 - accuracy: 0.9774 - val_loss: 1.4744 - val_accuracy: 0.5789\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.1068 - accuracy: 0.9718 - val_loss: 1.4805 - val_accuracy: 0.5658\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.1099 - accuracy: 0.9887 - val_loss: 1.4745 - val_accuracy: 0.5526\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1111 - accuracy: 0.9774 - val_loss: 1.5024 - val_accuracy: 0.5789\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.1141 - accuracy: 0.9718 - val_loss: 1.4964 - val_accuracy: 0.5658\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.1021 - accuracy: 0.9718 - val_loss: 1.5160 - val_accuracy: 0.5658\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.0982 - accuracy: 0.9774 - val_loss: 1.5022 - val_accuracy: 0.5658\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1013 - accuracy: 0.9718 - val_loss: 1.5084 - val_accuracy: 0.5658\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.1010 - accuracy: 0.9831 - val_loss: 1.5062 - val_accuracy: 0.5658\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.0976 - accuracy: 0.9831 - val_loss: 1.5164 - val_accuracy: 0.5658\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.1272 - accuracy: 0.9718 - val_loss: 1.5588 - val_accuracy: 0.5789\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.1081 - accuracy: 0.9718 - val_loss: 1.6063 - val_accuracy: 0.5789\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.1340 - accuracy: 0.9661 - val_loss: 1.5260 - val_accuracy: 0.5263\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.1317 - accuracy: 0.9548 - val_loss: 1.5423 - val_accuracy: 0.5921\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.1018 - accuracy: 0.9718 - val_loss: 1.5819 - val_accuracy: 0.5658\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.0958 - accuracy: 0.9831 - val_loss: 1.5692 - val_accuracy: 0.5658\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.0930 - accuracy: 0.9831 - val_loss: 1.5637 - val_accuracy: 0.5658\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0914 - accuracy: 0.9887 - val_loss: 1.5750 - val_accuracy: 0.5658\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.1318 - accuracy: 0.9435 - val_loss: 1.6263 - val_accuracy: 0.5395\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.1009 - accuracy: 0.9831 - val_loss: 1.5587 - val_accuracy: 0.5789\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0910 - accuracy: 0.9831 - val_loss: 1.5549 - val_accuracy: 0.5658\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0887 - accuracy: 0.9774 - val_loss: 1.5852 - val_accuracy: 0.5658\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.0848 - accuracy: 0.9831 - val_loss: 1.5932 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.0875 - accuracy: 0.9887 - val_loss: 1.5625 - val_accuracy: 0.5658\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0863 - accuracy: 0.9887 - val_loss: 1.5819 - val_accuracy: 0.5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0833 - accuracy: 0.9831 - val_loss: 1.5934 - val_accuracy: 0.5789\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.0839 - accuracy: 0.9887 - val_loss: 1.6311 - val_accuracy: 0.5658\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.1145 - accuracy: 0.9492 - val_loss: 1.6507 - val_accuracy: 0.5658\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.0964 - accuracy: 0.9661 - val_loss: 1.6470 - val_accuracy: 0.5658\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0902 - accuracy: 0.9718 - val_loss: 1.6329 - val_accuracy: 0.5658\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.1687 - accuracy: 0.9435 - val_loss: 1.7520 - val_accuracy: 0.5658\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.1263 - accuracy: 0.9492 - val_loss: 1.6782 - val_accuracy: 0.5658\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 1.6346 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.1159 - accuracy: 0.9605 - val_loss: 1.6057 - val_accuracy: 0.5526\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.0804 - accuracy: 0.9831 - val_loss: 1.6331 - val_accuracy: 0.5658\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.0764 - accuracy: 0.9831 - val_loss: 1.6450 - val_accuracy: 0.5658\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.0771 - accuracy: 0.9887 - val_loss: 1.6650 - val_accuracy: 0.5658\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.0857 - accuracy: 0.9831 - val_loss: 1.7406 - val_accuracy: 0.5658\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.0827 - accuracy: 0.9887 - val_loss: 1.6934 - val_accuracy: 0.5526\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.0753 - accuracy: 0.9831 - val_loss: 1.5949 - val_accuracy: 0.5526\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.0949 - accuracy: 0.9774 - val_loss: 1.5887 - val_accuracy: 0.5658\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.0840 - accuracy: 0.9831 - val_loss: 1.5774 - val_accuracy: 0.5526\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.0789 - accuracy: 0.9718 - val_loss: 1.5627 - val_accuracy: 0.5395\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.0794 - accuracy: 0.9605 - val_loss: 1.6156 - val_accuracy: 0.5789\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.0717 - accuracy: 0.9887 - val_loss: 1.6445 - val_accuracy: 0.5658\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.0718 - accuracy: 0.9887 - val_loss: 1.6611 - val_accuracy: 0.5526\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.0746 - accuracy: 0.9944 - val_loss: 1.6807 - val_accuracy: 0.5789\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.0719 - accuracy: 0.9887 - val_loss: 1.6691 - val_accuracy: 0.5658\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.0703 - accuracy: 0.9887 - val_loss: 1.6821 - val_accuracy: 0.5526\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0697 - accuracy: 0.9831 - val_loss: 1.6742 - val_accuracy: 0.5658\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0684 - accuracy: 0.9831 - val_loss: 1.6964 - val_accuracy: 0.5658\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.0672 - accuracy: 0.9831 - val_loss: 1.7145 - val_accuracy: 0.5789\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.0672 - accuracy: 0.9887 - val_loss: 1.7158 - val_accuracy: 0.5789\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.0659 - accuracy: 0.9831 - val_loss: 1.7205 - val_accuracy: 0.5658\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0735 - accuracy: 0.9831 - val_loss: 1.8193 - val_accuracy: 0.5658\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.1069 - accuracy: 0.9661 - val_loss: 1.9365 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.0973 - accuracy: 0.9718 - val_loss: 1.7621 - val_accuracy: 0.5526\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.0791 - accuracy: 0.9661 - val_loss: 1.7218 - val_accuracy: 0.5789\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0704 - accuracy: 0.9774 - val_loss: 1.7285 - val_accuracy: 0.5658\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.0649 - accuracy: 0.9831 - val_loss: 1.7516 - val_accuracy: 0.5789\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.0706 - accuracy: 0.9887 - val_loss: 1.7537 - val_accuracy: 0.5789\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.0673 - accuracy: 0.9887 - val_loss: 1.7563 - val_accuracy: 0.5526\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.0619 - accuracy: 0.9887 - val_loss: 1.7720 - val_accuracy: 0.5789\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0678 - accuracy: 0.9887 - val_loss: 1.8077 - val_accuracy: 0.5789\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0672 - accuracy: 0.9887 - val_loss: 1.7965 - val_accuracy: 0.5658\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.0649 - accuracy: 0.9887 - val_loss: 1.7776 - val_accuracy: 0.5658\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.0661 - accuracy: 0.9887 - val_loss: 1.7648 - val_accuracy: 0.5789\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.0610 - accuracy: 0.9831 - val_loss: 1.7573 - val_accuracy: 0.5658\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.0663 - accuracy: 0.9887 - val_loss: 1.7856 - val_accuracy: 0.5658\n"
     ]
    }
   ],
   "source": [
    "hist_sel4 = model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.43%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.210638e-02</td>\n",
       "      <td>0.917809</td>\n",
       "      <td>8.477923e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015229e-02</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>7.345203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.642946e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.963547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.809318e-03</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>8.980029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875667e-01</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>4.237761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual       NRS104          0           1  8.210638e-02   \n",
       "1       p0017kpresabs_qual       NRS071          0           2  1.015229e-02   \n",
       "2       p0017kpresabs_qual       NRS072          1           2  3.642946e-03   \n",
       "3       p0017kpresabs_qual    BCH-SA-12          0           2  2.809318e-03   \n",
       "4       p0017kpresabs_qual  CFBREBSa125          2           0  4.875667e-01   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual       NRS113          1           2  2.686909e-07   \n",
       "604  p0040presabsSTCC_qual    BCH-SA-09          2           1  5.529492e-07   \n",
       "605  p0040presabsSTCC_qual       NRS106          2           1  1.115902e-03   \n",
       "606  p0040presabsSTCC_qual  CFBREBSa131          2           2  2.708040e-07   \n",
       "607  p0040presabsSTCC_qual      GA51254          0           0  9.993569e-01   \n",
       "\n",
       "            1             2  \n",
       "0    0.917809  8.477923e-05  \n",
       "1    0.255327  7.345203e-01  \n",
       "2    0.000002  9.963547e-01  \n",
       "3    0.099188  8.980029e-01  \n",
       "4    0.088657  4.237761e-01  \n",
       "..        ...           ...  \n",
       "603  0.093121  9.068785e-01  \n",
       "604  0.999990  9.559324e-06  \n",
       "605  0.998816  6.852559e-05  \n",
       "606  0.156768  8.432316e-01  \n",
       "607  0.000643  1.816008e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.58166140e-01, 7.45737970e-01, 9.60958900e-02],\n",
       "       [3.87284900e-02, 4.63862100e-01, 4.97409500e-01],\n",
       "       [5.32129760e-01, 7.09250000e-02, 3.96945240e-01],\n",
       "       [1.98760090e-01, 6.57270800e-01, 1.43969130e-01],\n",
       "       [1.67028960e-02, 2.48681580e-01, 7.34615500e-01],\n",
       "       [2.38739430e-01, 7.27275130e-01, 3.39854250e-02],\n",
       "       [3.66635770e-02, 4.03542760e-01, 5.59793600e-01],\n",
       "       [3.05971830e-03, 2.49188860e-02, 9.72021400e-01],\n",
       "       [3.77392720e-03, 5.35890100e-01, 4.60335970e-01],\n",
       "       [9.57234740e-01, 3.91080400e-02, 3.65726980e-03],\n",
       "       [1.87064260e-01, 5.71198640e-01, 2.41737040e-01],\n",
       "       [3.39960870e-02, 1.55446290e-01, 8.10557660e-01],\n",
       "       [1.22354170e-03, 1.91438700e-01, 8.07337760e-01],\n",
       "       [9.64208900e-01, 2.55108760e-02, 1.02802210e-02],\n",
       "       [7.69508500e-01, 1.56375450e-01, 7.41160140e-02],\n",
       "       [8.57975200e-03, 1.51484090e-01, 8.39936200e-01],\n",
       "       [8.06468200e-04, 9.16705200e-01, 8.24883000e-02],\n",
       "       [1.99934160e-03, 7.71918000e-01, 2.26082680e-01],\n",
       "       [8.75204270e-01, 1.07137404e-01, 1.76584140e-02],\n",
       "       [6.25360000e-03, 9.91714060e-01, 2.03236000e-03],\n",
       "       [2.82250800e-03, 2.72599400e-01, 7.24578100e-01],\n",
       "       [2.02726300e-01, 3.01673830e-01, 4.95599840e-01],\n",
       "       [4.43398540e-01, 6.26030000e-03, 5.50341100e-01],\n",
       "       [4.67495670e-03, 9.61248040e-01, 3.40770370e-02],\n",
       "       [9.91607670e-01, 6.71450050e-03, 1.67784900e-03],\n",
       "       [7.37783600e-04, 2.71081250e-02, 9.72154140e-01],\n",
       "       [1.02749690e-05, 2.66599380e-03, 9.97323750e-01],\n",
       "       [5.42729440e-01, 4.31550300e-01, 2.57202420e-02],\n",
       "       [5.73547080e-05, 1.05135694e-01, 8.94807000e-01],\n",
       "       [2.30065510e-02, 8.18306270e-01, 1.58687190e-01],\n",
       "       [5.77858100e-04, 2.58223790e-02, 9.73599800e-01],\n",
       "       [8.10156940e-01, 1.84852060e-01, 4.99092230e-03],\n",
       "       [9.55070560e-01, 2.78653650e-02, 1.70640760e-02],\n",
       "       [2.00858080e-02, 9.31082800e-01, 4.88314220e-02],\n",
       "       [4.60456360e-05, 2.12396090e-02, 9.78714400e-01],\n",
       "       [2.02158570e-01, 7.92751970e-01, 5.08950740e-03],\n",
       "       [1.21264750e-03, 9.82999900e-01, 1.57874840e-02],\n",
       "       [7.91608100e-03, 2.12580650e-02, 9.70825850e-01],\n",
       "       [6.78207100e-01, 2.85357100e-01, 3.64358000e-02],\n",
       "       [4.64243600e-04, 5.38019200e-03, 9.94155500e-01],\n",
       "       [5.78679100e-01, 3.29904700e-01, 9.14161650e-02],\n",
       "       [1.30974950e-01, 3.65522200e-01, 5.03502900e-01],\n",
       "       [9.69750900e-01, 1.23042970e-02, 1.79447850e-02],\n",
       "       [2.57360760e-01, 2.30767770e-01, 5.11871500e-01],\n",
       "       [4.39112200e-01, 2.67691220e-01, 2.93196620e-01],\n",
       "       [3.51663500e-04, 8.34566600e-03, 9.91302600e-01],\n",
       "       [6.00253830e-02, 5.19887500e-01, 4.20087160e-01],\n",
       "       [9.77407100e-01, 1.47641490e-02, 7.82887450e-03],\n",
       "       [1.09826940e-01, 4.81007600e-01, 4.09165500e-01],\n",
       "       [5.80776670e-06, 7.80470800e-02, 9.21947100e-01],\n",
       "       [5.04288170e-03, 3.19821180e-01, 6.75135970e-01],\n",
       "       [9.91331460e-01, 8.13535400e-03, 5.33244860e-04],\n",
       "       [2.49251050e-03, 2.81006590e-03, 9.94697450e-01],\n",
       "       [8.12519800e-01, 1.46941100e-04, 1.87333270e-01],\n",
       "       [8.24394640e-01, 2.43140300e-02, 1.51291250e-01],\n",
       "       [1.78097150e-02, 3.81215700e-02, 9.44068800e-01],\n",
       "       [6.77125700e-01, 2.67298900e-01, 5.55754340e-02],\n",
       "       [6.87198640e-01, 1.12547290e-02, 3.01546540e-01],\n",
       "       [8.47739600e-07, 2.21709630e-02, 9.77828200e-01],\n",
       "       [5.65007800e-01, 2.73949530e-01, 1.61042680e-01],\n",
       "       [4.23388100e-01, 4.13567400e-01, 1.63044450e-01],\n",
       "       [9.86891100e-01, 3.18565320e-04, 1.27902530e-02],\n",
       "       [4.82079100e-03, 8.89655230e-01, 1.05523960e-01],\n",
       "       [3.90490700e-01, 9.98558300e-02, 5.09653500e-01],\n",
       "       [1.59667360e-01, 2.56139840e-01, 5.84192800e-01],\n",
       "       [9.96940400e-04, 9.97278500e-01, 1.72459750e-03],\n",
       "       [1.78745540e-02, 8.49739900e-01, 1.32385480e-01],\n",
       "       [7.43717900e-01, 1.02786680e-01, 1.53495430e-01],\n",
       "       [8.44108050e-01, 1.67084400e-02, 1.39183540e-01],\n",
       "       [7.77069100e-01, 2.03568850e-01, 1.93620290e-02],\n",
       "       [3.73698850e-02, 9.60399200e-01, 2.23094000e-03],\n",
       "       [4.56327300e-01, 1.03251350e-01, 4.40421370e-01],\n",
       "       [8.98748760e-01, 9.37943700e-02, 7.45692340e-03],\n",
       "       [4.44617400e-02, 9.17985100e-01, 3.75532880e-02],\n",
       "       [1.42120440e-05, 5.55891840e-02, 9.44396700e-01],\n",
       "       [6.38686800e-01, 3.18242580e-01, 4.30706440e-02]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0017presabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692743764172336"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692743764172336"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719320472296664"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016209217735817724"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719320472296664"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016209217735817724"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l= [acc_test_sel, acc_test_sel2, acc_test_sel3, acc_test_sel4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean after lasso: 60.86%\n"
     ]
    }
   ],
   "source": [
    "mean_l = np.mean(accs_l)\n",
    "print('test accuracy mean after lasso: %.2f%%' % (mean_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation after lasso: 0.017092598805124246\n"
     ]
    }
   ],
   "source": [
    "std_l = np.std(accs_l)\n",
    "print('test accuracy standard deviation after lasso:', std_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l = [np.mean(hist_sel.history['accuracy']), np.mean(hist_sel2.history['accuracy']), np.mean(hist_sel3.history['accuracy']),\n",
    "             np.mean(hist_sel4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean after lasso: 96.97%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l = np.mean(accs_train_l)\n",
    "print('train accuracy mean after lasso: %.2f%%' % (mean_train_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation after lasso: 0.0034746933\n"
     ]
    }
   ],
   "source": [
    "std_train_l = np.std(accs_train_l)\n",
    "print('train accuracy standard deviation after lasso:', std_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
