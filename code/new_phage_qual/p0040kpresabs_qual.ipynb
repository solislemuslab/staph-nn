{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks before and after lasso selection for p0040kpresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 182)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p0040kpresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "248    2\n",
       "249    1\n",
       "250    1\n",
       "251    2\n",
       "252    2\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT</th>\n",
       "      <th>TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG</th>\n",
       "      <th>TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG</th>\n",
       "      <th>TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC</th>\n",
       "      <th>TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT</th>\n",
       "      <th>TTTGGACAGGCAGTGAAAC</th>\n",
       "      <th>TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC</th>\n",
       "      <th>TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT</th>\n",
       "      <th>...</th>\n",
       "      <th>AGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTT</th>\n",
       "      <th>AGCAGATAAACTT</th>\n",
       "      <th>AGCAGATAAACTTT</th>\n",
       "      <th>ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT</th>\n",
       "      <th>ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT</th>\n",
       "      <th>ACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTT</th>\n",
       "      <th>ACAAGTCGCTGAAATATT</th>\n",
       "      <th>AACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTT</th>\n",
       "      <th>AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGGACAGGCAGTGAAAC  \\\n",
       "0                    0   \n",
       "1                    1   \n",
       "2                    1   \n",
       "3                    1   \n",
       "4                    1   \n",
       "\n",
       "   TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGCAGATAAACTT  AGCAGATAAACTTT  \\\n",
       "0              0               0   \n",
       "1              1               1   \n",
       "2              1               1   \n",
       "3              1               1   \n",
       "4              1               1   \n",
       "\n",
       "   ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACAAGTCGCTGAAATATT  \\\n",
       "0                   0   \n",
       "1                   1   \n",
       "2                   1   \n",
       "3                   1   \n",
       "4                   1   \n",
       "\n",
       "   AACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      2  \n",
       "1      0  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    95\n",
       "1    94\n",
       "0    64\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 181)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT</th>\n",
       "      <th>TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG</th>\n",
       "      <th>TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG</th>\n",
       "      <th>TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC</th>\n",
       "      <th>TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT</th>\n",
       "      <th>TTTGGACAGGCAGTGAAAC</th>\n",
       "      <th>TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC</th>\n",
       "      <th>TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT</th>\n",
       "      <th>TTTCAGCGACTT</th>\n",
       "      <th>...</th>\n",
       "      <th>AGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTT</th>\n",
       "      <th>AGCAGATAAACTT</th>\n",
       "      <th>AGCAGATAAACTTT</th>\n",
       "      <th>ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT</th>\n",
       "      <th>ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT</th>\n",
       "      <th>ACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTT</th>\n",
       "      <th>ACAAGTCGCTGAAATATT</th>\n",
       "      <th>AACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTT</th>\n",
       "      <th>AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTACAAAAGAGGAAGCAGATAAACTTTATCAACCTATCGGTTCTTCGCAGCCGTCACTGAATATTTGGACAGGCAGTGAAACAGAATATAATTATTTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTG  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTGGACAGGCAGTGAAAC  \\\n",
       "0                    0   \n",
       "1                    1   \n",
       "2                    1   \n",
       "3                    1   \n",
       "4                    1   \n",
       "\n",
       "   TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCGCTGTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTCAGCGACTT  ...  \\\n",
       "0             0  ...   \n",
       "1             1  ...   \n",
       "2             1  ...   \n",
       "3             1  ...   \n",
       "4             1  ...   \n",
       "\n",
       "   AGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AGCAGATAAACTT  AGCAGATAAACTTT  \\\n",
       "0              0               0   \n",
       "1              1               1   \n",
       "2              1               1   \n",
       "3              1               1   \n",
       "4              1               1   \n",
       "\n",
       "   ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   ACAAGTCGCTGAAATATT  \\\n",
       "0                   0   \n",
       "1                   1   \n",
       "2                   1   \n",
       "3                   1   \n",
       "4                   1   \n",
       "\n",
       "   AACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   pheno  \n",
       "0      2  \n",
       "1      0  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 181) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "221       NRS266     2\n",
       "177       NRS209     1\n",
       "223       NRS272     2\n",
       "49   CFBREBSa114     2\n",
       "53   CFBREBSa119     1\n",
       "..           ...   ...\n",
       "162       NRS187     1\n",
       "237       SR1287     0\n",
       "84      CFBRSa50     0\n",
       "168       NRS196     2\n",
       "124       NRS072     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 631us/step - loss: 1.1848 - accuracy: 0.3672 - val_loss: 1.0511 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 1.1064 - accuracy: 0.3559 - val_loss: 1.0558 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 1.0767 - accuracy: 0.3955 - val_loss: 1.0244 - val_accuracy: 0.4605\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 1.0554 - accuracy: 0.4407 - val_loss: 1.0151 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 1.0423 - accuracy: 0.4633 - val_loss: 1.0166 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 1.0294 - accuracy: 0.4633 - val_loss: 1.0007 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 1.0219 - accuracy: 0.4350 - val_loss: 0.9926 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 1.0169 - accuracy: 0.4350 - val_loss: 0.9916 - val_accuracy: 0.4605\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 1.0093 - accuracy: 0.4407 - val_loss: 0.9812 - val_accuracy: 0.4868\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 1.0050 - accuracy: 0.4689 - val_loss: 0.9776 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 1.0025 - accuracy: 0.4689 - val_loss: 0.9754 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.9927 - accuracy: 0.4463 - val_loss: 0.9775 - val_accuracy: 0.5263\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.9866 - accuracy: 0.4689 - val_loss: 0.9782 - val_accuracy: 0.5132\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.9843 - accuracy: 0.4915 - val_loss: 0.9692 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.9776 - accuracy: 0.4915 - val_loss: 0.9669 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.9726 - accuracy: 0.4972 - val_loss: 0.9651 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 242us/step - loss: 0.9722 - accuracy: 0.4972 - val_loss: 0.9657 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.9664 - accuracy: 0.5141 - val_loss: 0.9647 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.9623 - accuracy: 0.5028 - val_loss: 0.9720 - val_accuracy: 0.5395\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 575us/step - loss: 0.9579 - accuracy: 0.4915 - val_loss: 0.9673 - val_accuracy: 0.5132\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.9573 - accuracy: 0.5085 - val_loss: 0.9567 - val_accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.9488 - accuracy: 0.5141 - val_loss: 0.9556 - val_accuracy: 0.5395\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.9429 - accuracy: 0.5254 - val_loss: 0.9537 - val_accuracy: 0.5395\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.9394 - accuracy: 0.5254 - val_loss: 0.9462 - val_accuracy: 0.5658\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.9355 - accuracy: 0.5311 - val_loss: 0.9524 - val_accuracy: 0.5921\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.9324 - accuracy: 0.5198 - val_loss: 0.9504 - val_accuracy: 0.5789\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.9246 - accuracy: 0.5480 - val_loss: 0.9465 - val_accuracy: 0.5921\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.9253 - accuracy: 0.5424 - val_loss: 0.9435 - val_accuracy: 0.5921\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.9211 - accuracy: 0.5311 - val_loss: 0.9588 - val_accuracy: 0.5789\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.9151 - accuracy: 0.5424 - val_loss: 0.9474 - val_accuracy: 0.5921\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.9098 - accuracy: 0.5367 - val_loss: 0.9432 - val_accuracy: 0.5921\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.9069 - accuracy: 0.5424 - val_loss: 0.9352 - val_accuracy: 0.5658\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.9040 - accuracy: 0.5763 - val_loss: 0.9362 - val_accuracy: 0.5921\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.9028 - accuracy: 0.5819 - val_loss: 0.9401 - val_accuracy: 0.6053\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.8984 - accuracy: 0.5424 - val_loss: 0.9436 - val_accuracy: 0.5658\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.9008 - accuracy: 0.5650 - val_loss: 0.9386 - val_accuracy: 0.5789\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.8902 - accuracy: 0.5763 - val_loss: 0.9376 - val_accuracy: 0.5921\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.8894 - accuracy: 0.5876 - val_loss: 0.9370 - val_accuracy: 0.5921\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8883 - accuracy: 0.5593 - val_loss: 0.9478 - val_accuracy: 0.6053\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.8887 - accuracy: 0.5819 - val_loss: 0.9363 - val_accuracy: 0.5658\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.8872 - accuracy: 0.5819 - val_loss: 0.9303 - val_accuracy: 0.5526\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.8787 - accuracy: 0.5876 - val_loss: 0.9269 - val_accuracy: 0.5526\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.8794 - accuracy: 0.5763 - val_loss: 0.9405 - val_accuracy: 0.5658\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.8713 - accuracy: 0.5932 - val_loss: 0.9291 - val_accuracy: 0.5658\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.8655 - accuracy: 0.5876 - val_loss: 0.9257 - val_accuracy: 0.5658\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.8667 - accuracy: 0.5876 - val_loss: 0.9234 - val_accuracy: 0.5658\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.8643 - accuracy: 0.5819 - val_loss: 0.9234 - val_accuracy: 0.5526\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.8656 - accuracy: 0.6215 - val_loss: 0.9358 - val_accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.8592 - accuracy: 0.6158 - val_loss: 0.9198 - val_accuracy: 0.5789\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.8542 - accuracy: 0.6215 - val_loss: 0.9203 - val_accuracy: 0.5789\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.8547 - accuracy: 0.6158 - val_loss: 0.9199 - val_accuracy: 0.5789\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8492 - accuracy: 0.6102 - val_loss: 0.9187 - val_accuracy: 0.5526\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.8483 - accuracy: 0.6271 - val_loss: 0.9171 - val_accuracy: 0.5658\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.8473 - accuracy: 0.6271 - val_loss: 0.9134 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.8397 - accuracy: 0.6215 - val_loss: 0.9228 - val_accuracy: 0.5789\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.8444 - accuracy: 0.6158 - val_loss: 0.9243 - val_accuracy: 0.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.8382 - accuracy: 0.6215 - val_loss: 0.9384 - val_accuracy: 0.5395\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.8357 - accuracy: 0.6271 - val_loss: 0.9222 - val_accuracy: 0.5789\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.8349 - accuracy: 0.6158 - val_loss: 0.9090 - val_accuracy: 0.5526\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8342 - accuracy: 0.6271 - val_loss: 0.9055 - val_accuracy: 0.5395\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.8334 - accuracy: 0.6441 - val_loss: 0.9188 - val_accuracy: 0.5395\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.8270 - accuracy: 0.6441 - val_loss: 0.9221 - val_accuracy: 0.5395\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8249 - accuracy: 0.6384 - val_loss: 0.9142 - val_accuracy: 0.5658\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.8240 - accuracy: 0.6215 - val_loss: 0.9191 - val_accuracy: 0.5789\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.8195 - accuracy: 0.6215 - val_loss: 0.9171 - val_accuracy: 0.5526\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.8215 - accuracy: 0.6328 - val_loss: 0.9197 - val_accuracy: 0.5526\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.8151 - accuracy: 0.6441 - val_loss: 0.9164 - val_accuracy: 0.5395\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.8190 - accuracy: 0.6328 - val_loss: 0.9255 - val_accuracy: 0.5658\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.8144 - accuracy: 0.6384 - val_loss: 0.9164 - val_accuracy: 0.5526\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.8109 - accuracy: 0.6667 - val_loss: 0.9133 - val_accuracy: 0.5658\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8095 - accuracy: 0.6610 - val_loss: 0.9094 - val_accuracy: 0.5658\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.8072 - accuracy: 0.6497 - val_loss: 0.9215 - val_accuracy: 0.5658\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.8044 - accuracy: 0.6554 - val_loss: 0.9257 - val_accuracy: 0.5395\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.8042 - accuracy: 0.6554 - val_loss: 0.9178 - val_accuracy: 0.5658\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.8002 - accuracy: 0.6667 - val_loss: 0.9173 - val_accuracy: 0.5526\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7962 - accuracy: 0.6723 - val_loss: 0.9153 - val_accuracy: 0.5789\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.8038 - accuracy: 0.6554 - val_loss: 0.9157 - val_accuracy: 0.5658\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.8005 - accuracy: 0.6441 - val_loss: 0.9209 - val_accuracy: 0.5132\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.7956 - accuracy: 0.6723 - val_loss: 0.9238 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.7921 - accuracy: 0.6610 - val_loss: 0.9156 - val_accuracy: 0.5526\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.7891 - accuracy: 0.6497 - val_loss: 0.9245 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.7881 - accuracy: 0.6610 - val_loss: 0.9075 - val_accuracy: 0.5395\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.7840 - accuracy: 0.6441 - val_loss: 0.9077 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7853 - accuracy: 0.6667 - val_loss: 0.9089 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7847 - accuracy: 0.6497 - val_loss: 0.9233 - val_accuracy: 0.5395\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7796 - accuracy: 0.6554 - val_loss: 0.9171 - val_accuracy: 0.5263\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.7814 - accuracy: 0.6554 - val_loss: 0.9078 - val_accuracy: 0.5526\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.7789 - accuracy: 0.6667 - val_loss: 0.9152 - val_accuracy: 0.5526\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.7805 - accuracy: 0.6780 - val_loss: 0.9176 - val_accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.7826 - accuracy: 0.6610 - val_loss: 0.9123 - val_accuracy: 0.5395\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.7774 - accuracy: 0.6554 - val_loss: 0.9183 - val_accuracy: 0.5263\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.7689 - accuracy: 0.6723 - val_loss: 0.9126 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.7677 - accuracy: 0.6723 - val_loss: 0.9108 - val_accuracy: 0.5263\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.7666 - accuracy: 0.6667 - val_loss: 0.9112 - val_accuracy: 0.5263\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.7633 - accuracy: 0.6667 - val_loss: 0.9203 - val_accuracy: 0.5263\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.7634 - accuracy: 0.6780 - val_loss: 0.9169 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.7576 - accuracy: 0.6780 - val_loss: 0.9145 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.7570 - accuracy: 0.6723 - val_loss: 0.9217 - val_accuracy: 0.5132\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.7626 - accuracy: 0.6893 - val_loss: 0.9320 - val_accuracy: 0.5395\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.7535 - accuracy: 0.6723 - val_loss: 0.9061 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a30952198>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 201us/step\n",
      "test accuracy: 51.32%\n"
     ]
    }
   ],
   "source": [
    "acc_test1 = model1.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 1, 2, 0, 2, 2, 0, 0, 2,\n",
       "       2, 0, 2, 0, 2, 2, 2, 2, 1, 0, 2, 0, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1,\n",
       "       2, 0, 1, 2, 0, 2, 0, 1, 2, 2, 1, 0, 2, 2, 0, 2, 2, 2, 0, 1, 2, 0,\n",
       "       2, 0, 1, 0, 0, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NRS272</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CFBREBSa114</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "221       NRS266     2     2\n",
       "177       NRS209     1     1\n",
       "223       NRS272     2     2\n",
       "49   CFBREBSa114     2     2\n",
       "53   CFBREBSa119     1     0\n",
       "..           ...   ...   ...\n",
       "162       NRS187     1     2\n",
       "237       SR1287     0     0\n",
       "84      CFBRSa50     0     2\n",
       "168       NRS196     2     2\n",
       "124       NRS072     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1.predict_proba(X_test)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040479</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.679021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.176141</td>\n",
       "      <td>0.757298</td>\n",
       "      <td>0.066560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155533</td>\n",
       "      <td>0.366461</td>\n",
       "      <td>0.478006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123646</td>\n",
       "      <td>0.293973</td>\n",
       "      <td>0.582381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.489394</td>\n",
       "      <td>0.219591</td>\n",
       "      <td>0.291015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.240571</td>\n",
       "      <td>0.226299</td>\n",
       "      <td>0.533130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.514265</td>\n",
       "      <td>0.181804</td>\n",
       "      <td>0.303931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.376491</td>\n",
       "      <td>0.224424</td>\n",
       "      <td>0.399085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.015289</td>\n",
       "      <td>0.341986</td>\n",
       "      <td>0.642725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.746145</td>\n",
       "      <td>0.130871</td>\n",
       "      <td>0.122984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.040479  0.280500  0.679021\n",
       "1   0.176141  0.757298  0.066560\n",
       "2   0.155533  0.366461  0.478006\n",
       "3   0.123646  0.293973  0.582381\n",
       "4   0.489394  0.219591  0.291015\n",
       "..       ...       ...       ...\n",
       "71  0.240571  0.226299  0.533130\n",
       "72  0.514265  0.181804  0.303931\n",
       "73  0.376491  0.224424  0.399085\n",
       "74  0.015289  0.341986  0.642725\n",
       "75  0.746145  0.130871  0.122984\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7289 - accuracy: 0.6893 - val_loss: 0.9653 - val_accuracy: 0.5132\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.7316 - accuracy: 0.6949 - val_loss: 0.9683 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.7284 - accuracy: 0.7006 - val_loss: 0.9663 - val_accuracy: 0.4868\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7264 - accuracy: 0.7062 - val_loss: 0.9641 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.7228 - accuracy: 0.6949 - val_loss: 0.9605 - val_accuracy: 0.5132\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.7230 - accuracy: 0.6893 - val_loss: 0.9592 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7226 - accuracy: 0.6836 - val_loss: 0.9623 - val_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7195 - accuracy: 0.7119 - val_loss: 0.9707 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7175 - accuracy: 0.7119 - val_loss: 0.9737 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7169 - accuracy: 0.6949 - val_loss: 0.9777 - val_accuracy: 0.4737\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.7149 - accuracy: 0.7175 - val_loss: 0.9748 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.7119 - accuracy: 0.7119 - val_loss: 0.9713 - val_accuracy: 0.5132\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.7095 - accuracy: 0.6893 - val_loss: 0.9668 - val_accuracy: 0.5395\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.7101 - accuracy: 0.6893 - val_loss: 0.9690 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.7075 - accuracy: 0.6949 - val_loss: 0.9760 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.7064 - accuracy: 0.6893 - val_loss: 0.9738 - val_accuracy: 0.5263\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.7053 - accuracy: 0.6893 - val_loss: 0.9739 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.6984 - accuracy: 0.6893 - val_loss: 0.9815 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 284us/step - loss: 0.7005 - accuracy: 0.7175 - val_loss: 0.9877 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.7015 - accuracy: 0.7288 - val_loss: 0.9855 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.7005 - accuracy: 0.7062 - val_loss: 0.9758 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.6969 - accuracy: 0.6949 - val_loss: 0.9778 - val_accuracy: 0.4868\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.6932 - accuracy: 0.7175 - val_loss: 0.9776 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.6915 - accuracy: 0.7062 - val_loss: 0.9806 - val_accuracy: 0.5132\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6906 - accuracy: 0.7232 - val_loss: 0.9934 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.6880 - accuracy: 0.7345 - val_loss: 0.9979 - val_accuracy: 0.5132\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.6868 - accuracy: 0.7232 - val_loss: 1.0054 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.6865 - accuracy: 0.7175 - val_loss: 1.0106 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.6877 - accuracy: 0.7006 - val_loss: 0.9971 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.6827 - accuracy: 0.7232 - val_loss: 0.9851 - val_accuracy: 0.5395\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.6818 - accuracy: 0.7288 - val_loss: 0.9849 - val_accuracy: 0.5132\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.6828 - accuracy: 0.7175 - val_loss: 0.9899 - val_accuracy: 0.5132\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.6758 - accuracy: 0.7232 - val_loss: 0.9973 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.6770 - accuracy: 0.7062 - val_loss: 1.0027 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 332us/step - loss: 0.6736 - accuracy: 0.7288 - val_loss: 1.0038 - val_accuracy: 0.4868\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 456us/step - loss: 0.6707 - accuracy: 0.7345 - val_loss: 0.9985 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.6703 - accuracy: 0.7232 - val_loss: 1.0012 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.6684 - accuracy: 0.7345 - val_loss: 1.0049 - val_accuracy: 0.5132\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 316us/step - loss: 0.6687 - accuracy: 0.7345 - val_loss: 1.0122 - val_accuracy: 0.5132\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6627 - accuracy: 0.7345 - val_loss: 1.0059 - val_accuracy: 0.5132\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6667 - accuracy: 0.7345 - val_loss: 0.9996 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.6648 - accuracy: 0.7345 - val_loss: 0.9991 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.6649 - accuracy: 0.7232 - val_loss: 1.0024 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6597 - accuracy: 0.7345 - val_loss: 1.0133 - val_accuracy: 0.4868\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6589 - accuracy: 0.7288 - val_loss: 1.0183 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 314us/step - loss: 0.6601 - accuracy: 0.7288 - val_loss: 1.0172 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 364us/step - loss: 0.6575 - accuracy: 0.7232 - val_loss: 1.0022 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.6559 - accuracy: 0.7514 - val_loss: 1.0088 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 422us/step - loss: 0.6529 - accuracy: 0.7514 - val_loss: 1.0106 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.6545 - accuracy: 0.7232 - val_loss: 1.0216 - val_accuracy: 0.5132\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.6555 - accuracy: 0.7345 - val_loss: 1.0248 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 388us/step - loss: 0.6490 - accuracy: 0.7458 - val_loss: 1.0246 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 370us/step - loss: 0.6508 - accuracy: 0.7345 - val_loss: 1.0228 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.6457 - accuracy: 0.7514 - val_loss: 1.0244 - val_accuracy: 0.5132\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.6451 - accuracy: 0.7062 - val_loss: 1.0267 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.6467 - accuracy: 0.7401 - val_loss: 1.0287 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.6437 - accuracy: 0.7514 - val_loss: 1.0273 - val_accuracy: 0.5132\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.6380 - accuracy: 0.7571 - val_loss: 1.0317 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.6381 - accuracy: 0.7345 - val_loss: 1.0283 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6349 - accuracy: 0.7401 - val_loss: 1.0312 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.6348 - accuracy: 0.7401 - val_loss: 1.0321 - val_accuracy: 0.4868\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.6309 - accuracy: 0.7458 - val_loss: 1.0329 - val_accuracy: 0.5395\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.6348 - accuracy: 0.7458 - val_loss: 1.0270 - val_accuracy: 0.5132\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.6317 - accuracy: 0.7458 - val_loss: 1.0301 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.6305 - accuracy: 0.7458 - val_loss: 1.0304 - val_accuracy: 0.5132\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.6266 - accuracy: 0.7458 - val_loss: 1.0380 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.6333 - accuracy: 0.7458 - val_loss: 1.0530 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6291 - accuracy: 0.7062 - val_loss: 1.0405 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.6255 - accuracy: 0.7458 - val_loss: 1.0326 - val_accuracy: 0.5263\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.6287 - accuracy: 0.7458 - val_loss: 1.0389 - val_accuracy: 0.5132\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.6244 - accuracy: 0.7401 - val_loss: 1.0370 - val_accuracy: 0.4868\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6213 - accuracy: 0.7401 - val_loss: 1.0433 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.6198 - accuracy: 0.7401 - val_loss: 1.0495 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.6221 - accuracy: 0.7232 - val_loss: 1.0505 - val_accuracy: 0.5132\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.6192 - accuracy: 0.7571 - val_loss: 1.0452 - val_accuracy: 0.5132\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6168 - accuracy: 0.7514 - val_loss: 1.0490 - val_accuracy: 0.5395\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6191 - accuracy: 0.7514 - val_loss: 1.0489 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 276us/step - loss: 0.6119 - accuracy: 0.7458 - val_loss: 1.0516 - val_accuracy: 0.5132\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 325us/step - loss: 0.6152 - accuracy: 0.7571 - val_loss: 1.0530 - val_accuracy: 0.5395\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.6151 - accuracy: 0.7571 - val_loss: 1.0535 - val_accuracy: 0.5263\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6095 - accuracy: 0.7458 - val_loss: 1.0646 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.6093 - accuracy: 0.7627 - val_loss: 1.0630 - val_accuracy: 0.5132\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 293us/step - loss: 0.6108 - accuracy: 0.7571 - val_loss: 1.0586 - val_accuracy: 0.5132\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.6062 - accuracy: 0.7401 - val_loss: 1.0555 - val_accuracy: 0.5132\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6050 - accuracy: 0.7458 - val_loss: 1.0559 - val_accuracy: 0.5132\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.6043 - accuracy: 0.7571 - val_loss: 1.0585 - val_accuracy: 0.4868\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.6078 - accuracy: 0.7627 - val_loss: 1.0552 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.6007 - accuracy: 0.7514 - val_loss: 1.0559 - val_accuracy: 0.5395\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.6056 - accuracy: 0.7684 - val_loss: 1.0574 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.5999 - accuracy: 0.7684 - val_loss: 1.0522 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 458us/step - loss: 0.6066 - accuracy: 0.7514 - val_loss: 1.0786 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.6070 - accuracy: 0.7401 - val_loss: 1.0710 - val_accuracy: 0.5132\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 552us/step - loss: 0.6011 - accuracy: 0.7627 - val_loss: 1.0699 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 785us/step - loss: 0.5948 - accuracy: 0.7684 - val_loss: 1.0691 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.5928 - accuracy: 0.7627 - val_loss: 1.0644 - val_accuracy: 0.5132\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.5939 - accuracy: 0.7627 - val_loss: 1.0734 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.5941 - accuracy: 0.7514 - val_loss: 1.0782 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.5891 - accuracy: 0.7684 - val_loss: 1.0808 - val_accuracy: 0.4868\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.5940 - accuracy: 0.7627 - val_loss: 1.0822 - val_accuracy: 0.4868\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.5917 - accuracy: 0.7740 - val_loss: 1.0756 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist1 = model1.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 73.18%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist1.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759813</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.238883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947819</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.042591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.184744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216843</td>\n",
       "      <td>0.568123</td>\n",
       "      <td>0.215034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418802</td>\n",
       "      <td>0.553160</td>\n",
       "      <td>0.028038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>0.016869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.959940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795570</td>\n",
       "      <td>0.187358</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS027          1           0  0.759813   \n",
       "1       p0017kpresabs_qual    NRS246          1           0  0.947819   \n",
       "2       p0017kpresabs_qual    NRS218          2           1  0.008693   \n",
       "3       p0017kpresabs_qual  CFBRSa70          2           0  0.813774   \n",
       "4       p0017kpresabs_qual    NRS177          1           1  0.000916   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS187          1           1  0.216843   \n",
       "604  p0040presabsSTCC_qual    SR1287          0           1  0.418802   \n",
       "605  p0040presabsSTCC_qual  CFBRSa50          0           0  0.948100   \n",
       "606  p0040presabsSTCC_qual    NRS196          2           2  0.000964   \n",
       "607  p0040presabsSTCC_qual    NRS072          0           0  0.795570   \n",
       "\n",
       "            1         2  \n",
       "0    0.001304  0.238883  \n",
       "1    0.009591  0.042591  \n",
       "2    0.989390  0.001916  \n",
       "3    0.001482  0.184744  \n",
       "4    0.998926  0.000157  \n",
       "..        ...       ...  \n",
       "603  0.568123  0.215034  \n",
       "604  0.553160  0.028038  \n",
       "605  0.035031  0.016869  \n",
       "606  0.039095  0.959940  \n",
       "607  0.187358  0.017072  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04047949, 0.28049988, 0.67902064],\n",
       "       [0.17614147, 0.7572981 , 0.06656041],\n",
       "       [0.15553288, 0.366461  , 0.47800606],\n",
       "       [0.12364565, 0.29397324, 0.5823812 ],\n",
       "       [0.48939386, 0.2195914 , 0.29101476],\n",
       "       [0.4320851 , 0.3419223 , 0.22599259],\n",
       "       [0.335571  , 0.3187999 , 0.34562907],\n",
       "       [0.64074725, 0.15836829, 0.20088443],\n",
       "       [0.04583629, 0.33266762, 0.621496  ],\n",
       "       [0.44947666, 0.3355829 , 0.21494046],\n",
       "       [0.49329385, 0.18378085, 0.32292533],\n",
       "       [0.02040344, 0.36229795, 0.6172986 ],\n",
       "       [0.65604544, 0.23389927, 0.11005541],\n",
       "       [0.4982258 , 0.18142939, 0.32034487],\n",
       "       [0.18078317, 0.535986  , 0.2832308 ],\n",
       "       [0.23156622, 0.26814198, 0.50029176],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.15511893, 0.3227845 , 0.5220966 ],\n",
       "       [0.04047949, 0.28049988, 0.67902064],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.49329385, 0.18378085, 0.32292533],\n",
       "       [0.22725324, 0.3236626 , 0.44908413],\n",
       "       [0.04304667, 0.19001345, 0.7669399 ],\n",
       "       [0.373046  , 0.32229728, 0.30465665],\n",
       "       [0.17876418, 0.38743657, 0.4337992 ],\n",
       "       [0.43837473, 0.4211876 , 0.14043774],\n",
       "       [0.07832533, 0.28610006, 0.63557464],\n",
       "       [0.1234953 , 0.34599027, 0.53051436],\n",
       "       [0.12364565, 0.29397324, 0.5823812 ],\n",
       "       [0.099221  , 0.42993957, 0.47083938],\n",
       "       [0.29165703, 0.5736077 , 0.1347353 ],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.06316821, 0.11485171, 0.82198006],\n",
       "       [0.4982258 , 0.18142939, 0.32034487],\n",
       "       [0.20425227, 0.5813666 , 0.21438111],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.4248988 , 0.22071308, 0.35438818],\n",
       "       [0.01528896, 0.341986  , 0.64272505],\n",
       "       [0.45128134, 0.15601128, 0.39270732],\n",
       "       [0.11333585, 0.2919205 , 0.5947436 ],\n",
       "       [0.06092569, 0.2722452 , 0.66682917],\n",
       "       [0.17505775, 0.63095677, 0.19398554],\n",
       "       [0.00669292, 0.5092198 , 0.48408732],\n",
       "       [0.32809922, 0.5707335 , 0.10116726],\n",
       "       [0.03376637, 0.321433  , 0.6448006 ],\n",
       "       [0.45055482, 0.20392434, 0.3455208 ],\n",
       "       [0.18078317, 0.535986  , 0.2832308 ],\n",
       "       [0.05035709, 0.31893003, 0.63071287],\n",
       "       [0.8539228 , 0.08314186, 0.06293532],\n",
       "       [0.12364565, 0.29397324, 0.5823812 ],\n",
       "       [0.49329385, 0.18378085, 0.32292533],\n",
       "       [0.2866634 , 0.50370157, 0.20963496],\n",
       "       [0.06316821, 0.11485171, 0.82198006],\n",
       "       [0.06316821, 0.11485171, 0.82198006],\n",
       "       [0.12962638, 0.47927606, 0.39109752],\n",
       "       [0.4982258 , 0.18142939, 0.32034487],\n",
       "       [0.01528896, 0.341986  , 0.64272505],\n",
       "       [0.1610598 , 0.29446372, 0.54447645],\n",
       "       [0.49329385, 0.18378085, 0.32292533],\n",
       "       [0.06316821, 0.11485171, 0.82198006],\n",
       "       [0.23375735, 0.3717173 , 0.39452535],\n",
       "       [0.0063962 , 0.2813937 , 0.7122101 ],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.06348147, 0.5085906 , 0.42792794],\n",
       "       [0.32160416, 0.20315178, 0.47524402],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.11243272, 0.30829036, 0.5792769 ],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.12645096, 0.47413206, 0.39941695],\n",
       "       [0.42545268, 0.18145795, 0.39308935],\n",
       "       [0.3936193 , 0.3453653 , 0.26101547],\n",
       "       [0.2405713 , 0.22629873, 0.53313   ],\n",
       "       [0.5142646 , 0.18180439, 0.30393103],\n",
       "       [0.3764905 , 0.22442408, 0.39908534],\n",
       "       [0.01528896, 0.341986  , 0.64272505],\n",
       "       [0.7461451 , 0.13087112, 0.12298381]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743354525919531"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743354525919531"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat2['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NRS100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  test\n",
       "165    NRS191     2\n",
       "237    SR1287     0\n",
       "243    SR3569     2\n",
       "128    NRS100     0\n",
       "107    NRS001     1\n",
       "..        ...   ...\n",
       "220    NRS265     1\n",
       "233     NY439     2\n",
       "68   CFBRSa05     0\n",
       "175    NRS205     2\n",
       "31      CA105     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 740us/step - loss: 1.1445 - accuracy: 0.3164 - val_loss: 1.0819 - val_accuracy: 0.3684\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 1.0806 - accuracy: 0.3842 - val_loss: 1.0327 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 1.0665 - accuracy: 0.4181 - val_loss: 1.0172 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 1.0540 - accuracy: 0.4294 - val_loss: 1.0129 - val_accuracy: 0.5132\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 1.0420 - accuracy: 0.4407 - val_loss: 1.0087 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 1.0335 - accuracy: 0.4294 - val_loss: 1.0047 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 1.0283 - accuracy: 0.4350 - val_loss: 0.9986 - val_accuracy: 0.5132\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 1.0231 - accuracy: 0.4463 - val_loss: 1.0031 - val_accuracy: 0.5395\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 1.0172 - accuracy: 0.4689 - val_loss: 0.9960 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 1.0100 - accuracy: 0.4802 - val_loss: 0.9814 - val_accuracy: 0.5658\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 1.0048 - accuracy: 0.4689 - val_loss: 0.9754 - val_accuracy: 0.5789\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.9989 - accuracy: 0.4689 - val_loss: 0.9674 - val_accuracy: 0.5658\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.9976 - accuracy: 0.4576 - val_loss: 0.9615 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.9938 - accuracy: 0.4746 - val_loss: 0.9635 - val_accuracy: 0.5789\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.9849 - accuracy: 0.4915 - val_loss: 0.9735 - val_accuracy: 0.5789\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.9830 - accuracy: 0.5141 - val_loss: 0.9799 - val_accuracy: 0.5658\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.9785 - accuracy: 0.5141 - val_loss: 0.9662 - val_accuracy: 0.5526\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.9731 - accuracy: 0.5198 - val_loss: 0.9614 - val_accuracy: 0.5526\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.9711 - accuracy: 0.5141 - val_loss: 0.9585 - val_accuracy: 0.5526\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.9657 - accuracy: 0.5198 - val_loss: 0.9626 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.9600 - accuracy: 0.5198 - val_loss: 0.9621 - val_accuracy: 0.5658\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.9578 - accuracy: 0.5198 - val_loss: 0.9573 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.9537 - accuracy: 0.5254 - val_loss: 0.9543 - val_accuracy: 0.5921\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.9494 - accuracy: 0.5198 - val_loss: 0.9644 - val_accuracy: 0.5921\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.9440 - accuracy: 0.5367 - val_loss: 0.9591 - val_accuracy: 0.6184\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.9437 - accuracy: 0.5254 - val_loss: 0.9454 - val_accuracy: 0.5921\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.9371 - accuracy: 0.5480 - val_loss: 0.9490 - val_accuracy: 0.5921\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.9304 - accuracy: 0.5480 - val_loss: 0.9608 - val_accuracy: 0.5789\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.9283 - accuracy: 0.5593 - val_loss: 0.9609 - val_accuracy: 0.5658\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.9247 - accuracy: 0.5706 - val_loss: 0.9497 - val_accuracy: 0.5789\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.9236 - accuracy: 0.5537 - val_loss: 0.9535 - val_accuracy: 0.5789\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.9172 - accuracy: 0.5593 - val_loss: 0.9422 - val_accuracy: 0.5658\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9122 - accuracy: 0.5650 - val_loss: 0.9411 - val_accuracy: 0.5658\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.9072 - accuracy: 0.5819 - val_loss: 0.9459 - val_accuracy: 0.6184\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.9034 - accuracy: 0.5819 - val_loss: 0.9454 - val_accuracy: 0.5921\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.9018 - accuracy: 0.5876 - val_loss: 0.9343 - val_accuracy: 0.5789\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.8976 - accuracy: 0.5876 - val_loss: 0.9450 - val_accuracy: 0.6184\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.8926 - accuracy: 0.5819 - val_loss: 0.9460 - val_accuracy: 0.6316\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.8889 - accuracy: 0.5876 - val_loss: 0.9374 - val_accuracy: 0.6184\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.8832 - accuracy: 0.5989 - val_loss: 0.9409 - val_accuracy: 0.6447\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.8824 - accuracy: 0.6045 - val_loss: 0.9353 - val_accuracy: 0.5921\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.8770 - accuracy: 0.6102 - val_loss: 0.9407 - val_accuracy: 0.5921\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.8761 - accuracy: 0.6045 - val_loss: 0.9489 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.8703 - accuracy: 0.6045 - val_loss: 0.9458 - val_accuracy: 0.6053\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.8680 - accuracy: 0.6045 - val_loss: 0.9351 - val_accuracy: 0.5789\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.8659 - accuracy: 0.6158 - val_loss: 0.9415 - val_accuracy: 0.5921\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.8687 - accuracy: 0.6102 - val_loss: 0.9553 - val_accuracy: 0.5789\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.8565 - accuracy: 0.6215 - val_loss: 0.9408 - val_accuracy: 0.6053\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.8564 - accuracy: 0.5989 - val_loss: 0.9293 - val_accuracy: 0.5921\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.8523 - accuracy: 0.6045 - val_loss: 0.9447 - val_accuracy: 0.5789\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.8515 - accuracy: 0.6158 - val_loss: 0.9560 - val_accuracy: 0.5658\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.8471 - accuracy: 0.6158 - val_loss: 0.9430 - val_accuracy: 0.5921\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.8421 - accuracy: 0.6158 - val_loss: 0.9483 - val_accuracy: 0.5789\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.8380 - accuracy: 0.6215 - val_loss: 0.9438 - val_accuracy: 0.5658\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8350 - accuracy: 0.6328 - val_loss: 0.9432 - val_accuracy: 0.5658\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.8331 - accuracy: 0.6328 - val_loss: 0.9413 - val_accuracy: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.8351 - accuracy: 0.6271 - val_loss: 0.9473 - val_accuracy: 0.5395\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.8283 - accuracy: 0.6271 - val_loss: 0.9511 - val_accuracy: 0.5263\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.8218 - accuracy: 0.6328 - val_loss: 0.9523 - val_accuracy: 0.5658\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.8258 - accuracy: 0.6271 - val_loss: 0.9372 - val_accuracy: 0.5921\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.8226 - accuracy: 0.6497 - val_loss: 0.9626 - val_accuracy: 0.5526\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.8172 - accuracy: 0.6384 - val_loss: 0.9566 - val_accuracy: 0.5395\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.8111 - accuracy: 0.6384 - val_loss: 0.9440 - val_accuracy: 0.5526\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8072 - accuracy: 0.6497 - val_loss: 0.9419 - val_accuracy: 0.5395\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8081 - accuracy: 0.6328 - val_loss: 0.9519 - val_accuracy: 0.5658\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.8039 - accuracy: 0.6610 - val_loss: 0.9610 - val_accuracy: 0.5395\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8028 - accuracy: 0.6554 - val_loss: 0.9610 - val_accuracy: 0.5526\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.8015 - accuracy: 0.6497 - val_loss: 0.9422 - val_accuracy: 0.5263\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.7989 - accuracy: 0.6441 - val_loss: 0.9519 - val_accuracy: 0.5395\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.7923 - accuracy: 0.6610 - val_loss: 0.9470 - val_accuracy: 0.5395\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.7907 - accuracy: 0.6554 - val_loss: 0.9573 - val_accuracy: 0.5395\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7854 - accuracy: 0.6554 - val_loss: 0.9656 - val_accuracy: 0.5132\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7862 - accuracy: 0.6441 - val_loss: 0.9647 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.7817 - accuracy: 0.6780 - val_loss: 0.9535 - val_accuracy: 0.5395\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.7797 - accuracy: 0.6667 - val_loss: 0.9550 - val_accuracy: 0.5263\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.7740 - accuracy: 0.6610 - val_loss: 0.9572 - val_accuracy: 0.5132\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7723 - accuracy: 0.6497 - val_loss: 0.9619 - val_accuracy: 0.5132\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.7704 - accuracy: 0.6554 - val_loss: 0.9648 - val_accuracy: 0.5132\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.7691 - accuracy: 0.6667 - val_loss: 0.9625 - val_accuracy: 0.5132\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.7668 - accuracy: 0.6836 - val_loss: 0.9521 - val_accuracy: 0.5132\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.7639 - accuracy: 0.6836 - val_loss: 0.9544 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.7637 - accuracy: 0.6780 - val_loss: 0.9632 - val_accuracy: 0.5132\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.7585 - accuracy: 0.6780 - val_loss: 0.9669 - val_accuracy: 0.5132\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.7601 - accuracy: 0.6667 - val_loss: 0.9640 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.7545 - accuracy: 0.6949 - val_loss: 0.9680 - val_accuracy: 0.4868\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.7574 - accuracy: 0.6949 - val_loss: 0.9809 - val_accuracy: 0.4868\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.7535 - accuracy: 0.6949 - val_loss: 0.9633 - val_accuracy: 0.4737\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7458 - accuracy: 0.7006 - val_loss: 0.9715 - val_accuracy: 0.5132\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.7470 - accuracy: 0.6836 - val_loss: 0.9696 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.7429 - accuracy: 0.6836 - val_loss: 0.9755 - val_accuracy: 0.5132\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.7444 - accuracy: 0.6836 - val_loss: 0.9734 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.7400 - accuracy: 0.7062 - val_loss: 0.9730 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.7374 - accuracy: 0.6836 - val_loss: 0.9710 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.7376 - accuracy: 0.6893 - val_loss: 0.9740 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.7356 - accuracy: 0.7062 - val_loss: 0.9900 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.7324 - accuracy: 0.6949 - val_loss: 0.9913 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.7261 - accuracy: 0.7006 - val_loss: 0.9698 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.7275 - accuracy: 0.7119 - val_loss: 0.9622 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.7298 - accuracy: 0.6836 - val_loss: 0.9707 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.7211 - accuracy: 0.7006 - val_loss: 0.9744 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a31030160>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 135us/step\n",
      "test accuracy: 48.68%\n"
     ]
    }
   ],
   "source": [
    "acc_test2 = model2.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 0, 1, 1, 2, 2, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1,\n",
       "       1, 1, 0, 1, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 0,\n",
       "       2, 0, 2, 1, 1, 2, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict_classes(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SR3569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NRS100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  test  pred\n",
       "165    NRS191     2     2\n",
       "237    SR1287     0     0\n",
       "243    SR3569     2     2\n",
       "128    NRS100     0     1\n",
       "107    NRS001     1     0\n",
       "..        ...   ...   ...\n",
       "220    NRS265     1     2\n",
       "233     NY439     2     0\n",
       "68   CFBRSa05     0     1\n",
       "175    NRS205     2     2\n",
       "31      CA105     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model2.predict_proba(X_test)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027459</td>\n",
       "      <td>0.243888</td>\n",
       "      <td>0.728654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.410315</td>\n",
       "      <td>0.386324</td>\n",
       "      <td>0.203362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.173924</td>\n",
       "      <td>0.278553</td>\n",
       "      <td>0.547522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400569</td>\n",
       "      <td>0.464484</td>\n",
       "      <td>0.134947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567512</td>\n",
       "      <td>0.405903</td>\n",
       "      <td>0.026585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.361655</td>\n",
       "      <td>0.586545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.387840</td>\n",
       "      <td>0.320942</td>\n",
       "      <td>0.291218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.356108</td>\n",
       "      <td>0.396302</td>\n",
       "      <td>0.247590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.025135</td>\n",
       "      <td>0.374063</td>\n",
       "      <td>0.600802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.129418</td>\n",
       "      <td>0.206246</td>\n",
       "      <td>0.664336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.027459  0.243888  0.728654\n",
       "1   0.410315  0.386324  0.203362\n",
       "2   0.173924  0.278553  0.547522\n",
       "3   0.400569  0.464484  0.134947\n",
       "4   0.567512  0.405903  0.026585\n",
       "..       ...       ...       ...\n",
       "71  0.051800  0.361655  0.586545\n",
       "72  0.387840  0.320942  0.291218\n",
       "73  0.356108  0.396302  0.247590\n",
       "74  0.025135  0.374063  0.600802\n",
       "75  0.129418  0.206246  0.664336\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7200 - accuracy: 0.7006 - val_loss: 1.0241 - val_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.7177 - accuracy: 0.7062 - val_loss: 1.0113 - val_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.7139 - accuracy: 0.7232 - val_loss: 1.0095 - val_accuracy: 0.4868\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.7149 - accuracy: 0.7175 - val_loss: 1.0138 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.7292 - accuracy: 0.7119 - val_loss: 1.0303 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7155 - accuracy: 0.7119 - val_loss: 1.0111 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.7117 - accuracy: 0.7232 - val_loss: 1.0158 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.7033 - accuracy: 0.7288 - val_loss: 1.0307 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7035 - accuracy: 0.7175 - val_loss: 1.0354 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7059 - accuracy: 0.7345 - val_loss: 1.0160 - val_accuracy: 0.4605\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.7063 - accuracy: 0.7062 - val_loss: 1.0241 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6945 - accuracy: 0.7232 - val_loss: 1.0348 - val_accuracy: 0.4605\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6997 - accuracy: 0.7345 - val_loss: 1.0212 - val_accuracy: 0.4868\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6966 - accuracy: 0.7119 - val_loss: 1.0260 - val_accuracy: 0.4868\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.6932 - accuracy: 0.7232 - val_loss: 1.0189 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.7054 - accuracy: 0.7119 - val_loss: 1.0377 - val_accuracy: 0.4474\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.6956 - accuracy: 0.7175 - val_loss: 1.0312 - val_accuracy: 0.4605\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.6875 - accuracy: 0.7062 - val_loss: 1.0165 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.6870 - accuracy: 0.7175 - val_loss: 1.0348 - val_accuracy: 0.4737\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6869 - accuracy: 0.7232 - val_loss: 1.0464 - val_accuracy: 0.4474\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6793 - accuracy: 0.7401 - val_loss: 1.0497 - val_accuracy: 0.4605\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.6796 - accuracy: 0.7401 - val_loss: 1.0443 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6791 - accuracy: 0.7288 - val_loss: 1.0277 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.6775 - accuracy: 0.7345 - val_loss: 1.0534 - val_accuracy: 0.4342\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.6757 - accuracy: 0.7345 - val_loss: 1.0456 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6705 - accuracy: 0.7288 - val_loss: 1.0360 - val_accuracy: 0.4605\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.6737 - accuracy: 0.7232 - val_loss: 1.0465 - val_accuracy: 0.4474\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6743 - accuracy: 0.7119 - val_loss: 1.0557 - val_accuracy: 0.4342\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6690 - accuracy: 0.7345 - val_loss: 1.0509 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6740 - accuracy: 0.7345 - val_loss: 1.0435 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.6611 - accuracy: 0.7458 - val_loss: 1.0431 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6667 - accuracy: 0.7288 - val_loss: 1.0547 - val_accuracy: 0.4474\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.6628 - accuracy: 0.7458 - val_loss: 1.0689 - val_accuracy: 0.4474\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.6640 - accuracy: 0.7514 - val_loss: 1.0546 - val_accuracy: 0.4474\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6642 - accuracy: 0.7401 - val_loss: 1.0554 - val_accuracy: 0.4342\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6629 - accuracy: 0.7571 - val_loss: 1.0593 - val_accuracy: 0.4605\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.6579 - accuracy: 0.7345 - val_loss: 1.0493 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.6632 - accuracy: 0.7514 - val_loss: 1.0707 - val_accuracy: 0.4605\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.6600 - accuracy: 0.7288 - val_loss: 1.0614 - val_accuracy: 0.4605\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6538 - accuracy: 0.7401 - val_loss: 1.0572 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.6515 - accuracy: 0.7627 - val_loss: 1.0546 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.6526 - accuracy: 0.7571 - val_loss: 1.0630 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.6449 - accuracy: 0.7458 - val_loss: 1.0719 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.6511 - accuracy: 0.7458 - val_loss: 1.0845 - val_accuracy: 0.4474\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6484 - accuracy: 0.7345 - val_loss: 1.0810 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.6459 - accuracy: 0.7458 - val_loss: 1.0788 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6464 - accuracy: 0.7514 - val_loss: 1.0733 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6410 - accuracy: 0.7627 - val_loss: 1.0834 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6457 - accuracy: 0.7627 - val_loss: 1.0787 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.6408 - accuracy: 0.7514 - val_loss: 1.1033 - val_accuracy: 0.4342\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.6370 - accuracy: 0.7684 - val_loss: 1.0703 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.6469 - accuracy: 0.7345 - val_loss: 1.0731 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.6359 - accuracy: 0.7458 - val_loss: 1.1050 - val_accuracy: 0.4079\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6509 - accuracy: 0.7288 - val_loss: 1.0793 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6320 - accuracy: 0.7740 - val_loss: 1.0758 - val_accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.6430 - accuracy: 0.7458 - val_loss: 1.0920 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 946us/step - loss: 0.6324 - accuracy: 0.7514 - val_loss: 1.0678 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.6338 - accuracy: 0.7684 - val_loss: 1.0746 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 358us/step - loss: 0.6271 - accuracy: 0.7514 - val_loss: 1.0805 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6312 - accuracy: 0.7627 - val_loss: 1.0937 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.6269 - accuracy: 0.7684 - val_loss: 1.0854 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.6257 - accuracy: 0.7571 - val_loss: 1.0927 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.6301 - accuracy: 0.7684 - val_loss: 1.1107 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 774us/step - loss: 0.6247 - accuracy: 0.7627 - val_loss: 1.0825 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.6206 - accuracy: 0.7627 - val_loss: 1.0957 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.6183 - accuracy: 0.7684 - val_loss: 1.1093 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.6206 - accuracy: 0.7627 - val_loss: 1.0992 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.6246 - accuracy: 0.7571 - val_loss: 1.1074 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 447us/step - loss: 0.6200 - accuracy: 0.7627 - val_loss: 1.1086 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.6196 - accuracy: 0.7684 - val_loss: 1.0871 - val_accuracy: 0.4342\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.6201 - accuracy: 0.7514 - val_loss: 1.0924 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6144 - accuracy: 0.7571 - val_loss: 1.1067 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6164 - accuracy: 0.7514 - val_loss: 1.1027 - val_accuracy: 0.4474\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6135 - accuracy: 0.7458 - val_loss: 1.1178 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.6136 - accuracy: 0.7514 - val_loss: 1.1054 - val_accuracy: 0.4474\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.6154 - accuracy: 0.7797 - val_loss: 1.0922 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.6125 - accuracy: 0.7571 - val_loss: 1.1066 - val_accuracy: 0.4342\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.6130 - accuracy: 0.7740 - val_loss: 1.1229 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.6092 - accuracy: 0.7740 - val_loss: 1.1045 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.6115 - accuracy: 0.7514 - val_loss: 1.0955 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.6122 - accuracy: 0.7627 - val_loss: 1.1162 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.6043 - accuracy: 0.7627 - val_loss: 1.1142 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6040 - accuracy: 0.7627 - val_loss: 1.0977 - val_accuracy: 0.4342\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.6007 - accuracy: 0.7627 - val_loss: 1.1098 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.6033 - accuracy: 0.7627 - val_loss: 1.1143 - val_accuracy: 0.4342\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6050 - accuracy: 0.7740 - val_loss: 1.1066 - val_accuracy: 0.4474\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.5950 - accuracy: 0.7684 - val_loss: 1.1276 - val_accuracy: 0.4474\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.6112 - accuracy: 0.7401 - val_loss: 1.1454 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.5993 - accuracy: 0.7797 - val_loss: 1.0992 - val_accuracy: 0.4737\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.6008 - accuracy: 0.7684 - val_loss: 1.1193 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.5937 - accuracy: 0.7684 - val_loss: 1.1348 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.5951 - accuracy: 0.7627 - val_loss: 1.1388 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6017 - accuracy: 0.7797 - val_loss: 1.1298 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6067 - accuracy: 0.7514 - val_loss: 1.1162 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.5915 - accuracy: 0.7740 - val_loss: 1.1484 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.5966 - accuracy: 0.7797 - val_loss: 1.1443 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.5901 - accuracy: 0.7740 - val_loss: 1.1313 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 533us/step - loss: 0.5939 - accuracy: 0.7627 - val_loss: 1.1282 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.5868 - accuracy: 0.7627 - val_loss: 1.1470 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.7740 - val_loss: 1.1406 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.148005). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 74.70%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS210</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>8.851192e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>Grady1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625329</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.889404e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999098</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>6.335156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBRSa03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.331796</td>\n",
       "      <td>2.086646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.381903</td>\n",
       "      <td>4.754707e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025601</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>2.864372e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY439</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.266501</td>\n",
       "      <td>5.715521e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652983</td>\n",
       "      <td>0.254172</td>\n",
       "      <td>9.284494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>9.653131e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.260109</td>\n",
       "      <td>3.775318e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage    strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual    NRS210          2           0  0.999887   \n",
       "1       p0017kpresabs_qual    Grady1          0           0  0.625329   \n",
       "2       p0017kpresabs_qual  CFBRSa29          2           0  0.999098   \n",
       "3       p0017kpresabs_qual  CFBRSa03          0           0  0.647338   \n",
       "4       p0017kpresabs_qual       217          1           0  0.613342   \n",
       "..                     ...       ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual    NRS265          1           1  0.025601   \n",
       "604  p0040presabsSTCC_qual     NY439          2           2  0.161947   \n",
       "605  p0040presabsSTCC_qual  CFBRSa05          0           0  0.652983   \n",
       "606  p0040presabsSTCC_qual    NRS205          2           2  0.000927   \n",
       "607  p0040presabsSTCC_qual     CA105          1           0  0.736115   \n",
       "\n",
       "            1             2  \n",
       "0    0.000112  8.851192e-07  \n",
       "1    0.369782  4.889404e-03  \n",
       "2    0.000269  6.335156e-04  \n",
       "3    0.331796  2.086646e-02  \n",
       "4    0.381903  4.754707e-03  \n",
       "..        ...           ...  \n",
       "603  0.687962  2.864372e-01  \n",
       "604  0.266501  5.715521e-01  \n",
       "605  0.254172  9.284494e-02  \n",
       "606  0.033760  9.653131e-01  \n",
       "607  0.260109  3.775318e-03  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02745896, 0.24388753, 0.72865355],\n",
       "       [0.41031465, 0.3863236 , 0.20336173],\n",
       "       [0.17392445, 0.27855307, 0.5475225 ],\n",
       "       [0.4005692 , 0.46448374, 0.13494709],\n",
       "       [0.5675118 , 0.4059035 , 0.02658472],\n",
       "       [0.26331708, 0.39223802, 0.34444493],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.0430968 , 0.06405223, 0.89285094],\n",
       "       [0.13600153, 0.41564044, 0.448358  ],\n",
       "       [0.23632129, 0.39817488, 0.36550388],\n",
       "       [0.4429673 , 0.33354175, 0.22349092],\n",
       "       [0.48203686, 0.35466257, 0.1633005 ],\n",
       "       [0.48203686, 0.35466257, 0.1633005 ],\n",
       "       [0.06772693, 0.18584412, 0.74642897],\n",
       "       [0.49116248, 0.2417376 , 0.26709998],\n",
       "       [0.16175167, 0.29743174, 0.5408166 ],\n",
       "       [0.16274643, 0.12282115, 0.7144324 ],\n",
       "       [0.16113858, 0.25844392, 0.5804175 ],\n",
       "       [0.16175167, 0.29743174, 0.5408166 ],\n",
       "       [0.17020357, 0.39619341, 0.43360302],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.42929918, 0.30019745, 0.27050337],\n",
       "       [0.49116248, 0.2417376 , 0.26709998],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.46501884, 0.10254334, 0.43243775],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.4005692 , 0.46448374, 0.13494709],\n",
       "       [0.40812415, 0.34773186, 0.244144  ],\n",
       "       [0.16175167, 0.29743174, 0.5408166 ],\n",
       "       [0.5708354 , 0.2979454 , 0.13121922],\n",
       "       [0.09462334, 0.29873303, 0.60664356],\n",
       "       [0.09724902, 0.2282363 , 0.6745147 ],\n",
       "       [0.12958649, 0.3245133 , 0.5459002 ],\n",
       "       [0.36294585, 0.25708297, 0.37997124],\n",
       "       [0.0234161 , 0.54976   , 0.42682397],\n",
       "       [0.26984692, 0.67783743, 0.05231564],\n",
       "       [0.35187888, 0.51641166, 0.13170946],\n",
       "       [0.32498273, 0.33466306, 0.3403542 ],\n",
       "       [0.298384  , 0.36013794, 0.3414781 ],\n",
       "       [0.29390925, 0.11430815, 0.5917827 ],\n",
       "       [0.24830791, 0.43273696, 0.3189551 ],\n",
       "       [0.3244151 , 0.38089857, 0.29468644],\n",
       "       [0.21814641, 0.03722702, 0.7446265 ],\n",
       "       [0.04443342, 0.5152376 , 0.44032884],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.30795184, 0.6345375 , 0.05751068],\n",
       "       [0.5211579 , 0.257968  , 0.22087412],\n",
       "       [0.31781566, 0.3771309 , 0.3050534 ],\n",
       "       [0.14294627, 0.12770526, 0.7293485 ],\n",
       "       [0.53841674, 0.30130953, 0.16027376],\n",
       "       [0.42929918, 0.30019745, 0.27050337],\n",
       "       [0.0430968 , 0.06405223, 0.89285094],\n",
       "       [0.14813837, 0.36484587, 0.48701578],\n",
       "       [0.16123171, 0.5873365 , 0.25143182],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.09724902, 0.2282363 , 0.6745147 ],\n",
       "       [0.16175167, 0.29743174, 0.5408166 ],\n",
       "       [0.2983694 , 0.53025365, 0.17137688],\n",
       "       [0.32462034, 0.42153013, 0.25384954],\n",
       "       [0.1410121 , 0.84136015, 0.01762776],\n",
       "       [0.09724902, 0.2282363 , 0.6745147 ],\n",
       "       [0.13552724, 0.30338246, 0.5610903 ],\n",
       "       [0.20856227, 0.26759675, 0.52384096],\n",
       "       [0.17659849, 0.15929104, 0.6641105 ],\n",
       "       [0.03546378, 0.6329484 , 0.33158776],\n",
       "       [0.49681807, 0.2420034 , 0.26117855],\n",
       "       [0.09556322, 0.37189057, 0.5325462 ],\n",
       "       [0.49116248, 0.2417376 , 0.26709998],\n",
       "       [0.36294585, 0.25708297, 0.37997124],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.05180049, 0.36165482, 0.5865447 ],\n",
       "       [0.38783956, 0.3209425 , 0.29121795],\n",
       "       [0.35610828, 0.39630225, 0.24758951],\n",
       "       [0.02513497, 0.3740629 , 0.6008021 ],\n",
       "       [0.12941782, 0.20624624, 0.66433597]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134260852403562"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134260852403562"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat3['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CFBREBSa135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "165       NRS191     2\n",
       "64   CFBREBSa135     0\n",
       "121       NRS064     1\n",
       "228        NY224     1\n",
       "114       NRS035     1\n",
       "..           ...   ...\n",
       "16     BCH-SA-01     0\n",
       "13           504     0\n",
       "96          GA27     2\n",
       "177       NRS209     1\n",
       "28     BCH-SA-13     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 775us/step - loss: 1.1174 - accuracy: 0.3955 - val_loss: 1.0601 - val_accuracy: 0.3816\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 1.0623 - accuracy: 0.4237 - val_loss: 1.0731 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 1.0453 - accuracy: 0.4237 - val_loss: 1.0776 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 1.0330 - accuracy: 0.4463 - val_loss: 1.0691 - val_accuracy: 0.4079\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 1.0160 - accuracy: 0.4576 - val_loss: 1.0654 - val_accuracy: 0.3816\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 1.0067 - accuracy: 0.4520 - val_loss: 1.0591 - val_accuracy: 0.3684\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 1.0026 - accuracy: 0.4689 - val_loss: 1.0548 - val_accuracy: 0.3947\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.9921 - accuracy: 0.5141 - val_loss: 1.0482 - val_accuracy: 0.5132\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.9890 - accuracy: 0.5367 - val_loss: 1.0478 - val_accuracy: 0.4868\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.9859 - accuracy: 0.5311 - val_loss: 1.0405 - val_accuracy: 0.4868\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.9740 - accuracy: 0.5593 - val_loss: 1.0534 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.9698 - accuracy: 0.5480 - val_loss: 1.0569 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.9654 - accuracy: 0.5424 - val_loss: 1.0471 - val_accuracy: 0.4737\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.9603 - accuracy: 0.5480 - val_loss: 1.0357 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.9560 - accuracy: 0.5480 - val_loss: 1.0372 - val_accuracy: 0.4737\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.9493 - accuracy: 0.5537 - val_loss: 1.0424 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.9454 - accuracy: 0.5480 - val_loss: 1.0425 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.9406 - accuracy: 0.5706 - val_loss: 1.0477 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.9413 - accuracy: 0.5706 - val_loss: 1.0527 - val_accuracy: 0.4211\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.9346 - accuracy: 0.5876 - val_loss: 1.0358 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.9332 - accuracy: 0.5593 - val_loss: 1.0366 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.9257 - accuracy: 0.5650 - val_loss: 1.0450 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.9229 - accuracy: 0.6045 - val_loss: 1.0572 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9211 - accuracy: 0.5989 - val_loss: 1.0542 - val_accuracy: 0.4737\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.9152 - accuracy: 0.6102 - val_loss: 1.0366 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.9128 - accuracy: 0.5876 - val_loss: 1.0340 - val_accuracy: 0.5132\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.9150 - accuracy: 0.5650 - val_loss: 1.0407 - val_accuracy: 0.4737\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.9066 - accuracy: 0.5932 - val_loss: 1.0462 - val_accuracy: 0.4868\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.9002 - accuracy: 0.5989 - val_loss: 1.0423 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.8979 - accuracy: 0.6045 - val_loss: 1.0485 - val_accuracy: 0.4868\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.8923 - accuracy: 0.6271 - val_loss: 1.0580 - val_accuracy: 0.4737\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.8903 - accuracy: 0.6158 - val_loss: 1.0509 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.8856 - accuracy: 0.6215 - val_loss: 1.0481 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.8799 - accuracy: 0.6215 - val_loss: 1.0506 - val_accuracy: 0.4868\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.8796 - accuracy: 0.6328 - val_loss: 1.0459 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.8761 - accuracy: 0.6384 - val_loss: 1.0598 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.8716 - accuracy: 0.6158 - val_loss: 1.0489 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8745 - accuracy: 0.6045 - val_loss: 1.0407 - val_accuracy: 0.4868\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.8667 - accuracy: 0.6102 - val_loss: 1.0595 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.8609 - accuracy: 0.6554 - val_loss: 1.0683 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.8556 - accuracy: 0.6497 - val_loss: 1.0679 - val_accuracy: 0.5132\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8553 - accuracy: 0.6497 - val_loss: 1.0584 - val_accuracy: 0.5132\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.8498 - accuracy: 0.6384 - val_loss: 1.0650 - val_accuracy: 0.5263\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.8489 - accuracy: 0.6384 - val_loss: 1.0731 - val_accuracy: 0.5132\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.8445 - accuracy: 0.6441 - val_loss: 1.0692 - val_accuracy: 0.5132\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.8451 - accuracy: 0.6384 - val_loss: 1.0606 - val_accuracy: 0.5132\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.8354 - accuracy: 0.6610 - val_loss: 1.0748 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.8429 - accuracy: 0.6497 - val_loss: 1.0826 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8374 - accuracy: 0.6610 - val_loss: 1.0637 - val_accuracy: 0.5263\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8329 - accuracy: 0.6610 - val_loss: 1.0721 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.8268 - accuracy: 0.6554 - val_loss: 1.0713 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8273 - accuracy: 0.6610 - val_loss: 1.0781 - val_accuracy: 0.4868\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.8217 - accuracy: 0.6610 - val_loss: 1.0664 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8212 - accuracy: 0.6554 - val_loss: 1.0718 - val_accuracy: 0.5263\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8228 - accuracy: 0.6554 - val_loss: 1.0801 - val_accuracy: 0.4868\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 101us/step - loss: 0.8122 - accuracy: 0.6780 - val_loss: 1.0724 - val_accuracy: 0.5132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.8124 - accuracy: 0.6497 - val_loss: 1.0630 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8130 - accuracy: 0.6554 - val_loss: 1.0755 - val_accuracy: 0.5132\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.8055 - accuracy: 0.6723 - val_loss: 1.0764 - val_accuracy: 0.5132\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8028 - accuracy: 0.6667 - val_loss: 1.0712 - val_accuracy: 0.5263\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.8007 - accuracy: 0.6667 - val_loss: 1.0833 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.8003 - accuracy: 0.6667 - val_loss: 1.0846 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.7955 - accuracy: 0.6780 - val_loss: 1.0843 - val_accuracy: 0.5395\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.7933 - accuracy: 0.6667 - val_loss: 1.0848 - val_accuracy: 0.5263\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.7923 - accuracy: 0.6723 - val_loss: 1.0935 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.7863 - accuracy: 0.6780 - val_loss: 1.0901 - val_accuracy: 0.5132\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7883 - accuracy: 0.6723 - val_loss: 1.0907 - val_accuracy: 0.5132\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7855 - accuracy: 0.6667 - val_loss: 1.1007 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.7840 - accuracy: 0.6554 - val_loss: 1.0995 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.7828 - accuracy: 0.6836 - val_loss: 1.1013 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.7801 - accuracy: 0.6780 - val_loss: 1.0936 - val_accuracy: 0.5132\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7797 - accuracy: 0.6667 - val_loss: 1.0951 - val_accuracy: 0.4868\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.7740 - accuracy: 0.6667 - val_loss: 1.1179 - val_accuracy: 0.5132\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.7712 - accuracy: 0.6836 - val_loss: 1.1099 - val_accuracy: 0.5132\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.7674 - accuracy: 0.6723 - val_loss: 1.0977 - val_accuracy: 0.5132\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.7726 - accuracy: 0.6780 - val_loss: 1.0931 - val_accuracy: 0.5132\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.7696 - accuracy: 0.6836 - val_loss: 1.1188 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.7638 - accuracy: 0.6893 - val_loss: 1.1260 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.7624 - accuracy: 0.6949 - val_loss: 1.1139 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.7593 - accuracy: 0.6893 - val_loss: 1.1059 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.7565 - accuracy: 0.6949 - val_loss: 1.1188 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.7601 - accuracy: 0.6893 - val_loss: 1.1117 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.7544 - accuracy: 0.7006 - val_loss: 1.1066 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.7557 - accuracy: 0.6723 - val_loss: 1.1228 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7515 - accuracy: 0.6893 - val_loss: 1.1173 - val_accuracy: 0.4868\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.7491 - accuracy: 0.7006 - val_loss: 1.1148 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.7468 - accuracy: 0.7119 - val_loss: 1.1360 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7479 - accuracy: 0.7006 - val_loss: 1.1277 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.7422 - accuracy: 0.7062 - val_loss: 1.1157 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.7395 - accuracy: 0.7175 - val_loss: 1.1243 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7412 - accuracy: 0.7119 - val_loss: 1.1319 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.7364 - accuracy: 0.7119 - val_loss: 1.1280 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.7496 - accuracy: 0.7062 - val_loss: 1.1180 - val_accuracy: 0.4605\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.7441 - accuracy: 0.7119 - val_loss: 1.1439 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.7371 - accuracy: 0.6949 - val_loss: 1.1291 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.7314 - accuracy: 0.7232 - val_loss: 1.1272 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.7295 - accuracy: 0.7232 - val_loss: 1.1401 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.7269 - accuracy: 0.7232 - val_loss: 1.1417 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.7282 - accuracy: 0.7232 - val_loss: 1.1364 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.7249 - accuracy: 0.7175 - val_loss: 1.1327 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a314b1f60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 128us/step\n",
      "test accuracy: 51.32%\n"
     ]
    }
   ],
   "source": [
    "acc_test3 = model3.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 0, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 0,\n",
       "       0, 0, 2, 2, 1, 1, 0, 1, 1, 2, 1, 0, 2, 1, 0, 0, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 1, 2, 1, 0, 1, 0, 1, 1, 0, 2,\n",
       "       1, 0, 2, 2, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model3.predict_classes(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NRS191</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CFBREBSa135</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NY224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "165       NRS191     2     2\n",
       "64   CFBREBSa135     0     2\n",
       "121       NRS064     1     1\n",
       "228        NY224     1     2\n",
       "114       NRS035     1     2\n",
       "..           ...   ...   ...\n",
       "16     BCH-SA-01     0     0\n",
       "13           504     0     0\n",
       "96          GA27     2     1\n",
       "177       NRS209     1     1\n",
       "28     BCH-SA-13     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model3.predict_proba(X_test)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059193</td>\n",
       "      <td>0.221468</td>\n",
       "      <td>0.719339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.347444</td>\n",
       "      <td>0.230777</td>\n",
       "      <td>0.421778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.960383</td>\n",
       "      <td>0.009598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142872</td>\n",
       "      <td>0.296726</td>\n",
       "      <td>0.560402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124767</td>\n",
       "      <td>0.405024</td>\n",
       "      <td>0.470210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.512167</td>\n",
       "      <td>0.306114</td>\n",
       "      <td>0.181720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.469700</td>\n",
       "      <td>0.363842</td>\n",
       "      <td>0.166458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.290176</td>\n",
       "      <td>0.535882</td>\n",
       "      <td>0.173942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.255762</td>\n",
       "      <td>0.649710</td>\n",
       "      <td>0.094527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.386179</td>\n",
       "      <td>0.300367</td>\n",
       "      <td>0.313454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.059193  0.221468  0.719339\n",
       "1   0.347444  0.230777  0.421778\n",
       "2   0.030019  0.960383  0.009598\n",
       "3   0.142872  0.296726  0.560402\n",
       "4   0.124767  0.405024  0.470210\n",
       "..       ...       ...       ...\n",
       "71  0.512167  0.306114  0.181720\n",
       "72  0.469700  0.363842  0.166458\n",
       "73  0.290176  0.535882  0.173942\n",
       "74  0.255762  0.649710  0.094527\n",
       "75  0.386179  0.300367  0.313454\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 554us/step - loss: 0.7323 - accuracy: 0.7006 - val_loss: 1.0780 - val_accuracy: 0.5132\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.7283 - accuracy: 0.6949 - val_loss: 1.0694 - val_accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.7281 - accuracy: 0.6949 - val_loss: 1.0592 - val_accuracy: 0.5395\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.7273 - accuracy: 0.6893 - val_loss: 1.0740 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7256 - accuracy: 0.7006 - val_loss: 1.0875 - val_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7263 - accuracy: 0.7006 - val_loss: 1.0830 - val_accuracy: 0.5395\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.7253 - accuracy: 0.6780 - val_loss: 1.0696 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.7243 - accuracy: 0.7062 - val_loss: 1.0607 - val_accuracy: 0.5395\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7201 - accuracy: 0.7119 - val_loss: 1.0781 - val_accuracy: 0.5263\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.7177 - accuracy: 0.6893 - val_loss: 1.0835 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.7127 - accuracy: 0.7458 - val_loss: 1.0718 - val_accuracy: 0.5263\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.7118 - accuracy: 0.7062 - val_loss: 1.0669 - val_accuracy: 0.5263\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.7056 - accuracy: 0.6949 - val_loss: 1.0770 - val_accuracy: 0.5132\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.7160 - accuracy: 0.7006 - val_loss: 1.0914 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.7087 - accuracy: 0.7062 - val_loss: 1.0811 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.7084 - accuracy: 0.7175 - val_loss: 1.0883 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7015 - accuracy: 0.7232 - val_loss: 1.0985 - val_accuracy: 0.5132\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7019 - accuracy: 0.7006 - val_loss: 1.0850 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.7001 - accuracy: 0.7119 - val_loss: 1.0818 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.6982 - accuracy: 0.7119 - val_loss: 1.0949 - val_accuracy: 0.4868\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.7024 - accuracy: 0.7119 - val_loss: 1.0867 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.6984 - accuracy: 0.7232 - val_loss: 1.0971 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.6935 - accuracy: 0.7232 - val_loss: 1.1003 - val_accuracy: 0.5263\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6913 - accuracy: 0.7232 - val_loss: 1.1016 - val_accuracy: 0.5263\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.6947 - accuracy: 0.7175 - val_loss: 1.1010 - val_accuracy: 0.4868\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.6887 - accuracy: 0.7062 - val_loss: 1.1089 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6883 - accuracy: 0.7232 - val_loss: 1.1093 - val_accuracy: 0.5132\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.6880 - accuracy: 0.7288 - val_loss: 1.1148 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6867 - accuracy: 0.7288 - val_loss: 1.1200 - val_accuracy: 0.4868\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 315us/step - loss: 0.6891 - accuracy: 0.7175 - val_loss: 1.1054 - val_accuracy: 0.5263\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.6836 - accuracy: 0.7345 - val_loss: 1.1091 - val_accuracy: 0.4737\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.6868 - accuracy: 0.7232 - val_loss: 1.1180 - val_accuracy: 0.5263\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.6789 - accuracy: 0.7288 - val_loss: 1.1165 - val_accuracy: 0.5132\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6774 - accuracy: 0.7232 - val_loss: 1.1164 - val_accuracy: 0.5395\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6762 - accuracy: 0.7119 - val_loss: 1.1165 - val_accuracy: 0.4868\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6737 - accuracy: 0.7232 - val_loss: 1.1246 - val_accuracy: 0.5263\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.6756 - accuracy: 0.7345 - val_loss: 1.1162 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.6712 - accuracy: 0.7175 - val_loss: 1.1185 - val_accuracy: 0.4868\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6677 - accuracy: 0.7345 - val_loss: 1.1208 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.6683 - accuracy: 0.7175 - val_loss: 1.1249 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.6660 - accuracy: 0.7345 - val_loss: 1.1240 - val_accuracy: 0.5263\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.6695 - accuracy: 0.7345 - val_loss: 1.1307 - val_accuracy: 0.5263\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.6597 - accuracy: 0.7458 - val_loss: 1.1324 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.6732 - accuracy: 0.7288 - val_loss: 1.1316 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.6530 - accuracy: 0.7401 - val_loss: 1.1357 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 439us/step - loss: 0.6701 - accuracy: 0.7345 - val_loss: 1.1340 - val_accuracy: 0.5395\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.6568 - accuracy: 0.7514 - val_loss: 1.1553 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.6719 - accuracy: 0.7232 - val_loss: 1.1482 - val_accuracy: 0.4474\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.6582 - accuracy: 0.7288 - val_loss: 1.1360 - val_accuracy: 0.5263\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.6566 - accuracy: 0.7345 - val_loss: 1.1499 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.6560 - accuracy: 0.7232 - val_loss: 1.1386 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 946us/step - loss: 0.6484 - accuracy: 0.7514 - val_loss: 1.1440 - val_accuracy: 0.5132\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 277us/step - loss: 0.6506 - accuracy: 0.7514 - val_loss: 1.1464 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.6504 - accuracy: 0.7345 - val_loss: 1.1477 - val_accuracy: 0.4605\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.6484 - accuracy: 0.7401 - val_loss: 1.1445 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.6517 - accuracy: 0.7401 - val_loss: 1.1360 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.6428 - accuracy: 0.7401 - val_loss: 1.1577 - val_accuracy: 0.4868\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.6477 - accuracy: 0.7514 - val_loss: 1.1600 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6405 - accuracy: 0.7514 - val_loss: 1.1572 - val_accuracy: 0.4868\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 405us/step - loss: 0.6382 - accuracy: 0.7514 - val_loss: 1.1642 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.6383 - accuracy: 0.7514 - val_loss: 1.1665 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.6455 - accuracy: 0.7401 - val_loss: 1.1611 - val_accuracy: 0.5263\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.6343 - accuracy: 0.7345 - val_loss: 1.1685 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6396 - accuracy: 0.7401 - val_loss: 1.1689 - val_accuracy: 0.4868\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.6384 - accuracy: 0.7514 - val_loss: 1.1624 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6339 - accuracy: 0.7627 - val_loss: 1.1770 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.6311 - accuracy: 0.7514 - val_loss: 1.1644 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 135us/step - loss: 0.6447 - accuracy: 0.7458 - val_loss: 1.1680 - val_accuracy: 0.5132\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.6256 - accuracy: 0.7571 - val_loss: 1.1851 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.6335 - accuracy: 0.7345 - val_loss: 1.1790 - val_accuracy: 0.4868\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.6272 - accuracy: 0.7458 - val_loss: 1.1872 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.6258 - accuracy: 0.7627 - val_loss: 1.1772 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.6286 - accuracy: 0.7627 - val_loss: 1.1745 - val_accuracy: 0.4605\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.6210 - accuracy: 0.7740 - val_loss: 1.1804 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 345us/step - loss: 0.6259 - accuracy: 0.7627 - val_loss: 1.1916 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.6242 - accuracy: 0.7571 - val_loss: 1.1924 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6194 - accuracy: 0.7627 - val_loss: 1.1951 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.6195 - accuracy: 0.7514 - val_loss: 1.1891 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 512us/step - loss: 0.6194 - accuracy: 0.7571 - val_loss: 1.1853 - val_accuracy: 0.4605\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 823us/step - loss: 0.6250 - accuracy: 0.7684 - val_loss: 1.1895 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.6125 - accuracy: 0.7627 - val_loss: 1.2025 - val_accuracy: 0.4605\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.6156 - accuracy: 0.7571 - val_loss: 1.1987 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6223 - accuracy: 0.7514 - val_loss: 1.2003 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.6199 - accuracy: 0.7627 - val_loss: 1.2127 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.6165 - accuracy: 0.7740 - val_loss: 1.1996 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 145us/step - loss: 0.6116 - accuracy: 0.7627 - val_loss: 1.2037 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.6091 - accuracy: 0.7627 - val_loss: 1.2005 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.6132 - accuracy: 0.7684 - val_loss: 1.2169 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.6090 - accuracy: 0.7627 - val_loss: 1.2082 - val_accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6220 - accuracy: 0.7571 - val_loss: 1.2114 - val_accuracy: 0.5132\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.6088 - accuracy: 0.7571 - val_loss: 1.2342 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.6204 - accuracy: 0.7684 - val_loss: 1.2248 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6089 - accuracy: 0.7571 - val_loss: 1.2078 - val_accuracy: 0.4737\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.6049 - accuracy: 0.7684 - val_loss: 1.2102 - val_accuracy: 0.4605\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.6029 - accuracy: 0.7684 - val_loss: 1.2032 - val_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.6041 - accuracy: 0.7740 - val_loss: 1.2240 - val_accuracy: 0.4868\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.6036 - accuracy: 0.7797 - val_loss: 1.2217 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6040 - accuracy: 0.7571 - val_loss: 1.2284 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.6098 - accuracy: 0.7740 - val_loss: 1.2311 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.6023 - accuracy: 0.7571 - val_loss: 1.2311 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist3 = model3.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 73.68%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.165526e-02</td>\n",
       "      <td>4.848140e-01</td>\n",
       "      <td>0.493531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.986388e-01</td>\n",
       "      <td>1.245148e-03</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.227520e-04</td>\n",
       "      <td>1.424882e-02</td>\n",
       "      <td>0.984828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.374333e-01</td>\n",
       "      <td>1.614128e-01</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.976981e-09</td>\n",
       "      <td>5.145955e-10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.305407e-01</td>\n",
       "      <td>6.356251e-02</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.476389e-02</td>\n",
       "      <td>8.577548e-01</td>\n",
       "      <td>0.097481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779456e-01</td>\n",
       "      <td>5.384378e-01</td>\n",
       "      <td>0.183617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.210180e-01</td>\n",
       "      <td>3.559393e-01</td>\n",
       "      <td>0.223043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.484084e-03</td>\n",
       "      <td>9.944786e-01</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage     strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual      NY360          2           2  2.165526e-02   \n",
       "1       p0017kpresabs_qual      EUH25          2           0  9.986388e-01   \n",
       "2       p0017kpresabs_qual      EUH15          2           2  9.227520e-04   \n",
       "3       p0017kpresabs_qual     NRS241          0           0  8.374333e-01   \n",
       "4       p0017kpresabs_qual     SR2852          2           2  3.976981e-09   \n",
       "..                     ...        ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  BCH-SA-01          0           0  9.305407e-01   \n",
       "604  p0040presabsSTCC_qual        504          0           1  4.476389e-02   \n",
       "605  p0040presabsSTCC_qual       GA27          2           1  2.779456e-01   \n",
       "606  p0040presabsSTCC_qual     NRS209          1           0  4.210180e-01   \n",
       "607  p0040presabsSTCC_qual  BCH-SA-13          1           1  5.484084e-03   \n",
       "\n",
       "                1         2  \n",
       "0    4.848140e-01  0.493531  \n",
       "1    1.245148e-03  0.000116  \n",
       "2    1.424882e-02  0.984828  \n",
       "3    1.614128e-01  0.001154  \n",
       "4    5.145955e-10  1.000000  \n",
       "..            ...       ...  \n",
       "603  6.356251e-02  0.005897  \n",
       "604  8.577548e-01  0.097481  \n",
       "605  5.384378e-01  0.183617  \n",
       "606  3.559393e-01  0.223043  \n",
       "607  9.944786e-01  0.000037  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05919308, 0.22146776, 0.71933913],\n",
       "       [0.3474444 , 0.23077743, 0.42177823],\n",
       "       [0.03001855, 0.9603833 , 0.00959818],\n",
       "       [0.14287177, 0.29672587, 0.5604024 ],\n",
       "       [0.12476666, 0.4050238 , 0.47020954],\n",
       "       [0.4492654 , 0.17811875, 0.3726158 ],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ],\n",
       "       [0.6480597 , 0.3371173 , 0.01482301],\n",
       "       [0.08153449, 0.37896878, 0.53949666],\n",
       "       [0.25451064, 0.40364456, 0.34184483],\n",
       "       [0.18137051, 0.16252472, 0.6561048 ],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ],\n",
       "       [0.10315937, 0.5849639 , 0.31187674],\n",
       "       [0.03209526, 0.26224244, 0.7056623 ],\n",
       "       [0.06595705, 0.5413944 , 0.39264855],\n",
       "       [0.0579153 , 0.9104134 , 0.0316714 ],\n",
       "       [0.10755979, 0.31743598, 0.5750042 ],\n",
       "       [0.02664254, 0.9655366 , 0.00782085],\n",
       "       [0.10701442, 0.39919853, 0.49378714],\n",
       "       [0.05235415, 0.9157013 , 0.03194448],\n",
       "       [0.25403908, 0.26799777, 0.47796315],\n",
       "       [0.48178965, 0.19618548, 0.32202485],\n",
       "       [0.52888906, 0.2722879 , 0.19882311],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ],\n",
       "       [0.13336548, 0.16857445, 0.69806   ],\n",
       "       [0.2394453 , 0.30585188, 0.4547028 ],\n",
       "       [0.05998265, 0.61055523, 0.32946217],\n",
       "       [0.01136586, 0.96467286, 0.02396138],\n",
       "       [0.6123878 , 0.12806776, 0.2595445 ],\n",
       "       [0.1822106 , 0.6812715 , 0.13651793],\n",
       "       [0.38801873, 0.43088275, 0.18109854],\n",
       "       [0.14664055, 0.40271416, 0.4506453 ],\n",
       "       [0.12760781, 0.76396036, 0.10843179],\n",
       "       [0.561676  , 0.14134316, 0.29698086],\n",
       "       [0.04153499, 0.15585744, 0.8026075 ],\n",
       "       [0.3476823 , 0.40809986, 0.24421778],\n",
       "       [0.5848731 , 0.17127958, 0.24384734],\n",
       "       [0.49935627, 0.27149707, 0.2291467 ],\n",
       "       [0.5779898 , 0.18824603, 0.23376425],\n",
       "       [0.14287177, 0.29672587, 0.5604024 ],\n",
       "       [0.27687755, 0.5743883 , 0.14873414],\n",
       "       [0.14287177, 0.29672587, 0.5604024 ],\n",
       "       [0.03447018, 0.44566926, 0.5198606 ],\n",
       "       [0.3474444 , 0.23077743, 0.42177823],\n",
       "       [0.16405512, 0.15677011, 0.6791747 ],\n",
       "       [0.28244743, 0.4809664 , 0.23658615],\n",
       "       [0.4697003 , 0.36384168, 0.16645795],\n",
       "       [0.55064183, 0.11404934, 0.3353088 ],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ],\n",
       "       [0.34787396, 0.47212392, 0.18000217],\n",
       "       [0.06510813, 0.35769948, 0.5771924 ],\n",
       "       [0.12788284, 0.7046706 , 0.16744658],\n",
       "       [0.3474444 , 0.23077743, 0.42177823],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ],\n",
       "       [0.14287177, 0.29672587, 0.5604024 ],\n",
       "       [0.46191737, 0.18709068, 0.350992  ],\n",
       "       [0.15144974, 0.44718674, 0.4013635 ],\n",
       "       [0.08153449, 0.37896878, 0.53949666],\n",
       "       [0.08440874, 0.7293853 , 0.18620591],\n",
       "       [0.8142676 , 0.06607739, 0.1196551 ],\n",
       "       [0.12760781, 0.76396036, 0.10843179],\n",
       "       [0.5038418 , 0.26769075, 0.22846739],\n",
       "       [0.09604438, 0.63535225, 0.26860338],\n",
       "       [0.18765551, 0.72403   , 0.0883145 ],\n",
       "       [0.44768065, 0.2508417 , 0.3014776 ],\n",
       "       [0.16000775, 0.21862543, 0.62136686],\n",
       "       [0.17486656, 0.45783317, 0.36730024],\n",
       "       [0.46591958, 0.34172288, 0.19235757],\n",
       "       [0.13336548, 0.16857445, 0.69806   ],\n",
       "       [0.29869014, 0.20280156, 0.4985084 ],\n",
       "       [0.06060675, 0.5809466 , 0.35844663],\n",
       "       [0.5121667 , 0.30611375, 0.18171951],\n",
       "       [0.4697003 , 0.36384168, 0.16645795],\n",
       "       [0.29017624, 0.535882  , 0.1739417 ],\n",
       "       [0.25576246, 0.6497101 , 0.09452742],\n",
       "       [0.38617927, 0.30036715, 0.3134536 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248976736619902"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248976736619902"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test.iloc[:,0])\n",
    "dat4['test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CFBREBSa121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test\n",
       "54   CFBREBSa121     1\n",
       "28     BCH-SA-13     1\n",
       "143       NRS148     2\n",
       "73      CFBRSa23     2\n",
       "57   CFBREBSa125     0\n",
       "..           ...   ...\n",
       "208       NRS247     1\n",
       "183       NRS215     1\n",
       "248       SR4152     2\n",
       "114       NRS035     1\n",
       "252       SR4187     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_test = X_test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 793us/step - loss: 1.0764 - accuracy: 0.3559 - val_loss: 1.0954 - val_accuracy: 0.3816\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 1.0378 - accuracy: 0.3898 - val_loss: 1.0837 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 1.0249 - accuracy: 0.4407 - val_loss: 1.0735 - val_accuracy: 0.4605\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 1.0085 - accuracy: 0.4915 - val_loss: 1.0738 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.9973 - accuracy: 0.5085 - val_loss: 1.0720 - val_accuracy: 0.4868\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.9892 - accuracy: 0.5537 - val_loss: 1.0731 - val_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.9799 - accuracy: 0.5763 - val_loss: 1.0666 - val_accuracy: 0.4605\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.9770 - accuracy: 0.5480 - val_loss: 1.0620 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 249us/step - loss: 0.9658 - accuracy: 0.5706 - val_loss: 1.0720 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.9596 - accuracy: 0.5819 - val_loss: 1.0680 - val_accuracy: 0.4342\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.9534 - accuracy: 0.5819 - val_loss: 1.0672 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.9457 - accuracy: 0.5876 - val_loss: 1.0658 - val_accuracy: 0.4342\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.9409 - accuracy: 0.5876 - val_loss: 1.0691 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.9392 - accuracy: 0.5932 - val_loss: 1.0772 - val_accuracy: 0.4211\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.9336 - accuracy: 0.5989 - val_loss: 1.0678 - val_accuracy: 0.4342\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.9327 - accuracy: 0.5876 - val_loss: 1.0699 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.9241 - accuracy: 0.5876 - val_loss: 1.0712 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.9182 - accuracy: 0.5819 - val_loss: 1.0707 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.9150 - accuracy: 0.5932 - val_loss: 1.0768 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.9143 - accuracy: 0.5989 - val_loss: 1.0771 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.9085 - accuracy: 0.5932 - val_loss: 1.0788 - val_accuracy: 0.4342\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.9081 - accuracy: 0.5876 - val_loss: 1.0762 - val_accuracy: 0.4474\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.9023 - accuracy: 0.5932 - val_loss: 1.0808 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8983 - accuracy: 0.5819 - val_loss: 1.0925 - val_accuracy: 0.4342\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.8988 - accuracy: 0.5876 - val_loss: 1.0928 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.9022 - accuracy: 0.6045 - val_loss: 1.0781 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.8943 - accuracy: 0.6102 - val_loss: 1.0827 - val_accuracy: 0.4342\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.8848 - accuracy: 0.6158 - val_loss: 1.1027 - val_accuracy: 0.3947\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.8863 - accuracy: 0.5819 - val_loss: 1.0983 - val_accuracy: 0.4342\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.8800 - accuracy: 0.6158 - val_loss: 1.0859 - val_accuracy: 0.4474\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8797 - accuracy: 0.6045 - val_loss: 1.0906 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.8764 - accuracy: 0.6102 - val_loss: 1.0820 - val_accuracy: 0.4342\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.8714 - accuracy: 0.6102 - val_loss: 1.0901 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.8687 - accuracy: 0.6102 - val_loss: 1.0874 - val_accuracy: 0.4211\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.8646 - accuracy: 0.6102 - val_loss: 1.0876 - val_accuracy: 0.4342\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.8586 - accuracy: 0.6102 - val_loss: 1.0924 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.8582 - accuracy: 0.6215 - val_loss: 1.0982 - val_accuracy: 0.4474\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8615 - accuracy: 0.6328 - val_loss: 1.1017 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.8528 - accuracy: 0.6158 - val_loss: 1.0882 - val_accuracy: 0.4342\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.8518 - accuracy: 0.6215 - val_loss: 1.0917 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.8431 - accuracy: 0.6328 - val_loss: 1.0871 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.8414 - accuracy: 0.6328 - val_loss: 1.0890 - val_accuracy: 0.4474\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.8419 - accuracy: 0.6384 - val_loss: 1.1067 - val_accuracy: 0.4342\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.8360 - accuracy: 0.6441 - val_loss: 1.1007 - val_accuracy: 0.4342\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.8327 - accuracy: 0.6497 - val_loss: 1.1048 - val_accuracy: 0.4605\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.8272 - accuracy: 0.6441 - val_loss: 1.0934 - val_accuracy: 0.3947\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.8293 - accuracy: 0.6158 - val_loss: 1.1063 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 116us/step - loss: 0.8217 - accuracy: 0.6384 - val_loss: 1.1061 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.8204 - accuracy: 0.6328 - val_loss: 1.1036 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.8151 - accuracy: 0.6554 - val_loss: 1.1089 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.8147 - accuracy: 0.6384 - val_loss: 1.1026 - val_accuracy: 0.4211\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.8116 - accuracy: 0.6441 - val_loss: 1.1059 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 125us/step - loss: 0.8078 - accuracy: 0.6441 - val_loss: 1.1196 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.8074 - accuracy: 0.6384 - val_loss: 1.1167 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.8009 - accuracy: 0.6610 - val_loss: 1.1248 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.8007 - accuracy: 0.6497 - val_loss: 1.1205 - val_accuracy: 0.4079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.7967 - accuracy: 0.6441 - val_loss: 1.1123 - val_accuracy: 0.4342\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.7955 - accuracy: 0.6384 - val_loss: 1.1109 - val_accuracy: 0.4079\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.7926 - accuracy: 0.6610 - val_loss: 1.1266 - val_accuracy: 0.4342\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 100us/step - loss: 0.7905 - accuracy: 0.6497 - val_loss: 1.1302 - val_accuracy: 0.4211\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.7934 - accuracy: 0.6554 - val_loss: 1.1280 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.7866 - accuracy: 0.6554 - val_loss: 1.1371 - val_accuracy: 0.4211\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7850 - accuracy: 0.6441 - val_loss: 1.1367 - val_accuracy: 0.4211\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.7829 - accuracy: 0.6384 - val_loss: 1.1194 - val_accuracy: 0.4211\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7804 - accuracy: 0.6441 - val_loss: 1.1312 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.7761 - accuracy: 0.6554 - val_loss: 1.1447 - val_accuracy: 0.4211\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7830 - accuracy: 0.6215 - val_loss: 1.1575 - val_accuracy: 0.3947\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.7796 - accuracy: 0.6384 - val_loss: 1.1326 - val_accuracy: 0.4079\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7726 - accuracy: 0.6497 - val_loss: 1.1408 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.7678 - accuracy: 0.6780 - val_loss: 1.1433 - val_accuracy: 0.4079\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.7651 - accuracy: 0.6780 - val_loss: 1.1461 - val_accuracy: 0.4211\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 250us/step - loss: 0.7616 - accuracy: 0.6780 - val_loss: 1.1373 - val_accuracy: 0.4211\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.7616 - accuracy: 0.6723 - val_loss: 1.1310 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.7617 - accuracy: 0.6836 - val_loss: 1.1426 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7647 - accuracy: 0.6667 - val_loss: 1.1659 - val_accuracy: 0.4211\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7606 - accuracy: 0.6667 - val_loss: 1.1404 - val_accuracy: 0.4079\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.7562 - accuracy: 0.6667 - val_loss: 1.1464 - val_accuracy: 0.4211\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7498 - accuracy: 0.7006 - val_loss: 1.1533 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 147us/step - loss: 0.7508 - accuracy: 0.6949 - val_loss: 1.1603 - val_accuracy: 0.4079\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.7476 - accuracy: 0.6723 - val_loss: 1.1451 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 137us/step - loss: 0.7470 - accuracy: 0.6893 - val_loss: 1.1515 - val_accuracy: 0.4474\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.7409 - accuracy: 0.6949 - val_loss: 1.1794 - val_accuracy: 0.4211\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.7430 - accuracy: 0.6780 - val_loss: 1.1761 - val_accuracy: 0.4079\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.7354 - accuracy: 0.6893 - val_loss: 1.1527 - val_accuracy: 0.4079\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.7377 - accuracy: 0.6836 - val_loss: 1.1527 - val_accuracy: 0.4079\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7352 - accuracy: 0.7062 - val_loss: 1.1774 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.7290 - accuracy: 0.7006 - val_loss: 1.1621 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.7403 - accuracy: 0.6949 - val_loss: 1.1570 - val_accuracy: 0.4211\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7408 - accuracy: 0.6723 - val_loss: 1.1974 - val_accuracy: 0.3816\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.7288 - accuracy: 0.7006 - val_loss: 1.1634 - val_accuracy: 0.4211\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.7228 - accuracy: 0.6949 - val_loss: 1.1673 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.7229 - accuracy: 0.6949 - val_loss: 1.1719 - val_accuracy: 0.4079\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.7183 - accuracy: 0.7006 - val_loss: 1.1736 - val_accuracy: 0.4211\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.7150 - accuracy: 0.7006 - val_loss: 1.1912 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.7163 - accuracy: 0.7062 - val_loss: 1.1968 - val_accuracy: 0.4211\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.7150 - accuracy: 0.6949 - val_loss: 1.1763 - val_accuracy: 0.4474\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7143 - accuracy: 0.6949 - val_loss: 1.1711 - val_accuracy: 0.4474\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.7098 - accuracy: 0.6949 - val_loss: 1.1916 - val_accuracy: 0.4211\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.7087 - accuracy: 0.7119 - val_loss: 1.1913 - val_accuracy: 0.4342\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.7030 - accuracy: 0.6893 - val_loss: 1.1810 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a31931a20>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 189us/step\n",
      "test accuracy: 40.79%\n"
     ]
    }
   ],
   "source": [
    "acc_test4 = model4.evaluate(X_test, y_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2,\n",
       "       0, 0, 2, 0, 1, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2,\n",
       "       0, 0, 0, 1, 2, 0, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1,\n",
       "       1, 2, 0, 2, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model4.predict_classes(X_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CFBREBSa121</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BCH-SA-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CFBRSa23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  test  pred\n",
       "54   CFBREBSa121     1     2\n",
       "28     BCH-SA-13     1     0\n",
       "143       NRS148     2     2\n",
       "73      CFBRSa23     2     2\n",
       "57   CFBREBSa125     0     0\n",
       "..           ...   ...   ...\n",
       "208       NRS247     1     1\n",
       "183       NRS215     1     1\n",
       "248       SR4152     2     2\n",
       "114       NRS035     1     2\n",
       "252       SR4187     2     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model4.predict_proba(X_test)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165234</td>\n",
       "      <td>0.331337</td>\n",
       "      <td>0.503428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502827</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.240230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047732</td>\n",
       "      <td>0.225732</td>\n",
       "      <td>0.726536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178010</td>\n",
       "      <td>0.292197</td>\n",
       "      <td>0.529794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.502827</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.240230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.198291</td>\n",
       "      <td>0.539802</td>\n",
       "      <td>0.261907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.518846</td>\n",
       "      <td>0.471453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.057430</td>\n",
       "      <td>0.079704</td>\n",
       "      <td>0.862866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.163357</td>\n",
       "      <td>0.341239</td>\n",
       "      <td>0.495404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.057430</td>\n",
       "      <td>0.079704</td>\n",
       "      <td>0.862866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.165234  0.331337  0.503428\n",
       "1   0.502827  0.256943  0.240230\n",
       "2   0.047732  0.225732  0.726536\n",
       "3   0.178010  0.292197  0.529794\n",
       "4   0.502827  0.256943  0.240230\n",
       "..       ...       ...       ...\n",
       "71  0.198291  0.539802  0.261907\n",
       "72  0.009701  0.518846  0.471453\n",
       "73  0.057430  0.079704  0.862866\n",
       "74  0.163357  0.341239  0.495404\n",
       "75  0.057430  0.079704  0.862866\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7007 - accuracy: 0.7175 - val_loss: 1.2247 - val_accuracy: 0.4079\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 253us/step - loss: 0.7053 - accuracy: 0.7119 - val_loss: 1.2515 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.7023 - accuracy: 0.7062 - val_loss: 1.2214 - val_accuracy: 0.3947\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6931 - accuracy: 0.7062 - val_loss: 1.2390 - val_accuracy: 0.4342\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.6882 - accuracy: 0.7119 - val_loss: 1.2419 - val_accuracy: 0.3947\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.6902 - accuracy: 0.7288 - val_loss: 1.2470 - val_accuracy: 0.4079\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6841 - accuracy: 0.7232 - val_loss: 1.2440 - val_accuracy: 0.4342\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.6859 - accuracy: 0.7288 - val_loss: 1.2425 - val_accuracy: 0.4342\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6830 - accuracy: 0.7232 - val_loss: 1.2554 - val_accuracy: 0.4211\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 263us/step - loss: 0.6879 - accuracy: 0.7288 - val_loss: 1.2541 - val_accuracy: 0.4079\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6844 - accuracy: 0.7232 - val_loss: 1.2495 - val_accuracy: 0.4342\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6799 - accuracy: 0.7345 - val_loss: 1.2556 - val_accuracy: 0.4342\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.6753 - accuracy: 0.7232 - val_loss: 1.2537 - val_accuracy: 0.4079\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6786 - accuracy: 0.7288 - val_loss: 1.2534 - val_accuracy: 0.4079\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.6770 - accuracy: 0.7175 - val_loss: 1.2782 - val_accuracy: 0.3947\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.6741 - accuracy: 0.7232 - val_loss: 1.2643 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6698 - accuracy: 0.7401 - val_loss: 1.2725 - val_accuracy: 0.4211\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6690 - accuracy: 0.7401 - val_loss: 1.2623 - val_accuracy: 0.4211\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.6802 - accuracy: 0.7119 - val_loss: 1.2553 - val_accuracy: 0.4079\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.6699 - accuracy: 0.7401 - val_loss: 1.2890 - val_accuracy: 0.4342\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 849us/step - loss: 0.6672 - accuracy: 0.7345 - val_loss: 1.2802 - val_accuracy: 0.4342\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.6683 - accuracy: 0.7401 - val_loss: 1.2831 - val_accuracy: 0.4342\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 260us/step - loss: 0.6623 - accuracy: 0.7514 - val_loss: 1.2747 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6658 - accuracy: 0.7345 - val_loss: 1.2769 - val_accuracy: 0.4211\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6620 - accuracy: 0.7345 - val_loss: 1.2704 - val_accuracy: 0.4342\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.6621 - accuracy: 0.7232 - val_loss: 1.2826 - val_accuracy: 0.4342\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.6587 - accuracy: 0.7401 - val_loss: 1.2798 - val_accuracy: 0.4211\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 0.6618 - accuracy: 0.7401 - val_loss: 1.2694 - val_accuracy: 0.4211\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6552 - accuracy: 0.7288 - val_loss: 1.2756 - val_accuracy: 0.4079\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.6518 - accuracy: 0.7401 - val_loss: 1.2843 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6509 - accuracy: 0.7514 - val_loss: 1.2854 - val_accuracy: 0.4342\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6516 - accuracy: 0.7458 - val_loss: 1.2903 - val_accuracy: 0.4342\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6553 - accuracy: 0.7288 - val_loss: 1.2885 - val_accuracy: 0.4079\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.6467 - accuracy: 0.7401 - val_loss: 1.2996 - val_accuracy: 0.4342\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6489 - accuracy: 0.7514 - val_loss: 1.3133 - val_accuracy: 0.3947\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.6460 - accuracy: 0.7288 - val_loss: 1.3083 - val_accuracy: 0.4342\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 140us/step - loss: 0.6459 - accuracy: 0.7571 - val_loss: 1.2920 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.6431 - accuracy: 0.7514 - val_loss: 1.3023 - val_accuracy: 0.4211\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.6506 - accuracy: 0.7684 - val_loss: 1.3121 - val_accuracy: 0.3947\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.6428 - accuracy: 0.7401 - val_loss: 1.3078 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.6392 - accuracy: 0.7401 - val_loss: 1.2995 - val_accuracy: 0.4079\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.6401 - accuracy: 0.7401 - val_loss: 1.3095 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6405 - accuracy: 0.7288 - val_loss: 1.2976 - val_accuracy: 0.4211\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6415 - accuracy: 0.7514 - val_loss: 1.3174 - val_accuracy: 0.3947\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.6410 - accuracy: 0.7401 - val_loss: 1.3175 - val_accuracy: 0.4211\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6382 - accuracy: 0.7401 - val_loss: 1.3105 - val_accuracy: 0.4342\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.6334 - accuracy: 0.7345 - val_loss: 1.3192 - val_accuracy: 0.4211\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.6309 - accuracy: 0.7401 - val_loss: 1.3225 - val_accuracy: 0.4211\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.6269 - accuracy: 0.7571 - val_loss: 1.3353 - val_accuracy: 0.4342\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.6344 - accuracy: 0.7458 - val_loss: 1.3260 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.6411 - accuracy: 0.7006 - val_loss: 1.3539 - val_accuracy: 0.3947\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 0.6418 - accuracy: 0.7514 - val_loss: 1.3134 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.6309 - accuracy: 0.7627 - val_loss: 1.3470 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.6259 - accuracy: 0.7345 - val_loss: 1.3565 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.6252 - accuracy: 0.7401 - val_loss: 1.3362 - val_accuracy: 0.4474\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6195 - accuracy: 0.7684 - val_loss: 1.3315 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.6187 - accuracy: 0.7684 - val_loss: 1.3415 - val_accuracy: 0.4342\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.6191 - accuracy: 0.7571 - val_loss: 1.3448 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.6143 - accuracy: 0.7684 - val_loss: 1.3338 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.6192 - accuracy: 0.7571 - val_loss: 1.3419 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.6146 - accuracy: 0.7571 - val_loss: 1.3655 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.6212 - accuracy: 0.7514 - val_loss: 1.3467 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.6148 - accuracy: 0.7458 - val_loss: 1.3617 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.6097 - accuracy: 0.7571 - val_loss: 1.3395 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.6162 - accuracy: 0.7571 - val_loss: 1.3427 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.6095 - accuracy: 0.7627 - val_loss: 1.3611 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.6095 - accuracy: 0.7458 - val_loss: 1.3704 - val_accuracy: 0.4342\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6115 - accuracy: 0.7797 - val_loss: 1.3610 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6050 - accuracy: 0.7627 - val_loss: 1.3736 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6244 - accuracy: 0.7345 - val_loss: 1.3635 - val_accuracy: 0.4079\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 366us/step - loss: 0.6086 - accuracy: 0.7571 - val_loss: 1.3790 - val_accuracy: 0.4079\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.6162 - accuracy: 0.7627 - val_loss: 1.3745 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6052 - accuracy: 0.7684 - val_loss: 1.3705 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.6098 - accuracy: 0.7458 - val_loss: 1.3699 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6078 - accuracy: 0.7627 - val_loss: 1.3579 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.6095 - accuracy: 0.7571 - val_loss: 1.3954 - val_accuracy: 0.4342\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6041 - accuracy: 0.7401 - val_loss: 1.3774 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.5957 - accuracy: 0.7797 - val_loss: 1.3658 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.6049 - accuracy: 0.7514 - val_loss: 1.3752 - val_accuracy: 0.4211\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.5958 - accuracy: 0.7571 - val_loss: 1.3819 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.6018 - accuracy: 0.7458 - val_loss: 1.3879 - val_accuracy: 0.4474\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.5926 - accuracy: 0.7571 - val_loss: 1.3877 - val_accuracy: 0.4474\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.5902 - accuracy: 0.7684 - val_loss: 1.3691 - val_accuracy: 0.4474\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.5927 - accuracy: 0.7627 - val_loss: 1.3849 - val_accuracy: 0.4474\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.5984 - accuracy: 0.7458 - val_loss: 1.4086 - val_accuracy: 0.3947\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.5876 - accuracy: 0.7571 - val_loss: 1.3771 - val_accuracy: 0.4211\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.5932 - accuracy: 0.7740 - val_loss: 1.3896 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.5924 - accuracy: 0.7627 - val_loss: 1.4076 - val_accuracy: 0.4079\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.5904 - accuracy: 0.7627 - val_loss: 1.3818 - val_accuracy: 0.4474\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.5880 - accuracy: 0.7571 - val_loss: 1.3952 - val_accuracy: 0.4474\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.5889 - accuracy: 0.7401 - val_loss: 1.4095 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.5881 - accuracy: 0.7345 - val_loss: 1.4150 - val_accuracy: 0.4474\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 0.5835 - accuracy: 0.7684 - val_loss: 1.4184 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.5848 - accuracy: 0.7740 - val_loss: 1.4052 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.5851 - accuracy: 0.7684 - val_loss: 1.4000 - val_accuracy: 0.4474\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 294us/step - loss: 0.5800 - accuracy: 0.7740 - val_loss: 1.4100 - val_accuracy: 0.4342\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.5835 - accuracy: 0.7458 - val_loss: 1.4194 - val_accuracy: 0.3947\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.5870 - accuracy: 0.7458 - val_loss: 1.3948 - val_accuracy: 0.4474\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.5793 - accuracy: 0.7627 - val_loss: 1.4200 - val_accuracy: 0.4079\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.5798 - accuracy: 0.7684 - val_loss: 1.4155 - val_accuracy: 0.4605\n"
     ]
    }
   ],
   "source": [
    "hist4 = model4.fit(X_train, y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 74.54%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.821690e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA105</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.652370e-03</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>9.972990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198157e-02</td>\n",
       "      <td>0.988018</td>\n",
       "      <td>5.232074e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>EUH25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.388957e-01</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>1.251503e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS070</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231966e-03</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>1.824512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.957360e-02</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>5.846961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS215</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.196635e-03</td>\n",
       "      <td>0.445057</td>\n",
       "      <td>5.517461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.319404e-02</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>9.278219e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.902312e-03</td>\n",
       "      <td>0.680427</td>\n",
       "      <td>3.146706e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR4187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.566210e-04</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>9.439281e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage  strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  SR1129          2           2  4.821690e-07   \n",
       "1       p0017kpresabs_qual   CA105          2           2  2.652370e-03   \n",
       "2       p0017kpresabs_qual  NRS175          1           1  1.198157e-02   \n",
       "3       p0017kpresabs_qual   EUH25          2           1  1.388957e-01   \n",
       "4       p0017kpresabs_qual  NRS070          2           1  7.231966e-03   \n",
       "..                     ...     ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  NRS247          1           2  2.957360e-02   \n",
       "604  p0040presabsSTCC_qual  NRS215          1           2  3.196635e-03   \n",
       "605  p0040presabsSTCC_qual  SR4152          2           2  4.319404e-02   \n",
       "606  p0040presabsSTCC_qual  NRS035          1           1  4.902312e-03   \n",
       "607  p0040presabsSTCC_qual  SR4187          2           2  2.566210e-04   \n",
       "\n",
       "            1             2  \n",
       "0    0.000001  9.999983e-01  \n",
       "1    0.000049  9.972990e-01  \n",
       "2    0.988018  5.232074e-09  \n",
       "3    0.735954  1.251503e-01  \n",
       "4    0.810317  1.824512e-01  \n",
       "..        ...           ...  \n",
       "603  0.385730  5.846961e-01  \n",
       "604  0.445057  5.517461e-01  \n",
       "605  0.028984  9.278219e-01  \n",
       "606  0.680427  3.146706e-01  \n",
       "607  0.055815  9.439281e-01  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16523431, 0.33133727, 0.5034284 ],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.04773205, 0.22573198, 0.7265359 ],\n",
       "       [0.17800961, 0.29219654, 0.5297938 ],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.05742967, 0.07970402, 0.8628663 ],\n",
       "       [0.8313017 , 0.05558755, 0.11311081],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.03014656, 0.4413388 , 0.5285147 ],\n",
       "       [0.02700538, 0.71684307, 0.2561516 ],\n",
       "       [0.02916371, 0.64990294, 0.32093334],\n",
       "       [0.58799314, 0.22570574, 0.18630114],\n",
       "       [0.45778385, 0.2738882 , 0.26832792],\n",
       "       [0.5359039 , 0.14224726, 0.3218489 ],\n",
       "       [0.36572504, 0.4988753 , 0.13539974],\n",
       "       [0.45986798, 0.37405753, 0.16607451],\n",
       "       [0.19829066, 0.5398022 , 0.26190707],\n",
       "       [0.1412882 , 0.67800796, 0.1807038 ],\n",
       "       [0.17800961, 0.29219654, 0.5297938 ],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.18196003, 0.3765768 , 0.4414631 ],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.06469195, 0.07349418, 0.86181384],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.04355257, 0.6367496 , 0.3196979 ],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.03291535, 0.30859905, 0.6584856 ],\n",
       "       [0.0322935 , 0.4115292 , 0.55617726],\n",
       "       [0.40517905, 0.48704943, 0.10777157],\n",
       "       [0.4273586 , 0.3185427 , 0.2540988 ],\n",
       "       [0.01604213, 0.098613  , 0.88534486],\n",
       "       [0.20223221, 0.16506504, 0.6327027 ],\n",
       "       [0.1332656 , 0.6035616 , 0.26317278],\n",
       "       [0.18196003, 0.3765768 , 0.4414631 ],\n",
       "       [0.08401113, 0.04431332, 0.87167555],\n",
       "       [0.15950759, 0.3284842 , 0.51200813],\n",
       "       [0.04081778, 0.65258044, 0.30660176],\n",
       "       [0.05795816, 0.46774542, 0.47429645],\n",
       "       [0.14595233, 0.43200237, 0.42204526],\n",
       "       [0.05049624, 0.10903952, 0.84046423],\n",
       "       [0.05742967, 0.07970402, 0.8628663 ],\n",
       "       [0.27715215, 0.31197625, 0.41087162],\n",
       "       [0.67553353, 0.09432287, 0.23014359],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.68746865, 0.17934063, 0.13319078],\n",
       "       [0.18719324, 0.5374781 , 0.2753286 ],\n",
       "       [0.12005287, 0.32046664, 0.5594804 ],\n",
       "       [0.8526255 , 0.04715449, 0.10022008],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.05022368, 0.05520423, 0.8945721 ],\n",
       "       [0.06190123, 0.76426476, 0.17383406],\n",
       "       [0.08496565, 0.66689885, 0.2481355 ],\n",
       "       [0.1849639 , 0.66353726, 0.15149881],\n",
       "       [0.5390633 , 0.29135808, 0.16957867],\n",
       "       [0.01884978, 0.92542404, 0.05572613],\n",
       "       [0.33315492, 0.4382843 , 0.22856085],\n",
       "       [0.34614724, 0.44047752, 0.21337524],\n",
       "       [0.02207948, 0.9437752 , 0.03414532],\n",
       "       [0.38455015, 0.497773  , 0.11767685],\n",
       "       [0.30820566, 0.52359563, 0.16819866],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.502827  , 0.25694343, 0.24022952],\n",
       "       [0.02227658, 0.2799369 , 0.6977865 ],\n",
       "       [0.20054609, 0.43258047, 0.36687347],\n",
       "       [0.14618003, 0.6144079 , 0.23941208],\n",
       "       [0.16335729, 0.34123874, 0.49540398],\n",
       "       [0.50208455, 0.16712257, 0.33079287],\n",
       "       [0.17800961, 0.29219654, 0.5297938 ],\n",
       "       [0.09149234, 0.8583344 , 0.05017323],\n",
       "       [0.19829066, 0.5398022 , 0.26190707],\n",
       "       [0.00970146, 0.5188457 , 0.4714528 ],\n",
       "       [0.05742967, 0.07970402, 0.8628663 ],\n",
       "       [0.16335729, 0.34123874, 0.49540398],\n",
       "       [0.05742967, 0.07970402, 0.8628663 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955877204333735"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955877204333735"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6693165013138127"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06090207275160645"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6693165013138127"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06090207275160645"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test1, acc_test2, acc_test3, acc_test4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean: 48.03%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation: 0.04314104878345486\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1.history['accuracy']), np.mean(hist2.history['accuracy']), np.mean(hist3.history['accuracy']),\n",
    "             np.mean(hist4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean: 74.02%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation: 0.006239113\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Feature selection using lasso ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='auto',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=None,\n",
       "                                             solver='liblinear', tol=0.0001,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "selection.fit(X.loc[:, X.columns != 'id'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(df_clean.columns).tolist()\n",
    "names.remove('pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.vstack((names, X.loc[:, X.columns != 'id']))\n",
    "X_train_features = pd.DataFrame(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 180\n",
      "selected features: 53\n"
     ]
    }
   ],
   "source": [
    "sel_features = X_train_features.columns[(selection.get_support())]\n",
    "print('total features: {}'.format((X_train_features.shape[1])))\n",
    "print('selected features: {}'.format(len(sel_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   7,  12,  21,  35,  41,  44,  62,  64,  66,  67,  68,  70,\n",
       "         71,  75,  79,  80,  81,  82,  83,  87,  88,  90,  91,  92,  93,\n",
       "         94, 107, 108, 109, 110, 113, 116, 117, 125, 126, 129, 131, 132,\n",
       "        134, 135, 136, 139, 143, 146, 148, 152, 153, 163, 169, 174, 175,\n",
       "        179]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = sel_features.values\n",
    "cols.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT',\n",
       "       'TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC',\n",
       "       'TTTCACTGCCTGT', 'TTGCAAATCCAC',\n",
       "       'TTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTTGCAACAGCGAAATC',\n",
       "       'TGTCTGATTTTTT',\n",
       "       'TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA',\n",
       "       'TCGTGTCTGT', 'TCGCTGAAATAT', 'TCGCTGAAATATTT', 'TCGCTGAAATATTTG',\n",
       "       'TCGCTGAAATATTTGCGACAT', 'TCATCAAACTTT', 'TCAGTAGAGAT',\n",
       "       'TCACACCGCCT', 'TATCAGTTTTGTT', 'TATAGTGTTCAT', 'TAGTCATACAAT',\n",
       "       'TAGCTAAATCC', 'TAGATTCAAATAT', 'TAATGGTAGTAGATAATTTTTC',\n",
       "       'TAATCTTGTTGTT',\n",
       "       'TAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATT',\n",
       "       'TAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTT',\n",
       "       'TAACAAAACTGATAATTAATATACTGCTTATCAATAACATTAAGCGGTGGTGAAACTTCATCATT',\n",
       "       'TAAATTCCATAC',\n",
       "       'TAAATCGTCTTTATATTTAATTATTAAATTAACAAATTTTAATTGGCGGATGAGGTATCCAGTTACCTCGTTCGCCAATTATTTTTCGCAATATAAAAAG',\n",
       "       'GTTGCGAATGC',\n",
       "       'GTTGCAACATCTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAG',\n",
       "       'GTTGCAAATCCAC',\n",
       "       'GTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGT',\n",
       "       'GTGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTT',\n",
       "       'GTGAATTCATG', 'GTCTGATTTTTT', 'GGAGGATGAG', 'GGAGGATGAGG',\n",
       "       'GCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAG',\n",
       "       'GCTGAAATATTTG', 'GCTAATTATGTTTCTGGATT', 'GAGGAGGATGAGG',\n",
       "       'GAGGAAGCAGAT', 'GACAGGCAGT',\n",
       "       'GAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTT',\n",
       "       'CTTTAACAGGTGTTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGT',\n",
       "       'CTGTTTAATGATT', 'CTAATCCTTCAAT', 'CGCTGAAATATTTG',\n",
       "       'CGCTGAAATATTTGCG',\n",
       "       'CAAAAGATCAAACTAAAACACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGT',\n",
       "       'AGTTTATCTGCT',\n",
       "       'ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT',\n",
       "       'ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT',\n",
       "       'AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_arr = np.array(names)\n",
    "names_arr[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### keep selected variables as a new dataframe\n",
    "df_sel = df_clean.loc[:,names_arr[cols]].copy()\n",
    "df_sel['pheno'] = df_clean['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sel['strain'] = X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT</th>\n",
       "      <th>TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC</th>\n",
       "      <th>TTTCACTGCCTGT</th>\n",
       "      <th>TTGCAAATCCAC</th>\n",
       "      <th>TTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTTGCAACAGCGAAATC</th>\n",
       "      <th>TGTCTGATTTTTT</th>\n",
       "      <th>TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA</th>\n",
       "      <th>TCGTGTCTGT</th>\n",
       "      <th>TCGCTGAAATAT</th>\n",
       "      <th>TCGCTGAAATATTT</th>\n",
       "      <th>...</th>\n",
       "      <th>CTAATCCTTCAAT</th>\n",
       "      <th>CGCTGAAATATTTG</th>\n",
       "      <th>CGCTGAAATATTTGCG</th>\n",
       "      <th>CAAAAGATCAAACTAAAACACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGT</th>\n",
       "      <th>AGTTTATCTGCT</th>\n",
       "      <th>ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT</th>\n",
       "      <th>ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT</th>\n",
       "      <th>AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT</th>\n",
       "      <th>pheno</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SR4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SR4187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTTAT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TTTGAACTTTATTTTGTTCTTGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATC  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TTTCACTGCCTGT  TTGCAAATCCAC  \\\n",
       "0                0             0   \n",
       "1                1             1   \n",
       "2                1             1   \n",
       "3                1             1   \n",
       "4                1             1   \n",
       "..             ...           ...   \n",
       "248              1             1   \n",
       "249              1             1   \n",
       "250              1             1   \n",
       "251              0             1   \n",
       "252              1             1   \n",
       "\n",
       "     TTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTTGCAACAGCGAAATC  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     TGTCTGATTTTTT  \\\n",
       "0                0   \n",
       "1                1   \n",
       "2                1   \n",
       "3                1   \n",
       "4                1   \n",
       "..             ...   \n",
       "248              1   \n",
       "249              1   \n",
       "250              1   \n",
       "251              0   \n",
       "252              1   \n",
       "\n",
       "     TGGCTTAGGCTATAAATTGGAAAGACCTAAAGAACAATGATGAAGTTTCACCACCGCTTAATGTTATTGATAAGCAGTATATTAATTATCAGTTTTGTTA  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    1                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  1                                                      \n",
       "251                                                  0                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     TCGTGTCTGT  TCGCTGAAATAT  TCGCTGAAATATTT  ...  CTAATCCTTCAAT  \\\n",
       "0             1             0               0  ...              0   \n",
       "1             1             1               1  ...              1   \n",
       "2             1             1               1  ...              1   \n",
       "3             1             1               1  ...              1   \n",
       "4             1             1               1  ...              1   \n",
       "..          ...           ...             ...  ...            ...   \n",
       "248           1             1               1  ...              1   \n",
       "249           1             1               1  ...              1   \n",
       "250           1             1               1  ...              1   \n",
       "251           1             1               1  ...              0   \n",
       "252           1             1               1  ...              1   \n",
       "\n",
       "     CGCTGAAATATTTG  CGCTGAAATATTTGCG  \\\n",
       "0                 0                 0   \n",
       "1                 1                 1   \n",
       "2                 1                 1   \n",
       "3                 1                 1   \n",
       "4                 1                 1   \n",
       "..              ...               ...   \n",
       "248               1                 1   \n",
       "249               1                 1   \n",
       "250               1                 1   \n",
       "251               1                 1   \n",
       "252               1                 1   \n",
       "\n",
       "     CAAAAGATCAAACTAAAACACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AGTTTATCTGCT  \\\n",
       "0               0   \n",
       "1               1   \n",
       "2               1   \n",
       "3               1   \n",
       "4               1   \n",
       "..            ...   \n",
       "248             1   \n",
       "249             1   \n",
       "250             1   \n",
       "251             0   \n",
       "252             1   \n",
       "\n",
       "     ACTTTTTATATTGCGAAAAATAATTGGCGAACGAGGTAACTGGATACCTCATCCGCCAATTAAAATTTGTTAATTTAATAATTAAATATAAAGACGATTT  \\\n",
       "0                                                    1                                                      \n",
       "1                                                    1                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    0                                                      \n",
       "4                                                    0                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  0                                                      \n",
       "249                                                  0                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  0                                                      \n",
       "\n",
       "     ACTGTATGAGCAGTTTGTGCTGTTTTAACTGTATGAGCAGTTTGTGTTTTAGTTTGATCTTTTGTTGTGTCAGTACTTACAACTTTAGTAGAGTGATTGT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     AACTGCTCATACAGTTAAAACAGCACAAACTGCTCATACAGTTAAAACAGCACAAACTGCTCAAGAACAAAATAAAGTTCAAACACCTGTTAAAGATGTT  \\\n",
       "0                                                    0                                                      \n",
       "1                                                    0                                                      \n",
       "2                                                    0                                                      \n",
       "3                                                    1                                                      \n",
       "4                                                    1                                                      \n",
       "..                                                 ...                                                      \n",
       "248                                                  1                                                      \n",
       "249                                                  1                                                      \n",
       "250                                                  0                                                      \n",
       "251                                                  1                                                      \n",
       "252                                                  1                                                      \n",
       "\n",
       "     pheno  strain  \n",
       "0        2     107  \n",
       "1        0     109  \n",
       "2        2     115  \n",
       "3        2  120335  \n",
       "4        2  120337  \n",
       "..     ...     ...  \n",
       "248      2  SR4152  \n",
       "249      1  SR4153  \n",
       "250      1  SR4155  \n",
       "251      2  SR4156  \n",
       "252      2  SR4187  \n",
       "\n",
       "[253 rows x 55 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 54) (253,) (253, 55)\n"
     ]
    }
   ],
   "source": [
    "X_sel = df_sel.loc[:, df_sel.columns != 'pheno']\n",
    "y_sel = df_sel['pheno']\n",
    "print(X_sel.shape, y_sel.shape, df_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    95\n",
       "1    94\n",
       "0    64\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat5['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SR4156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BCH-SA-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NY417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "251       SR4156     2\n",
       "17     BCH-SA-02     0\n",
       "158       NRS180     2\n",
       "232        NY417     1\n",
       "47   CFBREBSa110     2\n",
       "..           ...   ...\n",
       "62   CFBREBSa131     2\n",
       "138       NRS112     2\n",
       "21     BCH-SA-06     0\n",
       "15          834N     2\n",
       "40           CA9     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model_sel = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 709us/step - loss: 1.1923 - accuracy: 0.2147 - val_loss: 1.1208 - val_accuracy: 0.3684\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 1.1612 - accuracy: 0.2825 - val_loss: 1.1036 - val_accuracy: 0.3553\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 1.1359 - accuracy: 0.3333 - val_loss: 1.0917 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 1.1124 - accuracy: 0.3503 - val_loss: 1.0835 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 1.0922 - accuracy: 0.3898 - val_loss: 1.0775 - val_accuracy: 0.3816\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 1.0730 - accuracy: 0.4237 - val_loss: 1.0714 - val_accuracy: 0.3816\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 1.0567 - accuracy: 0.4294 - val_loss: 1.0675 - val_accuracy: 0.4211\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 1.0415 - accuracy: 0.4463 - val_loss: 1.0649 - val_accuracy: 0.4079\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 1.0301 - accuracy: 0.4972 - val_loss: 1.0638 - val_accuracy: 0.4079\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 1.0197 - accuracy: 0.5028 - val_loss: 1.0635 - val_accuracy: 0.4342\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 1.0094 - accuracy: 0.5367 - val_loss: 1.0605 - val_accuracy: 0.4605\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 1.0019 - accuracy: 0.5706 - val_loss: 1.0583 - val_accuracy: 0.4342\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.9945 - accuracy: 0.5763 - val_loss: 1.0582 - val_accuracy: 0.4342\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.9859 - accuracy: 0.6102 - val_loss: 1.0583 - val_accuracy: 0.4079\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.9800 - accuracy: 0.5989 - val_loss: 1.0585 - val_accuracy: 0.4079\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.9733 - accuracy: 0.5932 - val_loss: 1.0606 - val_accuracy: 0.4079\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.9667 - accuracy: 0.5876 - val_loss: 1.0633 - val_accuracy: 0.4079\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.9595 - accuracy: 0.5932 - val_loss: 1.0667 - val_accuracy: 0.4079\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.9537 - accuracy: 0.5989 - val_loss: 1.0714 - val_accuracy: 0.3947\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.9471 - accuracy: 0.5932 - val_loss: 1.0724 - val_accuracy: 0.3947\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.9403 - accuracy: 0.5932 - val_loss: 1.0730 - val_accuracy: 0.3947\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.9342 - accuracy: 0.5989 - val_loss: 1.0716 - val_accuracy: 0.3947\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.9275 - accuracy: 0.5763 - val_loss: 1.0684 - val_accuracy: 0.3947\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.9224 - accuracy: 0.5932 - val_loss: 1.0660 - val_accuracy: 0.3947\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.9161 - accuracy: 0.5932 - val_loss: 1.0677 - val_accuracy: 0.3947\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.9104 - accuracy: 0.5932 - val_loss: 1.0717 - val_accuracy: 0.3947\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.9042 - accuracy: 0.5876 - val_loss: 1.0727 - val_accuracy: 0.3947\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.9003 - accuracy: 0.5989 - val_loss: 1.0708 - val_accuracy: 0.3947\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.8938 - accuracy: 0.5989 - val_loss: 1.0714 - val_accuracy: 0.3947\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.8900 - accuracy: 0.5989 - val_loss: 1.0769 - val_accuracy: 0.3947\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.8849 - accuracy: 0.5989 - val_loss: 1.0770 - val_accuracy: 0.3947\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.8791 - accuracy: 0.6045 - val_loss: 1.0768 - val_accuracy: 0.3947\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.8748 - accuracy: 0.6158 - val_loss: 1.0734 - val_accuracy: 0.4079\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.8739 - accuracy: 0.6102 - val_loss: 1.0720 - val_accuracy: 0.4079\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 91us/step - loss: 0.8685 - accuracy: 0.6102 - val_loss: 1.0755 - val_accuracy: 0.4079\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.8646 - accuracy: 0.6158 - val_loss: 1.0799 - val_accuracy: 0.4079\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.8596 - accuracy: 0.6158 - val_loss: 1.0821 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.8569 - accuracy: 0.6045 - val_loss: 1.0823 - val_accuracy: 0.4079\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.8521 - accuracy: 0.6158 - val_loss: 1.0804 - val_accuracy: 0.4079\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.8488 - accuracy: 0.6215 - val_loss: 1.0817 - val_accuracy: 0.4211\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.8462 - accuracy: 0.6158 - val_loss: 1.0858 - val_accuracy: 0.4079\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.8426 - accuracy: 0.6158 - val_loss: 1.0833 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.8376 - accuracy: 0.6215 - val_loss: 1.0846 - val_accuracy: 0.4079\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.8343 - accuracy: 0.6271 - val_loss: 1.0856 - val_accuracy: 0.4079\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.8312 - accuracy: 0.6271 - val_loss: 1.0877 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.8289 - accuracy: 0.6215 - val_loss: 1.0914 - val_accuracy: 0.4079\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.8251 - accuracy: 0.6271 - val_loss: 1.0949 - val_accuracy: 0.4079\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.8222 - accuracy: 0.6271 - val_loss: 1.0939 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8190 - accuracy: 0.6384 - val_loss: 1.0940 - val_accuracy: 0.4211\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.8159 - accuracy: 0.6328 - val_loss: 1.0930 - val_accuracy: 0.4211\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.8126 - accuracy: 0.6328 - val_loss: 1.0920 - val_accuracy: 0.4211\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.8094 - accuracy: 0.6328 - val_loss: 1.0922 - val_accuracy: 0.4211\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.8075 - accuracy: 0.6328 - val_loss: 1.0970 - val_accuracy: 0.4211\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.8041 - accuracy: 0.6328 - val_loss: 1.0956 - val_accuracy: 0.4211\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.8011 - accuracy: 0.6441 - val_loss: 1.0996 - val_accuracy: 0.4211\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.7984 - accuracy: 0.6384 - val_loss: 1.1004 - val_accuracy: 0.4211\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7947 - accuracy: 0.6441 - val_loss: 1.0988 - val_accuracy: 0.4211\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.7926 - accuracy: 0.6441 - val_loss: 1.0996 - val_accuracy: 0.4211\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 87us/step - loss: 0.7896 - accuracy: 0.6384 - val_loss: 1.1008 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7863 - accuracy: 0.6384 - val_loss: 1.1071 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 112us/step - loss: 0.7830 - accuracy: 0.6441 - val_loss: 1.1073 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.7810 - accuracy: 0.6441 - val_loss: 1.1091 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.7786 - accuracy: 0.6441 - val_loss: 1.1110 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7744 - accuracy: 0.6441 - val_loss: 1.1101 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.7726 - accuracy: 0.6441 - val_loss: 1.1074 - val_accuracy: 0.4211\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 70us/step - loss: 0.7710 - accuracy: 0.6497 - val_loss: 1.1114 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.7661 - accuracy: 0.6497 - val_loss: 1.1152 - val_accuracy: 0.4342\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.7644 - accuracy: 0.6441 - val_loss: 1.1190 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.7613 - accuracy: 0.6610 - val_loss: 1.1216 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.7596 - accuracy: 0.6497 - val_loss: 1.1198 - val_accuracy: 0.4342\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 57us/step - loss: 0.7552 - accuracy: 0.6554 - val_loss: 1.1252 - val_accuracy: 0.4342\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.7561 - accuracy: 0.6554 - val_loss: 1.1234 - val_accuracy: 0.4342\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.7502 - accuracy: 0.6667 - val_loss: 1.1262 - val_accuracy: 0.4342\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.7479 - accuracy: 0.6554 - val_loss: 1.1262 - val_accuracy: 0.4342\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 54us/step - loss: 0.7448 - accuracy: 0.6610 - val_loss: 1.1282 - val_accuracy: 0.4342\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.7431 - accuracy: 0.6667 - val_loss: 1.1289 - val_accuracy: 0.4342\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.7391 - accuracy: 0.6667 - val_loss: 1.1298 - val_accuracy: 0.4342\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.7394 - accuracy: 0.6723 - val_loss: 1.1343 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.7347 - accuracy: 0.6723 - val_loss: 1.1385 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.7308 - accuracy: 0.6780 - val_loss: 1.1402 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.7285 - accuracy: 0.6723 - val_loss: 1.1396 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.7263 - accuracy: 0.6723 - val_loss: 1.1411 - val_accuracy: 0.4342\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.7226 - accuracy: 0.6780 - val_loss: 1.1423 - val_accuracy: 0.4342\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.7214 - accuracy: 0.6780 - val_loss: 1.1465 - val_accuracy: 0.4211\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.7182 - accuracy: 0.7006 - val_loss: 1.1448 - val_accuracy: 0.4342\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.7156 - accuracy: 0.6949 - val_loss: 1.1481 - val_accuracy: 0.4342\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 104us/step - loss: 0.7121 - accuracy: 0.6893 - val_loss: 1.1513 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.7100 - accuracy: 0.6893 - val_loss: 1.1524 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.7070 - accuracy: 0.7006 - val_loss: 1.1492 - val_accuracy: 0.4079\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.7049 - accuracy: 0.7119 - val_loss: 1.1510 - val_accuracy: 0.4079\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.7020 - accuracy: 0.7175 - val_loss: 1.1561 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.6988 - accuracy: 0.7119 - val_loss: 1.1654 - val_accuracy: 0.4342\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.6990 - accuracy: 0.7119 - val_loss: 1.1730 - val_accuracy: 0.4342\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 98us/step - loss: 0.6959 - accuracy: 0.7119 - val_loss: 1.1646 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.6916 - accuracy: 0.7232 - val_loss: 1.1631 - val_accuracy: 0.3947\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 69us/step - loss: 0.6897 - accuracy: 0.7175 - val_loss: 1.1663 - val_accuracy: 0.3947\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.6876 - accuracy: 0.7288 - val_loss: 1.1705 - val_accuracy: 0.3947\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.6833 - accuracy: 0.7232 - val_loss: 1.1719 - val_accuracy: 0.3947\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.6813 - accuracy: 0.7288 - val_loss: 1.1751 - val_accuracy: 0.3947\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 97us/step - loss: 0.6787 - accuracy: 0.7288 - val_loss: 1.1783 - val_accuracy: 0.3947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a33637198>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 94us/step\n",
      "over-sampling test accuracy: 42.11%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel = model_sel.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 1,\n",
       "       1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2, 2, 1, 2, 1, 0, 1, 2, 2, 1, 2, 0,\n",
       "       2, 2, 2, 2, 0, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model_sel.predict_classes(X_sel_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SR4156</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BCH-SA-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NY417</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "251       SR4156     2     2\n",
       "17     BCH-SA-02     0     1\n",
       "158       NRS180     2     2\n",
       "232        NY417     1     2\n",
       "47   CFBREBSa110     2     2\n",
       "..           ...   ...   ...\n",
       "62   CFBREBSa131     2     0\n",
       "138       NRS112     2     1\n",
       "21     BCH-SA-06     0     1\n",
       "15          834N     2     2\n",
       "40           CA9     1     2\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model_sel.predict_proba(X_sel_test)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.273738</td>\n",
       "      <td>0.233240</td>\n",
       "      <td>0.493022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291361</td>\n",
       "      <td>0.594861</td>\n",
       "      <td>0.113779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048533</td>\n",
       "      <td>0.328458</td>\n",
       "      <td>0.623009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150530</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>0.641762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150530</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>0.641762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.479370</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>0.399271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.375478</td>\n",
       "      <td>0.541996</td>\n",
       "      <td>0.082526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.291361</td>\n",
       "      <td>0.594861</td>\n",
       "      <td>0.113779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.150530</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>0.641762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.107303</td>\n",
       "      <td>0.127619</td>\n",
       "      <td>0.765078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.273738  0.233240  0.493022\n",
       "1   0.291361  0.594861  0.113779\n",
       "2   0.048533  0.328458  0.623009\n",
       "3   0.150530  0.207708  0.641762\n",
       "4   0.150530  0.207708  0.641762\n",
       "..       ...       ...       ...\n",
       "71  0.479370  0.121359  0.399271\n",
       "72  0.375478  0.541996  0.082526\n",
       "73  0.291361  0.594861  0.113779\n",
       "74  0.150530  0.207708  0.641762\n",
       "75  0.107303  0.127619  0.765078\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.6450 - accuracy: 0.7514 - val_loss: 1.1442 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.6413 - accuracy: 0.7401 - val_loss: 1.1510 - val_accuracy: 0.4211\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.6402 - accuracy: 0.7232 - val_loss: 1.1596 - val_accuracy: 0.4079\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 128us/step - loss: 0.6385 - accuracy: 0.7458 - val_loss: 1.1550 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.6370 - accuracy: 0.7514 - val_loss: 1.1469 - val_accuracy: 0.4342\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.6340 - accuracy: 0.7514 - val_loss: 1.1478 - val_accuracy: 0.4342\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 102us/step - loss: 0.6347 - accuracy: 0.7458 - val_loss: 1.1614 - val_accuracy: 0.3947\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.6292 - accuracy: 0.7458 - val_loss: 1.1594 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.6264 - accuracy: 0.7458 - val_loss: 1.1613 - val_accuracy: 0.4211\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.6256 - accuracy: 0.7514 - val_loss: 1.1624 - val_accuracy: 0.4211\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 71us/step - loss: 0.6249 - accuracy: 0.7458 - val_loss: 1.1746 - val_accuracy: 0.4079\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.6204 - accuracy: 0.7514 - val_loss: 1.1627 - val_accuracy: 0.4211\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.6169 - accuracy: 0.7514 - val_loss: 1.1597 - val_accuracy: 0.4342\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.6153 - accuracy: 0.7514 - val_loss: 1.1638 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.6180 - accuracy: 0.7345 - val_loss: 1.1815 - val_accuracy: 0.4342\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.6101 - accuracy: 0.7401 - val_loss: 1.1650 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.6111 - accuracy: 0.7684 - val_loss: 1.1559 - val_accuracy: 0.4342\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.6082 - accuracy: 0.7627 - val_loss: 1.1682 - val_accuracy: 0.4342\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 111us/step - loss: 0.6036 - accuracy: 0.7458 - val_loss: 1.1761 - val_accuracy: 0.4342\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.6015 - accuracy: 0.7627 - val_loss: 1.1696 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 107us/step - loss: 0.5996 - accuracy: 0.7627 - val_loss: 1.1722 - val_accuracy: 0.4737\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.5977 - accuracy: 0.7684 - val_loss: 1.1750 - val_accuracy: 0.4474\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 110us/step - loss: 0.5970 - accuracy: 0.7684 - val_loss: 1.1806 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.5925 - accuracy: 0.7740 - val_loss: 1.1871 - val_accuracy: 0.4342\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5968 - accuracy: 0.7514 - val_loss: 1.1982 - val_accuracy: 0.4211\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.5902 - accuracy: 0.7627 - val_loss: 1.1822 - val_accuracy: 0.4605\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.5877 - accuracy: 0.7740 - val_loss: 1.1756 - val_accuracy: 0.4474\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 106us/step - loss: 0.5874 - accuracy: 0.7684 - val_loss: 1.1828 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5830 - accuracy: 0.7740 - val_loss: 1.2010 - val_accuracy: 0.4211\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.5836 - accuracy: 0.7684 - val_loss: 1.2116 - val_accuracy: 0.4211\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.5812 - accuracy: 0.7684 - val_loss: 1.1954 - val_accuracy: 0.4474\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 67us/step - loss: 0.5795 - accuracy: 0.7684 - val_loss: 1.1925 - val_accuracy: 0.4605\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5794 - accuracy: 0.7797 - val_loss: 1.1879 - val_accuracy: 0.4474\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 92us/step - loss: 0.5737 - accuracy: 0.7684 - val_loss: 1.2041 - val_accuracy: 0.4211\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.5739 - accuracy: 0.7627 - val_loss: 1.2145 - val_accuracy: 0.4211\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5723 - accuracy: 0.7627 - val_loss: 1.2097 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 68us/step - loss: 0.5671 - accuracy: 0.7684 - val_loss: 1.1988 - val_accuracy: 0.4474\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5697 - accuracy: 0.7740 - val_loss: 1.1956 - val_accuracy: 0.4342\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.5662 - accuracy: 0.7627 - val_loss: 1.2142 - val_accuracy: 0.4211\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5640 - accuracy: 0.7740 - val_loss: 1.2231 - val_accuracy: 0.4211\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5622 - accuracy: 0.7740 - val_loss: 1.2165 - val_accuracy: 0.4211\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.5578 - accuracy: 0.7684 - val_loss: 1.2187 - val_accuracy: 0.4737\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 95us/step - loss: 0.5568 - accuracy: 0.7740 - val_loss: 1.2203 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 94us/step - loss: 0.5565 - accuracy: 0.7740 - val_loss: 1.2219 - val_accuracy: 0.4474\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 83us/step - loss: 0.5557 - accuracy: 0.7740 - val_loss: 1.2323 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.5531 - accuracy: 0.7797 - val_loss: 1.2231 - val_accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.5551 - accuracy: 0.7797 - val_loss: 1.2338 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 150us/step - loss: 0.5473 - accuracy: 0.7797 - val_loss: 1.2262 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 105us/step - loss: 0.5458 - accuracy: 0.7797 - val_loss: 1.2280 - val_accuracy: 0.4474\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.5450 - accuracy: 0.7853 - val_loss: 1.2288 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 77us/step - loss: 0.5448 - accuracy: 0.7797 - val_loss: 1.2401 - val_accuracy: 0.4342\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 61us/step - loss: 0.5407 - accuracy: 0.7797 - val_loss: 1.2433 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.5393 - accuracy: 0.7853 - val_loss: 1.2408 - val_accuracy: 0.4342\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 60us/step - loss: 0.5378 - accuracy: 0.7853 - val_loss: 1.2490 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 74us/step - loss: 0.5356 - accuracy: 0.7853 - val_loss: 1.2471 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 96us/step - loss: 0.5341 - accuracy: 0.7910 - val_loss: 1.2483 - val_accuracy: 0.4342\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.5318 - accuracy: 0.7910 - val_loss: 1.2538 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 108us/step - loss: 0.5326 - accuracy: 0.7740 - val_loss: 1.2543 - val_accuracy: 0.4342\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 113us/step - loss: 0.5306 - accuracy: 0.7853 - val_loss: 1.2443 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.5283 - accuracy: 0.7910 - val_loss: 1.2475 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5269 - accuracy: 0.7910 - val_loss: 1.2576 - val_accuracy: 0.4474\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5270 - accuracy: 0.7910 - val_loss: 1.2591 - val_accuracy: 0.4474\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.5266 - accuracy: 0.7853 - val_loss: 1.2651 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 73us/step - loss: 0.5244 - accuracy: 0.7910 - val_loss: 1.2574 - val_accuracy: 0.4474\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 64us/step - loss: 0.5221 - accuracy: 0.7910 - val_loss: 1.2691 - val_accuracy: 0.4474\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 72us/step - loss: 0.5237 - accuracy: 0.7684 - val_loss: 1.2797 - val_accuracy: 0.4474\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.5186 - accuracy: 0.7910 - val_loss: 1.2649 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 78us/step - loss: 0.5224 - accuracy: 0.7910 - val_loss: 1.2671 - val_accuracy: 0.4474\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 65us/step - loss: 0.5191 - accuracy: 0.7910 - val_loss: 1.2862 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 85us/step - loss: 0.5171 - accuracy: 0.7966 - val_loss: 1.2835 - val_accuracy: 0.4474\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 103us/step - loss: 0.5124 - accuracy: 0.7966 - val_loss: 1.2747 - val_accuracy: 0.4474\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 99us/step - loss: 0.5126 - accuracy: 0.7910 - val_loss: 1.2754 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 75us/step - loss: 0.5135 - accuracy: 0.7910 - val_loss: 1.2853 - val_accuracy: 0.4474\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 80us/step - loss: 0.5086 - accuracy: 0.7910 - val_loss: 1.3031 - val_accuracy: 0.4211\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.5108 - accuracy: 0.7910 - val_loss: 1.2994 - val_accuracy: 0.4211\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 89us/step - loss: 0.5068 - accuracy: 0.7966 - val_loss: 1.2814 - val_accuracy: 0.4474\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 82us/step - loss: 0.5045 - accuracy: 0.7853 - val_loss: 1.2790 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 90us/step - loss: 0.5043 - accuracy: 0.7966 - val_loss: 1.2942 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.5034 - accuracy: 0.7910 - val_loss: 1.3048 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.5037 - accuracy: 0.7910 - val_loss: 1.2937 - val_accuracy: 0.4474\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 132us/step - loss: 0.4984 - accuracy: 0.8023 - val_loss: 1.2902 - val_accuracy: 0.4474\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 118us/step - loss: 0.5019 - accuracy: 0.7966 - val_loss: 1.2969 - val_accuracy: 0.4474\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 109us/step - loss: 0.4959 - accuracy: 0.8023 - val_loss: 1.3134 - val_accuracy: 0.4342\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 66us/step - loss: 0.4977 - accuracy: 0.7853 - val_loss: 1.3167 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 93us/step - loss: 0.4989 - accuracy: 0.8023 - val_loss: 1.3016 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 81us/step - loss: 0.4976 - accuracy: 0.8079 - val_loss: 1.3158 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 76us/step - loss: 0.4914 - accuracy: 0.8079 - val_loss: 1.3137 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.4917 - accuracy: 0.8023 - val_loss: 1.3192 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 84us/step - loss: 0.4932 - accuracy: 0.7797 - val_loss: 1.3265 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 86us/step - loss: 0.4877 - accuracy: 0.7966 - val_loss: 1.3119 - val_accuracy: 0.4605\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 88us/step - loss: 0.4910 - accuracy: 0.8023 - val_loss: 1.3139 - val_accuracy: 0.4605\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.4850 - accuracy: 0.8023 - val_loss: 1.3235 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.4856 - accuracy: 0.8023 - val_loss: 1.3362 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.4907 - accuracy: 0.7910 - val_loss: 1.3413 - val_accuracy: 0.4211\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.4818 - accuracy: 0.8023 - val_loss: 1.3185 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 130us/step - loss: 0.4873 - accuracy: 0.8023 - val_loss: 1.3193 - val_accuracy: 0.4605\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.4821 - accuracy: 0.8023 - val_loss: 1.3365 - val_accuracy: 0.4342\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 131us/step - loss: 0.4833 - accuracy: 0.8079 - val_loss: 1.3425 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 138us/step - loss: 0.4819 - accuracy: 0.8023 - val_loss: 1.3587 - val_accuracy: 0.4211\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 117us/step - loss: 0.4771 - accuracy: 0.8023 - val_loss: 1.3393 - val_accuracy: 0.4605\n"
     ]
    }
   ],
   "source": [
    "hist_sel = model_sel.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=64, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 77.75%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848032e-03</td>\n",
       "      <td>0.996096</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.441349e-01</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.155850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>120337</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.466081e-02</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.979626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.985392e-01</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.665667e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.617341e-03</td>\n",
       "      <td>0.565843</td>\n",
       "      <td>0.427540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.055758e-03</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.747076e-01</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.054130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>834N</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.593112e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.838999e-01</td>\n",
       "      <td>0.142659</td>\n",
       "      <td>0.473441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual        NY360          2           1  3.848032e-03   \n",
       "1       p0017kpresabs_qual       NRS113          0           0  8.441349e-01   \n",
       "2       p0017kpresabs_qual       120337          2           2  1.466081e-02   \n",
       "3       p0017kpresabs_qual  CFBREBSa127          1           0  9.985392e-01   \n",
       "4       p0017kpresabs_qual         GA27          2           2  1.665667e-08   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa131          2           1  6.617341e-03   \n",
       "604  p0040presabsSTCC_qual       NRS112          2           2  1.055758e-03   \n",
       "605  p0040presabsSTCC_qual    BCH-SA-06          0           0  8.747076e-01   \n",
       "606  p0040presabsSTCC_qual         834N          2           2  2.593112e-06   \n",
       "607  p0040presabsSTCC_qual          CA9          1           2  3.838999e-01   \n",
       "\n",
       "            1         2  \n",
       "0    0.996096  0.000056  \n",
       "1    0.000015  0.155850  \n",
       "2    0.005713  0.979626  \n",
       "3    0.000350  0.001111  \n",
       "4    0.000005  0.999995  \n",
       "..        ...       ...  \n",
       "603  0.565843  0.427540  \n",
       "604  0.045611  0.953333  \n",
       "605  0.071162  0.054130  \n",
       "606  0.000013  0.999985  \n",
       "607  0.142659  0.473441  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27373773, 0.23323973, 0.49302247],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.04853262, 0.3284582 , 0.6230092 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.0366947 , 0.21462493, 0.74868035],\n",
       "       [0.1073032 , 0.12761863, 0.7650782 ],\n",
       "       [0.00427501, 0.1338416 , 0.8618834 ],\n",
       "       [0.39074245, 0.5191766 , 0.09008092],\n",
       "       [0.0222603 , 0.20988078, 0.76785886],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.10275727, 0.7645176 , 0.13272516],\n",
       "       [0.32594627, 0.50115514, 0.17289868],\n",
       "       [0.01726191, 0.42798263, 0.5547555 ],\n",
       "       [0.14649852, 0.23868795, 0.6148135 ],\n",
       "       [0.6088695 , 0.13168919, 0.2594413 ],\n",
       "       [0.8687113 , 0.06762633, 0.06366237],\n",
       "       [0.08201418, 0.18083654, 0.7371493 ],\n",
       "       [0.1073032 , 0.12761863, 0.7650782 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.05884498, 0.511712  , 0.42944297],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.50374913, 0.17650147, 0.31974944],\n",
       "       [0.05723878, 0.59907955, 0.34368166],\n",
       "       [0.35902092, 0.41858545, 0.22239366],\n",
       "       [0.19199753, 0.48137626, 0.32662618],\n",
       "       [0.79894173, 0.16712436, 0.03393391],\n",
       "       [0.05960882, 0.4236073 , 0.5167839 ],\n",
       "       [0.27809593, 0.5309002 , 0.19100392],\n",
       "       [0.79894173, 0.16712436, 0.03393391],\n",
       "       [0.02750393, 0.35825244, 0.6142436 ],\n",
       "       [0.3753174 , 0.2527311 , 0.3719515 ],\n",
       "       [0.26410672, 0.5109811 , 0.2249122 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.6988328 , 0.24288616, 0.05828108],\n",
       "       [0.04716422, 0.29392406, 0.65891176],\n",
       "       [0.03035956, 0.13360932, 0.8360311 ],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.07390735, 0.82224786, 0.10384479],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.08044662, 0.8412266 , 0.07832675],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.17344409, 0.58521783, 0.24133812],\n",
       "       [0.1073032 , 0.12761863, 0.7650782 ],\n",
       "       [0.0232618 , 0.36183527, 0.6149029 ],\n",
       "       [0.17822027, 0.20693897, 0.61484075],\n",
       "       [0.07608676, 0.19536938, 0.7285439 ],\n",
       "       [0.04716422, 0.29392406, 0.65891176],\n",
       "       [0.02785681, 0.518601  , 0.45354208],\n",
       "       [0.32959372, 0.6140009 , 0.05640531],\n",
       "       [0.1073032 , 0.12761863, 0.7650782 ],\n",
       "       [0.5274484 , 0.39463285, 0.07791872],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.07635652, 0.29595542, 0.62768805],\n",
       "       [0.07366101, 0.3208538 , 0.60548514],\n",
       "       [0.02700692, 0.48817763, 0.4848155 ],\n",
       "       [0.02078684, 0.14334065, 0.83587253],\n",
       "       [0.24518953, 0.52274966, 0.23206085],\n",
       "       [0.4793698 , 0.12135945, 0.3992708 ],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.2855853 , 0.30506542, 0.40934923],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.13951053, 0.4154487 , 0.44504082],\n",
       "       [0.50374913, 0.17650147, 0.31974944],\n",
       "       [0.04716422, 0.29392406, 0.65891176],\n",
       "       [0.07635652, 0.29595542, 0.62768805],\n",
       "       [0.22871947, 0.23290671, 0.5383738 ],\n",
       "       [0.08766796, 0.33437338, 0.5779587 ],\n",
       "       [0.4021972 , 0.31168774, 0.28611502],\n",
       "       [0.4793698 , 0.12135945, 0.3992708 ],\n",
       "       [0.3754778 , 0.5419964 , 0.08252577],\n",
       "       [0.29136065, 0.5948606 , 0.11377878],\n",
       "       [0.15052983, 0.20770812, 0.6417621 ],\n",
       "       [0.1073032 , 0.12761863, 0.7650782 ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5858067082628343"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5858067082628343"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_sel_test, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat6['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NRS262</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     strain  test\n",
       "152  NRS169     1\n",
       "210  NRS249     2\n",
       "218  NRS262     2\n",
       "238  SR1746     1\n",
       "113  NRS029     1\n",
       "..      ...   ...\n",
       "96     GA27     2\n",
       "95    GA231     2\n",
       "237  SR1287     0\n",
       "14      506     2\n",
       "107  NRS001     1\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 1.2035 - accuracy: 0.3390 - val_loss: 1.0867 - val_accuracy: 0.3947\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 1.1020 - accuracy: 0.4124 - val_loss: 1.0968 - val_accuracy: 0.3816\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 1.0902 - accuracy: 0.4068 - val_loss: 1.1113 - val_accuracy: 0.3421\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 1.0815 - accuracy: 0.4011 - val_loss: 1.0901 - val_accuracy: 0.3289\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 1.0613 - accuracy: 0.4181 - val_loss: 1.0576 - val_accuracy: 0.4079\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 1.0554 - accuracy: 0.3503 - val_loss: 1.0485 - val_accuracy: 0.3947\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 1.0400 - accuracy: 0.4463 - val_loss: 1.0297 - val_accuracy: 0.4737\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 267us/step - loss: 1.0342 - accuracy: 0.4350 - val_loss: 1.0266 - val_accuracy: 0.4605\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 298us/step - loss: 1.0199 - accuracy: 0.4802 - val_loss: 1.0272 - val_accuracy: 0.4474\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 1.0171 - accuracy: 0.4689 - val_loss: 1.0131 - val_accuracy: 0.4474\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 278us/step - loss: 1.0043 - accuracy: 0.4915 - val_loss: 1.0128 - val_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.9982 - accuracy: 0.5141 - val_loss: 1.0141 - val_accuracy: 0.4474\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.9957 - accuracy: 0.5254 - val_loss: 1.0104 - val_accuracy: 0.4868\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.9875 - accuracy: 0.5198 - val_loss: 1.0202 - val_accuracy: 0.4342\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.9765 - accuracy: 0.5424 - val_loss: 1.0037 - val_accuracy: 0.4737\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.9822 - accuracy: 0.5198 - val_loss: 1.0042 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.9757 - accuracy: 0.5254 - val_loss: 0.9971 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.9730 - accuracy: 0.5141 - val_loss: 1.0152 - val_accuracy: 0.4737\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.9668 - accuracy: 0.5198 - val_loss: 1.0066 - val_accuracy: 0.4737\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.9530 - accuracy: 0.5650 - val_loss: 0.9914 - val_accuracy: 0.5132\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.9502 - accuracy: 0.5424 - val_loss: 0.9933 - val_accuracy: 0.5132\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.9403 - accuracy: 0.5650 - val_loss: 1.0158 - val_accuracy: 0.4605\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.9434 - accuracy: 0.5480 - val_loss: 1.0127 - val_accuracy: 0.4605\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.9417 - accuracy: 0.5650 - val_loss: 0.9933 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 275us/step - loss: 0.9396 - accuracy: 0.5367 - val_loss: 0.9911 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.9257 - accuracy: 0.5650 - val_loss: 1.0032 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.9321 - accuracy: 0.5480 - val_loss: 0.9977 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.9205 - accuracy: 0.5480 - val_loss: 0.9945 - val_accuracy: 0.5132\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.9152 - accuracy: 0.5593 - val_loss: 1.0051 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.9214 - accuracy: 0.6045 - val_loss: 1.0273 - val_accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.9094 - accuracy: 0.5932 - val_loss: 0.9988 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.9046 - accuracy: 0.5650 - val_loss: 0.9872 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 532us/step - loss: 0.8940 - accuracy: 0.5876 - val_loss: 0.9889 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 502us/step - loss: 0.8902 - accuracy: 0.5876 - val_loss: 1.0031 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 415us/step - loss: 0.8943 - accuracy: 0.5932 - val_loss: 1.0029 - val_accuracy: 0.5132\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.8864 - accuracy: 0.6215 - val_loss: 1.0194 - val_accuracy: 0.4868\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.8883 - accuracy: 0.6102 - val_loss: 1.0150 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.8746 - accuracy: 0.6102 - val_loss: 0.9900 - val_accuracy: 0.4868\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.8834 - accuracy: 0.6045 - val_loss: 0.9924 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.8745 - accuracy: 0.5989 - val_loss: 1.0024 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.8738 - accuracy: 0.6102 - val_loss: 1.0221 - val_accuracy: 0.4737\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.8653 - accuracy: 0.6045 - val_loss: 0.9971 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.8650 - accuracy: 0.5989 - val_loss: 1.0012 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 213us/step - loss: 0.8674 - accuracy: 0.5989 - val_loss: 1.0200 - val_accuracy: 0.4737\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 354us/step - loss: 0.8571 - accuracy: 0.6158 - val_loss: 1.0063 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.8546 - accuracy: 0.6158 - val_loss: 1.0103 - val_accuracy: 0.4868\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.8688 - accuracy: 0.6045 - val_loss: 1.0409 - val_accuracy: 0.4605\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.8597 - accuracy: 0.5932 - val_loss: 1.0202 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.8576 - accuracy: 0.6102 - val_loss: 1.0221 - val_accuracy: 0.4474\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.8471 - accuracy: 0.6158 - val_loss: 1.0259 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.8455 - accuracy: 0.6102 - val_loss: 1.0161 - val_accuracy: 0.4868\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.8403 - accuracy: 0.5932 - val_loss: 1.0258 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.8388 - accuracy: 0.6215 - val_loss: 1.0435 - val_accuracy: 0.4605\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.8379 - accuracy: 0.6102 - val_loss: 1.0162 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.8391 - accuracy: 0.6045 - val_loss: 1.0189 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.8372 - accuracy: 0.6102 - val_loss: 1.0257 - val_accuracy: 0.4605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.8374 - accuracy: 0.5989 - val_loss: 1.0497 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 340us/step - loss: 0.8277 - accuracy: 0.6271 - val_loss: 1.0341 - val_accuracy: 0.4868\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.8308 - accuracy: 0.6271 - val_loss: 1.0495 - val_accuracy: 0.4868\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.8253 - accuracy: 0.6328 - val_loss: 1.0519 - val_accuracy: 0.4868\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 408us/step - loss: 0.8198 - accuracy: 0.6271 - val_loss: 1.0375 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 326us/step - loss: 0.8217 - accuracy: 0.6102 - val_loss: 1.0331 - val_accuracy: 0.4868\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.8172 - accuracy: 0.6271 - val_loss: 1.0434 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.8117 - accuracy: 0.6271 - val_loss: 1.0442 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.8106 - accuracy: 0.6384 - val_loss: 1.0443 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 341us/step - loss: 0.8077 - accuracy: 0.6554 - val_loss: 1.0405 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 344us/step - loss: 0.8051 - accuracy: 0.6102 - val_loss: 1.0347 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.8075 - accuracy: 0.6158 - val_loss: 1.0460 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.8119 - accuracy: 0.6384 - val_loss: 1.0660 - val_accuracy: 0.4342\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.8133 - accuracy: 0.6271 - val_loss: 1.0504 - val_accuracy: 0.4474\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.8005 - accuracy: 0.6102 - val_loss: 1.0585 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 525us/step - loss: 0.8064 - accuracy: 0.6158 - val_loss: 1.0614 - val_accuracy: 0.4605\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.7937 - accuracy: 0.6497 - val_loss: 1.0649 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.8135 - accuracy: 0.6384 - val_loss: 1.0548 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.7933 - accuracy: 0.6554 - val_loss: 1.0534 - val_accuracy: 0.4868\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 165us/step - loss: 0.7909 - accuracy: 0.6328 - val_loss: 1.0544 - val_accuracy: 0.4737\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.7985 - accuracy: 0.6497 - val_loss: 1.0705 - val_accuracy: 0.4868\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7903 - accuracy: 0.6497 - val_loss: 1.0581 - val_accuracy: 0.4868\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7898 - accuracy: 0.6554 - val_loss: 1.0728 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7843 - accuracy: 0.6723 - val_loss: 1.0538 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.7795 - accuracy: 0.6723 - val_loss: 1.0516 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.7733 - accuracy: 0.6497 - val_loss: 1.0607 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.7717 - accuracy: 0.6610 - val_loss: 1.0671 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7727 - accuracy: 0.6780 - val_loss: 1.0533 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.7752 - accuracy: 0.6610 - val_loss: 1.0395 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7740 - accuracy: 0.6554 - val_loss: 1.0471 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.7650 - accuracy: 0.6610 - val_loss: 1.0672 - val_accuracy: 0.4868\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.7672 - accuracy: 0.6667 - val_loss: 1.0613 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.7629 - accuracy: 0.6780 - val_loss: 1.0588 - val_accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.7620 - accuracy: 0.6497 - val_loss: 1.0598 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.7575 - accuracy: 0.6780 - val_loss: 1.0582 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.7652 - accuracy: 0.6554 - val_loss: 1.0569 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 270us/step - loss: 0.7582 - accuracy: 0.6610 - val_loss: 1.0665 - val_accuracy: 0.4342\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.7605 - accuracy: 0.6610 - val_loss: 1.0633 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.7492 - accuracy: 0.6893 - val_loss: 1.0684 - val_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 134us/step - loss: 0.7639 - accuracy: 0.6723 - val_loss: 1.0553 - val_accuracy: 0.4868\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.7503 - accuracy: 0.6610 - val_loss: 1.0682 - val_accuracy: 0.4868\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 119us/step - loss: 0.7781 - accuracy: 0.6441 - val_loss: 1.1243 - val_accuracy: 0.3947\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 133us/step - loss: 0.7603 - accuracy: 0.6667 - val_loss: 1.0927 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.7468 - accuracy: 0.6949 - val_loss: 1.0841 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1036a3208>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 151us/step\n",
      "test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel2 = model_sel2.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 2,\n",
       "       0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 2, 1, 0, 1, 0, 2, 0, 0,\n",
       "       1, 2, 0, 2, 0, 1, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model_sel2.predict_classes(X_sel_test)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NRS169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NRS262</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NRS029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     strain  test  pred\n",
       "152  NRS169     1     1\n",
       "210  NRS249     2     2\n",
       "218  NRS262     2     1\n",
       "238  SR1746     1     1\n",
       "113  NRS029     1     1\n",
       "..      ...   ...   ...\n",
       "96     GA27     2     1\n",
       "95    GA231     2     2\n",
       "237  SR1287     0     0\n",
       "14      506     2     0\n",
       "107  NRS001     1     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model_sel2.predict_proba(X_sel_test)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051419</td>\n",
       "      <td>0.583905</td>\n",
       "      <td>0.364676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101089</td>\n",
       "      <td>0.312194</td>\n",
       "      <td>0.586718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.315176</td>\n",
       "      <td>0.446782</td>\n",
       "      <td>0.238041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323659</td>\n",
       "      <td>0.433297</td>\n",
       "      <td>0.243044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352156</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.057219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.248237</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.309390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.267271</td>\n",
       "      <td>0.173350</td>\n",
       "      <td>0.559380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.215303</td>\n",
       "      <td>0.238479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.453734</td>\n",
       "      <td>0.252130</td>\n",
       "      <td>0.294135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.570512</td>\n",
       "      <td>0.346064</td>\n",
       "      <td>0.083424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.051419  0.583905  0.364676\n",
       "1   0.101089  0.312194  0.586718\n",
       "2   0.315176  0.446782  0.238041\n",
       "3   0.323659  0.433297  0.243044\n",
       "4   0.352156  0.590625  0.057219\n",
       "..       ...       ...       ...\n",
       "71  0.248237  0.442374  0.309390\n",
       "72  0.267271  0.173350  0.559380\n",
       "73  0.546218  0.215303  0.238479\n",
       "74  0.453734  0.252130  0.294135\n",
       "75  0.570512  0.346064  0.083424\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.7525 - accuracy: 0.7006 - val_loss: 1.0553 - val_accuracy: 0.4605\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 268us/step - loss: 0.7366 - accuracy: 0.7006 - val_loss: 1.0478 - val_accuracy: 0.4605\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.7420 - accuracy: 0.6893 - val_loss: 1.0510 - val_accuracy: 0.4342\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7314 - accuracy: 0.6949 - val_loss: 1.0562 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.7337 - accuracy: 0.6836 - val_loss: 1.0586 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.7294 - accuracy: 0.6949 - val_loss: 1.0608 - val_accuracy: 0.4605\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.7331 - accuracy: 0.6836 - val_loss: 1.0606 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.7278 - accuracy: 0.6893 - val_loss: 1.0461 - val_accuracy: 0.4737\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7244 - accuracy: 0.7006 - val_loss: 1.0466 - val_accuracy: 0.4868\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.7200 - accuracy: 0.7062 - val_loss: 1.0519 - val_accuracy: 0.4737\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.7232 - accuracy: 0.6836 - val_loss: 1.0544 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7180 - accuracy: 0.6949 - val_loss: 1.0558 - val_accuracy: 0.4868\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.7111 - accuracy: 0.6893 - val_loss: 1.0635 - val_accuracy: 0.4605\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7105 - accuracy: 0.6949 - val_loss: 1.0594 - val_accuracy: 0.4868\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.7147 - accuracy: 0.6836 - val_loss: 1.0515 - val_accuracy: 0.4868\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7118 - accuracy: 0.6949 - val_loss: 1.0442 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.7127 - accuracy: 0.7006 - val_loss: 1.0498 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.7069 - accuracy: 0.7062 - val_loss: 1.0518 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.7148 - accuracy: 0.6949 - val_loss: 1.0753 - val_accuracy: 0.4737\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 190us/step - loss: 0.7227 - accuracy: 0.6949 - val_loss: 1.0766 - val_accuracy: 0.4605\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.7399 - accuracy: 0.6893 - val_loss: 1.0720 - val_accuracy: 0.4737\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.7134 - accuracy: 0.7175 - val_loss: 1.0501 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7056 - accuracy: 0.7175 - val_loss: 1.0590 - val_accuracy: 0.4474\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7078 - accuracy: 0.7232 - val_loss: 1.0587 - val_accuracy: 0.4868\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7035 - accuracy: 0.7232 - val_loss: 1.0609 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.7030 - accuracy: 0.7119 - val_loss: 1.0685 - val_accuracy: 0.4737\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.7050 - accuracy: 0.7119 - val_loss: 1.0536 - val_accuracy: 0.4868\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.7093 - accuracy: 0.6893 - val_loss: 1.0557 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.6967 - accuracy: 0.7119 - val_loss: 1.0610 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6960 - accuracy: 0.7175 - val_loss: 1.0712 - val_accuracy: 0.4605\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.6945 - accuracy: 0.7119 - val_loss: 1.0799 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.6858 - accuracy: 0.7288 - val_loss: 1.0765 - val_accuracy: 0.4605\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6893 - accuracy: 0.7006 - val_loss: 1.0703 - val_accuracy: 0.4737\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6860 - accuracy: 0.7401 - val_loss: 1.0748 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.6943 - accuracy: 0.7345 - val_loss: 1.0973 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.6955 - accuracy: 0.7288 - val_loss: 1.0879 - val_accuracy: 0.4737\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6864 - accuracy: 0.7288 - val_loss: 1.0879 - val_accuracy: 0.4474\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6813 - accuracy: 0.7401 - val_loss: 1.0851 - val_accuracy: 0.4737\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.6763 - accuracy: 0.7401 - val_loss: 1.0796 - val_accuracy: 0.4474\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.6802 - accuracy: 0.7119 - val_loss: 1.0854 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.6819 - accuracy: 0.7006 - val_loss: 1.0759 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 614us/step - loss: 0.6742 - accuracy: 0.7232 - val_loss: 1.0771 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 382us/step - loss: 0.6727 - accuracy: 0.7345 - val_loss: 1.0881 - val_accuracy: 0.4737\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.6744 - accuracy: 0.7288 - val_loss: 1.0931 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.6768 - accuracy: 0.7345 - val_loss: 1.0905 - val_accuracy: 0.4737\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 300us/step - loss: 0.6711 - accuracy: 0.7345 - val_loss: 1.0947 - val_accuracy: 0.4737\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 215us/step - loss: 0.6689 - accuracy: 0.7232 - val_loss: 1.0963 - val_accuracy: 0.4605\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.6691 - accuracy: 0.7345 - val_loss: 1.0939 - val_accuracy: 0.4605\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.6675 - accuracy: 0.7232 - val_loss: 1.0956 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.6709 - accuracy: 0.7401 - val_loss: 1.1095 - val_accuracy: 0.4737\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.6663 - accuracy: 0.7401 - val_loss: 1.1078 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.6698 - accuracy: 0.7288 - val_loss: 1.1145 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 816us/step - loss: 0.6677 - accuracy: 0.7345 - val_loss: 1.1004 - val_accuracy: 0.4737\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.6579 - accuracy: 0.7401 - val_loss: 1.0969 - val_accuracy: 0.4737\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.6567 - accuracy: 0.7514 - val_loss: 1.1008 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 257us/step - loss: 0.6545 - accuracy: 0.7571 - val_loss: 1.1026 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 303us/step - loss: 0.6763 - accuracy: 0.7232 - val_loss: 1.1217 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 336us/step - loss: 0.6722 - accuracy: 0.7232 - val_loss: 1.1168 - val_accuracy: 0.4605\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.6616 - accuracy: 0.7345 - val_loss: 1.1098 - val_accuracy: 0.4737\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.6602 - accuracy: 0.7458 - val_loss: 1.1103 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6515 - accuracy: 0.7401 - val_loss: 1.1021 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.6597 - accuracy: 0.7119 - val_loss: 1.0984 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.6561 - accuracy: 0.7232 - val_loss: 1.0924 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 796us/step - loss: 0.6472 - accuracy: 0.7401 - val_loss: 1.1006 - val_accuracy: 0.4737\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.6471 - accuracy: 0.7458 - val_loss: 1.1160 - val_accuracy: 0.4737\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.6506 - accuracy: 0.7401 - val_loss: 1.1087 - val_accuracy: 0.4737\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 323us/step - loss: 0.6421 - accuracy: 0.7345 - val_loss: 1.1082 - val_accuracy: 0.4737\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 515us/step - loss: 0.6385 - accuracy: 0.7458 - val_loss: 1.1131 - val_accuracy: 0.4737\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.6464 - accuracy: 0.7288 - val_loss: 1.1084 - val_accuracy: 0.5132\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.6534 - accuracy: 0.7232 - val_loss: 1.1242 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6475 - accuracy: 0.7458 - val_loss: 1.0985 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6398 - accuracy: 0.7514 - val_loss: 1.0999 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 199us/step - loss: 0.6444 - accuracy: 0.7627 - val_loss: 1.1036 - val_accuracy: 0.4868\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.6598 - accuracy: 0.7345 - val_loss: 1.1022 - val_accuracy: 0.4474\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6418 - accuracy: 0.7401 - val_loss: 1.1037 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6336 - accuracy: 0.7684 - val_loss: 1.1203 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.6368 - accuracy: 0.7571 - val_loss: 1.1222 - val_accuracy: 0.4737\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6398 - accuracy: 0.7458 - val_loss: 1.1185 - val_accuracy: 0.4474\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6365 - accuracy: 0.7458 - val_loss: 1.1165 - val_accuracy: 0.4474\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.6334 - accuracy: 0.7514 - val_loss: 1.1164 - val_accuracy: 0.4605\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.6294 - accuracy: 0.7514 - val_loss: 1.1130 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.6294 - accuracy: 0.7514 - val_loss: 1.1115 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 312us/step - loss: 0.6237 - accuracy: 0.7571 - val_loss: 1.1124 - val_accuracy: 0.4868\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 498us/step - loss: 0.6223 - accuracy: 0.7401 - val_loss: 1.1192 - val_accuracy: 0.4605\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.6229 - accuracy: 0.7514 - val_loss: 1.1197 - val_accuracy: 0.4605\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 710us/step - loss: 0.6218 - accuracy: 0.7458 - val_loss: 1.1168 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 636us/step - loss: 0.6279 - accuracy: 0.7514 - val_loss: 1.1164 - val_accuracy: 0.4737\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 418us/step - loss: 0.6229 - accuracy: 0.7514 - val_loss: 1.1173 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 337us/step - loss: 0.6250 - accuracy: 0.7514 - val_loss: 1.1231 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.6256 - accuracy: 0.7458 - val_loss: 1.1202 - val_accuracy: 0.4868\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 351us/step - loss: 0.6179 - accuracy: 0.7684 - val_loss: 1.1214 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.6144 - accuracy: 0.7571 - val_loss: 1.1252 - val_accuracy: 0.4605\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 352us/step - loss: 0.6416 - accuracy: 0.7232 - val_loss: 1.1440 - val_accuracy: 0.4342\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 396us/step - loss: 0.6323 - accuracy: 0.7232 - val_loss: 1.1278 - val_accuracy: 0.4474\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 514us/step - loss: 0.6309 - accuracy: 0.7458 - val_loss: 1.1503 - val_accuracy: 0.4737\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 309us/step - loss: 0.6237 - accuracy: 0.7514 - val_loss: 1.1236 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.6272 - accuracy: 0.7288 - val_loss: 1.1403 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.6261 - accuracy: 0.7232 - val_loss: 1.1199 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 420us/step - loss: 0.6158 - accuracy: 0.7514 - val_loss: 1.1293 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.6159 - accuracy: 0.7684 - val_loss: 1.1110 - val_accuracy: 0.4868\n"
     ]
    }
   ],
   "source": [
    "hist_sel2 = model_sel2.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 72.69%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.290039e-09</td>\n",
       "      <td>1.567630e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS199</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.856965e-05</td>\n",
       "      <td>2.843749e-03</td>\n",
       "      <td>9.971277e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999446e-01</td>\n",
       "      <td>4.541289e-06</td>\n",
       "      <td>5.090974e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.282367e-02</td>\n",
       "      <td>7.075194e-04</td>\n",
       "      <td>9.364688e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS202</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.229589e-03</td>\n",
       "      <td>2.163908e-05</td>\n",
       "      <td>9.917488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.964591e-03</td>\n",
       "      <td>9.959286e-01</td>\n",
       "      <td>1.068284e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309226e-04</td>\n",
       "      <td>9.996691e-01</td>\n",
       "      <td>6.232397e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>SR1287</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.445997e-06</td>\n",
       "      <td>9.999915e-01</td>\n",
       "      <td>1.182947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.516150e-01</td>\n",
       "      <td>1.480882e-02</td>\n",
       "      <td>3.335762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.841915e-04</td>\n",
       "      <td>9.994158e-01</td>\n",
       "      <td>6.525528e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual  CFBREBSa104          1           2  1.290039e-09   \n",
       "1       p0017kpresabs_qual       NRS199          2           2  2.856965e-05   \n",
       "2       p0017kpresabs_qual       NRS233          1           0  9.999446e-01   \n",
       "3       p0017kpresabs_qual       SR1746          0           2  6.282367e-02   \n",
       "4       p0017kpresabs_qual       NRS202          2           2  8.229589e-03   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual         GA27          2           1  3.964591e-03   \n",
       "604  p0040presabsSTCC_qual        GA231          2           1  3.309226e-04   \n",
       "605  p0040presabsSTCC_qual       SR1287          0           1  8.445997e-06   \n",
       "606  p0040presabsSTCC_qual          506          2           0  6.516150e-01   \n",
       "607  p0040presabsSTCC_qual       NRS001          1           1  5.841915e-04   \n",
       "\n",
       "                1             2  \n",
       "0    1.567630e-07  9.999999e-01  \n",
       "1    2.843749e-03  9.971277e-01  \n",
       "2    4.541289e-06  5.090974e-05  \n",
       "3    7.075194e-04  9.364688e-01  \n",
       "4    2.163908e-05  9.917488e-01  \n",
       "..            ...           ...  \n",
       "603  9.959286e-01  1.068284e-04  \n",
       "604  9.996691e-01  6.232397e-10  \n",
       "605  9.999915e-01  1.182947e-13  \n",
       "606  1.480882e-02  3.335762e-01  \n",
       "607  9.994158e-01  6.525528e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05141884, 0.58390534, 0.36467585],\n",
       "       [0.10108861, 0.3121938 , 0.58671755],\n",
       "       [0.31517643, 0.4467824 , 0.23804115],\n",
       "       [0.32365856, 0.43329704, 0.2430444 ],\n",
       "       [0.3521556 , 0.5906253 , 0.05721916],\n",
       "       [0.6695274 , 0.14287113, 0.1876014 ],\n",
       "       [0.16536398, 0.72540855, 0.10922749],\n",
       "       [0.02954216, 0.58235794, 0.38809988],\n",
       "       [0.21015587, 0.7127534 , 0.07709076],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.19735691, 0.5813008 , 0.22134228],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.17481852, 0.7992746 , 0.0259068 ],\n",
       "       [0.05083958, 0.3675986 , 0.58156186],\n",
       "       [0.01369852, 0.70745254, 0.27884892],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.08859741, 0.3068429 , 0.6045597 ],\n",
       "       [0.33711857, 0.15141867, 0.51146275],\n",
       "       [0.08859741, 0.3068429 , 0.6045597 ],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.26754895, 0.24908972, 0.4833613 ],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.13531189, 0.28711057, 0.57757753],\n",
       "       [0.02422029, 0.11797966, 0.85780007],\n",
       "       [0.5636881 , 0.338489  , 0.09782291],\n",
       "       [0.07418228, 0.2157486 , 0.7100691 ],\n",
       "       [0.56573355, 0.21143204, 0.22283442],\n",
       "       [0.06861988, 0.16211003, 0.76927006],\n",
       "       [0.06676453, 0.75060904, 0.18262634],\n",
       "       [0.10834545, 0.5610968 , 0.3305578 ],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.08859741, 0.3068429 , 0.6045597 ],\n",
       "       [0.20674501, 0.25598904, 0.53726596],\n",
       "       [0.56320053, 0.35217464, 0.08462479],\n",
       "       [0.19735691, 0.5813008 , 0.22134228],\n",
       "       [0.472193  , 0.46554717, 0.06225975],\n",
       "       [0.45373446, 0.2521304 , 0.2941351 ],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.03499803, 0.21739414, 0.7476079 ],\n",
       "       [0.08653521, 0.51647604, 0.39698878],\n",
       "       [0.015653  , 0.02816397, 0.956183  ],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.39181742, 0.43454483, 0.1736378 ],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.08859741, 0.3068429 , 0.6045597 ],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.25047266, 0.4706286 , 0.27889872],\n",
       "       [0.10108861, 0.3121938 , 0.58671755],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.61615175, 0.2808452 , 0.10300302],\n",
       "       [0.31894267, 0.19165972, 0.48939762],\n",
       "       [0.18660901, 0.43882236, 0.37456864],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.13635716, 0.19357787, 0.6700649 ],\n",
       "       [0.23935662, 0.19533077, 0.56531256],\n",
       "       [0.3083403 , 0.56936914, 0.12229059],\n",
       "       [0.47686866, 0.26417407, 0.2589573 ],\n",
       "       [0.17481852, 0.7992746 , 0.0259068 ],\n",
       "       [0.68980706, 0.2511144 , 0.05907853],\n",
       "       [0.03393178, 0.42909086, 0.53697735],\n",
       "       [0.4946322 , 0.13300906, 0.37235874],\n",
       "       [0.45373446, 0.2521304 , 0.2941351 ],\n",
       "       [0.08445336, 0.84922403, 0.06632252],\n",
       "       [0.07893784, 0.41348395, 0.50757825],\n",
       "       [0.6695983 , 0.19403207, 0.13636966],\n",
       "       [0.35819203, 0.25910902, 0.38269895],\n",
       "       [0.6605932 , 0.16321902, 0.17618775],\n",
       "       [0.24823667, 0.4423738 , 0.30938953],\n",
       "       [0.26727083, 0.17334963, 0.5593795 ],\n",
       "       [0.5462177 , 0.21530327, 0.23847897],\n",
       "       [0.45373446, 0.2521304 , 0.2941351 ],\n",
       "       [0.57051194, 0.3460641 , 0.08342388]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308749427476158"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308749427476158"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_sel_test, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat7['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "120       NRS063     1\n",
       "187       NRS219     2\n",
       "96          GA27     2\n",
       "53   CFBREBSa119     1\n",
       "197       NRS233     2\n",
       "..           ...   ...\n",
       "47   CFBREBSa110     2\n",
       "68      CFBRSa05     0\n",
       "56   CFBREBSa123     0\n",
       "231        NY360     1\n",
       "52   CFBREBSa118     2\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 729us/step - loss: 1.1378 - accuracy: 0.3559 - val_loss: 1.0918 - val_accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 1.0662 - accuracy: 0.4237 - val_loss: 1.0867 - val_accuracy: 0.4079\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 1.0365 - accuracy: 0.4633 - val_loss: 1.0828 - val_accuracy: 0.3816\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 1.0259 - accuracy: 0.4633 - val_loss: 1.0794 - val_accuracy: 0.3947\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 318us/step - loss: 1.0072 - accuracy: 0.5141 - val_loss: 1.0933 - val_accuracy: 0.4079\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 251us/step - loss: 1.0030 - accuracy: 0.5085 - val_loss: 1.0956 - val_accuracy: 0.3947\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 333us/step - loss: 0.9930 - accuracy: 0.5141 - val_loss: 1.0926 - val_accuracy: 0.3158\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.9863 - accuracy: 0.4633 - val_loss: 1.0893 - val_accuracy: 0.4079\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.9803 - accuracy: 0.4746 - val_loss: 1.0973 - val_accuracy: 0.3421\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.9710 - accuracy: 0.4972 - val_loss: 1.0930 - val_accuracy: 0.3553\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.9707 - accuracy: 0.5254 - val_loss: 1.1020 - val_accuracy: 0.3553\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.9585 - accuracy: 0.5198 - val_loss: 1.0951 - val_accuracy: 0.3421\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.9464 - accuracy: 0.5198 - val_loss: 1.0954 - val_accuracy: 0.3684\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.9367 - accuracy: 0.5198 - val_loss: 1.0994 - val_accuracy: 0.3816\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.9349 - accuracy: 0.5367 - val_loss: 1.1043 - val_accuracy: 0.4079\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.9284 - accuracy: 0.5198 - val_loss: 1.1031 - val_accuracy: 0.3816\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.9244 - accuracy: 0.5424 - val_loss: 1.1117 - val_accuracy: 0.4211\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.9291 - accuracy: 0.5480 - val_loss: 1.1109 - val_accuracy: 0.4474\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.9172 - accuracy: 0.5311 - val_loss: 1.1041 - val_accuracy: 0.3684\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 261us/step - loss: 0.9111 - accuracy: 0.5537 - val_loss: 1.1046 - val_accuracy: 0.4079\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.9073 - accuracy: 0.5480 - val_loss: 1.1005 - val_accuracy: 0.3816\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.9036 - accuracy: 0.5537 - val_loss: 1.1007 - val_accuracy: 0.4342\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 265us/step - loss: 0.9000 - accuracy: 0.5932 - val_loss: 1.0951 - val_accuracy: 0.3816\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.8992 - accuracy: 0.5819 - val_loss: 1.0924 - val_accuracy: 0.4079\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.8953 - accuracy: 0.5819 - val_loss: 1.0856 - val_accuracy: 0.3947\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.8947 - accuracy: 0.6102 - val_loss: 1.0782 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 227us/step - loss: 0.8890 - accuracy: 0.5706 - val_loss: 1.0896 - val_accuracy: 0.4342\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.8831 - accuracy: 0.5819 - val_loss: 1.0899 - val_accuracy: 0.4474\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.8805 - accuracy: 0.5876 - val_loss: 1.0919 - val_accuracy: 0.3816\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.8797 - accuracy: 0.6045 - val_loss: 1.0968 - val_accuracy: 0.3684\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 171us/step - loss: 0.8859 - accuracy: 0.5989 - val_loss: 1.1041 - val_accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.8761 - accuracy: 0.6158 - val_loss: 1.0914 - val_accuracy: 0.3947\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.8690 - accuracy: 0.6215 - val_loss: 1.0897 - val_accuracy: 0.3947\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 262us/step - loss: 0.8715 - accuracy: 0.6158 - val_loss: 1.0940 - val_accuracy: 0.3816\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.8693 - accuracy: 0.6158 - val_loss: 1.0984 - val_accuracy: 0.4605\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.8714 - accuracy: 0.6271 - val_loss: 1.0938 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.8563 - accuracy: 0.6271 - val_loss: 1.0966 - val_accuracy: 0.4079\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.8543 - accuracy: 0.6271 - val_loss: 1.0988 - val_accuracy: 0.4211\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.8549 - accuracy: 0.6328 - val_loss: 1.1034 - val_accuracy: 0.4342\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.8486 - accuracy: 0.6271 - val_loss: 1.0956 - val_accuracy: 0.4342\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 151us/step - loss: 0.8442 - accuracy: 0.6215 - val_loss: 1.0874 - val_accuracy: 0.4342\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 115us/step - loss: 0.8440 - accuracy: 0.6497 - val_loss: 1.0930 - val_accuracy: 0.4342\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.8449 - accuracy: 0.6328 - val_loss: 1.0898 - val_accuracy: 0.4474\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.8423 - accuracy: 0.6384 - val_loss: 1.0925 - val_accuracy: 0.4474\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 122us/step - loss: 0.8390 - accuracy: 0.6554 - val_loss: 1.0947 - val_accuracy: 0.4079\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 123us/step - loss: 0.8433 - accuracy: 0.6497 - val_loss: 1.0937 - val_accuracy: 0.3947\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.8397 - accuracy: 0.6328 - val_loss: 1.0925 - val_accuracy: 0.4342\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 376us/step - loss: 0.8336 - accuracy: 0.6497 - val_loss: 1.0953 - val_accuracy: 0.4079\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.8377 - accuracy: 0.6384 - val_loss: 1.1050 - val_accuracy: 0.4211\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 350us/step - loss: 0.8279 - accuracy: 0.6497 - val_loss: 1.1113 - val_accuracy: 0.4342\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 369us/step - loss: 0.8310 - accuracy: 0.6384 - val_loss: 1.1066 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.8153 - accuracy: 0.6554 - val_loss: 1.0970 - val_accuracy: 0.4342\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 256us/step - loss: 0.8180 - accuracy: 0.6554 - val_loss: 1.0965 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 278us/step - loss: 0.8172 - accuracy: 0.6610 - val_loss: 1.0962 - val_accuracy: 0.4474\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.8124 - accuracy: 0.6667 - val_loss: 1.0982 - val_accuracy: 0.4342\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.8156 - accuracy: 0.6723 - val_loss: 1.1016 - val_accuracy: 0.4474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 160us/step - loss: 0.8084 - accuracy: 0.6836 - val_loss: 1.0935 - val_accuracy: 0.4737\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.8099 - accuracy: 0.6554 - val_loss: 1.0931 - val_accuracy: 0.4211\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 243us/step - loss: 0.8074 - accuracy: 0.6610 - val_loss: 1.0936 - val_accuracy: 0.4605\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 166us/step - loss: 0.8101 - accuracy: 0.6723 - val_loss: 1.0973 - val_accuracy: 0.4474\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.8082 - accuracy: 0.6554 - val_loss: 1.0941 - val_accuracy: 0.4342\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.8079 - accuracy: 0.6384 - val_loss: 1.1091 - val_accuracy: 0.4737\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 279us/step - loss: 0.8045 - accuracy: 0.6441 - val_loss: 1.1018 - val_accuracy: 0.4342\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 328us/step - loss: 0.7976 - accuracy: 0.6667 - val_loss: 1.1026 - val_accuracy: 0.4342\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.7895 - accuracy: 0.6667 - val_loss: 1.1116 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 401us/step - loss: 0.7926 - accuracy: 0.6554 - val_loss: 1.1116 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 319us/step - loss: 0.7888 - accuracy: 0.6497 - val_loss: 1.1069 - val_accuracy: 0.4605\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7839 - accuracy: 0.6667 - val_loss: 1.0989 - val_accuracy: 0.4605\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.7824 - accuracy: 0.6667 - val_loss: 1.0972 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.7812 - accuracy: 0.6667 - val_loss: 1.0968 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.7789 - accuracy: 0.6667 - val_loss: 1.1117 - val_accuracy: 0.4737\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.7780 - accuracy: 0.6836 - val_loss: 1.1188 - val_accuracy: 0.4474\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 0.7773 - accuracy: 0.7006 - val_loss: 1.1085 - val_accuracy: 0.4605\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.7754 - accuracy: 0.6723 - val_loss: 1.1056 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 291us/step - loss: 0.7763 - accuracy: 0.6554 - val_loss: 1.1061 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.7734 - accuracy: 0.6780 - val_loss: 1.0940 - val_accuracy: 0.4605\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.7692 - accuracy: 0.6723 - val_loss: 1.0951 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.7722 - accuracy: 0.6836 - val_loss: 1.1034 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.7748 - accuracy: 0.6780 - val_loss: 1.1104 - val_accuracy: 0.4737\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 127us/step - loss: 0.7617 - accuracy: 0.6723 - val_loss: 1.1157 - val_accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.7589 - accuracy: 0.6780 - val_loss: 1.1190 - val_accuracy: 0.4737\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.7633 - accuracy: 0.6893 - val_loss: 1.1212 - val_accuracy: 0.4737\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.7606 - accuracy: 0.6836 - val_loss: 1.1328 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 124us/step - loss: 0.7725 - accuracy: 0.6667 - val_loss: 1.1389 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 144us/step - loss: 0.7783 - accuracy: 0.6723 - val_loss: 1.1293 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.7531 - accuracy: 0.6893 - val_loss: 1.1222 - val_accuracy: 0.4737\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 146us/step - loss: 0.7489 - accuracy: 0.6949 - val_loss: 1.1147 - val_accuracy: 0.4605\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.7507 - accuracy: 0.6949 - val_loss: 1.1117 - val_accuracy: 0.4605\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.7584 - accuracy: 0.6610 - val_loss: 1.1335 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.7470 - accuracy: 0.6836 - val_loss: 1.1174 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.7417 - accuracy: 0.6893 - val_loss: 1.1161 - val_accuracy: 0.4737\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.7551 - accuracy: 0.6836 - val_loss: 1.1111 - val_accuracy: 0.4474\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.7405 - accuracy: 0.6780 - val_loss: 1.1134 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.7437 - accuracy: 0.7006 - val_loss: 1.1179 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.7426 - accuracy: 0.6893 - val_loss: 1.1146 - val_accuracy: 0.4474\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7367 - accuracy: 0.6723 - val_loss: 1.1138 - val_accuracy: 0.4737\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.7407 - accuracy: 0.6780 - val_loss: 1.1295 - val_accuracy: 0.4737\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 139us/step - loss: 0.7304 - accuracy: 0.7062 - val_loss: 1.1203 - val_accuracy: 0.4605\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.7356 - accuracy: 0.6836 - val_loss: 1.1207 - val_accuracy: 0.4605\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.7264 - accuracy: 0.7119 - val_loss: 1.1267 - val_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a33df56d8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 90us/step\n",
      "test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel3 = model_sel3.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('test accuracy: %.2f%%' % (acc_test_sel3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 0, 0, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 0, 1, 1, 1, 2,\n",
       "       1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 1, 2,\n",
       "       1, 1, 2, 0, 2, 2, 2, 2, 2, 1, 0, 1, 2, 1, 1, 2, 1, 0, 2, 1, 2, 1,\n",
       "       1, 1, 0, 1, 1, 2, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model_sel3.predict_classes(X_sel_test)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NRS063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NRS219</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GA27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CFBREBSa119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS233</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "120       NRS063     1     1\n",
       "187       NRS219     2     2\n",
       "96          GA27     2     1\n",
       "53   CFBREBSa119     1     0\n",
       "197       NRS233     2     1\n",
       "..           ...   ...   ...\n",
       "47   CFBREBSa110     2     2\n",
       "68      CFBRSa05     0     1\n",
       "56   CFBREBSa123     0     1\n",
       "231        NY360     1     2\n",
       "52   CFBREBSa118     2     1\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model_sel3.predict_proba(X_sel_test)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117554</td>\n",
       "      <td>0.845996</td>\n",
       "      <td>0.036450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042698</td>\n",
       "      <td>0.234220</td>\n",
       "      <td>0.723082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.383970</td>\n",
       "      <td>0.479381</td>\n",
       "      <td>0.136649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545839</td>\n",
       "      <td>0.193339</td>\n",
       "      <td>0.260822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.161795</td>\n",
       "      <td>0.549704</td>\n",
       "      <td>0.288501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.248874</td>\n",
       "      <td>0.571441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.368936</td>\n",
       "      <td>0.500525</td>\n",
       "      <td>0.130539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.512505</td>\n",
       "      <td>0.351217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.248874</td>\n",
       "      <td>0.571441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.069757</td>\n",
       "      <td>0.812518</td>\n",
       "      <td>0.117725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.117554  0.845996  0.036450\n",
       "1   0.042698  0.234220  0.723082\n",
       "2   0.383970  0.479381  0.136649\n",
       "3   0.545839  0.193339  0.260822\n",
       "4   0.161795  0.549704  0.288501\n",
       "..       ...       ...       ...\n",
       "71  0.179684  0.248874  0.571441\n",
       "72  0.368936  0.500525  0.130539\n",
       "73  0.136278  0.512505  0.351217\n",
       "74  0.179684  0.248874  0.571441\n",
       "75  0.069757  0.812518  0.117725\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.7398 - accuracy: 0.7006 - val_loss: 1.0866 - val_accuracy: 0.4868\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.7414 - accuracy: 0.7119 - val_loss: 1.0821 - val_accuracy: 0.5132\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7401 - accuracy: 0.7175 - val_loss: 1.0845 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.7348 - accuracy: 0.7288 - val_loss: 1.0740 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.7524 - accuracy: 0.6780 - val_loss: 1.0751 - val_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.7442 - accuracy: 0.7006 - val_loss: 1.0671 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.7419 - accuracy: 0.7006 - val_loss: 1.0764 - val_accuracy: 0.4868\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 231us/step - loss: 0.7362 - accuracy: 0.7006 - val_loss: 1.0826 - val_accuracy: 0.4868\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.7290 - accuracy: 0.7006 - val_loss: 1.0871 - val_accuracy: 0.4868\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 269us/step - loss: 0.7266 - accuracy: 0.7119 - val_loss: 1.0847 - val_accuracy: 0.5132\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.7289 - accuracy: 0.7119 - val_loss: 1.0922 - val_accuracy: 0.5263\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.7274 - accuracy: 0.6949 - val_loss: 1.0878 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 0.7326 - accuracy: 0.6949 - val_loss: 1.0884 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.7331 - accuracy: 0.7006 - val_loss: 1.0995 - val_accuracy: 0.4737\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7347 - accuracy: 0.7232 - val_loss: 1.0980 - val_accuracy: 0.4737\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.7223 - accuracy: 0.7232 - val_loss: 1.1043 - val_accuracy: 0.4605\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.7290 - accuracy: 0.7062 - val_loss: 1.1064 - val_accuracy: 0.4868\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.7189 - accuracy: 0.7401 - val_loss: 1.1055 - val_accuracy: 0.4868\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.7146 - accuracy: 0.7006 - val_loss: 1.1003 - val_accuracy: 0.4868\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.7169 - accuracy: 0.7119 - val_loss: 1.1032 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.7103 - accuracy: 0.7006 - val_loss: 1.1062 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.7090 - accuracy: 0.7006 - val_loss: 1.1152 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.7079 - accuracy: 0.7119 - val_loss: 1.1202 - val_accuracy: 0.4737\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.7068 - accuracy: 0.7062 - val_loss: 1.1236 - val_accuracy: 0.4605\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.7083 - accuracy: 0.6893 - val_loss: 1.1283 - val_accuracy: 0.4737\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.7225 - accuracy: 0.6780 - val_loss: 1.1511 - val_accuracy: 0.5132\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.7320 - accuracy: 0.6723 - val_loss: 1.1273 - val_accuracy: 0.4605\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.7033 - accuracy: 0.7006 - val_loss: 1.1218 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.7132 - accuracy: 0.6836 - val_loss: 1.1180 - val_accuracy: 0.4605\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 187us/step - loss: 0.7014 - accuracy: 0.7062 - val_loss: 1.1167 - val_accuracy: 0.4737\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 248us/step - loss: 0.7193 - accuracy: 0.6893 - val_loss: 1.1499 - val_accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7138 - accuracy: 0.6780 - val_loss: 1.1147 - val_accuracy: 0.4868\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.6970 - accuracy: 0.7345 - val_loss: 1.1205 - val_accuracy: 0.4605\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.6997 - accuracy: 0.7288 - val_loss: 1.1195 - val_accuracy: 0.4605\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 168us/step - loss: 0.6974 - accuracy: 0.7401 - val_loss: 1.1227 - val_accuracy: 0.4737\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.6957 - accuracy: 0.6949 - val_loss: 1.1274 - val_accuracy: 0.5132\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.6926 - accuracy: 0.7288 - val_loss: 1.1203 - val_accuracy: 0.4737\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.6984 - accuracy: 0.7232 - val_loss: 1.1155 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.7011 - accuracy: 0.7062 - val_loss: 1.1291 - val_accuracy: 0.4737\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 518us/step - loss: 0.6948 - accuracy: 0.7119 - val_loss: 1.1307 - val_accuracy: 0.4737\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 940us/step - loss: 0.6855 - accuracy: 0.7175 - val_loss: 1.1311 - val_accuracy: 0.4474\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 338us/step - loss: 0.6877 - accuracy: 0.7288 - val_loss: 1.1407 - val_accuracy: 0.4605\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 282us/step - loss: 0.6857 - accuracy: 0.7288 - val_loss: 1.1313 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.6851 - accuracy: 0.7119 - val_loss: 1.1264 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 280us/step - loss: 0.6824 - accuracy: 0.7514 - val_loss: 1.1301 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 299us/step - loss: 0.6822 - accuracy: 0.7175 - val_loss: 1.1267 - val_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 322us/step - loss: 0.7124 - accuracy: 0.6836 - val_loss: 1.1366 - val_accuracy: 0.4474\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 601us/step - loss: 0.6942 - accuracy: 0.7232 - val_loss: 1.1236 - val_accuracy: 0.4342\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.7401 - val_loss: 1.1277 - val_accuracy: 0.4605\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 272us/step - loss: 0.6761 - accuracy: 0.7401 - val_loss: 1.1264 - val_accuracy: 0.4605\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 301us/step - loss: 0.6748 - accuracy: 0.7401 - val_loss: 1.1333 - val_accuracy: 0.4605\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 565us/step - loss: 0.6752 - accuracy: 0.7401 - val_loss: 1.1375 - val_accuracy: 0.4605\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 317us/step - loss: 0.6693 - accuracy: 0.7288 - val_loss: 1.1398 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.6694 - accuracy: 0.7288 - val_loss: 1.1444 - val_accuracy: 0.4474\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.6700 - accuracy: 0.7345 - val_loss: 1.1501 - val_accuracy: 0.4605\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 157us/step - loss: 0.6671 - accuracy: 0.7288 - val_loss: 1.1539 - val_accuracy: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.6729 - accuracy: 0.7119 - val_loss: 1.1517 - val_accuracy: 0.4474\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.6785 - accuracy: 0.7062 - val_loss: 1.1511 - val_accuracy: 0.4474\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 927us/step - loss: 0.6704 - accuracy: 0.7232 - val_loss: 1.1535 - val_accuracy: 0.4211\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 266us/step - loss: 0.6654 - accuracy: 0.7345 - val_loss: 1.1538 - val_accuracy: 0.4342\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 699us/step - loss: 0.6762 - accuracy: 0.7232 - val_loss: 1.1637 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.6715 - accuracy: 0.7175 - val_loss: 1.1574 - val_accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 232us/step - loss: 0.6636 - accuracy: 0.7175 - val_loss: 1.1586 - val_accuracy: 0.4605\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 259us/step - loss: 0.6645 - accuracy: 0.7345 - val_loss: 1.1599 - val_accuracy: 0.4474\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.6650 - accuracy: 0.7062 - val_loss: 1.1615 - val_accuracy: 0.4605\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.6643 - accuracy: 0.7345 - val_loss: 1.1672 - val_accuracy: 0.4342\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.6681 - accuracy: 0.7288 - val_loss: 1.1666 - val_accuracy: 0.4474\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.6693 - accuracy: 0.7345 - val_loss: 1.1613 - val_accuracy: 0.4342\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 385us/step - loss: 0.6640 - accuracy: 0.7288 - val_loss: 1.1633 - val_accuracy: 0.4211\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.6559 - accuracy: 0.7458 - val_loss: 1.1654 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.6593 - accuracy: 0.7571 - val_loss: 1.1602 - val_accuracy: 0.4474\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 0.6709 - accuracy: 0.7458 - val_loss: 1.1687 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.6618 - accuracy: 0.7175 - val_loss: 1.1606 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.6626 - accuracy: 0.7458 - val_loss: 1.1685 - val_accuracy: 0.4605\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 842us/step - loss: 0.6549 - accuracy: 0.7401 - val_loss: 1.1716 - val_accuracy: 0.4079\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 330us/step - loss: 0.6554 - accuracy: 0.7288 - val_loss: 1.1721 - val_accuracy: 0.4211\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 760us/step - loss: 0.6547 - accuracy: 0.7401 - val_loss: 1.1789 - val_accuracy: 0.4474\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 707us/step - loss: 0.6584 - accuracy: 0.7345 - val_loss: 1.1774 - val_accuracy: 0.4342\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 503us/step - loss: 0.6464 - accuracy: 0.7345 - val_loss: 1.1861 - val_accuracy: 0.4342\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 342us/step - loss: 0.6497 - accuracy: 0.7458 - val_loss: 1.1814 - val_accuracy: 0.4342\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 455us/step - loss: 0.6498 - accuracy: 0.7345 - val_loss: 1.1819 - val_accuracy: 0.4342\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 283us/step - loss: 0.6427 - accuracy: 0.7401 - val_loss: 1.1849 - val_accuracy: 0.4474\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 416us/step - loss: 0.6478 - accuracy: 0.7175 - val_loss: 1.1919 - val_accuracy: 0.4211\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.6503 - accuracy: 0.7175 - val_loss: 1.1839 - val_accuracy: 0.4342\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.6413 - accuracy: 0.7345 - val_loss: 1.1824 - val_accuracy: 0.4474\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6430 - accuracy: 0.7345 - val_loss: 1.1856 - val_accuracy: 0.4474\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 335us/step - loss: 0.6415 - accuracy: 0.7458 - val_loss: 1.1923 - val_accuracy: 0.4342\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 392us/step - loss: 0.6405 - accuracy: 0.7401 - val_loss: 1.1954 - val_accuracy: 0.4342\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.6355 - accuracy: 0.7458 - val_loss: 1.1943 - val_accuracy: 0.4605\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 678us/step - loss: 0.6349 - accuracy: 0.7345 - val_loss: 1.1954 - val_accuracy: 0.4474\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.6435 - accuracy: 0.7345 - val_loss: 1.1961 - val_accuracy: 0.4211\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 348us/step - loss: 0.6394 - accuracy: 0.7345 - val_loss: 1.1969 - val_accuracy: 0.4342\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.6338 - accuracy: 0.7288 - val_loss: 1.1831 - val_accuracy: 0.4474\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.6445 - accuracy: 0.7514 - val_loss: 1.1846 - val_accuracy: 0.4342\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 360us/step - loss: 0.6346 - accuracy: 0.7232 - val_loss: 1.1894 - val_accuracy: 0.4605\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.6377 - accuracy: 0.7345 - val_loss: 1.1915 - val_accuracy: 0.4211\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.6468 - accuracy: 0.7232 - val_loss: 1.2067 - val_accuracy: 0.4605\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 238us/step - loss: 0.6405 - accuracy: 0.7514 - val_loss: 1.1911 - val_accuracy: 0.4342\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 310us/step - loss: 0.6392 - accuracy: 0.7345 - val_loss: 1.1941 - val_accuracy: 0.4342\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.6420 - accuracy: 0.7288 - val_loss: 1.2033 - val_accuracy: 0.4737\n"
     ]
    }
   ],
   "source": [
    "hist_sel3 = model_sel3.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 72.11%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854929</td>\n",
       "      <td>0.144940</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>SR2852</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CA39</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959992</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.026602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NY356</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.411991</td>\n",
       "      <td>0.578852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044135</td>\n",
       "      <td>0.010244</td>\n",
       "      <td>0.945621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.145032</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>0.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994623</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NY360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.948566</td>\n",
       "      <td>0.050639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction         0  \\\n",
       "0       p0017kpresabs_qual       NRS271          1           0  0.854929   \n",
       "1       p0017kpresabs_qual       SR2852          2           2  0.000001   \n",
       "2       p0017kpresabs_qual         CA39          2           0  0.959992   \n",
       "3       p0017kpresabs_qual       NRS266          1           2  0.000018   \n",
       "4       p0017kpresabs_qual        NY356          2           2  0.009156   \n",
       "..                     ...          ...        ...         ...       ...   \n",
       "603  p0040presabsSTCC_qual  CFBREBSa110          2           2  0.044135   \n",
       "604  p0040presabsSTCC_qual     CFBRSa05          0           2  0.145032   \n",
       "605  p0040presabsSTCC_qual  CFBREBSa123          0           0  0.994623   \n",
       "606  p0040presabsSTCC_qual        NY360          1           1  0.000795   \n",
       "607  p0040presabsSTCC_qual  CFBREBSa118          2           1  0.000029   \n",
       "\n",
       "            1         2  \n",
       "0    0.144940  0.000130  \n",
       "1    0.000075  0.999923  \n",
       "2    0.013406  0.026602  \n",
       "3    0.000003  0.999980  \n",
       "4    0.411991  0.578852  \n",
       "..        ...       ...  \n",
       "603  0.010244  0.945621  \n",
       "604  0.408530  0.446439  \n",
       "605  0.004152  0.001224  \n",
       "606  0.948566  0.050639  \n",
       "607  0.999037  0.000934  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11755378, 0.8459965 , 0.03644972],\n",
       "       [0.04269802, 0.23422003, 0.72308195],\n",
       "       [0.3839702 , 0.4793813 , 0.13664854],\n",
       "       [0.5458387 , 0.19333918, 0.26082212],\n",
       "       [0.1617952 , 0.54970366, 0.2885011 ],\n",
       "       [0.40070727, 0.33775336, 0.2615393 ],\n",
       "       [0.47838765, 0.3219237 , 0.19968863],\n",
       "       [0.07698642, 0.32936263, 0.59365094],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.5694695 , 0.36324418, 0.06728628],\n",
       "       [0.00356365, 0.09140137, 0.90503496],\n",
       "       [0.04269802, 0.23422003, 0.72308195],\n",
       "       [0.00356365, 0.09140137, 0.90503496],\n",
       "       [0.00779021, 0.8835956 , 0.10861427],\n",
       "       [0.25838095, 0.33845374, 0.40316525],\n",
       "       [0.2820515 , 0.6775162 , 0.04043233],\n",
       "       [0.6649023 , 0.21456218, 0.12053547],\n",
       "       [0.2362025 , 0.690679  , 0.0731185 ],\n",
       "       [0.22566627, 0.55320513, 0.22112855],\n",
       "       [0.1617952 , 0.54970366, 0.2885011 ],\n",
       "       [0.01930976, 0.15389492, 0.8267954 ],\n",
       "       [0.36893642, 0.5005247 , 0.13053882],\n",
       "       [0.11755378, 0.8459965 , 0.03644972],\n",
       "       [0.36893642, 0.5005247 , 0.13053882],\n",
       "       [0.47554097, 0.40080196, 0.12365711],\n",
       "       [0.6783971 , 0.2911949 , 0.0304081 ],\n",
       "       [0.03875168, 0.42140302, 0.53984535],\n",
       "       [0.04954902, 0.22232114, 0.72812986],\n",
       "       [0.0960145 , 0.47723138, 0.42675412],\n",
       "       [0.26599205, 0.6886653 , 0.04534274],\n",
       "       [0.04872359, 0.88638717, 0.06488925],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.37784907, 0.14588845, 0.47626242],\n",
       "       [0.23659316, 0.28598827, 0.47741857],\n",
       "       [0.1582702 , 0.3044577 , 0.53727204],\n",
       "       [0.4980708 , 0.26385018, 0.23807894],\n",
       "       [0.00356365, 0.09140137, 0.90503496],\n",
       "       [0.24375507, 0.5672155 , 0.1890294 ],\n",
       "       [0.452739  , 0.24098042, 0.30628052],\n",
       "       [0.5458387 , 0.19333918, 0.26082212],\n",
       "       [0.6344787 , 0.10218134, 0.2633399 ],\n",
       "       [0.38290206, 0.42356437, 0.19353355],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.36893642, 0.5005247 , 0.13053882],\n",
       "       [0.17984821, 0.7017624 , 0.1183894 ],\n",
       "       [0.18305303, 0.20094132, 0.6160056 ],\n",
       "       [0.6344787 , 0.10218134, 0.2633399 ],\n",
       "       [0.02193073, 0.26372227, 0.714347  ],\n",
       "       [0.20242108, 0.36636013, 0.4312187 ],\n",
       "       [0.04269802, 0.23422003, 0.72308195],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.12062438, 0.3763316 , 0.50304407],\n",
       "       [0.1617952 , 0.54970366, 0.2885011 ],\n",
       "       [0.65817434, 0.20616832, 0.13565736],\n",
       "       [0.31246173, 0.3792521 , 0.30828616],\n",
       "       [0.32525268, 0.17397122, 0.50077605],\n",
       "       [0.29343444, 0.3899543 , 0.31661126],\n",
       "       [0.38290206, 0.42356437, 0.19353355],\n",
       "       [0.14806989, 0.21273093, 0.6391992 ],\n",
       "       [0.19750279, 0.5025793 , 0.29991788],\n",
       "       [0.66260415, 0.25659826, 0.08079753],\n",
       "       [0.16193259, 0.3466889 , 0.49137855],\n",
       "       [0.14156345, 0.5988202 , 0.25961632],\n",
       "       [0.10164286, 0.39975137, 0.49860576],\n",
       "       [0.06975678, 0.81251836, 0.11772489],\n",
       "       [0.36893642, 0.5005247 , 0.13053882],\n",
       "       [0.21099155, 0.5494854 , 0.23952305],\n",
       "       [0.6344787 , 0.10218134, 0.2633399 ],\n",
       "       [0.15106834, 0.5892288 , 0.25970283],\n",
       "       [0.4369153 , 0.44946504, 0.11361964],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.36893642, 0.5005247 , 0.13053882],\n",
       "       [0.13627818, 0.5125046 , 0.35121724],\n",
       "       [0.17968413, 0.24887443, 0.5714414 ],\n",
       "       [0.06975678, 0.81251836, 0.11772489]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645114281462899"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645114281462899"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_sel_test, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_sel_train, X_sel_test, y_sel_train, y_sel_test = train_test_split(X_sel, y_sel,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_sel_test.iloc[:,-1])\n",
    "dat8['test'] = y_sel_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NRS103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test\n",
       "130       NRS103     2\n",
       "92         EUH25     0\n",
       "143       NRS148     2\n",
       "107       NRS001     1\n",
       "166       NRS192     0\n",
       "..           ...   ...\n",
       "139       NRS113     1\n",
       "24     BCH-SA-09     2\n",
       "133       NRS106     2\n",
       "62   CFBREBSa131     2\n",
       "100      GA51254     0\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_train = X_sel_train.drop(['strain'], axis=1)\n",
    "X_sel_test = X_sel_test.drop(['strain'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_sel_train.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 673us/step - loss: 1.0916 - accuracy: 0.4576 - val_loss: 1.0525 - val_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 1.0564 - accuracy: 0.4633 - val_loss: 1.0568 - val_accuracy: 0.4474\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 233us/step - loss: 1.0291 - accuracy: 0.4802 - val_loss: 1.0588 - val_accuracy: 0.4342\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 285us/step - loss: 1.0173 - accuracy: 0.4746 - val_loss: 1.0593 - val_accuracy: 0.4605\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 237us/step - loss: 1.0145 - accuracy: 0.5141 - val_loss: 1.0632 - val_accuracy: 0.4605\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 304us/step - loss: 0.9982 - accuracy: 0.4972 - val_loss: 1.0529 - val_accuracy: 0.4079\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.9926 - accuracy: 0.5198 - val_loss: 1.0502 - val_accuracy: 0.4342\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.9764 - accuracy: 0.5141 - val_loss: 1.0565 - val_accuracy: 0.4211\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.9761 - accuracy: 0.5085 - val_loss: 1.0594 - val_accuracy: 0.4342\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.9756 - accuracy: 0.5028 - val_loss: 1.0561 - val_accuracy: 0.4737\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 246us/step - loss: 0.9645 - accuracy: 0.5198 - val_loss: 1.0526 - val_accuracy: 0.3947\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 239us/step - loss: 0.9562 - accuracy: 0.5424 - val_loss: 1.0504 - val_accuracy: 0.4342\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 296us/step - loss: 0.9450 - accuracy: 0.5763 - val_loss: 1.0488 - val_accuracy: 0.4474\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.9951 - accuracy: 0.50 - 0s 256us/step - loss: 0.9466 - accuracy: 0.5593 - val_loss: 1.0488 - val_accuracy: 0.4211\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.9414 - accuracy: 0.5537 - val_loss: 1.0487 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 236us/step - loss: 0.9346 - accuracy: 0.5763 - val_loss: 1.0416 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.9344 - accuracy: 0.5763 - val_loss: 1.0394 - val_accuracy: 0.4211\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.9315 - accuracy: 0.5593 - val_loss: 1.0414 - val_accuracy: 0.4211\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 271us/step - loss: 0.9326 - accuracy: 0.5593 - val_loss: 1.0467 - val_accuracy: 0.4211\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 324us/step - loss: 0.9339 - accuracy: 0.5480 - val_loss: 1.0429 - val_accuracy: 0.4211\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.9281 - accuracy: 0.5593 - val_loss: 1.0386 - val_accuracy: 0.4211\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 161us/step - loss: 0.9177 - accuracy: 0.5819 - val_loss: 1.0334 - val_accuracy: 0.4079\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.9145 - accuracy: 0.5650 - val_loss: 1.0361 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 142us/step - loss: 0.9178 - accuracy: 0.5763 - val_loss: 1.0346 - val_accuracy: 0.4342\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.9256 - accuracy: 0.5650 - val_loss: 1.0298 - val_accuracy: 0.4079\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.9151 - accuracy: 0.5763 - val_loss: 1.0287 - val_accuracy: 0.4474\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 254us/step - loss: 0.9109 - accuracy: 0.5650 - val_loss: 1.0357 - val_accuracy: 0.4474\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.9050 - accuracy: 0.5706 - val_loss: 1.0282 - val_accuracy: 0.4605\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 264us/step - loss: 0.8973 - accuracy: 0.5989 - val_loss: 1.0288 - val_accuracy: 0.4737\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.9090 - accuracy: 0.5932 - val_loss: 1.0327 - val_accuracy: 0.4868\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.9002 - accuracy: 0.5876 - val_loss: 1.0267 - val_accuracy: 0.4737\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.8897 - accuracy: 0.5876 - val_loss: 1.0275 - val_accuracy: 0.4737\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.8908 - accuracy: 0.5989 - val_loss: 1.0328 - val_accuracy: 0.4868\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 224us/step - loss: 0.8942 - accuracy: 0.6102 - val_loss: 1.0293 - val_accuracy: 0.4737\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 209us/step - loss: 0.8891 - accuracy: 0.5876 - val_loss: 1.0308 - val_accuracy: 0.4474\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 136us/step - loss: 0.8843 - accuracy: 0.5650 - val_loss: 1.0290 - val_accuracy: 0.4474\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 114us/step - loss: 0.8856 - accuracy: 0.5819 - val_loss: 1.0361 - val_accuracy: 0.4605\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.8810 - accuracy: 0.5706 - val_loss: 1.0272 - val_accuracy: 0.4474\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 129us/step - loss: 0.8842 - accuracy: 0.5876 - val_loss: 1.0272 - val_accuracy: 0.4868\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 126us/step - loss: 0.8866 - accuracy: 0.5763 - val_loss: 1.0189 - val_accuracy: 0.4605\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 121us/step - loss: 0.8722 - accuracy: 0.6102 - val_loss: 1.0162 - val_accuracy: 0.4868\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 185us/step - loss: 0.8685 - accuracy: 0.6102 - val_loss: 1.0206 - val_accuracy: 0.4868\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - 0s 414us/step - loss: 0.8683 - accuracy: 0.5876 - val_loss: 1.0280 - val_accuracy: 0.4605\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 339us/step - loss: 0.8660 - accuracy: 0.5932 - val_loss: 1.0249 - val_accuracy: 0.4605\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 453us/step - loss: 0.8721 - accuracy: 0.5763 - val_loss: 1.0287 - val_accuracy: 0.4474\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.8681 - accuracy: 0.5932 - val_loss: 1.0211 - val_accuracy: 0.4737\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 292us/step - loss: 0.8628 - accuracy: 0.6045 - val_loss: 1.0224 - val_accuracy: 0.4868\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 273us/step - loss: 0.8750 - accuracy: 0.6271 - val_loss: 1.0387 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.8776 - accuracy: 0.6158 - val_loss: 1.0327 - val_accuracy: 0.4737\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 141us/step - loss: 0.8600 - accuracy: 0.6271 - val_loss: 1.0369 - val_accuracy: 0.4474\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 156us/step - loss: 0.8626 - accuracy: 0.5932 - val_loss: 1.0353 - val_accuracy: 0.4474\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 163us/step - loss: 0.8618 - accuracy: 0.6158 - val_loss: 1.0296 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.8588 - accuracy: 0.6271 - val_loss: 1.0306 - val_accuracy: 0.4474\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.8528 - accuracy: 0.6102 - val_loss: 1.0384 - val_accuracy: 0.4342\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.8594 - accuracy: 0.5819 - val_loss: 1.0338 - val_accuracy: 0.4737\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.8491 - accuracy: 0.6215 - val_loss: 1.0368 - val_accuracy: 0.4605\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.8550 - accuracy: 0.5932 - val_loss: 1.0318 - val_accuracy: 0.4605\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 229us/step - loss: 0.8483 - accuracy: 0.6215 - val_loss: 1.0266 - val_accuracy: 0.4868\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.8637 - accuracy: 0.6441 - val_loss: 1.0272 - val_accuracy: 0.4474\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.8450 - accuracy: 0.6271 - val_loss: 1.0232 - val_accuracy: 0.4737\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.8416 - accuracy: 0.6328 - val_loss: 1.0279 - val_accuracy: 0.4605\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.8421 - accuracy: 0.6102 - val_loss: 1.0288 - val_accuracy: 0.4605\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 230us/step - loss: 0.8377 - accuracy: 0.6102 - val_loss: 1.0296 - val_accuracy: 0.4474\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.8365 - accuracy: 0.6045 - val_loss: 1.0333 - val_accuracy: 0.4605\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.8336 - accuracy: 0.6102 - val_loss: 1.0332 - val_accuracy: 0.4342\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.8351 - accuracy: 0.6271 - val_loss: 1.0298 - val_accuracy: 0.4605\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 152us/step - loss: 0.8267 - accuracy: 0.6271 - val_loss: 1.0375 - val_accuracy: 0.4868\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 173us/step - loss: 0.8420 - accuracy: 0.6215 - val_loss: 1.0349 - val_accuracy: 0.4868\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 409us/step - loss: 0.8305 - accuracy: 0.6271 - val_loss: 1.0292 - val_accuracy: 0.4868\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 434us/step - loss: 0.8277 - accuracy: 0.6158 - val_loss: 1.0419 - val_accuracy: 0.4605\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 167us/step - loss: 0.8374 - accuracy: 0.5763 - val_loss: 1.0382 - val_accuracy: 0.4605\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 207us/step - loss: 0.8281 - accuracy: 0.5989 - val_loss: 1.0343 - val_accuracy: 0.4737\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.8279 - accuracy: 0.6158 - val_loss: 1.0349 - val_accuracy: 0.4737\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.8263 - accuracy: 0.6215 - val_loss: 1.0360 - val_accuracy: 0.4737\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 305us/step - loss: 0.8230 - accuracy: 0.6384 - val_loss: 1.0412 - val_accuracy: 0.4737\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.8189 - accuracy: 0.6328 - val_loss: 1.0350 - val_accuracy: 0.4868\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.8138 - accuracy: 0.6384 - val_loss: 1.0355 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 149us/step - loss: 0.8189 - accuracy: 0.6441 - val_loss: 1.0430 - val_accuracy: 0.4737\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 217us/step - loss: 0.8111 - accuracy: 0.6384 - val_loss: 1.0381 - val_accuracy: 0.5132\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 311us/step - loss: 0.8090 - accuracy: 0.6384 - val_loss: 1.0345 - val_accuracy: 0.4868\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.8178 - accuracy: 0.6441 - val_loss: 1.0419 - val_accuracy: 0.4868\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.8277 - accuracy: 0.6441 - val_loss: 1.0415 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 258us/step - loss: 0.8249 - accuracy: 0.6384 - val_loss: 1.0360 - val_accuracy: 0.4737\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 252us/step - loss: 0.8258 - accuracy: 0.6271 - val_loss: 1.0358 - val_accuracy: 0.4868\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 175us/step - loss: 0.8117 - accuracy: 0.6554 - val_loss: 1.0256 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 212us/step - loss: 0.8014 - accuracy: 0.6554 - val_loss: 1.0262 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.8026 - accuracy: 0.6328 - val_loss: 1.0277 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 288us/step - loss: 0.8038 - accuracy: 0.6497 - val_loss: 1.0274 - val_accuracy: 0.4868\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 313us/step - loss: 0.8017 - accuracy: 0.6836 - val_loss: 1.0254 - val_accuracy: 0.5132\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 247us/step - loss: 0.8032 - accuracy: 0.6497 - val_loss: 1.0326 - val_accuracy: 0.4737\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 234us/step - loss: 0.8003 - accuracy: 0.6384 - val_loss: 1.0323 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 357us/step - loss: 0.8054 - accuracy: 0.6328 - val_loss: 1.0317 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 346us/step - loss: 0.7984 - accuracy: 0.6497 - val_loss: 1.0227 - val_accuracy: 0.5263\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 297us/step - loss: 0.8070 - accuracy: 0.6271 - val_loss: 1.0305 - val_accuracy: 0.5132\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 274us/step - loss: 0.7930 - accuracy: 0.6497 - val_loss: 1.0227 - val_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.8036 - accuracy: 0.6667 - val_loss: 1.0296 - val_accuracy: 0.4868\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.7913 - accuracy: 0.6610 - val_loss: 1.0276 - val_accuracy: 0.4868\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 120us/step - loss: 0.8013 - accuracy: 0.6328 - val_loss: 1.0343 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.7868 - accuracy: 0.6384 - val_loss: 1.0330 - val_accuracy: 0.5132\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 143us/step - loss: 0.7895 - accuracy: 0.6554 - val_loss: 1.0400 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a342b32e8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 63us/step\n",
      "over-sampling test accuracy: 52.63%\n"
     ]
    }
   ],
   "source": [
    "acc_test_sel4 = model_sel4.evaluate(X_sel_test, y_sel_test)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_sel4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       2, 0, 2, 0, 0, 2, 1, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 2, 0, 2,\n",
       "       2, 2, 1, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model_sel4.predict_classes(X_sel_test)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NRS103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EUH25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NRS192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  test  pred\n",
       "130       NRS103     2     2\n",
       "92         EUH25     0     0\n",
       "143       NRS148     2     2\n",
       "107       NRS001     1     0\n",
       "166       NRS192     0     1\n",
       "..           ...   ...   ...\n",
       "139       NRS113     1     1\n",
       "24     BCH-SA-09     2     1\n",
       "133       NRS106     2     0\n",
       "62   CFBREBSa131     2     0\n",
       "100      GA51254     0     0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model_sel4.predict_proba(X_sel_test)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065021</td>\n",
       "      <td>0.425737</td>\n",
       "      <td>0.509242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.353188</td>\n",
       "      <td>0.303337</td>\n",
       "      <td>0.343475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051844</td>\n",
       "      <td>0.473591</td>\n",
       "      <td>0.474565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574330</td>\n",
       "      <td>0.350626</td>\n",
       "      <td>0.075044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216782</td>\n",
       "      <td>0.485269</td>\n",
       "      <td>0.297949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.515135</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.172904</td>\n",
       "      <td>0.555872</td>\n",
       "      <td>0.271225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.489310</td>\n",
       "      <td>0.363842</td>\n",
       "      <td>0.146848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.489310</td>\n",
       "      <td>0.363842</td>\n",
       "      <td>0.146848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.353188</td>\n",
       "      <td>0.303337</td>\n",
       "      <td>0.343475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0   0.065021  0.425737  0.509242\n",
       "1   0.353188  0.303337  0.343475\n",
       "2   0.051844  0.473591  0.474565\n",
       "3   0.574330  0.350626  0.075044\n",
       "4   0.216782  0.485269  0.297949\n",
       "..       ...       ...       ...\n",
       "71  0.060622  0.515135  0.424242\n",
       "72  0.172904  0.555872  0.271225\n",
       "73  0.489310  0.363842  0.146848\n",
       "74  0.489310  0.363842  0.146848\n",
       "75  0.353188  0.303337  0.343475\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p40.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 0s 216us/step - loss: 0.7649 - accuracy: 0.6610 - val_loss: 1.0274 - val_accuracy: 0.5395\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.7560 - accuracy: 0.6780 - val_loss: 1.0192 - val_accuracy: 0.5395\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s 211us/step - loss: 0.7516 - accuracy: 0.6949 - val_loss: 1.0186 - val_accuracy: 0.5263\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s 194us/step - loss: 0.7570 - accuracy: 0.6780 - val_loss: 1.0229 - val_accuracy: 0.5263\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.7562 - accuracy: 0.6554 - val_loss: 1.0216 - val_accuracy: 0.5526\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s 193us/step - loss: 0.7603 - accuracy: 0.6723 - val_loss: 1.0138 - val_accuracy: 0.5658\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.7540 - accuracy: 0.6893 - val_loss: 1.0100 - val_accuracy: 0.5526\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7473 - accuracy: 0.6893 - val_loss: 1.0101 - val_accuracy: 0.5658\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.7529 - accuracy: 0.6949 - val_loss: 1.0159 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.7413 - accuracy: 0.7006 - val_loss: 1.0184 - val_accuracy: 0.5395\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7391 - accuracy: 0.6949 - val_loss: 1.0201 - val_accuracy: 0.5395\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s 177us/step - loss: 0.7392 - accuracy: 0.6667 - val_loss: 1.0187 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s 169us/step - loss: 0.7579 - accuracy: 0.6554 - val_loss: 1.0358 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s 170us/step - loss: 0.7524 - accuracy: 0.6667 - val_loss: 1.0213 - val_accuracy: 0.5395\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s 186us/step - loss: 0.7418 - accuracy: 0.6949 - val_loss: 1.0313 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 0s 159us/step - loss: 0.7411 - accuracy: 0.6780 - val_loss: 1.0234 - val_accuracy: 0.5263\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 0s 196us/step - loss: 0.7469 - accuracy: 0.6780 - val_loss: 1.0389 - val_accuracy: 0.4737\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.7449 - accuracy: 0.6667 - val_loss: 1.0210 - val_accuracy: 0.5263\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 0s 235us/step - loss: 0.7339 - accuracy: 0.6723 - val_loss: 1.0287 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 0s 223us/step - loss: 0.7328 - accuracy: 0.6780 - val_loss: 1.0209 - val_accuracy: 0.5263\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7278 - accuracy: 0.6836 - val_loss: 1.0237 - val_accuracy: 0.5395\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.7271 - accuracy: 0.7006 - val_loss: 1.0294 - val_accuracy: 0.5395\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 0s 172us/step - loss: 0.7298 - accuracy: 0.6949 - val_loss: 1.0318 - val_accuracy: 0.5263\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.7339 - accuracy: 0.6893 - val_loss: 1.0334 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 0s 197us/step - loss: 0.7216 - accuracy: 0.6893 - val_loss: 1.0430 - val_accuracy: 0.5132\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 0s 208us/step - loss: 0.7292 - accuracy: 0.6780 - val_loss: 1.0307 - val_accuracy: 0.5395\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 0s 183us/step - loss: 0.7212 - accuracy: 0.6893 - val_loss: 1.0232 - val_accuracy: 0.5132\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.7187 - accuracy: 0.6949 - val_loss: 1.0259 - val_accuracy: 0.5395\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 0s 226us/step - loss: 0.7283 - accuracy: 0.6893 - val_loss: 1.0365 - val_accuracy: 0.5132\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 0s 178us/step - loss: 0.7554 - accuracy: 0.6893 - val_loss: 1.0267 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.7248 - accuracy: 0.7006 - val_loss: 1.0108 - val_accuracy: 0.5263\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.7174 - accuracy: 0.7006 - val_loss: 1.0177 - val_accuracy: 0.5526\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.7343 - accuracy: 0.6836 - val_loss: 1.0250 - val_accuracy: 0.5526\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 0s 198us/step - loss: 0.7124 - accuracy: 0.7062 - val_loss: 1.0248 - val_accuracy: 0.5395\n",
      "Epoch 35/100\n",
      "177/177 [==============================] - 0s 174us/step - loss: 0.7084 - accuracy: 0.7232 - val_loss: 1.0308 - val_accuracy: 0.5395\n",
      "Epoch 36/100\n",
      "177/177 [==============================] - 0s 179us/step - loss: 0.7365 - accuracy: 0.6723 - val_loss: 1.0524 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "177/177 [==============================] - 0s 189us/step - loss: 0.7139 - accuracy: 0.7119 - val_loss: 1.0271 - val_accuracy: 0.5395\n",
      "Epoch 38/100\n",
      "177/177 [==============================] - 0s 240us/step - loss: 0.7089 - accuracy: 0.7062 - val_loss: 1.0277 - val_accuracy: 0.5395\n",
      "Epoch 39/100\n",
      "177/177 [==============================] - 0s 206us/step - loss: 0.7126 - accuracy: 0.7006 - val_loss: 1.0267 - val_accuracy: 0.5263\n",
      "Epoch 40/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.7104 - accuracy: 0.6893 - val_loss: 1.0310 - val_accuracy: 0.5395\n",
      "Epoch 41/100\n",
      "177/177 [==============================] - 0s 154us/step - loss: 0.7075 - accuracy: 0.6836 - val_loss: 1.0364 - val_accuracy: 0.5395\n",
      "Epoch 42/100\n",
      "177/177 [==============================] - 0s 155us/step - loss: 0.7045 - accuracy: 0.7119 - val_loss: 1.0378 - val_accuracy: 0.5526\n",
      "Epoch 43/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.8685 - accuracy: 0.56 - 0s 142us/step - loss: 0.7106 - accuracy: 0.6780 - val_loss: 1.0370 - val_accuracy: 0.5263\n",
      "Epoch 44/100\n",
      "177/177 [==============================] - 0s 181us/step - loss: 0.7090 - accuracy: 0.6949 - val_loss: 1.0353 - val_accuracy: 0.5263\n",
      "Epoch 45/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.7009 - accuracy: 0.7062 - val_loss: 1.0391 - val_accuracy: 0.5263\n",
      "Epoch 46/100\n",
      "177/177 [==============================] - 0s 188us/step - loss: 0.7031 - accuracy: 0.7232 - val_loss: 1.0356 - val_accuracy: 0.5132\n",
      "Epoch 47/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.6959 - accuracy: 0.7232 - val_loss: 1.0353 - val_accuracy: 0.5395\n",
      "Epoch 48/100\n",
      "177/177 [==============================] - 0s 182us/step - loss: 0.7030 - accuracy: 0.7119 - val_loss: 1.0570 - val_accuracy: 0.4737\n",
      "Epoch 49/100\n",
      "177/177 [==============================] - 0s 184us/step - loss: 0.7091 - accuracy: 0.6836 - val_loss: 1.0412 - val_accuracy: 0.5395\n",
      "Epoch 50/100\n",
      "177/177 [==============================] - 0s 164us/step - loss: 0.6872 - accuracy: 0.7232 - val_loss: 1.0419 - val_accuracy: 0.5395\n",
      "Epoch 51/100\n",
      "177/177 [==============================] - 0s 153us/step - loss: 0.6958 - accuracy: 0.7119 - val_loss: 1.0436 - val_accuracy: 0.5263\n",
      "Epoch 52/100\n",
      "177/177 [==============================] - 0s 158us/step - loss: 0.6959 - accuracy: 0.7119 - val_loss: 1.0411 - val_accuracy: 0.5395\n",
      "Epoch 53/100\n",
      "177/177 [==============================] - 0s 148us/step - loss: 0.6969 - accuracy: 0.7062 - val_loss: 1.0376 - val_accuracy: 0.5132\n",
      "Epoch 54/100\n",
      "177/177 [==============================] - 0s 162us/step - loss: 0.6905 - accuracy: 0.7345 - val_loss: 1.0395 - val_accuracy: 0.5526\n",
      "Epoch 55/100\n",
      "177/177 [==============================] - 0s 176us/step - loss: 0.6821 - accuracy: 0.7288 - val_loss: 1.0426 - val_accuracy: 0.5395\n",
      "Epoch 56/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6845 - accuracy: 0.7232 - val_loss: 1.0557 - val_accuracy: 0.5263\n",
      "Epoch 57/100\n",
      "177/177 [==============================] - 0s 214us/step - loss: 0.6981 - accuracy: 0.7288 - val_loss: 1.0599 - val_accuracy: 0.5263\n",
      "Epoch 58/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.6860 - accuracy: 0.7175 - val_loss: 1.0479 - val_accuracy: 0.5263\n",
      "Epoch 59/100\n",
      "177/177 [==============================] - 0s 203us/step - loss: 0.6813 - accuracy: 0.7175 - val_loss: 1.0556 - val_accuracy: 0.5395\n",
      "Epoch 60/100\n",
      "177/177 [==============================] - 0s 180us/step - loss: 0.6782 - accuracy: 0.7288 - val_loss: 1.0500 - val_accuracy: 0.5395\n",
      "Epoch 61/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.6906 - accuracy: 0.7006 - val_loss: 1.0655 - val_accuracy: 0.5132\n",
      "Epoch 62/100\n",
      "177/177 [==============================] - 0s 192us/step - loss: 0.6900 - accuracy: 0.7062 - val_loss: 1.0514 - val_accuracy: 0.5132\n",
      "Epoch 63/100\n",
      "177/177 [==============================] - 0s 200us/step - loss: 0.6839 - accuracy: 0.7006 - val_loss: 1.0522 - val_accuracy: 0.4737\n",
      "Epoch 64/100\n",
      "177/177 [==============================] - 0s 228us/step - loss: 0.6829 - accuracy: 0.7119 - val_loss: 1.0526 - val_accuracy: 0.5132\n",
      "Epoch 65/100\n",
      "177/177 [==============================] - 0s 287us/step - loss: 0.6780 - accuracy: 0.7232 - val_loss: 1.0413 - val_accuracy: 0.5263\n",
      "Epoch 66/100\n",
      "177/177 [==============================] - 0s 410us/step - loss: 0.6684 - accuracy: 0.7232 - val_loss: 1.0458 - val_accuracy: 0.5263\n",
      "Epoch 67/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.6726 - accuracy: 0.7345 - val_loss: 1.0510 - val_accuracy: 0.5395\n",
      "Epoch 68/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6737 - accuracy: 0.7232 - val_loss: 1.0616 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "177/177 [==============================] - 0s 255us/step - loss: 0.6762 - accuracy: 0.7062 - val_loss: 1.0664 - val_accuracy: 0.4605\n",
      "Epoch 70/100\n",
      "177/177 [==============================] - 0s 245us/step - loss: 0.6807 - accuracy: 0.7062 - val_loss: 1.0696 - val_accuracy: 0.5132\n",
      "Epoch 71/100\n",
      "177/177 [==============================] - 0s 204us/step - loss: 0.6709 - accuracy: 0.7175 - val_loss: 1.0652 - val_accuracy: 0.5395\n",
      "Epoch 72/100\n",
      "177/177 [==============================] - 0s 221us/step - loss: 0.6625 - accuracy: 0.7345 - val_loss: 1.0673 - val_accuracy: 0.5263\n",
      "Epoch 73/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.6664 - accuracy: 0.7401 - val_loss: 1.0739 - val_accuracy: 0.5395\n",
      "Epoch 74/100\n",
      "177/177 [==============================] - 0s 244us/step - loss: 0.6632 - accuracy: 0.7458 - val_loss: 1.0736 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "177/177 [==============================] - 0s 220us/step - loss: 0.6632 - accuracy: 0.7006 - val_loss: 1.0735 - val_accuracy: 0.5395\n",
      "Epoch 76/100\n",
      "177/177 [==============================] - 0s 195us/step - loss: 0.6616 - accuracy: 0.7345 - val_loss: 1.0690 - val_accuracy: 0.5263\n",
      "Epoch 77/100\n",
      "177/177 [==============================] - 0s 202us/step - loss: 0.6560 - accuracy: 0.7401 - val_loss: 1.0642 - val_accuracy: 0.5526\n",
      "Epoch 78/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.6588 - accuracy: 0.7288 - val_loss: 1.0650 - val_accuracy: 0.5395\n",
      "Epoch 79/100\n",
      "177/177 [==============================] - 0s 191us/step - loss: 0.6683 - accuracy: 0.7119 - val_loss: 1.0589 - val_accuracy: 0.5263\n",
      "Epoch 80/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6659 - accuracy: 0.6949 - val_loss: 1.0610 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "177/177 [==============================] - 0s 205us/step - loss: 0.6579 - accuracy: 0.7288 - val_loss: 1.0606 - val_accuracy: 0.5132\n",
      "Epoch 82/100\n",
      "177/177 [==============================] - 0s 218us/step - loss: 0.6538 - accuracy: 0.7288 - val_loss: 1.0599 - val_accuracy: 0.4868\n",
      "Epoch 83/100\n",
      "177/177 [==============================] - 0s 201us/step - loss: 0.6533 - accuracy: 0.7345 - val_loss: 1.0670 - val_accuracy: 0.5132\n",
      "Epoch 84/100\n",
      "177/177 [==============================] - 0s 222us/step - loss: 0.6527 - accuracy: 0.7345 - val_loss: 1.0730 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "177/177 [==============================] - 0s 210us/step - loss: 0.6508 - accuracy: 0.7345 - val_loss: 1.0804 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "177/177 [==============================] - 0s 241us/step - loss: 0.6672 - accuracy: 0.6949 - val_loss: 1.0883 - val_accuracy: 0.5132\n",
      "Epoch 87/100\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.71 - 0s 825us/step - loss: 0.6528 - accuracy: 0.7401 - val_loss: 1.0892 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "177/177 [==============================] - 0s 331us/step - loss: 0.6538 - accuracy: 0.7345 - val_loss: 1.0866 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "177/177 [==============================] - 0s 465us/step - loss: 0.6512 - accuracy: 0.7345 - val_loss: 1.0885 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "177/177 [==============================] - 0s 355us/step - loss: 0.6513 - accuracy: 0.7288 - val_loss: 1.0877 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "177/177 [==============================] - 0s 306us/step - loss: 0.6512 - accuracy: 0.7232 - val_loss: 1.0812 - val_accuracy: 0.4868\n",
      "Epoch 92/100\n",
      "177/177 [==============================] - 0s 356us/step - loss: 0.6513 - accuracy: 0.7232 - val_loss: 1.0750 - val_accuracy: 0.4737\n",
      "Epoch 93/100\n",
      "177/177 [==============================] - 0s 362us/step - loss: 0.6564 - accuracy: 0.7288 - val_loss: 1.0816 - val_accuracy: 0.4868\n",
      "Epoch 94/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.7288 - val_loss: 1.0858 - val_accuracy: 0.4868\n",
      "Epoch 95/100\n",
      "177/177 [==============================] - 0s 307us/step - loss: 0.6464 - accuracy: 0.7232 - val_loss: 1.0909 - val_accuracy: 0.5132\n",
      "Epoch 96/100\n",
      "177/177 [==============================] - 0s 667us/step - loss: 0.6448 - accuracy: 0.7232 - val_loss: 1.0900 - val_accuracy: 0.5132\n",
      "Epoch 97/100\n",
      "177/177 [==============================] - 0s 219us/step - loss: 0.6410 - accuracy: 0.7345 - val_loss: 1.0932 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "177/177 [==============================] - 0s 225us/step - loss: 0.6381 - accuracy: 0.7401 - val_loss: 1.0982 - val_accuracy: 0.5263\n",
      "Epoch 99/100\n",
      "177/177 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.7401 - val_loss: 1.1055 - val_accuracy: 0.5263\n",
      "Epoch 100/100\n",
      "177/177 [==============================] - 0s 302us/step - loss: 0.6471 - accuracy: 0.7345 - val_loss: 1.1052 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist_sel4 = model_sel4.fit(X_sel_train, y_sel_train,\n",
    "          batch_size=16, epochs=100,\n",
    "          validation_data=(X_sel_test, y_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 70.68%\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f%%' % (np.mean(hist_sel4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_lasso_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.210638e-02</td>\n",
       "      <td>0.917809</td>\n",
       "      <td>8.477923e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS071</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.015229e-02</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>7.345203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>NRS072</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.642946e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.963547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.809318e-03</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>8.980029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p0017kpresabs_qual</td>\n",
       "      <td>CFBREBSa125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875667e-01</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>4.237761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686909e-07</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>9.068785e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529492e-07</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.559324e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>NRS106</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115902e-03</td>\n",
       "      <td>0.998816</td>\n",
       "      <td>6.852559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>CFBREBSa131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.708040e-07</td>\n",
       "      <td>0.156768</td>\n",
       "      <td>8.432316e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>p0040presabsSTCC_qual</td>\n",
       "      <td>GA51254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.993569e-01</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1.816008e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     phage       strain  phenotype  prediction             0  \\\n",
       "0       p0017kpresabs_qual       NRS104          0           1  8.210638e-02   \n",
       "1       p0017kpresabs_qual       NRS071          0           2  1.015229e-02   \n",
       "2       p0017kpresabs_qual       NRS072          1           2  3.642946e-03   \n",
       "3       p0017kpresabs_qual    BCH-SA-12          0           2  2.809318e-03   \n",
       "4       p0017kpresabs_qual  CFBREBSa125          2           0  4.875667e-01   \n",
       "..                     ...          ...        ...         ...           ...   \n",
       "603  p0040presabsSTCC_qual       NRS113          1           2  2.686909e-07   \n",
       "604  p0040presabsSTCC_qual    BCH-SA-09          2           1  5.529492e-07   \n",
       "605  p0040presabsSTCC_qual       NRS106          2           1  1.115902e-03   \n",
       "606  p0040presabsSTCC_qual  CFBREBSa131          2           2  2.708040e-07   \n",
       "607  p0040presabsSTCC_qual      GA51254          0           0  9.993569e-01   \n",
       "\n",
       "            1             2  \n",
       "0    0.917809  8.477923e-05  \n",
       "1    0.255327  7.345203e-01  \n",
       "2    0.000002  9.963547e-01  \n",
       "3    0.099188  8.980029e-01  \n",
       "4    0.088657  4.237761e-01  \n",
       "..        ...           ...  \n",
       "603  0.093121  9.068785e-01  \n",
       "604  0.999990  9.559324e-06  \n",
       "605  0.998816  6.852559e-05  \n",
       "606  0.156768  8.432316e-01  \n",
       "607  0.000643  1.816008e-08  \n",
       "\n",
       "[608 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06502149, 0.42573664, 0.5092419 ],\n",
       "       [0.35318816, 0.30333686, 0.343475  ],\n",
       "       [0.05184364, 0.47359097, 0.47456536],\n",
       "       [0.57433015, 0.35062632, 0.07504351],\n",
       "       [0.21678227, 0.48526892, 0.29794878],\n",
       "       [0.14364265, 0.49772835, 0.358629  ],\n",
       "       [0.16133824, 0.67639565, 0.16226612],\n",
       "       [0.7120913 , 0.22905402, 0.05885464],\n",
       "       [0.06190963, 0.50238204, 0.43570828],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.07288651, 0.77674985, 0.15036368],\n",
       "       [0.30956638, 0.5371874 , 0.1532462 ],\n",
       "       [0.09097935, 0.54213053, 0.36689007],\n",
       "       [0.1671836 , 0.557644  , 0.27517232],\n",
       "       [0.07288651, 0.77674985, 0.15036368],\n",
       "       [0.18535659, 0.6803928 , 0.13425054],\n",
       "       [0.09204357, 0.46087155, 0.44708487],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.03084035, 0.38422337, 0.5849363 ],\n",
       "       [0.6035241 , 0.254427  , 0.14204891],\n",
       "       [0.11814371, 0.47777766, 0.4040787 ],\n",
       "       [0.48949414, 0.36511445, 0.14539143],\n",
       "       [0.41639993, 0.35404903, 0.22955102],\n",
       "       [0.7144196 , 0.11294802, 0.1726323 ],\n",
       "       [0.06543667, 0.76306367, 0.17149958],\n",
       "       [0.05828847, 0.7586634 , 0.18304808],\n",
       "       [0.80831116, 0.16104579, 0.03064303],\n",
       "       [0.15624897, 0.21030541, 0.6334457 ],\n",
       "       [0.04026835, 0.47257388, 0.4871578 ],\n",
       "       [0.0526435 , 0.12060142, 0.8267551 ],\n",
       "       [0.02635895, 0.19547379, 0.77816725],\n",
       "       [0.07902912, 0.5860512 , 0.33491966],\n",
       "       [0.05393366, 0.68378603, 0.26228026],\n",
       "       [0.12866463, 0.7543738 , 0.1169615 ],\n",
       "       [0.12482557, 0.3475803 , 0.52759415],\n",
       "       [0.07803888, 0.41993833, 0.50202286],\n",
       "       [0.5021264 , 0.38338158, 0.11449207],\n",
       "       [0.15624897, 0.21030541, 0.6334457 ],\n",
       "       [0.15690076, 0.55584055, 0.2872586 ],\n",
       "       [0.0526435 , 0.12060142, 0.8267551 ],\n",
       "       [0.40228608, 0.40339974, 0.19431414],\n",
       "       [0.20650636, 0.61859506, 0.17489855],\n",
       "       [0.18979107, 0.28038496, 0.52982396],\n",
       "       [0.35318816, 0.30333686, 0.343475  ],\n",
       "       [0.05236548, 0.22753787, 0.72009665],\n",
       "       [0.48949414, 0.36511445, 0.14539143],\n",
       "       [0.04877757, 0.2852768 , 0.66594565],\n",
       "       [0.48930994, 0.36384198, 0.1468481 ],\n",
       "       [0.5509503 , 0.34311756, 0.10593209],\n",
       "       [0.05442967, 0.42131883, 0.5242516 ],\n",
       "       [0.09863348, 0.5127011 , 0.38866538],\n",
       "       [0.06120776, 0.88766956, 0.05112269],\n",
       "       [0.09097935, 0.54213053, 0.36689007],\n",
       "       [0.48949414, 0.36511445, 0.14539143],\n",
       "       [0.59885854, 0.30740562, 0.09373584],\n",
       "       [0.25084314, 0.43201274, 0.31714413],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.12058265, 0.53600985, 0.3434075 ],\n",
       "       [0.15690076, 0.55584055, 0.2872586 ],\n",
       "       [0.35318816, 0.30333686, 0.343475  ],\n",
       "       [0.26011252, 0.42040268, 0.31948486],\n",
       "       [0.05764147, 0.22742547, 0.7149331 ],\n",
       "       [0.48949414, 0.36511445, 0.14539143],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.5141148 , 0.3064309 , 0.17945422],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.10827925, 0.36898807, 0.52273273],\n",
       "       [0.0526435 , 0.12060142, 0.8267551 ],\n",
       "       [0.1136378 , 0.45383763, 0.43252453],\n",
       "       [0.0706785 , 0.5379624 , 0.39135915],\n",
       "       [0.48949414, 0.36511445, 0.14539143],\n",
       "       [0.06062247, 0.5151352 , 0.42424232],\n",
       "       [0.17290384, 0.55587167, 0.27122453],\n",
       "       [0.48930994, 0.36384198, 0.1468481 ],\n",
       "       [0.48930994, 0.36384198, 0.1468481 ],\n",
       "       [0.35318816, 0.30333686, 0.343475  ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p0040kpresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6692453209301393"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6692453209301393"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_sel_test, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6327603133508721"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030380799690129925"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6327603133508721"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030380799690129925"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_l= [acc_test_sel, acc_test_sel2, acc_test_sel3, acc_test_sel4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy mean after lasso: 48.68%\n"
     ]
    }
   ],
   "source": [
    "mean_l = np.mean(accs_l)\n",
    "print('test accuracy mean after lasso: %.2f%%' % (mean_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy standard deviation after lasso: 0.03947368760903739\n"
     ]
    }
   ],
   "source": [
    "std_l = np.std(accs_l)\n",
    "print('test accuracy standard deviation after lasso:', std_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train_l = [np.mean(hist_sel.history['accuracy']), np.mean(hist_sel2.history['accuracy']), np.mean(hist_sel3.history['accuracy']),\n",
    "             np.mean(hist_sel4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy mean after lasso: 73.31%\n"
     ]
    }
   ],
   "source": [
    "mean_train_l = np.mean(accs_train_l)\n",
    "print('train accuracy mean after lasso: %.2f%%' % (mean_train_l*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy standard deviation after lasso: 0.026665628\n"
     ]
    }
   ],
   "source": [
    "std_train_l = np.std(accs_train_l)\n",
    "print('train accuracy standard deviation after lasso:', std_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
