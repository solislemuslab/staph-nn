{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p003ppresabs_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1091)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p003ppresabs_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8042</th>\n",
       "      <th>group_8177</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9489</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1091 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  ...  group_8042  group_8177  group_8643  \\\n",
       "0              1             1  ...           0           0           0   \n",
       "1              1             1  ...           0           0           0   \n",
       "2              1             1  ...           0           0           0   \n",
       "3              1             1  ...           0           0           0   \n",
       "4              1             1  ...           0           0           0   \n",
       "\n",
       "   group_8644  group_8645  group_8646  group_8815  group_8892  group_9489  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   pheno  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 1091 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    224\n",
       "1     26\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1090)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA</th>\n",
       "      <th>...</th>\n",
       "      <th>group_8042</th>\n",
       "      <th>group_8177</th>\n",
       "      <th>group_8643</th>\n",
       "      <th>group_8644</th>\n",
       "      <th>group_8645</th>\n",
       "      <th>group_8646</th>\n",
       "      <th>group_8815</th>\n",
       "      <th>group_8892</th>\n",
       "      <th>group_9489</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  \\\n",
       "0              1             1   \n",
       "1              1             1   \n",
       "2              1             1   \n",
       "3              1             1   \n",
       "4              1             1   \n",
       "\n",
       "   TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  group_8042  group_8177  group_8643  group_8644  group_8645  \\\n",
       "0  ...           0           0           0           0           0   \n",
       "1  ...           0           0           0           0           0   \n",
       "2  ...           0           0           0           0           0   \n",
       "3  ...           0           0           0           0           0   \n",
       "4  ...           0           0           0           0           0   \n",
       "\n",
       "   group_8646  group_8815  group_8892  group_9489  pheno  \n",
       "0           0           0           0           0      0  \n",
       "1           0           0           0           0      0  \n",
       "2           0           0           0           0      1  \n",
       "3           0           0           0           0      0  \n",
       "4           0           0           0           0      0  \n",
       "\n",
       "[5 rows x 1090 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 1090) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 224), (1, 224), (2, 224)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS265     1\n",
       "1        GA984     0\n",
       "2       NRS119     0\n",
       "3       NRS249     1\n",
       "4       NRS255     2\n",
       "..         ...   ...\n",
       "197     NRS035     1\n",
       "198     NRS387     1\n",
       "199     NRS222     0\n",
       "200  BCH-SA-11     1\n",
       "201     NRS148     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 326us/step - loss: 0.9164 - accuracy: 0.5745 - val_loss: 0.5625 - val_accuracy: 0.7723\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.5039 - accuracy: 0.7979 - val_loss: 0.4387 - val_accuracy: 0.8218\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.3977 - accuracy: 0.8468 - val_loss: 0.3746 - val_accuracy: 0.8713\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.3312 - accuracy: 0.8936 - val_loss: 0.3336 - val_accuracy: 0.8713\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.2997 - accuracy: 0.9043 - val_loss: 0.3163 - val_accuracy: 0.8663\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.2607 - accuracy: 0.9170 - val_loss: 0.3354 - val_accuracy: 0.8465\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.2436 - accuracy: 0.9191 - val_loss: 0.2819 - val_accuracy: 0.8713\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.2264 - accuracy: 0.9298 - val_loss: 0.2491 - val_accuracy: 0.8960\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.1960 - accuracy: 0.9426 - val_loss: 0.2376 - val_accuracy: 0.9010\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.1804 - accuracy: 0.9596 - val_loss: 0.2441 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.1552 - accuracy: 0.9660 - val_loss: 0.2210 - val_accuracy: 0.8960\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.1508 - accuracy: 0.9532 - val_loss: 0.1985 - val_accuracy: 0.9257\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1325 - accuracy: 0.9638 - val_loss: 0.1952 - val_accuracy: 0.8911\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.1338 - accuracy: 0.9511 - val_loss: 0.1981 - val_accuracy: 0.9257\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.1224 - accuracy: 0.9723 - val_loss: 0.1697 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.1044 - accuracy: 0.9872 - val_loss: 0.1615 - val_accuracy: 0.9554\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0966 - accuracy: 0.9851 - val_loss: 0.1901 - val_accuracy: 0.9257\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0888 - accuracy: 0.9872 - val_loss: 0.1553 - val_accuracy: 0.9455\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0890 - accuracy: 0.9915 - val_loss: 0.1637 - val_accuracy: 0.9406\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0829 - accuracy: 0.9851 - val_loss: 0.2110 - val_accuracy: 0.9257\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0744 - accuracy: 0.9894 - val_loss: 0.1581 - val_accuracy: 0.9406\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0672 - accuracy: 0.9915 - val_loss: 0.1994 - val_accuracy: 0.9257\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.0650 - accuracy: 0.9894 - val_loss: 0.1826 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 299us/step - loss: 0.0624 - accuracy: 0.9872 - val_loss: 0.1491 - val_accuracy: 0.9505\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.0586 - accuracy: 0.9915 - val_loss: 0.1269 - val_accuracy: 0.9703\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.0520 - accuracy: 0.9936 - val_loss: 0.1624 - val_accuracy: 0.9406\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0495 - accuracy: 0.9915 - val_loss: 0.1327 - val_accuracy: 0.9554\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.0465 - accuracy: 0.9936 - val_loss: 0.1616 - val_accuracy: 0.9406\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0448 - accuracy: 0.9936 - val_loss: 0.1824 - val_accuracy: 0.9406\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0480 - accuracy: 0.9915 - val_loss: 0.2143 - val_accuracy: 0.9356\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 0.1469 - val_accuracy: 0.9505\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.0433 - accuracy: 0.9915 - val_loss: 0.1564 - val_accuracy: 0.9455\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.0408 - accuracy: 0.9936 - val_loss: 0.1494 - val_accuracy: 0.9505\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0340 - accuracy: 0.9936 - val_loss: 0.1326 - val_accuracy: 0.9554\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0345 - accuracy: 0.9957 - val_loss: 0.1507 - val_accuracy: 0.9505\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0303 - accuracy: 0.9957 - val_loss: 0.1646 - val_accuracy: 0.9455\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.0296 - accuracy: 0.9936 - val_loss: 0.1152 - val_accuracy: 0.9703\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.0399 - accuracy: 0.9936 - val_loss: 0.1244 - val_accuracy: 0.9604\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.1118 - val_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.0284 - accuracy: 0.9936 - val_loss: 0.1350 - val_accuracy: 0.9653\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0272 - accuracy: 0.9979 - val_loss: 0.1383 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.0260 - accuracy: 0.9957 - val_loss: 0.1366 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.0278 - accuracy: 0.9957 - val_loss: 0.1337 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.1480 - val_accuracy: 0.9554\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0197 - accuracy: 0.9979 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.2106 - val_accuracy: 0.9406\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0220 - accuracy: 0.9957 - val_loss: 0.1484 - val_accuracy: 0.9554\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.1189 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.0211 - accuracy: 0.9979 - val_loss: 0.1629 - val_accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 312us/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.1563 - val_accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 0.1445 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.1785 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.1327 - val_accuracy: 0.9653\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 316us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9406\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.2286 - val_accuracy: 0.9356\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.0181 - accuracy: 0.9957 - val_loss: 0.1330 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1304 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.1402 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.1991 - val_accuracy: 0.9455\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.1960 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0189 - accuracy: 0.9979 - val_loss: 0.1792 - val_accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.1066 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 0.0242 - accuracy: 0.9957 - val_loss: 0.1022 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.2148 - val_accuracy: 0.9455\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1561 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 298us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9406\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9505\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9406\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9604\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9554\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36b914e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 119us/step\n",
      "over-sampling test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 2, 2, 2, 0,\n",
       "       0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 2, 1, 2, 1, 2, 1, 2, 0, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0,\n",
       "       2, 1, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 1, 1, 2, 0, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 0, 2,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
       "       1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS265     1     1\n",
       "1        GA984     0     0\n",
       "2       NRS119     0     0\n",
       "3       NRS249     1     1\n",
       "4       NRS255     2     2\n",
       "..         ...   ...   ...\n",
       "197     NRS035     1     1\n",
       "198     NRS387     1     1\n",
       "199     NRS222     0     0\n",
       "200  BCH-SA-11     1     1\n",
       "201     NRS148     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.285770e-04</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>4.354483e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999979e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.910657e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.995348e-01</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>4.638188e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.523895e-03</td>\n",
       "      <td>0.994476</td>\n",
       "      <td>9.884415e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.970241e-06</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>9.997938e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.956496e-03</td>\n",
       "      <td>0.997029</td>\n",
       "      <td>1.015072e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5.211424e-03</td>\n",
       "      <td>0.994770</td>\n",
       "      <td>1.875819e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9.999911e-01</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.052898e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.581237e-02</td>\n",
       "      <td>0.984188</td>\n",
       "      <td>3.957302e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.244065e-07</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>9.978313e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    5.285770e-04  0.999036  4.354483e-04\n",
       "1    9.999979e-01  0.000002  2.910657e-10\n",
       "2    9.995348e-01  0.000465  4.638188e-13\n",
       "3    5.523895e-03  0.994476  9.884415e-09\n",
       "4    3.970241e-06  0.000202  9.997938e-01\n",
       "..            ...       ...           ...\n",
       "197  1.956496e-03  0.997029  1.015072e-03\n",
       "198  5.211424e-03  0.994770  1.875819e-05\n",
       "199  9.999911e-01  0.000009  1.052898e-09\n",
       "200  1.581237e-02  0.984188  3.957302e-10\n",
       "201  1.244065e-07  0.002169  9.978313e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9554\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9604\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9604\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9604\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9604\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9604\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9604\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9554\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9604\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9604\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9604\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9604\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9604\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9604\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9604\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9604\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 493us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9604\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 483us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9604\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9604\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 370us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 350us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 601us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 287us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 9.8930e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 9.8337e-04 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9604\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 9.8282e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 9.4089e-04 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 9.5421e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 9.3612e-04 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 390us/step - loss: 9.4603e-04 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 396us/step - loss: 8.9736e-04 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 8.7538e-04 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 8.5739e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 8.5939e-04 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 8.3568e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 8.1223e-04 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 8.1906e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 8.1647e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 8.0622e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 7.9766e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 7.7595e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 7.7712e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 7.4223e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 7.3329e-04 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9604\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 7.2977e-04 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 7.8570e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 7.3579e-04 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 6.8260e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 6.7193e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 6.5821e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 6.6766e-04 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9604\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 6.4908e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 6.4904e-04 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 6.2891e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 6.3773e-04 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 350us/step - loss: 6.1508e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9604\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 377us/step - loss: 6.1124e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 451us/step - loss: 6.2735e-04 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 293us/step - loss: 5.9687e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 5.9492e-04 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 580us/step - loss: 5.9072e-04 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 5.6690e-04 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 269us/step - loss: 5.8682e-04 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 5.5645e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 5.6737e-04 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 5.4192e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 5.2842e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 5.2983e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.28576960e-04, 9.99036100e-01, 4.35448280e-04],\n",
       "       [9.99997850e-01, 2.13410570e-06, 2.91065700e-10],\n",
       "       [9.99534850e-01, 4.65188260e-04, 4.63818800e-13],\n",
       "       [5.52389500e-03, 9.94476140e-01, 9.88441500e-09],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [4.92807200e-04, 9.99507200e-01, 1.81465720e-08],\n",
       "       [5.64873600e-04, 9.83086350e-01, 1.63487620e-02],\n",
       "       [1.38570110e-02, 9.86120200e-01, 2.27580700e-05],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [9.99372540e-01, 6.27344000e-04, 1.44910360e-07],\n",
       "       [9.87894200e-03, 9.90121100e-01, 1.14227430e-09],\n",
       "       [9.99950500e-01, 4.94118030e-05, 1.90908990e-13],\n",
       "       [5.21142800e-03, 9.94769900e-01, 1.87581700e-05],\n",
       "       [9.99994900e-01, 5.08587530e-06, 3.79110880e-09],\n",
       "       [9.95335900e-04, 9.98410000e-01, 5.94596150e-04],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [9.93308540e-01, 6.69149450e-03, 1.96822040e-11],\n",
       "       [9.99961730e-01, 3.79842420e-05, 2.70684040e-07],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.99116600e-01, 8.83252700e-04, 1.28995550e-07],\n",
       "       [1.00000000e+00, 3.84085200e-10, 7.41628600e-13],\n",
       "       [1.00000000e+00, 2.10731880e-08, 1.65459800e-17],\n",
       "       [8.49018500e-04, 9.99110300e-01, 4.06985130e-05],\n",
       "       [4.92807200e-04, 9.99507200e-01, 1.81465720e-08],\n",
       "       [2.70001680e-02, 9.51278750e-01, 2.17211540e-02],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [1.53745390e-02, 9.84337500e-01, 2.87986540e-04],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.99995950e-01, 4.02993300e-06, 3.88289760e-09],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [8.21912200e-01, 1.78087800e-01, 1.41761220e-11],\n",
       "       [9.93983800e-01, 6.01608030e-03, 1.07855210e-07],\n",
       "       [9.99993700e-01, 6.33865400e-06, 2.40141860e-08],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [1.58123410e-02, 9.84187600e-01, 3.95730900e-10],\n",
       "       [9.98102500e-01, 1.89394730e-03, 3.52318800e-06],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [5.86794400e-03, 9.94132100e-01, 1.06681570e-09],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [4.92807200e-04, 9.99507200e-01, 1.81465720e-08],\n",
       "       [8.05204550e-03, 9.91939000e-01, 8.95308800e-06],\n",
       "       [2.11814700e-03, 9.97832360e-01, 4.94818050e-05],\n",
       "       [5.28127400e-05, 9.99899500e-01, 4.76202370e-05],\n",
       "       [2.06115170e-03, 9.97842100e-01, 9.66586500e-05],\n",
       "       [4.54987200e-03, 9.95073740e-01, 3.76411540e-04],\n",
       "       [9.99670150e-01, 3.29857280e-04, 6.57474000e-13],\n",
       "       [5.28127400e-05, 9.99899500e-01, 4.76202370e-05],\n",
       "       [1.58123410e-02, 9.84187600e-01, 3.95730900e-10],\n",
       "       [9.87894200e-03, 9.90121100e-01, 1.14227430e-09],\n",
       "       [1.00000000e+00, 7.04607600e-11, 1.54476480e-15],\n",
       "       [9.98685200e-01, 1.31476200e-03, 5.88701400e-12],\n",
       "       [9.99960200e-01, 3.97750550e-05, 3.03978000e-13],\n",
       "       [9.99650500e-01, 3.49563200e-04, 4.58597100e-08],\n",
       "       [9.99837900e-01, 1.61783900e-04, 3.45141760e-07],\n",
       "       [9.90552900e-01, 9.43893700e-03, 8.16942600e-06],\n",
       "       [1.58123410e-02, 9.84187600e-01, 3.95730900e-10],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.93873950e-01, 6.12422400e-03, 1.93963680e-06],\n",
       "       [4.54987200e-03, 9.95073740e-01, 3.76411540e-04],\n",
       "       [8.05204550e-03, 9.91939000e-01, 8.95308800e-06],\n",
       "       [1.00000000e+00, 2.32577640e-10, 1.92644240e-13],\n",
       "       [9.91146600e-01, 8.85237400e-03, 1.10928940e-06],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [1.14908880e-03, 9.98796700e-01, 5.41657400e-05],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [5.21142800e-03, 9.94769900e-01, 1.87581700e-05],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [2.97748160e-03, 9.96790470e-01, 2.32085380e-04],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.93913700e-01, 6.08630250e-03, 1.31853390e-11],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.95335900e-04, 9.98410000e-01, 5.94596150e-04],\n",
       "       [1.01339610e-02, 9.89860900e-01, 5.10813560e-06],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.88187600e-01, 1.18113270e-02, 1.06357300e-06],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [2.57331900e-08, 9.99924300e-01, 7.57333400e-05],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [1.95649570e-03, 9.97028500e-01, 1.01507070e-03],\n",
       "       [5.28576960e-04, 9.99036100e-01, 4.35448280e-04],\n",
       "       [9.99502660e-01, 4.97333650e-04, 7.15270850e-12],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [5.64873600e-04, 9.83086350e-01, 1.63487620e-02],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.51968970e-01, 4.80288040e-02, 2.19834420e-06],\n",
       "       [1.00000000e+00, 5.99723830e-09, 3.93212900e-18],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [5.86794400e-03, 9.94132100e-01, 1.06681570e-09],\n",
       "       [3.77360200e-04, 9.99615300e-01, 7.29009340e-06],\n",
       "       [9.99257000e-01, 7.42947040e-04, 2.54910370e-08],\n",
       "       [9.99167800e-01, 8.32107900e-04, 7.06121600e-08],\n",
       "       [5.64873600e-04, 9.83086350e-01, 1.63487620e-02],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [9.99785100e-01, 2.14718330e-04, 1.34239260e-07],\n",
       "       [9.97682000e-01, 2.31795500e-03, 3.06054030e-12],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [4.90692730e-01, 5.09143900e-01, 1.63425700e-04],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [3.77360200e-04, 9.99615300e-01, 7.29009340e-06],\n",
       "       [5.28127400e-05, 9.99899500e-01, 4.76202370e-05],\n",
       "       [7.97965840e-05, 9.99909040e-01, 1.11591900e-05],\n",
       "       [2.58168180e-03, 9.97369500e-01, 4.87022840e-05],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [8.20215340e-01, 1.78890660e-01, 8.93986140e-04],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.98307600e-01, 1.69239600e-03, 2.14659250e-11],\n",
       "       [9.99967100e-01, 3.29137660e-05, 2.09103810e-08],\n",
       "       [9.89064460e-01, 1.09351620e-02, 3.38499720e-07],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.99372900e-01, 6.27093370e-04, 3.43301350e-08],\n",
       "       [9.97391600e-01, 2.60840260e-03, 1.35775330e-11],\n",
       "       [7.16976800e-03, 9.92728100e-01, 1.02159494e-04],\n",
       "       [2.58168180e-03, 9.97369500e-01, 4.87022840e-05],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.99999900e-01, 1.58424360e-07, 1.12815230e-10],\n",
       "       [1.00000000e+00, 7.40487250e-11, 2.25688800e-13],\n",
       "       [9.99978800e-01, 2.11099430e-05, 8.63553100e-08],\n",
       "       [1.95649570e-03, 9.97028500e-01, 1.01507070e-03],\n",
       "       [9.99392400e-01, 6.07504450e-04, 8.52443800e-08],\n",
       "       [4.92807200e-04, 9.99507200e-01, 1.81465720e-08],\n",
       "       [9.99954460e-01, 4.55540800e-05, 1.30410900e-08],\n",
       "       [5.28576960e-04, 9.99036100e-01, 4.35448280e-04],\n",
       "       [5.52389500e-03, 9.94476140e-01, 9.88441500e-09],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [7.97965840e-05, 9.99909040e-01, 1.11591900e-05],\n",
       "       [7.16976800e-03, 9.92728100e-01, 1.02159494e-04],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [9.99999900e-01, 1.48828320e-07, 2.58447730e-16],\n",
       "       [9.99992400e-01, 7.57880200e-06, 2.97642720e-10],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [8.05204550e-03, 9.91939000e-01, 8.95308800e-06],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [8.47373250e-03, 9.91378660e-01, 1.47666370e-04],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [7.97965840e-05, 9.99909040e-01, 1.11591900e-05],\n",
       "       [9.55730500e-01, 4.41109240e-02, 1.58628430e-04],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [2.58168180e-03, 9.97369500e-01, 4.87022840e-05],\n",
       "       [9.99993300e-01, 6.61659900e-06, 5.29823500e-09],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [1.85480080e-02, 9.81419700e-01, 3.23354000e-05],\n",
       "       [9.99965100e-01, 3.49803630e-05, 2.98232160e-08],\n",
       "       [9.99999760e-01, 2.53074700e-07, 2.10983770e-10],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.99993300e-01, 6.68687300e-06, 3.17187790e-09],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [8.55078800e-01, 1.44920650e-01, 4.83331860e-07],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [1.00000000e+00, 6.45820770e-09, 3.40171510e-18],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [8.07601700e-03, 9.91924000e-01, 5.63561860e-10],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [2.11814700e-03, 9.97832360e-01, 4.94818050e-05],\n",
       "       [3.11220270e-02, 9.68478500e-01, 3.99485550e-04],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [2.57331900e-08, 9.99924300e-01, 7.57333400e-05],\n",
       "       [2.58168180e-03, 9.97369500e-01, 4.87022840e-05],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [6.96767200e-01, 3.02848820e-01, 3.84021870e-04],\n",
       "       [5.86794400e-03, 9.94132100e-01, 1.06681570e-09],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [1.24406410e-07, 2.16863470e-03, 9.97831300e-01],\n",
       "       [9.95335900e-04, 9.98410000e-01, 5.94596150e-04],\n",
       "       [9.99850030e-01, 1.49909000e-04, 3.25763740e-08],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [3.97024100e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [7.97965840e-05, 9.99909040e-01, 1.11591900e-05],\n",
       "       [2.57331900e-08, 9.99924300e-01, 7.57333400e-05],\n",
       "       [1.38570110e-02, 9.86120200e-01, 2.27580700e-05],\n",
       "       [7.75924800e-06, 4.06410900e-05, 9.99951600e-01],\n",
       "       [8.05204550e-03, 9.91939000e-01, 8.95308800e-06],\n",
       "       [9.98950600e-01, 1.04934000e-03, 3.52711080e-13],\n",
       "       [5.84865130e-03, 9.94094430e-01, 5.68635300e-05],\n",
       "       [1.58123410e-02, 9.84187600e-01, 3.95730900e-10],\n",
       "       [3.97023720e-06, 2.02186860e-04, 9.99793800e-01],\n",
       "       [9.99943600e-01, 5.63847420e-05, 4.93813000e-13],\n",
       "       [9.95335400e-04, 9.98410000e-01, 5.94596150e-04],\n",
       "       [7.16976800e-03, 9.92728100e-01, 1.02159390e-04],\n",
       "       [9.95335400e-04, 9.98410000e-01, 5.94596150e-04],\n",
       "       [1.95649570e-03, 9.97028500e-01, 1.01507160e-03],\n",
       "       [5.21142360e-03, 9.94769900e-01, 1.87581880e-05],\n",
       "       [9.99991060e-01, 8.92170800e-06, 1.05289750e-09],\n",
       "       [1.58123650e-02, 9.84187600e-01, 3.95730170e-10],\n",
       "       [1.24406530e-07, 2.16863680e-03, 9.97831300e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915975677169707"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915975677169707"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa05     0\n",
       "1      NRS114     0\n",
       "2      NRS168     1\n",
       "3      NRS255     2\n",
       "4      NRS209     2\n",
       "..        ...   ...\n",
       "197    NRS196     0\n",
       "198    NRS255     2\n",
       "199    NRS249     1\n",
       "200    NRS209     2\n",
       "201  CFBRSa28     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 340us/step - loss: 0.7594 - accuracy: 0.6596 - val_loss: 0.5949 - val_accuracy: 0.7822\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.4520 - accuracy: 0.8255 - val_loss: 0.4716 - val_accuracy: 0.8168\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.3519 - accuracy: 0.8617 - val_loss: 0.4032 - val_accuracy: 0.8416\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.2971 - accuracy: 0.8936 - val_loss: 0.3663 - val_accuracy: 0.8663\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.2450 - accuracy: 0.9213 - val_loss: 0.3200 - val_accuracy: 0.9059\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.2160 - accuracy: 0.9319 - val_loss: 0.2998 - val_accuracy: 0.8366\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.1982 - accuracy: 0.9426 - val_loss: 0.2591 - val_accuracy: 0.9208\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.1694 - accuracy: 0.9532 - val_loss: 0.2673 - val_accuracy: 0.9059\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1525 - accuracy: 0.9596 - val_loss: 0.2497 - val_accuracy: 0.9158\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1355 - accuracy: 0.9702 - val_loss: 0.2422 - val_accuracy: 0.9109\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1293 - accuracy: 0.9617 - val_loss: 0.2207 - val_accuracy: 0.9158\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.1181 - accuracy: 0.9681 - val_loss: 0.1917 - val_accuracy: 0.9505\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.1247 - accuracy: 0.9617 - val_loss: 0.1998 - val_accuracy: 0.9307\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.1029 - accuracy: 0.9702 - val_loss: 0.2088 - val_accuracy: 0.9455\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0826 - accuracy: 0.9851 - val_loss: 0.1988 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0764 - accuracy: 0.9915 - val_loss: 0.1926 - val_accuracy: 0.9455\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0724 - accuracy: 0.9894 - val_loss: 0.1945 - val_accuracy: 0.9406\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0643 - accuracy: 0.9915 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0627 - accuracy: 0.9915 - val_loss: 0.2036 - val_accuracy: 0.9406\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0592 - accuracy: 0.9936 - val_loss: 0.1814 - val_accuracy: 0.9554\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0746 - accuracy: 0.9872 - val_loss: 0.2118 - val_accuracy: 0.9010\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0667 - accuracy: 0.9851 - val_loss: 0.1662 - val_accuracy: 0.9505\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0548 - accuracy: 0.9936 - val_loss: 0.2099 - val_accuracy: 0.9406\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0566 - accuracy: 0.9915 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0600 - accuracy: 0.9872 - val_loss: 0.1672 - val_accuracy: 0.9455\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0450 - accuracy: 0.9936 - val_loss: 0.1579 - val_accuracy: 0.9505\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0432 - accuracy: 0.9936 - val_loss: 0.1550 - val_accuracy: 0.9455\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0419 - accuracy: 0.9936 - val_loss: 0.1694 - val_accuracy: 0.9505\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0334 - accuracy: 0.9936 - val_loss: 0.1726 - val_accuracy: 0.9455\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0420 - accuracy: 0.9915 - val_loss: 0.2133 - val_accuracy: 0.9406\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0382 - accuracy: 0.9936 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0353 - accuracy: 0.9936 - val_loss: 0.2208 - val_accuracy: 0.9406\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0296 - accuracy: 0.9936 - val_loss: 0.1608 - val_accuracy: 0.9554\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 359us/step - loss: 0.0324 - accuracy: 0.9936 - val_loss: 0.1484 - val_accuracy: 0.9455\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0361 - accuracy: 0.9936 - val_loss: 0.1784 - val_accuracy: 0.9455\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.2322 - val_accuracy: 0.9406\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 0.1770 - val_accuracy: 0.9554\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0337 - accuracy: 0.9957 - val_loss: 0.1446 - val_accuracy: 0.9505\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0366 - accuracy: 0.9894 - val_loss: 0.1674 - val_accuracy: 0.9554\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0383 - accuracy: 0.9915 - val_loss: 0.1504 - val_accuracy: 0.9307\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0248 - accuracy: 0.9957 - val_loss: 0.1606 - val_accuracy: 0.9505\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.2128 - val_accuracy: 0.9455\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.1502 - val_accuracy: 0.9505\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.1450 - val_accuracy: 0.9505\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0361 - accuracy: 0.9915 - val_loss: 0.1985 - val_accuracy: 0.9455\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.2140 - val_accuracy: 0.9455\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.1430 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 0.1522 - val_accuracy: 0.9505\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0285 - accuracy: 0.9957 - val_loss: 0.1983 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0274 - accuracy: 0.9979 - val_loss: 0.2661 - val_accuracy: 0.9356\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0283 - accuracy: 0.9957 - val_loss: 0.2762 - val_accuracy: 0.9356\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.1677 - val_accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.1607 - val_accuracy: 0.9505\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 0.1760 - val_accuracy: 0.9505\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.1576 - val_accuracy: 0.9505\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0360 - accuracy: 0.9851 - val_loss: 0.2418 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0149 - accuracy: 0.9979 - val_loss: 0.2100 - val_accuracy: 0.9505\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.2408 - val_accuracy: 0.9406\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 0.2056 - val_accuracy: 0.9505\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.1889 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.1613 - val_accuracy: 0.9505\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0142 - accuracy: 0.9936 - val_loss: 0.2077 - val_accuracy: 0.9455\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 116us/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.2063 - val_accuracy: 0.9505\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.1923 - val_accuracy: 0.9505\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.2607 - val_accuracy: 0.9406\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0143 - accuracy: 0.9979 - val_loss: 0.1255 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0159 - accuracy: 0.9957 - val_loss: 0.2166 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.1864 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0133 - accuracy: 0.9979 - val_loss: 0.2680 - val_accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.1899 - val_accuracy: 0.9505\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.1492 - val_accuracy: 0.9505\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.1733 - val_accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0145 - accuracy: 0.9936 - val_loss: 0.1439 - val_accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0171 - accuracy: 0.9979 - val_loss: 0.2062 - val_accuracy: 0.9455\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.1813 - val_accuracy: 0.9505\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9406\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.1766 - val_accuracy: 0.9505\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.2124 - val_accuracy: 0.9505\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1962 - val_accuracy: 0.9505\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.2046 - val_accuracy: 0.9505\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.1556 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.0185 - accuracy: 0.9979 - val_loss: 0.1517 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 285us/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.2585 - val_accuracy: 0.9356\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.1941 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9505\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0068 - accuracy: 0.9957 - val_loss: 0.1683 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0148 - accuracy: 0.9936 - val_loss: 0.1856 - val_accuracy: 0.9505\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 320us/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1768 - val_accuracy: 0.9505\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 307us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2317 - val_accuracy: 0.9455\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.1677 - val_accuracy: 0.9505\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.2585 - val_accuracy: 0.9455\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0169 - accuracy: 0.9936 - val_loss: 0.1658 - val_accuracy: 0.9455\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9455\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 322us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1515 - val_accuracy: 0.9505\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9455\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1643 - val_accuracy: 0.9554\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9406\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.2408 - val_accuracy: 0.9455\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.2273 - val_accuracy: 0.9505\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.1737 - val_accuracy: 0.9554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a371b9320>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 128us/step\n",
      "over-sampling test accuracy: 94.55%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 2, 1, 2, 2, 2,\n",
       "       0, 2, 0, 1, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0,\n",
       "       2, 0, 1, 2, 2, 2, 1, 0, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 1, 0, 1, 1,\n",
       "       1, 2, 1, 2, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "       1, 2, 0, 1, 2, 1, 0, 1, 0, 2, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 1, 0,\n",
       "       2, 0, 1, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 1, 0, 1, 2, 2, 2,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 2, 1,\n",
       "       1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 2, 2, 1, 0,\n",
       "       2, 1, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa05     0     0\n",
       "1      NRS114     0     0\n",
       "2      NRS168     1     1\n",
       "3      NRS255     2     2\n",
       "4      NRS209     2     2\n",
       "..        ...   ...   ...\n",
       "197    NRS196     0     0\n",
       "198    NRS255     2     2\n",
       "199    NRS249     1     1\n",
       "200    NRS209     2     2\n",
       "201  CFBRSa28     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.643428e-07</td>\n",
       "      <td>5.775328e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999949</td>\n",
       "      <td>5.072287e-05</td>\n",
       "      <td>8.993385e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071051</td>\n",
       "      <td>9.283946e-01</td>\n",
       "      <td>5.545159e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>2.764877e-05</td>\n",
       "      <td>9.998754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.668140e-05</td>\n",
       "      <td>9.999214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.999568</td>\n",
       "      <td>4.305906e-04</td>\n",
       "      <td>1.676442e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>2.764872e-05</td>\n",
       "      <td>9.998754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.042857</td>\n",
       "      <td>9.571427e-01</td>\n",
       "      <td>6.215257e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>7.668147e-05</td>\n",
       "      <td>9.999214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>4.521418e-08</td>\n",
       "      <td>1.359151e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0             1             2\n",
       "0    1.000000  1.643428e-07  5.775328e-08\n",
       "1    0.999949  5.072287e-05  8.993385e-09\n",
       "2    0.071051  9.283946e-01  5.545159e-04\n",
       "3    0.000097  2.764877e-05  9.998754e-01\n",
       "4    0.000002  7.668140e-05  9.999214e-01\n",
       "..        ...           ...           ...\n",
       "197  0.999568  4.305906e-04  1.676442e-06\n",
       "198  0.000097  2.764872e-05  9.998754e-01\n",
       "199  0.042857  9.571427e-01  6.215257e-07\n",
       "200  0.000002  7.668147e-05  9.999214e-01\n",
       "201  0.999999  4.521418e-08  1.359151e-06\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1531 - val_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1934 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9604\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2495 - val_accuracy: 0.9406\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.1854 - val_accuracy: 0.9604\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.1631 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.1742 - val_accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0160 - accuracy: 0.9915 - val_loss: 0.2783 - val_accuracy: 0.9455\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0092 - accuracy: 0.9957 - val_loss: 0.1586 - val_accuracy: 0.9604\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.2292 - val_accuracy: 0.9554\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.2165 - val_accuracy: 0.9554\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9554\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3579 - val_accuracy: 0.9307\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0165 - accuracy: 0.9979 - val_loss: 0.1506 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9554\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 318us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9554\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9554\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9554\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9554\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9554\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.1674 - val_accuracy: 0.9554\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9554\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9554\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9554\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 276us/step - loss: 0.0037 - accuracy: 0.9979 - val_loss: 0.1622 - val_accuracy: 0.9554\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9554\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.1578 - val_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 291us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2431 - val_accuracy: 0.9455\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 837us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9554\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 457us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9505\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 334us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9554\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.0036 - accuracy: 0.9979 - val_loss: 0.1502 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.2127 - val_accuracy: 0.9554\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9554\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9554\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9455\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.2151 - val_accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9554\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9505\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9554\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 354us/step - loss: 0.0060 - accuracy: 0.9957 - val_loss: 0.1674 - val_accuracy: 0.9554\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 361us/step - loss: 0.0680 - accuracy: 0.9766 - val_loss: 0.3652 - val_accuracy: 0.9455\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.0943 - accuracy: 0.9638 - val_loss: 0.4161 - val_accuracy: 0.9356\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 285us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.2619 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 422us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9356\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 276us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9455\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9554\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 314us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9455\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9554\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9554\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9554\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 377us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9554\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 285us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9554\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9554\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9554\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9554\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9554\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9554\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9554\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9505\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9554\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9554\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 9.6286e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9554\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 9.7854e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999900e-01, 1.64342810e-07, 5.77532760e-08],\n",
       "       [9.99949200e-01, 5.07228700e-05, 8.99338500e-09],\n",
       "       [7.10509050e-02, 9.28394600e-01, 5.54515900e-04],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.57064100e-04, 9.98357100e-01, 6.85767560e-04],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.99999640e-01, 2.41265700e-07, 1.03096234e-07],\n",
       "       [1.74968410e-03, 9.98245360e-01, 5.04387600e-06],\n",
       "       [9.99997600e-01, 2.23030360e-06, 1.45069320e-07],\n",
       "       [9.99962700e-01, 1.59491570e-05, 2.13460150e-05],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [7.10509050e-02, 9.28394600e-01, 5.54515900e-04],\n",
       "       [9.99961850e-01, 3.76090900e-05, 6.27830050e-07],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [2.24068610e-02, 9.77593060e-01, 2.03711200e-09],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99996300e-01, 3.57463730e-06, 9.38637900e-08],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.99998700e-01, 1.01301520e-06, 4.02006520e-07],\n",
       "       [1.66852640e-02, 9.83314630e-01, 1.30366860e-07],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99948500e-01, 5.14714100e-05, 1.12995770e-09],\n",
       "       [1.39582520e-03, 9.98598900e-01, 5.31714840e-06],\n",
       "       [1.00000000e+00, 1.47744440e-08, 1.39532680e-10],\n",
       "       [9.98946700e-01, 1.04509210e-03, 8.22812400e-06],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [2.52075100e-03, 9.97470500e-01, 8.83173500e-06],\n",
       "       [9.99999760e-01, 6.16510000e-08, 9.74531200e-08],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [5.11690400e-03, 9.94729100e-01, 1.54033290e-04],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [9.99994040e-01, 5.99216900e-06, 5.47498700e-10],\n",
       "       [3.63198330e-02, 9.63680000e-01, 1.49217020e-07],\n",
       "       [9.98046160e-01, 1.95035480e-03, 3.48907840e-06],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.98155300e-01, 1.83855160e-03, 6.16209760e-06],\n",
       "       [4.05648430e-02, 9.45437430e-01, 1.39977130e-02],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [3.06592290e-02, 9.68641160e-01, 6.99640900e-04],\n",
       "       [9.99955650e-01, 4.13864330e-05, 2.99749130e-06],\n",
       "       [9.99952100e-01, 4.74433200e-05, 5.29248270e-07],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [2.15638500e-02, 9.78329240e-01, 1.06785960e-04],\n",
       "       [4.28567680e-02, 9.57142650e-01, 6.21526200e-07],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.99999640e-01, 1.60768410e-10, 3.44290530e-07],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99999900e-01, 9.49897650e-08, 2.87384360e-08],\n",
       "       [9.99488950e-01, 5.09625770e-04, 1.47326700e-06],\n",
       "       [1.43635480e-04, 9.78642460e-01, 2.12139790e-02],\n",
       "       [7.24971700e-01, 2.75028140e-01, 1.28095600e-07],\n",
       "       [3.63198330e-02, 9.63680000e-01, 1.49217020e-07],\n",
       "       [3.06592290e-02, 9.68641160e-01, 6.99640900e-04],\n",
       "       [7.10509050e-02, 9.28394600e-01, 5.54515900e-04],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [4.01859430e-02, 9.59736000e-01, 7.80331900e-05],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.99248560e-01, 7.38327740e-04, 1.31414820e-05],\n",
       "       [5.11690400e-03, 9.94729100e-01, 1.54033290e-04],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [9.99084350e-01, 9.14433500e-04, 1.18833620e-06],\n",
       "       [9.73751000e-01, 2.62472720e-02, 1.70390840e-06],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [9.57064100e-04, 9.98357100e-01, 6.85767560e-04],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [1.74968410e-03, 9.98245360e-01, 5.04387600e-06],\n",
       "       [3.06592290e-02, 9.68641160e-01, 6.99640900e-04],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [1.00000000e+00, 1.78176930e-10, 1.72852100e-11],\n",
       "       [9.99889730e-01, 1.10303095e-04, 1.07022840e-10],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [9.99854200e-01, 1.43865200e-04, 1.87257670e-06],\n",
       "       [9.81062600e-01, 1.89373740e-02, 1.50215940e-09],\n",
       "       [6.65591700e-04, 9.99314070e-01, 2.03868100e-05],\n",
       "       [1.22945820e-06, 9.99997500e-01, 1.34640210e-06],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99999900e-01, 3.42940640e-08, 1.34441340e-07],\n",
       "       [6.65591700e-04, 9.99314070e-01, 2.03868100e-05],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [2.14023570e-02, 9.78593800e-01, 3.79511080e-06],\n",
       "       [7.79454000e-01, 1.91185120e-01, 2.93608350e-02],\n",
       "       [9.57064100e-04, 9.98357100e-01, 6.85767560e-04],\n",
       "       [1.00000000e+00, 5.49902350e-08, 3.72754520e-08],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [1.00000000e+00, 4.07533560e-11, 9.29629400e-12],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [3.06592290e-02, 9.68641160e-01, 6.99640900e-04],\n",
       "       [3.63198330e-02, 9.63680000e-01, 1.49217020e-07],\n",
       "       [1.66852640e-02, 9.83314630e-01, 1.30366860e-07],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [2.14023570e-02, 9.78593800e-01, 3.79511080e-06],\n",
       "       [9.99994300e-01, 5.66483900e-06, 3.77607630e-08],\n",
       "       [9.99850630e-01, 1.49325790e-04, 8.60277500e-09],\n",
       "       [2.52075100e-03, 9.97470500e-01, 8.83173500e-06],\n",
       "       [9.99681230e-01, 3.10319880e-04, 8.44290200e-06],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.97807100e-01, 2.13424980e-03, 5.86476380e-05],\n",
       "       [1.43635480e-04, 9.78642460e-01, 2.12139790e-02],\n",
       "       [3.12391950e-03, 9.96856330e-01, 1.97315130e-05],\n",
       "       [1.22945820e-06, 9.99997500e-01, 1.34640210e-06],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99989030e-01, 1.09558600e-05, 4.73249780e-08],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [1.66852640e-02, 9.83314630e-01, 1.30366860e-07],\n",
       "       [9.99995470e-01, 4.05841770e-06, 5.16966800e-07],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [3.13280820e-02, 9.68634250e-01, 3.76026600e-05],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [9.99549700e-01, 4.50311050e-04, 1.21660650e-08],\n",
       "       [2.15638500e-02, 9.78329240e-01, 1.06785960e-04],\n",
       "       [9.99926000e-01, 7.39939200e-05, 4.71037270e-11],\n",
       "       [9.98902440e-01, 1.09727110e-03, 2.48100950e-07],\n",
       "       [9.99543960e-01, 4.55831300e-04, 6.77515860e-08],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [4.28567680e-02, 9.57142650e-01, 6.21526200e-07],\n",
       "       [1.74968410e-03, 9.98245360e-01, 5.04387600e-06],\n",
       "       [1.43635480e-04, 9.78642460e-01, 2.12139790e-02],\n",
       "       [9.98956200e-01, 9.73998600e-04, 6.97649160e-05],\n",
       "       [8.73799600e-03, 9.91257800e-01, 4.28584640e-06],\n",
       "       [2.52075100e-03, 9.97470500e-01, 8.83173500e-06],\n",
       "       [1.22945820e-06, 9.99997500e-01, 1.34640210e-06],\n",
       "       [2.15638500e-02, 9.78329240e-01, 1.06785960e-04],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [9.99934200e-01, 6.57593300e-05, 5.69335360e-10],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [9.99993440e-01, 6.61397550e-06, 5.29617770e-08],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99963400e-01, 2.19998000e-05, 1.45704225e-05],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [3.30238800e-02, 9.66695130e-01, 2.81025160e-04],\n",
       "       [9.99949700e-01, 5.03465000e-05, 1.20078580e-09],\n",
       "       [6.50253600e-03, 9.93449300e-01, 4.82070250e-05],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [9.99922400e-01, 7.52605200e-05, 2.35582070e-06],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [4.28567680e-02, 9.57142650e-01, 6.21526200e-07],\n",
       "       [9.55368700e-03, 9.90396860e-01, 4.94381800e-05],\n",
       "       [9.99897600e-01, 1.02280035e-04, 6.62262500e-08],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.75247420e-05, 7.76682630e-04, 9.99205770e-01],\n",
       "       [6.50253600e-03, 9.93449300e-01, 4.82070250e-05],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [9.99751750e-01, 2.48182040e-04, 1.38148650e-07],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.39582520e-03, 9.98598900e-01, 5.31714840e-06],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99869800e-01, 1.29587740e-04, 5.41264340e-07],\n",
       "       [9.99995350e-01, 4.14270330e-06, 4.93426300e-07],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [9.99999760e-01, 3.76698100e-09, 2.69448520e-07],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [4.28567680e-02, 9.57142650e-01, 6.21526200e-07],\n",
       "       [1.09792120e-03, 9.98531460e-01, 3.70510740e-04],\n",
       "       [8.10670200e-04, 9.99108500e-01, 8.09128800e-05],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [7.17522630e-04, 9.99281600e-01, 9.88499800e-07],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [9.95502530e-01, 4.49751800e-03, 3.55951020e-10],\n",
       "       [2.86555980e-01, 7.13443930e-01, 7.17994060e-08],\n",
       "       [9.99993440e-01, 6.61397550e-06, 5.29617770e-08],\n",
       "       [1.39582520e-03, 9.98598900e-01, 5.31714840e-06],\n",
       "       [9.69614340e-05, 2.76487680e-05, 9.99875400e-01],\n",
       "       [3.69149100e-01, 6.30629100e-01, 2.21796580e-04],\n",
       "       [1.82985890e-06, 7.66814000e-05, 9.99921440e-01],\n",
       "       [2.14023570e-02, 9.78593800e-01, 3.79511080e-06],\n",
       "       [3.74485160e-03, 9.96251400e-01, 3.76891330e-06],\n",
       "       [9.99880300e-01, 1.15229040e-04, 4.41811970e-06],\n",
       "       [9.98268100e-01, 1.73174790e-03, 1.31019330e-07],\n",
       "       [3.49584820e-01, 6.50383500e-01, 3.16821350e-05],\n",
       "       [1.43635480e-04, 9.78642460e-01, 2.12139750e-02],\n",
       "       [1.82985890e-06, 7.66814700e-05, 9.99921440e-01],\n",
       "       [1.82985890e-06, 7.66814700e-05, 9.99921440e-01],\n",
       "       [2.14023720e-02, 9.78593800e-01, 3.79511450e-06],\n",
       "       [9.99567700e-01, 4.30590620e-04, 1.67644160e-06],\n",
       "       [9.69612500e-05, 2.76487150e-05, 9.99875400e-01],\n",
       "       [4.28567750e-02, 9.57142650e-01, 6.21525660e-07],\n",
       "       [1.82985890e-06, 7.66814700e-05, 9.99921440e-01],\n",
       "       [9.99998700e-01, 4.52141800e-08, 1.35915120e-06]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874050228162022"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874050228162022"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS148     2\n",
       "1         NRS209     2\n",
       "2         NRS187     1\n",
       "3    CFBREBSa116     0\n",
       "4         NRS187     1\n",
       "..           ...   ...\n",
       "197         GA12     0\n",
       "198       NRS209     2\n",
       "199       NRS265     1\n",
       "200       NRS253     1\n",
       "201       SR4187     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 402us/step - loss: 0.7325 - accuracy: 0.6447 - val_loss: 0.5086 - val_accuracy: 0.8069\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.4500 - accuracy: 0.8000 - val_loss: 0.4377 - val_accuracy: 0.8119\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.3688 - accuracy: 0.8617 - val_loss: 0.3770 - val_accuracy: 0.8218\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.3200 - accuracy: 0.8745 - val_loss: 0.3180 - val_accuracy: 0.8564\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.2743 - accuracy: 0.8979 - val_loss: 0.2832 - val_accuracy: 0.9059\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.2433 - accuracy: 0.9277 - val_loss: 0.2845 - val_accuracy: 0.8911\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.2460 - accuracy: 0.9191 - val_loss: 0.2449 - val_accuracy: 0.9505\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 310us/step - loss: 0.1999 - accuracy: 0.9319 - val_loss: 0.2258 - val_accuracy: 0.8911\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.1964 - accuracy: 0.9319 - val_loss: 0.2640 - val_accuracy: 0.8564\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.1778 - accuracy: 0.9511 - val_loss: 0.1742 - val_accuracy: 0.9455\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 0.1401 - accuracy: 0.9681 - val_loss: 0.1900 - val_accuracy: 0.9208\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.1357 - accuracy: 0.9681 - val_loss: 0.1657 - val_accuracy: 0.9406\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.1224 - accuracy: 0.9809 - val_loss: 0.2106 - val_accuracy: 0.8812\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.1481 - accuracy: 0.9660 - val_loss: 0.1406 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1123 - accuracy: 0.9681 - val_loss: 0.1338 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0954 - accuracy: 0.9702 - val_loss: 0.1238 - val_accuracy: 0.9505\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 412us/step - loss: 0.0892 - accuracy: 0.9851 - val_loss: 0.1279 - val_accuracy: 0.9653\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.0847 - accuracy: 0.9766 - val_loss: 0.1123 - val_accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.0836 - accuracy: 0.9872 - val_loss: 0.1105 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 368us/step - loss: 0.0773 - accuracy: 0.9830 - val_loss: 0.1042 - val_accuracy: 0.9703\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.0714 - accuracy: 0.9809 - val_loss: 0.1022 - val_accuracy: 0.9703\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 366us/step - loss: 0.0625 - accuracy: 0.9957 - val_loss: 0.0991 - val_accuracy: 0.9703\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.0637 - accuracy: 0.9957 - val_loss: 0.0914 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.0671 - accuracy: 0.9872 - val_loss: 0.0926 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0770 - accuracy: 0.9702 - val_loss: 0.1648 - val_accuracy: 0.9554\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0853 - accuracy: 0.9723 - val_loss: 0.1496 - val_accuracy: 0.9505\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 327us/step - loss: 0.0603 - accuracy: 0.9894 - val_loss: 0.0903 - val_accuracy: 0.9703\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 0.0455 - accuracy: 0.9957 - val_loss: 0.0895 - val_accuracy: 0.9703\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0440 - accuracy: 0.9957 - val_loss: 0.0766 - val_accuracy: 0.9752\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0427 - accuracy: 0.9936 - val_loss: 0.0729 - val_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0387 - accuracy: 0.9936 - val_loss: 0.0813 - val_accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0443 - accuracy: 0.9936 - val_loss: 0.0759 - val_accuracy: 0.9752\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0412 - accuracy: 0.9957 - val_loss: 0.0880 - val_accuracy: 0.9703\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0348 - accuracy: 0.9957 - val_loss: 0.0725 - val_accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0366 - accuracy: 0.9957 - val_loss: 0.0728 - val_accuracy: 0.9752\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.0382 - accuracy: 0.9957 - val_loss: 0.0697 - val_accuracy: 0.9752\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.0322 - accuracy: 0.9957 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0348 - accuracy: 0.9957 - val_loss: 0.0679 - val_accuracy: 0.9901\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0295 - accuracy: 0.9957 - val_loss: 0.0892 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0299 - accuracy: 0.9936 - val_loss: 0.0592 - val_accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0281 - accuracy: 0.9957 - val_loss: 0.0675 - val_accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0267 - accuracy: 0.9957 - val_loss: 0.0586 - val_accuracy: 0.9802\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0292 - accuracy: 0.9957 - val_loss: 0.0703 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.0252 - accuracy: 0.9957 - val_loss: 0.1121 - val_accuracy: 0.9604\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.0286 - accuracy: 0.9957 - val_loss: 0.1082 - val_accuracy: 0.9703\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0303 - accuracy: 0.9957 - val_loss: 0.0657 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0224 - accuracy: 0.9957 - val_loss: 0.0849 - val_accuracy: 0.9703\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0237 - accuracy: 0.9957 - val_loss: 0.0648 - val_accuracy: 0.9752\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.0523 - val_accuracy: 0.9851\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.1157 - val_accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.1041 - val_accuracy: 0.9703\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0246 - accuracy: 0.9979 - val_loss: 0.0523 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.0533 - val_accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0514 - val_accuracy: 0.9802\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0211 - accuracy: 0.9957 - val_loss: 0.1066 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.0547 - val_accuracy: 0.9802\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.0453 - val_accuracy: 0.9901\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0171 - accuracy: 0.9979 - val_loss: 0.0615 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.0460 - val_accuracy: 0.9802\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0189 - accuracy: 0.9979 - val_loss: 0.0446 - val_accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0240 - accuracy: 0.9979 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.1343 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0264 - accuracy: 0.9957 - val_loss: 0.0887 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.0469 - val_accuracy: 0.9950\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.0692 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.0506 - val_accuracy: 0.9802\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0507 - val_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0440 - val_accuracy: 0.9851\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9703\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0645 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0631 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.0401 - val_accuracy: 0.9901\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9703\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.0920 - val_accuracy: 0.9703\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0516 - val_accuracy: 0.9851\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0139 - accuracy: 0.9979 - val_loss: 0.0886 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0435 - val_accuracy: 0.9802\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.0381 - val_accuracy: 0.9851\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 375us/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0461 - val_accuracy: 0.9802\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9703\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0517 - val_accuracy: 0.9802\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0398 - val_accuracy: 0.9851\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9703\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0607 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0543 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 365us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0424 - val_accuracy: 0.9802\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0470 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.0579 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9752\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0371 - val_accuracy: 0.9851\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9703\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0530 - val_accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0442 - val_accuracy: 0.9802\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0436 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a374e32b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 120us/step\n",
      "over-sampling test accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 2, 2, 1, 2, 1, 1, 0, 2, 1, 0, 1, 0, 1, 2, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2,\n",
       "       0, 1, 1, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2,\n",
       "       2, 2, 1, 0, 1, 0, 2, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1,\n",
       "       2, 2, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 2, 1, 2, 0, 1, 0, 0,\n",
       "       0, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 1, 2, 0, 2, 0, 1,\n",
       "       0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
       "       0, 2, 1, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 1, 1, 0, 2, 0,\n",
       "       1, 2, 0, 1, 0, 1, 1, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 0,\n",
       "       2, 1, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS148     2     2\n",
       "1         NRS209     2     2\n",
       "2         NRS187     1     1\n",
       "3    CFBREBSa116     0     0\n",
       "4         NRS187     1     1\n",
       "..           ...   ...   ...\n",
       "197         GA12     0     0\n",
       "198       NRS209     2     2\n",
       "199       NRS265     1     1\n",
       "200       NRS253     1     1\n",
       "201       SR4187     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.889818e-06</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>9.982117e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.162348e-08</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>9.999627e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.155065e-03</td>\n",
       "      <td>0.994831</td>\n",
       "      <td>1.384165e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.999961e-01</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.616147e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.155065e-03</td>\n",
       "      <td>0.994831</td>\n",
       "      <td>1.384165e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.968407e-01</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>1.855058e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.162348e-08</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>9.999627e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9.772972e-05</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>2.701283e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>8.003599e-06</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>3.659078e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.999985e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.997853e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    2.889818e-06  0.001785  9.982117e-01\n",
       "1    4.162348e-08  0.000037  9.999627e-01\n",
       "2    5.155065e-03  0.994831  1.384165e-05\n",
       "3    9.999961e-01  0.000004  8.616147e-09\n",
       "4    5.155065e-03  0.994831  1.384165e-05\n",
       "..            ...       ...           ...\n",
       "197  9.968407e-01  0.003159  1.855058e-12\n",
       "198  4.162348e-08  0.000037  9.999627e-01\n",
       "199  9.772972e-05  0.999632  2.701283e-04\n",
       "200  8.003599e-06  0.999955  3.659078e-05\n",
       "201  9.999985e-01  0.000002  3.997853e-08\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0512 - val_accuracy: 0.9752\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9703\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0845 - val_accuracy: 0.9703\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0483 - val_accuracy: 0.9802\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9703\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0439 - val_accuracy: 0.9851\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0621 - val_accuracy: 0.9752\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0627 - val_accuracy: 0.9752\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.1838 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0187 - accuracy: 0.9979 - val_loss: 0.1302 - val_accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0450 - val_accuracy: 0.9802\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9703\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0382 - val_accuracy: 0.9802\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0459 - val_accuracy: 0.9752\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0566 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0554 - val_accuracy: 0.9752\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9752\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0420 - val_accuracy: 0.9752\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0793 - val_accuracy: 0.9703\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 368us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9752\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9752\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 491us/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.0602 - val_accuracy: 0.9752\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9703\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.1110 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0492 - val_accuracy: 0.9851\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 496us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9505\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.1015 - val_accuracy: 0.9703\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 0.0383 - val_accuracy: 0.9802\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9703\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0383 - val_accuracy: 0.9851\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9703\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9703\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.0458 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9703\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 461us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9752\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9703\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9703\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0034 - accuracy: 0.9979 - val_loss: 0.0700 - val_accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0369 - val_accuracy: 0.9851\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9703\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9703\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0542 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.0036 - accuracy: 0.9979 - val_loss: 0.0474 - val_accuracy: 0.9802\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9653\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0393 - val_accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9703\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9703\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9752\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9752\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9752\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9703\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9703\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 371us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9752\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 316us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9752\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9752\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9752\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 9.3897e-04 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9752\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9752\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9703\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.94%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [5.15506460e-03, 9.94831000e-01, 1.38416530e-05],\n",
       "       [9.99996070e-01, 3.96543150e-06, 8.61614700e-09],\n",
       "       [5.15506460e-03, 9.94831000e-01, 1.38416530e-05],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [5.48832900e-03, 9.94511600e-01, 1.48546230e-08],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [3.61525380e-03, 9.96367100e-01, 1.76307350e-05],\n",
       "       [9.99970560e-01, 2.94614130e-05, 1.06401220e-08],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.06229100e-03, 9.90733500e-01, 2.04258700e-04],\n",
       "       [9.99993800e-01, 6.24100800e-06, 1.11336890e-12],\n",
       "       [5.48832900e-03, 9.94511600e-01, 1.48546230e-08],\n",
       "       [9.99999050e-01, 9.19617300e-07, 8.25180400e-09],\n",
       "       [1.95766200e-04, 9.99113500e-01, 6.90684000e-04],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [1.40491880e-02, 9.85950900e-01, 2.30215280e-12],\n",
       "       [9.99739600e-01, 2.58912860e-04, 1.53293590e-06],\n",
       "       [9.99998800e-01, 1.19756430e-06, 1.51300700e-12],\n",
       "       [9.58322300e-01, 4.16647940e-02, 1.28787410e-05],\n",
       "       [9.99889140e-01, 1.10793260e-04, 3.09100900e-08],\n",
       "       [6.06635620e-02, 9.38994300e-01, 3.42047220e-04],\n",
       "       [1.00000000e+00, 8.82266100e-09, 2.19585730e-13],\n",
       "       [8.28018400e-03, 9.91706500e-01, 1.33266490e-05],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [1.00000000e+00, 3.39161600e-10, 1.05782790e-14],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [9.99618530e-01, 3.80360100e-04, 1.11221390e-06],\n",
       "       [8.28018400e-03, 9.91706500e-01, 1.33266490e-05],\n",
       "       [9.06229100e-03, 9.90733500e-01, 2.04258700e-04],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99998700e-01, 1.07902290e-06, 2.24622850e-07],\n",
       "       [8.00359900e-06, 9.99955400e-01, 3.65908200e-05],\n",
       "       [9.99964950e-01, 3.45472800e-05, 4.65470950e-07],\n",
       "       [9.99824600e-01, 1.75474980e-04, 1.05340360e-12],\n",
       "       [4.36154800e-03, 9.95543060e-01, 9.54581700e-05],\n",
       "       [9.99997600e-01, 2.34946860e-06, 1.40995590e-12],\n",
       "       [1.95766200e-04, 9.99113500e-01, 6.90684000e-04],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.99432150e-01, 5.66259700e-04, 1.56040530e-06],\n",
       "       [3.11123270e-04, 9.99672800e-01, 1.61382540e-05],\n",
       "       [8.28018400e-03, 9.91706500e-01, 1.33266490e-05],\n",
       "       [9.99999300e-01, 5.82072350e-07, 1.77940010e-07],\n",
       "       [4.82885170e-04, 9.76591900e-01, 2.29251960e-02],\n",
       "       [9.99195750e-01, 8.03132400e-04, 1.06935730e-06],\n",
       "       [9.99996070e-01, 3.97215760e-06, 1.00074375e-08],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [6.98219150e-08, 9.99999900e-01, 2.11028690e-08],\n",
       "       [9.99729800e-01, 2.70148220e-04, 4.19318680e-11],\n",
       "       [4.82885170e-04, 9.76591900e-01, 2.29251960e-02],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [7.29064500e-02, 9.27093600e-01, 2.11237920e-10],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99875800e-01, 1.24066720e-04, 1.58077970e-07],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [2.12412630e-02, 9.78305500e-01, 4.53231600e-04],\n",
       "       [9.52554900e-01, 4.74310670e-02, 1.40551680e-05],\n",
       "       [2.28260920e-01, 7.71733640e-01, 5.44509750e-06],\n",
       "       [9.99963300e-01, 3.67588840e-05, 7.55320400e-12],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.96558250e-01, 3.42442440e-03, 1.73961100e-05],\n",
       "       [9.99579130e-01, 4.20584290e-04, 2.29451710e-07],\n",
       "       [4.03950100e-02, 9.59605040e-01, 1.47978160e-08],\n",
       "       [5.84331900e-03, 9.94156600e-01, 1.08939430e-07],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [8.00359900e-06, 9.99955400e-01, 3.65908200e-05],\n",
       "       [7.56272160e-03, 9.92414530e-01, 2.27214990e-05],\n",
       "       [9.99998000e-01, 2.04870840e-06, 1.04673850e-11],\n",
       "       [1.20142080e-02, 9.87985800e-01, 3.42347500e-10],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [2.64884860e-03, 9.97351050e-01, 7.66778500e-08],\n",
       "       [3.61525380e-03, 9.96367100e-01, 1.76307350e-05],\n",
       "       [6.29535600e-04, 9.99281200e-01, 8.92412500e-05],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [7.29064500e-02, 9.27093600e-01, 2.11237920e-10],\n",
       "       [9.99993700e-01, 6.19797000e-06, 7.19623200e-08],\n",
       "       [8.00359900e-06, 9.99955400e-01, 3.65908200e-05],\n",
       "       [9.99942800e-01, 5.69985460e-05, 2.00318540e-07],\n",
       "       [3.11123270e-04, 9.99672800e-01, 1.61382540e-05],\n",
       "       [9.99999300e-01, 2.55762790e-08, 7.69463270e-07],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99897960e-01, 1.02037295e-04, 4.41507160e-12],\n",
       "       [2.64884860e-03, 9.97351050e-01, 7.66778500e-08],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [9.99993440e-01, 6.59630000e-06, 5.82827100e-13],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [6.98219150e-08, 9.99999900e-01, 2.11028690e-08],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.99455300e-01, 5.43859960e-04, 8.65860840e-07],\n",
       "       [4.79040950e-03, 9.95209630e-01, 4.24016800e-09],\n",
       "       [9.99859100e-01, 1.34106200e-04, 6.77750860e-06],\n",
       "       [9.75297400e-01, 2.47018990e-02, 6.63711100e-07],\n",
       "       [9.99986050e-01, 1.38963110e-05, 2.65739280e-12],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [1.40491880e-02, 9.85950900e-01, 2.30215280e-12],\n",
       "       [9.99971400e-01, 2.83708850e-05, 1.93830160e-07],\n",
       "       [9.99981300e-01, 1.80739440e-05, 6.16803560e-07],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [8.00359900e-06, 9.99955400e-01, 3.65908200e-05],\n",
       "       [8.28018400e-03, 9.91706500e-01, 1.33266490e-05],\n",
       "       [9.97003730e-01, 2.95348200e-03, 4.27538430e-05],\n",
       "       [9.99950770e-01, 4.91685570e-05, 8.22286300e-08],\n",
       "       [9.99998100e-01, 1.43901810e-06, 5.24997000e-07],\n",
       "       [4.36154800e-03, 9.95543060e-01, 9.54581700e-05],\n",
       "       [9.99754250e-01, 2.45716900e-04, 2.88630900e-08],\n",
       "       [6.98219150e-08, 9.99999900e-01, 2.11028690e-08],\n",
       "       [4.36154800e-03, 9.95543060e-01, 9.54581700e-05],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [8.28018400e-03, 9.91706500e-01, 1.33266490e-05],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [5.41532160e-01, 4.58451700e-01, 1.60636000e-05],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99974700e-01, 2.52252030e-05, 1.01523210e-11],\n",
       "       [6.29535600e-04, 9.99281200e-01, 8.92412500e-05],\n",
       "       [9.71676770e-01, 2.83232200e-02, 1.11048490e-09],\n",
       "       [9.99976300e-01, 2.36122120e-05, 6.49516640e-08],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.94875970e-01, 5.12398870e-03, 2.52139820e-11],\n",
       "       [9.99928000e-01, 7.20115900e-05, 1.65930740e-10],\n",
       "       [7.29064500e-02, 9.27093600e-01, 2.11237920e-10],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [2.55809700e-01, 7.44190300e-01, 2.61477920e-10],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [5.84331900e-03, 9.94156600e-01, 1.08939430e-07],\n",
       "       [5.48832900e-03, 9.94511600e-01, 1.48546230e-08],\n",
       "       [4.36154800e-03, 9.95543060e-01, 9.54581700e-05],\n",
       "       [9.99995800e-01, 4.10108440e-06, 6.64014900e-08],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [2.12412630e-02, 9.78305500e-01, 4.53231600e-04],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [1.00000000e+00, 7.61500100e-09, 1.16262630e-13],\n",
       "       [7.89645200e-01, 2.10333510e-01, 2.13010990e-05],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [6.29535600e-04, 9.99281200e-01, 8.92412500e-05],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [1.40491880e-02, 9.85950900e-01, 2.30215280e-12],\n",
       "       [9.99998100e-01, 1.87084700e-06, 5.75265570e-09],\n",
       "       [9.99998200e-01, 1.84586380e-06, 5.33069850e-09],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99560530e-01, 4.39440600e-04, 3.09485950e-08],\n",
       "       [1.20142080e-02, 9.87985800e-01, 3.42347500e-10],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.99933240e-01, 6.65500900e-05, 2.42366750e-07],\n",
       "       [4.16234830e-08, 3.72347860e-05, 9.99962700e-01],\n",
       "       [9.06229100e-03, 9.90733500e-01, 2.04258700e-04],\n",
       "       [5.84331900e-03, 9.94156600e-01, 1.08939430e-07],\n",
       "       [9.99266900e-01, 7.31393050e-04, 1.62993560e-06],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [1.00000000e+00, 1.40497210e-11, 5.00131940e-10],\n",
       "       [4.82885170e-04, 9.76591900e-01, 2.29251960e-02],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [9.99874350e-01, 6.06907400e-05, 6.49338760e-05],\n",
       "       [3.83865400e-01, 6.16100850e-01, 3.37204730e-05],\n",
       "       [9.99998900e-01, 1.02747570e-06, 4.37928230e-09],\n",
       "       [4.26706220e-04, 9.99491700e-01, 8.15608700e-05],\n",
       "       [1.95766200e-04, 9.99113500e-01, 6.90684000e-04],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [1.39928700e-04, 9.99836700e-01, 2.33751800e-05],\n",
       "       [2.88981780e-06, 1.78543220e-03, 9.98211740e-01],\n",
       "       [9.99970560e-01, 2.94614130e-05, 1.06401220e-08],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [3.16537630e-05, 5.86198700e-05, 9.99909760e-01],\n",
       "       [9.99900100e-01, 9.99381400e-05, 7.23755700e-11],\n",
       "       [9.99981300e-01, 1.84490960e-05, 2.24442500e-07],\n",
       "       [7.29064500e-02, 9.27093600e-01, 2.11238300e-10],\n",
       "       [4.16234830e-08, 3.72347500e-05, 9.99962700e-01],\n",
       "       [9.99970560e-01, 2.94614130e-05, 1.06401010e-08],\n",
       "       [4.79041600e-03, 9.95209630e-01, 4.24016800e-09],\n",
       "       [4.82885170e-04, 9.76591900e-01, 2.29251900e-02],\n",
       "       [9.96840700e-01, 3.15923800e-03, 1.85505760e-12],\n",
       "       [4.16234830e-08, 3.72347500e-05, 9.99962700e-01],\n",
       "       [9.77297240e-05, 9.99632100e-01, 2.70128280e-04],\n",
       "       [8.00359900e-06, 9.99955400e-01, 3.65907840e-05],\n",
       "       [9.99998450e-01, 1.55583000e-06, 3.99785340e-08]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999632827149655"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999632827149655"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa04     0\n",
       "1      NRS021     0\n",
       "2      NRS073     0\n",
       "3      NRS049     0\n",
       "4       CA541     1\n",
       "..        ...   ...\n",
       "197    NRS387     1\n",
       "198    SR1746     0\n",
       "199    NRS148     2\n",
       "200    NRS255     2\n",
       "201    NRS232     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 0.7562 - accuracy: 0.6447 - val_loss: 0.5156 - val_accuracy: 0.7327\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.4635 - accuracy: 0.8149 - val_loss: 0.3727 - val_accuracy: 0.8812\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.3759 - accuracy: 0.8447 - val_loss: 0.3386 - val_accuracy: 0.8465\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.3272 - accuracy: 0.8723 - val_loss: 0.3004 - val_accuracy: 0.8663\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.2776 - accuracy: 0.9149 - val_loss: 0.2527 - val_accuracy: 0.9059\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.2366 - accuracy: 0.9340 - val_loss: 0.2218 - val_accuracy: 0.9505\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.2128 - accuracy: 0.9553 - val_loss: 0.2142 - val_accuracy: 0.9208\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.1977 - accuracy: 0.9404 - val_loss: 0.1788 - val_accuracy: 0.9406\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.1672 - accuracy: 0.9638 - val_loss: 0.1805 - val_accuracy: 0.9455\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.1525 - accuracy: 0.9596 - val_loss: 0.1524 - val_accuracy: 0.9505\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.1441 - accuracy: 0.9553 - val_loss: 0.1396 - val_accuracy: 0.9604\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.1339 - accuracy: 0.9660 - val_loss: 0.1323 - val_accuracy: 0.9554\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.1152 - accuracy: 0.9702 - val_loss: 0.1239 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.1087 - accuracy: 0.9681 - val_loss: 0.1086 - val_accuracy: 0.9752\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.1133 - accuracy: 0.9702 - val_loss: 0.1433 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.1161 - accuracy: 0.9702 - val_loss: 0.0969 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0868 - accuracy: 0.9809 - val_loss: 0.0981 - val_accuracy: 0.9752\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.0837 - accuracy: 0.9872 - val_loss: 0.0993 - val_accuracy: 0.9901\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0812 - accuracy: 0.9830 - val_loss: 0.0860 - val_accuracy: 0.9802\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0788 - accuracy: 0.9830 - val_loss: 0.1171 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0715 - accuracy: 0.9851 - val_loss: 0.0898 - val_accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0595 - accuracy: 0.9872 - val_loss: 0.0980 - val_accuracy: 0.9703\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.0597 - accuracy: 0.9936 - val_loss: 0.0851 - val_accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 322us/step - loss: 0.0637 - accuracy: 0.9872 - val_loss: 0.0781 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0522 - accuracy: 0.9894 - val_loss: 0.0700 - val_accuracy: 0.9752\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0516 - accuracy: 0.9894 - val_loss: 0.0635 - val_accuracy: 0.9802\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 319us/step - loss: 0.0524 - accuracy: 0.9872 - val_loss: 0.0846 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 329us/step - loss: 0.0548 - accuracy: 0.9872 - val_loss: 0.0790 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 0.0450 - accuracy: 0.9936 - val_loss: 0.0618 - val_accuracy: 0.9802\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 0.0418 - accuracy: 0.9936 - val_loss: 0.0852 - val_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 294us/step - loss: 0.0525 - accuracy: 0.9894 - val_loss: 0.0540 - val_accuracy: 0.9802\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 363us/step - loss: 0.0360 - accuracy: 0.9957 - val_loss: 0.0564 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 0.0353 - accuracy: 0.9936 - val_loss: 0.0565 - val_accuracy: 0.9901\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0380 - accuracy: 0.9957 - val_loss: 0.0557 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0318 - accuracy: 0.9957 - val_loss: 0.0474 - val_accuracy: 0.9802\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0335 - accuracy: 0.9936 - val_loss: 0.0489 - val_accuracy: 0.9901\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0379 - accuracy: 0.9957 - val_loss: 0.0459 - val_accuracy: 0.9802\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0321 - accuracy: 0.9957 - val_loss: 0.0436 - val_accuracy: 0.9901\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0272 - accuracy: 0.9957 - val_loss: 0.0493 - val_accuracy: 0.9802\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0283 - accuracy: 0.9957 - val_loss: 0.0429 - val_accuracy: 0.9851\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0243 - accuracy: 0.9957 - val_loss: 0.0465 - val_accuracy: 0.9802\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 0.0624 - val_accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.0235 - accuracy: 0.9957 - val_loss: 0.0403 - val_accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.0445 - val_accuracy: 0.9802\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0231 - accuracy: 0.9957 - val_loss: 0.0453 - val_accuracy: 0.9802\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.0619 - val_accuracy: 0.9802\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0223 - accuracy: 0.9957 - val_loss: 0.0393 - val_accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.0431 - val_accuracy: 0.9802\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.0649 - val_accuracy: 0.9752\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.0246 - accuracy: 0.9957 - val_loss: 0.0367 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.0438 - val_accuracy: 0.9802\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0423 - val_accuracy: 0.9802\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.0376 - val_accuracy: 0.9901\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0224 - accuracy: 0.9979 - val_loss: 0.0439 - val_accuracy: 0.9802\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 0.0159 - accuracy: 0.9979 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0328 - val_accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0339 - val_accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 0.0325 - val_accuracy: 0.9901\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.0323 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 0.0305 - val_accuracy: 0.9901\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 0.0842 - val_accuracy: 0.9703\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 0.0473 - val_accuracy: 0.9802\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.0330 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0180 - accuracy: 0.9957 - val_loss: 0.0353 - val_accuracy: 0.9901\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9752\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0150 - accuracy: 0.9979 - val_loss: 0.0323 - val_accuracy: 0.9901\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.0288 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9802\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.0538 - val_accuracy: 0.9802\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0349 - val_accuracy: 0.9802\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 0.0250 - val_accuracy: 0.9901\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0402 - val_accuracy: 0.9802\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0401 - val_accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0442 - val_accuracy: 0.9802\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0478 - val_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0275 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0299 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0838 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.0326 - val_accuracy: 0.9901\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0261 - val_accuracy: 0.9901\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0303 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9802\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0357 - val_accuracy: 0.9901\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0511 - val_accuracy: 0.9802\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0233 - val_accuracy: 0.9901\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9802\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0439 - val_accuracy: 0.9802\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0264 - val_accuracy: 0.9901\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0344 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0561 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.0623 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9950\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0251 - val_accuracy: 0.9901\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9752\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0417 - val_accuracy: 0.9851\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37bff898>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 111us/step\n",
      "over-sampling test accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 1, 2, 0,\n",
       "       0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 2, 0, 0,\n",
       "       2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 0, 1, 1, 0, 2, 2, 0, 2,\n",
       "       2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 2, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 2, 2, 2, 2,\n",
       "       1, 2, 1, 2, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 0, 2, 0, 2, 1,\n",
       "       2, 2, 1, 2, 1, 2, 2, 1, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa04     0     0\n",
       "1      NRS021     0     0\n",
       "2      NRS073     0     0\n",
       "3      NRS049     0     0\n",
       "4       CA541     1     1\n",
       "..        ...   ...   ...\n",
       "197    NRS387     1     1\n",
       "198    SR1746     0     0\n",
       "199    NRS148     2     2\n",
       "200    NRS255     2     2\n",
       "201    NRS232     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>2.991748e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>3.567869e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997437</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>8.573055e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659272</td>\n",
       "      <td>0.340320</td>\n",
       "      <td>4.075804e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997069</td>\n",
       "      <td>4.911396e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.997528</td>\n",
       "      <td>2.131637e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.983707</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>4.803907e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>9.987069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>9.998962e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>3.557453e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.999899  0.000101  2.991748e-08\n",
       "1    0.999117  0.000883  3.567869e-11\n",
       "2    0.997437  0.002562  8.573055e-11\n",
       "3    0.659272  0.340320  4.075804e-04\n",
       "4    0.002930  0.997069  4.911396e-07\n",
       "..        ...       ...           ...\n",
       "197  0.002469  0.997528  2.131637e-06\n",
       "198  0.983707  0.016245  4.803907e-05\n",
       "199  0.000003  0.001290  9.987069e-01\n",
       "200  0.000053  0.000050  9.998962e-01\n",
       "201  0.001014  0.998950  3.557453e-05\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0477 - val_accuracy: 0.9802\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0214 - val_accuracy: 0.9950\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0294 - val_accuracy: 0.9802\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9802\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0130 - accuracy: 0.9979 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0210 - val_accuracy: 0.9901\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0222 - val_accuracy: 0.9901\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9802\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0209 - val_accuracy: 0.9901\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0250 - val_accuracy: 0.9901\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9802\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0323 - val_accuracy: 0.9802\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9802\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0227 - val_accuracy: 0.9901\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9851\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0200 - val_accuracy: 0.9950\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9752\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0190 - val_accuracy: 0.9950\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0247 - val_accuracy: 0.9901\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9901\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9802\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9802\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9901\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0192 - val_accuracy: 0.9901\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9802\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9802\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.0231 - val_accuracy: 0.9901\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9901\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9901\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9901\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9851\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9901\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9901\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9901\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9851\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9802\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9901\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9901\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9802\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9901\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9901\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9851\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9802\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9901\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9802\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9901\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9901\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9802\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9802\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9901\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9752\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9901\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9901\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9851\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9901\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9901\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9851\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9901\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9901\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9851\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9901\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9802\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9901\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9901\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9901\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9851\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 403us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9802\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9901\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9901\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9901\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9802\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 329us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9901\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9901\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9901\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9901\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 9.6355e-04 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 9.9962e-04 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9901\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 9.2823e-04 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9901\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9901\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 9.8393e-04 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9901\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 9.7447e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9901\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 9.8435e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9901\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 9.4846e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99899400e-01, 1.00561505e-04, 2.99174800e-08],\n",
       "       [9.99116840e-01, 8.83180500e-04, 3.56786930e-11],\n",
       "       [9.97437500e-01, 2.56248630e-03, 8.57305500e-11],\n",
       "       [6.59272300e-01, 3.40320100e-01, 4.07580400e-04],\n",
       "       [2.93028100e-03, 9.97069300e-01, 4.91139600e-07],\n",
       "       [1.02697750e-04, 9.99897240e-01, 1.44443820e-10],\n",
       "       [4.52524700e-05, 9.99878500e-01, 7.61285700e-05],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [9.99500300e-01, 4.99646200e-04, 1.37017920e-07],\n",
       "       [9.99695200e-01, 3.04887300e-04, 4.75835620e-08],\n",
       "       [9.99886040e-01, 1.13362010e-04, 6.37574400e-07],\n",
       "       [9.67339200e-01, 3.26603650e-02, 4.07020100e-07],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [6.15032500e-07, 9.99993560e-01, 5.86841000e-06],\n",
       "       [9.83794300e-01, 1.62057620e-02, 2.36236110e-10],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.88984000e-04, 9.99511000e-01, 3.10121600e-09],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.99381660e-01, 6.18297500e-04, 1.87871160e-11],\n",
       "       [9.99984600e-01, 1.53811470e-05, 2.23134450e-08],\n",
       "       [4.36713250e-04, 9.99563300e-01, 2.15845900e-10],\n",
       "       [8.98069100e-01, 1.01905520e-01, 2.54294680e-05],\n",
       "       [9.99695200e-01, 3.04887300e-04, 4.75835620e-08],\n",
       "       [9.99564230e-01, 4.35739780e-04, 1.30182210e-10],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [1.00334510e-03, 9.98940900e-01, 5.57897370e-05],\n",
       "       [3.00322680e-03, 9.96709800e-01, 2.86946900e-04],\n",
       "       [9.99030500e-01, 9.69094860e-04, 4.93667600e-07],\n",
       "       [9.99935750e-01, 6.40961660e-05, 1.64159810e-07],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.94143200e-01, 5.85516960e-03, 1.64589570e-06],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [1.81262500e-03, 9.97833200e-01, 3.54279100e-04],\n",
       "       [4.88984000e-04, 9.99511000e-01, 3.10121600e-09],\n",
       "       [6.15032500e-07, 9.99993560e-01, 5.86841000e-06],\n",
       "       [4.52524700e-05, 9.99878500e-01, 7.61285700e-05],\n",
       "       [1.37945020e-03, 9.98517930e-01, 1.02569870e-04],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99996660e-01, 3.56540340e-07, 2.96854250e-06],\n",
       "       [9.99879500e-01, 1.20440774e-04, 1.10571726e-07],\n",
       "       [9.95604400e-01, 4.39560550e-03, 8.19692100e-11],\n",
       "       [6.15032500e-07, 9.99993560e-01, 5.86841000e-06],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [1.02697750e-04, 9.99897240e-01, 1.44443820e-10],\n",
       "       [1.00334510e-03, 9.98940900e-01, 5.57897370e-05],\n",
       "       [9.44419300e-01, 5.55209900e-02, 5.96264070e-05],\n",
       "       [6.15032500e-07, 9.99993560e-01, 5.86841000e-06],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99988560e-01, 1.14418600e-05, 2.10384470e-08],\n",
       "       [8.63160360e-04, 9.99125540e-01, 1.12699145e-05],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [4.36713250e-04, 9.99563300e-01, 2.15845900e-10],\n",
       "       [2.46939500e-03, 9.97528500e-01, 2.13163500e-06],\n",
       "       [3.70738360e-04, 9.99625200e-01, 4.05967830e-06],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.36713250e-04, 9.99563300e-01, 2.15845900e-10],\n",
       "       [9.99999300e-01, 7.54318650e-07, 5.63009100e-08],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.92256160e-01, 7.74359300e-03, 1.88417530e-07],\n",
       "       [9.99993200e-01, 5.77023000e-06, 1.09451650e-06],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [1.81262500e-03, 9.97833200e-01, 3.54279100e-04],\n",
       "       [6.15032500e-07, 9.99993560e-01, 5.86841000e-06],\n",
       "       [1.83098890e-03, 9.98163300e-01, 5.69463740e-06],\n",
       "       [4.88984000e-04, 9.99511000e-01, 3.10121600e-09],\n",
       "       [2.89872680e-03, 9.96975060e-01, 1.26258020e-04],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [9.35061900e-05, 9.89415400e-01, 1.04910955e-02],\n",
       "       [6.78336660e-04, 9.99250800e-01, 7.08110750e-05],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.36713250e-04, 9.99563300e-01, 2.15845900e-10],\n",
       "       [2.33349260e-05, 9.99976500e-01, 1.06449610e-07],\n",
       "       [9.99098800e-01, 9.01165070e-04, 1.46838020e-07],\n",
       "       [1.37945020e-03, 9.98517930e-01, 1.02569870e-04],\n",
       "       [3.70738360e-04, 9.99625200e-01, 4.05967830e-06],\n",
       "       [9.95695700e-01, 4.30424460e-03, 1.76814770e-10],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.68085170e-01, 3.19148900e-02, 1.76019120e-09],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.36713250e-04, 9.99563300e-01, 2.15845900e-10],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99695200e-01, 3.04887300e-04, 4.75835620e-08],\n",
       "       [9.99993440e-01, 6.38375100e-06, 1.12665230e-07],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.52524700e-05, 9.99878500e-01, 7.61285700e-05],\n",
       "       [1.90005640e-03, 9.98100000e-01, 4.58695640e-10],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [2.46939500e-03, 9.97528500e-01, 2.13163500e-06],\n",
       "       [6.78336660e-04, 9.99250800e-01, 7.08110750e-05],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [1.00000000e+00, 4.72728750e-09, 4.63096400e-10],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [8.63160360e-04, 9.99125540e-01, 1.12699145e-05],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.99999500e-01, 5.35323350e-07, 5.36462250e-08],\n",
       "       [9.94990650e-01, 5.00460600e-03, 4.70348400e-06],\n",
       "       [8.88497600e-01, 1.11173620e-01, 3.28777650e-04],\n",
       "       [9.35061900e-05, 9.89415400e-01, 1.04910955e-02],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [4.88984000e-04, 9.99511000e-01, 3.10121600e-09],\n",
       "       [1.31314770e-04, 9.99853730e-01, 1.49021730e-05],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [9.99993300e-01, 6.48573950e-06, 2.39733230e-07],\n",
       "       [2.93028100e-03, 9.97069300e-01, 4.91139600e-07],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.99314900e-01, 6.84300550e-04, 8.31138150e-07],\n",
       "       [9.89801350e-01, 1.01928525e-02, 5.75486500e-06],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [3.70738360e-04, 9.99625200e-01, 4.05967830e-06],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [6.78336660e-04, 9.99250800e-01, 7.08110750e-05],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [4.39958160e-01, 5.59777500e-01, 2.64364300e-04],\n",
       "       [3.70738360e-04, 9.99625200e-01, 4.05967830e-06],\n",
       "       [1.00000000e+00, 2.16132530e-11, 2.66526350e-11],\n",
       "       [9.99998200e-01, 1.77033510e-06, 4.29741940e-13],\n",
       "       [1.00000000e+00, 2.13350050e-09, 2.36875800e-15],\n",
       "       [8.46819100e-01, 1.53180840e-01, 1.20494290e-09],\n",
       "       [9.99695200e-01, 3.04887300e-04, 4.75835620e-08],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [3.00322680e-03, 9.96709800e-01, 2.86946900e-04],\n",
       "       [9.99996660e-01, 3.33316260e-06, 1.19762000e-08],\n",
       "       [9.99289040e-01, 7.02677640e-04, 8.25579400e-06],\n",
       "       [1.02697750e-04, 9.99897240e-01, 1.44443820e-10],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.99992000e-01, 7.85843000e-06, 1.19260690e-07],\n",
       "       [2.12117350e-03, 9.97875800e-01, 3.02014200e-06],\n",
       "       [2.89872680e-03, 9.96975060e-01, 1.26258020e-04],\n",
       "       [2.33349260e-05, 9.99976500e-01, 1.06449610e-07],\n",
       "       [9.99996800e-01, 3.15898820e-06, 1.60020820e-07],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [3.00322680e-03, 9.96709800e-01, 2.86946900e-04],\n",
       "       [9.99760800e-01, 2.38312130e-04, 8.87195400e-07],\n",
       "       [2.93028100e-03, 9.97069300e-01, 4.91139600e-07],\n",
       "       [8.80408100e-03, 9.91067230e-01, 1.28645970e-04],\n",
       "       [1.59652600e-04, 9.99762950e-01, 7.73807400e-05],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [6.78336660e-04, 9.99250800e-01, 7.08110750e-05],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.35061900e-05, 9.89415400e-01, 1.04910955e-02],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.79051000e-01, 2.09486900e-02, 3.10254700e-07],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [9.92561400e-01, 7.43863200e-03, 3.77660180e-10],\n",
       "       [9.92119800e-01, 7.72420500e-03, 1.55975780e-04],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [2.93028100e-03, 9.97069300e-01, 4.91139600e-07],\n",
       "       [3.18373900e-02, 9.68138340e-01, 2.42108180e-05],\n",
       "       [9.99974500e-01, 2.54654310e-05, 2.53830020e-08],\n",
       "       [1.31314770e-04, 9.99853730e-01, 1.49021730e-05],\n",
       "       [9.90824100e-01, 9.16979300e-03, 6.13349860e-06],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99996800e-01, 3.21887360e-06, 5.49997060e-08],\n",
       "       [9.99195500e-01, 7.99246540e-04, 5.22506430e-06],\n",
       "       [8.50115300e-01, 1.49884640e-01, 1.36507670e-09],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99362050e-01, 6.37472140e-04, 4.64907770e-07],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [4.88984000e-04, 9.99511000e-01, 3.10121600e-09],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [3.70738360e-04, 9.99625200e-01, 4.05967830e-06],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [3.35484860e-01, 6.64419650e-01, 9.54242800e-05],\n",
       "       [9.99974600e-01, 2.50880180e-05, 3.75239400e-07],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.35940700e-06, 1.96173080e-05, 9.99971030e-01],\n",
       "       [9.99998450e-01, 1.37745990e-06, 6.07623000e-08],\n",
       "       [9.89104750e-01, 1.02075670e-02, 6.87793300e-04],\n",
       "       [5.34271530e-05, 5.04083300e-05, 9.99896170e-01],\n",
       "       [1.36875260e-03, 9.98611800e-01, 1.94395600e-05],\n",
       "       [8.67675000e-01, 1.32324980e-01, 7.45422670e-10],\n",
       "       [9.98138900e-01, 1.86046920e-03, 6.54246500e-07],\n",
       "       [5.34273060e-05, 5.04084240e-05, 9.99896170e-01],\n",
       "       [5.34273060e-05, 5.04084240e-05, 9.99896170e-01],\n",
       "       [9.35941600e-06, 1.96173460e-05, 9.99971030e-01],\n",
       "       [9.99783600e-01, 4.25559630e-05, 1.73932700e-04],\n",
       "       [2.46939620e-03, 9.97528500e-01, 2.13163700e-06],\n",
       "       [9.83706950e-01, 1.62450410e-02, 4.80390700e-05],\n",
       "       [2.80335000e-06, 1.29029210e-03, 9.98706940e-01],\n",
       "       [5.34273060e-05, 5.04084240e-05, 9.99896170e-01],\n",
       "       [1.01424010e-03, 9.98950200e-01, 3.55745300e-05]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987890070345441"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987890070345441"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994356106179343"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005084817807952712"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994356106179343"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005084817807952712"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 96.78%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.016604466894944863\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 99.94%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.00042312706\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS255     2\n",
       "1    NRS148     2\n",
       "2    NRS209     2\n",
       "3    NRS386     1\n",
       "4    NRS230     0\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS209     2\n",
       "199  SR4153     0\n",
       "200  NRS255     2\n",
       "201  NRS255     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 637us/step - loss: 3.1979 - accuracy: 0.5149 - val_loss: 0.9631 - val_accuracy: 0.6683\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 3.4190 - accuracy: 0.6064 - val_loss: 0.9001 - val_accuracy: 0.6386\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 4.0949 - accuracy: 0.5574 - val_loss: 0.9278 - val_accuracy: 0.7228\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 3.1735 - accuracy: 0.6596 - val_loss: 0.8950 - val_accuracy: 0.6485\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 3.2734 - accuracy: 0.6447 - val_loss: 0.8579 - val_accuracy: 0.7574\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 2.9296 - accuracy: 0.6809 - val_loss: 0.8947 - val_accuracy: 0.8663\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 3.3876 - accuracy: 0.6468 - val_loss: 0.8399 - val_accuracy: 0.8515\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 3.0342 - accuracy: 0.7213 - val_loss: 0.8356 - val_accuracy: 0.8663\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 2.8008 - accuracy: 0.7298 - val_loss: 0.7868 - val_accuracy: 0.8416\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 348us/step - loss: 3.2512 - accuracy: 0.6936 - val_loss: 0.8022 - val_accuracy: 0.8861\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 3.3097 - accuracy: 0.6915 - val_loss: 0.9947 - val_accuracy: 0.7673\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 3.1970 - accuracy: 0.6809 - val_loss: 0.7441 - val_accuracy: 0.8812\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 2.6712 - accuracy: 0.7234 - val_loss: 0.7356 - val_accuracy: 0.9010\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 2.6604 - accuracy: 0.7106 - val_loss: 0.7730 - val_accuracy: 0.8911\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 2.7871 - accuracy: 0.7000 - val_loss: 0.7888 - val_accuracy: 0.9109\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 2.6118 - accuracy: 0.7064 - val_loss: 0.7834 - val_accuracy: 0.9356\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 2.4213 - accuracy: 0.7277 - val_loss: 0.6957 - val_accuracy: 0.9208\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 2.6337 - accuracy: 0.6979 - val_loss: 0.7382 - val_accuracy: 0.9158\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 2.2430 - accuracy: 0.7277 - val_loss: 0.7928 - val_accuracy: 0.8762\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 2.2554 - accuracy: 0.7404 - val_loss: 0.6479 - val_accuracy: 0.9208\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 2.2333 - accuracy: 0.7383 - val_loss: 0.5393 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 1.9218 - accuracy: 0.7489 - val_loss: 0.6178 - val_accuracy: 0.9505\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.9083 - accuracy: 0.7745 - val_loss: 0.6796 - val_accuracy: 0.9406\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 388us/step - loss: 1.5031 - accuracy: 0.7957 - val_loss: 0.6011 - val_accuracy: 0.9455\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 751us/step - loss: 1.9967 - accuracy: 0.7468 - val_loss: 0.4487 - val_accuracy: 0.9505\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 560us/step - loss: 1.4278 - accuracy: 0.8128 - val_loss: 0.4515 - val_accuracy: 0.9554\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 510us/step - loss: 1.6891 - accuracy: 0.7681 - val_loss: 0.5958 - val_accuracy: 0.9505\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 463us/step - loss: 1.8198 - accuracy: 0.7426 - val_loss: 0.4984 - val_accuracy: 0.9752\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 1.7111 - accuracy: 0.7638 - val_loss: 0.6647 - val_accuracy: 0.9356\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 516us/step - loss: 1.6205 - accuracy: 0.7638 - val_loss: 0.6582 - val_accuracy: 0.9505\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 433us/step - loss: 1.4762 - accuracy: 0.7660 - val_loss: 0.4496 - val_accuracy: 0.9505\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 433us/step - loss: 1.3554 - accuracy: 0.8128 - val_loss: 0.3702 - val_accuracy: 0.9505\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 1.3377 - accuracy: 0.8128 - val_loss: 0.3559 - val_accuracy: 0.9703\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 1.3416 - accuracy: 0.7723 - val_loss: 0.4855 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 360us/step - loss: 1.5594 - accuracy: 0.7426 - val_loss: 0.4395 - val_accuracy: 0.9752\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 467us/step - loss: 1.3475 - accuracy: 0.7787 - val_loss: 0.5232 - val_accuracy: 0.9505\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 1.3733 - accuracy: 0.7660 - val_loss: 0.4369 - val_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 1.2896 - accuracy: 0.7979 - val_loss: 0.3966 - val_accuracy: 0.9802\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 710us/step - loss: 1.2991 - accuracy: 0.7638 - val_loss: 0.4872 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 1.2193 - accuracy: 0.8064 - val_loss: 0.3894 - val_accuracy: 0.9703\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 462us/step - loss: 1.3098 - accuracy: 0.7489 - val_loss: 0.3637 - val_accuracy: 0.9703\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.1323 - accuracy: 0.7809 - val_loss: 0.4564 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.9538 - accuracy: 0.8043 - val_loss: 0.3983 - val_accuracy: 0.9802\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 346us/step - loss: 1.0687 - accuracy: 0.7851 - val_loss: 0.2979 - val_accuracy: 0.9901\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 364us/step - loss: 1.0079 - accuracy: 0.7787 - val_loss: 0.2928 - val_accuracy: 0.9901\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 301us/step - loss: 0.8890 - accuracy: 0.8255 - val_loss: 0.3054 - val_accuracy: 0.9802\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 1.0374 - accuracy: 0.7681 - val_loss: 0.5149 - val_accuracy: 0.9505\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 392us/step - loss: 0.9665 - accuracy: 0.8064 - val_loss: 0.4699 - val_accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.9722 - accuracy: 0.7894 - val_loss: 0.3908 - val_accuracy: 0.9752\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 348us/step - loss: 1.0597 - accuracy: 0.7766 - val_loss: 0.3747 - val_accuracy: 0.9802\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 1.0366 - accuracy: 0.7915 - val_loss: 0.2758 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 0.8786 - accuracy: 0.7894 - val_loss: 0.4491 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 1.0033 - accuracy: 0.7894 - val_loss: 0.3639 - val_accuracy: 0.9802\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.8154 - accuracy: 0.7894 - val_loss: 0.2755 - val_accuracy: 0.9901\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.8583 - accuracy: 0.7936 - val_loss: 0.3436 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 0.5722 - accuracy: 0.8191 - val_loss: 0.3357 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 0.7765 - accuracy: 0.7872 - val_loss: 0.4243 - val_accuracy: 0.9703\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.7205 - accuracy: 0.8043 - val_loss: 0.4611 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.7688 - accuracy: 0.7681 - val_loss: 0.3832 - val_accuracy: 0.9802\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.7805 - accuracy: 0.8128 - val_loss: 0.2968 - val_accuracy: 0.9901\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.5962 - accuracy: 0.8362 - val_loss: 0.3708 - val_accuracy: 0.9802\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.7185 - accuracy: 0.7894 - val_loss: 0.4041 - val_accuracy: 0.9802\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.5056 - accuracy: 0.7915 - val_loss: 0.3125 - val_accuracy: 0.9851\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.6163 - accuracy: 0.8149 - val_loss: 0.4156 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.5940 - accuracy: 0.7468 - val_loss: 0.3931 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 447us/step - loss: 0.4702 - accuracy: 0.7809 - val_loss: 0.9528 - val_accuracy: 0.9208\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 328us/step - loss: 0.6030 - accuracy: 0.8064 - val_loss: 0.4907 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.5315 - accuracy: 0.8000 - val_loss: 0.4315 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 0.6136 - accuracy: 0.7872 - val_loss: 0.4020 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.6296 - accuracy: 0.7851 - val_loss: 0.5464 - val_accuracy: 0.9554\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.5107 - accuracy: 0.7957 - val_loss: 0.3153 - val_accuracy: 0.9851\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.5084 - accuracy: 0.7894 - val_loss: 0.4303 - val_accuracy: 0.9802\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.5368 - accuracy: 0.7936 - val_loss: 0.4111 - val_accuracy: 0.9802\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.4256 - accuracy: 0.7787 - val_loss: 0.2749 - val_accuracy: 0.9703\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.4583 - accuracy: 0.8128 - val_loss: 0.3050 - val_accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.4833 - accuracy: 0.8234 - val_loss: 0.3974 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.5856 - accuracy: 0.7702 - val_loss: 0.2957 - val_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.5429 - accuracy: 0.8021 - val_loss: 0.3607 - val_accuracy: 0.9802\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.3669 - accuracy: 0.8213 - val_loss: 0.3542 - val_accuracy: 0.9802\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.4804 - accuracy: 0.7957 - val_loss: 0.3702 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.3996 - accuracy: 0.8128 - val_loss: 0.4044 - val_accuracy: 0.9802\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.6106 - accuracy: 0.7787 - val_loss: 0.4202 - val_accuracy: 0.9703\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.4280 - accuracy: 0.8064 - val_loss: 0.4938 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.5857 - accuracy: 0.7979 - val_loss: 0.4587 - val_accuracy: 0.9802\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.5425 - accuracy: 0.7894 - val_loss: 0.3536 - val_accuracy: 0.9802\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.5751 - accuracy: 0.8043 - val_loss: 0.4889 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.6220 - accuracy: 0.7723 - val_loss: 0.3335 - val_accuracy: 0.9851\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.5498 - accuracy: 0.7702 - val_loss: 0.4159 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.3683 - accuracy: 0.8319 - val_loss: 0.3152 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.4799 - accuracy: 0.7872 - val_loss: 0.2521 - val_accuracy: 0.9851\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.6022 - accuracy: 0.7872 - val_loss: 0.5088 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.5236 - accuracy: 0.8021 - val_loss: 0.4495 - val_accuracy: 0.9752\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.4729 - accuracy: 0.7957 - val_loss: 0.2826 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.5477 - accuracy: 0.7702 - val_loss: 0.2689 - val_accuracy: 0.9851\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.2466 - val_accuracy: 0.9851\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.5654 - accuracy: 0.7723 - val_loss: 0.3896 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.4901 - accuracy: 0.8170 - val_loss: 0.3372 - val_accuracy: 0.9802\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.4512 - accuracy: 0.8191 - val_loss: 0.4300 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.5503 - accuracy: 0.7872 - val_loss: 0.3723 - val_accuracy: 0.9802\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.4836 - accuracy: 0.7851 - val_loss: 0.3635 - val_accuracy: 0.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a388b36d8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 125us/step\n",
      "over-sampling test accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2,\n",
       "       2, 2, 0, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 2, 2, 0,\n",
       "       2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0,\n",
       "       1, 2, 1, 0, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 1,\n",
       "       2, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0,\n",
       "       0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 1,\n",
       "       2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 2,\n",
       "       0, 0, 2, 1, 2, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1,\n",
       "       1, 2, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS255     2     2\n",
       "1    NRS148     2     2\n",
       "2    NRS209     2     2\n",
       "3    NRS386     1     1\n",
       "4    NRS230     0     0\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS209     2     2\n",
       "199  SR4153     0     0\n",
       "200  NRS255     2     2\n",
       "201  NRS255     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.994908e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>5.308003e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.034752e-16</td>\n",
       "      <td>3.696870e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.068874e-13</td>\n",
       "      <td>2.000986e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4.710171e-08</td>\n",
       "      <td>7.975358e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    4.710171e-08  7.975358e-08  9.999999e-01\n",
       "1    4.710171e-08  7.975358e-08  9.999999e-01\n",
       "2    4.710171e-08  7.975358e-08  9.999999e-01\n",
       "3    8.994908e-08  9.999999e-01  5.308003e-08\n",
       "4    1.000000e+00  7.034752e-16  3.696870e-17\n",
       "..            ...           ...           ...\n",
       "197  4.710171e-08  7.975358e-08  9.999999e-01\n",
       "198  4.710171e-08  7.975358e-08  9.999999e-01\n",
       "199  1.000000e+00  1.068874e-13  2.000986e-14\n",
       "200  4.710171e-08  7.975358e-08  9.999999e-01\n",
       "201  4.710171e-08  7.975358e-08  9.999999e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.4705 - accuracy: 0.8128 - val_loss: 0.2310 - val_accuracy: 0.9950\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.5148 - accuracy: 0.7851 - val_loss: 0.4367 - val_accuracy: 0.9703\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.4642 - accuracy: 0.8149 - val_loss: 0.2960 - val_accuracy: 0.9802\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.5767 - accuracy: 0.7766 - val_loss: 0.3151 - val_accuracy: 0.9752\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.4780 - accuracy: 0.7936 - val_loss: 0.2724 - val_accuracy: 0.9851\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.4819 - accuracy: 0.8106 - val_loss: 0.2810 - val_accuracy: 0.9802\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.5788 - accuracy: 0.7915 - val_loss: 0.5281 - val_accuracy: 0.9703\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.4812 - accuracy: 0.8064 - val_loss: 0.2767 - val_accuracy: 0.9802\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.4842 - accuracy: 0.7723 - val_loss: 0.2948 - val_accuracy: 0.9802\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.3943 - accuracy: 0.8234 - val_loss: 0.5305 - val_accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.4597 - accuracy: 0.7745 - val_loss: 0.3040 - val_accuracy: 0.9752\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.4271 - accuracy: 0.8298 - val_loss: 0.3005 - val_accuracy: 0.9802\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.3668 - accuracy: 0.8128 - val_loss: 0.2703 - val_accuracy: 0.9901\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.5293 - accuracy: 0.8021 - val_loss: 0.2791 - val_accuracy: 0.9851\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 0.5096 - accuracy: 0.7894 - val_loss: 0.3618 - val_accuracy: 0.9802\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 355us/step - loss: 0.4151 - accuracy: 0.8128 - val_loss: 0.2404 - val_accuracy: 0.9851\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 330us/step - loss: 0.4673 - accuracy: 0.8213 - val_loss: 0.2875 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 695us/step - loss: 0.3904 - accuracy: 0.8085 - val_loss: 0.2206 - val_accuracy: 0.9851\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 427us/step - loss: 0.3671 - accuracy: 0.8021 - val_loss: 0.2604 - val_accuracy: 0.9901\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.4757 - accuracy: 0.7787 - val_loss: 0.3098 - val_accuracy: 0.9703\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 496us/step - loss: 0.4729 - accuracy: 0.7809 - val_loss: 0.3506 - val_accuracy: 0.9802\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 367us/step - loss: 0.4922 - accuracy: 0.8043 - val_loss: 0.2904 - val_accuracy: 0.9802\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 522us/step - loss: 0.3642 - accuracy: 0.8255 - val_loss: 0.3197 - val_accuracy: 0.9752\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 0.4522 - accuracy: 0.7894 - val_loss: 0.2502 - val_accuracy: 0.9851\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.4746 - accuracy: 0.7745 - val_loss: 0.2633 - val_accuracy: 0.9901\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.3690 - accuracy: 0.8170 - val_loss: 0.2131 - val_accuracy: 0.9901\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 475us/step - loss: 0.4496 - accuracy: 0.8043 - val_loss: 0.5268 - val_accuracy: 0.9703\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 864us/step - loss: 0.5684 - accuracy: 0.7979 - val_loss: 0.5524 - val_accuracy: 0.9703\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 365us/step - loss: 0.5064 - accuracy: 0.7766 - val_loss: 0.2593 - val_accuracy: 0.9901\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 640us/step - loss: 0.3830 - accuracy: 0.8298 - val_loss: 0.3493 - val_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 518us/step - loss: 0.4674 - accuracy: 0.7723 - val_loss: 0.2622 - val_accuracy: 0.9851\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 515us/step - loss: 0.3889 - accuracy: 0.8149 - val_loss: 0.2936 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 417us/step - loss: 0.3560 - accuracy: 0.8426 - val_loss: 0.2255 - val_accuracy: 0.9851\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 466us/step - loss: 0.4032 - accuracy: 0.8106 - val_loss: 0.3048 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.4577 - accuracy: 0.8149 - val_loss: 0.2597 - val_accuracy: 0.9851\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 419us/step - loss: 0.4239 - accuracy: 0.7915 - val_loss: 0.3123 - val_accuracy: 0.9752\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 0.4661 - accuracy: 0.7702 - val_loss: 0.3141 - val_accuracy: 0.9752\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 0.4041 - accuracy: 0.7851 - val_loss: 0.3039 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 397us/step - loss: 0.4360 - accuracy: 0.7596 - val_loss: 0.2523 - val_accuracy: 0.9802\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.79 - 0s 419us/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.3291 - val_accuracy: 0.9703\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 381us/step - loss: 0.4210 - accuracy: 0.8319 - val_loss: 0.2795 - val_accuracy: 0.9703\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 364us/step - loss: 0.4200 - accuracy: 0.8043 - val_loss: 0.3655 - val_accuracy: 0.9802\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 285us/step - loss: 0.3753 - accuracy: 0.7894 - val_loss: 0.2520 - val_accuracy: 0.9851\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 419us/step - loss: 0.4402 - accuracy: 0.7936 - val_loss: 0.4597 - val_accuracy: 0.9703\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 382us/step - loss: 0.4427 - accuracy: 0.7894 - val_loss: 0.2246 - val_accuracy: 0.9851\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.5132 - accuracy: 0.7426 - val_loss: 0.2782 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.4367 - accuracy: 0.8277 - val_loss: 0.2164 - val_accuracy: 0.9703\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 306us/step - loss: 0.4386 - accuracy: 0.7957 - val_loss: 0.3341 - val_accuracy: 0.9752\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 299us/step - loss: 0.3216 - accuracy: 0.8255 - val_loss: 0.2786 - val_accuracy: 0.9802\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.3660 - accuracy: 0.8170 - val_loss: 0.2846 - val_accuracy: 0.9802\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.4253 - accuracy: 0.8213 - val_loss: 0.3456 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 377us/step - loss: 0.4293 - accuracy: 0.7872 - val_loss: 0.5711 - val_accuracy: 0.9703\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.4792 - accuracy: 0.7766 - val_loss: 0.2544 - val_accuracy: 0.9851\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 387us/step - loss: 0.4893 - accuracy: 0.7915 - val_loss: 0.4144 - val_accuracy: 0.9703\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 351us/step - loss: 0.3759 - accuracy: 0.8000 - val_loss: 0.3243 - val_accuracy: 0.9802\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.3518 - accuracy: 0.8191 - val_loss: 0.2220 - val_accuracy: 0.9901\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.3801 - accuracy: 0.8149 - val_loss: 0.3120 - val_accuracy: 0.9802\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.3997 - accuracy: 0.8128 - val_loss: 0.2050 - val_accuracy: 0.9901\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.3294 - accuracy: 0.8064 - val_loss: 0.3175 - val_accuracy: 0.9802\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.3650 - accuracy: 0.7936 - val_loss: 0.2335 - val_accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 416us/step - loss: 0.4399 - accuracy: 0.7936 - val_loss: 0.2119 - val_accuracy: 0.9851\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.3799 - accuracy: 0.7766 - val_loss: 0.1932 - val_accuracy: 0.9851\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 369us/step - loss: 0.3527 - accuracy: 0.7957 - val_loss: 0.2545 - val_accuracy: 0.9752\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 0.4200 - accuracy: 0.8128 - val_loss: 0.2951 - val_accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 0.3927 - accuracy: 0.8149 - val_loss: 0.2672 - val_accuracy: 0.9802\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.3753 - accuracy: 0.8277 - val_loss: 0.2892 - val_accuracy: 0.9703\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.4140 - accuracy: 0.8085 - val_loss: 0.2308 - val_accuracy: 0.9851\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.3654 - accuracy: 0.7894 - val_loss: 0.3995 - val_accuracy: 0.9703\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 304us/step - loss: 0.5139 - accuracy: 0.7894 - val_loss: 0.2749 - val_accuracy: 0.9455\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 0.4658 - accuracy: 0.8298 - val_loss: 0.3304 - val_accuracy: 0.9802\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.3704 - accuracy: 0.8170 - val_loss: 0.2771 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.4330 - accuracy: 0.7957 - val_loss: 0.2222 - val_accuracy: 0.9851\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.3467 - accuracy: 0.8255 - val_loss: 0.2692 - val_accuracy: 0.9802\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.3437 - accuracy: 0.8064 - val_loss: 0.1906 - val_accuracy: 0.9901\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.3688 - accuracy: 0.8021 - val_loss: 0.5711 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.4464 - accuracy: 0.8000 - val_loss: 0.3508 - val_accuracy: 0.9802\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.4156 - accuracy: 0.7809 - val_loss: 0.2514 - val_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.3353 - accuracy: 0.8191 - val_loss: 0.4336 - val_accuracy: 0.9703\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.3393 - accuracy: 0.8170 - val_loss: 0.1930 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.3533 - accuracy: 0.7809 - val_loss: 0.2543 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.4383 - accuracy: 0.7787 - val_loss: 0.2887 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.3444 - accuracy: 0.8404 - val_loss: 0.2896 - val_accuracy: 0.9851\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.4407 - accuracy: 0.7915 - val_loss: 0.4240 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.4382 - accuracy: 0.8021 - val_loss: 0.3741 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 276us/step - loss: 0.4992 - accuracy: 0.7851 - val_loss: 0.3314 - val_accuracy: 0.9851\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 0.4319 - accuracy: 0.7957 - val_loss: 0.4384 - val_accuracy: 0.9703\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.4029 - accuracy: 0.8043 - val_loss: 0.2716 - val_accuracy: 0.9851\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.4289 - accuracy: 0.7596 - val_loss: 0.2045 - val_accuracy: 0.9802\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.4216 - accuracy: 0.8064 - val_loss: 0.3142 - val_accuracy: 0.9752\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.4050 - accuracy: 0.7936 - val_loss: 0.5536 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.4599 - accuracy: 0.7894 - val_loss: 0.2405 - val_accuracy: 0.9802\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.4277 - accuracy: 0.8234 - val_loss: 0.2847 - val_accuracy: 0.9851\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.4443 - accuracy: 0.7787 - val_loss: 0.3185 - val_accuracy: 0.9851\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.3429 - accuracy: 0.8277 - val_loss: 0.2931 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.3652 - accuracy: 0.8064 - val_loss: 0.3588 - val_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.3635 - accuracy: 0.8085 - val_loss: 0.2509 - val_accuracy: 0.9851\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.3734 - accuracy: 0.7936 - val_loss: 0.2522 - val_accuracy: 0.9802\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.4397 - accuracy: 0.7723 - val_loss: 0.3125 - val_accuracy: 0.9802\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.4060 - accuracy: 0.7936 - val_loss: 0.2932 - val_accuracy: 0.9851\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.3423 - accuracy: 0.8149 - val_loss: 0.3000 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 80.07%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [8.99490800e-08, 9.99999900e-01, 5.30800330e-08],\n",
       "       [1.00000000e+00, 7.03475160e-16, 3.69686970e-17],\n",
       "       [1.00000000e+00, 5.92669660e-18, 3.55473970e-19],\n",
       "       [5.75826350e-02, 2.67106100e-01, 6.75311270e-01],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.55641340e-16, 1.04817090e-15],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [1.00000000e+00, 4.26041030e-19, 1.48830050e-18],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.81523950e-18, 2.44143200e-17],\n",
       "       [5.74440400e-15, 1.00000000e+00, 2.23779920e-14],\n",
       "       [1.00000000e+00, 2.13858530e-20, 4.76377420e-20],\n",
       "       [1.00000000e+00, 2.86235920e-17, 1.88004120e-16],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.30782140e-10, 3.01308370e-12],\n",
       "       [5.40108700e-06, 9.99994040e-01, 6.23499260e-07],\n",
       "       [5.40108700e-06, 9.99994040e-01, 6.23499260e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.44790930e-19, 3.27477960e-19],\n",
       "       [1.00000000e+00, 1.78484890e-16, 1.35726520e-18],\n",
       "       [1.00000000e+00, 4.04515720e-18, 1.98325800e-17],\n",
       "       [6.64869150e-05, 9.99933360e-01, 1.50485060e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [8.65439460e-07, 9.99997400e-01, 1.74882950e-06],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [3.29270930e-07, 9.99999050e-01, 5.53172200e-07],\n",
       "       [5.74440400e-15, 1.00000000e+00, 2.23779920e-14],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.21866960e-07, 9.99999900e-01, 1.13082480e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.79835820e-24, 2.20318650e-24],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.33625600e-30, 5.02658970e-31],\n",
       "       [7.27879700e-08, 9.99999640e-01, 1.79089740e-07],\n",
       "       [6.64869150e-05, 9.99933360e-01, 1.50485060e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 5.60716660e-21, 1.02407290e-24],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [1.00000000e+00, 1.34490740e-16, 1.11243170e-15],\n",
       "       [1.00000000e+00, 1.35921870e-14, 7.05377340e-17],\n",
       "       [1.00000000e+00, 1.23754270e-10, 1.70256130e-10],\n",
       "       [9.99996200e-01, 3.87428240e-06, 7.52415900e-09],\n",
       "       [9.76911840e-01, 1.71548860e-04, 2.29166820e-02],\n",
       "       [1.00000000e+00, 1.44446480e-11, 1.96587000e-13],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [1.21866960e-07, 9.99999900e-01, 1.13082480e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.91890020e-10, 6.84327540e-13],\n",
       "       [9.99999500e-01, 8.34085300e-08, 3.89902700e-07],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [1.00000000e+00, 1.19285920e-12, 6.28973100e-12],\n",
       "       [6.87571020e-09, 1.00000000e+00, 4.87715500e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [9.90655700e-09, 1.00000000e+00, 2.72407200e-09],\n",
       "       [1.00000000e+00, 6.76178840e-11, 8.66955760e-13],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.52266690e-23, 2.48598880e-24],\n",
       "       [1.74431470e-08, 9.99999900e-01, 8.99082600e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.19051780e-22, 2.82002900e-22],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [6.64869150e-05, 9.99933360e-01, 1.50485060e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [9.06677300e-02, 9.09331740e-01, 5.08260540e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.03294300e-31, 4.95706500e-32],\n",
       "       [5.40108700e-06, 9.99994040e-01, 6.23499260e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.15746800e-18, 7.45355900e-19],\n",
       "       [7.27879700e-08, 9.99999640e-01, 1.79089740e-07],\n",
       "       [5.75826350e-02, 2.67106100e-01, 6.75311270e-01],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [1.00000000e+00, 6.22095400e-29, 1.21597440e-29],\n",
       "       [9.90655700e-09, 1.00000000e+00, 2.72407200e-09],\n",
       "       [1.00000000e+00, 4.47829330e-09, 5.68149940e-11],\n",
       "       [1.00000000e+00, 3.08344680e-17, 2.66886580e-18],\n",
       "       [2.30130910e-09, 1.00000000e+00, 1.59044710e-09],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.50437500e-20, 2.65527720e-19],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [8.65439460e-07, 9.99997400e-01, 1.74882950e-06],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.03199794e-25, 5.58184200e-26],\n",
       "       [1.00000000e+00, 2.50813100e-20, 5.66375100e-20],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [1.00000000e+00, 4.08512340e-16, 1.12696930e-18],\n",
       "       [1.21866960e-07, 9.99999900e-01, 1.13082480e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [9.92891800e-01, 7.10814300e-03, 7.62679200e-08],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.04568000e-27, 3.39941660e-27],\n",
       "       [1.00000000e+00, 2.13858530e-20, 4.76377420e-20],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [8.99490800e-08, 9.99999900e-01, 5.30800330e-08],\n",
       "       [1.00000000e+00, 1.02125570e-25, 5.53741040e-26],\n",
       "       [1.98510720e-11, 1.00000000e+00, 2.92040750e-09],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.36593000e-16, 2.13681300e-15],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [2.10830960e-10, 1.00000000e+00, 1.53725100e-09],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.86235920e-17, 1.88004120e-16],\n",
       "       [9.92891800e-01, 7.10814300e-03, 7.62679200e-08],\n",
       "       [1.00000000e+00, 9.84590550e-23, 1.15093620e-22],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.46409710e-19, 4.35459360e-19],\n",
       "       [6.27531300e-09, 1.00000000e+00, 2.85490240e-08],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.28445870e-14, 1.36820610e-13],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [1.00000000e+00, 2.75611530e-27, 1.41934840e-28],\n",
       "       [6.98424040e-01, 3.00839200e-01, 7.36791300e-04],\n",
       "       [9.06677300e-02, 9.09331740e-01, 5.08260540e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.16862084e-08, 9.99999900e-01, 6.36944650e-08],\n",
       "       [9.99999170e-01, 1.85863070e-07, 6.04699700e-07],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [6.87571020e-09, 1.00000000e+00, 4.87715500e-08],\n",
       "       [1.00000000e+00, 2.34202980e-13, 4.27644100e-15],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [5.90420330e-09, 1.00000000e+00, 2.29207050e-09],\n",
       "       [1.73719360e-02, 9.82544700e-01, 8.34097450e-05],\n",
       "       [2.30130910e-09, 1.00000000e+00, 1.59044710e-09],\n",
       "       [5.74440400e-15, 1.00000000e+00, 2.23779920e-14],\n",
       "       [1.00000000e+00, 6.83806600e-29, 1.39448310e-29],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [8.65439460e-07, 9.99997400e-01, 1.74882950e-06],\n",
       "       [2.30130910e-09, 1.00000000e+00, 1.59044710e-09],\n",
       "       [5.40108700e-06, 9.99994040e-01, 6.23499260e-07],\n",
       "       [6.87571020e-09, 1.00000000e+00, 4.87715500e-08],\n",
       "       [1.00000000e+00, 2.86235920e-17, 1.88004120e-16],\n",
       "       [1.00000000e+00, 2.85851300e-13, 4.08879340e-13],\n",
       "       [1.00000000e+00, 1.95215630e-21, 3.15047500e-21],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.86235920e-17, 1.88004120e-16],\n",
       "       [1.00000000e+00, 7.45039530e-10, 1.87397320e-12],\n",
       "       [5.75826350e-02, 2.67106100e-01, 6.75311270e-01],\n",
       "       [2.01971460e-02, 9.79646000e-01, 1.56783940e-04],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.73947550e-24, 3.83172220e-24],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [6.27531300e-09, 1.00000000e+00, 2.85490240e-08],\n",
       "       [1.00000000e+00, 1.81090750e-19, 5.57768970e-19],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.73719360e-02, 9.82544700e-01, 8.34097450e-05],\n",
       "       [3.29270930e-07, 9.99999050e-01, 5.53172200e-07],\n",
       "       [9.65128000e-01, 3.48315100e-02, 4.05364630e-05],\n",
       "       [3.29270930e-07, 9.99999050e-01, 5.53172200e-07],\n",
       "       [1.00000000e+00, 3.13569400e-12, 1.54797700e-11],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.96560400e-18, 2.85757760e-19],\n",
       "       [1.00000000e+00, 1.84174200e-19, 2.42961960e-20],\n",
       "       [1.00000000e+00, 9.49487300e-29, 2.36084770e-29],\n",
       "       [1.00000000e+00, 1.13228780e-24, 7.81821500e-25],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [6.64869150e-05, 9.99933360e-01, 1.50485060e-07],\n",
       "       [1.33085510e-08, 1.00000000e+00, 2.93492600e-09],\n",
       "       [5.75826350e-02, 2.67106100e-01, 6.75311270e-01],\n",
       "       [2.30130910e-09, 1.00000000e+00, 1.59044710e-09],\n",
       "       [1.00000000e+00, 3.12914300e-10, 9.94813700e-13],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.74336200e-13, 3.76677680e-11],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.29559870e-21, 1.91173460e-21],\n",
       "       [3.29270930e-07, 9.99999050e-01, 5.53172200e-07],\n",
       "       [1.00000000e+00, 4.73250560e-15, 1.63098080e-15],\n",
       "       [1.00000000e+00, 5.65705300e-14, 1.27413640e-13],\n",
       "       [1.33085510e-08, 1.00000000e+00, 2.93492600e-09],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [9.71821300e-05, 1.45225900e-01, 8.54676960e-01],\n",
       "       [6.64869150e-05, 9.99933360e-01, 1.50485060e-07],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.10672630e-22, 1.16578310e-22],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.06887386e-13, 2.00098640e-14],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01],\n",
       "       [4.71017070e-08, 7.97535800e-08, 9.99999900e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979454578957067"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979454578957067"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0       115     1\n",
       "1    NRS209     2\n",
       "2     GA984     0\n",
       "3    NRS187     1\n",
       "4    NRS148     2\n",
       "..      ...   ...\n",
       "197  NRS253     1\n",
       "198   EUH15     0\n",
       "199  NRS180     1\n",
       "200  NRS266     1\n",
       "201  NRS109     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "   \n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 640us/step - loss: 4.2432 - accuracy: 0.4702 - val_loss: 0.8970 - val_accuracy: 0.7228\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 350us/step - loss: 3.3111 - accuracy: 0.6404 - val_loss: 0.8708 - val_accuracy: 0.7921\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 422us/step - loss: 2.9233 - accuracy: 0.6702 - val_loss: 0.7837 - val_accuracy: 0.8861\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 366us/step - loss: 2.9592 - accuracy: 0.6745 - val_loss: 0.7897 - val_accuracy: 0.9010\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 375us/step - loss: 2.9825 - accuracy: 0.6894 - val_loss: 0.7835 - val_accuracy: 0.8416\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 2.9464 - accuracy: 0.6681 - val_loss: 0.7746 - val_accuracy: 0.8861\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 3.2039 - accuracy: 0.6532 - val_loss: 0.7530 - val_accuracy: 0.8762\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 3.0699 - accuracy: 0.6787 - val_loss: 0.7615 - val_accuracy: 0.8515\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 415us/step - loss: 2.9514 - accuracy: 0.6936 - val_loss: 0.7578 - val_accuracy: 0.9406\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 2.8261 - accuracy: 0.7277 - val_loss: 0.8061 - val_accuracy: 0.9208\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 2.5120 - accuracy: 0.7468 - val_loss: 0.7209 - val_accuracy: 0.9010\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 2.5538 - accuracy: 0.7532 - val_loss: 0.7309 - val_accuracy: 0.9158\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 2.8591 - accuracy: 0.7106 - val_loss: 0.8431 - val_accuracy: 0.8713\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.7774 - accuracy: 0.7404 - val_loss: 0.8158 - val_accuracy: 0.9158\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 2.5740 - accuracy: 0.7660 - val_loss: 0.7798 - val_accuracy: 0.9455\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 2.6438 - accuracy: 0.7255 - val_loss: 0.8338 - val_accuracy: 0.9455\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 2.5102 - accuracy: 0.7532 - val_loss: 0.9342 - val_accuracy: 0.9109\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 355us/step - loss: 2.3684 - accuracy: 0.7617 - val_loss: 0.9403 - val_accuracy: 0.9455\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 3.0105 - accuracy: 0.7085 - val_loss: 0.9635 - val_accuracy: 0.9505\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.1765 - accuracy: 0.7574 - val_loss: 0.8871 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.4858 - accuracy: 0.7426 - val_loss: 0.8905 - val_accuracy: 0.9554\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.2281 - accuracy: 0.7447 - val_loss: 0.8372 - val_accuracy: 0.9505\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 326us/step - loss: 1.9828 - accuracy: 0.7723 - val_loss: 0.8943 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 333us/step - loss: 2.1884 - accuracy: 0.7426 - val_loss: 0.8776 - val_accuracy: 0.9455\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.0950 - accuracy: 0.7681 - val_loss: 0.9654 - val_accuracy: 0.9109\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.1239 - accuracy: 0.7426 - val_loss: 0.8949 - val_accuracy: 0.9505\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.8433 - accuracy: 0.7957 - val_loss: 0.8384 - val_accuracy: 0.9505\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 2.2119 - accuracy: 0.7362 - val_loss: 0.8870 - val_accuracy: 0.9455\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 1.9866 - accuracy: 0.7574 - val_loss: 0.8704 - val_accuracy: 0.9455\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 380us/step - loss: 1.9438 - accuracy: 0.7298 - val_loss: 0.8307 - val_accuracy: 0.9505\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 2.0799 - accuracy: 0.7340 - val_loss: 0.8545 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 2.0779 - accuracy: 0.7277 - val_loss: 0.9034 - val_accuracy: 0.9505\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.0127 - accuracy: 0.7511 - val_loss: 0.8904 - val_accuracy: 0.9505\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.7528 - accuracy: 0.7681 - val_loss: 0.8382 - val_accuracy: 0.9554\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.8261 - accuracy: 0.7681 - val_loss: 0.7607 - val_accuracy: 0.9505\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.6720 - accuracy: 0.7511 - val_loss: 0.7816 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.6630 - accuracy: 0.7723 - val_loss: 0.8259 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 1.9868 - accuracy: 0.7426 - val_loss: 0.8017 - val_accuracy: 0.9554\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.3947 - accuracy: 0.8043 - val_loss: 0.8256 - val_accuracy: 0.9554\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.4174 - accuracy: 0.7872 - val_loss: 0.7610 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 1.5099 - accuracy: 0.7660 - val_loss: 0.7996 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 1.4128 - accuracy: 0.8064 - val_loss: 0.8561 - val_accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.6826 - accuracy: 0.7660 - val_loss: 0.8130 - val_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.5642 - accuracy: 0.7638 - val_loss: 0.8502 - val_accuracy: 0.9455\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.4139 - accuracy: 0.7213 - val_loss: 0.7319 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.3807 - accuracy: 0.7723 - val_loss: 0.7103 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.5171 - accuracy: 0.7766 - val_loss: 0.7995 - val_accuracy: 0.9406\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.4118 - accuracy: 0.7851 - val_loss: 0.7039 - val_accuracy: 0.9158\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.3914 - accuracy: 0.8000 - val_loss: 0.7020 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 1.4876 - accuracy: 0.7681 - val_loss: 0.8194 - val_accuracy: 0.9208\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 485us/step - loss: 1.4048 - accuracy: 0.7723 - val_loss: 0.7415 - val_accuracy: 0.9505\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.2528 - accuracy: 0.8021 - val_loss: 0.7068 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.4961 - accuracy: 0.7383 - val_loss: 0.7565 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.3519 - accuracy: 0.7787 - val_loss: 0.6389 - val_accuracy: 0.9653\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 1.4757 - accuracy: 0.7553 - val_loss: 0.8004 - val_accuracy: 0.9455\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.3767 - accuracy: 0.7383 - val_loss: 0.7636 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.3312 - accuracy: 0.8021 - val_loss: 0.8416 - val_accuracy: 0.9208\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 1.3790 - accuracy: 0.7596 - val_loss: 0.6874 - val_accuracy: 0.9505\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.1951 - accuracy: 0.7851 - val_loss: 0.7015 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.3737 - accuracy: 0.7681 - val_loss: 0.6736 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 1.3367 - accuracy: 0.7574 - val_loss: 0.7996 - val_accuracy: 0.9208\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.2807 - accuracy: 0.7660 - val_loss: 0.6773 - val_accuracy: 0.9505\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.2333 - accuracy: 0.7681 - val_loss: 0.6584 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.1744 - accuracy: 0.7723 - val_loss: 0.6273 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.2307 - accuracy: 0.7894 - val_loss: 0.6417 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.1808 - accuracy: 0.7574 - val_loss: 0.6408 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.1918 - accuracy: 0.7745 - val_loss: 0.6063 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.1468 - accuracy: 0.7723 - val_loss: 0.6295 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.0821 - accuracy: 0.7872 - val_loss: 0.5333 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.0964 - accuracy: 0.7851 - val_loss: 0.6545 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.9652 - accuracy: 0.7936 - val_loss: 0.6329 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.0465 - accuracy: 0.7872 - val_loss: 0.6212 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.0308 - accuracy: 0.7979 - val_loss: 0.5459 - val_accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.0860 - accuracy: 0.7511 - val_loss: 0.6495 - val_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.9677 - accuracy: 0.8021 - val_loss: 0.5561 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.8141 - accuracy: 0.7872 - val_loss: 0.5484 - val_accuracy: 0.9653\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0265 - accuracy: 0.7340 - val_loss: 0.6072 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9557 - accuracy: 0.8021 - val_loss: 0.5097 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9946 - accuracy: 0.7702 - val_loss: 0.5381 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.9297 - accuracy: 0.7957 - val_loss: 0.5196 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.9808 - accuracy: 0.7617 - val_loss: 0.5284 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.9731 - accuracy: 0.7745 - val_loss: 0.5087 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.9786 - accuracy: 0.7957 - val_loss: 0.5621 - val_accuracy: 0.9505\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.8918 - accuracy: 0.7957 - val_loss: 0.5089 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.8952 - accuracy: 0.7745 - val_loss: 0.5176 - val_accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.9151 - accuracy: 0.7851 - val_loss: 0.5055 - val_accuracy: 0.9554\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.9009 - accuracy: 0.7681 - val_loss: 0.4789 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.0175 - accuracy: 0.7553 - val_loss: 0.4770 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.8208 - accuracy: 0.8277 - val_loss: 0.5032 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.9118 - accuracy: 0.7638 - val_loss: 0.4911 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.8960 - accuracy: 0.7830 - val_loss: 0.4815 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.9498 - accuracy: 0.7872 - val_loss: 0.5826 - val_accuracy: 0.9257\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 0.9078 - accuracy: 0.7660 - val_loss: 0.5276 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.9428 - accuracy: 0.7936 - val_loss: 0.4682 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.8312 - accuracy: 0.8000 - val_loss: 0.4373 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.8319 - accuracy: 0.7489 - val_loss: 0.5074 - val_accuracy: 0.9554\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.8170 - accuracy: 0.7723 - val_loss: 0.4666 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.8344 - accuracy: 0.7617 - val_loss: 0.4868 - val_accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.8581 - accuracy: 0.7787 - val_loss: 0.4468 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.9310 - accuracy: 0.7681 - val_loss: 0.4524 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3927e128>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 114us/step\n",
      "over-sampling test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0,\n",
       "       0, 0, 2, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 2, 2, 1, 0, 1,\n",
       "       2, 2, 2, 0, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       1, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 1, 0, 1, 1,\n",
       "       0, 2, 2, 2, 2, 1, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 2,\n",
       "       1, 0, 2, 2, 1, 2, 0, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1,\n",
       "       1, 2, 0, 2, 2, 0, 2, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 0, 2, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 1, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0       115     1     1\n",
       "1    NRS209     2     2\n",
       "2     GA984     0     0\n",
       "3    NRS187     1     1\n",
       "4    NRS148     2     2\n",
       "..      ...   ...   ...\n",
       "197  NRS253     1     1\n",
       "198   EUH15     0     0\n",
       "199  NRS180     1     1\n",
       "200  NRS266     1     1\n",
       "201  NRS109     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.848713e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>4.958978e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.694917e-08</td>\n",
       "      <td>8.750234e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.182892e-09</td>\n",
       "      <td>1.750376e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.422572e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.106527e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.769664e-08</td>\n",
       "      <td>1.260017e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.208738e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.136406e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.836975e-13</td>\n",
       "      <td>6.095818e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5.182315e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.894522e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.586869e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.713035e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.947558e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.583181e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.848713e-07  9.999998e-01  4.958978e-08\n",
       "1    5.694917e-08  8.750234e-08  9.999999e-01\n",
       "2    1.000000e+00  4.182892e-09  1.750376e-09\n",
       "3    3.422572e-08  1.000000e+00  1.106527e-09\n",
       "4    8.769664e-08  1.260017e-07  9.999998e-01\n",
       "..            ...           ...           ...\n",
       "197  1.208738e-12  1.000000e+00  5.136406e-13\n",
       "198  1.000000e+00  8.836975e-13  6.095818e-13\n",
       "199  5.182315e-08  1.000000e+00  2.894522e-08\n",
       "200  1.586869e-08  1.000000e+00  1.713035e-08\n",
       "201  1.947558e-08  1.000000e+00  4.583181e-09\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.8485 - accuracy: 0.7787 - val_loss: 0.4551 - val_accuracy: 0.9653\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.9419 - accuracy: 0.7723 - val_loss: 0.4897 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.9561 - accuracy: 0.7723 - val_loss: 0.5332 - val_accuracy: 0.9653\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.8859 - accuracy: 0.8064 - val_loss: 0.4342 - val_accuracy: 0.9604\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.9045 - accuracy: 0.7766 - val_loss: 0.4673 - val_accuracy: 0.9604\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.8163 - accuracy: 0.7766 - val_loss: 0.4503 - val_accuracy: 0.9653\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.9709 - accuracy: 0.7638 - val_loss: 0.4526 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.7910 - accuracy: 0.8085 - val_loss: 0.4244 - val_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.7250 - accuracy: 0.8043 - val_loss: 0.4172 - val_accuracy: 0.9653\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.8680 - accuracy: 0.7830 - val_loss: 0.4426 - val_accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.9250 - accuracy: 0.7574 - val_loss: 0.4097 - val_accuracy: 0.9653\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 548us/step - loss: 0.8139 - accuracy: 0.7745 - val_loss: 0.4466 - val_accuracy: 0.9604\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 515us/step - loss: 0.8105 - accuracy: 0.7830 - val_loss: 0.4256 - val_accuracy: 0.9604\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 530us/step - loss: 0.8451 - accuracy: 0.7766 - val_loss: 0.4079 - val_accuracy: 0.9653\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 533us/step - loss: 0.7268 - accuracy: 0.7830 - val_loss: 0.4054 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 332us/step - loss: 0.6586 - accuracy: 0.7851 - val_loss: 0.4254 - val_accuracy: 0.9604\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 0.9113 - accuracy: 0.7319 - val_loss: 0.4211 - val_accuracy: 0.9653\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 505us/step - loss: 0.7616 - accuracy: 0.7787 - val_loss: 0.4370 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.8461 - accuracy: 0.7681 - val_loss: 0.4319 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.8497 - accuracy: 0.7957 - val_loss: 0.4037 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 722us/step - loss: 0.8595 - accuracy: 0.7766 - val_loss: 0.3678 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 735us/step - loss: 0.7255 - accuracy: 0.7894 - val_loss: 0.3844 - val_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 422us/step - loss: 0.6707 - accuracy: 0.8128 - val_loss: 0.4363 - val_accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.7940 - accuracy: 0.7915 - val_loss: 0.4040 - val_accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.7686 - accuracy: 0.8106 - val_loss: 0.4016 - val_accuracy: 0.9653\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.7104 - accuracy: 0.8000 - val_loss: 0.3791 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.7238 - accuracy: 0.8106 - val_loss: 0.3765 - val_accuracy: 0.9653\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 294us/step - loss: 0.6976 - accuracy: 0.7915 - val_loss: 0.3559 - val_accuracy: 0.9653\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 551us/step - loss: 0.7875 - accuracy: 0.7766 - val_loss: 0.3813 - val_accuracy: 0.9653\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 404us/step - loss: 0.8358 - accuracy: 0.7660 - val_loss: 0.4089 - val_accuracy: 0.9653\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 313us/step - loss: 0.7895 - accuracy: 0.7702 - val_loss: 0.4033 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.6779 - accuracy: 0.7936 - val_loss: 0.3948 - val_accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.6925 - accuracy: 0.7787 - val_loss: 0.3754 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.7838 - accuracy: 0.7830 - val_loss: 0.3762 - val_accuracy: 0.9653\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 341us/step - loss: 0.9103 - accuracy: 0.7596 - val_loss: 0.3862 - val_accuracy: 0.9653\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.6934 - accuracy: 0.8128 - val_loss: 0.3815 - val_accuracy: 0.9653\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.8159 - accuracy: 0.7553 - val_loss: 0.3847 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 373us/step - loss: 0.7834 - accuracy: 0.7574 - val_loss: 0.3666 - val_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.7649 - accuracy: 0.8128 - val_loss: 0.3807 - val_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.6677 - accuracy: 0.7979 - val_loss: 0.3885 - val_accuracy: 0.9653\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 531us/step - loss: 0.7283 - accuracy: 0.7830 - val_loss: 0.3922 - val_accuracy: 0.9653\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 0.6852 - accuracy: 0.7830 - val_loss: 0.3898 - val_accuracy: 0.9653\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.8970 - accuracy: 0.7638 - val_loss: 0.3776 - val_accuracy: 0.9653\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.7054 - accuracy: 0.8000 - val_loss: 0.3645 - val_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 337us/step - loss: 0.7124 - accuracy: 0.7894 - val_loss: 0.3704 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.6341 - accuracy: 0.8000 - val_loss: 0.3826 - val_accuracy: 0.9653\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 0.7916 - accuracy: 0.7979 - val_loss: 0.3905 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.6917 - accuracy: 0.7979 - val_loss: 0.3707 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.7311 - accuracy: 0.7979 - val_loss: 0.3744 - val_accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.6670 - accuracy: 0.7723 - val_loss: 0.3788 - val_accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.6925 - accuracy: 0.8085 - val_loss: 0.3704 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.6204 - accuracy: 0.8255 - val_loss: 0.3711 - val_accuracy: 0.9653\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.6768 - accuracy: 0.7915 - val_loss: 0.3810 - val_accuracy: 0.9653\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 0.7303 - accuracy: 0.7660 - val_loss: 0.3659 - val_accuracy: 0.9653\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.6484 - accuracy: 0.8277 - val_loss: 0.3483 - val_accuracy: 0.9653\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 325us/step - loss: 0.6069 - accuracy: 0.8213 - val_loss: 0.3533 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.7537 - accuracy: 0.7809 - val_loss: 0.3944 - val_accuracy: 0.9653\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.6936 - accuracy: 0.7894 - val_loss: 0.3777 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.6290 - accuracy: 0.8021 - val_loss: 0.3734 - val_accuracy: 0.9653\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.7198 - accuracy: 0.7979 - val_loss: 0.3648 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 0.6600 - accuracy: 0.7830 - val_loss: 0.3792 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 292us/step - loss: 0.6895 - accuracy: 0.8106 - val_loss: 0.3772 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 310us/step - loss: 0.7481 - accuracy: 0.7766 - val_loss: 0.3595 - val_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.7038 - accuracy: 0.7660 - val_loss: 0.3687 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.6658 - accuracy: 0.7511 - val_loss: 0.3602 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 297us/step - loss: 0.6397 - accuracy: 0.7936 - val_loss: 0.3787 - val_accuracy: 0.9257\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 326us/step - loss: 0.7077 - accuracy: 0.7894 - val_loss: 0.3458 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 269us/step - loss: 0.7044 - accuracy: 0.7809 - val_loss: 0.3790 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.6636 - accuracy: 0.8000 - val_loss: 0.3475 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.6548 - accuracy: 0.7936 - val_loss: 0.3367 - val_accuracy: 0.9653\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.6500 - accuracy: 0.7957 - val_loss: 0.3383 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.6787 - accuracy: 0.7511 - val_loss: 0.3606 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.6642 - accuracy: 0.8213 - val_loss: 0.3448 - val_accuracy: 0.9653\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.6414 - accuracy: 0.7681 - val_loss: 0.3495 - val_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.6146 - accuracy: 0.7745 - val_loss: 0.3472 - val_accuracy: 0.9653\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.6229 - accuracy: 0.7809 - val_loss: 0.3607 - val_accuracy: 0.9653\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 315us/step - loss: 0.6830 - accuracy: 0.7766 - val_loss: 0.3739 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.7215 - accuracy: 0.7809 - val_loss: 0.3478 - val_accuracy: 0.9653\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 0.6689 - accuracy: 0.7894 - val_loss: 0.3671 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.7634 - accuracy: 0.7681 - val_loss: 0.3551 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.6383 - accuracy: 0.8149 - val_loss: 0.3911 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.6868 - accuracy: 0.7681 - val_loss: 0.3478 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.6514 - accuracy: 0.8000 - val_loss: 0.3519 - val_accuracy: 0.9604\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.6192 - accuracy: 0.7936 - val_loss: 0.3470 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 306us/step - loss: 0.6056 - accuracy: 0.7809 - val_loss: 0.3370 - val_accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.6424 - accuracy: 0.7957 - val_loss: 0.3416 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.6678 - accuracy: 0.7787 - val_loss: 0.3524 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.6353 - accuracy: 0.7894 - val_loss: 0.3575 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.5870 - accuracy: 0.7915 - val_loss: 0.3308 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.7237 - accuracy: 0.7766 - val_loss: 0.3237 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.5652 - accuracy: 0.8149 - val_loss: 0.3478 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.6844 - accuracy: 0.8106 - val_loss: 0.3650 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.6717 - accuracy: 0.7745 - val_loss: 0.3316 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.6053 - accuracy: 0.7957 - val_loss: 0.3539 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.7533 - accuracy: 0.7638 - val_loss: 0.3644 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.6392 - accuracy: 0.7745 - val_loss: 0.3360 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.5405 - accuracy: 0.8426 - val_loss: 0.3139 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.6638 - accuracy: 0.7894 - val_loss: 0.3329 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.5852 - accuracy: 0.8043 - val_loss: 0.3554 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.6895 - accuracy: 0.7957 - val_loss: 0.3327 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 78.73%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84871270e-07, 9.99999760e-01, 4.95897800e-08],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.18289200e-09, 1.75037640e-09],\n",
       "       [3.42257170e-08, 1.00000000e+00, 1.10652680e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.94755770e-08, 1.00000000e+00, 4.58318140e-09],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [1.33338320e-08, 1.00000000e+00, 7.80653700e-09],\n",
       "       [1.00000000e+00, 7.63802800e-09, 5.94583630e-09],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [2.72812630e-10, 1.00000000e+00, 3.48323400e-11],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [1.00000000e+00, 7.84103400e-10, 6.80646000e-10],\n",
       "       [1.00000000e+00, 1.71795240e-09, 1.02533550e-09],\n",
       "       [9.88913240e-01, 1.10144940e-02, 7.22992550e-05],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [7.09849900e-10, 1.00000000e+00, 1.61840670e-10],\n",
       "       [2.58337020e-07, 9.99999760e-01, 4.97393520e-08],\n",
       "       [1.00000000e+00, 3.38638320e-12, 5.26379370e-12],\n",
       "       [1.00000000e+00, 5.76968760e-13, 4.62124200e-13],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [1.00000000e+00, 1.53944640e-08, 1.00852740e-08],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [9.99999900e-01, 7.97128300e-08, 4.57598550e-08],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [9.95299700e-01, 4.67436530e-03, 2.58245650e-05],\n",
       "       [1.00000000e+00, 1.71004020e-10, 1.20811220e-10],\n",
       "       [9.98531000e-01, 1.46456780e-03, 4.40718260e-06],\n",
       "       [1.33338320e-08, 1.00000000e+00, 7.80653700e-09],\n",
       "       [1.00000000e+00, 2.28408500e-12, 1.79040330e-12],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.94755770e-08, 1.00000000e+00, 4.58318140e-09],\n",
       "       [1.00000000e+00, 5.15024820e-09, 4.77012000e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.58686630e-08, 1.00000000e+00, 1.71303220e-08],\n",
       "       [9.99999760e-01, 2.46594370e-07, 3.58240700e-08],\n",
       "       [2.12719940e-08, 1.00000000e+00, 1.70785790e-08],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [5.18231540e-08, 1.00000000e+00, 2.89453370e-08],\n",
       "       [1.20873790e-12, 1.00000000e+00, 5.13640560e-13],\n",
       "       [9.99334500e-01, 6.55935700e-04, 9.49514700e-06],\n",
       "       [3.42257170e-08, 1.00000000e+00, 1.10652680e-09],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [1.20873790e-12, 1.00000000e+00, 5.13640560e-13],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.10022120e-11, 1.41243350e-11],\n",
       "       [1.00000000e+00, 1.81880640e-08, 9.05815960e-09],\n",
       "       [1.00000000e+00, 3.19805790e-16, 3.97469150e-16],\n",
       "       [5.18231540e-08, 1.00000000e+00, 2.89453370e-08],\n",
       "       [3.62512300e-02, 9.63689500e-01, 5.92533540e-05],\n",
       "       [1.71344290e-09, 1.00000000e+00, 4.87682450e-10],\n",
       "       [1.43898780e-05, 9.99984150e-01, 1.42503540e-06],\n",
       "       [1.33338320e-08, 1.00000000e+00, 7.80653700e-09],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.56383430e-09, 3.00637180e-09],\n",
       "       [7.09849900e-10, 1.00000000e+00, 1.61840670e-10],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675040e-09],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.27808760e-10, 1.85686130e-10],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [9.99999760e-01, 7.27796560e-08, 6.39161900e-08],\n",
       "       [1.20873790e-12, 1.00000000e+00, 5.13640560e-13],\n",
       "       [6.25391800e-01, 3.74594480e-01, 1.37057490e-05],\n",
       "       [1.00000000e+00, 7.74243140e-13, 9.45728400e-13],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 8.43938300e-08, 6.71643650e-08],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.53496930e-08, 1.00000000e+00, 3.73393500e-08],\n",
       "       [1.00000000e+00, 1.74559090e-14, 1.26926520e-14],\n",
       "       [6.58652700e-09, 1.00000000e+00, 9.17759400e-10],\n",
       "       [2.32886100e-05, 9.99976300e-01, 5.01519370e-07],\n",
       "       [9.99999500e-01, 2.86732020e-07, 1.84446990e-07],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [6.58652700e-09, 1.00000000e+00, 9.17759400e-10],\n",
       "       [1.00000000e+00, 1.47226820e-12, 8.00911900e-13],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.00000000e+00, 1.38351400e-08, 9.52526200e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [2.32886100e-05, 9.99976300e-01, 5.01519370e-07],\n",
       "       [9.99998570e-01, 1.15707830e-06, 2.08520630e-07],\n",
       "       [1.00000000e+00, 6.05753500e-13, 9.88901800e-13],\n",
       "       [1.00000000e+00, 2.73954300e-12, 4.30976650e-12],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.00000000e+00, 3.38041730e-10, 2.50054420e-10],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [9.99999640e-01, 1.80966780e-07, 8.88997750e-08],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.27526960e-09, 1.06721780e-09],\n",
       "       [1.00000000e+00, 2.88889380e-10, 2.41434600e-10],\n",
       "       [1.00000000e+00, 5.58902800e-09, 4.38012250e-09],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [7.09849900e-10, 1.00000000e+00, 1.61840670e-10],\n",
       "       [1.00000000e+00, 8.38512450e-11, 4.33515300e-11],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [7.68855700e-09, 1.00000000e+00, 1.68329810e-09],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [9.99995800e-01, 3.88802400e-06, 2.29816140e-07],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [1.50125170e-08, 9.99999900e-01, 7.14419800e-08],\n",
       "       [1.00000000e+00, 1.16802240e-14, 6.92661600e-15],\n",
       "       [1.00000000e+00, 1.44124140e-12, 9.15921900e-13],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [2.72812630e-10, 1.00000000e+00, 3.48323400e-11],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675040e-09],\n",
       "       [6.58652700e-09, 1.00000000e+00, 9.17759400e-10],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675040e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.50125170e-08, 9.99999900e-01, 7.14419800e-08],\n",
       "       [1.00000000e+00, 3.46490040e-14, 1.70262280e-14],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [4.97478770e-09, 1.00000000e+00, 3.77287800e-09],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.42623050e-11, 5.70689200e-11],\n",
       "       [1.58686630e-08, 1.00000000e+00, 1.71303220e-08],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.78110470e-13, 3.32182690e-13],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675040e-09],\n",
       "       [1.00000000e+00, 7.12768800e-12, 4.41372900e-12],\n",
       "       [7.68855700e-09, 1.00000000e+00, 1.68329810e-09],\n",
       "       [1.33338320e-08, 1.00000000e+00, 7.80653700e-09],\n",
       "       [1.20873790e-12, 1.00000000e+00, 5.13640560e-13],\n",
       "       [9.95114300e-01, 4.87847160e-03, 7.14032700e-06],\n",
       "       [2.58337020e-07, 9.99999760e-01, 4.97393520e-08],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.37395880e-08, 1.36196590e-08],\n",
       "       [2.12719940e-08, 1.00000000e+00, 1.70785790e-08],\n",
       "       [1.00000000e+00, 6.34411140e-14, 4.52363570e-14],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [7.68855700e-09, 1.00000000e+00, 1.68329810e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.00000000e+00, 3.45214480e-09, 2.12847670e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [9.99993700e-01, 4.21830000e-06, 2.09809130e-06],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [6.58652700e-09, 1.00000000e+00, 9.17759400e-10],\n",
       "       [1.00000000e+00, 6.74597000e-11, 1.09501234e-10],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.00000000e+00, 6.79196100e-10, 6.14113040e-10],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [2.50032200e-05, 9.99974500e-01, 5.32822900e-07],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.94755770e-08, 1.00000000e+00, 4.58318140e-09],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [1.94755770e-08, 1.00000000e+00, 4.58318140e-09],\n",
       "       [1.00000000e+00, 1.82220720e-14, 1.32919450e-14],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.19384850e-11, 4.48843050e-11],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675040e-09],\n",
       "       [9.99998330e-01, 1.41538780e-06, 2.15344200e-07],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [8.76966400e-08, 1.26001670e-07, 9.99999760e-01],\n",
       "       [9.99999900e-01, 6.74984050e-08, 2.96122020e-08],\n",
       "       [9.99999300e-01, 5.87688100e-07, 1.22502410e-07],\n",
       "       [2.58337020e-07, 9.99999760e-01, 4.97393520e-08],\n",
       "       [1.69043520e-08, 1.00000000e+00, 5.48027800e-09],\n",
       "       [1.00000000e+00, 1.83028940e-13, 1.34538160e-13],\n",
       "       [1.00000000e+00, 4.65994900e-09, 3.69369910e-09],\n",
       "       [1.00000000e+00, 4.74667400e-10, 3.76341070e-10],\n",
       "       [3.72870360e-01, 3.32008060e-01, 2.95121640e-01],\n",
       "       [1.75419060e-08, 1.01721940e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.83627230e-10, 2.52193040e-10],\n",
       "       [1.00000000e+00, 1.64943000e-10, 1.31714390e-10],\n",
       "       [2.00004500e-07, 9.99999760e-01, 1.28675280e-09],\n",
       "       [2.50032440e-05, 9.99974500e-01, 5.32823950e-07],\n",
       "       [1.00000000e+00, 2.67944500e-10, 2.21751950e-10],\n",
       "       [1.00000000e+00, 4.74594670e-19, 6.74825830e-19],\n",
       "       [5.69491720e-08, 8.75023360e-08, 9.99999900e-01],\n",
       "       [1.20873790e-12, 1.00000000e+00, 5.13640560e-13],\n",
       "       [1.00000000e+00, 8.83697500e-13, 6.09581800e-13],\n",
       "       [5.18231540e-08, 1.00000000e+00, 2.89452250e-08],\n",
       "       [1.58686930e-08, 1.00000000e+00, 1.71303540e-08],\n",
       "       [1.94755770e-08, 1.00000000e+00, 4.58318140e-09]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929590880022546"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929590880022546"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS260     0\n",
       "1     NRS148     2\n",
       "2     NRS205     1\n",
       "3     NRS064     1\n",
       "4     NRS209     2\n",
       "..       ...   ...\n",
       "197   NRS255     2\n",
       "198  GA53649     0\n",
       "199   NRS209     2\n",
       "200   NRS210     0\n",
       "201   NRS162     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    \n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 455us/step - loss: 3.6182 - accuracy: 0.4915 - val_loss: 0.8273 - val_accuracy: 0.6683\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.8844 - accuracy: 0.6574 - val_loss: 0.7379 - val_accuracy: 0.8069\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 2.8127 - accuracy: 0.6915 - val_loss: 0.7188 - val_accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 3.5209 - accuracy: 0.6681 - val_loss: 0.6963 - val_accuracy: 0.8168\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 3.8162 - accuracy: 0.6404 - val_loss: 0.7086 - val_accuracy: 0.8020\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 3.5246 - accuracy: 0.6617 - val_loss: 0.7120 - val_accuracy: 0.8366\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 3.3772 - accuracy: 0.6617 - val_loss: 0.7426 - val_accuracy: 0.7921\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 2.8258 - accuracy: 0.7277 - val_loss: 0.7433 - val_accuracy: 0.8218\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 3.1728 - accuracy: 0.6809 - val_loss: 0.7192 - val_accuracy: 0.8317\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 3.1169 - accuracy: 0.6809 - val_loss: 0.7708 - val_accuracy: 0.8020\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 2.9692 - accuracy: 0.6894 - val_loss: 0.7887 - val_accuracy: 0.8515\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.6649 - accuracy: 0.7213 - val_loss: 0.8014 - val_accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 3.1048 - accuracy: 0.7043 - val_loss: 0.7561 - val_accuracy: 0.8713\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 2.4365 - accuracy: 0.7532 - val_loss: 0.7150 - val_accuracy: 0.8564\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 2.5442 - accuracy: 0.7319 - val_loss: 0.7270 - val_accuracy: 0.8713\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 2.7574 - accuracy: 0.7106 - val_loss: 0.7830 - val_accuracy: 0.8713\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 2.4040 - accuracy: 0.7362 - val_loss: 0.7842 - val_accuracy: 0.8911\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 2.7052 - accuracy: 0.7383 - val_loss: 0.8538 - val_accuracy: 0.8812\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 2.5276 - accuracy: 0.7404 - val_loss: 0.8766 - val_accuracy: 0.8911\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 2.2670 - accuracy: 0.7426 - val_loss: 0.9858 - val_accuracy: 0.8614\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 2.5593 - accuracy: 0.7021 - val_loss: 1.0566 - val_accuracy: 0.8366\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.5321 - accuracy: 0.7170 - val_loss: 0.9430 - val_accuracy: 0.8911\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 1.9095 - accuracy: 0.7553 - val_loss: 0.9595 - val_accuracy: 0.8614\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 412us/step - loss: 2.3894 - accuracy: 0.7447 - val_loss: 0.8669 - val_accuracy: 0.8960\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 1.8064 - accuracy: 0.7787 - val_loss: 0.8758 - val_accuracy: 0.8812\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 2.0905 - accuracy: 0.7660 - val_loss: 0.9072 - val_accuracy: 0.8911\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 2.1024 - accuracy: 0.7553 - val_loss: 0.8252 - val_accuracy: 0.9257\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 1.9797 - accuracy: 0.7574 - val_loss: 0.8888 - val_accuracy: 0.8713\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 1.8642 - accuracy: 0.7596 - val_loss: 0.8778 - val_accuracy: 0.9010\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 360us/step - loss: 1.6209 - accuracy: 0.7638 - val_loss: 0.8975 - val_accuracy: 0.9158\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 1.7626 - accuracy: 0.7809 - val_loss: 0.8698 - val_accuracy: 0.9010\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 444us/step - loss: 1.8998 - accuracy: 0.7511 - val_loss: 0.8672 - val_accuracy: 0.8911\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.5118 - accuracy: 0.7809 - val_loss: 0.8441 - val_accuracy: 0.9158\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.7859 - accuracy: 0.7426 - val_loss: 0.8948 - val_accuracy: 0.8861\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.7136 - accuracy: 0.7681 - val_loss: 0.8197 - val_accuracy: 0.8861\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.5838 - accuracy: 0.7830 - val_loss: 0.8532 - val_accuracy: 0.8861\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.6537 - accuracy: 0.7617 - val_loss: 0.8142 - val_accuracy: 0.9109\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.7679 - accuracy: 0.7277 - val_loss: 0.9271 - val_accuracy: 0.8911\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 349us/step - loss: 1.7076 - accuracy: 0.7574 - val_loss: 0.8145 - val_accuracy: 0.9208\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.6379 - accuracy: 0.7574 - val_loss: 0.8122 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.5583 - accuracy: 0.7872 - val_loss: 0.7901 - val_accuracy: 0.9109\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.5486 - accuracy: 0.7851 - val_loss: 0.7189 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.7384 - accuracy: 0.7489 - val_loss: 0.7893 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.6050 - accuracy: 0.7830 - val_loss: 0.7534 - val_accuracy: 0.9307\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.6050 - accuracy: 0.7809 - val_loss: 0.7482 - val_accuracy: 0.9257\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 1.8143 - accuracy: 0.7191 - val_loss: 0.9223 - val_accuracy: 0.9010\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 1.6399 - accuracy: 0.7681 - val_loss: 0.7320 - val_accuracy: 0.9257\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 1.3506 - accuracy: 0.7830 - val_loss: 0.7942 - val_accuracy: 0.9455\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 1.5085 - accuracy: 0.7702 - val_loss: 0.7474 - val_accuracy: 0.9406\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.7303 - accuracy: 0.7362 - val_loss: 1.0295 - val_accuracy: 0.8861\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.3264 - accuracy: 0.7596 - val_loss: 0.7421 - val_accuracy: 0.9455\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.4910 - accuracy: 0.7553 - val_loss: 0.7143 - val_accuracy: 0.9257\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 1.5158 - accuracy: 0.7702 - val_loss: 0.8236 - val_accuracy: 0.9307\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.2569 - accuracy: 0.8085 - val_loss: 0.7270 - val_accuracy: 0.9406\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.4881 - accuracy: 0.7787 - val_loss: 0.6254 - val_accuracy: 0.9406\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.2453 - accuracy: 0.8085 - val_loss: 0.7078 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.4790 - accuracy: 0.7723 - val_loss: 0.6952 - val_accuracy: 0.9455\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.3170 - accuracy: 0.8000 - val_loss: 0.7289 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.2616 - accuracy: 0.7979 - val_loss: 0.7358 - val_accuracy: 0.9455\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.2693 - accuracy: 0.7787 - val_loss: 0.6665 - val_accuracy: 0.9455\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.1767 - accuracy: 0.7915 - val_loss: 0.8240 - val_accuracy: 0.9307\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.1682 - accuracy: 0.7894 - val_loss: 0.6232 - val_accuracy: 0.9406\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 1.3573 - accuracy: 0.7426 - val_loss: 0.6261 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.4398 - accuracy: 0.7489 - val_loss: 0.6048 - val_accuracy: 0.9455\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 1.3047 - accuracy: 0.7638 - val_loss: 0.8977 - val_accuracy: 0.9158\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.2165 - accuracy: 0.7638 - val_loss: 0.6532 - val_accuracy: 0.9505\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.2427 - accuracy: 0.7894 - val_loss: 0.7269 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 1.3124 - accuracy: 0.7702 - val_loss: 0.6048 - val_accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.1259 - accuracy: 0.7851 - val_loss: 0.6807 - val_accuracy: 0.9505\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.2127 - accuracy: 0.7872 - val_loss: 0.5647 - val_accuracy: 0.9554\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.1495 - accuracy: 0.8149 - val_loss: 0.7436 - val_accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.8697 - accuracy: 0.8234 - val_loss: 0.5922 - val_accuracy: 0.9505\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.1673 - accuracy: 0.7447 - val_loss: 0.6834 - val_accuracy: 0.9455\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.0921 - accuracy: 0.7936 - val_loss: 0.5351 - val_accuracy: 0.9554\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.0837 - accuracy: 0.7660 - val_loss: 0.7874 - val_accuracy: 0.9307\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 1.0066 - accuracy: 0.7766 - val_loss: 0.5040 - val_accuracy: 0.9604\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 1.2415 - accuracy: 0.7745 - val_loss: 0.6735 - val_accuracy: 0.9455\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 1.1567 - accuracy: 0.7851 - val_loss: 0.6259 - val_accuracy: 0.9455\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.0361 - accuracy: 0.7957 - val_loss: 0.6143 - val_accuracy: 0.9455\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 1.0400 - accuracy: 0.7830 - val_loss: 0.5416 - val_accuracy: 0.9554\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.0391 - accuracy: 0.7894 - val_loss: 0.6046 - val_accuracy: 0.9505\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.1629 - accuracy: 0.8000 - val_loss: 0.5743 - val_accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 1.1385 - accuracy: 0.7681 - val_loss: 0.6381 - val_accuracy: 0.9505\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.0865 - accuracy: 0.7596 - val_loss: 0.5341 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.0473 - accuracy: 0.7617 - val_loss: 0.6460 - val_accuracy: 0.9505\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.9386 - accuracy: 0.7809 - val_loss: 0.7281 - val_accuracy: 0.9406\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9741 - accuracy: 0.7596 - val_loss: 0.5070 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.0825 - accuracy: 0.7787 - val_loss: 0.6947 - val_accuracy: 0.9356\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.9603 - accuracy: 0.7872 - val_loss: 0.4684 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 312us/step - loss: 0.9441 - accuracy: 0.7574 - val_loss: 0.5260 - val_accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.8508 - accuracy: 0.7915 - val_loss: 0.5832 - val_accuracy: 0.9505\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 333us/step - loss: 0.7916 - accuracy: 0.7894 - val_loss: 0.4928 - val_accuracy: 0.9554\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.9039 - accuracy: 0.8085 - val_loss: 0.6540 - val_accuracy: 0.9455\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 373us/step - loss: 1.1196 - accuracy: 0.7489 - val_loss: 0.6191 - val_accuracy: 0.9505\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.9874 - accuracy: 0.7702 - val_loss: 0.6305 - val_accuracy: 0.9455\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.0373 - accuracy: 0.7766 - val_loss: 0.5301 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.0007 - accuracy: 0.7787 - val_loss: 0.5067 - val_accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.9066 - accuracy: 0.7723 - val_loss: 0.5557 - val_accuracy: 0.9505\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 0.8522 - accuracy: 0.7872 - val_loss: 0.5410 - val_accuracy: 0.9505\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 0.8761 - accuracy: 0.7596 - val_loss: 0.6126 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39de7e48>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 400us/step\n",
      "over-sampling test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 1,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1,\n",
       "       0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1,\n",
       "       2, 2, 2, 0, 1, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1,\n",
       "       0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 0, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 2, 2, 1, 0,\n",
       "       1, 1, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2,\n",
       "       1, 1, 1, 2, 1, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2,\n",
       "       0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS260     0     0\n",
       "1     NRS148     2     2\n",
       "2     NRS205     1     2\n",
       "3     NRS064     1     1\n",
       "4     NRS209     2     2\n",
       "..       ...   ...   ...\n",
       "197   NRS255     2     2\n",
       "198  GA53649     0     0\n",
       "199   NRS209     2     2\n",
       "200   NRS210     0     0\n",
       "201   NRS162     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.994460e-01</td>\n",
       "      <td>5.363244e-04</td>\n",
       "      <td>1.764490e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.202002e-08</td>\n",
       "      <td>6.790426e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.680430e-01</td>\n",
       "      <td>1.410613e-01</td>\n",
       "      <td>4.908957e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.834393e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.849045e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.490408e-08</td>\n",
       "      <td>4.486665e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.314651e-08</td>\n",
       "      <td>4.263710e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>9.999968e-01</td>\n",
       "      <td>1.463843e-06</td>\n",
       "      <td>1.837797e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3.490415e-08</td>\n",
       "      <td>4.486665e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.822029e-01</td>\n",
       "      <td>1.778526e-02</td>\n",
       "      <td>1.183655e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.999961e-01</td>\n",
       "      <td>3.486899e-06</td>\n",
       "      <td>4.636105e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.994460e-01  5.363244e-04  1.764490e-05\n",
       "1    3.202002e-08  6.790426e-08  9.999999e-01\n",
       "2    3.680430e-01  1.410613e-01  4.908957e-01\n",
       "3    5.834393e-09  1.000000e+00  6.849045e-10\n",
       "4    3.490408e-08  4.486665e-08  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "197  3.314651e-08  4.263710e-08  9.999999e-01\n",
       "198  9.999968e-01  1.463843e-06  1.837797e-06\n",
       "199  3.490415e-08  4.486665e-08  9.999999e-01\n",
       "200  9.822029e-01  1.778526e-02  1.183655e-05\n",
       "201  9.999961e-01  3.486899e-06  4.636105e-07\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.9161 - accuracy: 0.8064 - val_loss: 0.7117 - val_accuracy: 0.9356\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.2447 - accuracy: 0.7872 - val_loss: 0.5647 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.0119 - accuracy: 0.7681 - val_loss: 0.5549 - val_accuracy: 0.9604\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.9783 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.9604\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.9361 - accuracy: 0.8043 - val_loss: 0.5579 - val_accuracy: 0.9604\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.2133 - accuracy: 0.7638 - val_loss: 0.5875 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.0607 - accuracy: 0.7702 - val_loss: 0.6383 - val_accuracy: 0.9505\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 1.1959 - accuracy: 0.7426 - val_loss: 0.4737 - val_accuracy: 0.9604\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.9622 - accuracy: 0.8106 - val_loss: 0.5940 - val_accuracy: 0.9554\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 1.2233 - accuracy: 0.8128 - val_loss: 0.5502 - val_accuracy: 0.9604\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 1.1408 - accuracy: 0.7638 - val_loss: 0.6617 - val_accuracy: 0.9505\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.1981 - accuracy: 0.7638 - val_loss: 0.5848 - val_accuracy: 0.9604\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.0028 - accuracy: 0.8021 - val_loss: 0.5550 - val_accuracy: 0.9604\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.0804 - accuracy: 0.7809 - val_loss: 0.5751 - val_accuracy: 0.9604\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.9387 - accuracy: 0.8021 - val_loss: 0.5817 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.1353 - accuracy: 0.7830 - val_loss: 0.5547 - val_accuracy: 0.9604\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 457us/step - loss: 1.0885 - accuracy: 0.7702 - val_loss: 0.5331 - val_accuracy: 0.9604\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.9523 - accuracy: 0.7872 - val_loss: 0.5206 - val_accuracy: 0.9604\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 1.0017 - accuracy: 0.7894 - val_loss: 0.6058 - val_accuracy: 0.9554\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.9629 - accuracy: 0.7936 - val_loss: 0.5453 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 635us/step - loss: 0.9771 - accuracy: 0.7915 - val_loss: 0.6099 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 362us/step - loss: 0.9134 - accuracy: 0.8043 - val_loss: 0.5620 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 523us/step - loss: 0.9062 - accuracy: 0.7851 - val_loss: 0.5522 - val_accuracy: 0.9604\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 426us/step - loss: 1.0271 - accuracy: 0.8213 - val_loss: 0.5797 - val_accuracy: 0.9604\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 1.0923 - accuracy: 0.7660 - val_loss: 0.5867 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.7677 - accuracy: 0.8085 - val_loss: 0.5362 - val_accuracy: 0.9604\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.9599 - accuracy: 0.7915 - val_loss: 0.6488 - val_accuracy: 0.9554\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.0337 - accuracy: 0.7894 - val_loss: 0.5293 - val_accuracy: 0.9604\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.9721 - accuracy: 0.8170 - val_loss: 0.5902 - val_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 506us/step - loss: 0.9529 - accuracy: 0.7723 - val_loss: 0.5777 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 737us/step - loss: 1.1207 - accuracy: 0.7660 - val_loss: 0.5688 - val_accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 459us/step - loss: 1.1699 - accuracy: 0.7702 - val_loss: 0.5359 - val_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 1.1615 - accuracy: 0.7617 - val_loss: 0.5567 - val_accuracy: 0.9604\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.9883 - accuracy: 0.7702 - val_loss: 0.5583 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 528us/step - loss: 1.0431 - accuracy: 0.7851 - val_loss: 0.5959 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 310us/step - loss: 0.9861 - accuracy: 0.7872 - val_loss: 0.5112 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 1.0163 - accuracy: 0.7936 - val_loss: 0.6649 - val_accuracy: 0.9455\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 354us/step - loss: 0.9028 - accuracy: 0.8000 - val_loss: 0.5181 - val_accuracy: 0.9604\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 1.0002 - accuracy: 0.7979 - val_loss: 0.5560 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 293us/step - loss: 1.1741 - accuracy: 0.7511 - val_loss: 0.6397 - val_accuracy: 0.9554\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.9531 - accuracy: 0.7915 - val_loss: 0.5133 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.7948 - accuracy: 0.8277 - val_loss: 0.5416 - val_accuracy: 0.9604\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.7918 - accuracy: 0.8064 - val_loss: 0.5645 - val_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 1.0862 - accuracy: 0.7830 - val_loss: 0.5418 - val_accuracy: 0.9604\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.8976 - accuracy: 0.8149 - val_loss: 0.5252 - val_accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.7194 - accuracy: 0.8340 - val_loss: 0.5488 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.9564 - accuracy: 0.8043 - val_loss: 0.5354 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 552us/step - loss: 0.8851 - accuracy: 0.8128 - val_loss: 0.5941 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.9263 - accuracy: 0.7809 - val_loss: 0.5537 - val_accuracy: 0.9604\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 393us/step - loss: 1.1815 - accuracy: 0.7766 - val_loss: 0.5947 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 495us/step - loss: 1.0820 - accuracy: 0.7979 - val_loss: 0.5504 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 289us/step - loss: 0.8731 - accuracy: 0.8128 - val_loss: 0.5227 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 337us/step - loss: 1.0641 - accuracy: 0.7787 - val_loss: 0.5535 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.9143 - accuracy: 0.8106 - val_loss: 0.5314 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 0.7408 - accuracy: 0.8191 - val_loss: 0.5052 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 354us/step - loss: 1.0724 - accuracy: 0.8064 - val_loss: 0.5884 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.9538 - accuracy: 0.7979 - val_loss: 0.5218 - val_accuracy: 0.9604\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.9995 - accuracy: 0.7723 - val_loss: 0.5960 - val_accuracy: 0.9604\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.9254 - accuracy: 0.8106 - val_loss: 0.5536 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 0.7802 - accuracy: 0.7957 - val_loss: 0.5384 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 1.1576 - accuracy: 0.7553 - val_loss: 0.5998 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 1.1301 - accuracy: 0.7830 - val_loss: 0.4769 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.0377 - accuracy: 0.7830 - val_loss: 0.5586 - val_accuracy: 0.9604\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.9202 - accuracy: 0.7766 - val_loss: 0.5119 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.0424 - accuracy: 0.7596 - val_loss: 0.5327 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.8877 - accuracy: 0.7957 - val_loss: 0.5771 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.9158 - accuracy: 0.8021 - val_loss: 0.5415 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.9125 - accuracy: 0.7766 - val_loss: 0.5397 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 533us/step - loss: 0.8417 - accuracy: 0.8106 - val_loss: 0.5926 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 419us/step - loss: 0.8980 - accuracy: 0.7766 - val_loss: 0.5167 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 318us/step - loss: 0.8064 - accuracy: 0.8085 - val_loss: 0.5302 - val_accuracy: 0.9604\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 404us/step - loss: 1.0865 - accuracy: 0.7809 - val_loss: 0.5443 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 470us/step - loss: 1.0403 - accuracy: 0.7979 - val_loss: 0.5811 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 328us/step - loss: 1.0605 - accuracy: 0.8170 - val_loss: 0.5745 - val_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.9020 - accuracy: 0.7894 - val_loss: 0.4924 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 344us/step - loss: 0.9428 - accuracy: 0.7894 - val_loss: 0.6547 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.9592 - accuracy: 0.8043 - val_loss: 0.5325 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.8879 - accuracy: 0.8191 - val_loss: 0.5356 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.6531 - accuracy: 0.8447 - val_loss: 0.5221 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.1381 - accuracy: 0.7574 - val_loss: 0.5726 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.9432 - accuracy: 0.7787 - val_loss: 0.5130 - val_accuracy: 0.9604\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 1.0153 - accuracy: 0.7830 - val_loss: 0.5532 - val_accuracy: 0.9604\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 1.0268 - accuracy: 0.7723 - val_loss: 0.5194 - val_accuracy: 0.9604\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.9241 - accuracy: 0.8021 - val_loss: 0.5181 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.9016 - accuracy: 0.7617 - val_loss: 0.5717 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.9718 - accuracy: 0.7638 - val_loss: 0.5382 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 0.9262 - accuracy: 0.8021 - val_loss: 0.4408 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 316us/step - loss: 1.0027 - accuracy: 0.7745 - val_loss: 0.6157 - val_accuracy: 0.9554\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.9844 - accuracy: 0.8021 - val_loss: 0.5312 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.6671 - accuracy: 0.8128 - val_loss: 0.5389 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.9091 - accuracy: 0.8021 - val_loss: 0.5039 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.9722 - accuracy: 0.8000 - val_loss: 0.5411 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.8076 - accuracy: 0.8021 - val_loss: 0.5026 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.8704 - accuracy: 0.7872 - val_loss: 0.5388 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.7199 - accuracy: 0.8277 - val_loss: 0.5290 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.9158 - accuracy: 0.8000 - val_loss: 0.5623 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.8157 - accuracy: 0.8085 - val_loss: 0.4831 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 0.9576 - accuracy: 0.7957 - val_loss: 0.5987 - val_accuracy: 0.9554\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 1.0767 - accuracy: 0.7787 - val_loss: 0.5177 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.8286 - accuracy: 0.7979 - val_loss: 0.5224 - val_accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.15%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99446000e-01, 5.36324400e-04, 1.76449010e-05],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.68043040e-01, 1.41061260e-01, 4.90895750e-01],\n",
       "       [5.83439340e-09, 1.00000000e+00, 6.84904470e-10],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [6.52873800e-07, 9.99999400e-01, 2.69478100e-08],\n",
       "       [1.00801790e-06, 9.99999050e-01, 1.17269650e-09],\n",
       "       [6.52873800e-07, 9.99999400e-01, 2.69478100e-08],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.92416010e-08, 3.14146500e-08],\n",
       "       [1.00000000e+00, 3.35057800e-08, 1.04133310e-09],\n",
       "       [1.12340330e-04, 9.99853400e-01, 3.42142230e-05],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.44459400e-09, 1.12767170e-08],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [9.99512430e-01, 4.85869100e-04, 1.61493590e-06],\n",
       "       [7.79621300e-08, 9.99999900e-01, 1.39343970e-08],\n",
       "       [8.88358700e-06, 9.99990940e-01, 1.22629030e-07],\n",
       "       [1.00000000e+00, 5.25516200e-10, 5.39168780e-11],\n",
       "       [5.25170500e-07, 9.99999400e-01, 1.15438716e-07],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 1.26358460e-07, 1.24368480e-07],\n",
       "       [6.76810500e-05, 9.99932170e-01, 1.59117520e-07],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [2.37818140e-09, 1.00000000e+00, 3.00001200e-10],\n",
       "       [1.00000000e+00, 6.15694000e-10, 5.84762570e-10],\n",
       "       [6.10185130e-06, 9.99993900e-01, 5.40765730e-08],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.01283676e-10, 1.00000000e+00, 8.99176900e-12],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.01179936e-07, 9.99999900e-01, 1.35601960e-08],\n",
       "       [9.43531700e-10, 1.00000000e+00, 1.01410290e-10],\n",
       "       [2.17605310e-09, 1.00000000e+00, 2.46075800e-10],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [1.00000000e+00, 2.92416010e-08, 3.14146500e-08],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [9.99999050e-01, 7.20314060e-07, 2.08601290e-07],\n",
       "       [2.33185520e-08, 1.00000000e+00, 3.67234380e-09],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [9.99998800e-01, 6.96541400e-07, 4.17248430e-07],\n",
       "       [9.99751270e-01, 2.41294950e-04, 7.34933470e-06],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [9.99965900e-01, 3.23012600e-05, 1.76332740e-06],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.87279430e-05, 9.99960660e-01, 5.62178570e-07],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [2.17605310e-09, 1.00000000e+00, 2.46075800e-10],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [9.99998100e-01, 1.53868480e-06, 3.55748800e-07],\n",
       "       [9.98694960e-01, 1.29789130e-03, 7.19413500e-06],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 4.09304840e-08, 2.57841100e-09],\n",
       "       [1.01179936e-07, 9.99999900e-01, 1.35601960e-08],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.68043040e-01, 1.41061260e-01, 4.90895750e-01],\n",
       "       [3.68043040e-01, 1.41061260e-01, 4.90895750e-01],\n",
       "       [9.99999170e-01, 7.46327200e-07, 1.43192500e-07],\n",
       "       [5.83439340e-09, 1.00000000e+00, 6.84904470e-10],\n",
       "       [5.42856470e-12, 1.00000000e+00, 3.06805340e-13],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [1.01179936e-07, 9.99999900e-01, 1.35601960e-08],\n",
       "       [9.99988800e-01, 7.00928800e-06, 4.15961180e-06],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [5.81027560e-08, 1.00000000e+00, 9.05933400e-09],\n",
       "       [3.68043040e-01, 1.41061260e-01, 4.90895750e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [9.99999050e-01, 6.89483160e-07, 2.54608800e-07],\n",
       "       [1.00000000e+00, 1.33624740e-08, 8.18456250e-10],\n",
       "       [9.99959470e-01, 2.37665230e-05, 1.68467230e-05],\n",
       "       [9.91581260e-01, 8.38929400e-03, 2.94513500e-05],\n",
       "       [9.99942660e-01, 5.48012140e-05, 2.44559780e-06],\n",
       "       [2.17605310e-09, 1.00000000e+00, 2.46075800e-10],\n",
       "       [1.00000000e+00, 3.03657540e-09, 2.46087200e-09],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [4.67917960e-02, 9.53185800e-01, 2.23937770e-05],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.21935710e-09, 6.84138000e-10],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [5.42856470e-12, 1.00000000e+00, 3.06805340e-13],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 1.43211150e-07, 9.16848600e-08],\n",
       "       [9.99999900e-01, 6.23667900e-08, 2.86172770e-08],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [1.20932540e-07, 9.99999900e-01, 2.09525890e-08],\n",
       "       [3.87279430e-05, 9.99960660e-01, 5.62178570e-07],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.20932540e-07, 9.99999900e-01, 2.09525890e-08],\n",
       "       [9.51307800e-01, 4.86471400e-02, 4.51075200e-05],\n",
       "       [5.95372640e-08, 1.00000000e+00, 1.13211980e-08],\n",
       "       [9.42075600e-09, 1.00000000e+00, 1.35047740e-09],\n",
       "       [1.01283676e-10, 1.00000000e+00, 8.99176900e-12],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [6.52873800e-07, 9.99999400e-01, 2.69478100e-08],\n",
       "       [1.00000000e+00, 4.50170100e-08, 4.13307170e-09],\n",
       "       [1.00000000e+00, 2.08643140e-10, 1.12012006e-11],\n",
       "       [1.00000000e+00, 5.57305240e-08, 5.29156500e-09],\n",
       "       [9.99999400e-01, 2.66991260e-07, 3.41938060e-07],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [2.94978040e-05, 9.99969960e-01, 6.55116700e-07],\n",
       "       [1.00000000e+00, 2.92416010e-08, 3.14146500e-08],\n",
       "       [8.49610500e-01, 1.45452990e-01, 4.93660850e-03],\n",
       "       [1.00000000e+00, 5.63384360e-08, 2.93238160e-08],\n",
       "       [9.99784400e-01, 2.14103710e-04, 1.52764550e-06],\n",
       "       [3.55967170e-08, 1.00000000e+00, 2.70187700e-10],\n",
       "       [1.01283676e-10, 1.00000000e+00, 8.99176900e-12],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.03657540e-09, 2.46087200e-09],\n",
       "       [1.01179936e-07, 9.99999900e-01, 1.35601960e-08],\n",
       "       [7.79621300e-08, 9.99999900e-01, 1.39343970e-08],\n",
       "       [5.42856470e-12, 1.00000000e+00, 3.06805340e-13],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.87279430e-05, 9.99960660e-01, 5.62178570e-07],\n",
       "       [9.97202750e-01, 2.78151080e-03, 1.57542650e-05],\n",
       "       [3.87279430e-05, 9.99960660e-01, 5.62178570e-07],\n",
       "       [9.42075600e-09, 1.00000000e+00, 1.35047740e-09],\n",
       "       [9.99196100e-01, 8.03392440e-04, 4.30428460e-07],\n",
       "       [5.25170500e-07, 9.99999400e-01, 1.15438716e-07],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [1.12129050e-02, 9.88782700e-01, 4.33365700e-06],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.46194560e-08, 1.00000000e+00, 1.24394960e-09],\n",
       "       [6.52873800e-07, 9.99999400e-01, 2.69478100e-08],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [9.99997500e-01, 1.62420570e-06, 8.71258800e-07],\n",
       "       [9.86955600e-01, 1.30379675e-02, 6.51711840e-06],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [9.99899860e-01, 5.82028950e-05, 4.20054930e-05],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [9.99999640e-01, 2.54643450e-07, 7.25715800e-08],\n",
       "       [9.99323250e-01, 6.68247500e-04, 8.52117500e-06],\n",
       "       [9.99996300e-01, 2.19252550e-06, 1.56519790e-06],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [1.01283676e-10, 1.00000000e+00, 8.99176900e-12],\n",
       "       [9.43531700e-10, 1.00000000e+00, 1.01410290e-10],\n",
       "       [2.37949840e-08, 1.00000000e+00, 2.92807670e-09],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [4.58901840e-07, 9.99999500e-01, 1.17792310e-08],\n",
       "       [9.99999760e-01, 7.55303300e-08, 9.81723150e-08],\n",
       "       [2.37818140e-09, 1.00000000e+00, 3.00001200e-10],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [9.99999760e-01, 1.29850460e-07, 1.10212746e-07],\n",
       "       [9.99998570e-01, 1.34342920e-06, 1.68003210e-07],\n",
       "       [2.17605310e-09, 1.00000000e+00, 2.46075800e-10],\n",
       "       [1.00801790e-06, 9.99999050e-01, 1.17269650e-09],\n",
       "       [1.00000000e+00, 3.13411000e-08, 4.11578260e-08],\n",
       "       [5.25170500e-07, 9.99999400e-01, 1.15438716e-07],\n",
       "       [1.00000000e+00, 2.30534770e-08, 1.27047530e-08],\n",
       "       [6.52873800e-07, 9.99999400e-01, 2.69478100e-08],\n",
       "       [5.17892000e-01, 4.82059800e-01, 4.81959720e-05],\n",
       "       [1.00801790e-06, 9.99999050e-01, 1.17269650e-09],\n",
       "       [9.99964000e-01, 2.72925800e-05, 8.69781300e-06],\n",
       "       [7.79621300e-08, 9.99999900e-01, 1.39343970e-08],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [9.99998330e-01, 1.32700780e-06, 4.14579630e-07],\n",
       "       [6.76810500e-05, 9.99932170e-01, 1.59117520e-07],\n",
       "       [3.31465130e-08, 4.26370200e-08, 9.99999900e-01],\n",
       "       [9.99999300e-01, 3.26891240e-07, 3.11030650e-07],\n",
       "       [1.00000000e+00, 4.27487000e-10, 5.90320960e-10],\n",
       "       [3.62443530e-07, 9.99999500e-01, 8.39555100e-08],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [6.76810500e-05, 9.99932170e-01, 1.59117520e-07],\n",
       "       [9.99999760e-01, 1.38263080e-07, 1.78443800e-07],\n",
       "       [5.25170500e-07, 9.99999400e-01, 1.15438716e-07],\n",
       "       [6.51420830e-01, 3.46567060e-01, 2.01207800e-03],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [3.49040830e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [5.25170500e-07, 9.99999400e-01, 1.15438716e-07],\n",
       "       [1.12340330e-04, 9.99853400e-01, 3.42142230e-05],\n",
       "       [3.20200150e-08, 6.79042600e-08, 9.99999900e-01],\n",
       "       [3.20201360e-08, 6.79043900e-08, 9.99999900e-01],\n",
       "       [1.20932430e-07, 9.99999900e-01, 2.09525480e-08],\n",
       "       [3.49041500e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.35442090e-10, 1.89566000e-10],\n",
       "       [3.20201360e-08, 6.79043900e-08, 9.99999900e-01],\n",
       "       [3.31465130e-08, 4.26371000e-08, 9.99999900e-01],\n",
       "       [9.99996800e-01, 1.46384250e-06, 1.83779720e-06],\n",
       "       [3.49041500e-08, 4.48666500e-08, 9.99999900e-01],\n",
       "       [9.82202900e-01, 1.77852600e-02, 1.18365530e-05],\n",
       "       [9.99996070e-01, 3.48689850e-06, 4.63610550e-07]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898654873779251"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898654873779251"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0     CA541     1\n",
       "1    SR3585     0\n",
       "2    NRS232     1\n",
       "3    NRS148     2\n",
       "4    NRS180     1\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS035     1\n",
       "199     506     0\n",
       "200  SR2091     0\n",
       "201  NRS205     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 581us/step - loss: 3.5614 - accuracy: 0.5894 - val_loss: 0.7760 - val_accuracy: 0.7673\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 3.0184 - accuracy: 0.7149 - val_loss: 0.7138 - val_accuracy: 0.7921\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 2.9050 - accuracy: 0.7191 - val_loss: 0.7065 - val_accuracy: 0.8465\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 2.9887 - accuracy: 0.7170 - val_loss: 0.6931 - val_accuracy: 0.8465\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 299us/step - loss: 2.9209 - accuracy: 0.7106 - val_loss: 0.6986 - val_accuracy: 0.8564\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 2.9025 - accuracy: 0.7106 - val_loss: 0.7628 - val_accuracy: 0.8663\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 2.8214 - accuracy: 0.7447 - val_loss: 0.7558 - val_accuracy: 0.8614\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 3.0355 - accuracy: 0.7191 - val_loss: 0.7998 - val_accuracy: 0.8713\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 313us/step - loss: 3.1672 - accuracy: 0.7255 - val_loss: 0.9277 - val_accuracy: 0.8663\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 2.5120 - accuracy: 0.7447 - val_loss: 1.0063 - val_accuracy: 0.8911\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.6182 - accuracy: 0.7468 - val_loss: 1.0331 - val_accuracy: 0.8812\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.3242 - accuracy: 0.7489 - val_loss: 0.9092 - val_accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 2.0729 - accuracy: 0.7702 - val_loss: 0.9934 - val_accuracy: 0.8960\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.3452 - accuracy: 0.7574 - val_loss: 1.0806 - val_accuracy: 0.8515\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 2.5698 - accuracy: 0.7383 - val_loss: 1.0184 - val_accuracy: 0.8564\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.4944 - accuracy: 0.6787 - val_loss: 0.9647 - val_accuracy: 0.8614\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 2.0662 - accuracy: 0.7766 - val_loss: 0.9517 - val_accuracy: 0.8515\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 2.2823 - accuracy: 0.7723 - val_loss: 1.0616 - val_accuracy: 0.8663\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 2.4754 - accuracy: 0.7277 - val_loss: 1.3837 - val_accuracy: 0.8465\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.4250 - accuracy: 0.7213 - val_loss: 1.0841 - val_accuracy: 0.8366\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.0367 - accuracy: 0.7553 - val_loss: 1.0894 - val_accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.9133 - accuracy: 0.7766 - val_loss: 1.1751 - val_accuracy: 0.8861\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 2.2386 - accuracy: 0.7213 - val_loss: 1.1433 - val_accuracy: 0.8713\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 368us/step - loss: 1.9780 - accuracy: 0.7511 - val_loss: 1.0477 - val_accuracy: 0.8812\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 450us/step - loss: 2.1764 - accuracy: 0.7340 - val_loss: 1.0284 - val_accuracy: 0.8614\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 292us/step - loss: 1.9157 - accuracy: 0.7553 - val_loss: 1.0669 - val_accuracy: 0.8762\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 395us/step - loss: 2.1041 - accuracy: 0.7234 - val_loss: 1.0421 - val_accuracy: 0.8762\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 1.6973 - accuracy: 0.7936 - val_loss: 0.9433 - val_accuracy: 0.9059\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 1.8887 - accuracy: 0.7660 - val_loss: 0.9474 - val_accuracy: 0.9158\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 642us/step - loss: 1.9425 - accuracy: 0.7702 - val_loss: 0.9772 - val_accuracy: 0.9010\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 1.8841 - accuracy: 0.7532 - val_loss: 0.9682 - val_accuracy: 0.8960\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.8611 - accuracy: 0.7809 - val_loss: 0.9146 - val_accuracy: 0.9059\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.8034 - accuracy: 0.7404 - val_loss: 0.9057 - val_accuracy: 0.9257\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 1.4286 - accuracy: 0.8021 - val_loss: 0.9072 - val_accuracy: 0.8960\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.8721 - accuracy: 0.7596 - val_loss: 0.9342 - val_accuracy: 0.9208\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 448us/step - loss: 1.6546 - accuracy: 0.7702 - val_loss: 0.8312 - val_accuracy: 0.8960\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 1.5840 - accuracy: 0.7830 - val_loss: 1.0028 - val_accuracy: 0.8960\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.8553 - accuracy: 0.7340 - val_loss: 0.9554 - val_accuracy: 0.9109\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 1.8480 - accuracy: 0.7383 - val_loss: 0.8692 - val_accuracy: 0.9307\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.6795 - accuracy: 0.7617 - val_loss: 0.7879 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.5337 - accuracy: 0.7511 - val_loss: 0.9672 - val_accuracy: 0.9208\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 1.7421 - accuracy: 0.7489 - val_loss: 0.7361 - val_accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.4687 - accuracy: 0.7745 - val_loss: 0.8503 - val_accuracy: 0.9208\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.8400 - accuracy: 0.7447 - val_loss: 0.8059 - val_accuracy: 0.9208\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.3922 - accuracy: 0.7809 - val_loss: 0.7573 - val_accuracy: 0.9554\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.5870 - accuracy: 0.7638 - val_loss: 0.7834 - val_accuracy: 0.9257\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.2239 - accuracy: 0.7915 - val_loss: 0.7112 - val_accuracy: 0.9406\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.3650 - accuracy: 0.7809 - val_loss: 0.7402 - val_accuracy: 0.9455\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.5794 - accuracy: 0.7638 - val_loss: 0.8368 - val_accuracy: 0.9158\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.4960 - accuracy: 0.7830 - val_loss: 0.6798 - val_accuracy: 0.9455\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.4022 - accuracy: 0.7957 - val_loss: 0.8489 - val_accuracy: 0.9158\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.5428 - accuracy: 0.7745 - val_loss: 0.7664 - val_accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.3746 - accuracy: 0.7702 - val_loss: 0.8046 - val_accuracy: 0.9208\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.3625 - accuracy: 0.7553 - val_loss: 0.7571 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.2752 - accuracy: 0.7745 - val_loss: 0.7143 - val_accuracy: 0.9554\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.2435 - accuracy: 0.7681 - val_loss: 0.7014 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.3557 - accuracy: 0.7596 - val_loss: 0.6483 - val_accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2320 - accuracy: 0.7830 - val_loss: 0.7192 - val_accuracy: 0.9356\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.3828 - accuracy: 0.7830 - val_loss: 0.6858 - val_accuracy: 0.9554\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 298us/step - loss: 1.0939 - accuracy: 0.8043 - val_loss: 0.6402 - val_accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 346us/step - loss: 1.1071 - accuracy: 0.7936 - val_loss: 0.6400 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 1.2859 - accuracy: 0.8000 - val_loss: 0.6094 - val_accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.2132 - accuracy: 0.7723 - val_loss: 0.6831 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 334us/step - loss: 1.2012 - accuracy: 0.7553 - val_loss: 0.6811 - val_accuracy: 0.9554\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 331us/step - loss: 1.2775 - accuracy: 0.7489 - val_loss: 0.6438 - val_accuracy: 0.9554\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 1.1098 - accuracy: 0.7851 - val_loss: 0.6459 - val_accuracy: 0.9554\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.2061 - accuracy: 0.7745 - val_loss: 0.6188 - val_accuracy: 0.9554\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 287us/step - loss: 1.2168 - accuracy: 0.7702 - val_loss: 0.5712 - val_accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.9800 - accuracy: 0.7511 - val_loss: 0.6483 - val_accuracy: 0.9406\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.0500 - accuracy: 0.7766 - val_loss: 0.5964 - val_accuracy: 0.9554\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.1564 - accuracy: 0.7404 - val_loss: 0.5845 - val_accuracy: 0.9653\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.0634 - accuracy: 0.7809 - val_loss: 0.5941 - val_accuracy: 0.9505\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.0050 - accuracy: 0.7766 - val_loss: 0.5690 - val_accuracy: 0.9406\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.9488 - accuracy: 0.7872 - val_loss: 0.7609 - val_accuracy: 0.9257\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.9743 - accuracy: 0.8043 - val_loss: 0.5168 - val_accuracy: 0.9554\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 1.1338 - accuracy: 0.8064 - val_loss: 0.6720 - val_accuracy: 0.9455\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 409us/step - loss: 1.0118 - accuracy: 0.7766 - val_loss: 0.5310 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 1.1327 - accuracy: 0.7447 - val_loss: 0.6169 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.8672 - accuracy: 0.7809 - val_loss: 0.5726 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.0123 - accuracy: 0.7702 - val_loss: 0.5273 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.9555 - accuracy: 0.7447 - val_loss: 0.6394 - val_accuracy: 0.9505\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.9662 - accuracy: 0.7553 - val_loss: 0.5170 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.7961 - accuracy: 0.8298 - val_loss: 0.5286 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.8060 - accuracy: 0.8064 - val_loss: 0.5440 - val_accuracy: 0.9851\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.8141 - accuracy: 0.7915 - val_loss: 0.5571 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.8021 - accuracy: 0.8234 - val_loss: 0.4738 - val_accuracy: 0.9752\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.8565 - accuracy: 0.8043 - val_loss: 0.5070 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.9783 - accuracy: 0.7830 - val_loss: 0.5377 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.9735 - accuracy: 0.7894 - val_loss: 0.7405 - val_accuracy: 0.9455\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.8991 - accuracy: 0.7957 - val_loss: 0.5082 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.9185 - accuracy: 0.7979 - val_loss: 0.5392 - val_accuracy: 0.9802\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.8370 - accuracy: 0.8043 - val_loss: 0.5180 - val_accuracy: 0.9901\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.8231 - accuracy: 0.7957 - val_loss: 0.4982 - val_accuracy: 0.9802\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.9573 - accuracy: 0.7723 - val_loss: 0.5296 - val_accuracy: 0.9802\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.7972 - accuracy: 0.7915 - val_loss: 0.5179 - val_accuracy: 0.9901\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.8568 - accuracy: 0.7936 - val_loss: 0.4985 - val_accuracy: 0.9901\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.6960 - accuracy: 0.7872 - val_loss: 0.4886 - val_accuracy: 0.9851\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.8833 - accuracy: 0.7766 - val_loss: 0.5224 - val_accuracy: 0.9901\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.8244 - accuracy: 0.8106 - val_loss: 0.5205 - val_accuracy: 0.9901\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.7015 - accuracy: 0.7915 - val_loss: 0.4987 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3a4b3518>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 112us/step\n",
      "over-sampling test accuracy: 98.02%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 2,\n",
       "       1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 0, 2, 2, 1, 1, 1, 0, 0, 2, 0, 2, 0, 1, 2, 1, 2, 1, 0, 2,\n",
       "       0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 1,\n",
       "       1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1, 2, 1,\n",
       "       0, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 0,\n",
       "       2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 0, 0, 1, 0, 0, 1, 2, 2,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0     CA541     1     1\n",
       "1    SR3585     0     0\n",
       "2    NRS232     1     1\n",
       "3    NRS148     2     2\n",
       "4    NRS180     1     1\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS035     1     1\n",
       "199     506     0     0\n",
       "200  SR2091     0     0\n",
       "201  NRS205     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.049835e-07</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>3.384297e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.947699e-11</td>\n",
       "      <td>7.612437e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.787098e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>5.476143e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.462030e-09</td>\n",
       "      <td>3.260693e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.225878e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>4.815261e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>7.304264e-08</td>\n",
       "      <td>7.608065e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.169835e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.569366e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.985692e-13</td>\n",
       "      <td>1.622500e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.967397e-01</td>\n",
       "      <td>3.254553e-03</td>\n",
       "      <td>5.816956e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4.364889e-02</td>\n",
       "      <td>8.128669e-01</td>\n",
       "      <td>1.434842e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    5.049835e-07  9.999992e-01  3.384297e-07\n",
       "1    1.000000e+00  3.947699e-11  7.612437e-11\n",
       "2    1.787098e-07  9.999999e-01  5.476143e-08\n",
       "3    9.462030e-09  3.260693e-08  1.000000e+00\n",
       "4    1.225878e-07  9.999999e-01  4.815261e-08\n",
       "..            ...           ...           ...\n",
       "197  7.304264e-08  7.608065e-08  9.999999e-01\n",
       "198  1.169835e-07  9.999999e-01  3.569366e-08\n",
       "199  1.000000e+00  4.985692e-13  1.622500e-12\n",
       "200  9.967397e-01  3.254553e-03  5.816956e-06\n",
       "201  4.364889e-02  8.128669e-01  1.434842e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p003pp.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.8518 - accuracy: 0.8021 - val_loss: 0.5288 - val_accuracy: 0.9752\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.7939 - accuracy: 0.8149 - val_loss: 0.5082 - val_accuracy: 0.9802\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.7611 - accuracy: 0.8043 - val_loss: 0.6233 - val_accuracy: 0.9505\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.7633 - accuracy: 0.7745 - val_loss: 0.5599 - val_accuracy: 0.9703\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.8188 - accuracy: 0.7915 - val_loss: 0.5342 - val_accuracy: 0.9802\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.8418 - accuracy: 0.7766 - val_loss: 0.5542 - val_accuracy: 0.9802\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7079 - accuracy: 0.8255 - val_loss: 0.5208 - val_accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.7542 - accuracy: 0.8213 - val_loss: 0.5245 - val_accuracy: 0.9802\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.7774 - accuracy: 0.7894 - val_loss: 0.5328 - val_accuracy: 0.9802\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7081 - accuracy: 0.8128 - val_loss: 0.5230 - val_accuracy: 0.9802\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.7291 - accuracy: 0.8021 - val_loss: 0.4993 - val_accuracy: 0.9851\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.6212 - accuracy: 0.8319 - val_loss: 0.5893 - val_accuracy: 0.9703\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.7664 - accuracy: 0.8000 - val_loss: 0.5095 - val_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7839 - accuracy: 0.7851 - val_loss: 0.5655 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.6286 - accuracy: 0.8362 - val_loss: 0.4868 - val_accuracy: 0.9901\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.8132 - accuracy: 0.7872 - val_loss: 0.5431 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.7502 - accuracy: 0.8085 - val_loss: 0.5255 - val_accuracy: 0.9703\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.7779 - accuracy: 0.7851 - val_loss: 0.5383 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.7197 - accuracy: 0.7851 - val_loss: 0.5162 - val_accuracy: 0.9901\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.8130 - accuracy: 0.7723 - val_loss: 0.7126 - val_accuracy: 0.9554\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.8562 - accuracy: 0.7745 - val_loss: 0.4519 - val_accuracy: 0.9901\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.8383 - accuracy: 0.8064 - val_loss: 0.5386 - val_accuracy: 0.9802\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.7996 - accuracy: 0.7957 - val_loss: 0.5176 - val_accuracy: 0.9703\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.7417 - accuracy: 0.7936 - val_loss: 0.5532 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.7712 - accuracy: 0.7915 - val_loss: 0.4883 - val_accuracy: 0.9901\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 280us/step - loss: 0.7478 - accuracy: 0.7957 - val_loss: 0.4402 - val_accuracy: 0.9901\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.7131 - accuracy: 0.8000 - val_loss: 0.6441 - val_accuracy: 0.9406\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.7704 - accuracy: 0.7894 - val_loss: 0.4784 - val_accuracy: 0.9901\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.9290 - accuracy: 0.7340 - val_loss: 0.5404 - val_accuracy: 0.9703\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.8323 - accuracy: 0.7936 - val_loss: 0.5136 - val_accuracy: 0.9851\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.7173 - accuracy: 0.8149 - val_loss: 0.5195 - val_accuracy: 0.9752\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.7262 - accuracy: 0.8255 - val_loss: 0.5043 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.7448 - accuracy: 0.7596 - val_loss: 0.5489 - val_accuracy: 0.9703\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.6304 - accuracy: 0.8000 - val_loss: 0.4891 - val_accuracy: 0.9851\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.8426 - accuracy: 0.7511 - val_loss: 0.4854 - val_accuracy: 0.9851\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.7886 - accuracy: 0.7809 - val_loss: 0.4637 - val_accuracy: 0.9851\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.6515 - accuracy: 0.8191 - val_loss: 0.4511 - val_accuracy: 0.9901\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.7053 - accuracy: 0.8149 - val_loss: 0.5353 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.7587 - accuracy: 0.7915 - val_loss: 0.4930 - val_accuracy: 0.9901\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.7684 - accuracy: 0.8149 - val_loss: 0.4943 - val_accuracy: 0.9901\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.7524 - accuracy: 0.8000 - val_loss: 0.4518 - val_accuracy: 0.9901\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.6287 - accuracy: 0.7915 - val_loss: 0.4769 - val_accuracy: 0.9851\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.6972 - accuracy: 0.7915 - val_loss: 0.4733 - val_accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.7366 - accuracy: 0.8085 - val_loss: 0.4498 - val_accuracy: 0.9901\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.5612 - accuracy: 0.8404 - val_loss: 0.4740 - val_accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.6869 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.7664 - accuracy: 0.7915 - val_loss: 0.4651 - val_accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.6625 - accuracy: 0.7936 - val_loss: 0.4968 - val_accuracy: 0.9752\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.7536 - accuracy: 0.7702 - val_loss: 0.5461 - val_accuracy: 0.9752\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.7379 - accuracy: 0.7830 - val_loss: 0.5167 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.5632 - accuracy: 0.8277 - val_loss: 0.4542 - val_accuracy: 0.9802\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.6502 - accuracy: 0.8085 - val_loss: 0.4588 - val_accuracy: 0.9752\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.5598 - accuracy: 0.8447 - val_loss: 0.4922 - val_accuracy: 0.9752\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.7107 - accuracy: 0.7872 - val_loss: 0.4877 - val_accuracy: 0.9752\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.6593 - accuracy: 0.8106 - val_loss: 0.4658 - val_accuracy: 0.9901\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.6536 - accuracy: 0.8170 - val_loss: 0.5033 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.6573 - accuracy: 0.8277 - val_loss: 0.4577 - val_accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.7114 - accuracy: 0.7851 - val_loss: 0.4732 - val_accuracy: 0.9752\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.7493 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.7197 - accuracy: 0.7957 - val_loss: 0.4695 - val_accuracy: 0.9901\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.7372 - accuracy: 0.8021 - val_loss: 0.4870 - val_accuracy: 0.9752\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.6924 - accuracy: 0.7957 - val_loss: 0.6202 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.8986 - accuracy: 0.84 - 0s 132us/step - loss: 0.5834 - accuracy: 0.8234 - val_loss: 0.4191 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.7190 - accuracy: 0.7851 - val_loss: 0.4900 - val_accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.6077 - accuracy: 0.8043 - val_loss: 0.4687 - val_accuracy: 0.9851\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.6815 - accuracy: 0.8234 - val_loss: 0.4476 - val_accuracy: 0.9851\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.7594 - accuracy: 0.7723 - val_loss: 0.4597 - val_accuracy: 0.9752\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.6944 - accuracy: 0.8021 - val_loss: 0.4555 - val_accuracy: 0.9851\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.7276 - accuracy: 0.7660 - val_loss: 0.4728 - val_accuracy: 0.9901\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.6307 - accuracy: 0.8128 - val_loss: 0.4645 - val_accuracy: 0.9851\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.5986 - accuracy: 0.8170 - val_loss: 0.4391 - val_accuracy: 0.9851\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.6963 - accuracy: 0.8021 - val_loss: 0.4338 - val_accuracy: 0.9802\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.6293 - accuracy: 0.8106 - val_loss: 0.4666 - val_accuracy: 0.9752\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.6245 - accuracy: 0.8128 - val_loss: 0.3611 - val_accuracy: 0.9901\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 0.6714 - accuracy: 0.8043 - val_loss: 0.4815 - val_accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.6781 - accuracy: 0.8149 - val_loss: 0.4933 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.6433 - accuracy: 0.8106 - val_loss: 0.4749 - val_accuracy: 0.9851\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.6681 - accuracy: 0.7851 - val_loss: 0.4862 - val_accuracy: 0.9752\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.7061 - accuracy: 0.7894 - val_loss: 0.4336 - val_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 583us/step - loss: 0.6935 - accuracy: 0.7851 - val_loss: 0.4733 - val_accuracy: 0.9851\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.6807 - accuracy: 0.7638 - val_loss: 0.4769 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.6722 - accuracy: 0.7745 - val_loss: 0.5549 - val_accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.7796 - accuracy: 0.7532 - val_loss: 0.4902 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.7041 - accuracy: 0.7660 - val_loss: 0.4466 - val_accuracy: 0.9851\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 377us/step - loss: 0.6482 - accuracy: 0.7915 - val_loss: 0.5085 - val_accuracy: 0.9752\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.5694 - accuracy: 0.8149 - val_loss: 0.4555 - val_accuracy: 0.9851\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.5650 - accuracy: 0.8000 - val_loss: 0.4352 - val_accuracy: 0.9901\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.6387 - accuracy: 0.7617 - val_loss: 0.4629 - val_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.7900 - accuracy: 0.7553 - val_loss: 0.4745 - val_accuracy: 0.9851\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.7160 - accuracy: 0.7936 - val_loss: 0.4427 - val_accuracy: 0.9851\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.5317 - accuracy: 0.8234 - val_loss: 0.5121 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.6187 - accuracy: 0.7851 - val_loss: 0.4585 - val_accuracy: 0.9851\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.5393 - accuracy: 0.8298 - val_loss: 0.5068 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.5801 - accuracy: 0.8213 - val_loss: 0.5020 - val_accuracy: 0.9752\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.5532 - accuracy: 0.8106 - val_loss: 0.4173 - val_accuracy: 0.9802\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.6276 - accuracy: 0.8106 - val_loss: 0.4864 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 416us/step - loss: 0.5716 - accuracy: 0.8021 - val_loss: 0.4504 - val_accuracy: 0.9851\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 553us/step - loss: 0.6013 - accuracy: 0.7766 - val_loss: 0.4528 - val_accuracy: 0.9851\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 324us/step - loss: 0.5974 - accuracy: 0.8319 - val_loss: 0.4179 - val_accuracy: 0.9901\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 0.6649 - accuracy: 0.7979 - val_loss: 0.5067 - val_accuracy: 0.9703\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 79.80%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.04983500e-07, 9.99999170e-01, 3.38429700e-07],\n",
       "       [1.00000000e+00, 3.94769880e-11, 7.61243700e-11],\n",
       "       [1.78709840e-07, 9.99999900e-01, 5.47614260e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [4.36488760e-02, 8.12866900e-01, 1.43484150e-01],\n",
       "       [3.23510850e-08, 1.00000000e+00, 3.27703300e-09],\n",
       "       [8.52893040e-07, 9.99998700e-01, 4.68896840e-07],\n",
       "       [1.24812690e-06, 9.99998700e-01, 6.50669500e-08],\n",
       "       [1.23115050e-06, 9.99998700e-01, 1.75076660e-07],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 3.67538300e-10, 6.97490400e-10],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [4.01261930e-07, 9.99999640e-01, 4.49401230e-08],\n",
       "       [1.23115050e-06, 9.99998700e-01, 1.75076660e-07],\n",
       "       [1.23115050e-06, 9.99998700e-01, 1.75076660e-07],\n",
       "       [1.00000000e+00, 1.26284790e-12, 3.24855680e-12],\n",
       "       [1.00000000e+00, 6.54189240e-09, 4.55281770e-09],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [1.24812690e-06, 9.99998700e-01, 6.50669500e-08],\n",
       "       [3.59101860e-01, 6.40862500e-01, 3.56065940e-05],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.55486960e-13, 2.78569030e-12],\n",
       "       [8.52893040e-07, 9.99998700e-01, 4.68896840e-07],\n",
       "       [3.23510850e-08, 1.00000000e+00, 3.27703300e-09],\n",
       "       [1.20848210e-08, 1.00000000e+00, 7.20374470e-09],\n",
       "       [4.56582900e-08, 9.99999900e-01, 1.10583570e-07],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.10702050e-10, 1.00000000e+00, 4.56203160e-09],\n",
       "       [1.00000000e+00, 1.29547570e-09, 1.96565650e-09],\n",
       "       [1.00000000e+00, 6.93030050e-12, 1.21459010e-11],\n",
       "       [4.92001180e-08, 9.99999900e-01, 8.55431900e-08],\n",
       "       [1.00000000e+00, 6.80891300e-14, 3.81401780e-13],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.99676800e-01, 3.20773920e-04, 2.34478060e-06],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.20286180e-08, 4.12802150e-09],\n",
       "       [9.99368970e-01, 6.26899500e-04, 4.16251600e-06],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [5.04983500e-07, 9.99999170e-01, 3.38429700e-07],\n",
       "       [7.10702050e-10, 1.00000000e+00, 4.56203160e-09],\n",
       "       [1.52790820e-07, 9.99999760e-01, 9.92891960e-08],\n",
       "       [1.00000000e+00, 7.65205440e-13, 1.32018580e-12],\n",
       "       [1.00000000e+00, 1.41606920e-08, 2.46976040e-08],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.82077360e-01, 1.79187860e-02, 3.88435730e-06],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.64211600e-10, 4.71548600e-11],\n",
       "       [1.20848210e-08, 1.00000000e+00, 7.20374470e-09],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [2.86551280e-08, 9.99999900e-01, 7.81698500e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [3.23510850e-08, 1.00000000e+00, 3.27703300e-09],\n",
       "       [1.00000000e+00, 3.67538300e-10, 6.97490400e-10],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 9.67829000e-09, 1.26360470e-08],\n",
       "       [1.78709840e-07, 9.99999900e-01, 5.47614260e-08],\n",
       "       [9.99992000e-01, 2.85600190e-06, 5.16111550e-06],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.70872520e-13, 2.06848260e-13],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.23115050e-06, 9.99998700e-01, 1.75076660e-07],\n",
       "       [9.99996800e-01, 1.73760350e-06, 1.48785920e-06],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [1.00000000e+00, 3.16481480e-10, 9.98306440e-11],\n",
       "       [1.00000000e+00, 7.50431800e-14, 1.70272110e-13],\n",
       "       [1.00000000e+00, 9.28682500e-13, 1.86144100e-12],\n",
       "       [7.10702050e-10, 1.00000000e+00, 4.56203160e-09],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [1.00000000e+00, 1.20139770e-10, 2.10053470e-10],\n",
       "       [5.67418100e-06, 9.99994040e-01, 2.49346530e-07],\n",
       "       [9.62888800e-01, 3.70889100e-02, 2.22766250e-05],\n",
       "       [2.16476900e-12, 1.00000000e+00, 2.83240420e-12],\n",
       "       [9.25175000e-01, 7.47870000e-02, 3.80455820e-05],\n",
       "       [1.00000000e+00, 2.68060770e-12, 3.99999480e-12],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [1.17045690e-08, 1.00000000e+00, 3.58639140e-09],\n",
       "       [1.00000000e+00, 1.51051970e-13, 1.91046300e-13],\n",
       "       [1.00000000e+00, 4.96337560e-13, 3.89875690e-13],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.66511370e-09, 5.72303050e-09],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [1.17045690e-08, 1.00000000e+00, 3.58639140e-09],\n",
       "       [1.00000000e+00, 2.14106020e-11, 4.17635060e-11],\n",
       "       [1.00000000e+00, 7.51162240e-10, 1.25071740e-10],\n",
       "       [1.00000000e+00, 1.31183370e-10, 2.93718560e-11],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.17165700e-11, 1.84836660e-10],\n",
       "       [1.23115050e-06, 9.99998700e-01, 1.75076660e-07],\n",
       "       [4.36488760e-02, 8.12866900e-01, 1.43484150e-01],\n",
       "       [1.00000000e+00, 1.58357420e-11, 3.63071900e-11],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.99999640e-01, 2.46333680e-07, 1.71760960e-07],\n",
       "       [7.49514350e-03, 9.91767470e-01, 7.37364460e-04],\n",
       "       [5.04983500e-07, 9.99999170e-01, 3.38429700e-07],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [4.01261930e-07, 9.99999640e-01, 4.49401230e-08],\n",
       "       [1.00000000e+00, 1.84549200e-10, 4.92920980e-11],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.73166660e-10, 3.60272760e-10],\n",
       "       [1.00000000e+00, 2.59419110e-13, 5.98309270e-13],\n",
       "       [2.86551280e-08, 9.99999900e-01, 7.81698500e-08],\n",
       "       [4.62632750e-01, 5.37239100e-01, 1.28209940e-04],\n",
       "       [1.00000000e+00, 1.24290890e-12, 5.90924140e-12],\n",
       "       [5.04983500e-07, 9.99999170e-01, 3.38429700e-07],\n",
       "       [7.49514350e-03, 9.91767470e-01, 7.37364460e-04],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [2.78587200e-07, 9.99999760e-01, 3.10819530e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [2.86551280e-08, 9.99999900e-01, 7.81698500e-08],\n",
       "       [1.00000000e+00, 6.99292000e-12, 4.83075260e-12],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [2.75225440e-08, 1.00000000e+00, 8.53129200e-09],\n",
       "       [9.99981640e-01, 1.80288120e-05, 3.55892920e-07],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.99998100e-01, 1.47346380e-06, 4.35227460e-07],\n",
       "       [2.18234150e-07, 9.99999760e-01, 2.82366540e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [2.86551280e-08, 9.99999900e-01, 7.81698500e-08],\n",
       "       [4.01261930e-07, 9.99999640e-01, 4.49401230e-08],\n",
       "       [9.99999900e-01, 6.38724500e-08, 7.84631800e-09],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [7.47876000e-09, 1.00000000e+00, 2.58419100e-09],\n",
       "       [9.99999900e-01, 8.09574600e-08, 1.95295120e-08],\n",
       "       [9.99991300e-01, 6.35574540e-06, 2.44165270e-06],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.49514350e-03, 9.91767470e-01, 7.37364460e-04],\n",
       "       [9.68353700e-01, 3.16412370e-02, 5.12337650e-06],\n",
       "       [9.99997500e-01, 1.69921900e-06, 8.17313550e-07],\n",
       "       [1.00000000e+00, 4.74292300e-12, 3.02809930e-11],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [1.78709840e-07, 9.99999900e-01, 5.47614260e-08],\n",
       "       [1.00000000e+00, 7.08643600e-09, 1.76391300e-09],\n",
       "       [9.99985200e-01, 1.46318010e-05, 1.30764430e-07],\n",
       "       [1.00000000e+00, 2.59075620e-08, 1.92652080e-08],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [2.16476900e-12, 1.00000000e+00, 2.83240420e-12],\n",
       "       [4.01261930e-07, 9.99999640e-01, 4.49401230e-08],\n",
       "       [1.20848210e-08, 1.00000000e+00, 7.20374470e-09],\n",
       "       [1.52790820e-07, 9.99999760e-01, 9.92891960e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [9.99898800e-01, 1.00966110e-04, 1.84451800e-07],\n",
       "       [1.00000000e+00, 6.13669560e-09, 1.52122630e-09],\n",
       "       [1.00000000e+00, 8.13181300e-10, 2.52967230e-10],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.68539200e-07, 9.99999300e-01, 5.71495700e-08],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.00000000e+00, 8.41878230e-10, 1.49623700e-09],\n",
       "       [3.23510850e-08, 1.00000000e+00, 3.27703300e-09],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [1.52790820e-07, 9.99999760e-01, 9.92891960e-08],\n",
       "       [1.00000000e+00, 8.31496500e-12, 1.35117420e-11],\n",
       "       [9.46203000e-09, 3.26069340e-08, 1.00000000e+00],\n",
       "       [1.22587790e-07, 9.99999900e-01, 4.81526100e-08],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [7.30427800e-08, 7.60807900e-08, 9.99999900e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [1.00000000e+00, 2.21784210e-09, 3.56218300e-09],\n",
       "       [9.53264240e-01, 4.67269050e-02, 8.87323400e-06],\n",
       "       [5.04982550e-07, 9.99999170e-01, 3.38429340e-07],\n",
       "       [9.98741300e-01, 1.19558010e-03, 6.30599600e-05],\n",
       "       [1.00000000e+00, 2.76635250e-09, 2.06982080e-09],\n",
       "       [4.36488950e-02, 8.12866870e-01, 1.43484220e-01],\n",
       "       [4.10628650e-08, 3.38463340e-08, 9.99999900e-01],\n",
       "       [7.30426400e-08, 7.60806460e-08, 9.99999900e-01],\n",
       "       [1.16983465e-07, 9.99999900e-01, 3.56936630e-08],\n",
       "       [1.00000000e+00, 4.98569200e-13, 1.62250030e-12],\n",
       "       [9.96739700e-01, 3.25455260e-03, 5.81695580e-06],\n",
       "       [4.36488950e-02, 8.12866870e-01, 1.43484220e-01]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p003ppresabs_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974571586511886"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974571586511886"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945567979817688"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003333773402070904"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945567979817688"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003333773402070904"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 96.91%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.008838393669982979\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 79.44%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.005295096\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
