{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file implements neural networks with/without dropout and regularizer for p003pkpresabsSTCC_qual with four replicates.\n",
    "## We compute the mean and standarad deviation of training and test accuracies.\n",
    "## We also compute the mean and standard deviation of AUC ROC values for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "seed(100)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 870)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/p003pkpresabsSTCC_qual.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "248    0\n",
       "249    0\n",
       "250    0\n",
       "251    0\n",
       "252    0\n",
       "Name: pheno, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>...</th>\n",
       "      <th>AACTAGGGGGGATTAGAATGCAAAATAAGTCAAAATCGCCTTTTAAAATTGCATTTTCTAAATTTATTCATAATAAAATTGCAATGTTATCGGTTATTTT</th>\n",
       "      <th>AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT</th>\n",
       "      <th>AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT</th>\n",
       "      <th>AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT</th>\n",
       "      <th>AAATTGCGTATTT</th>\n",
       "      <th>AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT</th>\n",
       "      <th>AAATCTACTGTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 870 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0     107   \n",
       "1     109   \n",
       "2     115   \n",
       "3  120335   \n",
       "4  120337   \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  ...  \\\n",
       "0              1             1  ...   \n",
       "1              1             1  ...   \n",
       "2              1             1  ...   \n",
       "3              1             1  ...   \n",
       "4              1             1  ...   \n",
       "\n",
       "   AACTAGGGGGGATTAGAATGCAAAATAAGTCAAAATCGCCTTTTAAAATTGCATTTTCTAAATTTATTCATAATAAAATTGCAATGTTATCGGTTATTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTGCGTATTT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATCTACTGTTT  ST  CC  pheno  \n",
       "0              1   5   5      0  \n",
       "1              1   8   8      0  \n",
       "2              1   5   5      1  \n",
       "3              1   5   5      0  \n",
       "4              1   5   5      0  \n",
       "\n",
       "[5 rows x 870 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    224\n",
       "1     26\n",
       "2      3\n",
       "Name: pheno, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pheno'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 869)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA</th>\n",
       "      <th>TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA</th>\n",
       "      <th>TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC</th>\n",
       "      <th>TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA</th>\n",
       "      <th>TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT</th>\n",
       "      <th>TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA</th>\n",
       "      <th>TTTTTTAGGTACC</th>\n",
       "      <th>TTTTTGCATTCA</th>\n",
       "      <th>TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA</th>\n",
       "      <th>...</th>\n",
       "      <th>AACTAGGGGGGATTAGAATGCAAAATAAGTCAAAATCGCCTTTTAAAATTGCATTTTCTAAATTTATTCATAATAAAATTGCAATGTTATCGGTTATTTT</th>\n",
       "      <th>AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT</th>\n",
       "      <th>AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT</th>\n",
       "      <th>AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT</th>\n",
       "      <th>AAATTGCGTATTT</th>\n",
       "      <th>AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT</th>\n",
       "      <th>AAATCTACTGTTT</th>\n",
       "      <th>ST</th>\n",
       "      <th>CC</th>\n",
       "      <th>pheno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 869 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATG  \\\n",
       "0                                                  1                                         \n",
       "1                                                  1                                         \n",
       "2                                                  1                                         \n",
       "3                                                  1                                         \n",
       "4                                                  1                                         \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGA  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   TTTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTCTTTTCATAACTGTGTTGGAAATGAATTAAATTAACAGCTCTTTGTGCTTTACGGTGTGTTGC  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  1                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   TTTTTTCAGCATTGTCTACATTACTTAACATTCGTGTTTGTAAGTAATATTGACCGCCAATATTTAGACACTTTATAAGTATGCCATTCATCATTTTTAA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTATCTCACCAATTTTGTAATACATCGTTCTCGTCCTCCTTGTCTTCTTCGTCCTCCTCGTTATCTTCTTCGTTTTGTAATTCATAAATTTTGTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  0                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   TTTTTTAGTTTATCCAATGATTGATGTTATAATAATACTAAATTTGTATCTATAAAAAAGTAATGAGCATTTGTGCGCATATGATGATGTAAAGCGTAAA  \\\n",
       "0                                                  1                                                      \n",
       "1                                                  1                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  1                                                      \n",
       "4                                                  1                                                      \n",
       "\n",
       "   TTTTTTAGGTACC  TTTTTGCATTCA  \\\n",
       "0              1             1   \n",
       "1              1             1   \n",
       "2              1             1   \n",
       "3              1             1   \n",
       "4              1             1   \n",
       "\n",
       "   TTTTTGAAAATAATCATTAGCTTGCTCACTATATAATTTGATGAATATATTTCGTGAAAGTGGGTATTTATTTAATGATTATTCTATATATGATAGTATA  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   AACTAGGGGGGATTAGAATGCAAAATAAGTCAAAATCGCCTTTTAAAATTGCATTTTCTAAATTTATTCATAATAAAATTGCAATGTTATCGGTTATTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTTCATTAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTTCAACAAACTCAATTAATACGAATTATCGCTTTCAATAAAAATTATTCATTAAATCATTAAAGATATTGAGTTCCAATACTATTTTCACTTTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTTTACTTAACAACTAGTACATAAAGTAATACAATTAAATTAATTCTATCTGAAAGATGTGTGGGGCATCGTTATTTTAGGTGGATATGAGCAATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATTGCGTATTT  \\\n",
       "0              0   \n",
       "1              0   \n",
       "2              1   \n",
       "3              0   \n",
       "4              0   \n",
       "\n",
       "   AAATCTTAGACGTAAACATGATAAAATGGCCTTGATTACTCAATAGTTATATTTCGGAGAACTGATTTGTGATATGATATTAAAGACTATAGGAGGATTT  \\\n",
       "0                                                  0                                                      \n",
       "1                                                  0                                                      \n",
       "2                                                  1                                                      \n",
       "3                                                  0                                                      \n",
       "4                                                  0                                                      \n",
       "\n",
       "   AAATCTACTGTTT  ST  CC  pheno  \n",
       "0              1   5   5      0  \n",
       "1              1   8   8      0  \n",
       "2              1   5   5      1  \n",
       "3              1   5   5      0  \n",
       "4              1   5   5      0  \n",
       "\n",
       "[5 rows x 869 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 869) (253,)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'pheno']\n",
    "y = df['pheno']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 224), (1, 224), (2, 224)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rebecca/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# over-sampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "overS = RandomOverSampler(random_state=100)\n",
    "X_over, y_over = overS.fit_resample(X, y)\n",
    "print(sorted(Counter(y_over).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Fully-Connected Neural Network ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(X_test_over[:,0])\n",
    "dat['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test\n",
       "0       NRS265     1\n",
       "1        GA984     0\n",
       "2       NRS119     0\n",
       "3       NRS249     1\n",
       "4       NRS255     2\n",
       "..         ...   ...\n",
       "197     NRS035     1\n",
       "198     NRS387     1\n",
       "199     NRS222     0\n",
       "200  BCH-SA-11     1\n",
       "201     NRS148     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### neural network on over-sampling data\n",
    "model1_over = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 325us/step - loss: 3.5887 - accuracy: 0.4979 - val_loss: 2.0695 - val_accuracy: 0.6139\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.1737 - accuracy: 0.5745 - val_loss: 0.9642 - val_accuracy: 0.7475\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.6577 - accuracy: 0.7447 - val_loss: 0.5074 - val_accuracy: 0.7624\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.4556 - accuracy: 0.8085 - val_loss: 0.4051 - val_accuracy: 0.8614\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.3994 - accuracy: 0.8511 - val_loss: 0.6045 - val_accuracy: 0.8465\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.4259 - accuracy: 0.8574 - val_loss: 0.4950 - val_accuracy: 0.8564\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 0.3773 - accuracy: 0.8553 - val_loss: 0.7770 - val_accuracy: 0.7376\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.3724 - accuracy: 0.8681 - val_loss: 0.3186 - val_accuracy: 0.8812\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.2952 - accuracy: 0.9085 - val_loss: 0.3095 - val_accuracy: 0.8911\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.2689 - accuracy: 0.9213 - val_loss: 0.3027 - val_accuracy: 0.8911\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 0.2939 - accuracy: 0.9043 - val_loss: 0.2980 - val_accuracy: 0.8861\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.2775 - accuracy: 0.9106 - val_loss: 0.2693 - val_accuracy: 0.9010\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.2663 - accuracy: 0.9128 - val_loss: 0.2681 - val_accuracy: 0.9010\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.2504 - accuracy: 0.9191 - val_loss: 0.2745 - val_accuracy: 0.8960\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.2653 - accuracy: 0.8979 - val_loss: 0.3144 - val_accuracy: 0.9010\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.2349 - accuracy: 0.9340 - val_loss: 0.2589 - val_accuracy: 0.9257\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.2159 - accuracy: 0.9149 - val_loss: 0.2624 - val_accuracy: 0.9010\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.2085 - accuracy: 0.9362 - val_loss: 0.2466 - val_accuracy: 0.9109\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.2142 - accuracy: 0.9383 - val_loss: 0.2602 - val_accuracy: 0.9208\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.1884 - accuracy: 0.9489 - val_loss: 0.2360 - val_accuracy: 0.9208\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1872 - accuracy: 0.9489 - val_loss: 0.2267 - val_accuracy: 0.9257\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1794 - accuracy: 0.9489 - val_loss: 0.2259 - val_accuracy: 0.9158\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1870 - accuracy: 0.9489 - val_loss: 0.2307 - val_accuracy: 0.9010\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.1937 - accuracy: 0.9447 - val_loss: 0.2401 - val_accuracy: 0.9208\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 325us/step - loss: 0.1869 - accuracy: 0.9468 - val_loss: 0.2451 - val_accuracy: 0.9109\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 0.1787 - accuracy: 0.9489 - val_loss: 0.2360 - val_accuracy: 0.9208\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.1688 - accuracy: 0.9489 - val_loss: 0.2337 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.1734 - accuracy: 0.9511 - val_loss: 0.2076 - val_accuracy: 0.9257\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.1679 - accuracy: 0.9489 - val_loss: 0.2240 - val_accuracy: 0.9406\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.1569 - accuracy: 0.9574 - val_loss: 0.2328 - val_accuracy: 0.9059\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.1723 - accuracy: 0.9447 - val_loss: 0.2380 - val_accuracy: 0.9307\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.1912 - accuracy: 0.9468 - val_loss: 0.2041 - val_accuracy: 0.9406\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.1569 - accuracy: 0.9468 - val_loss: 0.2106 - val_accuracy: 0.9257\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1480 - accuracy: 0.9553 - val_loss: 0.2103 - val_accuracy: 0.9356\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1614 - accuracy: 0.9468 - val_loss: 0.2085 - val_accuracy: 0.9356\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.1474 - accuracy: 0.9532 - val_loss: 0.2252 - val_accuracy: 0.9406\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1436 - accuracy: 0.9532 - val_loss: 0.1962 - val_accuracy: 0.9208\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.1368 - accuracy: 0.9532 - val_loss: 0.2067 - val_accuracy: 0.9109\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1374 - accuracy: 0.9553 - val_loss: 0.2012 - val_accuracy: 0.9208\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1471 - accuracy: 0.9511 - val_loss: 0.2055 - val_accuracy: 0.9208\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.1654 - accuracy: 0.9340 - val_loss: 0.2008 - val_accuracy: 0.9307\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.2084 - accuracy: 0.9404 - val_loss: 0.3709 - val_accuracy: 0.8762\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.2043 - accuracy: 0.9234 - val_loss: 0.2222 - val_accuracy: 0.9406\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.1566 - accuracy: 0.9511 - val_loss: 0.2156 - val_accuracy: 0.9356\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 0.1353 - accuracy: 0.9596 - val_loss: 0.1933 - val_accuracy: 0.9307\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.1348 - accuracy: 0.9489 - val_loss: 0.2179 - val_accuracy: 0.9059\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.1310 - accuracy: 0.9553 - val_loss: 0.1959 - val_accuracy: 0.9208\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.1921 - val_accuracy: 0.9257\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.1292 - accuracy: 0.9511 - val_loss: 0.1934 - val_accuracy: 0.9109\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1260 - accuracy: 0.9532 - val_loss: 0.1924 - val_accuracy: 0.9158\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1262 - accuracy: 0.9553 - val_loss: 0.1924 - val_accuracy: 0.9208\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1191 - accuracy: 0.9596 - val_loss: 0.1971 - val_accuracy: 0.9109\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.1215 - accuracy: 0.9532 - val_loss: 0.2101 - val_accuracy: 0.9109\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.1188 - accuracy: 0.9553 - val_loss: 0.2016 - val_accuracy: 0.9158\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1303 - accuracy: 0.9532 - val_loss: 0.1983 - val_accuracy: 0.9109\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1150 - accuracy: 0.9617 - val_loss: 0.1860 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1131 - accuracy: 0.9553 - val_loss: 0.2308 - val_accuracy: 0.9208\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1173 - accuracy: 0.9574 - val_loss: 0.1932 - val_accuracy: 0.9406\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.1164 - accuracy: 0.9617 - val_loss: 0.2057 - val_accuracy: 0.9356\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1115 - accuracy: 0.9489 - val_loss: 0.1925 - val_accuracy: 0.9406\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1422 - accuracy: 0.9468 - val_loss: 0.2117 - val_accuracy: 0.9257\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1445 - accuracy: 0.9404 - val_loss: 0.2257 - val_accuracy: 0.9257\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1244 - accuracy: 0.9574 - val_loss: 0.1794 - val_accuracy: 0.9455\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1243 - accuracy: 0.9511 - val_loss: 0.1890 - val_accuracy: 0.9307\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.1070 - accuracy: 0.9574 - val_loss: 0.2224 - val_accuracy: 0.9257\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.1340 - accuracy: 0.9426 - val_loss: 0.2117 - val_accuracy: 0.9158\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 348us/step - loss: 0.1171 - accuracy: 0.9617 - val_loss: 0.2156 - val_accuracy: 0.9059\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 0.1121 - accuracy: 0.9660 - val_loss: 0.1995 - val_accuracy: 0.9455\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.1138 - accuracy: 0.9596 - val_loss: 0.1806 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1170 - accuracy: 0.9553 - val_loss: 0.1935 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.2144 - val_accuracy: 0.9059\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.1023 - accuracy: 0.9638 - val_loss: 0.1744 - val_accuracy: 0.9505\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.1066 - accuracy: 0.9638 - val_loss: 0.1813 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1018 - accuracy: 0.9617 - val_loss: 0.1876 - val_accuracy: 0.9158\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1040 - accuracy: 0.9617 - val_loss: 0.1857 - val_accuracy: 0.9406\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1058 - accuracy: 0.9617 - val_loss: 0.1848 - val_accuracy: 0.9257\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1068 - accuracy: 0.9553 - val_loss: 0.2239 - val_accuracy: 0.9257\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.1052 - accuracy: 0.9617 - val_loss: 0.1877 - val_accuracy: 0.9208\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0965 - accuracy: 0.9638 - val_loss: 0.2088 - val_accuracy: 0.9059\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1049 - accuracy: 0.9489 - val_loss: 0.1891 - val_accuracy: 0.9406\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 99us/step - loss: 0.1125 - accuracy: 0.9617 - val_loss: 0.1790 - val_accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 0.2097 - val_accuracy: 0.9059\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.1068 - accuracy: 0.9660 - val_loss: 0.2251 - val_accuracy: 0.9059\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.1031 - accuracy: 0.9596 - val_loss: 0.1855 - val_accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.1036 - accuracy: 0.9596 - val_loss: 0.2048 - val_accuracy: 0.9307\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.1002 - accuracy: 0.9617 - val_loss: 0.2473 - val_accuracy: 0.9109\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.1100 - accuracy: 0.9660 - val_loss: 0.2594 - val_accuracy: 0.9158\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1183 - accuracy: 0.9553 - val_loss: 0.3547 - val_accuracy: 0.9356\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1955 - accuracy: 0.9489 - val_loss: 0.2337 - val_accuracy: 0.9307\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1247 - accuracy: 0.9596 - val_loss: 0.3135 - val_accuracy: 0.8960\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.1246 - accuracy: 0.9532 - val_loss: 0.4051 - val_accuracy: 0.9356\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1259 - accuracy: 0.9617 - val_loss: 0.1949 - val_accuracy: 0.9406\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.1003 - accuracy: 0.9489 - val_loss: 0.1925 - val_accuracy: 0.9554\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1039 - accuracy: 0.9638 - val_loss: 0.2290 - val_accuracy: 0.9307\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.2258 - val_accuracy: 0.9307\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1056 - accuracy: 0.9596 - val_loss: 0.2090 - val_accuracy: 0.9406\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.0900 - accuracy: 0.9638 - val_loss: 0.2435 - val_accuracy: 0.9257\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1065 - accuracy: 0.9617 - val_loss: 0.2619 - val_accuracy: 0.9257\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.1059 - accuracy: 0.9511 - val_loss: 0.2102 - val_accuracy: 0.9158\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.2009 - val_accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a35f20128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 89us/step\n",
      "over-sampling test accuracy: 94.55%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over = model1_over.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 2, 2, 2, 1,\n",
       "       0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 2, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0,\n",
       "       1, 2, 1, 2, 1, 2, 1, 2, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0,\n",
       "       2, 1, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 1, 2, 0, 0, 2, 1, 2, 2, 1, 1,\n",
       "       1, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 1, 1, 2, 0, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 0, 2,\n",
       "       1, 0, 2, 1, 0, 0, 2, 0, 2, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1, 1, 2, 0,\n",
       "       1, 2, 2, 1, 0, 2, 2, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1_over.predict_classes(X_test_over)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>BCH-SA-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  test  pred\n",
       "0       NRS265     1     1\n",
       "1        GA984     0     0\n",
       "2       NRS119     0     0\n",
       "3       NRS249     1     1\n",
       "4       NRS255     2     2\n",
       "..         ...   ...   ...\n",
       "197     NRS035     1     1\n",
       "198     NRS387     1     1\n",
       "199     NRS222     0     0\n",
       "200  BCH-SA-11     1     1\n",
       "201     NRS148     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['pred'] = pred\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba1 = model1_over.predict_proba(X_test_over)\n",
    "dat_proba1 = pd.DataFrame(proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>1.316916e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>1.668960e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.724804e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.994062</td>\n",
       "      <td>5.165093e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>9.973850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>1.451060e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.963009</td>\n",
       "      <td>5.596347e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.993051</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>2.236100e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.993249</td>\n",
       "      <td>6.406792e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.075546</td>\n",
       "      <td>9.241126e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.001061  0.997622  1.316916e-03\n",
       "1    0.996951  0.003033  1.668960e-05\n",
       "2    0.999995  0.000005  3.724804e-12\n",
       "3    0.005938  0.994062  5.165093e-08\n",
       "4    0.000325  0.002290  9.973850e-01\n",
       "..        ...       ...           ...\n",
       "197  0.002477  0.996072  1.451060e-03\n",
       "198  0.036935  0.963009  5.596347e-05\n",
       "199  0.993051  0.006947  2.236100e-06\n",
       "200  0.006751  0.993249  6.406792e-09\n",
       "201  0.000342  0.075546  9.241126e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba1.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba1.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/1p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.9638 - val_loss: 0.2009 - val_accuracy: 0.9307\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0847 - accuracy: 0.9723 - val_loss: 0.2067 - val_accuracy: 0.9208\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0953 - accuracy: 0.9617 - val_loss: 0.2308 - val_accuracy: 0.9010\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0944 - accuracy: 0.9574 - val_loss: 0.1780 - val_accuracy: 0.9554\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0849 - accuracy: 0.9596 - val_loss: 0.2641 - val_accuracy: 0.9109\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.2035 - val_accuracy: 0.9455\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0830 - accuracy: 0.9723 - val_loss: 0.1828 - val_accuracy: 0.9554\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0897 - accuracy: 0.9681 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0886 - accuracy: 0.9617 - val_loss: 0.2381 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0827 - accuracy: 0.9660 - val_loss: 0.1975 - val_accuracy: 0.9406\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.0803 - accuracy: 0.9702 - val_loss: 0.2157 - val_accuracy: 0.9307\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 0.1944 - val_accuracy: 0.9406\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.1960 - val_accuracy: 0.9406\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0783 - accuracy: 0.9723 - val_loss: 0.2271 - val_accuracy: 0.9257\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0782 - accuracy: 0.9702 - val_loss: 0.1972 - val_accuracy: 0.9406\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0796 - accuracy: 0.9723 - val_loss: 0.1988 - val_accuracy: 0.9356\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0841 - accuracy: 0.9638 - val_loss: 0.1971 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0956 - accuracy: 0.9638 - val_loss: 0.1957 - val_accuracy: 0.9455\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0800 - accuracy: 0.9723 - val_loss: 0.1771 - val_accuracy: 0.9455\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0807 - accuracy: 0.9702 - val_loss: 0.2941 - val_accuracy: 0.9158\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.0881 - accuracy: 0.9617 - val_loss: 0.1786 - val_accuracy: 0.9406\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.0990 - accuracy: 0.9660 - val_loss: 0.2047 - val_accuracy: 0.9406\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.0763 - accuracy: 0.9638 - val_loss: 0.1793 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0773 - accuracy: 0.9723 - val_loss: 0.1849 - val_accuracy: 0.9554\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.0803 - accuracy: 0.9681 - val_loss: 0.2086 - val_accuracy: 0.9307\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0804 - accuracy: 0.9723 - val_loss: 0.2171 - val_accuracy: 0.9307\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0886 - accuracy: 0.9681 - val_loss: 0.2401 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0843 - accuracy: 0.9617 - val_loss: 0.2022 - val_accuracy: 0.9356\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0890 - accuracy: 0.9723 - val_loss: 0.2394 - val_accuracy: 0.9257\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.0832 - accuracy: 0.9702 - val_loss: 0.1785 - val_accuracy: 0.9554\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0822 - accuracy: 0.9681 - val_loss: 0.2091 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.2165 - val_accuracy: 0.9307\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.2085 - val_accuracy: 0.9356\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0743 - accuracy: 0.9723 - val_loss: 0.2151 - val_accuracy: 0.9356\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0728 - accuracy: 0.9723 - val_loss: 0.2069 - val_accuracy: 0.9455\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0744 - accuracy: 0.9723 - val_loss: 0.2276 - val_accuracy: 0.9307\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.2198 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0715 - accuracy: 0.9681 - val_loss: 0.1823 - val_accuracy: 0.9554\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.0820 - accuracy: 0.9702 - val_loss: 0.2312 - val_accuracy: 0.9257\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.0811 - accuracy: 0.9702 - val_loss: 0.2315 - val_accuracy: 0.9158\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.0783 - accuracy: 0.9681 - val_loss: 0.2113 - val_accuracy: 0.9356\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.0771 - accuracy: 0.9723 - val_loss: 0.2346 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0749 - accuracy: 0.9723 - val_loss: 0.2291 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.0921 - accuracy: 0.9702 - val_loss: 0.2420 - val_accuracy: 0.9257\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.1045 - accuracy: 0.9532 - val_loss: 0.2223 - val_accuracy: 0.9356\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0777 - accuracy: 0.9681 - val_loss: 0.2035 - val_accuracy: 0.9406\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.2254 - val_accuracy: 0.9257\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.0710 - accuracy: 0.9723 - val_loss: 0.2040 - val_accuracy: 0.9356\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.0748 - accuracy: 0.9660 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.0763 - accuracy: 0.9723 - val_loss: 0.1938 - val_accuracy: 0.9455\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.0690 - accuracy: 0.9723 - val_loss: 0.2194 - val_accuracy: 0.9307\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.1935 - val_accuracy: 0.9356\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.0709 - accuracy: 0.9723 - val_loss: 0.1978 - val_accuracy: 0.9554\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 0.1887 - val_accuracy: 0.9554\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.0716 - accuracy: 0.9723 - val_loss: 0.2307 - val_accuracy: 0.9307\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0694 - accuracy: 0.9723 - val_loss: 0.1918 - val_accuracy: 0.9356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0744 - accuracy: 0.9638 - val_loss: 0.2181 - val_accuracy: 0.9307\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0681 - accuracy: 0.9723 - val_loss: 0.2095 - val_accuracy: 0.9307\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.0730 - accuracy: 0.9702 - val_loss: 0.2035 - val_accuracy: 0.9356\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0699 - accuracy: 0.9723 - val_loss: 0.2274 - val_accuracy: 0.9257\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0703 - accuracy: 0.9723 - val_loss: 0.2079 - val_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.0854 - accuracy: 0.9596 - val_loss: 0.2122 - val_accuracy: 0.9406\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 498us/step - loss: 0.0797 - accuracy: 0.9723 - val_loss: 0.2122 - val_accuracy: 0.9356\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 0.2080 - val_accuracy: 0.9356\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.0710 - accuracy: 0.9723 - val_loss: 0.2028 - val_accuracy: 0.9455\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 0.2097 - val_accuracy: 0.9356\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.0696 - accuracy: 0.9723 - val_loss: 0.2137 - val_accuracy: 0.9356\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0679 - accuracy: 0.9702 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0772 - accuracy: 0.9702 - val_loss: 0.2668 - val_accuracy: 0.9208\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0711 - accuracy: 0.9702 - val_loss: 0.2030 - val_accuracy: 0.9356\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0707 - accuracy: 0.9723 - val_loss: 0.2325 - val_accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.0710 - accuracy: 0.9723 - val_loss: 0.2257 - val_accuracy: 0.9307\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0721 - accuracy: 0.9723 - val_loss: 0.2065 - val_accuracy: 0.9455\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0727 - accuracy: 0.9723 - val_loss: 0.2036 - val_accuracy: 0.9356\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0692 - accuracy: 0.9723 - val_loss: 0.2147 - val_accuracy: 0.9554\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0717 - accuracy: 0.9723 - val_loss: 0.2575 - val_accuracy: 0.9208\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0712 - accuracy: 0.9702 - val_loss: 0.2112 - val_accuracy: 0.9356\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0651 - accuracy: 0.9723 - val_loss: 0.2085 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.0794 - accuracy: 0.9596 - val_loss: 0.2499 - val_accuracy: 0.9257\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.0721 - accuracy: 0.9723 - val_loss: 0.2411 - val_accuracy: 0.9257\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.0919 - accuracy: 0.9681 - val_loss: 0.2578 - val_accuracy: 0.9406\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.0735 - accuracy: 0.9723 - val_loss: 0.1902 - val_accuracy: 0.9406\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.0795 - accuracy: 0.9660 - val_loss: 0.1972 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 531us/step - loss: 0.0735 - accuracy: 0.9702 - val_loss: 0.2505 - val_accuracy: 0.9257\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.0796 - accuracy: 0.9681 - val_loss: 0.2628 - val_accuracy: 0.9455\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.0765 - accuracy: 0.9723 - val_loss: 0.3089 - val_accuracy: 0.9158\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0857 - accuracy: 0.9681 - val_loss: 0.3203 - val_accuracy: 0.9208\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0860 - accuracy: 0.9660 - val_loss: 0.2709 - val_accuracy: 0.9158\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.0686 - accuracy: 0.9702 - val_loss: 0.2268 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.2578 - val_accuracy: 0.9406\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.0786 - accuracy: 0.9553 - val_loss: 0.2286 - val_accuracy: 0.9307\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0710 - accuracy: 0.9723 - val_loss: 0.2798 - val_accuracy: 0.9257\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0701 - accuracy: 0.9723 - val_loss: 0.2806 - val_accuracy: 0.9257\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0718 - accuracy: 0.9702 - val_loss: 0.2582 - val_accuracy: 0.9356\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.0735 - accuracy: 0.9723 - val_loss: 0.2542 - val_accuracy: 0.9455\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0705 - accuracy: 0.9723 - val_loss: 0.2310 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0713 - accuracy: 0.9723 - val_loss: 0.2345 - val_accuracy: 0.9356\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 291us/step - loss: 0.0761 - accuracy: 0.9702 - val_loss: 0.2611 - val_accuracy: 0.9356\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0668 - accuracy: 0.9723 - val_loss: 0.2746 - val_accuracy: 0.9356\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 347us/step - loss: 0.0641 - accuracy: 0.9723 - val_loss: 0.2434 - val_accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "hist1_over = model1_over.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.94%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.241086</td>\n",
       "      <td>4.638713e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>9.784034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726623</td>\n",
       "      <td>0.273376</td>\n",
       "      <td>1.520979e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>0.861665</td>\n",
       "      <td>1.334123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882176</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>1.414530e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>9.998934e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>9.999435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>9.976944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>9.989737e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage    strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual  CFBRSa26          0           0  0.758914   \n",
       "1      p002ykpresabs_qual    NRS109          2           2  0.005361   \n",
       "2      p002ykpresabs_qual    NRS112          0           0  0.726623   \n",
       "3      p002ykpresabs_qual    NRS216          1           1  0.138322   \n",
       "4      p002ykpresabs_qual    NRS021          0           0  0.882176   \n",
       "...                   ...       ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual    NRS148          2           2  0.000007   \n",
       "4280  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4281  pyopresabsSTCC_qual    NRS205          2           2  0.000011   \n",
       "4282  pyopresabsSTCC_qual    NRS255          2           2  0.000257   \n",
       "4283  pyopresabsSTCC_qual    NRS109          2           2  0.000097   \n",
       "\n",
       "             1             2  \n",
       "0     0.241086  4.638713e-07  \n",
       "1     0.016236  9.784034e-01  \n",
       "2     0.273376  1.520979e-06  \n",
       "3     0.861665  1.334123e-05  \n",
       "4     0.117824  1.414530e-10  \n",
       "...        ...           ...  \n",
       "4279  0.000099  9.998934e-01  \n",
       "4280  0.002048  9.976944e-01  \n",
       "4281  0.000045  9.999435e-01  \n",
       "4282  0.002048  9.976944e-01  \n",
       "4283  0.000929  9.989737e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06127840e-03, 9.97621830e-01, 1.31691610e-03],\n",
       "       [9.96950750e-01, 3.03264220e-03, 1.66895950e-05],\n",
       "       [9.99995100e-01, 4.92194570e-06, 3.72480430e-12],\n",
       "       [5.93764850e-03, 9.94062360e-01, 5.16509250e-08],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.94247500e-06, 9.99981760e-01, 1.42963910e-05],\n",
       "       [3.59399270e-04, 7.57661340e-01, 2.41979350e-01],\n",
       "       [4.46977400e-02, 9.55213960e-01, 8.82108300e-05],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [9.99105400e-01, 8.90887800e-04, 3.71495570e-06],\n",
       "       [1.05186690e-02, 9.89481330e-01, 1.17181720e-08],\n",
       "       [9.98851660e-01, 1.14834250e-03, 3.89766500e-11],\n",
       "       [3.69354300e-02, 9.63008700e-01, 5.59634720e-05],\n",
       "       [9.99195750e-01, 6.42081100e-04, 1.62104130e-04],\n",
       "       [5.65948100e-03, 9.92046360e-01, 2.29416830e-03],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [9.77454660e-01, 2.25453400e-02, 7.24812650e-10],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.94593570e-01, 6.05343460e-01, 6.30143400e-05],\n",
       "       [9.81607560e-01, 1.83902890e-02, 2.28049320e-06],\n",
       "       [9.99584730e-01, 4.15284500e-04, 1.26635140e-11],\n",
       "       [3.49544640e-01, 6.50436760e-01, 1.86379530e-05],\n",
       "       [3.94247500e-06, 9.99981760e-01, 1.42963910e-05],\n",
       "       [2.56259130e-03, 9.93924100e-01, 3.51333920e-03],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [6.62416200e-02, 9.33693950e-01, 6.44780700e-05],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [9.99995100e-01, 4.91464740e-06, 2.30743460e-12],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [7.00334700e-02, 9.29966570e-01, 1.27924100e-09],\n",
       "       [9.87666600e-01, 1.23330930e-02, 3.93761900e-07],\n",
       "       [9.99862700e-01, 1.37268740e-04, 3.62538720e-13],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [6.75139100e-03, 9.93248600e-01, 6.40679240e-09],\n",
       "       [9.99862700e-01, 1.37268740e-04, 3.62538720e-13],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [1.22062870e-02, 9.87793740e-01, 3.69022770e-09],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.94247500e-06, 9.99981760e-01, 1.42963910e-05],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [1.02618180e-02, 9.89685600e-01, 5.24729480e-05],\n",
       "       [4.64562100e-03, 9.95338100e-01, 1.62158600e-05],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [1.82614700e-03, 9.98169400e-01, 4.44889700e-06],\n",
       "       [9.99541160e-01, 4.58850380e-04, 9.38223500e-11],\n",
       "       [4.64562100e-03, 9.95338100e-01, 1.62158600e-05],\n",
       "       [6.75139100e-03, 9.93248600e-01, 6.40679240e-09],\n",
       "       [1.05186690e-02, 9.89481330e-01, 1.17181720e-08],\n",
       "       [7.55038560e-01, 2.44941300e-01, 2.01766740e-05],\n",
       "       [9.99584730e-01, 4.15284500e-04, 1.26635140e-11],\n",
       "       [9.98441160e-01, 1.55883960e-03, 2.37107420e-10],\n",
       "       [9.99237900e-01, 7.61813300e-04, 3.13518940e-07],\n",
       "       [9.98312830e-01, 1.64994160e-03, 3.72434730e-05],\n",
       "       [9.16187760e-01, 8.37836860e-02, 2.84554540e-05],\n",
       "       [6.75139100e-03, 9.93248600e-01, 6.40679240e-09],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [9.99994160e-01, 5.80101230e-06, 5.32577000e-12],\n",
       "       [1.82614700e-03, 9.98169400e-01, 4.44889700e-06],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [9.08431950e-01, 9.14377350e-02, 1.30237470e-04],\n",
       "       [4.95132270e-01, 5.04824000e-01, 4.37352250e-05],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.42882240e-04, 9.99652150e-01, 5.00093940e-06],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.69354300e-02, 9.63008700e-01, 5.59634720e-05],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [4.70151570e-02, 9.52939900e-01, 4.50050170e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.99541160e-01, 4.58850380e-04, 9.38223500e-11],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [5.65948100e-03, 9.92046360e-01, 2.29416830e-03],\n",
       "       [9.99902370e-01, 9.76622100e-05, 2.46717340e-09],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.93051200e-01, 6.94664100e-03, 2.23610000e-06],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.03133400e-04, 9.98242740e-01, 1.45423350e-03],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [2.47660330e-03, 9.96072400e-01, 1.45106000e-03],\n",
       "       [1.06127840e-03, 9.97621830e-01, 1.31691610e-03],\n",
       "       [9.99793600e-01, 2.06395900e-04, 8.01881900e-10],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.59399270e-04, 7.57661340e-01, 2.41979350e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.89275300e-01, 1.06981100e-02, 2.66962050e-05],\n",
       "       [9.92146430e-01, 7.85356300e-03, 1.86538160e-10],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [1.22062870e-02, 9.87793740e-01, 3.69022770e-09],\n",
       "       [4.21037880e-05, 9.99944570e-01, 1.32993070e-05],\n",
       "       [7.98530940e-01, 2.01447950e-01, 2.11001000e-05],\n",
       "       [9.91800500e-01, 8.19930400e-03, 2.33705210e-07],\n",
       "       [3.59399270e-04, 7.57661340e-01, 2.41979350e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [9.99510300e-01, 4.89718700e-04, 9.35685500e-11],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [4.96591600e-01, 5.03320700e-01, 8.76937340e-05],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [4.21037880e-05, 9.99944570e-01, 1.32993070e-05],\n",
       "       [4.64562100e-03, 9.95338100e-01, 1.62158600e-05],\n",
       "       [9.31280740e-05, 9.99906800e-01, 6.24963700e-08],\n",
       "       [6.51598260e-03, 9.93461250e-01, 2.27103300e-05],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [6.99704600e-01, 2.99955500e-01, 3.39941620e-04],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.67587230e-01, 3.24127640e-02, 1.11678290e-08],\n",
       "       [9.71598100e-01, 2.54902730e-02, 2.91161030e-03],\n",
       "       [9.73320100e-01, 2.66783240e-02, 1.64007720e-06],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [9.97385700e-01, 2.61437300e-03, 6.81960100e-11],\n",
       "       [4.20743970e-02, 9.51056000e-01, 6.86956400e-03],\n",
       "       [6.51598260e-03, 9.93461250e-01, 2.27103300e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.15469000e-01, 8.45034500e-02, 2.75928100e-05],\n",
       "       [9.62029340e-01, 3.79633120e-02, 7.35817200e-06],\n",
       "       [8.30760960e-01, 1.69221100e-01, 1.79032140e-05],\n",
       "       [2.47660330e-03, 9.96072400e-01, 1.45106000e-03],\n",
       "       [9.99105400e-01, 8.90887800e-04, 3.71495570e-06],\n",
       "       [3.94247500e-06, 9.99981760e-01, 1.42963910e-05],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [1.06127840e-03, 9.97621830e-01, 1.31691610e-03],\n",
       "       [5.93764850e-03, 9.94062360e-01, 5.16509250e-08],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.31280740e-05, 9.99906800e-01, 6.24963700e-08],\n",
       "       [4.20743970e-02, 9.51056000e-01, 6.86956400e-03],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [9.77454660e-01, 2.25453400e-02, 7.24812650e-10],\n",
       "       [9.93051200e-01, 6.94664100e-03, 2.23610000e-06],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [8.57279800e-02, 9.13212200e-01, 1.05993620e-03],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [9.31280740e-05, 9.99906800e-01, 6.24963700e-08],\n",
       "       [9.94355100e-01, 5.63890860e-03, 6.10331500e-06],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [6.51598260e-03, 9.93461250e-01, 2.27103300e-05],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.49544640e-01, 6.50436760e-01, 1.86379530e-05],\n",
       "       [9.98199050e-01, 1.42098210e-03, 3.79936830e-04],\n",
       "       [9.98393950e-01, 1.59968040e-03, 6.28817630e-06],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [9.96950750e-01, 3.03264220e-03, 1.66895950e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [4.41425440e-01, 5.58530200e-01, 4.43906600e-05],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [9.99584730e-01, 4.15284500e-04, 1.26635140e-11],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [6.10263600e-03, 9.93897400e-01, 6.93016130e-09],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [1.02618180e-02, 9.89685600e-01, 5.24729480e-05],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [3.03133400e-04, 9.98242740e-01, 1.45423350e-03],\n",
       "       [6.51598260e-03, 9.93461250e-01, 2.27103300e-05],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [6.46203040e-01, 3.53760200e-01, 3.67744030e-05],\n",
       "       [1.22062870e-02, 9.87793740e-01, 3.69022770e-09],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01],\n",
       "       [5.65948100e-03, 9.92046360e-01, 2.29416830e-03],\n",
       "       [9.90615100e-01, 9.38068100e-03, 4.24791730e-06],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [9.31280740e-05, 9.99906800e-01, 6.24963700e-08],\n",
       "       [3.03133400e-04, 9.98242740e-01, 1.45423350e-03],\n",
       "       [4.46977400e-02, 9.55213960e-01, 8.82108300e-05],\n",
       "       [7.73916200e-09, 3.21387840e-04, 9.99678600e-01],\n",
       "       [6.83751800e-01, 3.16216900e-01, 3.13149470e-05],\n",
       "       [9.96618600e-01, 3.38140100e-03, 1.10821206e-10],\n",
       "       [2.56542280e-02, 9.74230950e-01, 1.14753370e-04],\n",
       "       [6.75139100e-03, 9.93248600e-01, 6.40679240e-09],\n",
       "       [3.25131720e-04, 2.28993800e-03, 9.97384970e-01],\n",
       "       [9.92048100e-01, 7.95188800e-03, 1.38849450e-09],\n",
       "       [5.65948100e-03, 9.92046360e-01, 2.29416830e-03],\n",
       "       [4.20743970e-02, 9.51056000e-01, 6.86956400e-03],\n",
       "       [5.65948100e-03, 9.92046360e-01, 2.29416830e-03],\n",
       "       [2.47660330e-03, 9.96072400e-01, 1.45106000e-03],\n",
       "       [3.69354300e-02, 9.63008700e-01, 5.59634720e-05],\n",
       "       [9.93051200e-01, 6.94664100e-03, 2.23610000e-06],\n",
       "       [6.75139100e-03, 9.93248600e-01, 6.40679240e-09],\n",
       "       [3.41517060e-04, 7.55458550e-02, 9.24112600e-01]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = df_proba[df_proba['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob = y_prob.to_numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieved from https://github.com/scikit-learn/scikit-learn/issues/3298\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def rocauc_ovo(truth, pred, average=\"macro\", multi_class=\"ovo\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "    \n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858485351022664"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo1 = rocauc_ovo(y_test_over, y_prob, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocauc_ovr(truth, pred, average=\"macro\", multi_class=\"ovr\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)   \n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average, multi_class=multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858485351022664"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr1 = rocauc_ovr(y_test_over, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=234,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = pd.DataFrame(X_test_over[:,0])\n",
    "dat2['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa05     0\n",
       "1      NRS114     0\n",
       "2      NRS168     1\n",
       "3      NRS255     2\n",
       "4      NRS209     2\n",
       "..        ...   ...\n",
       "197    NRS196     0\n",
       "198    NRS255     2\n",
       "199    NRS249     1\n",
       "200    NRS209     2\n",
       "201  CFBRSa28     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 2.8825 - accuracy: 0.4851 - val_loss: 1.0783 - val_accuracy: 0.4406\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.8292 - accuracy: 0.6511 - val_loss: 0.5338 - val_accuracy: 0.7723\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.4555 - accuracy: 0.8085 - val_loss: 0.4792 - val_accuracy: 0.7673\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.4124 - accuracy: 0.8447 - val_loss: 0.4709 - val_accuracy: 0.8267\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.4148 - accuracy: 0.8660 - val_loss: 0.4795 - val_accuracy: 0.8366\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.4293 - accuracy: 0.8489 - val_loss: 0.3709 - val_accuracy: 0.8663\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.3428 - accuracy: 0.8723 - val_loss: 0.3513 - val_accuracy: 0.8911\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 338us/step - loss: 0.3207 - accuracy: 0.8979 - val_loss: 0.3925 - val_accuracy: 0.8614\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.3100 - accuracy: 0.9106 - val_loss: 0.3447 - val_accuracy: 0.8861\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 411us/step - loss: 0.2768 - accuracy: 0.9106 - val_loss: 0.3106 - val_accuracy: 0.8861\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.2628 - accuracy: 0.9319 - val_loss: 0.3640 - val_accuracy: 0.8911\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.3073 - accuracy: 0.9128 - val_loss: 0.3211 - val_accuracy: 0.9059\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.2935 - accuracy: 0.9106 - val_loss: 0.2787 - val_accuracy: 0.8960\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.2629 - accuracy: 0.9234 - val_loss: 0.3348 - val_accuracy: 0.8911\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.2582 - accuracy: 0.9149 - val_loss: 0.2987 - val_accuracy: 0.8762\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.2563 - accuracy: 0.9277 - val_loss: 0.2819 - val_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.2355 - accuracy: 0.9170 - val_loss: 0.3232 - val_accuracy: 0.8911\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.2167 - accuracy: 0.9404 - val_loss: 0.3018 - val_accuracy: 0.8762\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.2258 - accuracy: 0.9340 - val_loss: 0.3338 - val_accuracy: 0.9059\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.2220 - accuracy: 0.9383 - val_loss: 0.2656 - val_accuracy: 0.9059\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 420us/step - loss: 0.2052 - accuracy: 0.9362 - val_loss: 0.2531 - val_accuracy: 0.9208\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 768us/step - loss: 0.2261 - accuracy: 0.9213 - val_loss: 0.3041 - val_accuracy: 0.8663\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.2584 - accuracy: 0.9170 - val_loss: 0.2812 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.2362 - accuracy: 0.9255 - val_loss: 0.2888 - val_accuracy: 0.8812\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.2198 - accuracy: 0.8936 - val_loss: 0.2474 - val_accuracy: 0.8713\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1996 - accuracy: 0.9277 - val_loss: 0.2372 - val_accuracy: 0.9059\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1864 - accuracy: 0.9532 - val_loss: 0.2926 - val_accuracy: 0.9059\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1906 - accuracy: 0.9383 - val_loss: 0.2150 - val_accuracy: 0.9158\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 280us/step - loss: 0.1882 - accuracy: 0.9404 - val_loss: 0.2447 - val_accuracy: 0.9010\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.1705 - accuracy: 0.9447 - val_loss: 0.2176 - val_accuracy: 0.9307\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 484us/step - loss: 0.1851 - accuracy: 0.9362 - val_loss: 0.2094 - val_accuracy: 0.9455\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 0.1863 - accuracy: 0.9298 - val_loss: 0.2719 - val_accuracy: 0.8812\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.1639 - accuracy: 0.9489 - val_loss: 0.2201 - val_accuracy: 0.9109\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.1598 - accuracy: 0.9426 - val_loss: 0.2388 - val_accuracy: 0.8960\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.1653 - accuracy: 0.9404 - val_loss: 0.2114 - val_accuracy: 0.9307\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.1579 - accuracy: 0.9532 - val_loss: 0.2188 - val_accuracy: 0.9109\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1567 - accuracy: 0.9468 - val_loss: 0.2561 - val_accuracy: 0.8465\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.1536 - accuracy: 0.9340 - val_loss: 0.2105 - val_accuracy: 0.9109\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 0.1457 - accuracy: 0.9511 - val_loss: 0.2327 - val_accuracy: 0.8911\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 329us/step - loss: 0.1514 - accuracy: 0.9340 - val_loss: 0.2132 - val_accuracy: 0.9208\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.1522 - accuracy: 0.9489 - val_loss: 0.2112 - val_accuracy: 0.9208\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 0.1511 - accuracy: 0.9532 - val_loss: 0.2007 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1381 - accuracy: 0.9511 - val_loss: 0.2321 - val_accuracy: 0.8911\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1396 - accuracy: 0.9532 - val_loss: 0.2299 - val_accuracy: 0.9059\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1354 - accuracy: 0.9574 - val_loss: 0.2507 - val_accuracy: 0.8416\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.1346 - accuracy: 0.9426 - val_loss: 0.1887 - val_accuracy: 0.9356\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1322 - accuracy: 0.9574 - val_loss: 0.1863 - val_accuracy: 0.9356\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1426 - accuracy: 0.9468 - val_loss: 0.1710 - val_accuracy: 0.9257\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1315 - accuracy: 0.9532 - val_loss: 0.1820 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 299us/step - loss: 0.1296 - accuracy: 0.9574 - val_loss: 0.1956 - val_accuracy: 0.9356\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 0.1844 - accuracy: 0.9170 - val_loss: 0.1771 - val_accuracy: 0.9307\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.1319 - accuracy: 0.9596 - val_loss: 0.1623 - val_accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1315 - accuracy: 0.9511 - val_loss: 0.1665 - val_accuracy: 0.9653\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 99us/step - loss: 0.2432 - accuracy: 0.9277 - val_loss: 0.3210 - val_accuracy: 0.9010\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.5616 - accuracy: 0.8489 - val_loss: 0.3251 - val_accuracy: 0.8515\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.3546 - accuracy: 0.8809 - val_loss: 0.1939 - val_accuracy: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.1692 - accuracy: 0.9383 - val_loss: 0.1872 - val_accuracy: 0.9356\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.1427 - accuracy: 0.9447 - val_loss: 0.1994 - val_accuracy: 0.9208\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1209 - accuracy: 0.9574 - val_loss: 0.2017 - val_accuracy: 0.9158\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1122 - accuracy: 0.9617 - val_loss: 0.1550 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.1156 - accuracy: 0.9638 - val_loss: 0.2011 - val_accuracy: 0.9010\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.1191 - accuracy: 0.9596 - val_loss: 0.1887 - val_accuracy: 0.9109\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.1317 - accuracy: 0.9511 - val_loss: 0.1687 - val_accuracy: 0.9406\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1226 - accuracy: 0.9553 - val_loss: 0.1585 - val_accuracy: 0.9455\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1094 - accuracy: 0.9574 - val_loss: 0.2164 - val_accuracy: 0.9109\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1129 - accuracy: 0.9511 - val_loss: 0.1518 - val_accuracy: 0.9703\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1169 - accuracy: 0.9638 - val_loss: 0.1597 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.1031 - accuracy: 0.9638 - val_loss: 0.1708 - val_accuracy: 0.9406\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1124 - accuracy: 0.9638 - val_loss: 0.2313 - val_accuracy: 0.8960\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1161 - accuracy: 0.9447 - val_loss: 0.1683 - val_accuracy: 0.9703\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.1766 - val_accuracy: 0.9356\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1166 - accuracy: 0.9596 - val_loss: 0.1598 - val_accuracy: 0.9455\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.1100 - accuracy: 0.9596 - val_loss: 0.1919 - val_accuracy: 0.9307\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 0.1744 - val_accuracy: 0.9505\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1317 - accuracy: 0.9404 - val_loss: 0.1456 - val_accuracy: 0.9703\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1169 - accuracy: 0.9574 - val_loss: 0.2500 - val_accuracy: 0.8713\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1755 - val_accuracy: 0.9356\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.0996 - accuracy: 0.9660 - val_loss: 0.1451 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1039 - accuracy: 0.9660 - val_loss: 0.1668 - val_accuracy: 0.9406\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0991 - accuracy: 0.9660 - val_loss: 0.1655 - val_accuracy: 0.9406\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0977 - accuracy: 0.9617 - val_loss: 0.1496 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1010 - accuracy: 0.9638 - val_loss: 0.1433 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 103us/step - loss: 0.0978 - accuracy: 0.9660 - val_loss: 0.1909 - val_accuracy: 0.9208\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1056 - accuracy: 0.9617 - val_loss: 0.1671 - val_accuracy: 0.9455\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1008 - accuracy: 0.9638 - val_loss: 0.2185 - val_accuracy: 0.8713\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1022 - accuracy: 0.9617 - val_loss: 0.1495 - val_accuracy: 0.9505\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.1073 - accuracy: 0.9617 - val_loss: 0.1966 - val_accuracy: 0.8960\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.1077 - accuracy: 0.9447 - val_loss: 0.1528 - val_accuracy: 0.9455\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.0954 - accuracy: 0.9660 - val_loss: 0.1626 - val_accuracy: 0.9455\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.0993 - accuracy: 0.9660 - val_loss: 0.1419 - val_accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1324 - accuracy: 0.9362 - val_loss: 0.1608 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.1138 - accuracy: 0.9489 - val_loss: 0.1490 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.0988 - accuracy: 0.9617 - val_loss: 0.1816 - val_accuracy: 0.9307\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.0934 - accuracy: 0.9660 - val_loss: 0.1414 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0965 - accuracy: 0.9638 - val_loss: 0.1397 - val_accuracy: 0.9703\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0958 - accuracy: 0.9660 - val_loss: 0.1499 - val_accuracy: 0.9455\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.1008 - accuracy: 0.9596 - val_loss: 0.2245 - val_accuracy: 0.8762\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1008 - accuracy: 0.9596 - val_loss: 0.1728 - val_accuracy: 0.9455\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0944 - accuracy: 0.9660 - val_loss: 0.1528 - val_accuracy: 0.9455\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0986 - accuracy: 0.9638 - val_loss: 0.1572 - val_accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1074910f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 170us/step\n",
      "over-sampling test accuracy: 91.09%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over2 = model1_over2.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 2, 1, 2, 2, 2,\n",
       "       0, 2, 0, 0, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0,\n",
       "       2, 0, 1, 2, 2, 2, 1, 0, 0, 2, 2, 1, 1, 2, 0, 2, 0, 1, 1, 0, 1, 1,\n",
       "       1, 2, 1, 2, 0, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1,\n",
       "       1, 2, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0,\n",
       "       2, 0, 1, 1, 1, 2, 0, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2,\n",
       "       0, 2, 1, 1, 0, 2, 2, 2, 1, 1, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 2, 1,\n",
       "       1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0,\n",
       "       2, 1, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model1_over2.predict_classes(X_test_over)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa05     0     0\n",
       "1      NRS114     0     0\n",
       "2      NRS168     1     1\n",
       "3      NRS255     2     2\n",
       "4      NRS209     2     2\n",
       "..        ...   ...   ...\n",
       "197    NRS196     0     0\n",
       "198    NRS255     2     2\n",
       "199    NRS249     1     1\n",
       "200    NRS209     2     2\n",
       "201  CFBRSa28     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2['pred'] = pred2\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba2 = model1_over2.predict_proba(X_test_over)\n",
    "dat_proba2 = pd.DataFrame(proba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.180933e-01</td>\n",
       "      <td>0.281888</td>\n",
       "      <td>1.898983e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.799658e-01</td>\n",
       "      <td>0.020034</td>\n",
       "      <td>3.792795e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.303862e-02</td>\n",
       "      <td>0.926957</td>\n",
       "      <td>4.478878e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.421833e-04</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>9.975851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.214109e-12</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>9.991568e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.960671e-01</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>9.774284e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.421833e-04</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>9.975851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2.347543e-02</td>\n",
       "      <td>0.976525</td>\n",
       "      <td>3.907105e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.214109e-12</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>9.991568e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6.994694e-01</td>\n",
       "      <td>0.300481</td>\n",
       "      <td>4.986521e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    7.180933e-01  0.281888  1.898983e-05\n",
       "1    9.799658e-01  0.020034  3.792795e-10\n",
       "2    7.303862e-02  0.926957  4.478878e-06\n",
       "3    3.421833e-04  0.002073  9.975851e-01\n",
       "4    3.214109e-12  0.000843  9.991568e-01\n",
       "..            ...       ...           ...\n",
       "197  9.960671e-01  0.003932  9.774284e-07\n",
       "198  3.421833e-04  0.002073  9.975851e-01\n",
       "199  2.347543e-02  0.976525  3.907105e-09\n",
       "200  3.214109e-12  0.000843  9.991568e-01\n",
       "201  6.994694e-01  0.300481  4.986521e-05\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba2.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/2p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.1114 - accuracy: 0.9617 - val_loss: 0.1984 - val_accuracy: 0.9356\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.1130 - accuracy: 0.9553 - val_loss: 0.2100 - val_accuracy: 0.9356\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.1097 - accuracy: 0.9596 - val_loss: 0.2527 - val_accuracy: 0.9059\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.1126 - accuracy: 0.9574 - val_loss: 0.2132 - val_accuracy: 0.9356\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 0.2323 - val_accuracy: 0.9307\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1122 - accuracy: 0.9617 - val_loss: 0.2146 - val_accuracy: 0.9158\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.1130 - accuracy: 0.9596 - val_loss: 0.2141 - val_accuracy: 0.9356\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1049 - accuracy: 0.9660 - val_loss: 0.2253 - val_accuracy: 0.9158\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1067 - accuracy: 0.9617 - val_loss: 0.2187 - val_accuracy: 0.9356\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1133 - accuracy: 0.9553 - val_loss: 0.2209 - val_accuracy: 0.9307\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1138 - accuracy: 0.9553 - val_loss: 0.2579 - val_accuracy: 0.9307\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 0.2262 - val_accuracy: 0.9307\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1052 - accuracy: 0.9660 - val_loss: 0.2316 - val_accuracy: 0.9307\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1064 - accuracy: 0.9660 - val_loss: 0.2411 - val_accuracy: 0.9307\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.1064 - accuracy: 0.9532 - val_loss: 0.2072 - val_accuracy: 0.9356\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1072 - accuracy: 0.9660 - val_loss: 0.2328 - val_accuracy: 0.9307\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.1009 - accuracy: 0.9660 - val_loss: 0.2176 - val_accuracy: 0.9356\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.2237 - val_accuracy: 0.9307\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.0991 - accuracy: 0.9660 - val_loss: 0.2313 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1040 - accuracy: 0.9553 - val_loss: 0.2441 - val_accuracy: 0.9307\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1006 - accuracy: 0.9660 - val_loss: 0.2055 - val_accuracy: 0.9356\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1022 - accuracy: 0.9596 - val_loss: 0.2630 - val_accuracy: 0.9158\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.0988 - accuracy: 0.9660 - val_loss: 0.2149 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1007 - accuracy: 0.9660 - val_loss: 0.2624 - val_accuracy: 0.9158\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1085 - accuracy: 0.9617 - val_loss: 0.2617 - val_accuracy: 0.9158\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.1171 - accuracy: 0.9511 - val_loss: 0.2281 - val_accuracy: 0.9356\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.1043 - accuracy: 0.9660 - val_loss: 0.2279 - val_accuracy: 0.9307\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.0966 - accuracy: 0.9660 - val_loss: 0.2375 - val_accuracy: 0.9307\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 373us/step - loss: 0.1010 - accuracy: 0.9660 - val_loss: 0.2273 - val_accuracy: 0.9307\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.1045 - accuracy: 0.9617 - val_loss: 0.2233 - val_accuracy: 0.9356\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.1041 - accuracy: 0.9638 - val_loss: 0.2600 - val_accuracy: 0.9158\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.1095 - accuracy: 0.9638 - val_loss: 0.2872 - val_accuracy: 0.8861\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 748us/step - loss: 0.1102 - accuracy: 0.9511 - val_loss: 0.2359 - val_accuracy: 0.9307\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.0976 - accuracy: 0.9660 - val_loss: 0.2392 - val_accuracy: 0.9307\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.0997 - accuracy: 0.9468 - val_loss: 0.2073 - val_accuracy: 0.9406\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 0.1028 - accuracy: 0.9660 - val_loss: 0.2992 - val_accuracy: 0.9158\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.1173 - accuracy: 0.9489 - val_loss: 0.2105 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0990 - accuracy: 0.9660 - val_loss: 0.2454 - val_accuracy: 0.9307\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 321us/step - loss: 0.1025 - accuracy: 0.9574 - val_loss: 0.2159 - val_accuracy: 0.9356\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0993 - accuracy: 0.9617 - val_loss: 0.2134 - val_accuracy: 0.9356\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.2252 - val_accuracy: 0.9307\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0978 - accuracy: 0.9660 - val_loss: 0.2534 - val_accuracy: 0.9158\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1052 - accuracy: 0.9553 - val_loss: 0.2053 - val_accuracy: 0.9406\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0986 - accuracy: 0.9638 - val_loss: 0.2212 - val_accuracy: 0.9307\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0958 - accuracy: 0.9660 - val_loss: 0.2706 - val_accuracy: 0.9158\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.1014 - accuracy: 0.9489 - val_loss: 0.2091 - val_accuracy: 0.9406\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.1026 - accuracy: 0.9617 - val_loss: 0.2101 - val_accuracy: 0.9406\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1032 - accuracy: 0.9489 - val_loss: 0.2335 - val_accuracy: 0.9307\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0975 - accuracy: 0.9617 - val_loss: 0.2277 - val_accuracy: 0.9307\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.0949 - accuracy: 0.9660 - val_loss: 0.2668 - val_accuracy: 0.9158\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.0953 - accuracy: 0.9596 - val_loss: 0.2191 - val_accuracy: 0.9356\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.0991 - accuracy: 0.9638 - val_loss: 0.2380 - val_accuracy: 0.9307\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.1001 - accuracy: 0.9660 - val_loss: 0.2479 - val_accuracy: 0.9109\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.0969 - accuracy: 0.9617 - val_loss: 0.2372 - val_accuracy: 0.9307\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 575us/step - loss: 0.0928 - accuracy: 0.9660 - val_loss: 0.2475 - val_accuracy: 0.9307\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0959 - accuracy: 0.9638 - val_loss: 0.2409 - val_accuracy: 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0964 - accuracy: 0.9638 - val_loss: 0.2162 - val_accuracy: 0.9406\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0910 - accuracy: 0.9660 - val_loss: 0.2480 - val_accuracy: 0.9307\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.0936 - accuracy: 0.9660 - val_loss: 0.2401 - val_accuracy: 0.9307\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0957 - accuracy: 0.9617 - val_loss: 0.2214 - val_accuracy: 0.9356\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.0962 - accuracy: 0.9638 - val_loss: 0.2114 - val_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.1084 - accuracy: 0.9447 - val_loss: 0.2068 - val_accuracy: 0.9406\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.1083 - accuracy: 0.9617 - val_loss: 0.2959 - val_accuracy: 0.8861\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 546us/step - loss: 0.0927 - accuracy: 0.9638 - val_loss: 0.2179 - val_accuracy: 0.9406\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.0925 - accuracy: 0.9638 - val_loss: 0.2696 - val_accuracy: 0.9208\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0927 - accuracy: 0.9617 - val_loss: 0.2398 - val_accuracy: 0.9307\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.2825 - val_accuracy: 0.8861\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0976 - accuracy: 0.9574 - val_loss: 0.2349 - val_accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.0948 - accuracy: 0.9660 - val_loss: 0.2579 - val_accuracy: 0.9307\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.1054 - accuracy: 0.9468 - val_loss: 0.2221 - val_accuracy: 0.9406\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.1004 - accuracy: 0.9574 - val_loss: 0.2270 - val_accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 318us/step - loss: 0.0953 - accuracy: 0.9638 - val_loss: 0.2546 - val_accuracy: 0.9158\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.0952 - accuracy: 0.9617 - val_loss: 0.2359 - val_accuracy: 0.9356\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0975 - accuracy: 0.9596 - val_loss: 0.2300 - val_accuracy: 0.9356\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0894 - accuracy: 0.9660 - val_loss: 0.2487 - val_accuracy: 0.9356\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0895 - accuracy: 0.9638 - val_loss: 0.2375 - val_accuracy: 0.9356\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 0.0883 - accuracy: 0.9660 - val_loss: 0.2394 - val_accuracy: 0.9356\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 268us/step - loss: 0.0946 - accuracy: 0.9532 - val_loss: 0.2100 - val_accuracy: 0.9406\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0981 - accuracy: 0.9638 - val_loss: 0.2487 - val_accuracy: 0.9307\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.0922 - accuracy: 0.9660 - val_loss: 0.2586 - val_accuracy: 0.9307\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0894 - accuracy: 0.9617 - val_loss: 0.2384 - val_accuracy: 0.9356\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0883 - accuracy: 0.9660 - val_loss: 0.2528 - val_accuracy: 0.9356\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0873 - accuracy: 0.9660 - val_loss: 0.2269 - val_accuracy: 0.9356\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.0900 - accuracy: 0.9617 - val_loss: 0.2397 - val_accuracy: 0.9356\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.0897 - accuracy: 0.9638 - val_loss: 0.2325 - val_accuracy: 0.9356\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.0963 - accuracy: 0.9681 - val_loss: 0.3058 - val_accuracy: 0.8861\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0953 - accuracy: 0.9574 - val_loss: 0.2528 - val_accuracy: 0.9257\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.0908 - accuracy: 0.9596 - val_loss: 0.2357 - val_accuracy: 0.9356\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0881 - accuracy: 0.9617 - val_loss: 0.2342 - val_accuracy: 0.9356\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 0.0895 - accuracy: 0.9660 - val_loss: 0.2505 - val_accuracy: 0.9356\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0915 - accuracy: 0.9617 - val_loss: 0.2452 - val_accuracy: 0.9356\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0883 - accuracy: 0.9660 - val_loss: 0.2652 - val_accuracy: 0.9356\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.2708 - val_accuracy: 0.9158\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0924 - accuracy: 0.9617 - val_loss: 0.2262 - val_accuracy: 0.9406\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 0.0889 - accuracy: 0.9660 - val_loss: 0.2682 - val_accuracy: 0.9158\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 0.1046 - accuracy: 0.9574 - val_loss: 0.2950 - val_accuracy: 0.9158\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.0925 - accuracy: 0.9660 - val_loss: 0.2361 - val_accuracy: 0.9356\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.0861 - accuracy: 0.9638 - val_loss: 0.2797 - val_accuracy: 0.9208\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.0915 - accuracy: 0.9638 - val_loss: 0.2413 - val_accuracy: 0.9356\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0869 - accuracy: 0.9617 - val_loss: 0.2961 - val_accuracy: 0.8861\n"
     ]
    }
   ],
   "source": [
    "hist1_over2 = model1_over2.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.16%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over2.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba2 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.748042e-03</td>\n",
       "      <td>9.981960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712007</td>\n",
       "      <td>2.879924e-01</td>\n",
       "      <td>9.646217e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>9.937732e-01</td>\n",
       "      <td>4.482882e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>1.173831e-01</td>\n",
       "      <td>2.310933e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571179</td>\n",
       "      <td>4.288184e-01</td>\n",
       "      <td>2.444667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>9.979747e-01</td>\n",
       "      <td>1.653396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>SR1065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982940</td>\n",
       "      <td>1.705227e-02</td>\n",
       "      <td>7.349168e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>1.962516e-03</td>\n",
       "      <td>9.441347e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.031141e-13</td>\n",
       "      <td>3.208205e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>1.669456e-04</td>\n",
       "      <td>4.411099e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage       strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual       NRS148          2           2  0.000056   \n",
       "1      p002ykpresabs_qual    BCH-SA-03          1           0  0.712007   \n",
       "2      p002ykpresabs_qual       NRS218          1           1  0.006222   \n",
       "3      p002ykpresabs_qual       NRS036          0           0  0.882617   \n",
       "4      p002ykpresabs_qual       NRS386          1           0  0.571179   \n",
       "...                   ...          ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual       NRS112          1           1  0.001860   \n",
       "4280  pyopresabsSTCC_qual       SR1065          0           0  0.982940   \n",
       "4281  pyopresabsSTCC_qual       NRS203          0           0  0.997093   \n",
       "4282  pyopresabsSTCC_qual  CFBREBSa129          0           0  1.000000   \n",
       "4283  pyopresabsSTCC_qual     CFBRSa25          0           0  0.999833   \n",
       "\n",
       "                 1             2  \n",
       "0     1.748042e-03  9.981960e-01  \n",
       "1     2.879924e-01  9.646217e-07  \n",
       "2     9.937732e-01  4.482882e-06  \n",
       "3     1.173831e-01  2.310933e-10  \n",
       "4     4.288184e-01  2.444667e-06  \n",
       "...            ...           ...  \n",
       "4279  9.979747e-01  1.653396e-04  \n",
       "4280  1.705227e-02  7.349168e-06  \n",
       "4281  1.962516e-03  9.441347e-04  \n",
       "4282  3.031141e-13  3.208205e-09  \n",
       "4283  1.669456e-04  4.411099e-08  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.18093300e-01, 2.81887650e-01, 1.89898330e-05],\n",
       "       [9.79965800e-01, 2.00342330e-02, 3.79279470e-10],\n",
       "       [7.30386200e-02, 9.26956830e-01, 4.47887800e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.93137000e-04, 9.93089850e-01, 6.51700750e-03],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [4.08698850e-03, 9.95903900e-01, 9.11266500e-06],\n",
       "       [9.99567100e-01, 4.32776600e-04, 1.56440590e-07],\n",
       "       [9.98988200e-01, 7.50830500e-04, 2.60972800e-04],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [7.30386200e-02, 9.26956830e-01, 4.47887800e-06],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [4.37005120e-02, 9.56299400e-01, 1.08562060e-09],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [5.79318050e-01, 4.20641180e-01, 4.07323680e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.79965800e-01, 2.00342330e-02, 3.79279470e-10],\n",
       "       [4.98294920e-03, 9.95002570e-01, 1.44489440e-05],\n",
       "       [9.79965800e-01, 2.00342330e-02, 3.79279470e-10],\n",
       "       [4.10603340e-01, 5.89273300e-01, 1.23375280e-04],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [1.41128170e-02, 9.85881570e-01, 5.69617940e-06],\n",
       "       [7.18093300e-01, 2.81887650e-01, 1.89898330e-05],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [5.62493900e-02, 9.43745700e-01, 5.00005630e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.97855370e-01, 2.14458840e-03, 9.57977400e-11],\n",
       "       [5.98552780e-03, 9.94014440e-01, 2.86015600e-10],\n",
       "       [8.50595100e-01, 1.49356950e-01, 4.79626980e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.93061960e-01, 6.93602900e-03, 1.96560250e-06],\n",
       "       [2.93548100e-01, 6.65840000e-01, 4.06118330e-02],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [7.81162300e-02, 9.21877150e-01, 6.55695100e-06],\n",
       "       [9.89722850e-01, 8.96631700e-03, 1.31083330e-03],\n",
       "       [9.99006200e-01, 9.56374300e-04, 3.73570900e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.55135300e-02, 9.03312700e-01, 1.17374390e-03],\n",
       "       [2.34754270e-02, 9.76524600e-01, 3.90710530e-09],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [6.88138400e-01, 3.11422680e-01, 4.38921500e-04],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.99530200e-01, 4.69672120e-04, 1.07250735e-07],\n",
       "       [4.17214330e-01, 5.82750100e-01, 3.55872070e-05],\n",
       "       [3.81168560e-04, 8.96246970e-01, 1.03371830e-01],\n",
       "       [9.52372900e-01, 4.76270700e-02, 1.52409780e-08],\n",
       "       [5.98552780e-03, 9.94014440e-01, 2.86015600e-10],\n",
       "       [7.81162300e-02, 9.21877150e-01, 6.55695100e-06],\n",
       "       [7.30386200e-02, 9.26956830e-01, 4.47887800e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.83351480e-01, 6.16647840e-01, 6.92919060e-07],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [9.91025000e-01, 8.96847300e-03, 6.60980370e-06],\n",
       "       [5.62493900e-02, 9.43745700e-01, 5.00005630e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [9.99581500e-01, 4.02532550e-04, 1.59625220e-05],\n",
       "       [9.99735300e-01, 2.64651800e-04, 2.86166880e-12],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [3.93137000e-04, 9.93089850e-01, 6.51700750e-03],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [4.08698850e-03, 9.95903900e-01, 9.11266500e-06],\n",
       "       [7.81162300e-02, 9.21877150e-01, 6.55695100e-06],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [9.79965800e-01, 2.00342330e-02, 3.79279470e-10],\n",
       "       [9.91292200e-01, 8.70775700e-03, 2.27458190e-10],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [9.89236200e-01, 1.07254990e-02, 3.83438050e-05],\n",
       "       [9.82693550e-01, 1.73064270e-02, 3.29400760e-10],\n",
       "       [6.01655760e-03, 9.93979800e-01, 3.72962650e-06],\n",
       "       [4.73432530e-04, 9.99488230e-01, 3.83812000e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.99965300e-01, 3.46369920e-05, 1.85251900e-15],\n",
       "       [6.01655760e-03, 9.93979800e-01, 3.72962650e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [7.66534300e-02, 9.23240540e-01, 1.06021886e-04],\n",
       "       [2.76781230e-02, 9.72122800e-01, 1.99099810e-04],\n",
       "       [3.93137000e-04, 9.93089850e-01, 6.51700750e-03],\n",
       "       [9.98345260e-01, 1.62681810e-03, 2.79162670e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [9.97855370e-01, 2.14458840e-03, 9.57977400e-11],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [7.81162300e-02, 9.21877150e-01, 6.55695100e-06],\n",
       "       [5.98552780e-03, 9.94014440e-01, 2.86015600e-10],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [7.66534300e-02, 9.23240540e-01, 1.06021886e-04],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [9.99988440e-01, 1.15577905e-05, 6.54744660e-09],\n",
       "       [1.41128170e-02, 9.85881570e-01, 5.69617940e-06],\n",
       "       [9.65526460e-01, 3.44628580e-02, 1.06790430e-05],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [6.42307600e-01, 3.54842800e-01, 2.84968970e-03],\n",
       "       [3.81168560e-04, 8.96246970e-01, 1.03371830e-01],\n",
       "       [3.16638850e-04, 9.99681600e-01, 1.83806250e-06],\n",
       "       [4.73432530e-04, 9.99488230e-01, 3.83812000e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [9.99384900e-01, 6.15100400e-04, 4.69301030e-12],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [8.88096200e-01, 1.11475590e-01, 4.28149880e-04],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [9.99988440e-01, 1.15577905e-05, 6.54744660e-09],\n",
       "       [9.55135300e-02, 9.03312700e-01, 1.17374390e-03],\n",
       "       [9.92840900e-01, 7.15910700e-03, 2.48195100e-10],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [9.96483450e-01, 3.51615860e-03, 3.07395570e-07],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [2.34754270e-02, 9.76524600e-01, 3.90710530e-09],\n",
       "       [4.08698850e-03, 9.95903900e-01, 9.11266500e-06],\n",
       "       [3.81168560e-04, 8.96246970e-01, 1.03371830e-01],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [4.12430300e-02, 9.58653300e-01, 1.03769160e-04],\n",
       "       [1.41128170e-02, 9.85881570e-01, 5.69617940e-06],\n",
       "       [4.73432530e-04, 9.99488230e-01, 3.83812000e-05],\n",
       "       [9.55135300e-02, 9.03312700e-01, 1.17374390e-03],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [1.00000000e+00, 2.63370890e-08, 6.93177100e-11],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.99341550e-01, 6.58322360e-04, 6.98514500e-08],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.53165530e-01, 4.66931430e-02, 1.41296840e-04],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [5.92643100e-01, 4.07352120e-01, 4.80395560e-06],\n",
       "       [9.79965800e-01, 2.00342330e-02, 3.79279470e-10],\n",
       "       [3.45896780e-02, 9.65359900e-01, 5.03531740e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.97374200e-01, 2.62578180e-03, 1.10260590e-11],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [2.34754270e-02, 9.76524600e-01, 3.90710530e-09],\n",
       "       [3.83351480e-01, 6.16647840e-01, 6.92919060e-07],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [1.51658310e-04, 3.02637500e-02, 9.69584500e-01],\n",
       "       [3.45896780e-02, 9.65359900e-01, 5.03531740e-05],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [6.82273270e-01, 3.17697320e-01, 2.93398680e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [4.98294920e-03, 9.95002570e-01, 1.44489440e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [8.80835200e-01, 1.19145260e-01, 1.96475650e-05],\n",
       "       [9.65823700e-01, 3.41651100e-02, 1.11805280e-05],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [9.68446500e-01, 3.15463880e-02, 7.12873300e-06],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [2.34754270e-02, 9.76524600e-01, 3.90710530e-09],\n",
       "       [2.26655770e-03, 9.87006200e-01, 1.07271920e-02],\n",
       "       [2.24880870e-04, 9.99761400e-01, 1.36866690e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [3.34321270e-05, 9.99875900e-01, 9.06528100e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [7.17621900e-01, 2.82364250e-01, 1.37548500e-05],\n",
       "       [9.07479100e-02, 9.09252100e-01, 1.62407860e-09],\n",
       "       [9.99341550e-01, 6.58322360e-04, 6.98514500e-08],\n",
       "       [4.98294920e-03, 9.95002570e-01, 1.44489440e-05],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [9.04246100e-01, 9.52535400e-02, 5.00412830e-04],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [7.66534300e-02, 9.23240540e-01, 1.06021886e-04],\n",
       "       [9.99874700e-01, 1.25286850e-04, 1.02178730e-08],\n",
       "       [9.96067100e-01, 3.93193730e-03, 9.77428400e-07],\n",
       "       [9.98345260e-01, 1.62681810e-03, 2.79162670e-05],\n",
       "       [4.31114020e-01, 5.68859700e-01, 2.62245890e-05],\n",
       "       [3.81168560e-04, 8.96246970e-01, 1.03371830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [7.66534300e-02, 9.23240540e-01, 1.06021886e-04],\n",
       "       [9.96067100e-01, 3.93193730e-03, 9.77428400e-07],\n",
       "       [3.42183340e-04, 2.07277180e-03, 9.97585060e-01],\n",
       "       [2.34754270e-02, 9.76524600e-01, 3.90710530e-09],\n",
       "       [3.21410900e-12, 8.43131860e-04, 9.99156830e-01],\n",
       "       [6.99469400e-01, 3.00480700e-01, 4.98652080e-05]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob2 = df_proba2[df_proba2['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob2 = y_prob2.to_numpy()\n",
    "y_prob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98909767610748"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo2 = rocauc_ovo(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98909767610748"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr2 = rocauc_ovr(y_test_over, y_prob2, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=345,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = pd.DataFrame(X_test_over[:,0])\n",
    "dat3['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test\n",
       "0         NRS148     2\n",
       "1         NRS209     2\n",
       "2         NRS187     1\n",
       "3    CFBREBSa116     0\n",
       "4         NRS187     1\n",
       "..           ...   ...\n",
       "197         GA12     0\n",
       "198       NRS209     2\n",
       "199       NRS265     1\n",
       "200       NRS253     1\n",
       "201       SR4187     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 316us/step - loss: 8.1953 - accuracy: 0.5255 - val_loss: 4.4994 - val_accuracy: 0.4851\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.9493 - accuracy: 0.5106 - val_loss: 2.0852 - val_accuracy: 0.5198\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 1.2796 - accuracy: 0.5574 - val_loss: 1.1100 - val_accuracy: 0.6881\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.7187 - accuracy: 0.7362 - val_loss: 0.5912 - val_accuracy: 0.7327\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.5239 - accuracy: 0.8043 - val_loss: 0.5104 - val_accuracy: 0.8366\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.4743 - accuracy: 0.8213 - val_loss: 0.4821 - val_accuracy: 0.8119\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 0.4135 - accuracy: 0.8340 - val_loss: 0.4445 - val_accuracy: 0.8366\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.4048 - accuracy: 0.8404 - val_loss: 0.4078 - val_accuracy: 0.8366\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.4196 - accuracy: 0.8553 - val_loss: 0.3869 - val_accuracy: 0.8218\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.3645 - accuracy: 0.8638 - val_loss: 0.3758 - val_accuracy: 0.8168\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.3246 - accuracy: 0.8723 - val_loss: 0.3874 - val_accuracy: 0.8465\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.3098 - accuracy: 0.8979 - val_loss: 0.3687 - val_accuracy: 0.8366\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.3372 - accuracy: 0.8830 - val_loss: 0.5217 - val_accuracy: 0.8366\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.3688 - accuracy: 0.8745 - val_loss: 0.3528 - val_accuracy: 0.8564\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.3334 - accuracy: 0.9021 - val_loss: 0.2955 - val_accuracy: 0.9010\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.3308 - accuracy: 0.9064 - val_loss: 0.5863 - val_accuracy: 0.8020\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3987 - val_accuracy: 0.8416\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.3176 - accuracy: 0.8851 - val_loss: 0.3013 - val_accuracy: 0.8663\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 0.3364 - accuracy: 0.8894 - val_loss: 0.2942 - val_accuracy: 0.9257\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 0.3317 - accuracy: 0.9106 - val_loss: 0.3093 - val_accuracy: 0.8515\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.2660 - accuracy: 0.9298 - val_loss: 0.3402 - val_accuracy: 0.8713\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.2417 - accuracy: 0.9234 - val_loss: 0.2445 - val_accuracy: 0.9257\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.2471 - accuracy: 0.9340 - val_loss: 0.2585 - val_accuracy: 0.8762\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 305us/step - loss: 0.2553 - accuracy: 0.9340 - val_loss: 0.2488 - val_accuracy: 0.8911\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 397us/step - loss: 0.2283 - accuracy: 0.9383 - val_loss: 0.3603 - val_accuracy: 0.9109\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 276us/step - loss: 0.2703 - accuracy: 0.9191 - val_loss: 0.2622 - val_accuracy: 0.9059\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.2424 - accuracy: 0.9362 - val_loss: 0.2631 - val_accuracy: 0.8960\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 0.2314 - accuracy: 0.9277 - val_loss: 0.2741 - val_accuracy: 0.8861\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 0.2120 - accuracy: 0.9277 - val_loss: 0.2528 - val_accuracy: 0.9059\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 332us/step - loss: 0.2452 - accuracy: 0.9319 - val_loss: 0.3652 - val_accuracy: 0.8911\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 0.2551 - accuracy: 0.9255 - val_loss: 0.2384 - val_accuracy: 0.9109\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.2143 - accuracy: 0.9277 - val_loss: 0.3107 - val_accuracy: 0.9010\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.2350 - accuracy: 0.9426 - val_loss: 0.4341 - val_accuracy: 0.8713\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.2484 - accuracy: 0.9277 - val_loss: 0.2445 - val_accuracy: 0.9208\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.2097 - accuracy: 0.9447 - val_loss: 0.2151 - val_accuracy: 0.9356\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1824 - accuracy: 0.9553 - val_loss: 0.1999 - val_accuracy: 0.9059\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1939 - accuracy: 0.9362 - val_loss: 0.2296 - val_accuracy: 0.9059\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1969 - accuracy: 0.9511 - val_loss: 0.3580 - val_accuracy: 0.9010\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.1870 - accuracy: 0.9489 - val_loss: 0.2522 - val_accuracy: 0.8911\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.2227 - accuracy: 0.9404 - val_loss: 0.2316 - val_accuracy: 0.9208\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.1790 - accuracy: 0.9468 - val_loss: 0.1811 - val_accuracy: 0.9307\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.1638 - accuracy: 0.9511 - val_loss: 0.1953 - val_accuracy: 0.9257\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1765 - accuracy: 0.9511 - val_loss: 0.1875 - val_accuracy: 0.9257\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 280us/step - loss: 0.1567 - accuracy: 0.9553 - val_loss: 0.2370 - val_accuracy: 0.8317\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 314us/step - loss: 0.1994 - accuracy: 0.9277 - val_loss: 0.2322 - val_accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.2332 - accuracy: 0.9383 - val_loss: 0.1800 - val_accuracy: 0.9257\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1716 - accuracy: 0.9468 - val_loss: 0.2203 - val_accuracy: 0.9307\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1920 - accuracy: 0.9255 - val_loss: 0.2803 - val_accuracy: 0.8960\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1795 - accuracy: 0.9404 - val_loss: 0.1759 - val_accuracy: 0.9158\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.1733 - accuracy: 0.9426 - val_loss: 0.1913 - val_accuracy: 0.9257\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1716 - accuracy: 0.9404 - val_loss: 0.2502 - val_accuracy: 0.9208\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1785 - accuracy: 0.9532 - val_loss: 0.2013 - val_accuracy: 0.9208\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.1737 - accuracy: 0.9489 - val_loss: 0.1776 - val_accuracy: 0.9505\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.1612 - accuracy: 0.9511 - val_loss: 0.1767 - val_accuracy: 0.9059\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.2087 - accuracy: 0.9426 - val_loss: 0.2283 - val_accuracy: 0.9356\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.2256 - accuracy: 0.9404 - val_loss: 0.2020 - val_accuracy: 0.9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.2247 - accuracy: 0.9319 - val_loss: 0.7964 - val_accuracy: 0.8564\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.4386 - accuracy: 0.8809 - val_loss: 0.3433 - val_accuracy: 0.8663\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.3278 - accuracy: 0.8745 - val_loss: 0.1975 - val_accuracy: 0.9208\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.1635 - accuracy: 0.9447 - val_loss: 0.1986 - val_accuracy: 0.9307\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.1778 - accuracy: 0.9532 - val_loss: 0.1799 - val_accuracy: 0.9307\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 369us/step - loss: 0.1657 - accuracy: 0.9532 - val_loss: 0.1975 - val_accuracy: 0.9307\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.1522 - accuracy: 0.9553 - val_loss: 0.1612 - val_accuracy: 0.9356\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1462 - accuracy: 0.9532 - val_loss: 0.1448 - val_accuracy: 0.9455\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1395 - accuracy: 0.9596 - val_loss: 0.1731 - val_accuracy: 0.9455\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1485 - accuracy: 0.9596 - val_loss: 0.1598 - val_accuracy: 0.9307\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1365 - accuracy: 0.9553 - val_loss: 0.1625 - val_accuracy: 0.9554\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 0.1350 - accuracy: 0.9617 - val_loss: 0.1599 - val_accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 299us/step - loss: 0.1331 - accuracy: 0.9617 - val_loss: 0.1443 - val_accuracy: 0.9257\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 541us/step - loss: 0.1295 - accuracy: 0.9638 - val_loss: 0.1432 - val_accuracy: 0.9455\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.1408 - accuracy: 0.9447 - val_loss: 0.1466 - val_accuracy: 0.9356\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 251us/step - loss: 0.1267 - accuracy: 0.9681 - val_loss: 0.1430 - val_accuracy: 0.9257\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.1294 - accuracy: 0.9617 - val_loss: 0.1436 - val_accuracy: 0.9356\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.1337 - accuracy: 0.9574 - val_loss: 0.1627 - val_accuracy: 0.9356\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.1349 - accuracy: 0.9596 - val_loss: 0.1367 - val_accuracy: 0.9554\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.1201 - accuracy: 0.9638 - val_loss: 0.1377 - val_accuracy: 0.9356\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.1297 - accuracy: 0.9574 - val_loss: 0.1342 - val_accuracy: 0.9455\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.1187 - accuracy: 0.9617 - val_loss: 0.1330 - val_accuracy: 0.9505\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1164 - accuracy: 0.9681 - val_loss: 0.1441 - val_accuracy: 0.9554\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.1267 - accuracy: 0.9702 - val_loss: 0.1287 - val_accuracy: 0.9455\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1361 - accuracy: 0.9617 - val_loss: 0.1511 - val_accuracy: 0.9307\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1324 - accuracy: 0.9574 - val_loss: 0.1541 - val_accuracy: 0.9356\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.1329 - accuracy: 0.9660 - val_loss: 0.1668 - val_accuracy: 0.9307\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.1263 - accuracy: 0.9638 - val_loss: 0.1947 - val_accuracy: 0.9307\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.1421 - accuracy: 0.9574 - val_loss: 0.1512 - val_accuracy: 0.9554\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.1301 - accuracy: 0.9617 - val_loss: 0.1317 - val_accuracy: 0.9356\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.1266 - accuracy: 0.9638 - val_loss: 0.1579 - val_accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1414 - accuracy: 0.9596 - val_loss: 0.2110 - val_accuracy: 0.8960\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.1363 - accuracy: 0.9489 - val_loss: 0.1331 - val_accuracy: 0.9554\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 0.1536 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1170 - accuracy: 0.9702 - val_loss: 0.1628 - val_accuracy: 0.9109\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1391 - accuracy: 0.9574 - val_loss: 0.1302 - val_accuracy: 0.9505\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1146 - accuracy: 0.9638 - val_loss: 0.1363 - val_accuracy: 0.9604\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1206 - accuracy: 0.9617 - val_loss: 0.1329 - val_accuracy: 0.9307\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1126 - accuracy: 0.9660 - val_loss: 0.1202 - val_accuracy: 0.9455\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.1078 - accuracy: 0.9702 - val_loss: 0.1203 - val_accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.1146 - accuracy: 0.9702 - val_loss: 0.1272 - val_accuracy: 0.9406\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.1189 - accuracy: 0.9681 - val_loss: 0.1376 - val_accuracy: 0.9307\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1114 - accuracy: 0.9702 - val_loss: 0.1191 - val_accuracy: 0.9554\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1214 - accuracy: 0.9660 - val_loss: 0.1361 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a368fe3c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 106us/step\n",
      "over-sampling test accuracy: 96.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over3 = model1_over3.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over3*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 2, 2, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 1, 2, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 1, 0, 1, 2,\n",
       "       0, 1, 1, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2,\n",
       "       2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1,\n",
       "       2, 2, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 2, 1, 2, 0, 1, 0, 0,\n",
       "       0, 2, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 1, 2, 0, 2, 0, 1,\n",
       "       0, 1, 2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 1, 2, 0,\n",
       "       0, 2, 1, 1, 1, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 0, 2, 1, 0, 0, 2, 1,\n",
       "       1, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 1, 0,\n",
       "       2, 1, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = model1_over3.predict_classes(X_test_over)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>GA12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SR4187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  test  pred\n",
       "0         NRS148     2     2\n",
       "1         NRS209     2     2\n",
       "2         NRS187     1     1\n",
       "3    CFBREBSa116     0     0\n",
       "4         NRS187     1     1\n",
       "..           ...   ...   ...\n",
       "197         GA12     0     0\n",
       "198       NRS209     2     2\n",
       "199       NRS265     1     1\n",
       "200       NRS253     1     1\n",
       "201       SR4187     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3['pred'] = pred3\n",
    "dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba3 = model1_over3.predict_proba(X_test_over)\n",
    "dat_proba3 = pd.DataFrame(proba3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.163079e-04</td>\n",
       "      <td>0.073239</td>\n",
       "      <td>9.264445e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.834474e-11</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>9.984019e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.197055e-01</td>\n",
       "      <td>0.880255</td>\n",
       "      <td>3.925587e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.983797e-01</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>5.845739e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.197055e-01</td>\n",
       "      <td>0.880255</td>\n",
       "      <td>3.925587e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>9.921768e-01</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>2.947980e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.834474e-11</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>9.984019e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3.676001e-02</td>\n",
       "      <td>0.950768</td>\n",
       "      <td>1.247150e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>5.030434e-03</td>\n",
       "      <td>0.994785</td>\n",
       "      <td>1.842785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.965759e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2\n",
       "0    3.163079e-04  0.073239  9.264445e-01\n",
       "1    4.834474e-11  0.001598  9.984019e-01\n",
       "2    1.197055e-01  0.880255  3.925587e-05\n",
       "3    8.983797e-01  0.101562  5.845739e-05\n",
       "4    1.197055e-01  0.880255  3.925587e-05\n",
       "..            ...       ...           ...\n",
       "197  9.921768e-01  0.007823  2.947980e-11\n",
       "198  4.834474e-11  0.001598  9.984019e-01\n",
       "199  3.676001e-02  0.950768  1.247150e-02\n",
       "200  5.030434e-03  0.994785  1.842785e-04\n",
       "201  9.999971e-01  0.000003  4.965759e-16\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba3.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/3p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.1285 - accuracy: 0.9660 - val_loss: 0.1325 - val_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.1009 - accuracy: 0.9681 - val_loss: 0.1184 - val_accuracy: 0.9604\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.1045 - accuracy: 0.9596 - val_loss: 0.1087 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 0.0998 - accuracy: 0.9681 - val_loss: 0.1818 - val_accuracy: 0.9059\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.1190 - accuracy: 0.9574 - val_loss: 0.1162 - val_accuracy: 0.9604\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.1448 - accuracy: 0.9468 - val_loss: 0.1519 - val_accuracy: 0.9604\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1518 - accuracy: 0.9426 - val_loss: 0.1200 - val_accuracy: 0.9604\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1188 - accuracy: 0.9617 - val_loss: 0.1135 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1469 - val_accuracy: 0.9158\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1037 - accuracy: 0.9638 - val_loss: 0.1283 - val_accuracy: 0.9604\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1097 - accuracy: 0.9660 - val_loss: 0.2065 - val_accuracy: 0.9356\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1720 - accuracy: 0.9404 - val_loss: 0.1437 - val_accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1373 - accuracy: 0.9511 - val_loss: 0.1795 - val_accuracy: 0.9356\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.1041 - accuracy: 0.9532 - val_loss: 0.1179 - val_accuracy: 0.9604\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 0.0981 - accuracy: 0.9702 - val_loss: 0.1196 - val_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.1012 - accuracy: 0.9681 - val_loss: 0.1190 - val_accuracy: 0.9604\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.0968 - accuracy: 0.9702 - val_loss: 0.1067 - val_accuracy: 0.9554\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1046 - accuracy: 0.9617 - val_loss: 0.1334 - val_accuracy: 0.9653\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1035 - accuracy: 0.9638 - val_loss: 0.1179 - val_accuracy: 0.9455\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.0960 - accuracy: 0.9702 - val_loss: 0.1118 - val_accuracy: 0.9604\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1037 - accuracy: 0.9596 - val_loss: 0.1118 - val_accuracy: 0.9604\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0971 - accuracy: 0.9702 - val_loss: 0.1057 - val_accuracy: 0.9604\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.1111 - val_accuracy: 0.9604\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 372us/step - loss: 0.1062 - accuracy: 0.9681 - val_loss: 0.1154 - val_accuracy: 0.9554\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.1040 - accuracy: 0.9702 - val_loss: 0.1231 - val_accuracy: 0.9455\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.1055 - accuracy: 0.9617 - val_loss: 0.1964 - val_accuracy: 0.9356\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.1899 - accuracy: 0.9277 - val_loss: 0.1239 - val_accuracy: 0.9554\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 601us/step - loss: 0.2203 - accuracy: 0.9298 - val_loss: 0.2475 - val_accuracy: 0.9208\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.1967 - accuracy: 0.9362 - val_loss: 0.2056 - val_accuracy: 0.9307\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 301us/step - loss: 0.1616 - accuracy: 0.9426 - val_loss: 0.1356 - val_accuracy: 0.9505\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.1087 - accuracy: 0.9681 - val_loss: 0.1095 - val_accuracy: 0.9356\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0989 - accuracy: 0.9617 - val_loss: 0.1152 - val_accuracy: 0.9604\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 397us/step - loss: 0.0967 - accuracy: 0.9681 - val_loss: 0.0989 - val_accuracy: 0.9604\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 437us/step - loss: 0.1108 - accuracy: 0.9660 - val_loss: 0.1341 - val_accuracy: 0.9356\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.1156 - accuracy: 0.9596 - val_loss: 0.1044 - val_accuracy: 0.9604\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0999 - accuracy: 0.9660 - val_loss: 0.1063 - val_accuracy: 0.9604\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.0995 - accuracy: 0.9681 - val_loss: 0.1322 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0992 - accuracy: 0.9468 - val_loss: 0.1046 - val_accuracy: 0.9604\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1141 - accuracy: 0.9596 - val_loss: 0.1224 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 0.1075 - val_accuracy: 0.9604\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.1047 - accuracy: 0.9617 - val_loss: 0.1117 - val_accuracy: 0.9554\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0919 - accuracy: 0.9702 - val_loss: 0.1109 - val_accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1215 - accuracy: 0.9532 - val_loss: 0.1415 - val_accuracy: 0.9158\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1084 - accuracy: 0.9660 - val_loss: 0.1282 - val_accuracy: 0.9307\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.1160 - val_accuracy: 0.9406\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1009 - accuracy: 0.9511 - val_loss: 0.1197 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0969 - accuracy: 0.9681 - val_loss: 0.1047 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0952 - accuracy: 0.9660 - val_loss: 0.1157 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.0953 - accuracy: 0.9702 - val_loss: 0.1039 - val_accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.0905 - accuracy: 0.9681 - val_loss: 0.1059 - val_accuracy: 0.9505\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 447us/step - loss: 0.0875 - accuracy: 0.9660 - val_loss: 0.1063 - val_accuracy: 0.9554\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 0.0912 - accuracy: 0.9702 - val_loss: 0.1179 - val_accuracy: 0.9406\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.0956 - accuracy: 0.9702 - val_loss: 0.1016 - val_accuracy: 0.9604\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0955 - accuracy: 0.9553 - val_loss: 0.1167 - val_accuracy: 0.9505\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.1058 - accuracy: 0.9723 - val_loss: 0.1440 - val_accuracy: 0.9109\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.1161 - val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.1056 - accuracy: 0.9574 - val_loss: 0.1197 - val_accuracy: 0.9604\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.0975 - accuracy: 0.9511 - val_loss: 0.1192 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0977 - accuracy: 0.9702 - val_loss: 0.1028 - val_accuracy: 0.9554\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 0.0994 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.0872 - accuracy: 0.9638 - val_loss: 0.1264 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.1011 - accuracy: 0.9638 - val_loss: 0.1021 - val_accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 0.0873 - accuracy: 0.9723 - val_loss: 0.0989 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0784 - accuracy: 0.9702 - val_loss: 0.1079 - val_accuracy: 0.9604\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.1046 - accuracy: 0.9681 - val_loss: 0.1208 - val_accuracy: 0.9604\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0849 - accuracy: 0.9681 - val_loss: 0.1003 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 0.0889 - accuracy: 0.9617 - val_loss: 0.1262 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 0.0948 - accuracy: 0.9702 - val_loss: 0.1021 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.0861 - accuracy: 0.9681 - val_loss: 0.0976 - val_accuracy: 0.9604\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 0.0925 - accuracy: 0.9553 - val_loss: 0.1056 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 0.0946 - accuracy: 0.9702 - val_loss: 0.1233 - val_accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.1101 - accuracy: 0.9681 - val_loss: 0.1401 - val_accuracy: 0.9208\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 0.1164 - accuracy: 0.9532 - val_loss: 0.1011 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.1176 - accuracy: 0.9574 - val_loss: 0.1277 - val_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.1094 - accuracy: 0.9532 - val_loss: 0.1096 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.0899 - accuracy: 0.9638 - val_loss: 0.1480 - val_accuracy: 0.9653\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.0979 - accuracy: 0.9553 - val_loss: 0.1368 - val_accuracy: 0.9604\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.1306 - val_accuracy: 0.9455\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.1060 - accuracy: 0.9638 - val_loss: 0.3136 - val_accuracy: 0.9208\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.1001 - val_accuracy: 0.9554\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.1461 - accuracy: 0.9447 - val_loss: 0.1221 - val_accuracy: 0.9554\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.2017 - accuracy: 0.9489 - val_loss: 0.1741 - val_accuracy: 0.9406\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 0.3562 - accuracy: 0.9447 - val_loss: 0.5722 - val_accuracy: 0.8663\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.1744 - accuracy: 0.9511 - val_loss: 0.1844 - val_accuracy: 0.9505\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.1143 - accuracy: 0.9574 - val_loss: 0.1004 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.0857 - accuracy: 0.9702 - val_loss: 0.0925 - val_accuracy: 0.9604\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.0871 - accuracy: 0.9681 - val_loss: 0.0978 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0787 - accuracy: 0.9702 - val_loss: 0.1126 - val_accuracy: 0.9604\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 0.0948 - val_accuracy: 0.9604\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 0.0915 - accuracy: 0.9553 - val_loss: 0.1109 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.0836 - accuracy: 0.9681 - val_loss: 0.0950 - val_accuracy: 0.9604\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 450us/step - loss: 0.0825 - accuracy: 0.9723 - val_loss: 0.1025 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.1661 - val_accuracy: 0.9208\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.1375 - accuracy: 0.9532 - val_loss: 0.1097 - val_accuracy: 0.9554\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.0785 - accuracy: 0.9702 - val_loss: 0.1003 - val_accuracy: 0.9604\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 0.0808 - accuracy: 0.9681 - val_loss: 0.0987 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0907 - accuracy: 0.9723 - val_loss: 0.1020 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0842 - accuracy: 0.9702 - val_loss: 0.1049 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.0907 - accuracy: 0.9617 - val_loss: 0.1154 - val_accuracy: 0.9604\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.0959 - accuracy: 0.9702 - val_loss: 0.1160 - val_accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "hist1_over3 = model1_over3.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.19%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over3.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba3 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851725</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>5.980786e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS109</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>9.820048e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>GA50245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812055</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>1.161034e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>9.984396e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.974061</td>\n",
       "      <td>7.323514e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>3.675362e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.168620e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage   strain  phenotype  prediction         0         1  \\\n",
       "0      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "1      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "2      p002ykpresabs_qual   NRS222          0           0  0.851725  0.148269   \n",
       "3      p002ykpresabs_qual   NRS109          2           2  0.004477  0.013518   \n",
       "4      p002ykpresabs_qual  GA50245          0           0  0.812055  0.187945   \n",
       "...                   ...      ...        ...         ...       ...       ...   \n",
       "4279  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4280  pyopresabsSTCC_qual   NRS255          2           2  0.000633  0.000928   \n",
       "4281  pyopresabsSTCC_qual   NRS266          1           1  0.025932  0.974061   \n",
       "4282  pyopresabsSTCC_qual   NRS001          1           1  0.000597  0.999403   \n",
       "4283  pyopresabsSTCC_qual   NRS112          1           1  0.000537  0.999452   \n",
       "\n",
       "                 2  \n",
       "0     9.820048e-01  \n",
       "1     9.820048e-01  \n",
       "2     5.980786e-06  \n",
       "3     9.820048e-01  \n",
       "4     1.161034e-07  \n",
       "...            ...  \n",
       "4279  9.984396e-01  \n",
       "4280  9.984396e-01  \n",
       "4281  7.323514e-06  \n",
       "4282  3.675362e-10  \n",
       "4283  1.168620e-05  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.19705480e-01, 8.80255200e-01, 3.92558720e-05],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [1.19705480e-01, 8.80255200e-01, 3.92558720e-05],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [6.69607900e-02, 9.32511300e-01, 5.27940400e-04],\n",
       "       [9.99560060e-01, 4.39986350e-04, 3.78957450e-10],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [2.25106100e-01, 7.74045470e-01, 8.48337130e-04],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [9.96455200e-01, 3.54470520e-03, 1.26692410e-07],\n",
       "       [1.32752250e-02, 9.85978900e-01, 7.45893340e-04],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.91953570e-01, 8.08046460e-01, 5.03459330e-10],\n",
       "       [9.79376900e-01, 2.06231120e-02, 1.88919550e-08],\n",
       "       [9.98031560e-01, 1.96848550e-03, 3.66678940e-11],\n",
       "       [9.53635750e-01, 4.51246650e-02, 1.23959060e-03],\n",
       "       [9.96455200e-01, 3.54470520e-03, 1.26692410e-07],\n",
       "       [1.02828410e-01, 8.97008360e-01, 1.63190200e-04],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [1.17576234e-01, 8.82207930e-01, 2.15834730e-04],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [9.89779950e-01, 1.01228930e-02, 9.70621000e-05],\n",
       "       [1.17576234e-01, 8.82207930e-01, 2.15834730e-04],\n",
       "       [2.25106100e-01, 7.74045470e-01, 8.48337130e-04],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.89739240e-01, 1.01446660e-02, 1.16136530e-04],\n",
       "       [5.03043360e-03, 9.94785250e-01, 1.84278510e-04],\n",
       "       [9.99999900e-01, 7.00359900e-08, 2.93738400e-13],\n",
       "       [9.92176830e-01, 7.82320650e-03, 2.94798000e-11],\n",
       "       [9.86268600e-02, 9.01208100e-01, 1.64977190e-04],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [1.32752250e-02, 9.85978900e-01, 7.45893340e-04],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.88942740e-01, 1.09580710e-02, 9.91936800e-05],\n",
       "       [1.43023550e-02, 9.85682550e-01, 1.50444240e-05],\n",
       "       [1.17576234e-01, 8.82207930e-01, 2.15834730e-04],\n",
       "       [9.99682550e-01, 3.15691170e-04, 1.82310320e-06],\n",
       "       [2.02363640e-03, 8.89159500e-01, 1.08816820e-01],\n",
       "       [9.99845600e-01, 1.54409470e-04, 8.93265550e-09],\n",
       "       [9.12808700e-01, 8.71094900e-02, 8.18292540e-05],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [4.30763250e-06, 9.99995700e-01, 7.38111900e-12],\n",
       "       [9.98914700e-01, 1.08527220e-03, 8.00032600e-19],\n",
       "       [2.02363640e-03, 8.89159500e-01, 1.08816820e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.32626620e-01, 8.67373350e-01, 1.38160010e-12],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.23479240e-01, 8.76093030e-01, 4.27750640e-04],\n",
       "       [8.66657800e-01, 1.33157000e-01, 1.85093380e-04],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.88301100e-01, 1.16988960e-02, 1.14702650e-08],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [7.00353900e-01, 2.99646080e-01, 4.34443700e-15],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [5.03043360e-03, 9.94785250e-01, 1.84278510e-04],\n",
       "       [1.71004500e-01, 8.28695100e-01, 3.00460230e-04],\n",
       "       [9.97390570e-01, 2.60948480e-03, 1.96783870e-18],\n",
       "       [8.70096400e-03, 9.91299000e-01, 3.15324070e-14],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.27641960e-01, 8.72235400e-01, 1.22623300e-04],\n",
       "       [6.69607900e-02, 9.32511300e-01, 5.27940400e-04],\n",
       "       [2.47531800e-02, 9.75246700e-01, 1.01094464e-07],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.32626620e-01, 8.67373350e-01, 1.38160010e-12],\n",
       "       [9.87525800e-01, 1.24152520e-02, 5.90055970e-05],\n",
       "       [5.03043360e-03, 9.94785250e-01, 1.84278510e-04],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [1.43023550e-02, 9.85682550e-01, 1.50444240e-05],\n",
       "       [9.97660640e-01, 1.39687770e-03, 9.42528800e-04],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.98031560e-01, 1.96848550e-03, 3.66678940e-11],\n",
       "       [1.27641960e-01, 8.72235400e-01, 1.22623300e-04],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [9.89843500e-01, 1.01564750e-02, 4.09065280e-11],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.30763250e-06, 9.99995700e-01, 7.38111900e-12],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [5.21265100e-01, 4.76009900e-01, 2.72501680e-03],\n",
       "       [1.98568240e-02, 9.80143130e-01, 5.21067240e-10],\n",
       "       [9.89779950e-01, 1.01228930e-02, 9.70621000e-05],\n",
       "       [9.87525800e-01, 1.24152520e-02, 5.90055970e-05],\n",
       "       [9.82213740e-01, 1.77863390e-02, 2.56931130e-11],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.91953570e-01, 8.08046460e-01, 5.03459330e-10],\n",
       "       [9.98986400e-01, 1.01358700e-03, 8.31160100e-10],\n",
       "       [9.98660800e-01, 1.33809260e-03, 1.12852790e-06],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [5.03043360e-03, 9.94785250e-01, 1.84278510e-04],\n",
       "       [1.17576234e-01, 8.82207930e-01, 2.15834730e-04],\n",
       "       [9.92736600e-01, 7.26318500e-03, 2.35496220e-07],\n",
       "       [9.97879000e-01, 2.12100150e-03, 2.32871200e-08],\n",
       "       [9.97821450e-01, 2.13494730e-03, 4.36660200e-05],\n",
       "       [9.86268600e-02, 9.01208100e-01, 1.64977190e-04],\n",
       "       [6.93582240e-01, 3.06293600e-01, 1.24155900e-04],\n",
       "       [4.30763250e-06, 9.99995700e-01, 7.38111900e-12],\n",
       "       [9.86268600e-02, 9.01208100e-01, 1.64977190e-04],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.17576234e-01, 8.82207930e-01, 2.15834730e-04],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [8.83218900e-01, 1.16708740e-01, 7.24153650e-05],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.97639540e-01, 2.36052300e-03, 2.61216320e-18],\n",
       "       [2.47531800e-02, 9.75246700e-01, 1.01094464e-07],\n",
       "       [7.44042200e-01, 2.55957780e-01, 1.71756820e-15],\n",
       "       [3.48732860e-01, 6.46146800e-01, 5.12042600e-03],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.92176830e-01, 7.82320650e-03, 2.94798000e-11],\n",
       "       [9.89331500e-01, 1.06685530e-02, 1.98913910e-10],\n",
       "       [1.32626620e-01, 8.67373350e-01, 1.38160010e-12],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.98031560e-01, 1.96848550e-03, 3.66678940e-11],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [9.86268600e-02, 9.01208100e-01, 1.64977190e-04],\n",
       "       [1.00000000e+00, 2.11246580e-08, 2.56018910e-14],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [1.23479240e-01, 8.76093030e-01, 4.27750640e-04],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.67834060e-01, 3.21658660e-02, 5.44039050e-11],\n",
       "       [9.87190840e-01, 1.27472800e-02, 6.18666100e-05],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [2.47531800e-02, 9.75246700e-01, 1.01094464e-07],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [1.91953570e-01, 8.08046460e-01, 5.03459330e-10],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.96455200e-01, 3.54470520e-03, 1.26692410e-07],\n",
       "       [8.70096400e-03, 9.91299000e-01, 3.15324070e-14],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [7.83219000e-01, 2.16362310e-01, 4.18760760e-04],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [2.25106100e-01, 7.74045470e-01, 8.48337130e-04],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [9.82769700e-01, 1.70825700e-02, 1.47704910e-04],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.96013840e-01, 7.99287900e-01, 4.69827140e-03],\n",
       "       [2.02363640e-03, 8.89159500e-01, 1.08816820e-01],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [9.61932000e-01, 3.42949630e-02, 3.77305570e-03],\n",
       "       [6.38897360e-01, 3.56139630e-01, 4.96294160e-03],\n",
       "       [8.98379740e-01, 1.01561815e-01, 5.84573940e-05],\n",
       "       [4.96984130e-03, 9.92043100e-01, 2.98716620e-03],\n",
       "       [1.32752250e-02, 9.85978900e-01, 7.45893340e-04],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [6.88714400e-04, 9.99311300e-01, 6.08895400e-11],\n",
       "       [3.16307940e-04, 7.32391300e-02, 9.26444530e-01],\n",
       "       [9.99560060e-01, 4.39986350e-04, 3.78957450e-10],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [1.75080610e-03, 2.00983560e-03, 9.96239300e-01],\n",
       "       [9.98914700e-01, 1.08527220e-03, 8.00032600e-19],\n",
       "       [9.99927400e-01, 7.25516400e-05, 1.13327280e-09],\n",
       "       [1.32626620e-01, 8.67373350e-01, 1.38160010e-12],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [9.99560060e-01, 4.39986350e-04, 3.78957450e-10],\n",
       "       [1.98568240e-02, 9.80143130e-01, 5.21067240e-10],\n",
       "       [2.02363640e-03, 8.89159500e-01, 1.08816820e-01],\n",
       "       [9.92176830e-01, 7.82320650e-03, 2.94798000e-11],\n",
       "       [4.83447400e-11, 1.59805550e-03, 9.98401940e-01],\n",
       "       [3.67600060e-02, 9.50768400e-01, 1.24715045e-02],\n",
       "       [5.03043360e-03, 9.94785250e-01, 1.84278510e-04],\n",
       "       [9.99997140e-01, 2.87463350e-06, 4.96575900e-16]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob3 = df_proba3[df_proba3['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob3 = y_prob3.to_numpy()\n",
    "y_prob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936111924039931"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo3 = rocauc_ovo(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936111924039931"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr3 = rocauc_ovr(y_test_over, y_prob3, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=456,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4 = pd.DataFrame(X_test_over[:,0])\n",
    "dat4['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test\n",
       "0    CFBRSa04     0\n",
       "1      NRS021     0\n",
       "2      NRS073     0\n",
       "3      NRS049     0\n",
       "4       CA541     1\n",
       "..        ...   ...\n",
       "197    NRS387     1\n",
       "198    SR1746     0\n",
       "199    NRS148     2\n",
       "200    NRS255     2\n",
       "201    NRS232     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],)),\n",
    "    Dense(3, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 327us/step - loss: 3.9472 - accuracy: 0.5255 - val_loss: 4.6515 - val_accuracy: 0.5297\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.7468 - accuracy: 0.6085 - val_loss: 2.3568 - val_accuracy: 0.4851\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 1.0450 - accuracy: 0.7085 - val_loss: 0.8285 - val_accuracy: 0.7673\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.5841 - accuracy: 0.7787 - val_loss: 0.4784 - val_accuracy: 0.7871\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.5503 - accuracy: 0.7872 - val_loss: 0.5056 - val_accuracy: 0.8614\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.4720 - accuracy: 0.8191 - val_loss: 0.5152 - val_accuracy: 0.7970\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.4242 - accuracy: 0.8404 - val_loss: 0.3633 - val_accuracy: 0.8168\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.4103 - accuracy: 0.8149 - val_loss: 0.4327 - val_accuracy: 0.7426\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.3730 - accuracy: 0.8489 - val_loss: 0.3909 - val_accuracy: 0.8762\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.3510 - accuracy: 0.8851 - val_loss: 0.3040 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.3237 - accuracy: 0.8894 - val_loss: 0.3220 - val_accuracy: 0.8911\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.4050 - accuracy: 0.8681 - val_loss: 0.3855 - val_accuracy: 0.8762\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 364us/step - loss: 0.3403 - accuracy: 0.8766 - val_loss: 0.2722 - val_accuracy: 0.9158\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.3058 - accuracy: 0.9064 - val_loss: 0.3373 - val_accuracy: 0.8713\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.3751 - accuracy: 0.8638 - val_loss: 0.3022 - val_accuracy: 0.8861\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.3036 - accuracy: 0.8915 - val_loss: 0.2524 - val_accuracy: 0.9158\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 0.2725 - accuracy: 0.9234 - val_loss: 0.2497 - val_accuracy: 0.8960\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.2720 - accuracy: 0.9149 - val_loss: 0.2594 - val_accuracy: 0.8960\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 0.3206 - accuracy: 0.9128 - val_loss: 0.2374 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.2675 - accuracy: 0.9362 - val_loss: 0.2650 - val_accuracy: 0.9010\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.2420 - accuracy: 0.9362 - val_loss: 0.2804 - val_accuracy: 0.8812\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 400us/step - loss: 0.2750 - accuracy: 0.9043 - val_loss: 0.2790 - val_accuracy: 0.8564\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 281us/step - loss: 0.2560 - accuracy: 0.9000 - val_loss: 0.2319 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 224us/step - loss: 0.2491 - accuracy: 0.9404 - val_loss: 0.2357 - val_accuracy: 0.8762\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 0.2642 - accuracy: 0.9213 - val_loss: 0.2067 - val_accuracy: 0.9307\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.2483 - accuracy: 0.9106 - val_loss: 0.1987 - val_accuracy: 0.9356\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.2196 - accuracy: 0.9319 - val_loss: 0.1986 - val_accuracy: 0.9356\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 304us/step - loss: 0.2475 - accuracy: 0.9277 - val_loss: 0.2867 - val_accuracy: 0.8911\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.2333 - accuracy: 0.9213 - val_loss: 0.2074 - val_accuracy: 0.9653\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 0.2297 - accuracy: 0.9404 - val_loss: 0.1933 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.2218 - accuracy: 0.9362 - val_loss: 0.1876 - val_accuracy: 0.9356\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.2120 - accuracy: 0.9340 - val_loss: 0.1905 - val_accuracy: 0.9406\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.2102 - accuracy: 0.9277 - val_loss: 0.1849 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.2163 - accuracy: 0.9383 - val_loss: 0.2459 - val_accuracy: 0.8416\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.2683 - accuracy: 0.9000 - val_loss: 0.2426 - val_accuracy: 0.8713\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 293us/step - loss: 0.2266 - accuracy: 0.9340 - val_loss: 0.1994 - val_accuracy: 0.9257\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 0.2024 - accuracy: 0.9468 - val_loss: 0.1908 - val_accuracy: 0.9109\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 0.1976 - accuracy: 0.9383 - val_loss: 0.1635 - val_accuracy: 0.9455\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1914 - accuracy: 0.9319 - val_loss: 0.1646 - val_accuracy: 0.9505\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1856 - accuracy: 0.9426 - val_loss: 0.1659 - val_accuracy: 0.9505\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1815 - accuracy: 0.9447 - val_loss: 0.1593 - val_accuracy: 0.9505\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1825 - accuracy: 0.9362 - val_loss: 0.1595 - val_accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1756 - accuracy: 0.9426 - val_loss: 0.1544 - val_accuracy: 0.9505\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 105us/step - loss: 0.1748 - accuracy: 0.9426 - val_loss: 0.1534 - val_accuracy: 0.9356\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1819 - accuracy: 0.9404 - val_loss: 0.1559 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.1976 - accuracy: 0.9468 - val_loss: 0.1714 - val_accuracy: 0.9307\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 0.1729 - accuracy: 0.9447 - val_loss: 0.1470 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 315us/step - loss: 0.1675 - accuracy: 0.9447 - val_loss: 0.1519 - val_accuracy: 0.9455\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 0.1779 - accuracy: 0.9468 - val_loss: 0.1556 - val_accuracy: 0.9356\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1636 - accuracy: 0.9468 - val_loss: 0.1509 - val_accuracy: 0.9604\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1636 - accuracy: 0.9532 - val_loss: 0.1555 - val_accuracy: 0.9257\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 98us/step - loss: 0.1611 - accuracy: 0.9489 - val_loss: 0.1402 - val_accuracy: 0.9703\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1598 - accuracy: 0.9489 - val_loss: 0.1357 - val_accuracy: 0.9505\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.1522 - accuracy: 0.9468 - val_loss: 0.1462 - val_accuracy: 0.9356\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.1528 - accuracy: 0.9511 - val_loss: 0.1328 - val_accuracy: 0.9554\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.1450 - accuracy: 0.9511 - val_loss: 0.1288 - val_accuracy: 0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1557 - accuracy: 0.9532 - val_loss: 0.1397 - val_accuracy: 0.9554\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1885 - accuracy: 0.9404 - val_loss: 0.1294 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.1886 - accuracy: 0.9213 - val_loss: 0.1371 - val_accuracy: 0.9307\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 306us/step - loss: 0.1700 - accuracy: 0.9404 - val_loss: 0.1525 - val_accuracy: 0.9208\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 293us/step - loss: 0.1967 - accuracy: 0.9234 - val_loss: 0.1940 - val_accuracy: 0.8861\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.1818 - accuracy: 0.9362 - val_loss: 0.1746 - val_accuracy: 0.9059\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1629 - accuracy: 0.9426 - val_loss: 0.1394 - val_accuracy: 0.9554\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1454 - accuracy: 0.9489 - val_loss: 0.1229 - val_accuracy: 0.9752\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1377 - accuracy: 0.9574 - val_loss: 0.1178 - val_accuracy: 0.9653\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1369 - accuracy: 0.9660 - val_loss: 0.1236 - val_accuracy: 0.9604\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1419 - accuracy: 0.9596 - val_loss: 0.1224 - val_accuracy: 0.9505\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1413 - accuracy: 0.9574 - val_loss: 0.1165 - val_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.1175 - val_accuracy: 0.9752\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.1285 - accuracy: 0.9660 - val_loss: 0.1109 - val_accuracy: 0.9604\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.1330 - accuracy: 0.9617 - val_loss: 0.1243 - val_accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 0.1215 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.1290 - accuracy: 0.9660 - val_loss: 0.1213 - val_accuracy: 0.9505\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 0.1456 - accuracy: 0.9404 - val_loss: 0.1282 - val_accuracy: 0.9307\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 0.1432 - accuracy: 0.9596 - val_loss: 0.1157 - val_accuracy: 0.9455\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.1292 - accuracy: 0.9574 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 160us/step - loss: 0.1205 - accuracy: 0.9660 - val_loss: 0.1075 - val_accuracy: 0.9653\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1295 - accuracy: 0.9511 - val_loss: 0.1159 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 106us/step - loss: 0.1342 - accuracy: 0.9596 - val_loss: 0.1172 - val_accuracy: 0.9604\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1303 - accuracy: 0.9574 - val_loss: 0.1043 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 0.1215 - accuracy: 0.9638 - val_loss: 0.1027 - val_accuracy: 0.9752\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 0.1141 - accuracy: 0.9681 - val_loss: 0.1040 - val_accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.1208 - accuracy: 0.9681 - val_loss: 0.1097 - val_accuracy: 0.9752\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1141 - accuracy: 0.9681 - val_loss: 0.1064 - val_accuracy: 0.9604\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1211 - accuracy: 0.9681 - val_loss: 0.1037 - val_accuracy: 0.9653\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 0.1207 - accuracy: 0.9638 - val_loss: 0.1003 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1187 - accuracy: 0.9574 - val_loss: 0.1078 - val_accuracy: 0.9703\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.1300 - accuracy: 0.9574 - val_loss: 0.1056 - val_accuracy: 0.9653\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1283 - accuracy: 0.9596 - val_loss: 0.1012 - val_accuracy: 0.9653\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 0.1316 - accuracy: 0.9596 - val_loss: 0.1018 - val_accuracy: 0.9604\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 0.1276 - accuracy: 0.9617 - val_loss: 0.1087 - val_accuracy: 0.9554\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.1380 - accuracy: 0.9383 - val_loss: 0.0920 - val_accuracy: 0.9703\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 0.1114 - accuracy: 0.9681 - val_loss: 0.1145 - val_accuracy: 0.9505\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 102us/step - loss: 0.1258 - accuracy: 0.9617 - val_loss: 0.1056 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.1186 - accuracy: 0.9617 - val_loss: 0.1150 - val_accuracy: 0.9505\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1133 - accuracy: 0.9553 - val_loss: 0.1184 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 0.1311 - accuracy: 0.9617 - val_loss: 0.1896 - val_accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1216 - accuracy: 0.9596 - val_loss: 0.1160 - val_accuracy: 0.9604\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 101us/step - loss: 0.1396 - accuracy: 0.9404 - val_loss: 0.0980 - val_accuracy: 0.9703\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 99us/step - loss: 0.1276 - accuracy: 0.9447 - val_loss: 0.1338 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a36d55cf8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 115us/step\n",
      "over-sampling test accuracy: 96.53%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over4 = model1_over4.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over4*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 0, 2, 1, 2, 0,\n",
       "       0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 0,\n",
       "       2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 2,\n",
       "       2, 0, 2, 0, 0, 2, 1, 0, 2, 2, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 0, 0,\n",
       "       0, 1, 2, 1, 1, 2, 0, 0, 2, 0, 0, 2, 1, 2, 1, 2, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 2,\n",
       "       1, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 2, 1,\n",
       "       2, 2, 1, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = model1_over4.predict_classes(X_test_over)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CFBRSa04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS387</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SR1746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  test  pred\n",
       "0    CFBRSa04     0     0\n",
       "1      NRS021     0     0\n",
       "2      NRS073     0     0\n",
       "3      NRS049     0     0\n",
       "4       CA541     1     0\n",
       "..        ...   ...   ...\n",
       "197    NRS387     1     1\n",
       "198    SR1746     0     0\n",
       "199    NRS148     2     2\n",
       "200    NRS255     2     2\n",
       "201    NRS232     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat4['pred'] = pred4\n",
    "dat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba4 = model1_over4.predict_proba(X_test_over)\n",
    "dat_proba4 = pd.DataFrame(proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948561</td>\n",
       "      <td>0.051417</td>\n",
       "      <td>2.209942e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>5.170221e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>5.170221e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.894868</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>2.778030e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894868</td>\n",
       "      <td>0.105105</td>\n",
       "      <td>2.778030e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.241478</td>\n",
       "      <td>0.758325</td>\n",
       "      <td>1.975381e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.976457</td>\n",
       "      <td>0.023543</td>\n",
       "      <td>5.295739e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.160147</td>\n",
       "      <td>8.354138e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>9.969168e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.090466</td>\n",
       "      <td>0.909336</td>\n",
       "      <td>1.978898e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1             2\n",
       "0    0.948561  0.051417  2.209942e-05\n",
       "1    0.996933  0.003068  5.170221e-09\n",
       "2    0.996933  0.003068  5.170221e-09\n",
       "3    0.894868  0.105105  2.778030e-05\n",
       "4    0.894868  0.105105  2.778030e-05\n",
       "..        ...       ...           ...\n",
       "197  0.241478  0.758325  1.975381e-04\n",
       "198  0.976457  0.023543  5.295739e-08\n",
       "199  0.004439  0.160147  8.354138e-01\n",
       "200  0.002211  0.000872  9.969168e-01\n",
       "201  0.090466  0.909336  1.978898e-04\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba4.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/4p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 0.1073 - accuracy: 0.9681 - val_loss: 0.0934 - val_accuracy: 0.9653\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.1034 - accuracy: 0.9681 - val_loss: 0.0927 - val_accuracy: 0.9703\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.1026 - accuracy: 0.9638 - val_loss: 0.0936 - val_accuracy: 0.9703\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 0.1047 - accuracy: 0.9638 - val_loss: 0.0876 - val_accuracy: 0.9653\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.1071 - accuracy: 0.9681 - val_loss: 0.0862 - val_accuracy: 0.9653\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 0.1035 - accuracy: 0.9596 - val_loss: 0.0918 - val_accuracy: 0.9703\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1034 - accuracy: 0.9681 - val_loss: 0.0873 - val_accuracy: 0.9703\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1006 - accuracy: 0.9681 - val_loss: 0.0860 - val_accuracy: 0.9653\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.1013 - accuracy: 0.9617 - val_loss: 0.0981 - val_accuracy: 0.9752\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 0.1007 - accuracy: 0.9660 - val_loss: 0.0865 - val_accuracy: 0.9703\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1164 - accuracy: 0.9681 - val_loss: 0.0874 - val_accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.0993 - accuracy: 0.9681 - val_loss: 0.0852 - val_accuracy: 0.9703\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.0865 - val_accuracy: 0.9703\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0972 - accuracy: 0.9681 - val_loss: 0.0862 - val_accuracy: 0.9703\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.0985 - accuracy: 0.9681 - val_loss: 0.0860 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0909 - accuracy: 0.9638 - val_loss: 0.1039 - val_accuracy: 0.9752\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.1036 - accuracy: 0.9660 - val_loss: 0.0849 - val_accuracy: 0.9703\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.0945 - accuracy: 0.9681 - val_loss: 0.0838 - val_accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0971 - accuracy: 0.9660 - val_loss: 0.0848 - val_accuracy: 0.9703\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.0961 - accuracy: 0.9681 - val_loss: 0.0879 - val_accuracy: 0.9554\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0985 - accuracy: 0.9660 - val_loss: 0.0867 - val_accuracy: 0.9703\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0945 - accuracy: 0.9660 - val_loss: 0.0873 - val_accuracy: 0.9703\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 0.0979 - accuracy: 0.9681 - val_loss: 0.0876 - val_accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0952 - accuracy: 0.9660 - val_loss: 0.0877 - val_accuracy: 0.9703\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1006 - accuracy: 0.9574 - val_loss: 0.1031 - val_accuracy: 0.9257\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1058 - accuracy: 0.9702 - val_loss: 0.0866 - val_accuracy: 0.9752\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 0.1138 - accuracy: 0.9638 - val_loss: 0.0952 - val_accuracy: 0.9752\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.1067 - accuracy: 0.9574 - val_loss: 0.0927 - val_accuracy: 0.9703\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.1031 - accuracy: 0.9660 - val_loss: 0.0812 - val_accuracy: 0.9703\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.0903 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0976 - accuracy: 0.9660 - val_loss: 0.0896 - val_accuracy: 0.9554\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.0948 - accuracy: 0.9681 - val_loss: 0.0887 - val_accuracy: 0.9703\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.0913 - accuracy: 0.9660 - val_loss: 0.0821 - val_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.0921 - accuracy: 0.9681 - val_loss: 0.0851 - val_accuracy: 0.9703\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.0784 - val_accuracy: 0.9703\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0901 - accuracy: 0.9660 - val_loss: 0.0814 - val_accuracy: 0.9703\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 0.0891 - accuracy: 0.9681 - val_loss: 0.0800 - val_accuracy: 0.9703\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 0.1002 - accuracy: 0.9681 - val_loss: 0.0825 - val_accuracy: 0.9703\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 529us/step - loss: 0.1016 - accuracy: 0.9617 - val_loss: 0.0851 - val_accuracy: 0.9752\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.0928 - accuracy: 0.9681 - val_loss: 0.0854 - val_accuracy: 0.9703\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 0.0903 - accuracy: 0.9681 - val_loss: 0.0870 - val_accuracy: 0.9703\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.0903 - accuracy: 0.9660 - val_loss: 0.0783 - val_accuracy: 0.9703\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0928 - accuracy: 0.9660 - val_loss: 0.0959 - val_accuracy: 0.9406\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 0.0929 - accuracy: 0.9660 - val_loss: 0.0806 - val_accuracy: 0.9703\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0930 - accuracy: 0.9660 - val_loss: 0.0828 - val_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 0.0872 - accuracy: 0.9681 - val_loss: 0.0785 - val_accuracy: 0.9703\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0935 - accuracy: 0.9681 - val_loss: 0.0862 - val_accuracy: 0.9604\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.0901 - accuracy: 0.9660 - val_loss: 0.0831 - val_accuracy: 0.9703\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.0923 - accuracy: 0.9660 - val_loss: 0.0938 - val_accuracy: 0.9406\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.1001 - accuracy: 0.9596 - val_loss: 0.0899 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0976 - accuracy: 0.9617 - val_loss: 0.0826 - val_accuracy: 0.9653\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.0796 - val_accuracy: 0.9653\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 0.0887 - accuracy: 0.9681 - val_loss: 0.0769 - val_accuracy: 0.9703\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.1008 - accuracy: 0.9426 - val_loss: 0.0846 - val_accuracy: 0.9703\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.1013 - accuracy: 0.9681 - val_loss: 0.0784 - val_accuracy: 0.9703\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.0882 - accuracy: 0.9681 - val_loss: 0.0857 - val_accuracy: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 0.0852 - accuracy: 0.9681 - val_loss: 0.0784 - val_accuracy: 0.9703\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0872 - accuracy: 0.9681 - val_loss: 0.0825 - val_accuracy: 0.9653\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 108us/step - loss: 0.0865 - accuracy: 0.9660 - val_loss: 0.0788 - val_accuracy: 0.9703\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.0895 - accuracy: 0.9681 - val_loss: 0.0788 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 0.0853 - accuracy: 0.9660 - val_loss: 0.0780 - val_accuracy: 0.9703\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.0861 - accuracy: 0.9660 - val_loss: 0.0801 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 383us/step - loss: 0.0998 - accuracy: 0.9660 - val_loss: 0.0918 - val_accuracy: 0.9505\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 0.0881 - accuracy: 0.9660 - val_loss: 0.0778 - val_accuracy: 0.9703\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.0876 - accuracy: 0.9660 - val_loss: 0.0805 - val_accuracy: 0.9703\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 0.0894 - accuracy: 0.9638 - val_loss: 0.1070 - val_accuracy: 0.9257\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 0.0953 - accuracy: 0.9553 - val_loss: 0.0812 - val_accuracy: 0.9653\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 0.0910 - accuracy: 0.9681 - val_loss: 0.0829 - val_accuracy: 0.9703\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0829 - accuracy: 0.9702 - val_loss: 0.0881 - val_accuracy: 0.9554\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.0929 - accuracy: 0.9681 - val_loss: 0.0811 - val_accuracy: 0.9703\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 306us/step - loss: 0.0873 - accuracy: 0.9681 - val_loss: 0.0793 - val_accuracy: 0.9703\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 0.0860 - accuracy: 0.9660 - val_loss: 0.0832 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 279us/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.0753 - val_accuracy: 0.9703\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 0.0842 - accuracy: 0.9681 - val_loss: 0.0780 - val_accuracy: 0.9703\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 462us/step - loss: 0.0866 - accuracy: 0.9617 - val_loss: 0.0903 - val_accuracy: 0.9703\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 290us/step - loss: 0.0892 - accuracy: 0.9702 - val_loss: 0.0859 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.0816 - val_accuracy: 0.9703\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 317us/step - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.0783 - val_accuracy: 0.9653\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 320us/step - loss: 0.0880 - accuracy: 0.9660 - val_loss: 0.0831 - val_accuracy: 0.9653\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.0841 - accuracy: 0.9660 - val_loss: 0.0779 - val_accuracy: 0.9653\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 0.0896 - accuracy: 0.9660 - val_loss: 0.0772 - val_accuracy: 0.9703\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 0.0871 - accuracy: 0.9660 - val_loss: 0.0788 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.0886 - accuracy: 0.9660 - val_loss: 0.0785 - val_accuracy: 0.9653\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.0806 - val_accuracy: 0.9653\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 0.0903 - accuracy: 0.9596 - val_loss: 0.0807 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.0776 - val_accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.0802 - accuracy: 0.9660 - val_loss: 0.0779 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.0887 - accuracy: 0.9702 - val_loss: 0.0863 - val_accuracy: 0.9505\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 236us/step - loss: 0.1033 - accuracy: 0.9404 - val_loss: 0.0811 - val_accuracy: 0.9703\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.0856 - accuracy: 0.9660 - val_loss: 0.0843 - val_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 0.0847 - accuracy: 0.9660 - val_loss: 0.0933 - val_accuracy: 0.9703\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 0.0881 - accuracy: 0.9660 - val_loss: 0.0822 - val_accuracy: 0.9604\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.0982 - accuracy: 0.9702 - val_loss: 0.0950 - val_accuracy: 0.9406\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 0.0909 - accuracy: 0.9596 - val_loss: 0.0772 - val_accuracy: 0.9703\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 0.0812 - accuracy: 0.9681 - val_loss: 0.0773 - val_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 0.0823 - accuracy: 0.9681 - val_loss: 0.0775 - val_accuracy: 0.9653\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 0.0807 - accuracy: 0.9660 - val_loss: 0.0766 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 0.0785 - accuracy: 0.9660 - val_loss: 0.0781 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.0798 - val_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 0.0814 - accuracy: 0.9660 - val_loss: 0.0772 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over4 = model1_over4.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 96.57%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over4.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba4 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.870196e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>9.078969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326752</td>\n",
       "      <td>0.673248</td>\n",
       "      <td>1.061032e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>CFBRSa25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabs_qual</td>\n",
       "      <td>BCH-SA-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>0.388916</td>\n",
       "      <td>7.664974e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>1.803156e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.677496</td>\n",
       "      <td>1.533154e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.999682e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBRSa28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999288</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>5.361527e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999868e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    phage     strain  phenotype  prediction         0  \\\n",
       "0      p002ykpresabs_qual     NRS110          1           1  0.000003   \n",
       "1      p002ykpresabs_qual     NRS216          1           1  0.039254   \n",
       "2      p002ykpresabs_qual     NRS386          1           1  0.326752   \n",
       "3      p002ykpresabs_qual   CFBRSa25          0           0  0.611084   \n",
       "4      p002ykpresabs_qual  BCH-SA-03          1           0  0.611084   \n",
       "...                   ...        ...        ...         ...       ...   \n",
       "4279  pyopresabsSTCC_qual     NRS236          1           1  0.000052   \n",
       "4280  pyopresabsSTCC_qual     NRS029          0           1  0.322350   \n",
       "4281  pyopresabsSTCC_qual     NRS148          2           2  0.000006   \n",
       "4282  pyopresabsSTCC_qual   CFBRSa28          0           0  0.999288   \n",
       "4283  pyopresabsSTCC_qual     NRS205          2           2  0.000007   \n",
       "\n",
       "             1             2  \n",
       "0     0.999997  5.870196e-13  \n",
       "1     0.960745  9.078969e-07  \n",
       "2     0.673248  1.061032e-07  \n",
       "3     0.388916  7.664974e-07  \n",
       "4     0.388916  7.664974e-07  \n",
       "...        ...           ...  \n",
       "4279  0.999768  1.803156e-04  \n",
       "4280  0.677496  1.533154e-04  \n",
       "4281  0.000026  9.999682e-01  \n",
       "4282  0.000176  5.361527e-04  \n",
       "4283  0.000007  9.999868e-01  \n",
       "\n",
       "[4284 rows x 7 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.48561400e-01, 5.14166360e-02, 2.20994170e-05],\n",
       "       [9.96932500e-01, 3.06751320e-03, 5.17022100e-09],\n",
       "       [9.96932500e-01, 3.06751320e-03, 5.17022100e-09],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [6.50246800e-02, 9.34975300e-01, 7.61967100e-09],\n",
       "       [1.66112720e-02, 9.82741530e-01, 6.47174300e-04],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [9.59392800e-01, 4.05865940e-02, 2.05507040e-05],\n",
       "       [9.35723300e-01, 6.42458800e-02, 3.07378650e-05],\n",
       "       [7.47551560e-01, 2.52355580e-01, 9.28358400e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [6.90548630e-03, 9.92323040e-01, 7.71391960e-04],\n",
       "       [9.93783700e-01, 6.21628530e-03, 1.29778550e-08],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.70177070e-01, 8.29822300e-01, 6.22486250e-07],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.96932500e-01, 3.06751320e-03, 5.17022100e-09],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [5.86185630e-01, 4.13814400e-01, 2.68517760e-08],\n",
       "       [7.05964270e-01, 2.93970530e-01, 6.51364700e-05],\n",
       "       [9.59392800e-01, 4.05865940e-02, 2.05507040e-05],\n",
       "       [9.99201950e-01, 7.98013640e-04, 7.16420200e-10],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.04980960e-01, 8.93492800e-01, 1.52616720e-03],\n",
       "       [4.11129000e-03, 9.95888770e-01, 1.00064060e-09],\n",
       "       [9.98486300e-01, 1.42846950e-03, 8.52749100e-05],\n",
       "       [9.48561400e-01, 5.14166360e-02, 2.20994170e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.99112300e-01, 8.46352840e-04, 4.13175080e-05],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [1.25036700e-02, 9.87467650e-01, 2.86491600e-05],\n",
       "       [1.70177070e-01, 8.29822300e-01, 6.22486250e-07],\n",
       "       [6.90548630e-03, 9.92323040e-01, 7.71391960e-04],\n",
       "       [1.66112720e-02, 9.82741530e-01, 6.47174300e-04],\n",
       "       [3.07346640e-01, 6.91391400e-01, 1.26194940e-03],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.99948740e-01, 5.00131900e-05, 1.14258600e-06],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [9.93783700e-01, 6.21628530e-03, 1.29778550e-08],\n",
       "       [6.90548630e-03, 9.92323040e-01, 7.71391960e-04],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [6.50246800e-02, 9.34975300e-01, 7.61967100e-09],\n",
       "       [1.04980960e-01, 8.93492800e-01, 1.52616720e-03],\n",
       "       [9.95297000e-01, 4.70195430e-03, 1.10575300e-06],\n",
       "       [6.90548630e-03, 9.92323040e-01, 7.71391960e-04],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [1.73367560e-01, 8.26598200e-01, 3.41881820e-05],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [5.86185630e-01, 4.13814400e-01, 2.68517760e-08],\n",
       "       [2.41477850e-01, 7.58324700e-01, 1.97538120e-04],\n",
       "       [2.19672150e-02, 9.78032700e-01, 1.40095800e-07],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [5.86185630e-01, 4.13814400e-01, 2.68517760e-08],\n",
       "       [9.99712650e-01, 2.87303500e-04, 3.29630100e-08],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.97483730e-01, 2.47525050e-03, 4.10188660e-05],\n",
       "       [9.98948630e-01, 1.02883200e-03, 2.25414590e-05],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [1.25036700e-02, 9.87467650e-01, 2.86491600e-05],\n",
       "       [6.90548630e-03, 9.92323040e-01, 7.71391960e-04],\n",
       "       [1.18050870e-01, 8.81911930e-01, 3.72359540e-05],\n",
       "       [1.70177070e-01, 8.29822300e-01, 6.22486250e-07],\n",
       "       [1.40518950e-01, 8.58774600e-01, 7.06499970e-04],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [3.07012140e-03, 9.70264600e-01, 2.66653490e-02],\n",
       "       [1.19241030e-01, 8.80399350e-01, 3.59535480e-04],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [5.86185630e-01, 4.13814400e-01, 2.68517760e-08],\n",
       "       [6.36470400e-05, 9.99926800e-01, 9.57740850e-06],\n",
       "       [9.97483730e-01, 2.47525050e-03, 4.10188660e-05],\n",
       "       [3.07346640e-01, 6.91391400e-01, 1.26194940e-03],\n",
       "       [2.19672150e-02, 9.78032700e-01, 1.40095800e-07],\n",
       "       [9.96932500e-01, 3.06751320e-03, 5.17022100e-09],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.99989400e-01, 1.06626260e-05, 8.22847500e-10],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [5.86185630e-01, 4.13814400e-01, 2.68517760e-08],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.59392800e-01, 4.05865940e-02, 2.05507040e-05],\n",
       "       [9.99952300e-01, 4.76381970e-05, 9.87314800e-17],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.66112720e-02, 9.82741530e-01, 6.47174300e-04],\n",
       "       [9.99573900e-01, 4.26105700e-04, 2.34760080e-09],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [2.41477850e-01, 7.58324700e-01, 1.97538120e-04],\n",
       "       [1.19241030e-01, 8.80399350e-01, 3.59535480e-04],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [8.93490000e-01, 1.06478760e-01, 3.12225100e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [1.73367560e-01, 8.26598200e-01, 3.41881820e-05],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.98913760e-01, 1.08036900e-03, 5.83188970e-06],\n",
       "       [8.82523100e-01, 1.17458910e-01, 1.80198460e-05],\n",
       "       [9.12615840e-01, 8.72698400e-02, 1.14354945e-04],\n",
       "       [3.07012140e-03, 9.70264600e-01, 2.66653490e-02],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [1.70177070e-01, 8.29822300e-01, 6.22486250e-07],\n",
       "       [2.83330770e-03, 9.97161750e-01, 4.99612270e-06],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [9.94096300e-01, 5.85561660e-03, 4.81129940e-05],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [8.73411950e-01, 1.26450750e-01, 1.37377750e-04],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [2.19672150e-02, 9.78032700e-01, 1.40095800e-07],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.19241030e-01, 8.80399350e-01, 3.59535480e-04],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [8.63576530e-01, 1.36379550e-01, 4.38758760e-05],\n",
       "       [2.19672150e-02, 9.78032700e-01, 1.40095800e-07],\n",
       "       [9.99683140e-01, 3.16847760e-04, 1.22301160e-08],\n",
       "       [9.99999400e-01, 6.30783630e-07, 7.60759850e-15],\n",
       "       [9.99573900e-01, 4.26105700e-04, 2.34760080e-09],\n",
       "       [9.99573900e-01, 4.26105700e-04, 2.34760080e-09],\n",
       "       [9.59392800e-01, 4.05865940e-02, 2.05507040e-05],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [4.11129000e-03, 9.95888770e-01, 1.00064060e-09],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [9.95142460e-01, 4.85628420e-03, 1.35392400e-06],\n",
       "       [6.50246800e-02, 9.34975300e-01, 7.61967100e-09],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.99840600e-01, 1.58992470e-04, 3.42295460e-07],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [1.40518950e-01, 8.58774600e-01, 7.06499970e-04],\n",
       "       [6.36470400e-05, 9.99926800e-01, 9.57740850e-06],\n",
       "       [9.91618100e-01, 8.37803500e-03, 3.88426700e-06],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [4.11129000e-03, 9.95888770e-01, 1.00064060e-09],\n",
       "       [9.99963500e-01, 3.64357040e-05, 2.43201190e-16],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [1.10754210e-01, 8.88931450e-01, 3.14251050e-04],\n",
       "       [6.42255460e-03, 9.92234950e-01, 1.34247760e-03],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [1.19241030e-01, 8.80399350e-01, 3.59535480e-04],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [3.07012140e-03, 9.70264600e-01, 2.66653490e-02],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.93783700e-01, 6.21628530e-03, 1.29778550e-08],\n",
       "       [9.40179000e-01, 5.94605060e-02, 3.60407050e-04],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [8.94867540e-01, 1.05104730e-01, 2.77802960e-05],\n",
       "       [9.71113860e-01, 2.88805680e-02, 5.54044940e-06],\n",
       "       [9.93174730e-01, 6.82230570e-03, 2.91435410e-06],\n",
       "       [2.83330770e-03, 9.97161750e-01, 4.99612270e-06],\n",
       "       [9.88651040e-01, 1.13445865e-02, 4.33343100e-06],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [8.93490000e-01, 1.06478760e-01, 3.12225100e-05],\n",
       "       [9.65662400e-01, 3.43236030e-02, 1.39076255e-05],\n",
       "       [9.99982100e-01, 1.78402370e-05, 9.12813000e-10],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.97483730e-01, 2.47525050e-03, 4.10188660e-05],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.70177070e-01, 8.29822300e-01, 6.22486250e-07],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [2.19672150e-02, 9.78032700e-01, 1.40095800e-07],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.99587100e-01, 4.12885480e-04, 2.16660450e-09],\n",
       "       [9.99611560e-01, 3.87940900e-04, 4.94494000e-07],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.99895450e-01, 1.04534410e-04, 1.10971500e-08],\n",
       "       [8.93715800e-01, 1.06084526e-01, 1.99651750e-04],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [1.48616920e-01, 8.51296600e-01, 8.64549950e-05],\n",
       "       [9.98535900e-01, 1.46412260e-03, 3.84763500e-09],\n",
       "       [9.73391830e-01, 2.65996400e-02, 8.60694100e-06],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.70485900e-10, 2.90616530e-04, 9.99709300e-01],\n",
       "       [9.99592600e-01, 3.45841370e-04, 6.16433300e-05],\n",
       "       [2.41477850e-01, 7.58324700e-01, 1.97538120e-04],\n",
       "       [9.76457200e-01, 2.35427520e-02, 5.29573930e-08],\n",
       "       [4.43882540e-03, 1.60147400e-01, 8.35413800e-01],\n",
       "       [2.21077980e-03, 8.72457050e-04, 9.96916800e-01],\n",
       "       [9.04663350e-02, 9.09335800e-01, 1.97889820e-04]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob4 = df_proba4[df_proba4['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob4 = y_prob4.to_numpy()\n",
    "y_prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993033200013007"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo4 = rocauc_ovo(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993033200013007"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr4 = rocauc_ovr(y_test_over, y_prob4, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903976509066866"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos = [ovo1, ovo2, ovo3, ovo4]\n",
    "np.mean(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003148704381461307"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903976509066866"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs = [ovr1, ovr2, ovr3, ovr4]\n",
    "np.mean(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003148704381461307"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [acc_test_over, acc_test_over2, acc_test_over3, acc_test_over4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy mean: 94.68%\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(accs)\n",
    "print('over-sampling test accuracy mean: %.2f%%' % (mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy standard deviation: 0.022242804066183213\n"
     ]
    }
   ],
   "source": [
    "std = np.std(accs)\n",
    "print('over-sampling test accuracy standard deviation:', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_train = [np.mean(hist1_over.history['accuracy']), np.mean(hist1_over2.history['accuracy']), np.mean(hist1_over3.history['accuracy']),\n",
    "             np.mean(hist1_over4.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy mean: 96.46%\n"
     ]
    }
   ],
   "source": [
    "mean_train = np.mean(accs_train)\n",
    "print('over-sampling train accuracy mean: %.2f%%' % (mean_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy standard deviation: 0.0032066016\n"
     ]
    }
   ],
   "source": [
    "std_train = np.std(accs_train)\n",
    "print('over-sampling train accuracy standard deviation:', std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=567,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.DataFrame(X_test_over[:,0])\n",
    "dat5['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0    NRS255     2\n",
       "1    NRS148     2\n",
       "2    NRS209     2\n",
       "3    NRS386     1\n",
       "4    NRS230     0\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS209     2\n",
       "199  SR4153     0\n",
       "200  NRS255     2\n",
       "201  NRS255     2\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### add regularizer and dropout\n",
    "model1_over5 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 716us/step - loss: 8.6878 - accuracy: 0.4979 - val_loss: 5.1503 - val_accuracy: 0.5693\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 6.9972 - accuracy: 0.5787 - val_loss: 4.0346 - val_accuracy: 0.6089\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 222us/step - loss: 6.4895 - accuracy: 0.5064 - val_loss: 3.1314 - val_accuracy: 0.5792\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 4.9844 - accuracy: 0.5553 - val_loss: 2.1448 - val_accuracy: 0.6485\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 4.4914 - accuracy: 0.5596 - val_loss: 1.7362 - val_accuracy: 0.6881\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 3.8642 - accuracy: 0.5957 - val_loss: 1.4299 - val_accuracy: 0.7030\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 4.1442 - accuracy: 0.5702 - val_loss: 1.1654 - val_accuracy: 0.7772\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 202us/step - loss: 3.4317 - accuracy: 0.6787 - val_loss: 0.9985 - val_accuracy: 0.7822\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 3.2747 - accuracy: 0.6957 - val_loss: 0.8973 - val_accuracy: 0.8069\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 3.7179 - accuracy: 0.6596 - val_loss: 0.9000 - val_accuracy: 0.6980\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 345us/step - loss: 3.7172 - accuracy: 0.6574 - val_loss: 0.9572 - val_accuracy: 0.7772\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 3.6989 - accuracy: 0.6383 - val_loss: 0.9438 - val_accuracy: 0.7673\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 3.1498 - accuracy: 0.6702 - val_loss: 0.8769 - val_accuracy: 0.7921\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 575us/step - loss: 3.2490 - accuracy: 0.6766 - val_loss: 0.8649 - val_accuracy: 0.8267\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 323us/step - loss: 3.2793 - accuracy: 0.6723 - val_loss: 0.9113 - val_accuracy: 0.7970\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 3.3476 - accuracy: 0.6638 - val_loss: 0.9069 - val_accuracy: 0.7822\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 280us/step - loss: 3.0400 - accuracy: 0.6957 - val_loss: 0.9317 - val_accuracy: 0.8069\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 3.2868 - accuracy: 0.6468 - val_loss: 0.8886 - val_accuracy: 0.7970\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 2.8905 - accuracy: 0.6809 - val_loss: 0.8938 - val_accuracy: 0.7871\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 3.0230 - accuracy: 0.7000 - val_loss: 0.9355 - val_accuracy: 0.8069\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 2.9290 - accuracy: 0.6957 - val_loss: 0.9272 - val_accuracy: 0.8267\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 352us/step - loss: 2.9023 - accuracy: 0.6787 - val_loss: 1.0263 - val_accuracy: 0.7772\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 2.9319 - accuracy: 0.7021 - val_loss: 0.9812 - val_accuracy: 0.8168\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 2.1695 - accuracy: 0.7447 - val_loss: 0.9992 - val_accuracy: 0.8317\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 2.8679 - accuracy: 0.6915 - val_loss: 1.1383 - val_accuracy: 0.8218\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 2.2951 - accuracy: 0.7340 - val_loss: 1.0346 - val_accuracy: 0.8366\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 2.6171 - accuracy: 0.7234 - val_loss: 0.9374 - val_accuracy: 0.8416\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 2.6502 - accuracy: 0.6894 - val_loss: 1.1381 - val_accuracy: 0.7673\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 2.5076 - accuracy: 0.6894 - val_loss: 1.1898 - val_accuracy: 0.7822\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 2.7082 - accuracy: 0.6979 - val_loss: 1.2149 - val_accuracy: 0.7178\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 177us/step - loss: 2.6052 - accuracy: 0.6809 - val_loss: 1.2122 - val_accuracy: 0.8317\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 2.3313 - accuracy: 0.7426 - val_loss: 1.2169 - val_accuracy: 0.7921\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 371us/step - loss: 2.3345 - accuracy: 0.7234 - val_loss: 0.8538 - val_accuracy: 0.8564\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 298us/step - loss: 2.2572 - accuracy: 0.7085 - val_loss: 1.1853 - val_accuracy: 0.7970\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 2.7686 - accuracy: 0.6851 - val_loss: 1.2765 - val_accuracy: 0.8168\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 2.4584 - accuracy: 0.7021 - val_loss: 0.8845 - val_accuracy: 0.8564\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 2.4234 - accuracy: 0.7106 - val_loss: 0.9742 - val_accuracy: 0.8366\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 2.3834 - accuracy: 0.7255 - val_loss: 1.0699 - val_accuracy: 0.8564\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 2.5249 - accuracy: 0.6979 - val_loss: 0.8609 - val_accuracy: 0.8713\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 2.1418 - accuracy: 0.7213 - val_loss: 1.0543 - val_accuracy: 0.8564\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.4817 - accuracy: 0.6702 - val_loss: 1.1687 - val_accuracy: 0.8564\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 2.1208 - accuracy: 0.7213 - val_loss: 0.9772 - val_accuracy: 0.8366\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 1.8662 - accuracy: 0.7298 - val_loss: 0.9493 - val_accuracy: 0.8564\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 2.0637 - accuracy: 0.7298 - val_loss: 1.0033 - val_accuracy: 0.8564\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 1.9360 - accuracy: 0.7404 - val_loss: 1.0402 - val_accuracy: 0.8564\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 1.8157 - accuracy: 0.7617 - val_loss: 0.8168 - val_accuracy: 0.8663\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 107us/step - loss: 2.1968 - accuracy: 0.6979 - val_loss: 1.1705 - val_accuracy: 0.8317\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 2.0920 - accuracy: 0.7383 - val_loss: 1.0762 - val_accuracy: 0.8564\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 1.9558 - accuracy: 0.7277 - val_loss: 1.2635 - val_accuracy: 0.8366\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.9124 - accuracy: 0.7064 - val_loss: 0.9235 - val_accuracy: 0.8861\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 2.2585 - accuracy: 0.7383 - val_loss: 1.4699 - val_accuracy: 0.8267\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.9478 - accuracy: 0.7234 - val_loss: 0.9307 - val_accuracy: 0.8119\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 2.0087 - accuracy: 0.7234 - val_loss: 1.4183 - val_accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.9546 - accuracy: 0.7319 - val_loss: 0.9600 - val_accuracy: 0.8713\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 1.8865 - accuracy: 0.7340 - val_loss: 1.4390 - val_accuracy: 0.8267\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 2.0685 - accuracy: 0.7383 - val_loss: 1.2637 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.9922 - accuracy: 0.7234 - val_loss: 1.3804 - val_accuracy: 0.8515\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.7927 - accuracy: 0.7489 - val_loss: 1.0250 - val_accuracy: 0.8762\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.9099 - accuracy: 0.7340 - val_loss: 1.0496 - val_accuracy: 0.8713\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 1.6334 - accuracy: 0.7511 - val_loss: 0.9007 - val_accuracy: 0.8713\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.6199 - accuracy: 0.7766 - val_loss: 1.0265 - val_accuracy: 0.8713\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.8629 - accuracy: 0.7128 - val_loss: 1.0597 - val_accuracy: 0.8762\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 1.7487 - accuracy: 0.7277 - val_loss: 0.9719 - val_accuracy: 0.9010\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 1.5054 - accuracy: 0.7532 - val_loss: 1.0745 - val_accuracy: 0.8762\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.8393 - accuracy: 0.6660 - val_loss: 1.1695 - val_accuracy: 0.8465\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.7758 - accuracy: 0.7255 - val_loss: 0.9752 - val_accuracy: 0.9109\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.6290 - accuracy: 0.7638 - val_loss: 0.8013 - val_accuracy: 0.9059\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 1.4077 - accuracy: 0.7596 - val_loss: 0.8163 - val_accuracy: 0.9158\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 1.8458 - accuracy: 0.7383 - val_loss: 1.0227 - val_accuracy: 0.9208\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.6139 - accuracy: 0.7511 - val_loss: 0.9711 - val_accuracy: 0.9158\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 1.7371 - accuracy: 0.7383 - val_loss: 1.0194 - val_accuracy: 0.8911\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 144us/step - loss: 1.5804 - accuracy: 0.7340 - val_loss: 1.0233 - val_accuracy: 0.9109\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.5180 - accuracy: 0.7404 - val_loss: 0.9550 - val_accuracy: 0.8960\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.6386 - accuracy: 0.7404 - val_loss: 1.1637 - val_accuracy: 0.8762\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.5226 - accuracy: 0.7745 - val_loss: 0.7164 - val_accuracy: 0.8960\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 1.4543 - accuracy: 0.7851 - val_loss: 1.0350 - val_accuracy: 0.9208\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 295us/step - loss: 1.8297 - accuracy: 0.7277 - val_loss: 0.9877 - val_accuracy: 0.9208\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 1.7792 - accuracy: 0.7404 - val_loss: 0.8850 - val_accuracy: 0.9059\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 1.3647 - accuracy: 0.7766 - val_loss: 0.9338 - val_accuracy: 0.9059\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.6028 - accuracy: 0.7447 - val_loss: 1.0915 - val_accuracy: 0.9208\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 1.6444 - accuracy: 0.7745 - val_loss: 0.9217 - val_accuracy: 0.9158\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 397us/step - loss: 1.5518 - accuracy: 0.7489 - val_loss: 0.9891 - val_accuracy: 0.9208\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 1.5653 - accuracy: 0.7362 - val_loss: 0.8680 - val_accuracy: 0.9208\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 1.5165 - accuracy: 0.7447 - val_loss: 1.1223 - val_accuracy: 0.8861\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 1.6435 - accuracy: 0.7489 - val_loss: 0.9918 - val_accuracy: 0.9208\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.4883 - accuracy: 0.7745 - val_loss: 1.0680 - val_accuracy: 0.9158\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.6263 - accuracy: 0.7532 - val_loss: 0.9205 - val_accuracy: 0.8762\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.7607 - accuracy: 0.7234 - val_loss: 0.8274 - val_accuracy: 0.9208\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.2151 - accuracy: 0.7830 - val_loss: 0.9218 - val_accuracy: 0.9208\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.4242 - accuracy: 0.7532 - val_loss: 0.6455 - val_accuracy: 0.9356\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.4644 - accuracy: 0.7383 - val_loss: 0.8545 - val_accuracy: 0.9208\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.4976 - accuracy: 0.7362 - val_loss: 1.0521 - val_accuracy: 0.9257\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.4775 - accuracy: 0.7404 - val_loss: 0.5758 - val_accuracy: 0.9406\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.8940 - accuracy: 0.7298 - val_loss: 1.1888 - val_accuracy: 0.8960\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.8285 - accuracy: 0.7383 - val_loss: 0.6837 - val_accuracy: 0.9158\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.8676 - accuracy: 0.7277 - val_loss: 0.9065 - val_accuracy: 0.9356\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 1.4362 - accuracy: 0.7723 - val_loss: 0.8978 - val_accuracy: 0.9158\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 235us/step - loss: 1.5163 - accuracy: 0.7745 - val_loss: 0.8248 - val_accuracy: 0.9208\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.6104 - accuracy: 0.7404 - val_loss: 0.8515 - val_accuracy: 0.9406\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.4824 - accuracy: 0.7617 - val_loss: 0.9360 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3780c128>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 428us/step\n",
      "over-sampling test accuracy: 88.12%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over5 = model1_over5.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over5*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 1, 0, 0, 2, 0, 1, 1, 2,\n",
       "       2, 2, 1, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 2, 2, 0,\n",
       "       2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 2, 2, 0, 0, 1, 0,\n",
       "       1, 2, 1, 0, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 2, 0,\n",
       "       0, 2, 1, 0, 1, 2, 0, 2, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1,\n",
       "       2, 2, 0, 0, 1, 1, 0, 2, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 2,\n",
       "       0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 0, 0, 0, 0, 2, 1,\n",
       "       1, 0, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = model1_over5.predict_classes(X_test_over)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SR4153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0    NRS255     2     2\n",
       "1    NRS148     2     2\n",
       "2    NRS209     2     2\n",
       "3    NRS386     1     1\n",
       "4    NRS230     0     0\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS209     2     2\n",
       "199  SR4153     0     0\n",
       "200  NRS255     2     2\n",
       "201  NRS255     2     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat5['pred'] = pred5\n",
    "dat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba5 = model1_over5.predict_proba(X_test_over)\n",
    "dat_proba5 = pd.DataFrame(proba5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.258997e-04</td>\n",
       "      <td>2.146967e-03</td>\n",
       "      <td>9.977271e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.622584e-17</td>\n",
       "      <td>1.171789e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.312901e-12</td>\n",
       "      <td>1.454831e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.127909e-02</td>\n",
       "      <td>9.786837e-01</td>\n",
       "      <td>3.726870e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.345151e-08</td>\n",
       "      <td>1.853019e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.312901e-12</td>\n",
       "      <td>1.454831e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.312901e-12</td>\n",
       "      <td>1.454831e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.258997e-04</td>\n",
       "      <td>2.146967e-03</td>\n",
       "      <td>9.977271e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.258997e-04</td>\n",
       "      <td>2.146967e-03</td>\n",
       "      <td>9.977271e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.258997e-04  2.146967e-03  9.977271e-01\n",
       "1    2.622584e-17  1.171789e-14  1.000000e+00\n",
       "2    1.312901e-12  1.454831e-10  1.000000e+00\n",
       "3    2.127909e-02  9.786837e-01  3.726870e-05\n",
       "4    1.000000e+00  2.345151e-08  1.853019e-17\n",
       "..            ...           ...           ...\n",
       "197  1.312901e-12  1.454831e-10  1.000000e+00\n",
       "198  1.312901e-12  1.454831e-10  1.000000e+00\n",
       "199  1.000000e+00  0.000000e+00  0.000000e+00\n",
       "200  1.258997e-04  2.146967e-03  9.977271e-01\n",
       "201  1.258997e-04  2.146967e-03  9.977271e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba5.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/5p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 1.4322 - accuracy: 0.7277 - val_loss: 0.7450 - val_accuracy: 0.8911\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.6145 - accuracy: 0.7340 - val_loss: 0.6549 - val_accuracy: 0.8812\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.4263 - accuracy: 0.7383 - val_loss: 0.7513 - val_accuracy: 0.8812\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 1.3111 - accuracy: 0.7447 - val_loss: 0.8308 - val_accuracy: 0.8416\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.3749 - accuracy: 0.7191 - val_loss: 0.5903 - val_accuracy: 0.9208\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 1.5134 - accuracy: 0.7255 - val_loss: 0.6759 - val_accuracy: 0.8911\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.4627 - accuracy: 0.7596 - val_loss: 0.7135 - val_accuracy: 0.8911\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.4699 - accuracy: 0.7383 - val_loss: 0.5937 - val_accuracy: 0.8911\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.3985 - accuracy: 0.7426 - val_loss: 0.5617 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 1.3113 - accuracy: 0.7638 - val_loss: 0.5697 - val_accuracy: 0.9208\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.2534 - accuracy: 0.7574 - val_loss: 0.8076 - val_accuracy: 0.8366\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.3333 - accuracy: 0.7404 - val_loss: 0.5708 - val_accuracy: 0.9208\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 1.3930 - accuracy: 0.7213 - val_loss: 0.8127 - val_accuracy: 0.8911\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2023 - accuracy: 0.7596 - val_loss: 0.8130 - val_accuracy: 0.8762\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.5242 - accuracy: 0.7255 - val_loss: 0.5699 - val_accuracy: 0.8911\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.3254 - accuracy: 0.7617 - val_loss: 0.4843 - val_accuracy: 0.9406\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.1684 - accuracy: 0.7553 - val_loss: 0.6400 - val_accuracy: 0.9059\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.4495 - accuracy: 0.7596 - val_loss: 0.5083 - val_accuracy: 0.9406\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.2684 - accuracy: 0.7532 - val_loss: 0.7808 - val_accuracy: 0.8564\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.2844 - accuracy: 0.7553 - val_loss: 0.6670 - val_accuracy: 0.9109\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 1.1933 - accuracy: 0.7426 - val_loss: 0.6624 - val_accuracy: 0.9109\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.3892 - accuracy: 0.7511 - val_loss: 0.5691 - val_accuracy: 0.8911\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.1326 - accuracy: 0.7915 - val_loss: 0.6118 - val_accuracy: 0.9307\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.1743 - accuracy: 0.7660 - val_loss: 0.5909 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 1.2436 - accuracy: 0.7511 - val_loss: 0.5991 - val_accuracy: 0.9406\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 1.1959 - accuracy: 0.7532 - val_loss: 0.6149 - val_accuracy: 0.8911\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.1480 - accuracy: 0.7489 - val_loss: 0.7820 - val_accuracy: 0.8911\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.4209 - accuracy: 0.7277 - val_loss: 0.6561 - val_accuracy: 0.8911\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.2552 - accuracy: 0.7681 - val_loss: 0.7061 - val_accuracy: 0.8911\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.2155 - accuracy: 0.7553 - val_loss: 0.7729 - val_accuracy: 0.8861\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 1.2163 - accuracy: 0.7957 - val_loss: 0.6106 - val_accuracy: 0.9109\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.1884 - accuracy: 0.7681 - val_loss: 0.6438 - val_accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.2700 - accuracy: 0.7468 - val_loss: 0.7867 - val_accuracy: 0.8911\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 1.0550 - accuracy: 0.7340 - val_loss: 0.4417 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.1935 - accuracy: 0.7702 - val_loss: 0.5548 - val_accuracy: 0.9307\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.1334 - accuracy: 0.7596 - val_loss: 0.6751 - val_accuracy: 0.8911\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.1464 - accuracy: 0.7638 - val_loss: 0.4389 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.3995 - accuracy: 0.7383 - val_loss: 0.5490 - val_accuracy: 0.9307\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.0415 - accuracy: 0.7468 - val_loss: 0.7032 - val_accuracy: 0.8564\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.3994 - accuracy: 0.7638 - val_loss: 1.5321 - val_accuracy: 0.8911\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.6872 - accuracy: 0.7255 - val_loss: 0.6213 - val_accuracy: 0.9158\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 1.2041 - accuracy: 0.7745 - val_loss: 0.4673 - val_accuracy: 0.9307\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 356us/step - loss: 1.3206 - accuracy: 0.7532 - val_loss: 0.5489 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 308us/step - loss: 1.3411 - accuracy: 0.7766 - val_loss: 0.7715 - val_accuracy: 0.8960\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.3546 - accuracy: 0.7638 - val_loss: 0.5819 - val_accuracy: 0.9455\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 303us/step - loss: 1.2234 - accuracy: 0.7447 - val_loss: 0.6561 - val_accuracy: 0.8614\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 1.2490 - accuracy: 0.7574 - val_loss: 0.6506 - val_accuracy: 0.9010\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 1.2461 - accuracy: 0.7532 - val_loss: 0.6229 - val_accuracy: 0.9109\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.0224 - accuracy: 0.7830 - val_loss: 0.5352 - val_accuracy: 0.9307\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.1801 - accuracy: 0.7553 - val_loss: 0.4619 - val_accuracy: 0.9356\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.9361 - accuracy: 0.7553 - val_loss: 0.3978 - val_accuracy: 0.9604\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 0.9298 - accuracy: 0.7745 - val_loss: 0.4979 - val_accuracy: 0.9208\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 1.0416 - accuracy: 0.7809 - val_loss: 0.4716 - val_accuracy: 0.9455\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.9602 - accuracy: 0.7957 - val_loss: 0.4394 - val_accuracy: 0.9455\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 0.9254 - accuracy: 0.7787 - val_loss: 0.4590 - val_accuracy: 0.9406\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.9773 - accuracy: 0.7915 - val_loss: 0.4897 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 1.0936 - accuracy: 0.7383 - val_loss: 0.4372 - val_accuracy: 0.9505\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.8967 - accuracy: 0.7957 - val_loss: 0.4540 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 0.9847 - accuracy: 0.7809 - val_loss: 0.4544 - val_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 0.9074 - accuracy: 0.7830 - val_loss: 0.4679 - val_accuracy: 0.9257\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 1.0340 - accuracy: 0.7596 - val_loss: 0.7131 - val_accuracy: 0.9307\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.0471 - accuracy: 0.7574 - val_loss: 0.7239 - val_accuracy: 0.9307\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.1341 - accuracy: 0.7532 - val_loss: 0.7166 - val_accuracy: 0.8861\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.2027 - accuracy: 0.7596 - val_loss: 0.7127 - val_accuracy: 0.9307\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 1.3967 - accuracy: 0.7745 - val_loss: 0.8900 - val_accuracy: 0.8861\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 1.1531 - accuracy: 0.7511 - val_loss: 0.7662 - val_accuracy: 0.9158\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.2359 - accuracy: 0.7383 - val_loss: 0.7714 - val_accuracy: 0.9356\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.4499 - accuracy: 0.7106 - val_loss: 0.8844 - val_accuracy: 0.8762\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.2537 - accuracy: 0.7468 - val_loss: 0.8223 - val_accuracy: 0.9059\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.5465 - accuracy: 0.7532 - val_loss: 0.9964 - val_accuracy: 0.8861\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.2477 - accuracy: 0.7660 - val_loss: 0.6058 - val_accuracy: 0.9158\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 109us/step - loss: 1.2461 - accuracy: 0.7426 - val_loss: 0.5769 - val_accuracy: 0.9604\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 1.2204 - accuracy: 0.7894 - val_loss: 0.6174 - val_accuracy: 0.9455\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.0133 - accuracy: 0.7979 - val_loss: 0.6350 - val_accuracy: 0.9010\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 1.0238 - accuracy: 0.7362 - val_loss: 0.4152 - val_accuracy: 0.9505\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.1016 - accuracy: 0.7277 - val_loss: 0.7200 - val_accuracy: 0.8465\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.2753 - accuracy: 0.7532 - val_loss: 0.7686 - val_accuracy: 0.9010\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 1.2337 - accuracy: 0.7468 - val_loss: 0.5443 - val_accuracy: 0.9604\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 1.3701 - accuracy: 0.7702 - val_loss: 0.6506 - val_accuracy: 0.9208\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 1.3951 - accuracy: 0.7426 - val_loss: 0.6016 - val_accuracy: 0.9604\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.1805 - accuracy: 0.7617 - val_loss: 0.7643 - val_accuracy: 0.8911\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.4754 - accuracy: 0.7085 - val_loss: 0.5850 - val_accuracy: 0.9455\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.1540 - accuracy: 0.7745 - val_loss: 0.5408 - val_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 1.2290 - accuracy: 0.7426 - val_loss: 0.6098 - val_accuracy: 0.9208\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 0.9104 - accuracy: 0.7617 - val_loss: 0.4798 - val_accuracy: 0.9356\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.9953 - accuracy: 0.7255 - val_loss: 0.6020 - val_accuracy: 0.9307\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.9903 - accuracy: 0.7660 - val_loss: 0.4213 - val_accuracy: 0.9455\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.8841 - accuracy: 0.7766 - val_loss: 0.4670 - val_accuracy: 0.9257\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 0.9788 - accuracy: 0.7617 - val_loss: 0.3838 - val_accuracy: 0.9406\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.0222 - accuracy: 0.7553 - val_loss: 0.3189 - val_accuracy: 0.9752\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.7203 - accuracy: 0.8000 - val_loss: 0.3288 - val_accuracy: 0.9752\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 0.9140 - accuracy: 0.8149 - val_loss: 0.4029 - val_accuracy: 0.9208\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.9033 - accuracy: 0.7362 - val_loss: 0.3887 - val_accuracy: 0.9703\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.9278 - accuracy: 0.7553 - val_loss: 0.4081 - val_accuracy: 0.9554\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0757 - accuracy: 0.7574 - val_loss: 0.4436 - val_accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.0794 - accuracy: 0.7723 - val_loss: 0.4390 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.0908 - accuracy: 0.7745 - val_loss: 0.4196 - val_accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.1223 - accuracy: 0.7872 - val_loss: 0.3533 - val_accuracy: 0.9653\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 0.9909 - accuracy: 0.7830 - val_loss: 0.4700 - val_accuracy: 0.9158\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.8929 - accuracy: 0.7766 - val_loss: 0.4218 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "hist1_over5 = model1_over5.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.76%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over5.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba5 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=0,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342914e-03</td>\n",
       "      <td>9.986569e-01</td>\n",
       "      <td>2.348628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780311e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>2.544841e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.203547e-10</td>\n",
       "      <td>5.688883e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.170289e-08</td>\n",
       "      <td>1.017893e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.152503e-09</td>\n",
       "      <td>1.898730e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.401357e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.209735e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.755084e-10</td>\n",
       "      <td>1.974275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS236</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357345e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.293117e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.074704e-08</td>\n",
       "      <td>2.329201e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS241          1           1  1.342914e-03   \n",
       "1     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "2     p002ykpresabsSTCC_qual     NRS255          1           1  1.780311e-07   \n",
       "3     p002ykpresabsSTCC_qual     NRS214          0           0  1.000000e+00   \n",
       "4     p002ykpresabsSTCC_qual     NRS148          2           2  5.170289e-08   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual  BCH-SA-12          0           0  1.000000e+00   \n",
       "1978     pyopresabsSTCC_qual     NRS049          0           1  8.401357e-11   \n",
       "1979     pyopresabsSTCC_qual     NRS022          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS236          1           1  1.357345e-08   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  4.074704e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     9.986569e-01  2.348628e-07  \n",
       "1     1.017893e-07  9.999999e-01  \n",
       "2     9.999999e-01  2.544841e-12  \n",
       "3     2.203547e-10  5.688883e-15  \n",
       "4     1.017893e-07  9.999999e-01  \n",
       "...            ...           ...  \n",
       "1977  1.152503e-09  1.898730e-09  \n",
       "1978  1.000000e+00  3.209735e-13  \n",
       "1979  4.755084e-10  1.974275e-10  \n",
       "1980  1.000000e+00  1.293117e-10  \n",
       "1981  2.329201e-08  9.999999e-01  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [2.12790900e-02, 9.78683650e-01, 3.72687030e-05],\n",
       "       [1.00000000e+00, 2.34515150e-08, 1.85301940e-17],\n",
       "       [1.00000000e+00, 4.58270300e-08, 1.02282040e-15],\n",
       "       [9.99998200e-01, 1.73866520e-06, 1.12610840e-17],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 9.93071940e-12, 3.48034750e-21],\n",
       "       [1.28087640e-01, 8.71086660e-01, 8.25726140e-04],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.00000000e+00, 6.42052260e-14, 1.62811880e-18],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.99982600e-01, 1.73791290e-05, 5.40100800e-16],\n",
       "       [2.00067570e-08, 1.00000000e+00, 1.97239030e-09],\n",
       "       [2.00067570e-08, 1.00000000e+00, 1.97239030e-09],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [6.75229030e-03, 9.93247750e-01, 1.15677940e-10],\n",
       "       [1.00000000e+00, 3.49529200e-08, 2.53120100e-11],\n",
       "       [9.97371100e-01, 2.62894950e-03, 3.69797470e-14],\n",
       "       [2.19545520e-13, 1.00000000e+00, 1.05439300e-11],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [7.96341060e-08, 9.99999900e-01, 1.58868630e-08],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.02125960e-10, 1.00000000e+00, 8.39883450e-09],\n",
       "       [1.28087640e-01, 8.71086660e-01, 8.25726140e-04],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [6.07375300e-03, 9.93926200e-01, 1.03250810e-13],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 5.44108200e-10, 4.00999870e-21],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.44108200e-10, 4.00999870e-21],\n",
       "       [1.09992340e-17, 1.00000000e+00, 2.80089000e-16],\n",
       "       [2.19545520e-13, 1.00000000e+00, 1.05439300e-11],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 1.98965520e-08, 2.52216070e-18],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.00000000e+00, 3.11338460e-10, 1.00681070e-20],\n",
       "       [9.99992700e-01, 7.27386260e-06, 2.28883500e-12],\n",
       "       [8.98028400e-01, 1.01971574e-01, 3.39108170e-12],\n",
       "       [9.99934430e-01, 6.55300900e-05, 6.53282500e-12],\n",
       "       [1.00000000e+00, 2.80510900e-08, 3.07420130e-11],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [6.07375300e-03, 9.93926200e-01, 1.03250810e-13],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.99999760e-01, 2.55572400e-07, 8.87028800e-10],\n",
       "       [9.99644500e-01, 3.55494350e-04, 8.44373000e-11],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [9.99999300e-01, 6.94733300e-07, 7.09524000e-19],\n",
       "       [5.49995900e-11, 1.00000000e+00, 4.26765420e-09],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [5.94457700e-13, 1.00000000e+00, 3.11294950e-11],\n",
       "       [9.99995600e-01, 4.39405860e-06, 9.46058900e-11],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [9.97371100e-01, 2.62894950e-03, 3.69797470e-14],\n",
       "       [8.21162500e-11, 1.00000000e+00, 2.07227000e-09],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 5.73936400e-12, 2.36747440e-23],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [2.19545520e-13, 1.00000000e+00, 1.05439300e-11],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [2.73519760e-13, 1.00000000e+00, 1.33893695e-11],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 5.44108200e-10, 4.00999870e-21],\n",
       "       [2.00067570e-08, 1.00000000e+00, 1.97239030e-09],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.02450060e-13, 2.34047040e-25],\n",
       "       [1.09992340e-17, 1.00000000e+00, 2.80089000e-16],\n",
       "       [9.99998200e-01, 1.73866520e-06, 1.12610840e-17],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [9.81956700e-01, 1.80432400e-02, 1.55576010e-12],\n",
       "       [5.94457700e-13, 1.00000000e+00, 3.11294950e-11],\n",
       "       [1.00000000e+00, 8.27519400e-11, 3.80183870e-20],\n",
       "       [9.95242800e-01, 4.75719300e-03, 7.79678400e-14],\n",
       "       [4.57220170e-01, 5.42779600e-01, 2.30287380e-07],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [7.96341060e-08, 9.99999900e-01, 1.58868630e-08],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.00804030e-14, 5.70956720e-27],\n",
       "       [1.00000000e+00, 3.94577200e-11, 2.21299340e-22],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [1.00000000e+00, 6.01941300e-09, 3.36360900e-19],\n",
       "       [6.07375300e-03, 9.93926200e-01, 1.03250810e-13],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [5.40605830e-09, 1.00000000e+00, 2.24357620e-15],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 2.00804030e-14, 5.70956720e-27],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [2.12790900e-02, 9.78683650e-01, 3.72687030e-05],\n",
       "       [1.00000000e+00, 1.51343900e-08, 5.29596870e-16],\n",
       "       [3.02868950e-10, 9.99999900e-01, 1.03508450e-07],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.99999900e-01, 8.05042900e-08, 7.22474420e-12],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [8.50445300e-09, 1.00000000e+00, 1.17885800e-09],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 6.42052260e-14, 1.62811880e-18],\n",
       "       [5.40605830e-09, 1.00000000e+00, 2.24357620e-15],\n",
       "       [9.99999900e-01, 1.47539780e-07, 1.17984910e-14],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [9.99999900e-01, 1.70557830e-07, 7.72399000e-14],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [9.81956700e-01, 1.80432400e-02, 1.55576010e-12],\n",
       "       [4.67925200e-07, 9.99999500e-01, 4.09071900e-09],\n",
       "       [2.73519760e-13, 1.00000000e+00, 1.33893695e-11],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [9.99985600e-01, 1.44523100e-05, 3.65210480e-16],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [5.49995900e-11, 1.00000000e+00, 4.26765420e-09],\n",
       "       [1.00000000e+00, 2.63096250e-08, 1.69051780e-17],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [7.74345100e-09, 1.00000000e+00, 1.23914180e-10],\n",
       "       [9.08433600e-13, 1.05555860e-10, 1.00000000e+00],\n",
       "       [4.57220170e-01, 5.42779600e-01, 2.30287380e-07],\n",
       "       [1.28087640e-01, 8.71086660e-01, 8.25726140e-04],\n",
       "       [9.97965340e-01, 2.03471350e-03, 4.79700480e-11],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [7.96341060e-08, 9.99999900e-01, 1.58868630e-08],\n",
       "       [4.57220170e-01, 5.42779600e-01, 2.30287380e-07],\n",
       "       [2.00067570e-08, 1.00000000e+00, 1.97239030e-09],\n",
       "       [5.49995900e-11, 1.00000000e+00, 4.26765420e-09],\n",
       "       [1.00000000e+00, 6.42052260e-14, 1.62811880e-18],\n",
       "       [1.00000000e+00, 1.79440730e-15, 8.32316200e-21],\n",
       "       [1.00000000e+00, 5.25533530e-09, 7.36175800e-17],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 6.42052260e-14, 1.62811880e-18],\n",
       "       [1.00000000e+00, 3.49529200e-08, 2.53120100e-11],\n",
       "       [9.99998200e-01, 1.73866520e-06, 1.12610840e-17],\n",
       "       [9.48846600e-02, 9.01289050e-01, 3.82632480e-03],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.14824170e-09, 2.68573910e-17],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.08433600e-13, 1.05555860e-10, 1.00000000e+00],\n",
       "       [1.02125960e-10, 1.00000000e+00, 8.39883450e-09],\n",
       "       [1.69548460e-07, 9.99999900e-01, 1.27188560e-09],\n",
       "       [1.02125960e-10, 1.00000000e+00, 8.39883450e-09],\n",
       "       [9.97324700e-01, 2.67530770e-03, 1.07225426e-13],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.00000000e+00, 1.38161930e-10, 1.37756750e-13],\n",
       "       [9.99999900e-01, 1.47728730e-07, 6.73248850e-10],\n",
       "       [1.00000000e+00, 3.94577200e-11, 2.21299340e-22],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [2.19545520e-13, 1.00000000e+00, 1.05439300e-11],\n",
       "       [7.28771700e-12, 1.00000000e+00, 4.74442040e-10],\n",
       "       [9.99998200e-01, 1.73866520e-06, 1.12610840e-17],\n",
       "       [4.57220170e-01, 5.42779600e-01, 2.30287380e-07],\n",
       "       [9.99999400e-01, 6.27105600e-07, 1.16389720e-09],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.44326200e-10, 1.18301340e-21],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.99999760e-01, 1.82592560e-07, 4.05599440e-15],\n",
       "       [1.02125960e-10, 1.00000000e+00, 8.39883450e-09],\n",
       "       [9.99353600e-01, 6.46454000e-04, 1.24771750e-14],\n",
       "       [6.24834400e-01, 3.75165500e-01, 9.18440300e-08],\n",
       "       [7.28771700e-12, 1.00000000e+00, 4.74442040e-10],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [3.52623290e-13, 1.00000000e+00, 7.31980900e-17],\n",
       "       [2.19545520e-13, 1.00000000e+00, 1.05439300e-11],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [2.62258360e-17, 1.17178900e-14, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [9.81584800e-01, 1.84152050e-02, 3.88670760e-13],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.31290120e-12, 1.45483140e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01],\n",
       "       [1.25899660e-04, 2.14696680e-03, 9.97727100e-01]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob5 = df_proba5[df_proba5['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob5 = y_prob5.to_numpy()\n",
    "y_prob5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967152120660315"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo5 = rocauc_ovo(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967152120660315"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr5 = rocauc_ovr(y_test_over, y_prob5, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=678,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6 = pd.DataFrame(X_test_over[:,0])\n",
    "dat6['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0       115     1\n",
       "1    NRS209     2\n",
       "2     GA984     0\n",
       "3    NRS187     1\n",
       "4    NRS148     2\n",
       "..      ...   ...\n",
       "197  NRS253     1\n",
       "198   EUH15     0\n",
       "199  NRS180     1\n",
       "200  NRS266     1\n",
       "201  NRS109     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 743us/step - loss: 9.9542 - accuracy: 0.3745 - val_loss: 5.8433 - val_accuracy: 0.4703\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 8.1247 - accuracy: 0.4213 - val_loss: 4.7025 - val_accuracy: 0.4505\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 6.1863 - accuracy: 0.4489 - val_loss: 2.2844 - val_accuracy: 0.5495\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 243us/step - loss: 5.0407 - accuracy: 0.4915 - val_loss: 0.9682 - val_accuracy: 0.6139\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 3.3077 - accuracy: 0.5532 - val_loss: 0.8372 - val_accuracy: 0.6139\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 3.1675 - accuracy: 0.5872 - val_loss: 0.7498 - val_accuracy: 0.6535\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 440us/step - loss: 3.0265 - accuracy: 0.6000 - val_loss: 0.7143 - val_accuracy: 0.6832\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 3.1065 - accuracy: 0.5872 - val_loss: 0.7526 - val_accuracy: 0.6832\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 3.1660 - accuracy: 0.5809 - val_loss: 0.8280 - val_accuracy: 0.6832\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 3.1121 - accuracy: 0.5894 - val_loss: 0.8502 - val_accuracy: 0.7129\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 3.1995 - accuracy: 0.5957 - val_loss: 1.0504 - val_accuracy: 0.7772\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 486us/step - loss: 3.0744 - accuracy: 0.6128 - val_loss: 0.9124 - val_accuracy: 0.7525\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 280us/step - loss: 2.5660 - accuracy: 0.6468 - val_loss: 0.9868 - val_accuracy: 0.8020\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 2.5540 - accuracy: 0.6830 - val_loss: 1.0173 - val_accuracy: 0.8317\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 2.7231 - accuracy: 0.6766 - val_loss: 0.9715 - val_accuracy: 0.8168\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 386us/step - loss: 2.6340 - accuracy: 0.6660 - val_loss: 1.0756 - val_accuracy: 0.8119\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 427us/step - loss: 2.2159 - accuracy: 0.6404 - val_loss: 0.9770 - val_accuracy: 0.7426\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 2.1681 - accuracy: 0.6553 - val_loss: 1.1552 - val_accuracy: 0.7525\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 2.6122 - accuracy: 0.6617 - val_loss: 1.1025 - val_accuracy: 0.8812\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 303us/step - loss: 2.1528 - accuracy: 0.7021 - val_loss: 1.0193 - val_accuracy: 0.8119\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 2.1541 - accuracy: 0.6957 - val_loss: 0.8966 - val_accuracy: 0.8614\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.3710 - accuracy: 0.6766 - val_loss: 1.0465 - val_accuracy: 0.8812\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 2.3503 - accuracy: 0.6894 - val_loss: 1.0623 - val_accuracy: 0.8861\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.2853 - accuracy: 0.6830 - val_loss: 1.0119 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 2.6684 - accuracy: 0.6766 - val_loss: 0.9900 - val_accuracy: 0.8762\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.5724 - accuracy: 0.6617 - val_loss: 1.0370 - val_accuracy: 0.8861\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 2.6391 - accuracy: 0.6979 - val_loss: 1.0364 - val_accuracy: 0.8812\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 2.1344 - accuracy: 0.6851 - val_loss: 0.9410 - val_accuracy: 0.8416\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 318us/step - loss: 2.2514 - accuracy: 0.7085 - val_loss: 0.8143 - val_accuracy: 0.8515\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 2.2543 - accuracy: 0.6787 - val_loss: 1.0216 - val_accuracy: 0.8119\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.6994 - accuracy: 0.6681 - val_loss: 1.0943 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.5027 - accuracy: 0.6723 - val_loss: 0.9389 - val_accuracy: 0.8317\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.3462 - accuracy: 0.6851 - val_loss: 0.9854 - val_accuracy: 0.8861\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 2.2867 - accuracy: 0.6766 - val_loss: 0.9663 - val_accuracy: 0.8911\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 2.1942 - accuracy: 0.7149 - val_loss: 0.8822 - val_accuracy: 0.8861\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 2.2584 - accuracy: 0.6553 - val_loss: 1.0963 - val_accuracy: 0.7624\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 209us/step - loss: 2.3709 - accuracy: 0.6617 - val_loss: 1.0005 - val_accuracy: 0.8267\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 2.6080 - accuracy: 0.6638 - val_loss: 0.9235 - val_accuracy: 0.8267\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 2.2956 - accuracy: 0.6553 - val_loss: 0.9389 - val_accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 2.6333 - accuracy: 0.6638 - val_loss: 0.9228 - val_accuracy: 0.8861\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.2744 - accuracy: 0.6915 - val_loss: 0.7851 - val_accuracy: 0.8911\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.1263 - accuracy: 0.6915 - val_loss: 0.8948 - val_accuracy: 0.8960\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 2.2592 - accuracy: 0.6851 - val_loss: 0.9932 - val_accuracy: 0.8119\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.1666 - accuracy: 0.6915 - val_loss: 0.8531 - val_accuracy: 0.8366\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.0132 - accuracy: 0.6809 - val_loss: 0.9844 - val_accuracy: 0.7673\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.2692 - accuracy: 0.6872 - val_loss: 1.0543 - val_accuracy: 0.7822\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.2108 - accuracy: 0.6660 - val_loss: 0.9223 - val_accuracy: 0.7970\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 2.0391 - accuracy: 0.6638 - val_loss: 0.9389 - val_accuracy: 0.8762\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 2.0454 - accuracy: 0.6957 - val_loss: 0.8900 - val_accuracy: 0.8911\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 2.1732 - accuracy: 0.6745 - val_loss: 0.8479 - val_accuracy: 0.8465\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.1066 - accuracy: 0.6809 - val_loss: 0.8829 - val_accuracy: 0.8911\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 2.0261 - accuracy: 0.7064 - val_loss: 0.8283 - val_accuracy: 0.8911\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 2.1860 - accuracy: 0.7043 - val_loss: 0.8185 - val_accuracy: 0.8564\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 1.8022 - accuracy: 0.7255 - val_loss: 0.8674 - val_accuracy: 0.8960\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.9907 - accuracy: 0.7170 - val_loss: 0.8529 - val_accuracy: 0.8812\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.8362 - accuracy: 0.7234 - val_loss: 0.8078 - val_accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 2.3475 - accuracy: 0.6574 - val_loss: 0.7120 - val_accuracy: 0.8564\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 2.1451 - accuracy: 0.6894 - val_loss: 0.8748 - val_accuracy: 0.8960\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 2.0915 - accuracy: 0.7213 - val_loss: 0.8936 - val_accuracy: 0.8861\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.9944 - accuracy: 0.7149 - val_loss: 0.8410 - val_accuracy: 0.9010\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.8754 - accuracy: 0.7021 - val_loss: 0.9756 - val_accuracy: 0.8515\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 2.1572 - accuracy: 0.6638 - val_loss: 0.7440 - val_accuracy: 0.9010\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.9212 - accuracy: 0.6936 - val_loss: 0.8766 - val_accuracy: 0.8713\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.9743 - accuracy: 0.7000 - val_loss: 0.8513 - val_accuracy: 0.8960\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.2047 - accuracy: 0.6979 - val_loss: 0.8955 - val_accuracy: 0.8960\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.9074 - accuracy: 0.7128 - val_loss: 0.7416 - val_accuracy: 0.8663\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 171us/step - loss: 1.9138 - accuracy: 0.7064 - val_loss: 0.8749 - val_accuracy: 0.8663\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 1.8183 - accuracy: 0.6957 - val_loss: 0.6257 - val_accuracy: 0.9010\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.7867 - accuracy: 0.6957 - val_loss: 0.7391 - val_accuracy: 0.8762\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.8965 - accuracy: 0.7128 - val_loss: 0.7179 - val_accuracy: 0.8762\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 2.2387 - accuracy: 0.6574 - val_loss: 0.8729 - val_accuracy: 0.8960\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 185us/step - loss: 1.9087 - accuracy: 0.6894 - val_loss: 0.8237 - val_accuracy: 0.8960\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 2.0699 - accuracy: 0.7043 - val_loss: 0.8397 - val_accuracy: 0.8960\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 148us/step - loss: 1.6612 - accuracy: 0.6894 - val_loss: 0.8821 - val_accuracy: 0.8317\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 1.8550 - accuracy: 0.7021 - val_loss: 0.8855 - val_accuracy: 0.8515\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.6411 - accuracy: 0.7191 - val_loss: 0.7207 - val_accuracy: 0.8663\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 199us/step - loss: 1.7835 - accuracy: 0.6830 - val_loss: 0.7993 - val_accuracy: 0.8564\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 2.0707 - accuracy: 0.6936 - val_loss: 0.6150 - val_accuracy: 0.8960\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 149us/step - loss: 1.8484 - accuracy: 0.6957 - val_loss: 0.7241 - val_accuracy: 0.8713\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.6895 - accuracy: 0.7064 - val_loss: 0.6417 - val_accuracy: 0.8861\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.1598 - accuracy: 0.7021 - val_loss: 0.9677 - val_accuracy: 0.8564\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 1.6467 - accuracy: 0.7106 - val_loss: 0.7715 - val_accuracy: 0.8564\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.8537 - accuracy: 0.7085 - val_loss: 0.6208 - val_accuracy: 0.8960\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 1.5942 - accuracy: 0.7064 - val_loss: 0.9794 - val_accuracy: 0.8317\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.9199 - accuracy: 0.6957 - val_loss: 0.8486 - val_accuracy: 0.8614\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.7001 - accuracy: 0.7085 - val_loss: 0.8614 - val_accuracy: 0.8960\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 1.8223 - accuracy: 0.7255 - val_loss: 0.8481 - val_accuracy: 0.8960\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.6118 - accuracy: 0.7213 - val_loss: 0.6078 - val_accuracy: 0.8861\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.5708 - accuracy: 0.7128 - val_loss: 0.6982 - val_accuracy: 0.8960\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 1.8068 - accuracy: 0.6957 - val_loss: 0.6678 - val_accuracy: 0.8564\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.7942 - accuracy: 0.7043 - val_loss: 0.8472 - val_accuracy: 0.8119\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 2.1503 - accuracy: 0.6213 - val_loss: 0.7853 - val_accuracy: 0.8861\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.7797 - accuracy: 0.7000 - val_loss: 0.8334 - val_accuracy: 0.9010\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 1.7775 - accuracy: 0.6979 - val_loss: 0.8709 - val_accuracy: 0.9010\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 329us/step - loss: 1.8902 - accuracy: 0.6979 - val_loss: 0.9059 - val_accuracy: 0.8762\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 1.8056 - accuracy: 0.7000 - val_loss: 0.8322 - val_accuracy: 0.8960\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.7844 - accuracy: 0.6872 - val_loss: 0.8490 - val_accuracy: 0.8713\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.7937 - accuracy: 0.7064 - val_loss: 0.8410 - val_accuracy: 0.8762\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.6630 - accuracy: 0.6851 - val_loss: 0.8405 - val_accuracy: 0.9010\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 193us/step - loss: 1.6745 - accuracy: 0.7064 - val_loss: 0.9512 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38205080>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 108us/step\n",
      "over-sampling test accuracy: 92.08%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over6 = model1_over6.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over6*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 0, 1,\n",
       "       2, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 0, 1,\n",
       "       2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 1,\n",
       "       0, 2, 2, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 1, 2, 2,\n",
       "       1, 1, 0, 2, 1, 0, 1, 1, 2, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 2,\n",
       "       1, 0, 2, 2, 1, 2, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 0, 2, 2, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 2, 1, 0, 2, 0, 2, 2,\n",
       "       1, 1, 2, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 2, 1, 0, 1, 1, 1, 0, 2, 1,\n",
       "       0, 1, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6 = model1_over6.predict_classes(X_test_over)\n",
    "pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GA984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>EUH15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0       115     1     1\n",
       "1    NRS209     2     2\n",
       "2     GA984     0     1\n",
       "3    NRS187     1     1\n",
       "4    NRS148     2     2\n",
       "..      ...   ...   ...\n",
       "197  NRS253     1     1\n",
       "198   EUH15     0     0\n",
       "199  NRS180     1     1\n",
       "200  NRS266     1     1\n",
       "201  NRS109     1     1\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat6['pred'] = pred6\n",
    "dat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba6 = model1_over6.predict_proba(X_test_over)\n",
    "dat_proba6 = pd.DataFrame(proba6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.378712e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.580147e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.755056e-10</td>\n",
       "      <td>1.493326e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.207942e-01</td>\n",
       "      <td>6.746280e-01</td>\n",
       "      <td>4.577814e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.123706e-06</td>\n",
       "      <td>9.999939e-01</td>\n",
       "      <td>2.119516e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.780598e-11</td>\n",
       "      <td>2.499853e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.207942e-01</td>\n",
       "      <td>6.746280e-01</td>\n",
       "      <td>4.577814e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>9.992932e-01</td>\n",
       "      <td>7.067574e-04</td>\n",
       "      <td>3.600648e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4.149153e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.871512e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.619248e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.663113e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6.762146e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.304643e-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    3.378712e-08  1.000000e+00  2.580147e-21\n",
       "1    5.755056e-10  1.493326e-09  1.000000e+00\n",
       "2    3.207942e-01  6.746280e-01  4.577814e-03\n",
       "3    6.123706e-06  9.999939e-01  2.119516e-15\n",
       "4    8.780598e-11  2.499853e-10  1.000000e+00\n",
       "..            ...           ...           ...\n",
       "197  3.207942e-01  6.746280e-01  4.577814e-03\n",
       "198  9.992932e-01  7.067574e-04  3.600648e-14\n",
       "199  4.149153e-09  1.000000e+00  9.871512e-24\n",
       "200  1.619248e-08  1.000000e+00  3.663113e-22\n",
       "201  6.762146e-08  9.999999e-01  3.304643e-21\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba6.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat6.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/6p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 1.9564 - accuracy: 0.7383 - val_loss: 0.7850 - val_accuracy: 0.9455\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 2.0272 - accuracy: 0.7362 - val_loss: 0.6557 - val_accuracy: 0.9455\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.5909 - accuracy: 0.7255 - val_loss: 0.8612 - val_accuracy: 0.8416\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.9322 - accuracy: 0.7660 - val_loss: 0.8010 - val_accuracy: 0.9356\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 2.1065 - accuracy: 0.7383 - val_loss: 0.8736 - val_accuracy: 0.9307\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.9895 - accuracy: 0.7447 - val_loss: 0.6777 - val_accuracy: 0.8911\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.8077 - accuracy: 0.7681 - val_loss: 0.5603 - val_accuracy: 0.8861\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 2.1241 - accuracy: 0.7298 - val_loss: 0.6676 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.7478 - accuracy: 0.7489 - val_loss: 0.4908 - val_accuracy: 0.9257\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.9526 - accuracy: 0.7511 - val_loss: 0.8249 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.0812 - accuracy: 0.7702 - val_loss: 0.8250 - val_accuracy: 0.9455\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.8590 - accuracy: 0.7660 - val_loss: 0.5495 - val_accuracy: 0.9307\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 2.0044 - accuracy: 0.7532 - val_loss: 0.7171 - val_accuracy: 0.8960\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 2.0490 - accuracy: 0.7213 - val_loss: 0.6174 - val_accuracy: 0.9307\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 1.6180 - accuracy: 0.7489 - val_loss: 0.6104 - val_accuracy: 0.9257\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.9880 - accuracy: 0.7234 - val_loss: 0.5290 - val_accuracy: 0.9455\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.9448 - accuracy: 0.7277 - val_loss: 0.8536 - val_accuracy: 0.8762\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.7793 - accuracy: 0.7447 - val_loss: 0.8264 - val_accuracy: 0.9059\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.8500 - accuracy: 0.7362 - val_loss: 0.8039 - val_accuracy: 0.9208\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.9137 - accuracy: 0.7298 - val_loss: 0.5513 - val_accuracy: 0.9455\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.9402 - accuracy: 0.7404 - val_loss: 0.3303 - val_accuracy: 0.9802\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 1.8325 - accuracy: 0.7383 - val_loss: 0.8171 - val_accuracy: 0.9406\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 225us/step - loss: 1.9359 - accuracy: 0.7277 - val_loss: 0.8478 - val_accuracy: 0.9208\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 380us/step - loss: 2.0465 - accuracy: 0.7340 - val_loss: 0.8270 - val_accuracy: 0.9257\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 2.0273 - accuracy: 0.7191 - val_loss: 0.8874 - val_accuracy: 0.9455\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 1.7446 - accuracy: 0.7553 - val_loss: 0.8458 - val_accuracy: 0.9455\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 2.0801 - accuracy: 0.7106 - val_loss: 0.6235 - val_accuracy: 0.9208\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 443us/step - loss: 1.5434 - accuracy: 0.7617 - val_loss: 0.5600 - val_accuracy: 0.9406\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 229us/step - loss: 1.5959 - accuracy: 0.7532 - val_loss: 0.7051 - val_accuracy: 0.9010\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 1.9810 - accuracy: 0.7489 - val_loss: 0.5611 - val_accuracy: 0.9406\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 164us/step - loss: 1.7422 - accuracy: 0.7574 - val_loss: 0.5850 - val_accuracy: 0.8762\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.9189 - accuracy: 0.7298 - val_loss: 0.6591 - val_accuracy: 0.8812\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 1.7106 - accuracy: 0.7404 - val_loss: 0.5921 - val_accuracy: 0.9109\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 1.6399 - accuracy: 0.7723 - val_loss: 0.6324 - val_accuracy: 0.9208\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.4301 - accuracy: 0.7851 - val_loss: 0.5851 - val_accuracy: 0.9059\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 1.7223 - accuracy: 0.7702 - val_loss: 0.5919 - val_accuracy: 0.9208\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 1.9345 - accuracy: 0.7362 - val_loss: 0.5731 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 339us/step - loss: 1.6857 - accuracy: 0.7532 - val_loss: 0.5943 - val_accuracy: 0.9505\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 609us/step - loss: 1.6808 - accuracy: 0.7532 - val_loss: 0.6371 - val_accuracy: 0.9158\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 1.7852 - accuracy: 0.7404 - val_loss: 0.6393 - val_accuracy: 0.9010\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 1.7984 - accuracy: 0.7532 - val_loss: 0.6236 - val_accuracy: 0.9455\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 1.7635 - accuracy: 0.7340 - val_loss: 0.7809 - val_accuracy: 0.8762\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.9167 - accuracy: 0.7021 - val_loss: 0.6646 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 1.4946 - accuracy: 0.7745 - val_loss: 0.6856 - val_accuracy: 0.9158\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.6339 - accuracy: 0.7702 - val_loss: 0.4377 - val_accuracy: 0.9059\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 248us/step - loss: 1.2937 - accuracy: 0.7745 - val_loss: 0.7820 - val_accuracy: 0.8762\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.6239 - accuracy: 0.7723 - val_loss: 0.6797 - val_accuracy: 0.9307\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.5997 - accuracy: 0.7511 - val_loss: 0.6683 - val_accuracy: 0.9208\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 1.6290 - accuracy: 0.7745 - val_loss: 0.6819 - val_accuracy: 0.9208\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 1.8813 - accuracy: 0.7362 - val_loss: 0.7100 - val_accuracy: 0.9208\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 1.4990 - accuracy: 0.7511 - val_loss: 0.6989 - val_accuracy: 0.9307\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 1.5560 - accuracy: 0.7532 - val_loss: 0.7398 - val_accuracy: 0.9208\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 1.5044 - accuracy: 0.7404 - val_loss: 0.7901 - val_accuracy: 0.9257\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 1.4298 - accuracy: 0.7936 - val_loss: 0.7203 - val_accuracy: 0.9505\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.3641 - accuracy: 0.7723 - val_loss: 0.7481 - val_accuracy: 0.8861\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 1.4766 - accuracy: 0.7489 - val_loss: 0.8804 - val_accuracy: 0.8911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 219us/step - loss: 1.4055 - accuracy: 0.7617 - val_loss: 0.9447 - val_accuracy: 0.8663\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 1.8504 - accuracy: 0.7149 - val_loss: 0.7486 - val_accuracy: 0.9406\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 1.2528 - accuracy: 0.7915 - val_loss: 0.7591 - val_accuracy: 0.9208\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 217us/step - loss: 1.5172 - accuracy: 0.7617 - val_loss: 0.7406 - val_accuracy: 0.9455\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 1.5605 - accuracy: 0.7660 - val_loss: 0.7458 - val_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 1.5783 - accuracy: 0.7489 - val_loss: 0.7738 - val_accuracy: 0.9505\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 1.5278 - accuracy: 0.7638 - val_loss: 0.7930 - val_accuracy: 0.9257\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 208us/step - loss: 1.2742 - accuracy: 0.7766 - val_loss: 0.7938 - val_accuracy: 0.9406\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.4670 - accuracy: 0.7489 - val_loss: 0.7680 - val_accuracy: 0.9505\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 194us/step - loss: 1.7298 - accuracy: 0.7277 - val_loss: 0.8296 - val_accuracy: 0.9109\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 1.3950 - accuracy: 0.7191 - val_loss: 0.8000 - val_accuracy: 0.9307\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 260us/step - loss: 1.2120 - accuracy: 0.8000 - val_loss: 0.9090 - val_accuracy: 0.9158\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 1.5957 - accuracy: 0.7532 - val_loss: 0.8066 - val_accuracy: 0.9505\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 1.5983 - accuracy: 0.7426 - val_loss: 0.8531 - val_accuracy: 0.9406\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.4067 - accuracy: 0.7830 - val_loss: 0.8096 - val_accuracy: 0.9208\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 1.4611 - accuracy: 0.7681 - val_loss: 0.7943 - val_accuracy: 0.9406\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 1.3153 - accuracy: 0.7830 - val_loss: 0.8062 - val_accuracy: 0.9406\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 1.3239 - accuracy: 0.7723 - val_loss: 0.8042 - val_accuracy: 0.9208\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 1.8396 - accuracy: 0.7255 - val_loss: 0.8528 - val_accuracy: 0.9208\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 1.8252 - accuracy: 0.7404 - val_loss: 0.8043 - val_accuracy: 0.9208\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.5431 - accuracy: 0.7638 - val_loss: 0.8301 - val_accuracy: 0.9010\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 402us/step - loss: 1.4779 - accuracy: 0.7404 - val_loss: 1.3574 - val_accuracy: 0.8119\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 275us/step - loss: 1.5694 - accuracy: 0.7255 - val_loss: 0.8993 - val_accuracy: 0.9208\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.5042 - accuracy: 0.7468 - val_loss: 0.9326 - val_accuracy: 0.8564\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 1.4324 - accuracy: 0.7660 - val_loss: 0.8116 - val_accuracy: 0.9307\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 1.4261 - accuracy: 0.7660 - val_loss: 0.8549 - val_accuracy: 0.9208\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.3707 - accuracy: 0.7574 - val_loss: 0.8082 - val_accuracy: 0.9406\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 1.3185 - accuracy: 0.7745 - val_loss: 0.8370 - val_accuracy: 0.9356\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.4575 - accuracy: 0.7489 - val_loss: 0.8447 - val_accuracy: 0.9158\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.2851 - accuracy: 0.7915 - val_loss: 0.8421 - val_accuracy: 0.9455\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.3514 - accuracy: 0.7809 - val_loss: 0.8377 - val_accuracy: 0.9307\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.3732 - accuracy: 0.7362 - val_loss: 0.8550 - val_accuracy: 0.9208\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 1.4343 - accuracy: 0.7638 - val_loss: 0.8206 - val_accuracy: 0.9455\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 1.2288 - accuracy: 0.7830 - val_loss: 0.8598 - val_accuracy: 0.9208\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.2154 - accuracy: 0.7766 - val_loss: 0.8734 - val_accuracy: 0.9158\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 486us/step - loss: 1.3586 - accuracy: 0.7532 - val_loss: 0.8232 - val_accuracy: 0.9208\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 1.2682 - accuracy: 0.7319 - val_loss: 0.9008 - val_accuracy: 0.9158\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 1.4078 - accuracy: 0.7681 - val_loss: 0.8921 - val_accuracy: 0.9158\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 247us/step - loss: 1.2296 - accuracy: 0.7553 - val_loss: 0.8257 - val_accuracy: 0.9356\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 266us/step - loss: 1.4859 - accuracy: 0.7511 - val_loss: 0.8341 - val_accuracy: 0.9356\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.3988 - accuracy: 0.7617 - val_loss: 0.8890 - val_accuracy: 0.9158\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.0979 - accuracy: 0.7830 - val_loss: 0.8683 - val_accuracy: 0.9158\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.3668 - accuracy: 0.7702 - val_loss: 0.8992 - val_accuracy: 0.9158\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.2396 - accuracy: 0.7660 - val_loss: 0.8826 - val_accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "hist1_over6 = model1_over6.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.31%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over6.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba6 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=1,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.790400e-08</td>\n",
       "      <td>4.141849e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.739934e-04</td>\n",
       "      <td>9.994259e-01</td>\n",
       "      <td>6.773014e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.286934e-09</td>\n",
       "      <td>1.269109e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.494936e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.537080e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.701098e-02</td>\n",
       "      <td>9.399204e-01</td>\n",
       "      <td>3.068583e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999607e-01</td>\n",
       "      <td>3.367024e-05</td>\n",
       "      <td>5.776848e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.275442e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>3.739556e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168245e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.603962e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.026408e-15</td>\n",
       "      <td>1.630406e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120633e-08</td>\n",
       "      <td>1.998346e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  1.790400e-08   \n",
       "1     p002ykpresabsSTCC_qual     NRS386          1           1  5.739934e-04   \n",
       "2     p002ykpresabsSTCC_qual     NRS148          2           2  5.286934e-09   \n",
       "3     p002ykpresabsSTCC_qual     NRS178          0           1  6.494936e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS237          0           1  5.701098e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS272          0           0  9.999607e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS112          1           1  8.275442e-08   \n",
       "1979     pyopresabsSTCC_qual     NRS064          1           1  2.168245e-08   \n",
       "1980     pyopresabsSTCC_qual  BCH-SA-04          0           0  1.000000e+00   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.120633e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     4.141849e-08  1.000000e+00  \n",
       "1     9.994259e-01  6.773014e-08  \n",
       "2     1.269109e-08  1.000000e+00  \n",
       "3     1.000000e+00  2.537080e-25  \n",
       "4     9.399204e-01  3.068583e-03  \n",
       "...            ...           ...  \n",
       "1977  3.367024e-05  5.776848e-06  \n",
       "1978  9.999999e-01  3.739556e-09  \n",
       "1979  1.000000e+00  9.603962e-09  \n",
       "1980  1.026408e-15  1.630406e-14  \n",
       "1981  1.998346e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.37871240e-08, 1.00000000e+00, 2.58014660e-21],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [6.12370650e-06, 9.99993900e-01, 2.11951640e-15],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [6.76214640e-08, 9.99999900e-01, 3.30464290e-21],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [4.05319240e-09, 1.00000000e+00, 9.27707100e-24],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [5.47757430e-08, 1.00000000e+00, 9.30167800e-21],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [9.99876000e-01, 1.23928620e-04, 1.61447960e-09],\n",
       "       [9.99999640e-01, 3.89809430e-07, 2.33771300e-17],\n",
       "       [9.99857200e-01, 1.42834440e-04, 2.34590540e-14],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [8.05952100e-09, 1.00000000e+00, 5.74999300e-23],\n",
       "       [4.03069860e-08, 1.00000000e+00, 1.64195650e-21],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [2.41341330e-02, 9.75865840e-01, 1.93726300e-09],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.76438170e-09, 3.93588550e-12],\n",
       "       [1.00000000e+00, 1.07942980e-08, 6.09199700e-12],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [4.05319240e-09, 1.00000000e+00, 9.27707100e-24],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [6.76214640e-08, 9.99999900e-01, 3.30464290e-21],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.61924820e-08, 1.00000000e+00, 3.66311300e-22],\n",
       "       [1.00000000e+00, 1.41460830e-20, 1.20299490e-23],\n",
       "       [1.17976444e-04, 9.99882000e-01, 4.13305800e-12],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [4.14915300e-09, 1.00000000e+00, 9.87151200e-24],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [2.14228600e-03, 9.97857750e-01, 6.92021460e-09],\n",
       "       [6.12370650e-06, 9.99993900e-01, 2.11951640e-15],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [9.99892830e-01, 1.01603010e-04, 5.58387200e-06],\n",
       "       [4.50026330e-04, 9.99549900e-01, 1.27416740e-10],\n",
       "       [7.55057450e-01, 2.44942560e-01, 4.17107500e-11],\n",
       "       [4.14915300e-09, 1.00000000e+00, 9.87151200e-24],\n",
       "       [9.99169800e-01, 8.30191800e-04, 3.45350950e-14],\n",
       "       [2.95775200e-02, 9.70416500e-01, 5.96844100e-06],\n",
       "       [8.72054350e-06, 9.99991300e-01, 5.24061900e-15],\n",
       "       [4.05319240e-09, 1.00000000e+00, 9.27707100e-24],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [8.05952100e-09, 1.00000000e+00, 5.74999300e-23],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [1.28862190e-02, 9.87113700e-01, 4.93548200e-12],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [9.99999400e-01, 6.53764200e-07, 1.49355710e-15],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [2.41341330e-02, 9.75865840e-01, 1.93726300e-09],\n",
       "       [3.87638100e-05, 9.99961260e-01, 2.39028060e-13],\n",
       "       [4.10162180e-08, 1.00000000e+00, 1.53782230e-21],\n",
       "       [8.70544550e-01, 1.29455500e-01, 7.01551000e-11],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.87638100e-05, 9.99961260e-01, 2.39028060e-13],\n",
       "       [1.00000000e+00, 1.64568800e-13, 2.80189200e-14],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.87502810e-08, 3.56423280e-18],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [4.10162180e-08, 1.00000000e+00, 1.53782230e-21],\n",
       "       [9.82398450e-01, 1.76014940e-02, 1.84784400e-13],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [9.99985200e-01, 3.18975250e-07, 1.43864910e-05],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [9.99887000e-01, 1.12983070e-04, 8.09055950e-11],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [8.05952100e-09, 1.00000000e+00, 5.74999300e-23],\n",
       "       [9.99999900e-01, 1.29650520e-07, 1.30766730e-09],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [1.02906530e-10, 1.00000000e+00, 5.41131860e-28],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [9.97613430e-01, 2.38656670e-03, 5.37911550e-08],\n",
       "       [9.99950400e-01, 4.81576100e-05, 1.42587100e-06],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [5.47757430e-08, 1.00000000e+00, 9.30167800e-21],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [3.87638100e-05, 9.99961260e-01, 2.39028060e-13],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [1.00000000e+00, 9.65875200e-22, 1.76338600e-19],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [9.99876000e-01, 1.23928620e-04, 1.61447960e-09],\n",
       "       [1.61924820e-08, 1.00000000e+00, 3.66311300e-22],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [9.99999500e-01, 4.45234500e-07, 3.74075760e-18],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [4.01778670e-02, 9.59808800e-01, 1.32978410e-05],\n",
       "       [1.02906530e-10, 1.00000000e+00, 5.41131860e-28],\n",
       "       [4.05319240e-09, 1.00000000e+00, 9.27707100e-24],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [9.99997400e-01, 2.60505500e-06, 5.98603680e-12],\n",
       "       [4.03069860e-08, 1.00000000e+00, 1.64195650e-21],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [1.17976444e-04, 9.99882000e-01, 4.13305800e-12],\n",
       "       [2.41341330e-02, 9.75865840e-01, 1.93726300e-09],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [1.02906530e-10, 1.00000000e+00, 5.41131860e-28],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [9.98266500e-01, 1.73352800e-03, 2.27382310e-09],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.87638100e-05, 9.99961260e-01, 2.39028060e-13],\n",
       "       [6.81073500e-01, 3.18926500e-01, 9.13152900e-10],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [6.76214640e-08, 9.99999900e-01, 3.30464290e-21],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [6.76214640e-08, 9.99999900e-01, 3.30464290e-21],\n",
       "       [9.99993100e-01, 6.94134630e-06, 1.09827350e-11],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 7.89347300e-15, 1.15569620e-15],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [6.52061200e-02, 9.34793830e-01, 1.21069320e-09],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [8.78059850e-11, 2.49985250e-10, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.43019140e-09, 2.60796670e-18],\n",
       "       [9.99999900e-01, 1.76255430e-07, 8.66454200e-18],\n",
       "       [4.03069860e-08, 1.00000000e+00, 1.64195650e-21],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [1.00000000e+00, 1.63020730e-25, 3.29565130e-23],\n",
       "       [9.99985200e-01, 3.18975250e-07, 1.43864910e-05],\n",
       "       [9.96394100e-01, 3.60587050e-03, 1.22037580e-13],\n",
       "       [1.44168710e-07, 2.84855500e-07, 9.99999500e-01],\n",
       "       [4.05094550e-08, 9.61968450e-18, 1.00000000e+00],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [1.00000000e+00, 2.90633070e-10, 4.27363600e-15],\n",
       "       [3.96440130e-09, 1.00000000e+00, 8.74744300e-24],\n",
       "       [1.51447530e-05, 9.99984860e-01, 2.15396800e-14],\n",
       "       [3.85185630e-01, 6.14814400e-01, 5.92295000e-09],\n",
       "       [1.00000000e+00, 1.31927290e-22, 8.26181660e-23],\n",
       "       [5.75505640e-10, 1.49332610e-09, 1.00000000e+00],\n",
       "       [3.20794200e-01, 6.74628000e-01, 4.57781370e-03],\n",
       "       [9.99293200e-01, 7.06757400e-04, 3.60064760e-14],\n",
       "       [4.14915300e-09, 1.00000000e+00, 9.87151200e-24],\n",
       "       [1.61924820e-08, 1.00000000e+00, 3.66311300e-22],\n",
       "       [6.76214640e-08, 9.99999900e-01, 3.30464290e-21]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob6 = df_proba6[df_proba6['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob6 = y_prob6.to_numpy()\n",
    "y_prob6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769854431545975"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo6 = rocauc_ovo(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769854431545975"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr6 = rocauc_ovr(y_test_over, y_prob6, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=789,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7 = pd.DataFrame(X_test_over[:,0])\n",
    "dat7['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test\n",
       "0     NRS260     0\n",
       "1     NRS148     2\n",
       "2     NRS205     1\n",
       "3     NRS064     1\n",
       "4     NRS209     2\n",
       "..       ...   ...\n",
       "197   NRS255     2\n",
       "198  GA53649     0\n",
       "199   NRS209     2\n",
       "200   NRS210     0\n",
       "201   NRS162     0\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over7.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 682us/step - loss: 10.9208 - accuracy: 0.3660 - val_loss: 6.7597 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 227us/step - loss: 7.8083 - accuracy: 0.5149 - val_loss: 4.9314 - val_accuracy: 0.5396\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 6.2548 - accuracy: 0.4660 - val_loss: 3.3329 - val_accuracy: 0.5990\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 5.2616 - accuracy: 0.4638 - val_loss: 2.1933 - val_accuracy: 0.5693\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 4.1984 - accuracy: 0.5255 - val_loss: 1.5212 - val_accuracy: 0.6386\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 215us/step - loss: 3.9139 - accuracy: 0.5170 - val_loss: 1.0769 - val_accuracy: 0.5941\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 3.7003 - accuracy: 0.5149 - val_loss: 0.9854 - val_accuracy: 0.5842\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 296us/step - loss: 3.7361 - accuracy: 0.5277 - val_loss: 0.9482 - val_accuracy: 0.5842\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 3.3418 - accuracy: 0.5511 - val_loss: 0.9045 - val_accuracy: 0.5990\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 3.5014 - accuracy: 0.5660 - val_loss: 0.8884 - val_accuracy: 0.5941\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 3.3207 - accuracy: 0.5702 - val_loss: 0.8998 - val_accuracy: 0.5842\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 3.1702 - accuracy: 0.5511 - val_loss: 0.8845 - val_accuracy: 0.5842\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 3.6684 - accuracy: 0.5191 - val_loss: 0.8949 - val_accuracy: 0.6040\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 404us/step - loss: 3.5888 - accuracy: 0.5660 - val_loss: 0.9014 - val_accuracy: 0.6040\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 392us/step - loss: 3.5376 - accuracy: 0.5638 - val_loss: 0.9632 - val_accuracy: 0.6386\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 3.0494 - accuracy: 0.5745 - val_loss: 0.9484 - val_accuracy: 0.6040\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 386us/step - loss: 2.7104 - accuracy: 0.6277 - val_loss: 0.8441 - val_accuracy: 0.6782\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 319us/step - loss: 3.3497 - accuracy: 0.6255 - val_loss: 0.8671 - val_accuracy: 0.7129\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 254us/step - loss: 3.1128 - accuracy: 0.6191 - val_loss: 0.8106 - val_accuracy: 0.6683\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 3.0494 - accuracy: 0.6191 - val_loss: 0.8902 - val_accuracy: 0.7030\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 2.8964 - accuracy: 0.6000 - val_loss: 0.9397 - val_accuracy: 0.6584\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 353us/step - loss: 3.2577 - accuracy: 0.6191 - val_loss: 0.9307 - val_accuracy: 0.7129\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 2.7276 - accuracy: 0.6255 - val_loss: 1.0400 - val_accuracy: 0.7129\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 2.6931 - accuracy: 0.6468 - val_loss: 1.0591 - val_accuracy: 0.7129\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 3.4276 - accuracy: 0.6021 - val_loss: 1.0668 - val_accuracy: 0.7129\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 2.6446 - accuracy: 0.5936 - val_loss: 1.0823 - val_accuracy: 0.7178\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.6045 - accuracy: 0.6277 - val_loss: 1.1015 - val_accuracy: 0.7129\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 274us/step - loss: 3.0378 - accuracy: 0.6319 - val_loss: 1.0254 - val_accuracy: 0.7129\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 522us/step - loss: 2.8107 - accuracy: 0.6340 - val_loss: 1.0375 - val_accuracy: 0.7228\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 3.1793 - accuracy: 0.5809 - val_loss: 1.0359 - val_accuracy: 0.7178\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 2.7129 - accuracy: 0.6383 - val_loss: 1.1368 - val_accuracy: 0.7228\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.7887 - accuracy: 0.6404 - val_loss: 1.0257 - val_accuracy: 0.7178\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 115us/step - loss: 2.9396 - accuracy: 0.6340 - val_loss: 0.9043 - val_accuracy: 0.7426\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.9824 - accuracy: 0.6362 - val_loss: 0.8217 - val_accuracy: 0.7475\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 2.5601 - accuracy: 0.6532 - val_loss: 0.8756 - val_accuracy: 0.7673\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 341us/step - loss: 2.9162 - accuracy: 0.6851 - val_loss: 1.0019 - val_accuracy: 0.7624\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 230us/step - loss: 2.6736 - accuracy: 0.6681 - val_loss: 1.0145 - val_accuracy: 0.7475\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 2.4177 - accuracy: 0.6404 - val_loss: 0.9044 - val_accuracy: 0.7723\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.1505 - accuracy: 0.6617 - val_loss: 0.9363 - val_accuracy: 0.7624\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.5413 - accuracy: 0.6574 - val_loss: 0.9543 - val_accuracy: 0.7624\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 2.7615 - accuracy: 0.6362 - val_loss: 0.9323 - val_accuracy: 0.7426\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 2.3646 - accuracy: 0.6511 - val_loss: 0.8759 - val_accuracy: 0.7673\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 2.6620 - accuracy: 0.6702 - val_loss: 0.8618 - val_accuracy: 0.7673\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 110us/step - loss: 2.3925 - accuracy: 0.6915 - val_loss: 1.0443 - val_accuracy: 0.7673\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 120us/step - loss: 2.5604 - accuracy: 0.6702 - val_loss: 0.9174 - val_accuracy: 0.7574\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 2.4494 - accuracy: 0.6702 - val_loss: 0.9254 - val_accuracy: 0.7822\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.4835 - accuracy: 0.6894 - val_loss: 0.8123 - val_accuracy: 0.8020\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 2.7302 - accuracy: 0.6766 - val_loss: 1.0517 - val_accuracy: 0.7525\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 2.2106 - accuracy: 0.6681 - val_loss: 0.7997 - val_accuracy: 0.7871\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 2.8260 - accuracy: 0.6723 - val_loss: 0.8648 - val_accuracy: 0.7822\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.3838 - accuracy: 0.6851 - val_loss: 0.9641 - val_accuracy: 0.8069\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 284us/step - loss: 2.5865 - accuracy: 0.6787 - val_loss: 0.8657 - val_accuracy: 0.7822\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 2.4016 - accuracy: 0.6468 - val_loss: 0.9632 - val_accuracy: 0.7921\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 2.4612 - accuracy: 0.6957 - val_loss: 0.9116 - val_accuracy: 0.8020\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 309us/step - loss: 2.3485 - accuracy: 0.6681 - val_loss: 0.9392 - val_accuracy: 0.8218\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 404us/step - loss: 2.2184 - accuracy: 0.6872 - val_loss: 0.7735 - val_accuracy: 0.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 2.7128 - accuracy: 0.6574 - val_loss: 0.8765 - val_accuracy: 0.7475\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 2.4628 - accuracy: 0.6596 - val_loss: 1.0409 - val_accuracy: 0.8020\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 2.6706 - accuracy: 0.6872 - val_loss: 0.8989 - val_accuracy: 0.8168\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 2.4073 - accuracy: 0.6872 - val_loss: 0.9465 - val_accuracy: 0.8465\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.9870 - accuracy: 0.7213 - val_loss: 0.7696 - val_accuracy: 0.8366\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 2.2174 - accuracy: 0.6723 - val_loss: 0.7958 - val_accuracy: 0.8465\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.7835 - accuracy: 0.7553 - val_loss: 1.0330 - val_accuracy: 0.8416\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 2.0641 - accuracy: 0.7064 - val_loss: 0.8113 - val_accuracy: 0.8218\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 2.5399 - accuracy: 0.6872 - val_loss: 0.9019 - val_accuracy: 0.8465\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 2.3015 - accuracy: 0.6957 - val_loss: 0.7999 - val_accuracy: 0.8812\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 2.2900 - accuracy: 0.6702 - val_loss: 1.0923 - val_accuracy: 0.8614\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.9888 - accuracy: 0.7106 - val_loss: 0.8777 - val_accuracy: 0.8663\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.0390 - accuracy: 0.7106 - val_loss: 0.9080 - val_accuracy: 0.8762\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 111us/step - loss: 1.9045 - accuracy: 0.7298 - val_loss: 0.8008 - val_accuracy: 0.8614\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.9293 - accuracy: 0.7255 - val_loss: 0.7874 - val_accuracy: 0.8663\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 1.9623 - accuracy: 0.7298 - val_loss: 0.8234 - val_accuracy: 0.8713\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.9568 - accuracy: 0.7234 - val_loss: 0.7390 - val_accuracy: 0.8911\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 1.6860 - accuracy: 0.7596 - val_loss: 0.8602 - val_accuracy: 0.8317\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 112us/step - loss: 2.0393 - accuracy: 0.7000 - val_loss: 0.7427 - val_accuracy: 0.8762\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.6480 - accuracy: 0.7191 - val_loss: 0.7765 - val_accuracy: 0.8861\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.0814 - accuracy: 0.7362 - val_loss: 0.9497 - val_accuracy: 0.8812\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.9596 - accuracy: 0.7106 - val_loss: 0.9518 - val_accuracy: 0.8465\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.9619 - accuracy: 0.7170 - val_loss: 0.8329 - val_accuracy: 0.8713\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 1.8453 - accuracy: 0.7170 - val_loss: 1.0235 - val_accuracy: 0.8762\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 195us/step - loss: 2.2749 - accuracy: 0.7170 - val_loss: 0.9648 - val_accuracy: 0.8812\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.0519 - accuracy: 0.7234 - val_loss: 0.9543 - val_accuracy: 0.8812\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.9204 - accuracy: 0.7298 - val_loss: 0.9206 - val_accuracy: 0.8663\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 1.6203 - accuracy: 0.7404 - val_loss: 0.7695 - val_accuracy: 0.8663\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.8614 - accuracy: 0.7106 - val_loss: 0.7072 - val_accuracy: 0.8812\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 1.7395 - accuracy: 0.7213 - val_loss: 1.0360 - val_accuracy: 0.8861\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.7523 - accuracy: 0.7489 - val_loss: 1.0239 - val_accuracy: 0.8614\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.4607 - accuracy: 0.7149 - val_loss: 0.6616 - val_accuracy: 0.8762\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.4780 - accuracy: 0.7553 - val_loss: 0.7834 - val_accuracy: 0.8762\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.6560 - accuracy: 0.7085 - val_loss: 1.1535 - val_accuracy: 0.8366\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.6455 - accuracy: 0.7191 - val_loss: 0.7777 - val_accuracy: 0.8317\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 1.7557 - accuracy: 0.7170 - val_loss: 0.8346 - val_accuracy: 0.8861\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.5094 - accuracy: 0.7298 - val_loss: 1.0087 - val_accuracy: 0.8416\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 244us/step - loss: 1.6336 - accuracy: 0.7447 - val_loss: 0.8454 - val_accuracy: 0.8812\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.5006 - accuracy: 0.7532 - val_loss: 0.7475 - val_accuracy: 0.8812\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.6647 - accuracy: 0.7511 - val_loss: 0.8542 - val_accuracy: 0.8861\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.5628 - accuracy: 0.7532 - val_loss: 0.9306 - val_accuracy: 0.8762\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.4397 - accuracy: 0.7319 - val_loss: 0.8008 - val_accuracy: 0.8762\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.7109 - accuracy: 0.7340 - val_loss: 0.8341 - val_accuracy: 0.8713\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 1.5328 - accuracy: 0.7340 - val_loss: 0.6628 - val_accuracy: 0.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a38b749e8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 123us/step\n",
      "over-sampling test accuracy: 91.09%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over7 = model1_over7.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over7*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 1, 0, 0, 1,\n",
       "       2, 0, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1,\n",
       "       0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1,\n",
       "       2, 2, 2, 0, 2, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1,\n",
       "       0, 2, 0, 2, 0, 2, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 1, 0, 2, 2, 2, 1,\n",
       "       1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 0,\n",
       "       0, 2, 0, 1, 2, 2, 2, 0, 2, 1, 1, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2,\n",
       "       2, 1, 0, 2, 1, 0, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2,\n",
       "       0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2,\n",
       "       0, 2, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred7 = model1_over7.predict_classes(X_test_over)\n",
    "pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NRS260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS064</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS255</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GA53649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NRS210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  test  pred\n",
       "0     NRS260     0     1\n",
       "1     NRS148     2     2\n",
       "2     NRS205     1     2\n",
       "3     NRS064     1     2\n",
       "4     NRS209     2     2\n",
       "..       ...   ...   ...\n",
       "197   NRS255     2     2\n",
       "198  GA53649     0     0\n",
       "199   NRS209     2     2\n",
       "200   NRS210     0     0\n",
       "201   NRS162     0     0\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat7['pred'] = pred7\n",
    "dat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba7 = model1_over7.predict_proba(X_test_over)\n",
    "dat_proba7 = pd.DataFrame(proba7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.910703e-01</td>\n",
       "      <td>8.089237e-01</td>\n",
       "      <td>5.899579e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.019913e-09</td>\n",
       "      <td>9.196866e-07</td>\n",
       "      <td>9.999990e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.036906e-05</td>\n",
       "      <td>1.417140e-03</td>\n",
       "      <td>9.985525e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.137212e-03</td>\n",
       "      <td>1.493428e-01</td>\n",
       "      <td>8.455200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.863225e-10</td>\n",
       "      <td>1.086092e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5.137212e-03</td>\n",
       "      <td>1.493428e-01</td>\n",
       "      <td>8.455200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>1.917346e-07</td>\n",
       "      <td>5.435073e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4.863225e-10</td>\n",
       "      <td>1.086092e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.615954e-08</td>\n",
       "      <td>3.265495e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.206703e-16</td>\n",
       "      <td>5.341726e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    1.910703e-01  8.089237e-01  5.899579e-06\n",
       "1    6.019913e-09  9.196866e-07  9.999990e-01\n",
       "2    3.036906e-05  1.417140e-03  9.985525e-01\n",
       "3    5.137212e-03  1.493428e-01  8.455200e-01\n",
       "4    4.863225e-10  1.086092e-07  9.999999e-01\n",
       "..            ...           ...           ...\n",
       "197  5.137212e-03  1.493428e-01  8.455200e-01\n",
       "198  9.999998e-01  1.917346e-07  5.435073e-11\n",
       "199  4.863225e-10  1.086092e-07  9.999999e-01\n",
       "200  9.999999e-01  6.615954e-08  3.265495e-21\n",
       "201  1.000000e+00  2.206703e-16  5.341726e-22\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba7.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat7.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/7p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.2601 - accuracy: 0.7447 - val_loss: 1.0064 - val_accuracy: 0.9208\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 151us/step - loss: 1.2713 - accuracy: 0.7596 - val_loss: 1.0617 - val_accuracy: 0.9257\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.4613 - accuracy: 0.7255 - val_loss: 0.9513 - val_accuracy: 0.9307\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.2524 - accuracy: 0.7447 - val_loss: 0.9522 - val_accuracy: 0.9158\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 187us/step - loss: 1.2148 - accuracy: 0.7511 - val_loss: 0.9698 - val_accuracy: 0.9158\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 198us/step - loss: 1.2385 - accuracy: 0.7532 - val_loss: 0.8065 - val_accuracy: 0.9257\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.2186 - accuracy: 0.7915 - val_loss: 0.9013 - val_accuracy: 0.9158\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.1025 - accuracy: 0.7340 - val_loss: 0.5407 - val_accuracy: 0.9406\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 1.2090 - accuracy: 0.7574 - val_loss: 0.8189 - val_accuracy: 0.9406\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.1369 - accuracy: 0.7638 - val_loss: 0.8046 - val_accuracy: 0.9158\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.0558 - accuracy: 0.7660 - val_loss: 0.8047 - val_accuracy: 0.9505\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 170us/step - loss: 1.1514 - accuracy: 0.7447 - val_loss: 0.5682 - val_accuracy: 0.9406\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 269us/step - loss: 1.2046 - accuracy: 0.7532 - val_loss: 0.8151 - val_accuracy: 0.9406\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.1465 - accuracy: 0.7787 - val_loss: 1.2896 - val_accuracy: 0.9208\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.1988 - accuracy: 0.7660 - val_loss: 0.5305 - val_accuracy: 0.9059\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.0161 - accuracy: 0.8128 - val_loss: 0.6015 - val_accuracy: 0.9257\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.9979 - accuracy: 0.7553 - val_loss: 0.5595 - val_accuracy: 0.9307\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.4469 - accuracy: 0.7319 - val_loss: 0.6910 - val_accuracy: 0.9257\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 1.2360 - accuracy: 0.7489 - val_loss: 0.5524 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 156us/step - loss: 1.0450 - accuracy: 0.7574 - val_loss: 0.6915 - val_accuracy: 0.9307\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - ETA: 0s - loss: 1.1804 - accuracy: 0.73 - 0s 420us/step - loss: 1.1895 - accuracy: 0.7340 - val_loss: 0.7350 - val_accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 213us/step - loss: 1.2734 - accuracy: 0.7617 - val_loss: 0.7977 - val_accuracy: 0.9208\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 271us/step - loss: 1.1503 - accuracy: 0.7383 - val_loss: 0.8761 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.1225 - accuracy: 0.7468 - val_loss: 0.8653 - val_accuracy: 0.9257\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 346us/step - loss: 1.2382 - accuracy: 0.7383 - val_loss: 0.8127 - val_accuracy: 0.9158\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 1.2829 - accuracy: 0.7255 - val_loss: 0.7814 - val_accuracy: 0.9455\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 0.9639 - accuracy: 0.7638 - val_loss: 0.8342 - val_accuracy: 0.9307\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 325us/step - loss: 1.1655 - accuracy: 0.7447 - val_loss: 0.9133 - val_accuracy: 0.9010\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 1.1097 - accuracy: 0.7830 - val_loss: 0.6651 - val_accuracy: 0.9307\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 238us/step - loss: 1.1553 - accuracy: 0.7851 - val_loss: 0.8068 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 265us/step - loss: 1.0997 - accuracy: 0.7553 - val_loss: 0.7279 - val_accuracy: 0.9158\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.0935 - accuracy: 0.7638 - val_loss: 0.7747 - val_accuracy: 0.9356\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 1.2141 - accuracy: 0.7553 - val_loss: 0.5730 - val_accuracy: 0.9307\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 423us/step - loss: 1.1028 - accuracy: 0.7766 - val_loss: 0.4783 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 1.0738 - accuracy: 0.7872 - val_loss: 0.6921 - val_accuracy: 0.9406\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 0.9286 - accuracy: 0.8021 - val_loss: 0.4914 - val_accuracy: 0.9010\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 147us/step - loss: 1.0882 - accuracy: 0.7681 - val_loss: 0.4876 - val_accuracy: 0.9505\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.2327 - accuracy: 0.7532 - val_loss: 0.9309 - val_accuracy: 0.9208\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.0250 - accuracy: 0.7809 - val_loss: 0.8042 - val_accuracy: 0.9406\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.1611 - accuracy: 0.7851 - val_loss: 1.2258 - val_accuracy: 0.9010\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.4884 - accuracy: 0.7426 - val_loss: 1.3411 - val_accuracy: 0.8465\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.3596 - accuracy: 0.7511 - val_loss: 0.9751 - val_accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 142us/step - loss: 1.1872 - accuracy: 0.7638 - val_loss: 0.9348 - val_accuracy: 0.9455\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 168us/step - loss: 1.2057 - accuracy: 0.7872 - val_loss: 1.0209 - val_accuracy: 0.9109\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.2279 - accuracy: 0.7681 - val_loss: 1.0089 - val_accuracy: 0.8861\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 1.0380 - accuracy: 0.7723 - val_loss: 0.9161 - val_accuracy: 0.9010\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.1162 - accuracy: 0.7532 - val_loss: 0.9884 - val_accuracy: 0.9208\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.2197 - accuracy: 0.7617 - val_loss: 0.9019 - val_accuracy: 0.8960\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 1.0779 - accuracy: 0.7723 - val_loss: 0.7153 - val_accuracy: 0.9158\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.9780 - accuracy: 0.7787 - val_loss: 0.8026 - val_accuracy: 0.9356\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.0510 - accuracy: 0.7511 - val_loss: 0.7701 - val_accuracy: 0.9455\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.2558 - accuracy: 0.7064 - val_loss: 0.7954 - val_accuracy: 0.9505\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 1.2076 - accuracy: 0.7574 - val_loss: 0.6104 - val_accuracy: 0.9307\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.9096 - accuracy: 0.7447 - val_loss: 0.7459 - val_accuracy: 0.9356\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 125us/step - loss: 1.0362 - accuracy: 0.7723 - val_loss: 0.5125 - val_accuracy: 0.9406\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 262us/step - loss: 1.1019 - accuracy: 0.7660 - val_loss: 0.8101 - val_accuracy: 0.9158\n",
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 173us/step - loss: 0.9806 - accuracy: 0.7426 - val_loss: 0.8075 - val_accuracy: 0.8762\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 1.2939 - accuracy: 0.7340 - val_loss: 0.5809 - val_accuracy: 0.9406\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 343us/step - loss: 1.1230 - accuracy: 0.7511 - val_loss: 0.5549 - val_accuracy: 0.9307\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 367us/step - loss: 1.0555 - accuracy: 0.7596 - val_loss: 0.5312 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 1.0216 - accuracy: 0.7426 - val_loss: 0.5788 - val_accuracy: 0.9406\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 233us/step - loss: 0.8121 - accuracy: 0.8043 - val_loss: 0.5238 - val_accuracy: 0.9406\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 0.9060 - accuracy: 0.7596 - val_loss: 0.4730 - val_accuracy: 0.9307\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.1789 - accuracy: 0.7681 - val_loss: 0.8067 - val_accuracy: 0.9505\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.1685 - accuracy: 0.7979 - val_loss: 0.8122 - val_accuracy: 0.9356\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 1.1101 - accuracy: 0.7383 - val_loss: 0.7308 - val_accuracy: 0.9356\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 1.0160 - accuracy: 0.7617 - val_loss: 0.8152 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 0.8459 - accuracy: 0.7830 - val_loss: 0.4955 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 1.0168 - accuracy: 0.7830 - val_loss: 0.7696 - val_accuracy: 0.9356\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 1.1299 - accuracy: 0.7574 - val_loss: 0.7465 - val_accuracy: 0.9406\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 259us/step - loss: 1.1797 - accuracy: 0.7468 - val_loss: 0.7187 - val_accuracy: 0.9257\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 184us/step - loss: 1.0173 - accuracy: 0.7894 - val_loss: 0.5665 - val_accuracy: 0.9653\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 277us/step - loss: 1.1234 - accuracy: 0.7574 - val_loss: 0.6244 - val_accuracy: 0.9208\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 288us/step - loss: 0.9774 - accuracy: 0.7447 - val_loss: 0.6312 - val_accuracy: 0.9208\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 282us/step - loss: 0.8801 - accuracy: 0.7681 - val_loss: 0.7395 - val_accuracy: 0.9158\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 1.0510 - accuracy: 0.7787 - val_loss: 0.7711 - val_accuracy: 0.9505\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 1.1516 - accuracy: 0.7574 - val_loss: 0.7111 - val_accuracy: 0.9257\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.9948 - accuracy: 0.7702 - val_loss: 0.7460 - val_accuracy: 0.8960\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 0.9996 - accuracy: 0.7489 - val_loss: 0.6920 - val_accuracy: 0.9505\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 357us/step - loss: 1.1148 - accuracy: 0.7362 - val_loss: 0.8506 - val_accuracy: 0.9158\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 210us/step - loss: 0.9332 - accuracy: 0.7936 - val_loss: 0.3892 - val_accuracy: 0.9653\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.9262 - accuracy: 0.7660 - val_loss: 0.3316 - val_accuracy: 0.9653\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.8651 - accuracy: 0.7745 - val_loss: 0.4272 - val_accuracy: 0.9208\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.3070 - accuracy: 0.7234 - val_loss: 0.4753 - val_accuracy: 0.9455\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.1284 - accuracy: 0.7255 - val_loss: 0.7063 - val_accuracy: 0.9059\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 1.0859 - accuracy: 0.7574 - val_loss: 0.4114 - val_accuracy: 0.9356\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 232us/step - loss: 0.8714 - accuracy: 0.8106 - val_loss: 0.4846 - val_accuracy: 0.9653\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 220us/step - loss: 0.9406 - accuracy: 0.7574 - val_loss: 0.4015 - val_accuracy: 0.9406\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.8797 - accuracy: 0.7702 - val_loss: 0.4858 - val_accuracy: 0.9406\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 0.8880 - accuracy: 0.7745 - val_loss: 0.6273 - val_accuracy: 0.9505\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 218us/step - loss: 0.9595 - accuracy: 0.7787 - val_loss: 0.7123 - val_accuracy: 0.9505\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 1.0066 - accuracy: 0.7468 - val_loss: 0.6908 - val_accuracy: 0.9356\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.8644 - accuracy: 0.7809 - val_loss: 0.7200 - val_accuracy: 0.9505\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 0.9321 - accuracy: 0.7511 - val_loss: 0.3434 - val_accuracy: 0.9554\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 192us/step - loss: 0.8942 - accuracy: 0.7553 - val_loss: 0.4121 - val_accuracy: 0.9356\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 267us/step - loss: 0.8332 - accuracy: 0.8106 - val_loss: 0.7067 - val_accuracy: 0.9455\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.8970 - accuracy: 0.7830 - val_loss: 0.4242 - val_accuracy: 0.9257\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 0.9615 - accuracy: 0.7617 - val_loss: 0.3628 - val_accuracy: 0.9703\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 241us/step - loss: 0.9599 - accuracy: 0.7447 - val_loss: 0.3463 - val_accuracy: 0.9505\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 474us/step - loss: 1.1378 - accuracy: 0.7511 - val_loss: 0.3814 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "hist1_over7 = model1_over7.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 76.14%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over7.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba7 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=2,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>BCH-SA-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.137139e-06</td>\n",
       "      <td>9.999988e-01</td>\n",
       "      <td>2.067601e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.093110e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.300497e-12</td>\n",
       "      <td>1.036520e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.243513e-02</td>\n",
       "      <td>9.774035e-01</td>\n",
       "      <td>1.615106e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.354528e-01</td>\n",
       "      <td>6.414209e-02</td>\n",
       "      <td>4.051121e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.808470e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.364639e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CA9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.361323e-08</td>\n",
       "      <td>2.871247e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.755864e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>5.310879e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.386494e-08</td>\n",
       "      <td>2.366233e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage     strain  phenotype  prediction             0  \\\n",
       "0     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "1     p002ykpresabsSTCC_qual  BCH-SA-09          1           1  1.137139e-06   \n",
       "2     p002ykpresabsSTCC_qual     NRS224          0           0  1.000000e+00   \n",
       "3     p002ykpresabsSTCC_qual     NRS209          2           2  8.300497e-12   \n",
       "4     p002ykpresabsSTCC_qual     NRS235          1           1  2.243513e-02   \n",
       "...                      ...        ...        ...         ...           ...   \n",
       "1977     pyopresabsSTCC_qual     NRS035          0           0  9.354528e-01   \n",
       "1978     pyopresabsSTCC_qual     NRS260          1           1  4.808470e-08   \n",
       "1979     pyopresabsSTCC_qual        CA9          0           0  1.000000e+00   \n",
       "1980     pyopresabsSTCC_qual     NRS183          1           1  2.755864e-07   \n",
       "1981     pyopresabsSTCC_qual     NRS148          2           2  2.386494e-08   \n",
       "\n",
       "                 1             2  \n",
       "0     1.036520e-09  1.000000e+00  \n",
       "1     9.999988e-01  2.067601e-09  \n",
       "2     2.093110e-31  0.000000e+00  \n",
       "3     1.036520e-09  1.000000e+00  \n",
       "4     9.774035e-01  1.615106e-04  \n",
       "...            ...           ...  \n",
       "1977  6.414209e-02  4.051121e-04  \n",
       "1978  1.000000e+00  7.364639e-09  \n",
       "1979  2.361323e-08  2.871247e-08  \n",
       "1980  9.999998e-01  5.310879e-08  \n",
       "1981  2.366233e-08  1.000000e+00  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91070330e-01, 8.08923700e-01, 5.89957900e-06],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [3.03690610e-05, 1.41713950e-03, 9.98552500e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [2.02612520e-05, 9.99979600e-01, 8.02177240e-08],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [2.02612520e-05, 9.99979600e-01, 8.02177240e-08],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.20013240e-08, 1.31695870e-09],\n",
       "       [9.99999900e-01, 6.61595440e-08, 3.26549480e-21],\n",
       "       [1.48641620e-05, 9.99979600e-01, 5.44671900e-06],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.99998800e-01, 1.15188190e-06, 5.71751440e-20],\n",
       "       [1.34508770e-15, 1.00000000e+00, 3.08796050e-21],\n",
       "       [1.00000000e+00, 6.59775500e-09, 3.86724550e-12],\n",
       "       [9.98131330e-01, 1.86865700e-03, 4.28402100e-11],\n",
       "       [8.16906800e-12, 1.00000000e+00, 2.08999100e-15],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [2.91348800e-05, 9.99970900e-01, 5.46927200e-08],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [6.35864280e-12, 1.00000000e+00, 1.43292020e-15],\n",
       "       [9.99992130e-01, 6.55595340e-06, 1.27029450e-06],\n",
       "       [9.96046360e-01, 3.95363800e-03, 7.70329800e-12],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [3.60890060e-08, 1.00000000e+00, 4.70544560e-13],\n",
       "       [3.73644300e-08, 1.00000000e+00, 6.83109240e-10],\n",
       "       [2.83157370e-11, 1.00000000e+00, 1.35973470e-14],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [1.00000000e+00, 1.20013240e-08, 1.31695870e-09],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [1.00000000e+00, 1.33606070e-09, 1.21427560e-10],\n",
       "       [3.66951800e-15, 1.00000000e+00, 1.15009910e-20],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [9.99999900e-01, 8.46626100e-08, 1.09869545e-08],\n",
       "       [9.99999760e-01, 2.53227770e-07, 9.88937500e-09],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.99999900e-01, 9.41307200e-08, 2.24194360e-21],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.76438200e-01, 1.54954900e-02, 8.06627050e-03],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [2.83157370e-11, 1.00000000e+00, 1.35973470e-14],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [9.99998100e-01, 1.86320850e-06, 2.41320400e-10],\n",
       "       [9.99999900e-01, 1.19072180e-07, 1.73058800e-16],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [1.00000000e+00, 3.08917700e-08, 1.86407900e-10],\n",
       "       [3.60890060e-08, 1.00000000e+00, 4.70544560e-13],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [3.03690610e-05, 1.41713950e-03, 9.98552500e-01],\n",
       "       [3.03690610e-05, 1.41713950e-03, 9.98552500e-01],\n",
       "       [1.00000000e+00, 3.08917700e-08, 1.86407900e-10],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [2.16495980e-07, 9.99999760e-01, 9.63744800e-09],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [3.60890060e-08, 1.00000000e+00, 4.70544560e-13],\n",
       "       [9.99999760e-01, 1.97325350e-07, 7.31007100e-09],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [2.20655400e-03, 9.97793440e-01, 7.69495100e-09],\n",
       "       [3.03690610e-05, 1.41713950e-03, 9.98552500e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.99950200e-01, 4.97847000e-05, 1.60206170e-13],\n",
       "       [9.99999900e-01, 8.95652550e-08, 1.16795010e-08],\n",
       "       [9.99999760e-01, 2.53227770e-07, 9.88937500e-09],\n",
       "       [9.99999760e-01, 2.39334070e-07, 9.23586300e-09],\n",
       "       [1.00000000e+00, 9.01819700e-17, 4.40171100e-25],\n",
       "       [2.83157370e-11, 1.00000000e+00, 1.35973470e-14],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.31519750e-01, 6.84802900e-02, 1.03569944e-10],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [1.00000000e+00, 5.12401100e-08, 6.36901860e-09],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [2.16495980e-07, 9.99999760e-01, 9.63744800e-09],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [1.00000000e+00, 6.59775500e-09, 3.86724550e-12],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.21249250e-18, 1.00000000e+00, 2.07916660e-24],\n",
       "       [9.76438200e-01, 1.54954900e-02, 8.06627050e-03],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.21249250e-18, 1.00000000e+00, 2.07916660e-24],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [2.02612520e-05, 9.99979600e-01, 8.02177240e-08],\n",
       "       [1.00000000e+00, 7.40203400e-15, 4.16123140e-24],\n",
       "       [9.99681500e-01, 3.18494680e-04, 1.75543470e-13],\n",
       "       [1.00000000e+00, 1.93518280e-23, 4.91099420e-30],\n",
       "       [9.99999760e-01, 1.95869500e-07, 2.73165350e-08],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [1.00000000e+00, 1.25852550e-18, 5.42618000e-36],\n",
       "       [1.00000000e+00, 1.20013240e-08, 1.31695870e-09],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.98131330e-01, 1.86865700e-03, 4.28402100e-11],\n",
       "       [1.00000000e+00, 4.78934940e-08, 3.46905400e-21],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [3.60890060e-08, 1.00000000e+00, 4.70544560e-13],\n",
       "       [1.34508770e-15, 1.00000000e+00, 3.08796050e-21],\n",
       "       [2.16495980e-07, 9.99999760e-01, 9.63744800e-09],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.76438200e-01, 1.54954900e-02, 8.06627050e-03],\n",
       "       [9.99989150e-01, 1.08161460e-05, 5.45965830e-19],\n",
       "       [9.76438200e-01, 1.54954900e-02, 8.06627050e-03],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.99999760e-01, 2.31819710e-07, 9.27749700e-16],\n",
       "       [8.16906800e-12, 1.00000000e+00, 2.08999100e-15],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [1.00000000e+00, 3.41444830e-15, 1.02726580e-16],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [6.72574340e-07, 9.99999300e-01, 8.48050600e-09],\n",
       "       [2.02612520e-05, 9.99979600e-01, 8.02177240e-08],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [8.49114100e-01, 1.50885900e-01, 5.51812540e-10],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.99058800e-01, 9.40856600e-04, 3.91327660e-07],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [1.00000000e+00, 1.17489030e-15, 8.77812500e-25],\n",
       "       [1.00000000e+00, 5.70816200e-16, 1.47287680e-17],\n",
       "       [1.00000000e+00, 5.91999800e-14, 2.27538060e-15],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [3.73644300e-08, 1.00000000e+00, 6.83109240e-10],\n",
       "       [9.21448000e-01, 5.30846900e-02, 2.54673680e-02],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [4.43725400e-08, 1.00000000e+00, 6.93147100e-10],\n",
       "       [1.00000000e+00, 5.12401100e-08, 6.36901860e-09],\n",
       "       [6.35864280e-12, 1.00000000e+00, 1.43292020e-15],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [9.99998100e-01, 1.86320850e-06, 2.41320400e-10],\n",
       "       [2.83157370e-11, 1.00000000e+00, 1.35973470e-14],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [8.16906800e-12, 1.00000000e+00, 2.08999100e-15],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [2.02612520e-05, 9.99979600e-01, 8.02177240e-08],\n",
       "       [9.99989870e-01, 1.01908030e-05, 5.26246250e-17],\n",
       "       [9.95574000e-01, 4.42594600e-03, 7.46347800e-12],\n",
       "       [9.99999050e-01, 1.00279900e-06, 4.18166700e-09],\n",
       "       [1.34508770e-15, 1.00000000e+00, 3.08796050e-21],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [1.00000000e+00, 8.46239050e-11, 2.05493900e-21],\n",
       "       [2.91348800e-05, 9.99970900e-01, 5.46927200e-08],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [1.00000000e+00, 5.12401100e-08, 6.36901860e-09],\n",
       "       [9.99998100e-01, 1.86320850e-06, 2.41320400e-10],\n",
       "       [1.33532580e-06, 9.99998570e-01, 1.49393510e-07],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [2.91348800e-05, 9.99970900e-01, 5.46927200e-08],\n",
       "       [1.00000000e+00, 5.12401100e-08, 6.36901860e-09],\n",
       "       [8.16906800e-12, 1.00000000e+00, 2.08999100e-15],\n",
       "       [2.67815200e-04, 9.99725040e-01, 7.19752460e-06],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [8.16906800e-12, 1.00000000e+00, 2.08999100e-15],\n",
       "       [1.48641620e-05, 9.99979600e-01, 5.44671900e-06],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [9.21249250e-18, 1.00000000e+00, 2.07916660e-24],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.59775500e-09, 3.86724550e-12],\n",
       "       [6.01991260e-09, 9.19686600e-07, 9.99999050e-01],\n",
       "       [5.13721200e-03, 1.49342820e-01, 8.45519960e-01],\n",
       "       [9.99999760e-01, 1.91734590e-07, 5.43507250e-11],\n",
       "       [4.86322500e-10, 1.08609250e-07, 9.99999900e-01],\n",
       "       [9.99999900e-01, 6.61595440e-08, 3.26549480e-21],\n",
       "       [1.00000000e+00, 2.20670310e-16, 5.34172600e-22]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob7 = df_proba7[df_proba7['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob7 = y_prob7.to_numpy()\n",
    "y_prob7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725885821437475"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo7 = rocauc_ovo(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725885821437475"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr7 = rocauc_ovr(y_test_over, y_prob7, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test data (over)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=890,\n",
    "                                                    stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8 = pd.DataFrame(X_test_over[:,0])\n",
    "dat8['test'] = y_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test\n",
       "0     CA541     1\n",
       "1    SR3585     0\n",
       "2    NRS232     1\n",
       "3    NRS148     2\n",
       "4    NRS180     1\n",
       "..      ...   ...\n",
       "197  NRS209     2\n",
       "198  NRS035     1\n",
       "199     506     0\n",
       "200  SR2091     0\n",
       "201  NRS205     1\n",
       "\n",
       "[202 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = X_train_over[:,1:]\n",
    "X_test_over = X_test_over[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_over.shape[1],), activity_regularizer=l1(0.001)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax'),\n",
    "    Dropout(0.2, ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_over8.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 890us/step - loss: 9.1235 - accuracy: 0.3851 - val_loss: 5.4841 - val_accuracy: 0.6188\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 200us/step - loss: 6.3987 - accuracy: 0.5255 - val_loss: 3.6354 - val_accuracy: 0.5743\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 255us/step - loss: 5.0567 - accuracy: 0.5553 - val_loss: 2.4884 - val_accuracy: 0.6139\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 4.2149 - accuracy: 0.5766 - val_loss: 1.9187 - val_accuracy: 0.6337\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 3.8136 - accuracy: 0.5766 - val_loss: 1.5601 - val_accuracy: 0.6040\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 270us/step - loss: 3.9670 - accuracy: 0.5851 - val_loss: 1.2235 - val_accuracy: 0.6485\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 237us/step - loss: 3.1748 - accuracy: 0.6106 - val_loss: 1.1332 - val_accuracy: 0.5941\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 3.4527 - accuracy: 0.5638 - val_loss: 1.0341 - val_accuracy: 0.6980\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 2.8881 - accuracy: 0.6574 - val_loss: 0.9575 - val_accuracy: 0.7327\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 3.2442 - accuracy: 0.6362 - val_loss: 0.8949 - val_accuracy: 0.7772\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 269us/step - loss: 3.1252 - accuracy: 0.6596 - val_loss: 1.0811 - val_accuracy: 0.6337\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 3.1588 - accuracy: 0.6489 - val_loss: 0.9405 - val_accuracy: 0.7277\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 3.3187 - accuracy: 0.6191 - val_loss: 1.0525 - val_accuracy: 0.7079\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 126us/step - loss: 3.2265 - accuracy: 0.6085 - val_loss: 1.0768 - val_accuracy: 0.7574\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 2.8555 - accuracy: 0.6723 - val_loss: 1.1197 - val_accuracy: 0.7723\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 2.5046 - accuracy: 0.7085 - val_loss: 0.9358 - val_accuracy: 0.7921\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 450us/step - loss: 2.7013 - accuracy: 0.6915 - val_loss: 0.9220 - val_accuracy: 0.8317\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 272us/step - loss: 2.7158 - accuracy: 0.6936 - val_loss: 0.8404 - val_accuracy: 0.8020\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 278us/step - loss: 2.7128 - accuracy: 0.6766 - val_loss: 0.8901 - val_accuracy: 0.8416\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 283us/step - loss: 3.0987 - accuracy: 0.6596 - val_loss: 0.9632 - val_accuracy: 0.8168\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 363us/step - loss: 2.6205 - accuracy: 0.7064 - val_loss: 0.8285 - val_accuracy: 0.8416\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 309us/step - loss: 3.0307 - accuracy: 0.6809 - val_loss: 1.1626 - val_accuracy: 0.8168\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 2.3818 - accuracy: 0.7383 - val_loss: 1.0238 - val_accuracy: 0.8317\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 2.2031 - accuracy: 0.7617 - val_loss: 0.8583 - val_accuracy: 0.8465\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 2.4781 - accuracy: 0.7383 - val_loss: 1.0959 - val_accuracy: 0.8267\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.3739 - accuracy: 0.7213 - val_loss: 1.1938 - val_accuracy: 0.8267\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 2.6823 - accuracy: 0.7234 - val_loss: 1.1624 - val_accuracy: 0.8416\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 351us/step - loss: 2.5078 - accuracy: 0.7213 - val_loss: 1.4869 - val_accuracy: 0.7871\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 300us/step - loss: 2.3657 - accuracy: 0.7277 - val_loss: 1.1304 - val_accuracy: 0.8812\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 179us/step - loss: 2.6180 - accuracy: 0.7191 - val_loss: 1.3337 - val_accuracy: 0.7970\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 2.1079 - accuracy: 0.7106 - val_loss: 1.0295 - val_accuracy: 0.8762\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 2.0269 - accuracy: 0.7277 - val_loss: 1.0678 - val_accuracy: 0.8762\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 2.3905 - accuracy: 0.7383 - val_loss: 1.1136 - val_accuracy: 0.8119\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.2373 - accuracy: 0.7340 - val_loss: 1.3539 - val_accuracy: 0.8267\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 116us/step - loss: 2.1541 - accuracy: 0.7191 - val_loss: 0.9926 - val_accuracy: 0.8861\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 2.2523 - accuracy: 0.7319 - val_loss: 1.1194 - val_accuracy: 0.8713\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 303us/step - loss: 2.3041 - accuracy: 0.7319 - val_loss: 1.3341 - val_accuracy: 0.8515\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 323us/step - loss: 2.0156 - accuracy: 0.7511 - val_loss: 0.8959 - val_accuracy: 0.8960\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 180us/step - loss: 2.0869 - accuracy: 0.7085 - val_loss: 1.7886 - val_accuracy: 0.7822\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.9299 - accuracy: 0.7404 - val_loss: 1.0518 - val_accuracy: 0.8812\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 123us/step - loss: 2.2883 - accuracy: 0.6957 - val_loss: 0.9265 - val_accuracy: 0.8861\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 113us/step - loss: 1.8090 - accuracy: 0.7532 - val_loss: 1.4234 - val_accuracy: 0.8564\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 2.5464 - accuracy: 0.6851 - val_loss: 1.1271 - val_accuracy: 0.9010\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 117us/step - loss: 2.1493 - accuracy: 0.7298 - val_loss: 1.1457 - val_accuracy: 0.8713\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 114us/step - loss: 2.2333 - accuracy: 0.7255 - val_loss: 1.4296 - val_accuracy: 0.8465\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 303us/step - loss: 2.2241 - accuracy: 0.7362 - val_loss: 1.4257 - val_accuracy: 0.8465\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 256us/step - loss: 1.9606 - accuracy: 0.7383 - val_loss: 1.3073 - val_accuracy: 0.8861\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 2.0734 - accuracy: 0.7383 - val_loss: 1.2650 - val_accuracy: 0.8861\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.8608 - accuracy: 0.7277 - val_loss: 1.3060 - val_accuracy: 0.8663\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 2.1022 - accuracy: 0.7170 - val_loss: 0.9809 - val_accuracy: 0.8861\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 1.7740 - accuracy: 0.7553 - val_loss: 1.0343 - val_accuracy: 0.8861\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.5238 - accuracy: 0.7723 - val_loss: 1.2148 - val_accuracy: 0.8762\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.8551 - accuracy: 0.7447 - val_loss: 1.1936 - val_accuracy: 0.8861\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 1.8745 - accuracy: 0.7489 - val_loss: 1.1809 - val_accuracy: 0.8564\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.8512 - accuracy: 0.7745 - val_loss: 1.2339 - val_accuracy: 0.8911\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 2.2200 - accuracy: 0.7255 - val_loss: 0.8696 - val_accuracy: 0.8861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 2.0712 - accuracy: 0.7383 - val_loss: 1.2173 - val_accuracy: 0.8614\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.8811 - accuracy: 0.7383 - val_loss: 1.5324 - val_accuracy: 0.8515\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 1.9498 - accuracy: 0.7255 - val_loss: 1.3068 - val_accuracy: 0.8960\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 214us/step - loss: 1.8532 - accuracy: 0.7532 - val_loss: 1.3347 - val_accuracy: 0.8812\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.8258 - accuracy: 0.7234 - val_loss: 1.0622 - val_accuracy: 0.8812\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.8467 - accuracy: 0.7553 - val_loss: 0.9187 - val_accuracy: 0.8861\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 121us/step - loss: 1.9101 - accuracy: 0.7298 - val_loss: 1.0193 - val_accuracy: 0.8861\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.9359 - accuracy: 0.7191 - val_loss: 1.0976 - val_accuracy: 0.8812\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 212us/step - loss: 1.9203 - accuracy: 0.7234 - val_loss: 1.4183 - val_accuracy: 0.8911\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.9103 - accuracy: 0.7106 - val_loss: 1.0413 - val_accuracy: 0.8861\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 154us/step - loss: 1.8464 - accuracy: 0.7298 - val_loss: 1.0759 - val_accuracy: 0.9010\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.6210 - accuracy: 0.7404 - val_loss: 1.2527 - val_accuracy: 0.8861\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.5970 - accuracy: 0.7511 - val_loss: 1.1946 - val_accuracy: 0.8812\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.7034 - accuracy: 0.7511 - val_loss: 1.2365 - val_accuracy: 0.8861\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 163us/step - loss: 1.4717 - accuracy: 0.7319 - val_loss: 1.1550 - val_accuracy: 0.8861\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 124us/step - loss: 1.8724 - accuracy: 0.7319 - val_loss: 1.3457 - val_accuracy: 0.8713\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 201us/step - loss: 1.7597 - accuracy: 0.7340 - val_loss: 1.2932 - val_accuracy: 0.8861\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.7122 - accuracy: 0.7468 - val_loss: 0.9880 - val_accuracy: 0.9059\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 176us/step - loss: 1.6372 - accuracy: 0.7426 - val_loss: 1.0615 - val_accuracy: 0.8861\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.5093 - accuracy: 0.7298 - val_loss: 1.1889 - val_accuracy: 0.8515\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 145us/step - loss: 1.6369 - accuracy: 0.7298 - val_loss: 1.4860 - val_accuracy: 0.8713\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 382us/step - loss: 1.3837 - accuracy: 0.7489 - val_loss: 0.8753 - val_accuracy: 0.9059\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 207us/step - loss: 1.5314 - accuracy: 0.7617 - val_loss: 0.9626 - val_accuracy: 0.9059\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 189us/step - loss: 1.4724 - accuracy: 0.7362 - val_loss: 1.3555 - val_accuracy: 0.8861\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.7106 - accuracy: 0.7447 - val_loss: 1.3357 - val_accuracy: 0.9010\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 1.5095 - accuracy: 0.7660 - val_loss: 1.2165 - val_accuracy: 0.8861\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 1.5656 - accuracy: 0.7340 - val_loss: 0.7485 - val_accuracy: 0.9059\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.5232 - accuracy: 0.7170 - val_loss: 1.4038 - val_accuracy: 0.8713\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.6223 - accuracy: 0.7298 - val_loss: 0.7941 - val_accuracy: 0.9059\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 250us/step - loss: 1.2660 - accuracy: 0.7745 - val_loss: 0.7899 - val_accuracy: 0.9059\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 226us/step - loss: 1.4071 - accuracy: 0.7277 - val_loss: 0.8098 - val_accuracy: 0.9010\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 223us/step - loss: 1.4952 - accuracy: 0.7532 - val_loss: 1.0185 - val_accuracy: 0.8911\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 302us/step - loss: 1.5683 - accuracy: 0.7447 - val_loss: 0.9312 - val_accuracy: 0.9059\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 257us/step - loss: 1.6279 - accuracy: 0.7277 - val_loss: 1.1575 - val_accuracy: 0.8911\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 263us/step - loss: 1.3942 - accuracy: 0.7617 - val_loss: 0.8690 - val_accuracy: 0.8960\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 131us/step - loss: 1.4940 - accuracy: 0.7489 - val_loss: 1.0695 - val_accuracy: 0.9010\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.4030 - accuracy: 0.7277 - val_loss: 1.3038 - val_accuracy: 0.9010\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 361us/step - loss: 1.4633 - accuracy: 0.7638 - val_loss: 1.0979 - val_accuracy: 0.8812\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 249us/step - loss: 1.5433 - accuracy: 0.7553 - val_loss: 1.2604 - val_accuracy: 0.8911\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 167us/step - loss: 1.5537 - accuracy: 0.7404 - val_loss: 1.2243 - val_accuracy: 0.8911\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.4811 - accuracy: 0.7447 - val_loss: 1.0807 - val_accuracy: 0.8911\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 153us/step - loss: 1.7023 - accuracy: 0.7298 - val_loss: 1.1427 - val_accuracy: 0.8911\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 204us/step - loss: 1.3115 - accuracy: 0.7702 - val_loss: 1.0218 - val_accuracy: 0.8762\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.4870 - accuracy: 0.7277 - val_loss: 1.0927 - val_accuracy: 0.8911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a39530940>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 111us/step\n",
      "over-sampling test accuracy: 92.57%\n"
     ]
    }
   ],
   "source": [
    "acc_test_over8 = model1_over8.evaluate(X_test_over, y_test_over)[1]\n",
    "print('over-sampling test accuracy: %.2f%%' % (acc_test_over8*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 2,\n",
       "       1, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 0, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 0, 2, 1, 0, 2,\n",
       "       0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 0, 2, 2, 1,\n",
       "       0, 2, 2, 2, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 0,\n",
       "       1, 2, 0, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 1, 0, 1, 2, 1, 0, 0, 2,\n",
       "       1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 2,\n",
       "       2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       1, 0, 1, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred8 = model1_over8.predict_classes(X_test_over)\n",
    "pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SR3585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRS232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRS180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NRS209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NRS035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SR2091</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NRS205</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  test  pred\n",
       "0     CA541     1     0\n",
       "1    SR3585     0     0\n",
       "2    NRS232     1     1\n",
       "3    NRS148     2     2\n",
       "4    NRS180     1     1\n",
       "..      ...   ...   ...\n",
       "197  NRS209     2     2\n",
       "198  NRS035     1     1\n",
       "199     506     0     0\n",
       "200  SR2091     0     1\n",
       "201  NRS205     1     2\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat8['pred'] = pred8\n",
    "dat8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba8 = model1_over8.predict_proba(X_test_over)\n",
    "dat_proba8 = pd.DataFrame(proba8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.969602e-01</td>\n",
       "      <td>3.039824e-03</td>\n",
       "      <td>8.615204e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.969602e-01</td>\n",
       "      <td>3.039824e-03</td>\n",
       "      <td>8.615204e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.787695e-06</td>\n",
       "      <td>9.999982e-01</td>\n",
       "      <td>3.214948e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.319543e-08</td>\n",
       "      <td>1.008986e-07</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.011245e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.781401e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.449390e-09</td>\n",
       "      <td>6.278701e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.906269e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.059978e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.207479e-08</td>\n",
       "      <td>9.831998e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4.492901e-05</td>\n",
       "      <td>9.999549e-01</td>\n",
       "      <td>1.165648e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2.205748e-04</td>\n",
       "      <td>4.212096e-04</td>\n",
       "      <td>9.993582e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2\n",
       "0    9.969602e-01  3.039824e-03  8.615204e-10\n",
       "1    9.969602e-01  3.039824e-03  8.615204e-10\n",
       "2    1.787695e-06  9.999982e-01  3.214948e-10\n",
       "3    4.319543e-08  1.008986e-07  9.999999e-01\n",
       "4    4.011245e-10  1.000000e+00  4.781401e-11\n",
       "..            ...           ...           ...\n",
       "197  1.449390e-09  6.278701e-09  1.000000e+00\n",
       "198  4.906269e-10  1.000000e+00  4.059978e-13\n",
       "199  9.999999e-01  9.207479e-08  9.831998e-12\n",
       "200  4.492901e-05  9.999549e-01  1.165648e-07\n",
       "201  2.205748e-04  4.212096e-04  9.993582e-01\n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_proba8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/proba8.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat8.to_csv(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/8p003ST.csv\", index = False,\n",
    "         header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "470/470 [==============================] - 0s 211us/step - loss: 1.4766 - accuracy: 0.7106 - val_loss: 1.0298 - val_accuracy: 0.8812\n",
      "Epoch 2/100\n",
      "470/470 [==============================] - 0s 182us/step - loss: 1.2216 - accuracy: 0.7426 - val_loss: 0.7255 - val_accuracy: 0.9109\n",
      "Epoch 3/100\n",
      "470/470 [==============================] - 0s 175us/step - loss: 1.1136 - accuracy: 0.7723 - val_loss: 0.6541 - val_accuracy: 0.9059\n",
      "Epoch 4/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.1265 - accuracy: 0.7660 - val_loss: 0.6172 - val_accuracy: 0.9109\n",
      "Epoch 5/100\n",
      "470/470 [==============================] - 0s 186us/step - loss: 1.0156 - accuracy: 0.7617 - val_loss: 0.8317 - val_accuracy: 0.9208\n",
      "Epoch 6/100\n",
      "470/470 [==============================] - 0s 183us/step - loss: 1.1365 - accuracy: 0.7553 - val_loss: 0.5337 - val_accuracy: 0.9109\n",
      "Epoch 7/100\n",
      "470/470 [==============================] - 0s 206us/step - loss: 1.2868 - accuracy: 0.7553 - val_loss: 0.7673 - val_accuracy: 0.9059\n",
      "Epoch 8/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 1.1073 - accuracy: 0.7596 - val_loss: 0.6086 - val_accuracy: 0.9109\n",
      "Epoch 9/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.1687 - accuracy: 0.7532 - val_loss: 0.8238 - val_accuracy: 0.9109\n",
      "Epoch 10/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.1474 - accuracy: 0.7340 - val_loss: 0.4981 - val_accuracy: 0.9208\n",
      "Epoch 11/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.0584 - accuracy: 0.7723 - val_loss: 0.9769 - val_accuracy: 0.8911\n",
      "Epoch 12/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.0860 - accuracy: 0.7340 - val_loss: 0.4313 - val_accuracy: 0.9307\n",
      "Epoch 13/100\n",
      "470/470 [==============================] - 0s 240us/step - loss: 1.4275 - accuracy: 0.7404 - val_loss: 0.7661 - val_accuracy: 0.9257\n",
      "Epoch 14/100\n",
      "470/470 [==============================] - 0s 252us/step - loss: 1.2698 - accuracy: 0.7574 - val_loss: 0.6377 - val_accuracy: 0.9257\n",
      "Epoch 15/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 1.1750 - accuracy: 0.7383 - val_loss: 0.4457 - val_accuracy: 0.9059\n",
      "Epoch 16/100\n",
      "470/470 [==============================] - 0s 139us/step - loss: 1.0498 - accuracy: 0.7489 - val_loss: 0.6874 - val_accuracy: 0.9307\n",
      "Epoch 17/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.3755 - accuracy: 0.7426 - val_loss: 0.7247 - val_accuracy: 0.9257\n",
      "Epoch 18/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.0218 - accuracy: 0.7723 - val_loss: 0.5191 - val_accuracy: 0.9109\n",
      "Epoch 19/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.2323 - accuracy: 0.7723 - val_loss: 0.7102 - val_accuracy: 0.9307\n",
      "Epoch 20/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 1.3095 - accuracy: 0.7681 - val_loss: 0.7120 - val_accuracy: 0.9505\n",
      "Epoch 21/100\n",
      "470/470 [==============================] - 0s 172us/step - loss: 1.3483 - accuracy: 0.7404 - val_loss: 1.0462 - val_accuracy: 0.9158\n",
      "Epoch 22/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.2633 - accuracy: 0.7319 - val_loss: 0.6178 - val_accuracy: 0.9257\n",
      "Epoch 23/100\n",
      "470/470 [==============================] - 0s 161us/step - loss: 0.9514 - accuracy: 0.7638 - val_loss: 0.5907 - val_accuracy: 0.9406\n",
      "Epoch 24/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.0943 - accuracy: 0.8021 - val_loss: 0.6317 - val_accuracy: 0.9208\n",
      "Epoch 25/100\n",
      "470/470 [==============================] - 0s 166us/step - loss: 1.1158 - accuracy: 0.7660 - val_loss: 0.4744 - val_accuracy: 0.9208\n",
      "Epoch 26/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.9733 - accuracy: 0.7766 - val_loss: 0.4594 - val_accuracy: 0.9059\n",
      "Epoch 27/100\n",
      "470/470 [==============================] - 0s 178us/step - loss: 1.0258 - accuracy: 0.7681 - val_loss: 0.7651 - val_accuracy: 0.9307\n",
      "Epoch 28/100\n",
      "470/470 [==============================] - 0s 188us/step - loss: 1.2938 - accuracy: 0.7362 - val_loss: 0.7005 - val_accuracy: 0.9307\n",
      "Epoch 29/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.2484 - accuracy: 0.7234 - val_loss: 0.6058 - val_accuracy: 0.9455\n",
      "Epoch 30/100\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.9814 - accuracy: 0.7787 - val_loss: 0.5622 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.2608 - accuracy: 0.7362 - val_loss: 0.8230 - val_accuracy: 0.9307\n",
      "Epoch 32/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 1.1230 - accuracy: 0.7553 - val_loss: 0.6867 - val_accuracy: 0.9455\n",
      "Epoch 33/100\n",
      "470/470 [==============================] - 0s 158us/step - loss: 1.0538 - accuracy: 0.7702 - val_loss: 0.5123 - val_accuracy: 0.9406\n",
      "Epoch 34/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.9737 - accuracy: 0.7638 - val_loss: 0.7659 - val_accuracy: 0.9010\n",
      "Epoch 35/100\n",
      "470/470 [==============================] - 0s 157us/step - loss: 1.1620 - accuracy: 0.7234 - val_loss: 0.4866 - val_accuracy: 0.9208\n",
      "Epoch 36/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 1.0586 - accuracy: 0.7404 - val_loss: 0.9619 - val_accuracy: 0.8960\n",
      "Epoch 37/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.1065 - accuracy: 0.7766 - val_loss: 0.6074 - val_accuracy: 0.9109\n",
      "Epoch 38/100\n",
      "470/470 [==============================] - 0s 137us/step - loss: 1.0297 - accuracy: 0.7553 - val_loss: 0.9363 - val_accuracy: 0.9257\n",
      "Epoch 39/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.3007 - accuracy: 0.7702 - val_loss: 0.8729 - val_accuracy: 0.9109\n",
      "Epoch 40/100\n",
      "470/470 [==============================] - 0s 129us/step - loss: 1.2919 - accuracy: 0.7340 - val_loss: 0.9731 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.2331 - accuracy: 0.7447 - val_loss: 0.9120 - val_accuracy: 0.8812\n",
      "Epoch 42/100\n",
      "470/470 [==============================] - 0s 152us/step - loss: 1.2889 - accuracy: 0.7362 - val_loss: 0.9592 - val_accuracy: 0.9257\n",
      "Epoch 43/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.1905 - accuracy: 0.7277 - val_loss: 0.9094 - val_accuracy: 0.9257\n",
      "Epoch 44/100\n",
      "470/470 [==============================] - 0s 132us/step - loss: 1.0767 - accuracy: 0.7681 - val_loss: 0.4918 - val_accuracy: 0.9307\n",
      "Epoch 45/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.1159 - accuracy: 0.7447 - val_loss: 0.7617 - val_accuracy: 0.9257\n",
      "Epoch 46/100\n",
      "470/470 [==============================] - 0s 127us/step - loss: 1.2637 - accuracy: 0.7447 - val_loss: 0.6671 - val_accuracy: 0.9257\n",
      "Epoch 47/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 1.1935 - accuracy: 0.7617 - val_loss: 0.5856 - val_accuracy: 0.9455\n",
      "Epoch 48/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 0.9967 - accuracy: 0.7702 - val_loss: 0.6003 - val_accuracy: 0.9455\n",
      "Epoch 49/100\n",
      "470/470 [==============================] - 0s 128us/step - loss: 1.0106 - accuracy: 0.7638 - val_loss: 0.6442 - val_accuracy: 0.9455\n",
      "Epoch 50/100\n",
      "470/470 [==============================] - 0s 141us/step - loss: 1.0097 - accuracy: 0.7851 - val_loss: 0.5577 - val_accuracy: 0.9406\n",
      "Epoch 51/100\n",
      "470/470 [==============================] - 0s 197us/step - loss: 0.9741 - accuracy: 0.7574 - val_loss: 0.7425 - val_accuracy: 0.9455\n",
      "Epoch 52/100\n",
      "470/470 [==============================] - 0s 133us/step - loss: 1.0246 - accuracy: 0.7830 - val_loss: 0.6596 - val_accuracy: 0.8960\n",
      "Epoch 53/100\n",
      "470/470 [==============================] - 0s 130us/step - loss: 1.0167 - accuracy: 0.7617 - val_loss: 0.7333 - val_accuracy: 0.9307\n",
      "Epoch 54/100\n",
      "470/470 [==============================] - 0s 134us/step - loss: 1.0238 - accuracy: 0.7702 - val_loss: 0.4793 - val_accuracy: 0.9307\n",
      "Epoch 55/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 1.0852 - accuracy: 0.7596 - val_loss: 0.7868 - val_accuracy: 0.9455\n",
      "Epoch 56/100\n",
      "470/470 [==============================] - 0s 119us/step - loss: 1.0383 - accuracy: 0.7681 - val_loss: 0.7572 - val_accuracy: 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "470/470 [==============================] - 0s 122us/step - loss: 0.9610 - accuracy: 0.7553 - val_loss: 0.4524 - val_accuracy: 0.9208\n",
      "Epoch 58/100\n",
      "470/470 [==============================] - 0s 118us/step - loss: 0.9293 - accuracy: 0.7532 - val_loss: 0.6538 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "470/470 [==============================] - 0s 135us/step - loss: 1.0819 - accuracy: 0.7404 - val_loss: 0.7406 - val_accuracy: 0.9455\n",
      "Epoch 60/100\n",
      "470/470 [==============================] - 0s 155us/step - loss: 1.1219 - accuracy: 0.7447 - val_loss: 0.6481 - val_accuracy: 0.9455\n",
      "Epoch 61/100\n",
      "470/470 [==============================] - 0s 401us/step - loss: 0.7475 - accuracy: 0.8149 - val_loss: 0.4204 - val_accuracy: 0.9307\n",
      "Epoch 62/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 1.2104 - accuracy: 0.7660 - val_loss: 0.7108 - val_accuracy: 0.9406\n",
      "Epoch 63/100\n",
      "470/470 [==============================] - 0s 191us/step - loss: 0.9307 - accuracy: 0.7957 - val_loss: 0.6432 - val_accuracy: 0.9455\n",
      "Epoch 64/100\n",
      "470/470 [==============================] - 0s 203us/step - loss: 1.1482 - accuracy: 0.7553 - val_loss: 0.4380 - val_accuracy: 0.9208\n",
      "Epoch 65/100\n",
      "470/470 [==============================] - 0s 205us/step - loss: 0.9777 - accuracy: 0.7681 - val_loss: 0.4796 - val_accuracy: 0.9356\n",
      "Epoch 66/100\n",
      "470/470 [==============================] - 0s 500us/step - loss: 0.9672 - accuracy: 0.7745 - val_loss: 0.5476 - val_accuracy: 0.9406\n",
      "Epoch 67/100\n",
      "470/470 [==============================] - 0s 350us/step - loss: 0.9796 - accuracy: 0.7894 - val_loss: 0.4704 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "470/470 [==============================] - 0s 339us/step - loss: 0.9740 - accuracy: 0.7681 - val_loss: 0.7423 - val_accuracy: 0.9158\n",
      "Epoch 69/100\n",
      "470/470 [==============================] - 0s 258us/step - loss: 1.1459 - accuracy: 0.7766 - val_loss: 0.7827 - val_accuracy: 0.9455\n",
      "Epoch 70/100\n",
      "470/470 [==============================] - 0s 174us/step - loss: 1.0635 - accuracy: 0.7383 - val_loss: 0.5948 - val_accuracy: 0.9455\n",
      "Epoch 71/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.0901 - accuracy: 0.7617 - val_loss: 0.8179 - val_accuracy: 0.9158\n",
      "Epoch 72/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.1029 - accuracy: 0.7574 - val_loss: 0.5221 - val_accuracy: 0.9257\n",
      "Epoch 73/100\n",
      "470/470 [==============================] - 0s 358us/step - loss: 1.0002 - accuracy: 0.7574 - val_loss: 0.7041 - val_accuracy: 0.9455\n",
      "Epoch 74/100\n",
      "470/470 [==============================] - 0s 216us/step - loss: 0.8690 - accuracy: 0.7872 - val_loss: 0.4790 - val_accuracy: 0.9307\n",
      "Epoch 75/100\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.9042 - accuracy: 0.7957 - val_loss: 0.4356 - val_accuracy: 0.9208\n",
      "Epoch 76/100\n",
      "470/470 [==============================] - 0s 181us/step - loss: 1.0548 - accuracy: 0.7596 - val_loss: 0.4890 - val_accuracy: 0.9455\n",
      "Epoch 77/100\n",
      "470/470 [==============================] - 0s 165us/step - loss: 0.9826 - accuracy: 0.7638 - val_loss: 0.8228 - val_accuracy: 0.9208\n",
      "Epoch 78/100\n",
      "470/470 [==============================] - 0s 146us/step - loss: 1.1653 - accuracy: 0.7915 - val_loss: 0.7505 - val_accuracy: 0.9356\n",
      "Epoch 79/100\n",
      "470/470 [==============================] - 0s 169us/step - loss: 1.2127 - accuracy: 0.7532 - val_loss: 0.6410 - val_accuracy: 0.9109\n",
      "Epoch 80/100\n",
      "470/470 [==============================] - 0s 150us/step - loss: 1.1738 - accuracy: 0.7723 - val_loss: 0.5097 - val_accuracy: 0.9455\n",
      "Epoch 81/100\n",
      "470/470 [==============================] - 0s 143us/step - loss: 0.9460 - accuracy: 0.7766 - val_loss: 0.9592 - val_accuracy: 0.9109\n",
      "Epoch 82/100\n",
      "470/470 [==============================] - 0s 162us/step - loss: 1.0706 - accuracy: 0.8021 - val_loss: 0.6148 - val_accuracy: 0.9455\n",
      "Epoch 83/100\n",
      "470/470 [==============================] - 0s 136us/step - loss: 0.9245 - accuracy: 0.7489 - val_loss: 0.4554 - val_accuracy: 0.9208\n",
      "Epoch 84/100\n",
      "470/470 [==============================] - 0s 140us/step - loss: 1.1514 - accuracy: 0.7574 - val_loss: 0.7964 - val_accuracy: 0.9455\n",
      "Epoch 85/100\n",
      "470/470 [==============================] - 0s 264us/step - loss: 0.9599 - accuracy: 0.7851 - val_loss: 0.6284 - val_accuracy: 0.9455\n",
      "Epoch 86/100\n",
      "470/470 [==============================] - 0s 371us/step - loss: 1.0172 - accuracy: 0.7468 - val_loss: 0.5635 - val_accuracy: 0.9455\n",
      "Epoch 87/100\n",
      "470/470 [==============================] - 0s 583us/step - loss: 1.0077 - accuracy: 0.7468 - val_loss: 0.7079 - val_accuracy: 0.9307\n",
      "Epoch 88/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.9712 - accuracy: 0.7149 - val_loss: 0.4745 - val_accuracy: 0.9109\n",
      "Epoch 89/100\n",
      "470/470 [==============================] - 0s 239us/step - loss: 0.7880 - accuracy: 0.7830 - val_loss: 0.4470 - val_accuracy: 0.9257\n",
      "Epoch 90/100\n",
      "470/470 [==============================] - 0s 228us/step - loss: 1.0749 - accuracy: 0.7745 - val_loss: 0.8218 - val_accuracy: 0.9307\n",
      "Epoch 91/100\n",
      "470/470 [==============================] - 0s 221us/step - loss: 1.0482 - accuracy: 0.7745 - val_loss: 0.7032 - val_accuracy: 0.9257\n",
      "Epoch 92/100\n",
      "470/470 [==============================] - 0s 242us/step - loss: 1.0294 - accuracy: 0.7426 - val_loss: 0.5700 - val_accuracy: 0.9455\n",
      "Epoch 93/100\n",
      "470/470 [==============================] - 0s 190us/step - loss: 0.8858 - accuracy: 0.7404 - val_loss: 0.6494 - val_accuracy: 0.9455\n",
      "Epoch 94/100\n",
      "470/470 [==============================] - 0s 261us/step - loss: 0.9366 - accuracy: 0.7574 - val_loss: 0.5468 - val_accuracy: 0.9406\n",
      "Epoch 95/100\n",
      "470/470 [==============================] - 0s 231us/step - loss: 1.2191 - accuracy: 0.7128 - val_loss: 1.2130 - val_accuracy: 0.8762\n",
      "Epoch 96/100\n",
      "470/470 [==============================] - 0s 245us/step - loss: 0.8297 - accuracy: 0.7681 - val_loss: 0.5668 - val_accuracy: 0.9307\n",
      "Epoch 97/100\n",
      "470/470 [==============================] - 0s 246us/step - loss: 0.9863 - accuracy: 0.7660 - val_loss: 0.5053 - val_accuracy: 0.9356\n",
      "Epoch 98/100\n",
      "470/470 [==============================] - 0s 273us/step - loss: 0.9844 - accuracy: 0.7638 - val_loss: 0.6344 - val_accuracy: 0.9406\n",
      "Epoch 99/100\n",
      "470/470 [==============================] - 0s 286us/step - loss: 0.9012 - accuracy: 0.7702 - val_loss: 0.5986 - val_accuracy: 0.9307\n",
      "Epoch 100/100\n",
      "470/470 [==============================] - 0s 253us/step - loss: 0.7494 - accuracy: 0.7723 - val_loss: 0.4405 - val_accuracy: 0.9307\n"
     ]
    }
   ],
   "source": [
    "hist1_over8 = model1_over8.fit(X_train_over, y_train_over,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_test_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy: 75.96%\n"
     ]
    }
   ],
   "source": [
    "print('over-sampling train accuracy: %.2f%%' % (np.mean(hist1_over8.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba8 = pd.read_excel(\"/Users/Rebecca/Desktop/Claudia/neural network/new_phage_qual/dataset/NN_over_regularizor_dropout_2.xlsx\",\n",
    "                        sheet_name=3,\n",
    "                        index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phage</th>\n",
       "      <th>strain</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.676203e-01</td>\n",
       "      <td>3.237956e-02</td>\n",
       "      <td>1.480166e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534852e-11</td>\n",
       "      <td>2.250731e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002ykpresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.948571e-11</td>\n",
       "      <td>2.839096e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS205</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.691095e-08</td>\n",
       "      <td>3.571927e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>CFBREBSa122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.261665e-02</td>\n",
       "      <td>9.073822e-01</td>\n",
       "      <td>1.162373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.174278e-07</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>3.254024e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS148</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.234670e-08</td>\n",
       "      <td>3.121212e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>pyopresabsSTCC_qual</td>\n",
       "      <td>NRS265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.250178e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>6.719974e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1982 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phage       strain  phenotype  prediction  \\\n",
       "0     p002ykpresabsSTCC_qual  CFBREBSa116          0           0   \n",
       "1     p002ykpresabsSTCC_qual       NRS214          0           0   \n",
       "2     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "3     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "4     p002ykpresabsSTCC_qual       NRS148          2           2   \n",
       "...                      ...          ...        ...         ...   \n",
       "1977     pyopresabsSTCC_qual       NRS205          2           2   \n",
       "1978     pyopresabsSTCC_qual  CFBREBSa122          0           1   \n",
       "1979     pyopresabsSTCC_qual       NRS001          1           1   \n",
       "1980     pyopresabsSTCC_qual       NRS148          2           2   \n",
       "1981     pyopresabsSTCC_qual       NRS265          1           1   \n",
       "\n",
       "                 0             1             2  \n",
       "0     9.676203e-01  3.237956e-02  1.480166e-07  \n",
       "1     1.000000e+00  6.534852e-11  2.250731e-18  \n",
       "2     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "3     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "4     3.948571e-11  2.839096e-07  9.999998e-01  \n",
       "...            ...           ...           ...  \n",
       "1977  3.691095e-08  3.571927e-08  9.999999e-01  \n",
       "1978  9.261665e-02  9.073822e-01  1.162373e-06  \n",
       "1979  4.174278e-07  9.999995e-01  3.254024e-09  \n",
       "1980  3.234670e-08  3.121212e-08  9.999999e-01  \n",
       "1981  5.250178e-08  9.999999e-01  6.719974e-08  \n",
       "\n",
       "[1982 rows x 7 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.78769460e-06, 9.99998200e-01, 3.21494800e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [2.20574830e-04, 4.21209580e-04, 9.99358240e-01],\n",
       "       [2.52445300e-17, 1.00000000e+00, 3.75606500e-15],\n",
       "       [4.38614620e-05, 9.99956000e-01, 1.11552330e-07],\n",
       "       [1.05748220e-08, 1.00000000e+00, 2.73962910e-14],\n",
       "       [7.28439900e-05, 9.99927160e-01, 1.29792440e-08],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.70838720e-10, 1.16078610e-15],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [7.41889300e-12, 1.00000000e+00, 4.46696200e-10],\n",
       "       [7.28439900e-05, 9.99927160e-01, 1.29792440e-08],\n",
       "       [7.28439900e-05, 9.99927160e-01, 1.29792440e-08],\n",
       "       [9.87471760e-01, 1.25282150e-02, 8.42257430e-10],\n",
       "       [1.00000000e+00, 7.40206200e-15, 9.97417500e-15],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.05748220e-08, 1.00000000e+00, 2.73962910e-14],\n",
       "       [1.00000000e+00, 1.77081430e-08, 2.99907800e-11],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [9.99897100e-01, 1.02897830e-04, 5.91650800e-11],\n",
       "       [4.38614620e-05, 9.99956000e-01, 1.11552330e-07],\n",
       "       [2.52445300e-17, 1.00000000e+00, 3.75606500e-15],\n",
       "       [1.58437470e-15, 1.00000000e+00, 3.27654630e-16],\n",
       "       [1.08345916e-10, 1.00000000e+00, 6.40801800e-18],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [9.26139300e-08, 9.99999900e-01, 1.43771870e-12],\n",
       "       [1.00000000e+00, 1.30227040e-14, 2.64607370e-28],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [7.75545400e-09, 1.00000000e+00, 2.71841180e-11],\n",
       "       [1.00000000e+00, 1.00733540e-12, 6.67439840e-19],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 1.16542230e-08, 1.38624040e-15],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.73604330e-16, 2.35832140e-19],\n",
       "       [9.99996070e-01, 3.92964830e-06, 1.71706860e-08],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [9.26139300e-08, 9.99999900e-01, 1.43771870e-12],\n",
       "       [1.76257060e-06, 9.99998200e-01, 3.13284600e-10],\n",
       "       [1.00000000e+00, 1.30586090e-12, 1.86954440e-14],\n",
       "       [1.00000000e+00, 1.55587400e-19, 5.45998300e-36],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 2.00385330e-08, 1.67824570e-09],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.08565500e-02, 5.65140100e-01, 3.94003240e-01],\n",
       "       [1.58437470e-15, 1.00000000e+00, 3.27654630e-16],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 1.34848120e-11, 1.99766490e-14],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [2.52445300e-17, 1.00000000e+00, 3.75606500e-15],\n",
       "       [1.00000000e+00, 3.70838720e-10, 1.16078610e-15],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [9.99897100e-01, 1.02897830e-04, 5.91650800e-11],\n",
       "       [1.78769460e-06, 9.99998200e-01, 3.21494800e-10],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 4.32612500e-11, 1.70966600e-09],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [7.28439900e-05, 9.99927160e-01, 1.29792440e-08],\n",
       "       [1.00000000e+00, 4.97040350e-10, 3.22711830e-10],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [2.12287500e-02, 1.26924220e-01, 8.51847050e-01],\n",
       "       [9.99920500e-01, 7.95174100e-05, 1.56382280e-10],\n",
       "       [1.00000000e+00, 1.30363980e-10, 2.81017600e-11],\n",
       "       [9.26139300e-08, 9.99999900e-01, 1.43771870e-12],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [9.53140440e-01, 4.68595660e-02, 7.54204500e-09],\n",
       "       [1.00000000e+00, 7.40206200e-15, 9.97417500e-15],\n",
       "       [1.00000000e+00, 3.81929650e-20, 1.55078840e-36],\n",
       "       [5.55750960e-09, 1.00000000e+00, 8.46781500e-15],\n",
       "       [1.00000000e+00, 2.16028400e-17, 1.20367430e-23],\n",
       "       [1.00000000e+00, 2.36531880e-14, 1.61175910e-21],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [7.11807600e-14, 1.00000000e+00, 6.49134440e-12],\n",
       "       [3.34179150e-03, 9.96163500e-01, 4.94708250e-04],\n",
       "       [9.99920500e-01, 7.95174100e-05, 1.56382280e-10],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [9.88865300e-01, 1.11346910e-02, 5.61000630e-10],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [7.11807600e-14, 1.00000000e+00, 6.49134440e-12],\n",
       "       [1.00000000e+00, 2.87351370e-35, 0.00000000e+00],\n",
       "       [1.00000000e+00, 7.97621800e-10, 2.61530000e-10],\n",
       "       [1.00000000e+00, 7.97621800e-10, 2.61530000e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 6.82823540e-15, 2.34554300e-21],\n",
       "       [7.28439900e-05, 9.99927160e-01, 1.29792440e-08],\n",
       "       [2.20574830e-04, 4.21209580e-04, 9.99358240e-01],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [3.71323380e-02, 3.74203440e-01, 5.88664200e-01],\n",
       "       [5.80742230e-10, 1.00000000e+00, 8.32850800e-11],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [7.41889300e-12, 1.00000000e+00, 4.46696200e-10],\n",
       "       [1.00000000e+00, 1.85830520e-08, 6.91833800e-11],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.00000000e+00, 4.83210900e-15, 1.12113970e-22],\n",
       "       [1.00000000e+00, 1.34848120e-11, 1.99766490e-14],\n",
       "       [1.00000000e+00, 5.92183660e-11, 7.25704150e-14],\n",
       "       [9.99996200e-01, 3.78055570e-06, 7.86170200e-17],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [5.80742230e-10, 1.00000000e+00, 8.32850800e-11],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [4.85105150e-14, 1.00000000e+00, 4.51860420e-12],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.34848120e-11, 1.99766490e-14],\n",
       "       [4.24103350e-03, 9.94925600e-01, 8.33291970e-04],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 4.97040350e-10, 3.22711830e-10],\n",
       "       [2.72943660e-11, 1.00000000e+00, 1.79202550e-09],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 1.34848120e-11, 1.99766490e-14],\n",
       "       [7.41889300e-12, 1.00000000e+00, 4.46696200e-10],\n",
       "       [9.99642400e-01, 3.57375070e-04, 2.92394700e-07],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.61516420e-08, 1.00000000e+00, 3.93807460e-10],\n",
       "       [9.99983200e-01, 1.67985900e-05, 5.68715900e-08],\n",
       "       [1.00000000e+00, 8.34176300e-12, 6.52247100e-12],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [5.80742230e-10, 1.00000000e+00, 8.32850800e-11],\n",
       "       [9.98934570e-01, 1.06545490e-03, 4.75172950e-14],\n",
       "       [1.00000000e+00, 8.34176300e-12, 6.52247100e-12],\n",
       "       [9.99920500e-01, 7.95174100e-05, 1.56382280e-10],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.78769460e-06, 9.99998200e-01, 3.21494800e-10],\n",
       "       [1.00000000e+00, 5.31503700e-11, 1.27577250e-10],\n",
       "       [1.00000000e+00, 1.30363980e-10, 2.81017600e-11],\n",
       "       [1.00000000e+00, 7.97621800e-10, 2.61530000e-10],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [5.55750960e-09, 1.00000000e+00, 8.46781500e-15],\n",
       "       [7.41889300e-12, 1.00000000e+00, 4.46696200e-10],\n",
       "       [1.58437470e-15, 1.00000000e+00, 3.27654630e-16],\n",
       "       [1.76257060e-06, 9.99998200e-01, 3.13284600e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 1.30363980e-10, 2.81017600e-11],\n",
       "       [1.00000000e+00, 6.27979350e-12, 6.07903200e-12],\n",
       "       [2.66921070e-02, 1.90325130e-01, 7.82982770e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [4.39013260e-07, 9.99999500e-01, 1.91910670e-13],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.00000000e+00, 7.29523960e-35, 0.00000000e+00],\n",
       "       [2.52445300e-17, 1.00000000e+00, 3.75606500e-15],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.76257060e-06, 9.99998200e-01, 3.13284600e-10],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [4.31954350e-08, 1.00898570e-07, 9.99999900e-01],\n",
       "       [4.01124500e-10, 1.00000000e+00, 4.78140130e-11],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.00000000e+00, 9.08530850e-20, 2.95570500e-36],\n",
       "       [1.00000000e+00, 2.98256020e-13, 8.09339800e-16],\n",
       "       [9.96960160e-01, 3.03982430e-03, 8.61520400e-10],\n",
       "       [1.00000000e+00, 7.40206200e-15, 9.97417500e-15],\n",
       "       [1.00000000e+00, 7.97621800e-10, 2.61530000e-10],\n",
       "       [2.20574830e-04, 4.21209580e-04, 9.99358240e-01],\n",
       "       [1.81552200e-03, 2.62257100e-03, 9.95561960e-01],\n",
       "       [1.44938970e-09, 6.27870100e-09, 1.00000000e+00],\n",
       "       [4.90626930e-10, 1.00000000e+00, 4.05997770e-13],\n",
       "       [9.99999900e-01, 9.20747850e-08, 9.83199800e-12],\n",
       "       [4.49290130e-05, 9.99954940e-01, 1.16564834e-07],\n",
       "       [2.20574830e-04, 4.21209580e-04, 9.99358240e-01]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob8 = df_proba8[df_proba8['phage']=='p003pkpresabsSTCC_qual'].iloc[:,-3:]\n",
    "y_prob8 = y_prob8.to_numpy()\n",
    "y_prob8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539199427698111"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo8 = rocauc_ovo(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovo\")\n",
    "ovo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9539199427698111"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr8 = rocauc_ovr(y_test_over, y_prob8, average=\"macro\", multi_class=\"ovr\")\n",
    "ovr8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676615221821178"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovos2 = [ovo5, ovo6, ovo7, ovo8]\n",
    "np.mean(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008664610735943193"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676615221821178"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovrs2 = [ovr5, ovr6, ovr7, ovr8]\n",
    "np.mean(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008664610735943193"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(ovrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_reg = [acc_test_over5, acc_test_over6, acc_test_over7, acc_test_over8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization mean: 90.97%\n"
     ]
    }
   ],
   "source": [
    "mean_reg = np.mean(accs_reg)\n",
    "print('over-sampling test accuracy regularization mean: %.2f%%' % (mean_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling test accuracy regularization standard deviation: 0.017282487758180157\n"
     ]
    }
   ],
   "source": [
    "std_reg = np.std(accs_reg)\n",
    "print('over-sampling test accuracy regularization standard deviation:', std_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accs_train_reg = [np.mean(hist1_over5.history['accuracy']), np.mean(hist1_over6.history['accuracy']), np.mean(hist1_over7.history['accuracy']),\n",
    "             np.mean(hist1_over8.history['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization mean: 75.79%\n"
     ]
    }
   ],
   "source": [
    "mean_train_reg = np.mean(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization mean: %.2f%%' % (mean_train_reg*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over-sampling train accuracy regularization standard deviation: 0.0030917057\n"
     ]
    }
   ],
   "source": [
    "std_train_reg = np.std(accs_train_reg)\n",
    "print('over-sampling train accuracy regularization standard deviation:', std_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
